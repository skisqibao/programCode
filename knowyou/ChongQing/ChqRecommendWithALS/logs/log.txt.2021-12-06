2021-12-06 14:55:28,701 [main] INFO [org.apache.spark.SparkContext] - Running Spark version 2.3.0
2021-12-06 14:55:29,067 [main] INFO [org.apache.spark.SparkContext] - Submitted application: PaidPromotion
2021-12-06 14:55:29,132 [main] INFO [org.apache.spark.SecurityManager] - Changing view acls to: ACER,root
2021-12-06 14:55:29,132 [main] INFO [org.apache.spark.SecurityManager] - Changing modify acls to: ACER,root
2021-12-06 14:55:29,133 [main] INFO [org.apache.spark.SecurityManager] - Changing view acls groups to: 
2021-12-06 14:55:29,133 [main] INFO [org.apache.spark.SecurityManager] - Changing modify acls groups to: 
2021-12-06 14:55:29,134 [main] INFO [org.apache.spark.SecurityManager] - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(ACER, root); groups with view permissions: Set(); users  with modify permissions: Set(ACER, root); groups with modify permissions: Set()
2021-12-06 14:55:29,747 [main] INFO [org.apache.spark.util.Utils] - Successfully started service 'sparkDriver' on port 54504.
2021-12-06 14:55:29,766 [main] INFO [org.apache.spark.SparkEnv] - Registering MapOutputTracker
2021-12-06 14:55:29,781 [main] INFO [org.apache.spark.SparkEnv] - Registering BlockManagerMaster
2021-12-06 14:55:29,783 [main] INFO [org.apache.spark.storage.BlockManagerMasterEndpoint] - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2021-12-06 14:55:29,784 [main] INFO [org.apache.spark.storage.BlockManagerMasterEndpoint] - BlockManagerMasterEndpoint up
2021-12-06 14:55:29,791 [main] INFO [org.apache.spark.storage.DiskBlockManager] - Created local directory at C:\Users\ACER\AppData\Local\Temp\blockmgr-c5e341f8-b078-49ce-a086-d2a1119cf4fc
2021-12-06 14:55:29,806 [main] INFO [org.apache.spark.storage.memory.MemoryStore] - MemoryStore started with capacity 1990.8 MB
2021-12-06 14:55:29,816 [main] INFO [org.apache.spark.SparkEnv] - Registering OutputCommitCoordinator
2021-12-06 14:55:29,871 [main] INFO [org.spark_project.jetty.util.log] - Logging initialized @3533ms
2021-12-06 14:55:29,923 [main] INFO [org.spark_project.jetty.server.Server] - jetty-9.3.z-SNAPSHOT
2021-12-06 14:55:29,935 [main] INFO [org.spark_project.jetty.server.Server] - Started @3597ms
2021-12-06 14:55:29,959 [main] INFO [org.spark_project.jetty.server.AbstractConnector] - Started ServerConnector@3414a8c3{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2021-12-06 14:55:29,959 [main] INFO [org.apache.spark.util.Utils] - Successfully started service 'SparkUI' on port 4040.
2021-12-06 14:55:29,981 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@27b45ea{/jobs,null,AVAILABLE,@Spark}
2021-12-06 14:55:29,982 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@4fc142ec{/jobs/json,null,AVAILABLE,@Spark}
2021-12-06 14:55:29,983 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@702b06fb{/jobs/job,null,AVAILABLE,@Spark}
2021-12-06 14:55:29,984 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@2b22a1cc{/jobs/job/json,null,AVAILABLE,@Spark}
2021-12-06 14:55:29,985 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@7fd8c559{/stages,null,AVAILABLE,@Spark}
2021-12-06 14:55:29,986 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@55a88417{/stages/json,null,AVAILABLE,@Spark}
2021-12-06 14:55:29,987 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@19962194{/stages/stage,null,AVAILABLE,@Spark}
2021-12-06 14:55:29,989 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@3cbf1ba4{/stages/stage/json,null,AVAILABLE,@Spark}
2021-12-06 14:55:29,990 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@3dd818e8{/stages/pool,null,AVAILABLE,@Spark}
2021-12-06 14:55:29,992 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@47b67fcb{/stages/pool/json,null,AVAILABLE,@Spark}
2021-12-06 14:55:29,993 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@66420549{/storage,null,AVAILABLE,@Spark}
2021-12-06 14:55:29,994 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@42b28ff1{/storage/json,null,AVAILABLE,@Spark}
2021-12-06 14:55:29,995 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@706fe5c6{/storage/rdd,null,AVAILABLE,@Spark}
2021-12-06 14:55:29,996 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@6b3f6585{/storage/rdd/json,null,AVAILABLE,@Spark}
2021-12-06 14:55:29,997 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@64469d8{/environment,null,AVAILABLE,@Spark}
2021-12-06 14:55:29,998 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@1cec219f{/environment/json,null,AVAILABLE,@Spark}
2021-12-06 14:55:29,999 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@3cb8c8ce{/executors,null,AVAILABLE,@Spark}
2021-12-06 14:55:30,000 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@260a3a5e{/executors/json,null,AVAILABLE,@Spark}
2021-12-06 14:55:30,001 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@2e51d054{/executors/threadDump,null,AVAILABLE,@Spark}
2021-12-06 14:55:30,002 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@608bc8f8{/executors/threadDump/json,null,AVAILABLE,@Spark}
2021-12-06 14:55:30,008 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@381d7219{/static,null,AVAILABLE,@Spark}
2021-12-06 14:55:30,009 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@5f117b3d{/,null,AVAILABLE,@Spark}
2021-12-06 14:55:30,011 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@11f406f8{/api,null,AVAILABLE,@Spark}
2021-12-06 14:55:30,012 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@fb713e7{/jobs/job/kill,null,AVAILABLE,@Spark}
2021-12-06 14:55:30,013 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@35f639fa{/stages/stage/kill,null,AVAILABLE,@Spark}
2021-12-06 14:55:30,015 [main] INFO [org.apache.spark.ui.SparkUI] - Bound SparkUI to 0.0.0.0, and started at http://qb:4040
2021-12-06 14:55:30,098 [main] INFO [org.apache.spark.executor.Executor] - Starting executor ID driver on host localhost
2021-12-06 14:55:30,142 [main] INFO [org.apache.spark.util.Utils] - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 54545.
2021-12-06 14:55:30,143 [main] INFO [org.apache.spark.network.netty.NettyBlockTransferService] - Server created on qb:54545
2021-12-06 14:55:30,144 [main] INFO [org.apache.spark.storage.BlockManager] - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2021-12-06 14:55:30,146 [main] INFO [org.apache.spark.storage.BlockManagerMaster] - Registering BlockManager BlockManagerId(driver, qb, 54545, None)
2021-12-06 14:55:30,149 [dispatcher-event-loop-10] INFO [org.apache.spark.storage.BlockManagerMasterEndpoint] - Registering block manager qb:54545 with 1990.8 MB RAM, BlockManagerId(driver, qb, 54545, None)
2021-12-06 14:55:30,151 [main] INFO [org.apache.spark.storage.BlockManagerMaster] - Registered BlockManager BlockManagerId(driver, qb, 54545, None)
2021-12-06 14:55:30,152 [main] INFO [org.apache.spark.storage.BlockManager] - Initialized BlockManager: BlockManagerId(driver, qb, 54545, None)
2021-12-06 14:55:30,291 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@7165d530{/metrics/json,null,AVAILABLE,@Spark}
2021-12-06 14:55:30,800 [main] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_0 stored as values in memory (estimated size 312.7 KB, free 1990.5 MB)
2021-12-06 14:55:31,001 [main] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_0_piece0 stored as bytes in memory (estimated size 27.3 KB, free 1990.5 MB)
2021-12-06 14:55:31,002 [dispatcher-event-loop-0] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_0_piece0 in memory on qb:54545 (size: 27.3 KB, free: 1990.8 MB)
2021-12-06 14:55:31,006 [main] INFO [org.apache.spark.SparkContext] - Created broadcast 0 from textFile at PaidPromotionAdjustParameter.scala:57
2021-12-06 14:55:31,338 [main] WARN [org.apache.hadoop.hdfs.shortcircuit.DomainSocketFactory] - The short-circuit local reads feature cannot be used because UNIX Domain sockets are not available on Windows.
2021-12-06 14:55:31,476 [Thread-1] INFO [org.apache.spark.SparkContext] - Invoking stop() from shutdown hook
2021-12-06 14:55:31,481 [Thread-1] INFO [org.spark_project.jetty.server.AbstractConnector] - Stopped Spark@3414a8c3{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2021-12-06 14:55:31,483 [Thread-1] INFO [org.apache.spark.ui.SparkUI] - Stopped Spark web UI at http://qb:4040
2021-12-06 14:55:31,490 [dispatcher-event-loop-3] INFO [org.apache.spark.MapOutputTrackerMasterEndpoint] - MapOutputTrackerMasterEndpoint stopped!
2021-12-06 14:55:31,497 [Thread-1] INFO [org.apache.spark.storage.memory.MemoryStore] - MemoryStore cleared
2021-12-06 14:55:31,498 [Thread-1] INFO [org.apache.spark.storage.BlockManager] - BlockManager stopped
2021-12-06 14:55:31,502 [Thread-1] INFO [org.apache.spark.storage.BlockManagerMaster] - BlockManagerMaster stopped
2021-12-06 14:55:31,505 [dispatcher-event-loop-8] INFO [org.apache.spark.scheduler.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint] - OutputCommitCoordinator stopped!
2021-12-06 14:55:31,507 [Thread-1] INFO [org.apache.spark.SparkContext] - Successfully stopped SparkContext
2021-12-06 14:55:31,507 [Thread-1] INFO [org.apache.spark.util.ShutdownHookManager] - Shutdown hook called
2021-12-06 14:55:31,508 [Thread-1] INFO [org.apache.spark.util.ShutdownHookManager] - Deleting directory C:\Users\ACER\AppData\Local\Temp\spark-981b127a-41a9-4cf8-a18a-4066d5a82c9b
2021-12-06 14:56:19,535 [main] INFO [org.apache.spark.SparkContext] - Running Spark version 2.3.0
2021-12-06 14:56:19,862 [main] INFO [org.apache.spark.SparkContext] - Submitted application: PaidPromotion
2021-12-06 14:56:19,917 [main] INFO [org.apache.spark.SecurityManager] - Changing view acls to: ACER,root
2021-12-06 14:56:19,918 [main] INFO [org.apache.spark.SecurityManager] - Changing modify acls to: ACER,root
2021-12-06 14:56:19,918 [main] INFO [org.apache.spark.SecurityManager] - Changing view acls groups to: 
2021-12-06 14:56:19,918 [main] INFO [org.apache.spark.SecurityManager] - Changing modify acls groups to: 
2021-12-06 14:56:19,919 [main] INFO [org.apache.spark.SecurityManager] - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(ACER, root); groups with view permissions: Set(); users  with modify permissions: Set(ACER, root); groups with modify permissions: Set()
2021-12-06 14:56:20,586 [main] INFO [org.apache.spark.util.Utils] - Successfully started service 'sparkDriver' on port 60402.
2021-12-06 14:56:20,607 [main] INFO [org.apache.spark.SparkEnv] - Registering MapOutputTracker
2021-12-06 14:56:20,626 [main] INFO [org.apache.spark.SparkEnv] - Registering BlockManagerMaster
2021-12-06 14:56:20,629 [main] INFO [org.apache.spark.storage.BlockManagerMasterEndpoint] - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2021-12-06 14:56:20,630 [main] INFO [org.apache.spark.storage.BlockManagerMasterEndpoint] - BlockManagerMasterEndpoint up
2021-12-06 14:56:20,637 [main] INFO [org.apache.spark.storage.DiskBlockManager] - Created local directory at C:\Users\ACER\AppData\Local\Temp\blockmgr-ea817296-ace3-47aa-96a3-0fcc86b54418
2021-12-06 14:56:20,653 [main] INFO [org.apache.spark.storage.memory.MemoryStore] - MemoryStore started with capacity 1990.8 MB
2021-12-06 14:56:20,663 [main] INFO [org.apache.spark.SparkEnv] - Registering OutputCommitCoordinator
2021-12-06 14:56:20,716 [main] INFO [org.spark_project.jetty.util.log] - Logging initialized @3272ms
2021-12-06 14:56:20,764 [main] INFO [org.spark_project.jetty.server.Server] - jetty-9.3.z-SNAPSHOT
2021-12-06 14:56:20,775 [main] INFO [org.spark_project.jetty.server.Server] - Started @3331ms
2021-12-06 14:56:20,800 [main] INFO [org.spark_project.jetty.server.AbstractConnector] - Started ServerConnector@68d651f2{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2021-12-06 14:56:20,800 [main] INFO [org.apache.spark.util.Utils] - Successfully started service 'SparkUI' on port 4040.
2021-12-06 14:56:20,821 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@150ede8b{/jobs,null,AVAILABLE,@Spark}
2021-12-06 14:56:20,821 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@5e048149{/jobs/json,null,AVAILABLE,@Spark}
2021-12-06 14:56:20,822 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@2b22a1cc{/jobs/job,null,AVAILABLE,@Spark}
2021-12-06 14:56:20,823 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@2ab0702e{/jobs/job/json,null,AVAILABLE,@Spark}
2021-12-06 14:56:20,824 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@55a88417{/stages,null,AVAILABLE,@Spark}
2021-12-06 14:56:20,825 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@6631cb64{/stages/json,null,AVAILABLE,@Spark}
2021-12-06 14:56:20,826 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@3cbf1ba4{/stages/stage,null,AVAILABLE,@Spark}
2021-12-06 14:56:20,827 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@383864d5{/stages/stage/json,null,AVAILABLE,@Spark}
2021-12-06 14:56:20,828 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@47b67fcb{/stages/pool,null,AVAILABLE,@Spark}
2021-12-06 14:56:20,829 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@ac20bb4{/stages/pool/json,null,AVAILABLE,@Spark}
2021-12-06 14:56:20,830 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@42b28ff1{/storage,null,AVAILABLE,@Spark}
2021-12-06 14:56:20,831 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@76889e60{/storage/json,null,AVAILABLE,@Spark}
2021-12-06 14:56:20,832 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@6b3f6585{/storage/rdd,null,AVAILABLE,@Spark}
2021-12-06 14:56:20,833 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@45e1aa48{/storage/rdd/json,null,AVAILABLE,@Spark}
2021-12-06 14:56:20,834 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@1cec219f{/environment,null,AVAILABLE,@Spark}
2021-12-06 14:56:20,835 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@3e7c4815{/environment/json,null,AVAILABLE,@Spark}
2021-12-06 14:56:20,835 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@260a3a5e{/executors,null,AVAILABLE,@Spark}
2021-12-06 14:56:20,836 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@6438a7fe{/executors/json,null,AVAILABLE,@Spark}
2021-12-06 14:56:20,837 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@608bc8f8{/executors/threadDump,null,AVAILABLE,@Spark}
2021-12-06 14:56:20,838 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@79316f3a{/executors/threadDump/json,null,AVAILABLE,@Spark}
2021-12-06 14:56:20,844 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@329a1f8d{/static,null,AVAILABLE,@Spark}
2021-12-06 14:56:20,846 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@4cfa8227{/,null,AVAILABLE,@Spark}
2021-12-06 14:56:20,846 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@2ec3633f{/api,null,AVAILABLE,@Spark}
2021-12-06 14:56:20,847 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@5c7668ba{/jobs/job/kill,null,AVAILABLE,@Spark}
2021-12-06 14:56:20,848 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@7d9ba6c{/stages/stage/kill,null,AVAILABLE,@Spark}
2021-12-06 14:56:20,850 [main] INFO [org.apache.spark.ui.SparkUI] - Bound SparkUI to 0.0.0.0, and started at http://qb:4040
2021-12-06 14:56:20,930 [main] INFO [org.apache.spark.executor.Executor] - Starting executor ID driver on host localhost
2021-12-06 14:56:20,972 [main] INFO [org.apache.spark.util.Utils] - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 60443.
2021-12-06 14:56:20,972 [main] INFO [org.apache.spark.network.netty.NettyBlockTransferService] - Server created on qb:60443
2021-12-06 14:56:20,974 [main] INFO [org.apache.spark.storage.BlockManager] - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2021-12-06 14:56:20,975 [main] INFO [org.apache.spark.storage.BlockManagerMaster] - Registering BlockManager BlockManagerId(driver, qb, 60443, None)
2021-12-06 14:56:20,977 [dispatcher-event-loop-10] INFO [org.apache.spark.storage.BlockManagerMasterEndpoint] - Registering block manager qb:60443 with 1990.8 MB RAM, BlockManagerId(driver, qb, 60443, None)
2021-12-06 14:56:20,979 [main] INFO [org.apache.spark.storage.BlockManagerMaster] - Registered BlockManager BlockManagerId(driver, qb, 60443, None)
2021-12-06 14:56:20,979 [main] INFO [org.apache.spark.storage.BlockManager] - Initialized BlockManager: BlockManagerId(driver, qb, 60443, None)
2021-12-06 14:56:21,096 [SparkUI-46] WARN [org.apache.spark.ui.JettyUtils] - GET /jobs/ failed: java.util.NoSuchElementException
java.util.NoSuchElementException
	at java.util.Collections$EmptyIterator.next(Collections.java:4189)
	at org.apache.spark.util.kvstore.InMemoryStore$InMemoryIterator.next(InMemoryStore.java:281)
	at org.apache.spark.status.AppStatusStore.applicationInfo(AppStatusStore.scala:38)
	at org.apache.spark.ui.jobs.AllJobsPage.render(AllJobsPage.scala:273)
	at org.apache.spark.ui.WebUI$$anonfun$2.apply(WebUI.scala:82)
	at org.apache.spark.ui.WebUI$$anonfun$2.apply(WebUI.scala:82)
	at org.apache.spark.ui.JettyUtils$$anon$3.doGet(JettyUtils.scala:90)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:707)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:820)
	at org.spark_project.jetty.servlet.ServletHolder.handle(ServletHolder.java:848)
	at org.spark_project.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:584)
	at org.spark_project.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
	at org.spark_project.jetty.servlet.ServletHandler.doScope(ServletHandler.java:512)
	at org.spark_project.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
	at org.spark_project.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.spark_project.jetty.server.handler.gzip.GzipHandler.handle(GzipHandler.java:493)
	at org.spark_project.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:213)
	at org.spark_project.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
	at org.spark_project.jetty.server.Server.handle(Server.java:534)
	at org.spark_project.jetty.server.HttpChannel.handle(HttpChannel.java:320)
	at org.spark_project.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
	at org.spark_project.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
	at org.spark_project.jetty.io.FillInterest.fillable(FillInterest.java:108)
	at org.spark_project.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
	at org.spark_project.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
	at org.spark_project.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
	at java.lang.Thread.run(Thread.java:745)
2021-12-06 14:56:21,099 [SparkUI-46] WARN [org.spark_project.jetty.servlet.ServletHandler] - /jobs/
java.util.NoSuchElementException
	at java.util.Collections$EmptyIterator.next(Collections.java:4189)
	at org.apache.spark.util.kvstore.InMemoryStore$InMemoryIterator.next(InMemoryStore.java:281)
	at org.apache.spark.status.AppStatusStore.applicationInfo(AppStatusStore.scala:38)
	at org.apache.spark.ui.jobs.AllJobsPage.render(AllJobsPage.scala:273)
	at org.apache.spark.ui.WebUI$$anonfun$2.apply(WebUI.scala:82)
	at org.apache.spark.ui.WebUI$$anonfun$2.apply(WebUI.scala:82)
	at org.apache.spark.ui.JettyUtils$$anon$3.doGet(JettyUtils.scala:90)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:707)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:820)
	at org.spark_project.jetty.servlet.ServletHolder.handle(ServletHolder.java:848)
	at org.spark_project.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:584)
	at org.spark_project.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
	at org.spark_project.jetty.servlet.ServletHandler.doScope(ServletHandler.java:512)
	at org.spark_project.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
	at org.spark_project.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.spark_project.jetty.server.handler.gzip.GzipHandler.handle(GzipHandler.java:493)
	at org.spark_project.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:213)
	at org.spark_project.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
	at org.spark_project.jetty.server.Server.handle(Server.java:534)
	at org.spark_project.jetty.server.HttpChannel.handle(HttpChannel.java:320)
	at org.spark_project.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
	at org.spark_project.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
	at org.spark_project.jetty.io.FillInterest.fillable(FillInterest.java:108)
	at org.spark_project.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
	at org.spark_project.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
	at org.spark_project.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
	at java.lang.Thread.run(Thread.java:745)
2021-12-06 14:56:21,100 [SparkUI-46] WARN [org.spark_project.jetty.server.HttpChannel] - //qb:4040/jobs/
java.lang.NoSuchMethodError: javax.servlet.http.HttpServletRequest.isAsyncStarted()Z
	at org.spark_project.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:688)
	at org.spark_project.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
	at org.spark_project.jetty.servlet.ServletHandler.doScope(ServletHandler.java:512)
	at org.spark_project.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
	at org.spark_project.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.spark_project.jetty.server.handler.gzip.GzipHandler.handle(GzipHandler.java:493)
	at org.spark_project.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:213)
	at org.spark_project.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
	at org.spark_project.jetty.server.Server.handle(Server.java:534)
	at org.spark_project.jetty.server.HttpChannel.handle(HttpChannel.java:320)
	at org.spark_project.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
	at org.spark_project.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
	at org.spark_project.jetty.io.FillInterest.fillable(FillInterest.java:108)
	at org.spark_project.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
	at org.spark_project.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
	at org.spark_project.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
	at java.lang.Thread.run(Thread.java:745)
2021-12-06 14:56:21,104 [SparkUI-45] WARN [org.apache.spark.ui.JettyUtils] - GET /jobs/ failed: java.util.NoSuchElementException
java.util.NoSuchElementException
	at java.util.Collections$EmptyIterator.next(Collections.java:4189)
	at org.apache.spark.util.kvstore.InMemoryStore$InMemoryIterator.next(InMemoryStore.java:281)
	at org.apache.spark.status.AppStatusStore.applicationInfo(AppStatusStore.scala:38)
	at org.apache.spark.ui.jobs.AllJobsPage.render(AllJobsPage.scala:273)
	at org.apache.spark.ui.WebUI$$anonfun$2.apply(WebUI.scala:82)
	at org.apache.spark.ui.WebUI$$anonfun$2.apply(WebUI.scala:82)
	at org.apache.spark.ui.JettyUtils$$anon$3.doGet(JettyUtils.scala:90)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:707)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:820)
	at org.spark_project.jetty.servlet.ServletHolder.handle(ServletHolder.java:848)
	at org.spark_project.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:584)
	at org.spark_project.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
	at org.spark_project.jetty.servlet.ServletHandler.doScope(ServletHandler.java:512)
	at org.spark_project.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
	at org.spark_project.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.spark_project.jetty.server.handler.gzip.GzipHandler.handle(GzipHandler.java:493)
	at org.spark_project.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:213)
	at org.spark_project.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
	at org.spark_project.jetty.server.Server.handle(Server.java:534)
	at org.spark_project.jetty.server.HttpChannel.handle(HttpChannel.java:320)
	at org.spark_project.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
	at org.spark_project.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
	at org.spark_project.jetty.io.FillInterest.fillable(FillInterest.java:108)
	at org.spark_project.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
	at org.spark_project.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
	at org.spark_project.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
	at java.lang.Thread.run(Thread.java:745)
2021-12-06 14:56:21,104 [SparkUI-45] WARN [org.spark_project.jetty.servlet.ServletHandler] - /jobs/
java.util.NoSuchElementException
	at java.util.Collections$EmptyIterator.next(Collections.java:4189)
	at org.apache.spark.util.kvstore.InMemoryStore$InMemoryIterator.next(InMemoryStore.java:281)
	at org.apache.spark.status.AppStatusStore.applicationInfo(AppStatusStore.scala:38)
	at org.apache.spark.ui.jobs.AllJobsPage.render(AllJobsPage.scala:273)
	at org.apache.spark.ui.WebUI$$anonfun$2.apply(WebUI.scala:82)
	at org.apache.spark.ui.WebUI$$anonfun$2.apply(WebUI.scala:82)
	at org.apache.spark.ui.JettyUtils$$anon$3.doGet(JettyUtils.scala:90)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:707)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:820)
	at org.spark_project.jetty.servlet.ServletHolder.handle(ServletHolder.java:848)
	at org.spark_project.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:584)
	at org.spark_project.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
	at org.spark_project.jetty.servlet.ServletHandler.doScope(ServletHandler.java:512)
	at org.spark_project.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
	at org.spark_project.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.spark_project.jetty.server.handler.gzip.GzipHandler.handle(GzipHandler.java:493)
	at org.spark_project.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:213)
	at org.spark_project.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
	at org.spark_project.jetty.server.Server.handle(Server.java:534)
	at org.spark_project.jetty.server.HttpChannel.handle(HttpChannel.java:320)
	at org.spark_project.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
	at org.spark_project.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
	at org.spark_project.jetty.io.FillInterest.fillable(FillInterest.java:108)
	at org.spark_project.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
	at org.spark_project.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
	at org.spark_project.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
	at java.lang.Thread.run(Thread.java:745)
2021-12-06 14:56:21,105 [SparkUI-45] WARN [org.spark_project.jetty.server.HttpChannel] - //qb:4040/jobs/
java.lang.NoSuchMethodError: javax.servlet.http.HttpServletRequest.isAsyncStarted()Z
	at org.spark_project.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:688)
	at org.spark_project.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
	at org.spark_project.jetty.servlet.ServletHandler.doScope(ServletHandler.java:512)
	at org.spark_project.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
	at org.spark_project.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.spark_project.jetty.server.handler.gzip.GzipHandler.handle(GzipHandler.java:493)
	at org.spark_project.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:213)
	at org.spark_project.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
	at org.spark_project.jetty.server.Server.handle(Server.java:534)
	at org.spark_project.jetty.server.HttpChannel.handle(HttpChannel.java:320)
	at org.spark_project.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
	at org.spark_project.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
	at org.spark_project.jetty.io.FillInterest.fillable(FillInterest.java:108)
	at org.spark_project.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
	at org.spark_project.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
	at org.spark_project.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
	at java.lang.Thread.run(Thread.java:745)
2021-12-06 14:56:21,123 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@44be69aa{/metrics/json,null,AVAILABLE,@Spark}
2021-12-06 14:56:21,399 [SparkUI-46] INFO [org.spark_project.jetty.servlet.DefaultServlet] - content=ResourceHttpContent@61f25172{r=jar:file:/C:/Users/ACER/.m2/repository/org/apache/spark/spark-core_2.11/2.3.0/spark-core_2.11-2.3.0.jar!/org/apache/spark/ui/static/bootstrap.min.css,gz=false}
2021-12-06 14:56:21,400 [SparkUI-46] WARN [org.spark_project.jetty.servlet.ServletHandler] - Error for /static/bootstrap.min.css
java.lang.NoSuchMethodError: javax.servlet.http.HttpServletRequest.isAsyncSupported()Z
	at org.spark_project.jetty.servlet.DefaultServlet.sendData(DefaultServlet.java:909)
	at org.spark_project.jetty.servlet.DefaultServlet.doGet(DefaultServlet.java:526)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:707)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:820)
	at org.spark_project.jetty.servlet.ServletHolder.handle(ServletHolder.java:848)
	at org.spark_project.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:584)
	at org.spark_project.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
	at org.spark_project.jetty.servlet.ServletHandler.doScope(ServletHandler.java:512)
	at org.spark_project.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
	at org.spark_project.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.spark_project.jetty.server.handler.gzip.GzipHandler.handle(GzipHandler.java:493)
	at org.spark_project.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:213)
	at org.spark_project.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
	at org.spark_project.jetty.server.Server.handle(Server.java:534)
	at org.spark_project.jetty.server.HttpChannel.handle(HttpChannel.java:320)
	at org.spark_project.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
	at org.spark_project.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
	at org.spark_project.jetty.io.FillInterest.fillable(FillInterest.java:108)
	at org.spark_project.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
	at org.spark_project.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
	at org.spark_project.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
	at java.lang.Thread.run(Thread.java:745)
2021-12-06 14:56:21,401 [SparkUI-46] WARN [org.spark_project.jetty.server.HttpChannel] - //qb:4040/static/bootstrap.min.css
java.lang.NoSuchMethodError: javax.servlet.http.HttpServletRequest.isAsyncStarted()Z
	at org.spark_project.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:688)
	at org.spark_project.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
	at org.spark_project.jetty.servlet.ServletHandler.doScope(ServletHandler.java:512)
	at org.spark_project.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
	at org.spark_project.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.spark_project.jetty.server.handler.gzip.GzipHandler.handle(GzipHandler.java:493)
	at org.spark_project.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:213)
	at org.spark_project.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
	at org.spark_project.jetty.server.Server.handle(Server.java:534)
	at org.spark_project.jetty.server.HttpChannel.handle(HttpChannel.java:320)
	at org.spark_project.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
	at org.spark_project.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
	at org.spark_project.jetty.io.FillInterest.fillable(FillInterest.java:108)
	at org.spark_project.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
	at org.spark_project.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
	at org.spark_project.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
	at java.lang.Thread.run(Thread.java:745)
2021-12-06 14:56:21,401 [SparkUI-45] INFO [org.spark_project.jetty.servlet.DefaultServlet] - content=ResourceHttpContent@32360faf{r=jar:file:/C:/Users/ACER/.m2/repository/org/apache/spark/spark-core_2.11/2.3.0/spark-core_2.11-2.3.0.jar!/org/apache/spark/ui/static/vis.min.css,gz=false}
2021-12-06 14:56:21,401 [SparkUI-45] WARN [org.spark_project.jetty.servlet.ServletHandler] - Error for /static/vis.min.css
java.lang.NoSuchMethodError: javax.servlet.http.HttpServletRequest.isAsyncSupported()Z
	at org.spark_project.jetty.servlet.DefaultServlet.sendData(DefaultServlet.java:909)
	at org.spark_project.jetty.servlet.DefaultServlet.doGet(DefaultServlet.java:526)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:707)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:820)
	at org.spark_project.jetty.servlet.ServletHolder.handle(ServletHolder.java:848)
	at org.spark_project.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:584)
	at org.spark_project.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
	at org.spark_project.jetty.servlet.ServletHandler.doScope(ServletHandler.java:512)
	at org.spark_project.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
	at org.spark_project.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.spark_project.jetty.server.handler.gzip.GzipHandler.handle(GzipHandler.java:493)
	at org.spark_project.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:213)
	at org.spark_project.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
	at org.spark_project.jetty.server.Server.handle(Server.java:534)
	at org.spark_project.jetty.server.HttpChannel.handle(HttpChannel.java:320)
	at org.spark_project.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
	at org.spark_project.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
	at org.spark_project.jetty.io.FillInterest.fillable(FillInterest.java:108)
	at org.spark_project.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
	at org.spark_project.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
	at org.spark_project.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
	at java.lang.Thread.run(Thread.java:745)
2021-12-06 14:56:21,402 [SparkUI-45] WARN [org.spark_project.jetty.server.HttpChannel] - //qb:4040/static/vis.min.css
java.lang.NoSuchMethodError: javax.servlet.http.HttpServletRequest.isAsyncStarted()Z
	at org.spark_project.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:688)
	at org.spark_project.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
	at org.spark_project.jetty.servlet.ServletHandler.doScope(ServletHandler.java:512)
	at org.spark_project.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
	at org.spark_project.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.spark_project.jetty.server.handler.gzip.GzipHandler.handle(GzipHandler.java:493)
	at org.spark_project.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:213)
	at org.spark_project.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
	at org.spark_project.jetty.server.Server.handle(Server.java:534)
	at org.spark_project.jetty.server.HttpChannel.handle(HttpChannel.java:320)
	at org.spark_project.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
	at org.spark_project.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
	at org.spark_project.jetty.io.FillInterest.fillable(FillInterest.java:108)
	at org.spark_project.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
	at org.spark_project.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
	at org.spark_project.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
	at java.lang.Thread.run(Thread.java:745)
2021-12-06 14:56:21,404 [SparkUI-41] INFO [org.spark_project.jetty.servlet.DefaultServlet] - content=ResourceHttpContent@3118afe9{r=jar:file:/C:/Users/ACER/.m2/repository/org/apache/spark/spark-core_2.11/2.3.0/spark-core_2.11-2.3.0.jar!/org/apache/spark/ui/static/webui.css,gz=false}
2021-12-06 14:56:21,405 [SparkUI-41] WARN [org.spark_project.jetty.servlet.ServletHandler] - Error for /static/webui.css
java.lang.NoSuchMethodError: javax.servlet.http.HttpServletRequest.isAsyncSupported()Z
	at org.spark_project.jetty.servlet.DefaultServlet.sendData(DefaultServlet.java:909)
	at org.spark_project.jetty.servlet.DefaultServlet.doGet(DefaultServlet.java:526)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:707)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:820)
	at org.spark_project.jetty.servlet.ServletHolder.handle(ServletHolder.java:848)
	at org.spark_project.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:584)
	at org.spark_project.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
	at org.spark_project.jetty.servlet.ServletHandler.doScope(ServletHandler.java:512)
	at org.spark_project.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
	at org.spark_project.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.spark_project.jetty.server.handler.gzip.GzipHandler.handle(GzipHandler.java:493)
	at org.spark_project.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:213)
	at org.spark_project.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
	at org.spark_project.jetty.server.Server.handle(Server.java:534)
	at org.spark_project.jetty.server.HttpChannel.handle(HttpChannel.java:320)
	at org.spark_project.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
	at org.spark_project.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
	at org.spark_project.jetty.io.FillInterest.fillable(FillInterest.java:108)
	at org.spark_project.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
	at org.spark_project.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
	at org.spark_project.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
	at java.lang.Thread.run(Thread.java:745)
2021-12-06 14:56:21,405 [SparkUI-41] WARN [org.spark_project.jetty.server.HttpChannel] - //qb:4040/static/webui.css
java.lang.NoSuchMethodError: javax.servlet.http.HttpServletRequest.isAsyncStarted()Z
	at org.spark_project.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:688)
	at org.spark_project.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
	at org.spark_project.jetty.servlet.ServletHandler.doScope(ServletHandler.java:512)
	at org.spark_project.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
	at org.spark_project.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.spark_project.jetty.server.handler.gzip.GzipHandler.handle(GzipHandler.java:493)
	at org.spark_project.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:213)
	at org.spark_project.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
	at org.spark_project.jetty.server.Server.handle(Server.java:534)
	at org.spark_project.jetty.server.HttpChannel.handle(HttpChannel.java:320)
	at org.spark_project.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
	at org.spark_project.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
	at org.spark_project.jetty.io.FillInterest.fillable(FillInterest.java:108)
	at org.spark_project.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
	at org.spark_project.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
	at org.spark_project.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
	at java.lang.Thread.run(Thread.java:745)
2021-12-06 14:56:21,407 [SparkUI-45] INFO [org.spark_project.jetty.servlet.DefaultServlet] - content=ResourceHttpContent@3ece673b{r=jar:file:/C:/Users/ACER/.m2/repository/org/apache/spark/spark-core_2.11/2.3.0/spark-core_2.11-2.3.0.jar!/org/apache/spark/ui/static/bootstrap.min.css,gz=false}
2021-12-06 14:56:21,407 [SparkUI-42] INFO [org.spark_project.jetty.servlet.DefaultServlet] - content=ResourceHttpContent@2400188{r=jar:file:/C:/Users/ACER/.m2/repository/org/apache/spark/spark-core_2.11/2.3.0/spark-core_2.11-2.3.0.jar!/org/apache/spark/ui/static/timeline-view.css,gz=false}
2021-12-06 14:56:21,408 [SparkUI-42] WARN [org.spark_project.jetty.servlet.ServletHandler] - Error for /static/timeline-view.css
java.lang.NoSuchMethodError: javax.servlet.http.HttpServletRequest.isAsyncSupported()Z
	at org.spark_project.jetty.servlet.DefaultServlet.sendData(DefaultServlet.java:909)
	at org.spark_project.jetty.servlet.DefaultServlet.doGet(DefaultServlet.java:526)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:707)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:820)
	at org.spark_project.jetty.servlet.ServletHolder.handle(ServletHolder.java:848)
	at org.spark_project.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:584)
	at org.spark_project.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
	at org.spark_project.jetty.servlet.ServletHandler.doScope(ServletHandler.java:512)
	at org.spark_project.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
	at org.spark_project.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.spark_project.jetty.server.handler.gzip.GzipHandler.handle(GzipHandler.java:493)
	at org.spark_project.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:213)
	at org.spark_project.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
	at org.spark_project.jetty.server.Server.handle(Server.java:534)
	at org.spark_project.jetty.server.HttpChannel.handle(HttpChannel.java:320)
	at org.spark_project.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
	at org.spark_project.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
	at org.spark_project.jetty.io.FillInterest.fillable(FillInterest.java:108)
	at org.spark_project.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
	at org.spark_project.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
	at org.spark_project.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
	at java.lang.Thread.run(Thread.java:745)
2021-12-06 14:56:21,408 [SparkUI-45] WARN [org.spark_project.jetty.servlet.ServletHandler] - Error for /static/bootstrap.min.css
java.lang.NoSuchMethodError: javax.servlet.http.HttpServletRequest.isAsyncSupported()Z
	at org.spark_project.jetty.servlet.DefaultServlet.sendData(DefaultServlet.java:909)
	at org.spark_project.jetty.servlet.DefaultServlet.doGet(DefaultServlet.java:526)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:707)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:820)
	at org.spark_project.jetty.servlet.ServletHolder.handle(ServletHolder.java:848)
	at org.spark_project.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:584)
	at org.spark_project.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
	at org.spark_project.jetty.servlet.ServletHandler.doScope(ServletHandler.java:512)
	at org.spark_project.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
	at org.spark_project.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.spark_project.jetty.server.handler.gzip.GzipHandler.handle(GzipHandler.java:493)
	at org.spark_project.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:213)
	at org.spark_project.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
	at org.spark_project.jetty.server.Server.handle(Server.java:534)
	at org.spark_project.jetty.server.HttpChannel.handle(HttpChannel.java:320)
	at org.spark_project.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
	at org.spark_project.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
	at org.spark_project.jetty.io.FillInterest.fillable(FillInterest.java:108)
	at org.spark_project.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
	at org.spark_project.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
	at org.spark_project.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
	at java.lang.Thread.run(Thread.java:745)
2021-12-06 14:56:21,409 [SparkUI-45] WARN [org.spark_project.jetty.server.HttpChannel] - //qb:4040/static/bootstrap.min.css
java.lang.NoSuchMethodError: javax.servlet.http.HttpServletRequest.isAsyncStarted()Z
	at org.spark_project.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:688)
	at org.spark_project.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
	at org.spark_project.jetty.servlet.ServletHandler.doScope(ServletHandler.java:512)
	at org.spark_project.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
	at org.spark_project.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.spark_project.jetty.server.handler.gzip.GzipHandler.handle(GzipHandler.java:493)
	at org.spark_project.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:213)
	at org.spark_project.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
	at org.spark_project.jetty.server.Server.handle(Server.java:534)
	at org.spark_project.jetty.server.HttpChannel.handle(HttpChannel.java:320)
	at org.spark_project.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
	at org.spark_project.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
	at org.spark_project.jetty.io.FillInterest.fillable(FillInterest.java:108)
	at org.spark_project.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
	at org.spark_project.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
	at org.spark_project.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
	at java.lang.Thread.run(Thread.java:745)
2021-12-06 14:56:21,409 [SparkUI-42] WARN [org.spark_project.jetty.server.HttpChannel] - //qb:4040/static/timeline-view.css
java.lang.NoSuchMethodError: javax.servlet.http.HttpServletRequest.isAsyncStarted()Z
	at org.spark_project.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:688)
	at org.spark_project.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
	at org.spark_project.jetty.servlet.ServletHandler.doScope(ServletHandler.java:512)
	at org.spark_project.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
	at org.spark_project.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.spark_project.jetty.server.handler.gzip.GzipHandler.handle(GzipHandler.java:493)
	at org.spark_project.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:213)
	at org.spark_project.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
	at org.spark_project.jetty.server.Server.handle(Server.java:534)
	at org.spark_project.jetty.server.HttpChannel.handle(HttpChannel.java:320)
	at org.spark_project.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
	at org.spark_project.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
	at org.spark_project.jetty.io.FillInterest.fillable(FillInterest.java:108)
	at org.spark_project.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
	at org.spark_project.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
	at org.spark_project.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
	at java.lang.Thread.run(Thread.java:745)
2021-12-06 14:56:21,421 [SparkUI-55] INFO [org.spark_project.jetty.servlet.DefaultServlet] - content=ResourceHttpContent@226dc51b{r=jar:file:/C:/Users/ACER/.m2/repository/org/apache/spark/spark-core_2.11/2.3.0/spark-core_2.11-2.3.0.jar!/org/apache/spark/ui/static/sorttable.js,gz=false}
2021-12-06 14:56:21,421 [SparkUI-44] INFO [org.spark_project.jetty.servlet.DefaultServlet] - content=ResourceHttpContent@3f18b867{r=jar:file:/C:/Users/ACER/.m2/repository/org/apache/spark/spark-core_2.11/2.3.0/spark-core_2.11-2.3.0.jar!/org/apache/spark/ui/static/jquery-1.11.1.min.js,gz=false}
2021-12-06 14:56:21,421 [SparkUI-41] INFO [org.spark_project.jetty.servlet.DefaultServlet] - content=ResourceHttpContent@6466ba1{r=jar:file:/C:/Users/ACER/.m2/repository/org/apache/spark/spark-core_2.11/2.3.0/spark-core_2.11-2.3.0.jar!/org/apache/spark/ui/static/vis.min.js,gz=false}
2021-12-06 14:56:21,421 [SparkUI-55] WARN [org.spark_project.jetty.servlet.ServletHandler] - Error for /static/sorttable.js
java.lang.NoSuchMethodError: javax.servlet.http.HttpServletRequest.isAsyncSupported()Z
	at org.spark_project.jetty.servlet.DefaultServlet.sendData(DefaultServlet.java:909)
	at org.spark_project.jetty.servlet.DefaultServlet.doGet(DefaultServlet.java:526)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:707)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:820)
	at org.spark_project.jetty.servlet.ServletHolder.handle(ServletHolder.java:848)
	at org.spark_project.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:584)
	at org.spark_project.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
	at org.spark_project.jetty.servlet.ServletHandler.doScope(ServletHandler.java:512)
	at org.spark_project.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
	at org.spark_project.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.spark_project.jetty.server.handler.gzip.GzipHandler.handle(GzipHandler.java:493)
	at org.spark_project.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:213)
	at org.spark_project.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
	at org.spark_project.jetty.server.Server.handle(Server.java:534)
	at org.spark_project.jetty.server.HttpChannel.handle(HttpChannel.java:320)
	at org.spark_project.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
	at org.spark_project.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
	at org.spark_project.jetty.io.FillInterest.fillable(FillInterest.java:108)
	at org.spark_project.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
	at org.spark_project.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
	at org.spark_project.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
	at java.lang.Thread.run(Thread.java:745)
2021-12-06 14:56:21,421 [SparkUI-41] WARN [org.spark_project.jetty.servlet.ServletHandler] - Error for /static/vis.min.js
java.lang.NoSuchMethodError: javax.servlet.http.HttpServletRequest.isAsyncSupported()Z
	at org.spark_project.jetty.servlet.DefaultServlet.sendData(DefaultServlet.java:909)
	at org.spark_project.jetty.servlet.DefaultServlet.doGet(DefaultServlet.java:526)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:707)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:820)
	at org.spark_project.jetty.servlet.ServletHolder.handle(ServletHolder.java:848)
	at org.spark_project.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:584)
	at org.spark_project.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
	at org.spark_project.jetty.servlet.ServletHandler.doScope(ServletHandler.java:512)
	at org.spark_project.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
	at org.spark_project.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.spark_project.jetty.server.handler.gzip.GzipHandler.handle(GzipHandler.java:493)
	at org.spark_project.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:213)
	at org.spark_project.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
	at org.spark_project.jetty.server.Server.handle(Server.java:534)
	at org.spark_project.jetty.server.HttpChannel.handle(HttpChannel.java:320)
	at org.spark_project.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
	at org.spark_project.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
	at org.spark_project.jetty.io.FillInterest.fillable(FillInterest.java:108)
	at org.spark_project.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
	at org.spark_project.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
	at org.spark_project.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
	at java.lang.Thread.run(Thread.java:745)
2021-12-06 14:56:21,421 [SparkUI-44] WARN [org.spark_project.jetty.servlet.ServletHandler] - Error for /static/jquery-1.11.1.min.js
java.lang.NoSuchMethodError: javax.servlet.http.HttpServletRequest.isAsyncSupported()Z
	at org.spark_project.jetty.servlet.DefaultServlet.sendData(DefaultServlet.java:909)
	at org.spark_project.jetty.servlet.DefaultServlet.doGet(DefaultServlet.java:526)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:707)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:820)
	at org.spark_project.jetty.servlet.ServletHolder.handle(ServletHolder.java:848)
	at org.spark_project.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:584)
	at org.spark_project.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
	at org.spark_project.jetty.servlet.ServletHandler.doScope(ServletHandler.java:512)
	at org.spark_project.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
	at org.spark_project.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.spark_project.jetty.server.handler.gzip.GzipHandler.handle(GzipHandler.java:493)
	at org.spark_project.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:213)
	at org.spark_project.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
	at org.spark_project.jetty.server.Server.handle(Server.java:534)
	at org.spark_project.jetty.server.HttpChannel.handle(HttpChannel.java:320)
	at org.spark_project.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
	at org.spark_project.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
	at org.spark_project.jetty.io.FillInterest.fillable(FillInterest.java:108)
	at org.spark_project.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
	at org.spark_project.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
	at org.spark_project.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
	at java.lang.Thread.run(Thread.java:745)
2021-12-06 14:56:21,422 [SparkUI-44] WARN [org.spark_project.jetty.server.HttpChannel] - //qb:4040/static/jquery-1.11.1.min.js
java.lang.NoSuchMethodError: javax.servlet.http.HttpServletRequest.isAsyncStarted()Z
	at org.spark_project.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:688)
	at org.spark_project.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
	at org.spark_project.jetty.servlet.ServletHandler.doScope(ServletHandler.java:512)
	at org.spark_project.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
	at org.spark_project.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.spark_project.jetty.server.handler.gzip.GzipHandler.handle(GzipHandler.java:493)
	at org.spark_project.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:213)
	at org.spark_project.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
	at org.spark_project.jetty.server.Server.handle(Server.java:534)
	at org.spark_project.jetty.server.HttpChannel.handle(HttpChannel.java:320)
	at org.spark_project.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
	at org.spark_project.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
	at org.spark_project.jetty.io.FillInterest.fillable(FillInterest.java:108)
	at org.spark_project.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
	at org.spark_project.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
	at org.spark_project.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
	at java.lang.Thread.run(Thread.java:745)
2021-12-06 14:56:21,422 [SparkUI-41] WARN [org.spark_project.jetty.server.HttpChannel] - //qb:4040/static/vis.min.js
java.lang.NoSuchMethodError: javax.servlet.http.HttpServletRequest.isAsyncStarted()Z
	at org.spark_project.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:688)
	at org.spark_project.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
	at org.spark_project.jetty.servlet.ServletHandler.doScope(ServletHandler.java:512)
	at org.spark_project.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
	at org.spark_project.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.spark_project.jetty.server.handler.gzip.GzipHandler.handle(GzipHandler.java:493)
	at org.spark_project.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:213)
	at org.spark_project.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
	at org.spark_project.jetty.server.Server.handle(Server.java:534)
	at org.spark_project.jetty.server.HttpChannel.handle(HttpChannel.java:320)
	at org.spark_project.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
	at org.spark_project.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
	at org.spark_project.jetty.io.FillInterest.fillable(FillInterest.java:108)
	at org.spark_project.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
	at org.spark_project.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
	at org.spark_project.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
	at java.lang.Thread.run(Thread.java:745)
2021-12-06 14:56:21,422 [SparkUI-55] WARN [org.spark_project.jetty.server.HttpChannel] - //qb:4040/static/sorttable.js
java.lang.NoSuchMethodError: javax.servlet.http.HttpServletRequest.isAsyncStarted()Z
	at org.spark_project.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:688)
	at org.spark_project.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
	at org.spark_project.jetty.servlet.ServletHandler.doScope(ServletHandler.java:512)
	at org.spark_project.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
	at org.spark_project.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.spark_project.jetty.server.handler.gzip.GzipHandler.handle(GzipHandler.java:493)
	at org.spark_project.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:213)
	at org.spark_project.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
	at org.spark_project.jetty.server.Server.handle(Server.java:534)
	at org.spark_project.jetty.server.HttpChannel.handle(HttpChannel.java:320)
	at org.spark_project.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
	at org.spark_project.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
	at org.spark_project.jetty.io.FillInterest.fillable(FillInterest.java:108)
	at org.spark_project.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
	at org.spark_project.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
	at org.spark_project.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
	at java.lang.Thread.run(Thread.java:745)
2021-12-06 14:56:21,424 [SparkUI-45] INFO [org.spark_project.jetty.servlet.DefaultServlet] - content=ResourceHttpContent@6b6b3457{r=jar:file:/C:/Users/ACER/.m2/repository/org/apache/spark/spark-core_2.11/2.3.0/spark-core_2.11-2.3.0.jar!/org/apache/spark/ui/static/bootstrap-tooltip.js,gz=false}
2021-12-06 14:56:21,424 [SparkUI-45] WARN [org.spark_project.jetty.servlet.ServletHandler] - Error for /static/bootstrap-tooltip.js
java.lang.NoSuchMethodError: javax.servlet.http.HttpServletRequest.isAsyncSupported()Z
	at org.spark_project.jetty.servlet.DefaultServlet.sendData(DefaultServlet.java:909)
	at org.spark_project.jetty.servlet.DefaultServlet.doGet(DefaultServlet.java:526)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:707)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:820)
	at org.spark_project.jetty.servlet.ServletHolder.handle(ServletHolder.java:848)
	at org.spark_project.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:584)
	at org.spark_project.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
	at org.spark_project.jetty.servlet.ServletHandler.doScope(ServletHandler.java:512)
	at org.spark_project.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
	at org.spark_project.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.spark_project.jetty.server.handler.gzip.GzipHandler.handle(GzipHandler.java:493)
	at org.spark_project.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:213)
	at org.spark_project.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
	at org.spark_project.jetty.server.Server.handle(Server.java:534)
	at org.spark_project.jetty.server.HttpChannel.handle(HttpChannel.java:320)
	at org.spark_project.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
	at org.spark_project.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
	at org.spark_project.jetty.io.FillInterest.fillable(FillInterest.java:108)
	at org.spark_project.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
	at org.spark_project.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
	at org.spark_project.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
	at java.lang.Thread.run(Thread.java:745)
2021-12-06 14:56:21,425 [SparkUI-45] WARN [org.spark_project.jetty.server.HttpChannel] - //qb:4040/static/bootstrap-tooltip.js
java.lang.NoSuchMethodError: javax.servlet.http.HttpServletRequest.isAsyncStarted()Z
	at org.spark_project.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:688)
	at org.spark_project.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
	at org.spark_project.jetty.servlet.ServletHandler.doScope(ServletHandler.java:512)
	at org.spark_project.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
	at org.spark_project.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.spark_project.jetty.server.handler.gzip.GzipHandler.handle(GzipHandler.java:493)
	at org.spark_project.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:213)
	at org.spark_project.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
	at org.spark_project.jetty.server.Server.handle(Server.java:534)
	at org.spark_project.jetty.server.HttpChannel.handle(HttpChannel.java:320)
	at org.spark_project.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
	at org.spark_project.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
	at org.spark_project.jetty.io.FillInterest.fillable(FillInterest.java:108)
	at org.spark_project.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
	at org.spark_project.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
	at org.spark_project.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
	at java.lang.Thread.run(Thread.java:745)
2021-12-06 14:56:21,427 [SparkUI-41] INFO [org.spark_project.jetty.servlet.DefaultServlet] - content=ResourceHttpContent@6bba3332{r=jar:file:/C:/Users/ACER/.m2/repository/org/apache/spark/spark-core_2.11/2.3.0/spark-core_2.11-2.3.0.jar!/org/apache/spark/ui/static/initialize-tooltips.js,gz=false}
2021-12-06 14:56:21,428 [SparkUI-41] WARN [org.spark_project.jetty.servlet.ServletHandler] - Error for /static/initialize-tooltips.js
java.lang.NoSuchMethodError: javax.servlet.http.HttpServletRequest.isAsyncSupported()Z
	at org.spark_project.jetty.servlet.DefaultServlet.sendData(DefaultServlet.java:909)
	at org.spark_project.jetty.servlet.DefaultServlet.doGet(DefaultServlet.java:526)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:707)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:820)
	at org.spark_project.jetty.servlet.ServletHolder.handle(ServletHolder.java:848)
	at org.spark_project.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:584)
	at org.spark_project.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
	at org.spark_project.jetty.servlet.ServletHandler.doScope(ServletHandler.java:512)
	at org.spark_project.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
	at org.spark_project.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.spark_project.jetty.server.handler.gzip.GzipHandler.handle(GzipHandler.java:493)
	at org.spark_project.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:213)
	at org.spark_project.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
	at org.spark_project.jetty.server.Server.handle(Server.java:534)
	at org.spark_project.jetty.server.HttpChannel.handle(HttpChannel.java:320)
	at org.spark_project.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
	at org.spark_project.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
	at org.spark_project.jetty.io.FillInterest.fillable(FillInterest.java:108)
	at org.spark_project.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
	at org.spark_project.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
	at org.spark_project.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
	at java.lang.Thread.run(Thread.java:745)
2021-12-06 14:56:21,428 [SparkUI-41] WARN [org.spark_project.jetty.server.HttpChannel] - //qb:4040/static/initialize-tooltips.js
java.lang.NoSuchMethodError: javax.servlet.http.HttpServletRequest.isAsyncStarted()Z
	at org.spark_project.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:688)
	at org.spark_project.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
	at org.spark_project.jetty.servlet.ServletHandler.doScope(ServletHandler.java:512)
	at org.spark_project.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
	at org.spark_project.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.spark_project.jetty.server.handler.gzip.GzipHandler.handle(GzipHandler.java:493)
	at org.spark_project.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:213)
	at org.spark_project.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
	at org.spark_project.jetty.server.Server.handle(Server.java:534)
	at org.spark_project.jetty.server.HttpChannel.handle(HttpChannel.java:320)
	at org.spark_project.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
	at org.spark_project.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
	at org.spark_project.jetty.io.FillInterest.fillable(FillInterest.java:108)
	at org.spark_project.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
	at org.spark_project.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
	at org.spark_project.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
	at java.lang.Thread.run(Thread.java:745)
2021-12-06 14:56:21,428 [SparkUI-39] INFO [org.spark_project.jetty.servlet.DefaultServlet] - content=ResourceHttpContent@67728d73{r=jar:file:/C:/Users/ACER/.m2/repository/org/apache/spark/spark-core_2.11/2.3.0/spark-core_2.11-2.3.0.jar!/org/apache/spark/ui/static/table.js,gz=false}
2021-12-06 14:56:21,429 [SparkUI-39] WARN [org.spark_project.jetty.servlet.ServletHandler] - Error for /static/table.js
java.lang.NoSuchMethodError: javax.servlet.http.HttpServletRequest.isAsyncSupported()Z
	at org.spark_project.jetty.servlet.DefaultServlet.sendData(DefaultServlet.java:909)
	at org.spark_project.jetty.servlet.DefaultServlet.doGet(DefaultServlet.java:526)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:707)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:820)
	at org.spark_project.jetty.servlet.ServletHolder.handle(ServletHolder.java:848)
	at org.spark_project.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:584)
	at org.spark_project.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
	at org.spark_project.jetty.servlet.ServletHandler.doScope(ServletHandler.java:512)
	at org.spark_project.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
	at org.spark_project.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.spark_project.jetty.server.handler.gzip.GzipHandler.handle(GzipHandler.java:493)
	at org.spark_project.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:213)
	at org.spark_project.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
	at org.spark_project.jetty.server.Server.handle(Server.java:534)
	at org.spark_project.jetty.server.HttpChannel.handle(HttpChannel.java:320)
	at org.spark_project.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
	at org.spark_project.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
	at org.spark_project.jetty.io.FillInterest.fillable(FillInterest.java:108)
	at org.spark_project.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
	at org.spark_project.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
	at org.spark_project.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
	at java.lang.Thread.run(Thread.java:745)
2021-12-06 14:56:21,430 [SparkUI-39] WARN [org.spark_project.jetty.server.HttpChannel] - //qb:4040/static/table.js
java.lang.NoSuchMethodError: javax.servlet.http.HttpServletRequest.isAsyncStarted()Z
	at org.spark_project.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:688)
	at org.spark_project.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
	at org.spark_project.jetty.servlet.ServletHandler.doScope(ServletHandler.java:512)
	at org.spark_project.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
	at org.spark_project.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.spark_project.jetty.server.handler.gzip.GzipHandler.handle(GzipHandler.java:493)
	at org.spark_project.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:213)
	at org.spark_project.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
	at org.spark_project.jetty.server.Server.handle(Server.java:534)
	at org.spark_project.jetty.server.HttpChannel.handle(HttpChannel.java:320)
	at org.spark_project.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
	at org.spark_project.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
	at org.spark_project.jetty.io.FillInterest.fillable(FillInterest.java:108)
	at org.spark_project.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
	at org.spark_project.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
	at org.spark_project.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
	at java.lang.Thread.run(Thread.java:745)
2021-12-06 14:56:21,432 [SparkUI-56] INFO [org.spark_project.jetty.servlet.DefaultServlet] - content=ResourceHttpContent@8884ac3{r=jar:file:/C:/Users/ACER/.m2/repository/org/apache/spark/spark-core_2.11/2.3.0/spark-core_2.11-2.3.0.jar!/org/apache/spark/ui/static/additional-metrics.js,gz=false}
2021-12-06 14:56:21,432 [SparkUI-56] WARN [org.spark_project.jetty.servlet.ServletHandler] - Error for /static/additional-metrics.js
java.lang.NoSuchMethodError: javax.servlet.http.HttpServletRequest.isAsyncSupported()Z
	at org.spark_project.jetty.servlet.DefaultServlet.sendData(DefaultServlet.java:909)
	at org.spark_project.jetty.servlet.DefaultServlet.doGet(DefaultServlet.java:526)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:707)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:820)
	at org.spark_project.jetty.servlet.ServletHolder.handle(ServletHolder.java:848)
	at org.spark_project.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:584)
	at org.spark_project.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
	at org.spark_project.jetty.servlet.ServletHandler.doScope(ServletHandler.java:512)
	at org.spark_project.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
	at org.spark_project.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.spark_project.jetty.server.handler.gzip.GzipHandler.handle(GzipHandler.java:493)
	at org.spark_project.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:213)
	at org.spark_project.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
	at org.spark_project.jetty.server.Server.handle(Server.java:534)
	at org.spark_project.jetty.server.HttpChannel.handle(HttpChannel.java:320)
	at org.spark_project.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
	at org.spark_project.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
	at org.spark_project.jetty.io.FillInterest.fillable(FillInterest.java:108)
	at org.spark_project.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
	at org.spark_project.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
	at org.spark_project.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
	at java.lang.Thread.run(Thread.java:745)
2021-12-06 14:56:21,432 [SparkUI-56] WARN [org.spark_project.jetty.server.HttpChannel] - //qb:4040/static/additional-metrics.js
java.lang.NoSuchMethodError: javax.servlet.http.HttpServletRequest.isAsyncStarted()Z
	at org.spark_project.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:688)
	at org.spark_project.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
	at org.spark_project.jetty.servlet.ServletHandler.doScope(ServletHandler.java:512)
	at org.spark_project.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
	at org.spark_project.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.spark_project.jetty.server.handler.gzip.GzipHandler.handle(GzipHandler.java:493)
	at org.spark_project.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:213)
	at org.spark_project.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
	at org.spark_project.jetty.server.Server.handle(Server.java:534)
	at org.spark_project.jetty.server.HttpChannel.handle(HttpChannel.java:320)
	at org.spark_project.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
	at org.spark_project.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
	at org.spark_project.jetty.io.FillInterest.fillable(FillInterest.java:108)
	at org.spark_project.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
	at org.spark_project.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
	at org.spark_project.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
	at java.lang.Thread.run(Thread.java:745)
2021-12-06 14:56:21,435 [SparkUI-45] INFO [org.spark_project.jetty.servlet.DefaultServlet] - content=ResourceHttpContent@4948c486{r=jar:file:/C:/Users/ACER/.m2/repository/org/apache/spark/spark-core_2.11/2.3.0/spark-core_2.11-2.3.0.jar!/org/apache/spark/ui/static/timeline-view.js,gz=false}
2021-12-06 14:56:21,435 [SparkUI-45] WARN [org.spark_project.jetty.servlet.ServletHandler] - Error for /static/timeline-view.js
java.lang.NoSuchMethodError: javax.servlet.http.HttpServletRequest.isAsyncSupported()Z
	at org.spark_project.jetty.servlet.DefaultServlet.sendData(DefaultServlet.java:909)
	at org.spark_project.jetty.servlet.DefaultServlet.doGet(DefaultServlet.java:526)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:707)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:820)
	at org.spark_project.jetty.servlet.ServletHolder.handle(ServletHolder.java:848)
	at org.spark_project.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:584)
	at org.spark_project.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
	at org.spark_project.jetty.servlet.ServletHandler.doScope(ServletHandler.java:512)
	at org.spark_project.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
	at org.spark_project.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.spark_project.jetty.server.handler.gzip.GzipHandler.handle(GzipHandler.java:493)
	at org.spark_project.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:213)
	at org.spark_project.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
	at org.spark_project.jetty.server.Server.handle(Server.java:534)
	at org.spark_project.jetty.server.HttpChannel.handle(HttpChannel.java:320)
	at org.spark_project.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
	at org.spark_project.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
	at org.spark_project.jetty.io.FillInterest.fillable(FillInterest.java:108)
	at org.spark_project.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
	at org.spark_project.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
	at org.spark_project.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
	at java.lang.Thread.run(Thread.java:745)
2021-12-06 14:56:21,435 [SparkUI-61] INFO [org.spark_project.jetty.servlet.DefaultServlet] - content=ResourceHttpContent@321d74eb{r=jar:file:/C:/Users/ACER/.m2/repository/org/apache/spark/spark-core_2.11/2.3.0/spark-core_2.11-2.3.0.jar!/org/apache/spark/ui/static/log-view.js,gz=false}
2021-12-06 14:56:21,435 [SparkUI-45] WARN [org.spark_project.jetty.server.HttpChannel] - //qb:4040/static/timeline-view.js
java.lang.NoSuchMethodError: javax.servlet.http.HttpServletRequest.isAsyncStarted()Z
	at org.spark_project.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:688)
	at org.spark_project.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
	at org.spark_project.jetty.servlet.ServletHandler.doScope(ServletHandler.java:512)
	at org.spark_project.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
	at org.spark_project.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.spark_project.jetty.server.handler.gzip.GzipHandler.handle(GzipHandler.java:493)
	at org.spark_project.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:213)
	at org.spark_project.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
	at org.spark_project.jetty.server.Server.handle(Server.java:534)
	at org.spark_project.jetty.server.HttpChannel.handle(HttpChannel.java:320)
	at org.spark_project.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
	at org.spark_project.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
	at org.spark_project.jetty.io.FillInterest.fillable(FillInterest.java:108)
	at org.spark_project.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
	at org.spark_project.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
	at org.spark_project.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
	at java.lang.Thread.run(Thread.java:745)
2021-12-06 14:56:21,435 [SparkUI-61] WARN [org.spark_project.jetty.servlet.ServletHandler] - Error for /static/log-view.js
java.lang.NoSuchMethodError: javax.servlet.http.HttpServletRequest.isAsyncSupported()Z
	at org.spark_project.jetty.servlet.DefaultServlet.sendData(DefaultServlet.java:909)
	at org.spark_project.jetty.servlet.DefaultServlet.doGet(DefaultServlet.java:526)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:707)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:820)
	at org.spark_project.jetty.servlet.ServletHolder.handle(ServletHolder.java:848)
	at org.spark_project.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:584)
	at org.spark_project.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
	at org.spark_project.jetty.servlet.ServletHandler.doScope(ServletHandler.java:512)
	at org.spark_project.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
	at org.spark_project.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.spark_project.jetty.server.handler.gzip.GzipHandler.handle(GzipHandler.java:493)
	at org.spark_project.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:213)
	at org.spark_project.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
	at org.spark_project.jetty.server.Server.handle(Server.java:534)
	at org.spark_project.jetty.server.HttpChannel.handle(HttpChannel.java:320)
	at org.spark_project.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
	at org.spark_project.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
	at org.spark_project.jetty.io.FillInterest.fillable(FillInterest.java:108)
	at org.spark_project.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
	at org.spark_project.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
	at org.spark_project.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
	at java.lang.Thread.run(Thread.java:745)
2021-12-06 14:56:21,436 [SparkUI-61] WARN [org.spark_project.jetty.server.HttpChannel] - //qb:4040/static/log-view.js
java.lang.NoSuchMethodError: javax.servlet.http.HttpServletRequest.isAsyncStarted()Z
	at org.spark_project.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:688)
	at org.spark_project.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
	at org.spark_project.jetty.servlet.ServletHandler.doScope(ServletHandler.java:512)
	at org.spark_project.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
	at org.spark_project.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.spark_project.jetty.server.handler.gzip.GzipHandler.handle(GzipHandler.java:493)
	at org.spark_project.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:213)
	at org.spark_project.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
	at org.spark_project.jetty.server.Server.handle(Server.java:534)
	at org.spark_project.jetty.server.HttpChannel.handle(HttpChannel.java:320)
	at org.spark_project.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
	at org.spark_project.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
	at org.spark_project.jetty.io.FillInterest.fillable(FillInterest.java:108)
	at org.spark_project.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
	at org.spark_project.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
	at org.spark_project.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
	at java.lang.Thread.run(Thread.java:745)
2021-12-06 14:56:21,436 [SparkUI-41] INFO [org.spark_project.jetty.servlet.DefaultServlet] - content=ResourceHttpContent@5139f00d{r=jar:file:/C:/Users/ACER/.m2/repository/org/apache/spark/spark-core_2.11/2.3.0/spark-core_2.11-2.3.0.jar!/org/apache/spark/ui/static/webui.js,gz=false}
2021-12-06 14:56:21,436 [SparkUI-41] WARN [org.spark_project.jetty.servlet.ServletHandler] - Error for /static/webui.js
java.lang.NoSuchMethodError: javax.servlet.http.HttpServletRequest.isAsyncSupported()Z
	at org.spark_project.jetty.servlet.DefaultServlet.sendData(DefaultServlet.java:909)
	at org.spark_project.jetty.servlet.DefaultServlet.doGet(DefaultServlet.java:526)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:707)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:820)
	at org.spark_project.jetty.servlet.ServletHolder.handle(ServletHolder.java:848)
	at org.spark_project.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:584)
	at org.spark_project.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
	at org.spark_project.jetty.servlet.ServletHandler.doScope(ServletHandler.java:512)
	at org.spark_project.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
	at org.spark_project.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.spark_project.jetty.server.handler.gzip.GzipHandler.handle(GzipHandler.java:493)
	at org.spark_project.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:213)
	at org.spark_project.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
	at org.spark_project.jetty.server.Server.handle(Server.java:534)
	at org.spark_project.jetty.server.HttpChannel.handle(HttpChannel.java:320)
	at org.spark_project.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
	at org.spark_project.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
	at org.spark_project.jetty.io.FillInterest.fillable(FillInterest.java:108)
	at org.spark_project.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
	at org.spark_project.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
	at org.spark_project.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
	at java.lang.Thread.run(Thread.java:745)
2021-12-06 14:56:21,437 [SparkUI-41] WARN [org.spark_project.jetty.server.HttpChannel] - //qb:4040/static/webui.js
java.lang.NoSuchMethodError: javax.servlet.http.HttpServletRequest.isAsyncStarted()Z
	at org.spark_project.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:688)
	at org.spark_project.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
	at org.spark_project.jetty.servlet.ServletHandler.doScope(ServletHandler.java:512)
	at org.spark_project.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
	at org.spark_project.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.spark_project.jetty.server.handler.gzip.GzipHandler.handle(GzipHandler.java:493)
	at org.spark_project.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:213)
	at org.spark_project.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
	at org.spark_project.jetty.server.Server.handle(Server.java:534)
	at org.spark_project.jetty.server.HttpChannel.handle(HttpChannel.java:320)
	at org.spark_project.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
	at org.spark_project.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
	at org.spark_project.jetty.io.FillInterest.fillable(FillInterest.java:108)
	at org.spark_project.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
	at org.spark_project.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
	at org.spark_project.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
	at java.lang.Thread.run(Thread.java:745)
2021-12-06 14:56:21,442 [SparkUI-44] INFO [org.spark_project.jetty.servlet.DefaultServlet] - content=ResourceHttpContent@50594477{r=jar:file:/C:/Users/ACER/.m2/repository/org/apache/spark/spark-core_2.11/2.3.0/spark-core_2.11-2.3.0.jar!/org/apache/spark/ui/static/spark-logo-77x50px-hd.png,gz=false}
2021-12-06 14:56:21,443 [SparkUI-44] WARN [org.spark_project.jetty.servlet.ServletHandler] - Error for /static/spark-logo-77x50px-hd.png
java.lang.NoSuchMethodError: javax.servlet.http.HttpServletRequest.isAsyncSupported()Z
	at org.spark_project.jetty.servlet.DefaultServlet.sendData(DefaultServlet.java:909)
	at org.spark_project.jetty.servlet.DefaultServlet.doGet(DefaultServlet.java:526)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:707)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:820)
	at org.spark_project.jetty.servlet.ServletHolder.handle(ServletHolder.java:848)
	at org.spark_project.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:584)
	at org.spark_project.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
	at org.spark_project.jetty.servlet.ServletHandler.doScope(ServletHandler.java:512)
	at org.spark_project.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
	at org.spark_project.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.spark_project.jetty.server.handler.gzip.GzipHandler.handle(GzipHandler.java:448)
	at org.spark_project.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:213)
	at org.spark_project.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
	at org.spark_project.jetty.server.Server.handle(Server.java:534)
	at org.spark_project.jetty.server.HttpChannel.handle(HttpChannel.java:320)
	at org.spark_project.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
	at org.spark_project.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
	at org.spark_project.jetty.io.FillInterest.fillable(FillInterest.java:108)
	at org.spark_project.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
	at org.spark_project.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
	at org.spark_project.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
	at java.lang.Thread.run(Thread.java:745)
2021-12-06 14:56:21,443 [SparkUI-44] WARN [org.spark_project.jetty.server.HttpChannel] - //qb:4040/static/spark-logo-77x50px-hd.png
java.lang.NoSuchMethodError: javax.servlet.http.HttpServletRequest.isAsyncStarted()Z
	at org.spark_project.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:688)
	at org.spark_project.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
	at org.spark_project.jetty.servlet.ServletHandler.doScope(ServletHandler.java:512)
	at org.spark_project.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
	at org.spark_project.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.spark_project.jetty.server.handler.gzip.GzipHandler.handle(GzipHandler.java:448)
	at org.spark_project.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:213)
	at org.spark_project.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
	at org.spark_project.jetty.server.Server.handle(Server.java:534)
	at org.spark_project.jetty.server.HttpChannel.handle(HttpChannel.java:320)
	at org.spark_project.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
	at org.spark_project.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
	at org.spark_project.jetty.io.FillInterest.fillable(FillInterest.java:108)
	at org.spark_project.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
	at org.spark_project.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
	at org.spark_project.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
	at java.lang.Thread.run(Thread.java:745)
2021-12-06 14:56:21,753 [main] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_0 stored as values in memory (estimated size 312.7 KB, free 1990.5 MB)
2021-12-06 14:56:21,951 [main] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_0_piece0 stored as bytes in memory (estimated size 27.3 KB, free 1990.5 MB)
2021-12-06 14:56:21,953 [dispatcher-event-loop-0] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_0_piece0 in memory on qb:60443 (size: 27.3 KB, free: 1990.8 MB)
2021-12-06 14:56:21,956 [main] INFO [org.apache.spark.SparkContext] - Created broadcast 0 from textFile at PaidPromotionAdjustParameter.scala:239
2021-12-06 14:56:22,000 [main] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_1 stored as values in memory (estimated size 312.7 KB, free 1990.2 MB)
2021-12-06 14:56:22,013 [main] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_1_piece0 stored as bytes in memory (estimated size 27.3 KB, free 1990.1 MB)
2021-12-06 14:56:22,014 [dispatcher-event-loop-1] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_1_piece0 in memory on qb:60443 (size: 27.3 KB, free: 1990.7 MB)
2021-12-06 14:56:22,014 [main] INFO [org.apache.spark.SparkContext] - Created broadcast 1 from textFile at PaidPromotionAdjustParameter.scala:240
2021-12-06 14:56:25,514 [SparkUI-41] INFO [org.spark_project.jetty.servlet.DefaultServlet] - content=ResourceHttpContent@18b4e858{r=jar:file:/C:/Users/ACER/.m2/repository/org/apache/spark/spark-core_2.11/2.3.0/spark-core_2.11-2.3.0.jar!/org/apache/spark/ui/static/vis.min.css,gz=false}
2021-12-06 14:56:25,514 [SparkUI-41] WARN [org.spark_project.jetty.servlet.ServletHandler] - Error for /static/vis.min.css
java.lang.NoSuchMethodError: javax.servlet.http.HttpServletRequest.isAsyncSupported()Z
	at org.spark_project.jetty.servlet.DefaultServlet.sendData(DefaultServlet.java:909)
	at org.spark_project.jetty.servlet.DefaultServlet.doGet(DefaultServlet.java:526)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:707)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:820)
	at org.spark_project.jetty.servlet.ServletHolder.handle(ServletHolder.java:848)
	at org.spark_project.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:584)
	at org.spark_project.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
	at org.spark_project.jetty.servlet.ServletHandler.doScope(ServletHandler.java:512)
	at org.spark_project.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
	at org.spark_project.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.spark_project.jetty.server.handler.gzip.GzipHandler.handle(GzipHandler.java:493)
	at org.spark_project.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:213)
	at org.spark_project.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
	at org.spark_project.jetty.server.Server.handle(Server.java:534)
	at org.spark_project.jetty.server.HttpChannel.handle(HttpChannel.java:320)
	at org.spark_project.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
	at org.spark_project.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
	at org.spark_project.jetty.io.FillInterest.fillable(FillInterest.java:108)
	at org.spark_project.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
	at org.spark_project.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
	at org.spark_project.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
	at java.lang.Thread.run(Thread.java:745)
2021-12-06 14:56:25,515 [SparkUI-41] WARN [org.spark_project.jetty.server.HttpChannel] - //qb:4040/static/vis.min.css
java.lang.NoSuchMethodError: javax.servlet.http.HttpServletRequest.isAsyncStarted()Z
	at org.spark_project.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:688)
	at org.spark_project.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
	at org.spark_project.jetty.servlet.ServletHandler.doScope(ServletHandler.java:512)
	at org.spark_project.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
	at org.spark_project.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.spark_project.jetty.server.handler.gzip.GzipHandler.handle(GzipHandler.java:493)
	at org.spark_project.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:213)
	at org.spark_project.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
	at org.spark_project.jetty.server.Server.handle(Server.java:534)
	at org.spark_project.jetty.server.HttpChannel.handle(HttpChannel.java:320)
	at org.spark_project.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
	at org.spark_project.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
	at org.spark_project.jetty.io.FillInterest.fillable(FillInterest.java:108)
	at org.spark_project.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
	at org.spark_project.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
	at org.spark_project.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
	at java.lang.Thread.run(Thread.java:745)
2021-12-06 14:56:25,514 [SparkUI-63] INFO [org.spark_project.jetty.servlet.DefaultServlet] - content=ResourceHttpContent@53b363a3{r=jar:file:/C:/Users/ACER/.m2/repository/org/apache/spark/spark-core_2.11/2.3.0/spark-core_2.11-2.3.0.jar!/org/apache/spark/ui/static/bootstrap.min.css,gz=false}
2021-12-06 14:56:25,515 [SparkUI-63] WARN [org.spark_project.jetty.servlet.ServletHandler] - Error for /static/bootstrap.min.css
java.lang.NoSuchMethodError: javax.servlet.http.HttpServletRequest.isAsyncSupported()Z
	at org.spark_project.jetty.servlet.DefaultServlet.sendData(DefaultServlet.java:909)
	at org.spark_project.jetty.servlet.DefaultServlet.doGet(DefaultServlet.java:526)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:707)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:820)
	at org.spark_project.jetty.servlet.ServletHolder.handle(ServletHolder.java:848)
	at org.spark_project.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:584)
	at org.spark_project.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
	at org.spark_project.jetty.servlet.ServletHandler.doScope(ServletHandler.java:512)
	at org.spark_project.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
	at org.spark_project.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.spark_project.jetty.server.handler.gzip.GzipHandler.handle(GzipHandler.java:493)
	at org.spark_project.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:213)
	at org.spark_project.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
	at org.spark_project.jetty.server.Server.handle(Server.java:534)
	at org.spark_project.jetty.server.HttpChannel.handle(HttpChannel.java:320)
	at org.spark_project.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
	at org.spark_project.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
	at org.spark_project.jetty.io.FillInterest.fillable(FillInterest.java:108)
	at org.spark_project.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
	at org.spark_project.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
	at org.spark_project.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
	at java.lang.Thread.run(Thread.java:745)
2021-12-06 14:56:25,515 [SparkUI-63] WARN [org.spark_project.jetty.server.HttpChannel] - //qb:4040/static/bootstrap.min.css
java.lang.NoSuchMethodError: javax.servlet.http.HttpServletRequest.isAsyncStarted()Z
	at org.spark_project.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:688)
	at org.spark_project.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
	at org.spark_project.jetty.servlet.ServletHandler.doScope(ServletHandler.java:512)
	at org.spark_project.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
	at org.spark_project.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.spark_project.jetty.server.handler.gzip.GzipHandler.handle(GzipHandler.java:493)
	at org.spark_project.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:213)
	at org.spark_project.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
	at org.spark_project.jetty.server.Server.handle(Server.java:534)
	at org.spark_project.jetty.server.HttpChannel.handle(HttpChannel.java:320)
	at org.spark_project.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
	at org.spark_project.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
	at org.spark_project.jetty.io.FillInterest.fillable(FillInterest.java:108)
	at org.spark_project.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
	at org.spark_project.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
	at org.spark_project.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
	at java.lang.Thread.run(Thread.java:745)
2021-12-06 14:56:25,521 [SparkUI-61] INFO [org.spark_project.jetty.servlet.DefaultServlet] - content=ResourceHttpContent@52659de1{r=jar:file:/C:/Users/ACER/.m2/repository/org/apache/spark/spark-core_2.11/2.3.0/spark-core_2.11-2.3.0.jar!/org/apache/spark/ui/static/timeline-view.css,gz=false}
2021-12-06 14:56:25,522 [SparkUI-61] WARN [org.spark_project.jetty.servlet.ServletHandler] - Error for /static/timeline-view.css
java.lang.NoSuchMethodError: javax.servlet.http.HttpServletRequest.isAsyncSupported()Z
	at org.spark_project.jetty.servlet.DefaultServlet.sendData(DefaultServlet.java:909)
	at org.spark_project.jetty.servlet.DefaultServlet.doGet(DefaultServlet.java:526)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:707)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:820)
	at org.spark_project.jetty.servlet.ServletHolder.handle(ServletHolder.java:848)
	at org.spark_project.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:584)
	at org.spark_project.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
	at org.spark_project.jetty.servlet.ServletHandler.doScope(ServletHandler.java:512)
	at org.spark_project.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
	at org.spark_project.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.spark_project.jetty.server.handler.gzip.GzipHandler.handle(GzipHandler.java:493)
	at org.spark_project.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:213)
	at org.spark_project.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
	at org.spark_project.jetty.server.Server.handle(Server.java:534)
	at org.spark_project.jetty.server.HttpChannel.handle(HttpChannel.java:320)
	at org.spark_project.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
	at org.spark_project.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
	at org.spark_project.jetty.io.FillInterest.fillable(FillInterest.java:108)
	at org.spark_project.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
	at org.spark_project.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
	at org.spark_project.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
	at java.lang.Thread.run(Thread.java:745)
2021-12-06 14:56:25,522 [SparkUI-61] WARN [org.spark_project.jetty.server.HttpChannel] - //qb:4040/static/timeline-view.css
java.lang.NoSuchMethodError: javax.servlet.http.HttpServletRequest.isAsyncStarted()Z
	at org.spark_project.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:688)
	at org.spark_project.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
	at org.spark_project.jetty.servlet.ServletHandler.doScope(ServletHandler.java:512)
	at org.spark_project.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
	at org.spark_project.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.spark_project.jetty.server.handler.gzip.GzipHandler.handle(GzipHandler.java:493)
	at org.spark_project.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:213)
	at org.spark_project.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
	at org.spark_project.jetty.server.Server.handle(Server.java:534)
	at org.spark_project.jetty.server.HttpChannel.handle(HttpChannel.java:320)
	at org.spark_project.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
	at org.spark_project.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
	at org.spark_project.jetty.io.FillInterest.fillable(FillInterest.java:108)
	at org.spark_project.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
	at org.spark_project.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
	at org.spark_project.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
	at java.lang.Thread.run(Thread.java:745)
2021-12-06 14:56:25,523 [SparkUI-46] INFO [org.spark_project.jetty.servlet.DefaultServlet] - content=ResourceHttpContent@617a183f{r=jar:file:/C:/Users/ACER/.m2/repository/org/apache/spark/spark-core_2.11/2.3.0/spark-core_2.11-2.3.0.jar!/org/apache/spark/ui/static/webui.css,gz=false}
2021-12-06 14:56:25,523 [SparkUI-46] WARN [org.spark_project.jetty.servlet.ServletHandler] - Error for /static/webui.css
java.lang.NoSuchMethodError: javax.servlet.http.HttpServletRequest.isAsyncSupported()Z
	at org.spark_project.jetty.servlet.DefaultServlet.sendData(DefaultServlet.java:909)
	at org.spark_project.jetty.servlet.DefaultServlet.doGet(DefaultServlet.java:526)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:707)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:820)
	at org.spark_project.jetty.servlet.ServletHolder.handle(ServletHolder.java:848)
	at org.spark_project.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:584)
	at org.spark_project.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
	at org.spark_project.jetty.servlet.ServletHandler.doScope(ServletHandler.java:512)
	at org.spark_project.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
	at org.spark_project.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.spark_project.jetty.server.handler.gzip.GzipHandler.handle(GzipHandler.java:493)
	at org.spark_project.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:213)
	at org.spark_project.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
	at org.spark_project.jetty.server.Server.handle(Server.java:534)
	at org.spark_project.jetty.server.HttpChannel.handle(HttpChannel.java:320)
	at org.spark_project.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
	at org.spark_project.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
	at org.spark_project.jetty.io.FillInterest.fillable(FillInterest.java:108)
	at org.spark_project.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
	at org.spark_project.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
	at org.spark_project.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
	at java.lang.Thread.run(Thread.java:745)
2021-12-06 14:56:25,524 [SparkUI-46] WARN [org.spark_project.jetty.server.HttpChannel] - //qb:4040/static/webui.css
java.lang.NoSuchMethodError: javax.servlet.http.HttpServletRequest.isAsyncStarted()Z
	at org.spark_project.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:688)
	at org.spark_project.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
	at org.spark_project.jetty.servlet.ServletHandler.doScope(ServletHandler.java:512)
	at org.spark_project.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
	at org.spark_project.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.spark_project.jetty.server.handler.gzip.GzipHandler.handle(GzipHandler.java:493)
	at org.spark_project.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:213)
	at org.spark_project.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
	at org.spark_project.jetty.server.Server.handle(Server.java:534)
	at org.spark_project.jetty.server.HttpChannel.handle(HttpChannel.java:320)
	at org.spark_project.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
	at org.spark_project.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
	at org.spark_project.jetty.io.FillInterest.fillable(FillInterest.java:108)
	at org.spark_project.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
	at org.spark_project.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
	at org.spark_project.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
	at java.lang.Thread.run(Thread.java:745)
2021-12-06 14:56:25,527 [SparkUI-41] INFO [org.spark_project.jetty.servlet.DefaultServlet] - content=ResourceHttpContent@4b06c522{r=jar:file:/C:/Users/ACER/.m2/repository/org/apache/spark/spark-core_2.11/2.3.0/spark-core_2.11-2.3.0.jar!/org/apache/spark/ui/static/jquery-1.11.1.min.js,gz=false}
2021-12-06 14:56:25,527 [SparkUI-56] INFO [org.spark_project.jetty.servlet.DefaultServlet] - content=ResourceHttpContent@e0de30{r=jar:file:/C:/Users/ACER/.m2/repository/org/apache/spark/spark-core_2.11/2.3.0/spark-core_2.11-2.3.0.jar!/org/apache/spark/ui/static/bootstrap.min.css,gz=false}
2021-12-06 14:56:25,527 [SparkUI-55] INFO [org.spark_project.jetty.servlet.DefaultServlet] - content=ResourceHttpContent@29f14496{r=jar:file:/C:/Users/ACER/.m2/repository/org/apache/spark/spark-core_2.11/2.3.0/spark-core_2.11-2.3.0.jar!/org/apache/spark/ui/static/vis.min.css,gz=false}
2021-12-06 14:56:25,527 [SparkUI-56] WARN [org.spark_project.jetty.servlet.ServletHandler] - Error for /static/bootstrap.min.css
java.lang.NoSuchMethodError: javax.servlet.http.HttpServletRequest.isAsyncSupported()Z
	at org.spark_project.jetty.servlet.DefaultServlet.sendData(DefaultServlet.java:909)
	at org.spark_project.jetty.servlet.DefaultServlet.doGet(DefaultServlet.java:526)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:707)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:820)
	at org.spark_project.jetty.servlet.ServletHolder.handle(ServletHolder.java:848)
	at org.spark_project.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:584)
	at org.spark_project.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
	at org.spark_project.jetty.servlet.ServletHandler.doScope(ServletHandler.java:512)
	at org.spark_project.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
	at org.spark_project.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.spark_project.jetty.server.handler.gzip.GzipHandler.handle(GzipHandler.java:493)
	at org.spark_project.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:213)
	at org.spark_project.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
	at org.spark_project.jetty.server.Server.handle(Server.java:534)
	at org.spark_project.jetty.server.HttpChannel.handle(HttpChannel.java:320)
	at org.spark_project.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
	at org.spark_project.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
	at org.spark_project.jetty.io.FillInterest.fillable(FillInterest.java:108)
	at org.spark_project.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
	at org.spark_project.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
	at org.spark_project.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
	at java.lang.Thread.run(Thread.java:745)
2021-12-06 14:56:25,527 [SparkUI-55] WARN [org.spark_project.jetty.servlet.ServletHandler] - Error for /static/vis.min.css
java.lang.NoSuchMethodError: javax.servlet.http.HttpServletRequest.isAsyncSupported()Z
	at org.spark_project.jetty.servlet.DefaultServlet.sendData(DefaultServlet.java:909)
	at org.spark_project.jetty.servlet.DefaultServlet.doGet(DefaultServlet.java:526)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:707)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:820)
	at org.spark_project.jetty.servlet.ServletHolder.handle(ServletHolder.java:848)
	at org.spark_project.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:584)
	at org.spark_project.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
	at org.spark_project.jetty.servlet.ServletHandler.doScope(ServletHandler.java:512)
	at org.spark_project.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
	at org.spark_project.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.spark_project.jetty.server.handler.gzip.GzipHandler.handle(GzipHandler.java:493)
	at org.spark_project.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:213)
	at org.spark_project.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
	at org.spark_project.jetty.server.Server.handle(Server.java:534)
	at org.spark_project.jetty.server.HttpChannel.handle(HttpChannel.java:320)
	at org.spark_project.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
	at org.spark_project.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
	at org.spark_project.jetty.io.FillInterest.fillable(FillInterest.java:108)
	at org.spark_project.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
	at org.spark_project.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
	at org.spark_project.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
	at java.lang.Thread.run(Thread.java:745)
2021-12-06 14:56:25,527 [SparkUI-41] WARN [org.spark_project.jetty.servlet.ServletHandler] - Error for /static/jquery-1.11.1.min.js
java.lang.NoSuchMethodError: javax.servlet.http.HttpServletRequest.isAsyncSupported()Z
	at org.spark_project.jetty.servlet.DefaultServlet.sendData(DefaultServlet.java:909)
	at org.spark_project.jetty.servlet.DefaultServlet.doGet(DefaultServlet.java:526)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:707)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:820)
	at org.spark_project.jetty.servlet.ServletHolder.handle(ServletHolder.java:848)
	at org.spark_project.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:584)
	at org.spark_project.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
	at org.spark_project.jetty.servlet.ServletHandler.doScope(ServletHandler.java:512)
	at org.spark_project.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
	at org.spark_project.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.spark_project.jetty.server.handler.gzip.GzipHandler.handle(GzipHandler.java:493)
	at org.spark_project.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:213)
	at org.spark_project.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
	at org.spark_project.jetty.server.Server.handle(Server.java:534)
	at org.spark_project.jetty.server.HttpChannel.handle(HttpChannel.java:320)
	at org.spark_project.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
	at org.spark_project.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
	at org.spark_project.jetty.io.FillInterest.fillable(FillInterest.java:108)
	at org.spark_project.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
	at org.spark_project.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
	at org.spark_project.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
	at java.lang.Thread.run(Thread.java:745)
2021-12-06 14:56:25,527 [SparkUI-56] WARN [org.spark_project.jetty.server.HttpChannel] - //qb:4040/static/bootstrap.min.css
java.lang.NoSuchMethodError: javax.servlet.http.HttpServletRequest.isAsyncStarted()Z
	at org.spark_project.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:688)
	at org.spark_project.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
	at org.spark_project.jetty.servlet.ServletHandler.doScope(ServletHandler.java:512)
	at org.spark_project.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
	at org.spark_project.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.spark_project.jetty.server.handler.gzip.GzipHandler.handle(GzipHandler.java:493)
	at org.spark_project.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:213)
	at org.spark_project.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
	at org.spark_project.jetty.server.Server.handle(Server.java:534)
	at org.spark_project.jetty.server.HttpChannel.handle(HttpChannel.java:320)
	at org.spark_project.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
	at org.spark_project.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
	at org.spark_project.jetty.io.FillInterest.fillable(FillInterest.java:108)
	at org.spark_project.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
	at org.spark_project.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
	at org.spark_project.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
	at java.lang.Thread.run(Thread.java:745)
2021-12-06 14:56:25,528 [SparkUI-41] WARN [org.spark_project.jetty.server.HttpChannel] - //qb:4040/static/jquery-1.11.1.min.js
java.lang.NoSuchMethodError: javax.servlet.http.HttpServletRequest.isAsyncStarted()Z
	at org.spark_project.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:688)
	at org.spark_project.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
	at org.spark_project.jetty.servlet.ServletHandler.doScope(ServletHandler.java:512)
	at org.spark_project.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
	at org.spark_project.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.spark_project.jetty.server.handler.gzip.GzipHandler.handle(GzipHandler.java:493)
	at org.spark_project.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:213)
	at org.spark_project.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
	at org.spark_project.jetty.server.Server.handle(Server.java:534)
	at org.spark_project.jetty.server.HttpChannel.handle(HttpChannel.java:320)
	at org.spark_project.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
	at org.spark_project.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
	at org.spark_project.jetty.io.FillInterest.fillable(FillInterest.java:108)
	at org.spark_project.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
	at org.spark_project.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
	at org.spark_project.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
	at java.lang.Thread.run(Thread.java:745)
2021-12-06 14:56:25,528 [SparkUI-55] WARN [org.spark_project.jetty.server.HttpChannel] - //qb:4040/static/vis.min.css
java.lang.NoSuchMethodError: javax.servlet.http.HttpServletRequest.isAsyncStarted()Z
	at org.spark_project.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:688)
	at org.spark_project.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
	at org.spark_project.jetty.servlet.ServletHandler.doScope(ServletHandler.java:512)
	at org.spark_project.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
	at org.spark_project.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.spark_project.jetty.server.handler.gzip.GzipHandler.handle(GzipHandler.java:493)
	at org.spark_project.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:213)
	at org.spark_project.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
	at org.spark_project.jetty.server.Server.handle(Server.java:534)
	at org.spark_project.jetty.server.HttpChannel.handle(HttpChannel.java:320)
	at org.spark_project.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
	at org.spark_project.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
	at org.spark_project.jetty.io.FillInterest.fillable(FillInterest.java:108)
	at org.spark_project.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
	at org.spark_project.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
	at org.spark_project.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
	at java.lang.Thread.run(Thread.java:745)
2021-12-06 14:56:25,531 [SparkUI-42] INFO [org.spark_project.jetty.servlet.DefaultServlet] - content=ResourceHttpContent@56ad3230{r=jar:file:/C:/Users/ACER/.m2/repository/org/apache/spark/spark-core_2.11/2.3.0/spark-core_2.11-2.3.0.jar!/org/apache/spark/ui/static/sorttable.js,gz=false}
2021-12-06 14:56:25,532 [SparkUI-42] WARN [org.spark_project.jetty.servlet.ServletHandler] - Error for /static/sorttable.js
java.lang.NoSuchMethodError: javax.servlet.http.HttpServletRequest.isAsyncSupported()Z
	at org.spark_project.jetty.servlet.DefaultServlet.sendData(DefaultServlet.java:909)
	at org.spark_project.jetty.servlet.DefaultServlet.doGet(DefaultServlet.java:526)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:707)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:820)
	at org.spark_project.jetty.servlet.ServletHolder.handle(ServletHolder.java:848)
	at org.spark_project.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:584)
	at org.spark_project.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
	at org.spark_project.jetty.servlet.ServletHandler.doScope(ServletHandler.java:512)
	at org.spark_project.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
	at org.spark_project.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.spark_project.jetty.server.handler.gzip.GzipHandler.handle(GzipHandler.java:493)
	at org.spark_project.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:213)
	at org.spark_project.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
	at org.spark_project.jetty.server.Server.handle(Server.java:534)
	at org.spark_project.jetty.server.HttpChannel.handle(HttpChannel.java:320)
	at org.spark_project.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
	at org.spark_project.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
	at org.spark_project.jetty.io.FillInterest.fillable(FillInterest.java:108)
	at org.spark_project.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
	at org.spark_project.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
	at org.spark_project.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
	at java.lang.Thread.run(Thread.java:745)
2021-12-06 14:56:25,532 [SparkUI-42] WARN [org.spark_project.jetty.server.HttpChannel] - //qb:4040/static/sorttable.js
java.lang.NoSuchMethodError: javax.servlet.http.HttpServletRequest.isAsyncStarted()Z
	at org.spark_project.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:688)
	at org.spark_project.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
	at org.spark_project.jetty.servlet.ServletHandler.doScope(ServletHandler.java:512)
	at org.spark_project.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
	at org.spark_project.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.spark_project.jetty.server.handler.gzip.GzipHandler.handle(GzipHandler.java:493)
	at org.spark_project.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:213)
	at org.spark_project.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
	at org.spark_project.jetty.server.Server.handle(Server.java:534)
	at org.spark_project.jetty.server.HttpChannel.handle(HttpChannel.java:320)
	at org.spark_project.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
	at org.spark_project.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
	at org.spark_project.jetty.io.FillInterest.fillable(FillInterest.java:108)
	at org.spark_project.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
	at org.spark_project.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
	at org.spark_project.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
	at java.lang.Thread.run(Thread.java:745)
2021-12-06 14:56:25,533 [SparkUI-62] INFO [org.spark_project.jetty.servlet.DefaultServlet] - content=ResourceHttpContent@4baa51ba{r=jar:file:/C:/Users/ACER/.m2/repository/org/apache/spark/spark-core_2.11/2.3.0/spark-core_2.11-2.3.0.jar!/org/apache/spark/ui/static/vis.min.js,gz=false}
2021-12-06 14:56:25,533 [SparkUI-62] WARN [org.spark_project.jetty.servlet.ServletHandler] - Error for /static/vis.min.js
java.lang.NoSuchMethodError: javax.servlet.http.HttpServletRequest.isAsyncSupported()Z
	at org.spark_project.jetty.servlet.DefaultServlet.sendData(DefaultServlet.java:909)
	at org.spark_project.jetty.servlet.DefaultServlet.doGet(DefaultServlet.java:526)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:707)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:820)
	at org.spark_project.jetty.servlet.ServletHolder.handle(ServletHolder.java:848)
	at org.spark_project.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:584)
	at org.spark_project.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
	at org.spark_project.jetty.servlet.ServletHandler.doScope(ServletHandler.java:512)
	at org.spark_project.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
	at org.spark_project.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.spark_project.jetty.server.handler.gzip.GzipHandler.handle(GzipHandler.java:493)
	at org.spark_project.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:213)
	at org.spark_project.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
	at org.spark_project.jetty.server.Server.handle(Server.java:534)
	at org.spark_project.jetty.server.HttpChannel.handle(HttpChannel.java:320)
	at org.spark_project.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
	at org.spark_project.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
	at org.spark_project.jetty.io.FillInterest.fillable(FillInterest.java:108)
	at org.spark_project.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
	at org.spark_project.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
	at org.spark_project.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
	at java.lang.Thread.run(Thread.java:745)
2021-12-06 14:56:25,533 [SparkUI-62] WARN [org.spark_project.jetty.server.HttpChannel] - //qb:4040/static/vis.min.js
java.lang.NoSuchMethodError: javax.servlet.http.HttpServletRequest.isAsyncStarted()Z
	at org.spark_project.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:688)
	at org.spark_project.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
	at org.spark_project.jetty.servlet.ServletHandler.doScope(ServletHandler.java:512)
	at org.spark_project.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
	at org.spark_project.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.spark_project.jetty.server.handler.gzip.GzipHandler.handle(GzipHandler.java:493)
	at org.spark_project.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:213)
	at org.spark_project.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
	at org.spark_project.jetty.server.Server.handle(Server.java:534)
	at org.spark_project.jetty.server.HttpChannel.handle(HttpChannel.java:320)
	at org.spark_project.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
	at org.spark_project.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
	at org.spark_project.jetty.io.FillInterest.fillable(FillInterest.java:108)
	at org.spark_project.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
	at org.spark_project.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
	at org.spark_project.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
	at java.lang.Thread.run(Thread.java:745)
2021-12-06 14:56:25,534 [SparkUI-39] INFO [org.spark_project.jetty.servlet.DefaultServlet] - content=ResourceHttpContent@12520d02{r=jar:file:/C:/Users/ACER/.m2/repository/org/apache/spark/spark-core_2.11/2.3.0/spark-core_2.11-2.3.0.jar!/org/apache/spark/ui/static/bootstrap-tooltip.js,gz=false}
2021-12-06 14:56:25,536 [SparkUI-39] WARN [org.spark_project.jetty.servlet.ServletHandler] - Error for /static/bootstrap-tooltip.js
java.lang.NoSuchMethodError: javax.servlet.http.HttpServletRequest.isAsyncSupported()Z
	at org.spark_project.jetty.servlet.DefaultServlet.sendData(DefaultServlet.java:909)
	at org.spark_project.jetty.servlet.DefaultServlet.doGet(DefaultServlet.java:526)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:707)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:820)
	at org.spark_project.jetty.servlet.ServletHolder.handle(ServletHolder.java:848)
	at org.spark_project.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:584)
	at org.spark_project.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
	at org.spark_project.jetty.servlet.ServletHandler.doScope(ServletHandler.java:512)
	at org.spark_project.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
	at org.spark_project.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.spark_project.jetty.server.handler.gzip.GzipHandler.handle(GzipHandler.java:493)
	at org.spark_project.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:213)
	at org.spark_project.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
	at org.spark_project.jetty.server.Server.handle(Server.java:534)
	at org.spark_project.jetty.server.HttpChannel.handle(HttpChannel.java:320)
	at org.spark_project.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
	at org.spark_project.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
	at org.spark_project.jetty.io.FillInterest.fillable(FillInterest.java:108)
	at org.spark_project.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
	at org.spark_project.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
	at org.spark_project.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
	at java.lang.Thread.run(Thread.java:745)
2021-12-06 14:56:25,537 [SparkUI-39] WARN [org.spark_project.jetty.server.HttpChannel] - //qb:4040/static/bootstrap-tooltip.js
java.lang.NoSuchMethodError: javax.servlet.http.HttpServletRequest.isAsyncStarted()Z
	at org.spark_project.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:688)
	at org.spark_project.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
	at org.spark_project.jetty.servlet.ServletHandler.doScope(ServletHandler.java:512)
	at org.spark_project.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
	at org.spark_project.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.spark_project.jetty.server.handler.gzip.GzipHandler.handle(GzipHandler.java:493)
	at org.spark_project.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:213)
	at org.spark_project.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
	at org.spark_project.jetty.server.Server.handle(Server.java:534)
	at org.spark_project.jetty.server.HttpChannel.handle(HttpChannel.java:320)
	at org.spark_project.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
	at org.spark_project.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
	at org.spark_project.jetty.io.FillInterest.fillable(FillInterest.java:108)
	at org.spark_project.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
	at org.spark_project.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
	at org.spark_project.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
	at java.lang.Thread.run(Thread.java:745)
2021-12-06 14:56:25,538 [SparkUI-44] INFO [org.spark_project.jetty.servlet.DefaultServlet] - content=ResourceHttpContent@3dec05db{r=jar:file:/C:/Users/ACER/.m2/repository/org/apache/spark/spark-core_2.11/2.3.0/spark-core_2.11-2.3.0.jar!/org/apache/spark/ui/static/initialize-tooltips.js,gz=false}
2021-12-06 14:56:25,538 [SparkUI-44] WARN [org.spark_project.jetty.servlet.ServletHandler] - Error for /static/initialize-tooltips.js
java.lang.NoSuchMethodError: javax.servlet.http.HttpServletRequest.isAsyncSupported()Z
	at org.spark_project.jetty.servlet.DefaultServlet.sendData(DefaultServlet.java:909)
	at org.spark_project.jetty.servlet.DefaultServlet.doGet(DefaultServlet.java:526)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:707)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:820)
	at org.spark_project.jetty.servlet.ServletHolder.handle(ServletHolder.java:848)
	at org.spark_project.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:584)
	at org.spark_project.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
	at org.spark_project.jetty.servlet.ServletHandler.doScope(ServletHandler.java:512)
	at org.spark_project.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
	at org.spark_project.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.spark_project.jetty.server.handler.gzip.GzipHandler.handle(GzipHandler.java:493)
	at org.spark_project.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:213)
	at org.spark_project.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
	at org.spark_project.jetty.server.Server.handle(Server.java:534)
	at org.spark_project.jetty.server.HttpChannel.handle(HttpChannel.java:320)
	at org.spark_project.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
	at org.spark_project.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
	at org.spark_project.jetty.io.FillInterest.fillable(FillInterest.java:108)
	at org.spark_project.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
	at org.spark_project.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
	at org.spark_project.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
	at java.lang.Thread.run(Thread.java:745)
2021-12-06 14:56:25,539 [SparkUI-44] WARN [org.spark_project.jetty.server.HttpChannel] - //qb:4040/static/initialize-tooltips.js
java.lang.NoSuchMethodError: javax.servlet.http.HttpServletRequest.isAsyncStarted()Z
	at org.spark_project.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:688)
	at org.spark_project.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
	at org.spark_project.jetty.servlet.ServletHandler.doScope(ServletHandler.java:512)
	at org.spark_project.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
	at org.spark_project.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.spark_project.jetty.server.handler.gzip.GzipHandler.handle(GzipHandler.java:493)
	at org.spark_project.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:213)
	at org.spark_project.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
	at org.spark_project.jetty.server.Server.handle(Server.java:534)
	at org.spark_project.jetty.server.HttpChannel.handle(HttpChannel.java:320)
	at org.spark_project.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
	at org.spark_project.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
	at org.spark_project.jetty.io.FillInterest.fillable(FillInterest.java:108)
	at org.spark_project.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
	at org.spark_project.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
	at org.spark_project.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
	at java.lang.Thread.run(Thread.java:745)
2021-12-06 14:56:25,541 [SparkUI-46] INFO [org.spark_project.jetty.servlet.DefaultServlet] - content=ResourceHttpContent@5dd4999e{r=jar:file:/C:/Users/ACER/.m2/repository/org/apache/spark/spark-core_2.11/2.3.0/spark-core_2.11-2.3.0.jar!/org/apache/spark/ui/static/additional-metrics.js,gz=false}
2021-12-06 14:56:25,541 [SparkUI-46] WARN [org.spark_project.jetty.servlet.ServletHandler] - Error for /static/additional-metrics.js
java.lang.NoSuchMethodError: javax.servlet.http.HttpServletRequest.isAsyncSupported()Z
	at org.spark_project.jetty.servlet.DefaultServlet.sendData(DefaultServlet.java:909)
	at org.spark_project.jetty.servlet.DefaultServlet.doGet(DefaultServlet.java:526)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:707)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:820)
	at org.spark_project.jetty.servlet.ServletHolder.handle(ServletHolder.java:848)
	at org.spark_project.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:584)
	at org.spark_project.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
	at org.spark_project.jetty.servlet.ServletHandler.doScope(ServletHandler.java:512)
	at org.spark_project.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
	at org.spark_project.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.spark_project.jetty.server.handler.gzip.GzipHandler.handle(GzipHandler.java:493)
	at org.spark_project.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:213)
	at org.spark_project.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
	at org.spark_project.jetty.server.Server.handle(Server.java:534)
	at org.spark_project.jetty.server.HttpChannel.handle(HttpChannel.java:320)
	at org.spark_project.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
	at org.spark_project.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
	at org.spark_project.jetty.io.FillInterest.fillable(FillInterest.java:108)
	at org.spark_project.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
	at org.spark_project.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
	at org.spark_project.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
	at java.lang.Thread.run(Thread.java:745)
2021-12-06 14:56:25,541 [SparkUI-46] WARN [org.spark_project.jetty.server.HttpChannel] - //qb:4040/static/additional-metrics.js
java.lang.NoSuchMethodError: javax.servlet.http.HttpServletRequest.isAsyncStarted()Z
	at org.spark_project.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:688)
	at org.spark_project.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
	at org.spark_project.jetty.servlet.ServletHandler.doScope(ServletHandler.java:512)
	at org.spark_project.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
	at org.spark_project.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.spark_project.jetty.server.handler.gzip.GzipHandler.handle(GzipHandler.java:493)
	at org.spark_project.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:213)
	at org.spark_project.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
	at org.spark_project.jetty.server.Server.handle(Server.java:534)
	at org.spark_project.jetty.server.HttpChannel.handle(HttpChannel.java:320)
	at org.spark_project.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
	at org.spark_project.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
	at org.spark_project.jetty.io.FillInterest.fillable(FillInterest.java:108)
	at org.spark_project.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
	at org.spark_project.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
	at org.spark_project.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
	at java.lang.Thread.run(Thread.java:745)
2021-12-06 14:56:25,542 [SparkUI-65] INFO [org.spark_project.jetty.servlet.DefaultServlet] - content=ResourceHttpContent@514c5899{r=jar:file:/C:/Users/ACER/.m2/repository/org/apache/spark/spark-core_2.11/2.3.0/spark-core_2.11-2.3.0.jar!/org/apache/spark/ui/static/table.js,gz=false}
2021-12-06 14:56:25,542 [SparkUI-65] WARN [org.spark_project.jetty.servlet.ServletHandler] - Error for /static/table.js
java.lang.NoSuchMethodError: javax.servlet.http.HttpServletRequest.isAsyncSupported()Z
	at org.spark_project.jetty.servlet.DefaultServlet.sendData(DefaultServlet.java:909)
	at org.spark_project.jetty.servlet.DefaultServlet.doGet(DefaultServlet.java:526)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:707)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:820)
	at org.spark_project.jetty.servlet.ServletHolder.handle(ServletHolder.java:848)
	at org.spark_project.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:584)
	at org.spark_project.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
	at org.spark_project.jetty.servlet.ServletHandler.doScope(ServletHandler.java:512)
	at org.spark_project.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
	at org.spark_project.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.spark_project.jetty.server.handler.gzip.GzipHandler.handle(GzipHandler.java:493)
	at org.spark_project.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:213)
	at org.spark_project.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
	at org.spark_project.jetty.server.Server.handle(Server.java:534)
	at org.spark_project.jetty.server.HttpChannel.handle(HttpChannel.java:320)
	at org.spark_project.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
	at org.spark_project.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
	at org.spark_project.jetty.io.FillInterest.fillable(FillInterest.java:108)
	at org.spark_project.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
	at org.spark_project.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
	at org.spark_project.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
	at java.lang.Thread.run(Thread.java:745)
2021-12-06 14:56:25,543 [SparkUI-65] WARN [org.spark_project.jetty.server.HttpChannel] - //qb:4040/static/table.js
java.lang.NoSuchMethodError: javax.servlet.http.HttpServletRequest.isAsyncStarted()Z
	at org.spark_project.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:688)
	at org.spark_project.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
	at org.spark_project.jetty.servlet.ServletHandler.doScope(ServletHandler.java:512)
	at org.spark_project.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
	at org.spark_project.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.spark_project.jetty.server.handler.gzip.GzipHandler.handle(GzipHandler.java:493)
	at org.spark_project.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:213)
	at org.spark_project.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
	at org.spark_project.jetty.server.Server.handle(Server.java:534)
	at org.spark_project.jetty.server.HttpChannel.handle(HttpChannel.java:320)
	at org.spark_project.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
	at org.spark_project.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
	at org.spark_project.jetty.io.FillInterest.fillable(FillInterest.java:108)
	at org.spark_project.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
	at org.spark_project.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
	at org.spark_project.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
	at java.lang.Thread.run(Thread.java:745)
2021-12-06 14:56:25,544 [SparkUI-45] INFO [org.spark_project.jetty.servlet.DefaultServlet] - content=ResourceHttpContent@475f75ea{r=jar:file:/C:/Users/ACER/.m2/repository/org/apache/spark/spark-core_2.11/2.3.0/spark-core_2.11-2.3.0.jar!/org/apache/spark/ui/static/timeline-view.js,gz=false}
2021-12-06 14:56:25,544 [SparkUI-45] WARN [org.spark_project.jetty.servlet.ServletHandler] - Error for /static/timeline-view.js
java.lang.NoSuchMethodError: javax.servlet.http.HttpServletRequest.isAsyncSupported()Z
	at org.spark_project.jetty.servlet.DefaultServlet.sendData(DefaultServlet.java:909)
	at org.spark_project.jetty.servlet.DefaultServlet.doGet(DefaultServlet.java:526)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:707)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:820)
	at org.spark_project.jetty.servlet.ServletHolder.handle(ServletHolder.java:848)
	at org.spark_project.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:584)
	at org.spark_project.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
	at org.spark_project.jetty.servlet.ServletHandler.doScope(ServletHandler.java:512)
	at org.spark_project.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
	at org.spark_project.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.spark_project.jetty.server.handler.gzip.GzipHandler.handle(GzipHandler.java:493)
	at org.spark_project.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:213)
	at org.spark_project.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
	at org.spark_project.jetty.server.Server.handle(Server.java:534)
	at org.spark_project.jetty.server.HttpChannel.handle(HttpChannel.java:320)
	at org.spark_project.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
	at org.spark_project.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
	at org.spark_project.jetty.io.FillInterest.fillable(FillInterest.java:108)
	at org.spark_project.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
	at org.spark_project.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
	at org.spark_project.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
	at java.lang.Thread.run(Thread.java:745)
2021-12-06 14:56:25,544 [SparkUI-45] WARN [org.spark_project.jetty.server.HttpChannel] - //qb:4040/static/timeline-view.js
java.lang.NoSuchMethodError: javax.servlet.http.HttpServletRequest.isAsyncStarted()Z
	at org.spark_project.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:688)
	at org.spark_project.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
	at org.spark_project.jetty.servlet.ServletHandler.doScope(ServletHandler.java:512)
	at org.spark_project.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
	at org.spark_project.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.spark_project.jetty.server.handler.gzip.GzipHandler.handle(GzipHandler.java:493)
	at org.spark_project.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:213)
	at org.spark_project.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
	at org.spark_project.jetty.server.Server.handle(Server.java:534)
	at org.spark_project.jetty.server.HttpChannel.handle(HttpChannel.java:320)
	at org.spark_project.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
	at org.spark_project.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
	at org.spark_project.jetty.io.FillInterest.fillable(FillInterest.java:108)
	at org.spark_project.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
	at org.spark_project.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
	at org.spark_project.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
	at java.lang.Thread.run(Thread.java:745)
2021-12-06 14:56:25,545 [SparkUI-61] INFO [org.spark_project.jetty.servlet.DefaultServlet] - content=ResourceHttpContent@1997e29e{r=jar:file:/C:/Users/ACER/.m2/repository/org/apache/spark/spark-core_2.11/2.3.0/spark-core_2.11-2.3.0.jar!/org/apache/spark/ui/static/webui.js,gz=false}
2021-12-06 14:56:25,545 [SparkUI-61] WARN [org.spark_project.jetty.servlet.ServletHandler] - Error for /static/webui.js
java.lang.NoSuchMethodError: javax.servlet.http.HttpServletRequest.isAsyncSupported()Z
	at org.spark_project.jetty.servlet.DefaultServlet.sendData(DefaultServlet.java:909)
	at org.spark_project.jetty.servlet.DefaultServlet.doGet(DefaultServlet.java:526)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:707)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:820)
	at org.spark_project.jetty.servlet.ServletHolder.handle(ServletHolder.java:848)
	at org.spark_project.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:584)
	at org.spark_project.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
	at org.spark_project.jetty.servlet.ServletHandler.doScope(ServletHandler.java:512)
	at org.spark_project.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
	at org.spark_project.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.spark_project.jetty.server.handler.gzip.GzipHandler.handle(GzipHandler.java:493)
	at org.spark_project.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:213)
	at org.spark_project.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
	at org.spark_project.jetty.server.Server.handle(Server.java:534)
	at org.spark_project.jetty.server.HttpChannel.handle(HttpChannel.java:320)
	at org.spark_project.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
	at org.spark_project.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
	at org.spark_project.jetty.io.FillInterest.fillable(FillInterest.java:108)
	at org.spark_project.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
	at org.spark_project.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
	at org.spark_project.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
	at java.lang.Thread.run(Thread.java:745)
2021-12-06 14:56:25,545 [SparkUI-55] INFO [org.spark_project.jetty.servlet.DefaultServlet] - content=ResourceHttpContent@7ab2fdb5{r=jar:file:/C:/Users/ACER/.m2/repository/org/apache/spark/spark-core_2.11/2.3.0/spark-core_2.11-2.3.0.jar!/org/apache/spark/ui/static/log-view.js,gz=false}
2021-12-06 14:56:25,545 [SparkUI-61] WARN [org.spark_project.jetty.server.HttpChannel] - //qb:4040/static/webui.js
java.lang.NoSuchMethodError: javax.servlet.http.HttpServletRequest.isAsyncStarted()Z
	at org.spark_project.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:688)
	at org.spark_project.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
	at org.spark_project.jetty.servlet.ServletHandler.doScope(ServletHandler.java:512)
	at org.spark_project.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
	at org.spark_project.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.spark_project.jetty.server.handler.gzip.GzipHandler.handle(GzipHandler.java:493)
	at org.spark_project.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:213)
	at org.spark_project.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
	at org.spark_project.jetty.server.Server.handle(Server.java:534)
	at org.spark_project.jetty.server.HttpChannel.handle(HttpChannel.java:320)
	at org.spark_project.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
	at org.spark_project.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
	at org.spark_project.jetty.io.FillInterest.fillable(FillInterest.java:108)
	at org.spark_project.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
	at org.spark_project.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
	at org.spark_project.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
	at java.lang.Thread.run(Thread.java:745)
2021-12-06 14:56:25,545 [SparkUI-55] WARN [org.spark_project.jetty.servlet.ServletHandler] - Error for /static/log-view.js
java.lang.NoSuchMethodError: javax.servlet.http.HttpServletRequest.isAsyncSupported()Z
	at org.spark_project.jetty.servlet.DefaultServlet.sendData(DefaultServlet.java:909)
	at org.spark_project.jetty.servlet.DefaultServlet.doGet(DefaultServlet.java:526)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:707)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:820)
	at org.spark_project.jetty.servlet.ServletHolder.handle(ServletHolder.java:848)
	at org.spark_project.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:584)
	at org.spark_project.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
	at org.spark_project.jetty.servlet.ServletHandler.doScope(ServletHandler.java:512)
	at org.spark_project.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
	at org.spark_project.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.spark_project.jetty.server.handler.gzip.GzipHandler.handle(GzipHandler.java:493)
	at org.spark_project.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:213)
	at org.spark_project.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
	at org.spark_project.jetty.server.Server.handle(Server.java:534)
	at org.spark_project.jetty.server.HttpChannel.handle(HttpChannel.java:320)
	at org.spark_project.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
	at org.spark_project.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
	at org.spark_project.jetty.io.FillInterest.fillable(FillInterest.java:108)
	at org.spark_project.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
	at org.spark_project.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
	at org.spark_project.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
	at java.lang.Thread.run(Thread.java:745)
2021-12-06 14:56:25,546 [SparkUI-55] WARN [org.spark_project.jetty.server.HttpChannel] - //qb:4040/static/log-view.js
java.lang.NoSuchMethodError: javax.servlet.http.HttpServletRequest.isAsyncStarted()Z
	at org.spark_project.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:688)
	at org.spark_project.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
	at org.spark_project.jetty.servlet.ServletHandler.doScope(ServletHandler.java:512)
	at org.spark_project.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
	at org.spark_project.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.spark_project.jetty.server.handler.gzip.GzipHandler.handle(GzipHandler.java:493)
	at org.spark_project.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:213)
	at org.spark_project.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
	at org.spark_project.jetty.server.Server.handle(Server.java:534)
	at org.spark_project.jetty.server.HttpChannel.handle(HttpChannel.java:320)
	at org.spark_project.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
	at org.spark_project.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
	at org.spark_project.jetty.io.FillInterest.fillable(FillInterest.java:108)
	at org.spark_project.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
	at org.spark_project.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
	at org.spark_project.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
	at java.lang.Thread.run(Thread.java:745)
2021-12-06 14:56:25,550 [SparkUI-62] INFO [org.spark_project.jetty.servlet.DefaultServlet] - content=ResourceHttpContent@11a59887{r=jar:file:/C:/Users/ACER/.m2/repository/org/apache/spark/spark-core_2.11/2.3.0/spark-core_2.11-2.3.0.jar!/org/apache/spark/ui/static/spark-logo-77x50px-hd.png,gz=false}
2021-12-06 14:56:25,551 [SparkUI-62] WARN [org.spark_project.jetty.servlet.ServletHandler] - Error for /static/spark-logo-77x50px-hd.png
java.lang.NoSuchMethodError: javax.servlet.http.HttpServletRequest.isAsyncSupported()Z
	at org.spark_project.jetty.servlet.DefaultServlet.sendData(DefaultServlet.java:909)
	at org.spark_project.jetty.servlet.DefaultServlet.doGet(DefaultServlet.java:526)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:707)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:820)
	at org.spark_project.jetty.servlet.ServletHolder.handle(ServletHolder.java:848)
	at org.spark_project.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:584)
	at org.spark_project.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
	at org.spark_project.jetty.servlet.ServletHandler.doScope(ServletHandler.java:512)
	at org.spark_project.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
	at org.spark_project.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.spark_project.jetty.server.handler.gzip.GzipHandler.handle(GzipHandler.java:448)
	at org.spark_project.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:213)
	at org.spark_project.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
	at org.spark_project.jetty.server.Server.handle(Server.java:534)
	at org.spark_project.jetty.server.HttpChannel.handle(HttpChannel.java:320)
	at org.spark_project.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
	at org.spark_project.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
	at org.spark_project.jetty.io.FillInterest.fillable(FillInterest.java:108)
	at org.spark_project.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
	at org.spark_project.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
	at org.spark_project.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
	at java.lang.Thread.run(Thread.java:745)
2021-12-06 14:56:25,551 [SparkUI-62] WARN [org.spark_project.jetty.server.HttpChannel] - //qb:4040/static/spark-logo-77x50px-hd.png
java.lang.NoSuchMethodError: javax.servlet.http.HttpServletRequest.isAsyncStarted()Z
	at org.spark_project.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:688)
	at org.spark_project.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
	at org.spark_project.jetty.servlet.ServletHandler.doScope(ServletHandler.java:512)
	at org.spark_project.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
	at org.spark_project.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.spark_project.jetty.server.handler.gzip.GzipHandler.handle(GzipHandler.java:448)
	at org.spark_project.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:213)
	at org.spark_project.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
	at org.spark_project.jetty.server.Server.handle(Server.java:534)
	at org.spark_project.jetty.server.HttpChannel.handle(HttpChannel.java:320)
	at org.spark_project.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
	at org.spark_project.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
	at org.spark_project.jetty.io.FillInterest.fillable(FillInterest.java:108)
	at org.spark_project.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
	at org.spark_project.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
	at org.spark_project.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
	at java.lang.Thread.run(Thread.java:745)
2021-12-06 14:56:25,627 [main] WARN [org.apache.hadoop.hdfs.shortcircuit.DomainSocketFactory] - The short-circuit local reads feature cannot be used because UNIX Domain sockets are not available on Windows.
2021-12-06 14:56:25,994 [main] INFO [org.apache.hadoop.mapred.FileInputFormat] - Total input paths to process : 1
2021-12-06 14:56:26,005 [main] INFO [org.apache.spark.SparkContext] - Starting job: count at PaidPromotionAdjustParameter.scala:248
2021-12-06 14:56:26,016 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 0 (count at PaidPromotionAdjustParameter.scala:248) with 2 output partitions
2021-12-06 14:56:26,016 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 0 (count at PaidPromotionAdjustParameter.scala:248)
2021-12-06 14:56:26,017 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List()
2021-12-06 14:56:26,018 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2021-12-06 14:56:26,023 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 0 (MapPartitionsRDD[4] at map at PaidPromotionAdjustParameter.scala:244), which has no missing parents
2021-12-06 14:56:26,058 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_2 stored as values in memory (estimated size 3.3 KB, free 1990.1 MB)
2021-12-06 14:56:26,062 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_2_piece0 stored as bytes in memory (estimated size 1994.0 B, free 1990.1 MB)
2021-12-06 14:56:26,063 [dispatcher-event-loop-2] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_2_piece0 in memory on qb:60443 (size: 1994.0 B, free: 1990.7 MB)
2021-12-06 14:56:26,063 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 2 from broadcast at DAGScheduler.scala:1039
2021-12-06 14:56:26,074 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from ResultStage 0 (MapPartitionsRDD[4] at map at PaidPromotionAdjustParameter.scala:244) (first 15 tasks are for partitions Vector(0, 1))
2021-12-06 14:56:26,075 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 0.0 with 2 tasks
2021-12-06 14:56:26,109 [dispatcher-event-loop-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 0.0 (TID 0, localhost, executor driver, partition 0, ANY, 7932 bytes)
2021-12-06 14:56:26,111 [dispatcher-event-loop-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 0.0 (TID 1, localhost, executor driver, partition 1, ANY, 7932 bytes)
2021-12-06 14:56:26,116 [Executor task launch worker for task 1] INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 0.0 (TID 1)
2021-12-06 14:56:26,116 [Executor task launch worker for task 0] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 0.0 (TID 0)
2021-12-06 14:56:26,154 [Executor task launch worker for task 1] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/handle_data/set-train-device-production-data/part-00000:3235948+3235949
2021-12-06 14:56:26,154 [Executor task launch worker for task 0] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/handle_data/set-train-device-production-data/part-00000:0+3235948
2021-12-06 14:56:26,899 [Executor task launch worker for task 1] INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 0.0 (TID 1). 754 bytes result sent to driver
2021-12-06 14:56:26,908 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 0.0 (TID 1) in 797 ms on localhost (executor driver) (1/2)
2021-12-06 14:56:28,470 [Executor task launch worker for task 0] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 0.0 (TID 0). 754 bytes result sent to driver
2021-12-06 14:56:28,473 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 0.0 (TID 0) in 2373 ms on localhost (executor driver) (2/2)
2021-12-06 14:56:28,474 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 0 (count at PaidPromotionAdjustParameter.scala:248) finished in 2.437 s
2021-12-06 14:56:28,474 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 0.0, whose tasks have all completed, from pool 
2021-12-06 14:56:28,479 [main] INFO [org.apache.spark.scheduler.DAGScheduler] - Job 0 finished: count at PaidPromotionAdjustParameter.scala:248, took 2.472346 s
2021-12-06 14:56:28,480 [main] INFO [PaidPromotion$] - 100999
2021-12-06 14:56:28,968 [main] INFO [org.apache.spark.SparkContext] - Starting job: zipWithIndex at PaidPromotionAdjustParameter.scala:253
2021-12-06 14:56:28,980 [SparkUI-39] INFO [org.spark_project.jetty.servlet.DefaultServlet] - content=ResourceHttpContent@358f4c6c{r=jar:file:/C:/Users/ACER/.m2/repository/org/apache/spark/spark-core_2.11/2.3.0/spark-core_2.11-2.3.0.jar!/org/apache/spark/ui/static/bootstrap.min.css,gz=false}
2021-12-06 14:56:28,980 [SparkUI-39] WARN [org.spark_project.jetty.servlet.ServletHandler] - Error for /static/bootstrap.min.css
java.lang.NoSuchMethodError: javax.servlet.http.HttpServletRequest.isAsyncSupported()Z
	at org.spark_project.jetty.servlet.DefaultServlet.sendData(DefaultServlet.java:909)
	at org.spark_project.jetty.servlet.DefaultServlet.doGet(DefaultServlet.java:526)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:707)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:820)
	at org.spark_project.jetty.servlet.ServletHolder.handle(ServletHolder.java:848)
	at org.spark_project.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:584)
	at org.spark_project.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
	at org.spark_project.jetty.servlet.ServletHandler.doScope(ServletHandler.java:512)
	at org.spark_project.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
	at org.spark_project.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.spark_project.jetty.server.handler.gzip.GzipHandler.handle(GzipHandler.java:493)
	at org.spark_project.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:213)
	at org.spark_project.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
	at org.spark_project.jetty.server.Server.handle(Server.java:534)
	at org.spark_project.jetty.server.HttpChannel.handle(HttpChannel.java:320)
	at org.spark_project.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
	at org.spark_project.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
	at org.spark_project.jetty.io.FillInterest.fillable(FillInterest.java:108)
	at org.spark_project.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
	at org.spark_project.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
	at org.spark_project.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
	at java.lang.Thread.run(Thread.java:745)
2021-12-06 14:56:28,981 [SparkUI-39] WARN [org.spark_project.jetty.server.HttpChannel] - //qb:4040/static/bootstrap.min.css
java.lang.NoSuchMethodError: javax.servlet.http.HttpServletRequest.isAsyncStarted()Z
	at org.spark_project.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:688)
	at org.spark_project.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
	at org.spark_project.jetty.servlet.ServletHandler.doScope(ServletHandler.java:512)
	at org.spark_project.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
	at org.spark_project.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.spark_project.jetty.server.handler.gzip.GzipHandler.handle(GzipHandler.java:493)
	at org.spark_project.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:213)
	at org.spark_project.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
	at org.spark_project.jetty.server.Server.handle(Server.java:534)
	at org.spark_project.jetty.server.HttpChannel.handle(HttpChannel.java:320)
	at org.spark_project.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
	at org.spark_project.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
	at org.spark_project.jetty.io.FillInterest.fillable(FillInterest.java:108)
	at org.spark_project.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
	at org.spark_project.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
	at org.spark_project.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
	at java.lang.Thread.run(Thread.java:745)
2021-12-06 14:56:28,983 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 6 (distinct at PaidPromotionAdjustParameter.scala:252)
2021-12-06 14:56:28,983 [SparkUI-63] INFO [org.spark_project.jetty.servlet.DefaultServlet] - content=ResourceHttpContent@b4a4fe2{r=jar:file:/C:/Users/ACER/.m2/repository/org/apache/spark/spark-core_2.11/2.3.0/spark-core_2.11-2.3.0.jar!/org/apache/spark/ui/static/vis.min.css,gz=false}
2021-12-06 14:56:28,983 [SparkUI-63] WARN [org.spark_project.jetty.servlet.ServletHandler] - Error for /static/vis.min.css
java.lang.NoSuchMethodError: javax.servlet.http.HttpServletRequest.isAsyncSupported()Z
	at org.spark_project.jetty.servlet.DefaultServlet.sendData(DefaultServlet.java:909)
	at org.spark_project.jetty.servlet.DefaultServlet.doGet(DefaultServlet.java:526)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:707)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:820)
	at org.spark_project.jetty.servlet.ServletHolder.handle(ServletHolder.java:848)
	at org.spark_project.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:584)
	at org.spark_project.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
	at org.spark_project.jetty.servlet.ServletHandler.doScope(ServletHandler.java:512)
	at org.spark_project.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
	at org.spark_project.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.spark_project.jetty.server.handler.gzip.GzipHandler.handle(GzipHandler.java:493)
	at org.spark_project.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:213)
	at org.spark_project.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
	at org.spark_project.jetty.server.Server.handle(Server.java:534)
	at org.spark_project.jetty.server.HttpChannel.handle(HttpChannel.java:320)
	at org.spark_project.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
	at org.spark_project.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
	at org.spark_project.jetty.io.FillInterest.fillable(FillInterest.java:108)
	at org.spark_project.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
	at org.spark_project.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
	at org.spark_project.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
	at java.lang.Thread.run(Thread.java:745)
2021-12-06 14:56:28,984 [SparkUI-63] WARN [org.spark_project.jetty.server.HttpChannel] - //qb:4040/static/vis.min.css
java.lang.NoSuchMethodError: javax.servlet.http.HttpServletRequest.isAsyncStarted()Z
	at org.spark_project.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:688)
	at org.spark_project.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
	at org.spark_project.jetty.servlet.ServletHandler.doScope(ServletHandler.java:512)
	at org.spark_project.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
	at org.spark_project.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.spark_project.jetty.server.handler.gzip.GzipHandler.handle(GzipHandler.java:493)
	at org.spark_project.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:213)
	at org.spark_project.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
	at org.spark_project.jetty.server.Server.handle(Server.java:534)
	at org.spark_project.jetty.server.HttpChannel.handle(HttpChannel.java:320)
	at org.spark_project.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
	at org.spark_project.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
	at org.spark_project.jetty.io.FillInterest.fillable(FillInterest.java:108)
	at org.spark_project.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
	at org.spark_project.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
	at org.spark_project.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
	at java.lang.Thread.run(Thread.java:745)
2021-12-06 14:56:28,984 [SparkUI-46] INFO [org.spark_project.jetty.servlet.DefaultServlet] - content=ResourceHttpContent@c226d6b{r=jar:file:/C:/Users/ACER/.m2/repository/org/apache/spark/spark-core_2.11/2.3.0/spark-core_2.11-2.3.0.jar!/org/apache/spark/ui/static/webui.css,gz=false}
2021-12-06 14:56:28,985 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 1 (zipWithIndex at PaidPromotionAdjustParameter.scala:253) with 9 output partitions
2021-12-06 14:56:28,985 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 2 (zipWithIndex at PaidPromotionAdjustParameter.scala:253)
2021-12-06 14:56:28,985 [SparkUI-46] WARN [org.spark_project.jetty.servlet.ServletHandler] - Error for /static/webui.css
java.lang.NoSuchMethodError: javax.servlet.http.HttpServletRequest.isAsyncSupported()Z
	at org.spark_project.jetty.servlet.DefaultServlet.sendData(DefaultServlet.java:909)
	at org.spark_project.jetty.servlet.DefaultServlet.doGet(DefaultServlet.java:526)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:707)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:820)
	at org.spark_project.jetty.servlet.ServletHolder.handle(ServletHolder.java:848)
	at org.spark_project.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:584)
	at org.spark_project.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
	at org.spark_project.jetty.servlet.ServletHandler.doScope(ServletHandler.java:512)
	at org.spark_project.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
	at org.spark_project.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.spark_project.jetty.server.handler.gzip.GzipHandler.handle(GzipHandler.java:493)
	at org.spark_project.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:213)
	at org.spark_project.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
	at org.spark_project.jetty.server.Server.handle(Server.java:534)
	at org.spark_project.jetty.server.HttpChannel.handle(HttpChannel.java:320)
	at org.spark_project.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
	at org.spark_project.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
	at org.spark_project.jetty.io.FillInterest.fillable(FillInterest.java:108)
	at org.spark_project.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
	at org.spark_project.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
	at org.spark_project.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
	at java.lang.Thread.run(Thread.java:745)
2021-12-06 14:56:28,985 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 1)
2021-12-06 14:56:28,986 [SparkUI-46] WARN [org.spark_project.jetty.server.HttpChannel] - //qb:4040/static/webui.css
java.lang.NoSuchMethodError: javax.servlet.http.HttpServletRequest.isAsyncStarted()Z
	at org.spark_project.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:688)
	at org.spark_project.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
	at org.spark_project.jetty.servlet.ServletHandler.doScope(ServletHandler.java:512)
	at org.spark_project.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
	at org.spark_project.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.spark_project.jetty.server.handler.gzip.GzipHandler.handle(GzipHandler.java:493)
	at org.spark_project.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:213)
	at org.spark_project.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
	at org.spark_project.jetty.server.Server.handle(Server.java:534)
	at org.spark_project.jetty.server.HttpChannel.handle(HttpChannel.java:320)
	at org.spark_project.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
	at org.spark_project.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
	at org.spark_project.jetty.io.FillInterest.fillable(FillInterest.java:108)
	at org.spark_project.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
	at org.spark_project.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
	at org.spark_project.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
	at java.lang.Thread.run(Thread.java:745)
2021-12-06 14:56:28,988 [SparkUI-55] INFO [org.spark_project.jetty.servlet.DefaultServlet] - content=ResourceHttpContent@2bcb9a1e{r=jar:file:/C:/Users/ACER/.m2/repository/org/apache/spark/spark-core_2.11/2.3.0/spark-core_2.11-2.3.0.jar!/org/apache/spark/ui/static/timeline-view.css,gz=false}
2021-12-06 14:56:28,988 [SparkUI-55] WARN [org.spark_project.jetty.servlet.ServletHandler] - Error for /static/timeline-view.css
java.lang.NoSuchMethodError: javax.servlet.http.HttpServletRequest.isAsyncSupported()Z
	at org.spark_project.jetty.servlet.DefaultServlet.sendData(DefaultServlet.java:909)
	at org.spark_project.jetty.servlet.DefaultServlet.doGet(DefaultServlet.java:526)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:707)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:820)
	at org.spark_project.jetty.servlet.ServletHolder.handle(ServletHolder.java:848)
	at org.spark_project.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:584)
	at org.spark_project.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
	at org.spark_project.jetty.servlet.ServletHandler.doScope(ServletHandler.java:512)
	at org.spark_project.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
	at org.spark_project.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.spark_project.jetty.server.handler.gzip.GzipHandler.handle(GzipHandler.java:493)
	at org.spark_project.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:213)
	at org.spark_project.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
	at org.spark_project.jetty.server.Server.handle(Server.java:534)
	at org.spark_project.jetty.server.HttpChannel.handle(HttpChannel.java:320)
	at org.spark_project.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
	at org.spark_project.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
	at org.spark_project.jetty.io.FillInterest.fillable(FillInterest.java:108)
	at org.spark_project.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
	at org.spark_project.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
	at org.spark_project.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
	at java.lang.Thread.run(Thread.java:745)
2021-12-06 14:56:28,989 [SparkUI-55] WARN [org.spark_project.jetty.server.HttpChannel] - //qb:4040/static/timeline-view.css
java.lang.NoSuchMethodError: javax.servlet.http.HttpServletRequest.isAsyncStarted()Z
	at org.spark_project.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:688)
	at org.spark_project.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
	at org.spark_project.jetty.servlet.ServletHandler.doScope(ServletHandler.java:512)
	at org.spark_project.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
	at org.spark_project.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.spark_project.jetty.server.handler.gzip.GzipHandler.handle(GzipHandler.java:493)
	at org.spark_project.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:213)
	at org.spark_project.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
	at org.spark_project.jetty.server.Server.handle(Server.java:534)
	at org.spark_project.jetty.server.HttpChannel.handle(HttpChannel.java:320)
	at org.spark_project.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
	at org.spark_project.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
	at org.spark_project.jetty.io.FillInterest.fillable(FillInterest.java:108)
	at org.spark_project.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
	at org.spark_project.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
	at org.spark_project.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
	at java.lang.Thread.run(Thread.java:745)
2021-12-06 14:56:28,990 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List(ShuffleMapStage 1)
2021-12-06 14:56:28,990 [SparkUI-67] INFO [org.spark_project.jetty.servlet.DefaultServlet] - content=ResourceHttpContent@448a87c1{r=jar:file:/C:/Users/ACER/.m2/repository/org/apache/spark/spark-core_2.11/2.3.0/spark-core_2.11-2.3.0.jar!/org/apache/spark/ui/static/bootstrap.min.css,gz=false}
2021-12-06 14:56:28,991 [SparkUI-67] WARN [org.spark_project.jetty.servlet.ServletHandler] - Error for /static/bootstrap.min.css
java.lang.NoSuchMethodError: javax.servlet.http.HttpServletRequest.isAsyncSupported()Z
	at org.spark_project.jetty.servlet.DefaultServlet.sendData(DefaultServlet.java:909)
	at org.spark_project.jetty.servlet.DefaultServlet.doGet(DefaultServlet.java:526)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:707)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:820)
	at org.spark_project.jetty.servlet.ServletHolder.handle(ServletHolder.java:848)
	at org.spark_project.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:584)
	at org.spark_project.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
	at org.spark_project.jetty.servlet.ServletHandler.doScope(ServletHandler.java:512)
	at org.spark_project.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
	at org.spark_project.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.spark_project.jetty.server.handler.gzip.GzipHandler.handle(GzipHandler.java:493)
	at org.spark_project.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:213)
	at org.spark_project.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
	at org.spark_project.jetty.server.Server.handle(Server.java:534)
	at org.spark_project.jetty.server.HttpChannel.handle(HttpChannel.java:320)
	at org.spark_project.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
	at org.spark_project.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
	at org.spark_project.jetty.io.FillInterest.fillable(FillInterest.java:108)
	at org.spark_project.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
	at org.spark_project.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
	at org.spark_project.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
	at java.lang.Thread.run(Thread.java:745)
2021-12-06 14:56:28,991 [SparkUI-67] WARN [org.spark_project.jetty.server.HttpChannel] - //qb:4040/static/bootstrap.min.css
java.lang.NoSuchMethodError: javax.servlet.http.HttpServletRequest.isAsyncStarted()Z
	at org.spark_project.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:688)
	at org.spark_project.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
	at org.spark_project.jetty.servlet.ServletHandler.doScope(ServletHandler.java:512)
	at org.spark_project.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
	at org.spark_project.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.spark_project.jetty.server.handler.gzip.GzipHandler.handle(GzipHandler.java:493)
	at org.spark_project.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:213)
	at org.spark_project.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
	at org.spark_project.jetty.server.Server.handle(Server.java:534)
	at org.spark_project.jetty.server.HttpChannel.handle(HttpChannel.java:320)
	at org.spark_project.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
	at org.spark_project.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
	at org.spark_project.jetty.io.FillInterest.fillable(FillInterest.java:108)
	at org.spark_project.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
	at org.spark_project.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
	at org.spark_project.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
	at java.lang.Thread.run(Thread.java:745)
2021-12-06 14:56:28,991 [SparkUI-63] INFO [org.spark_project.jetty.servlet.DefaultServlet] - content=ResourceHttpContent@58c7e19b{r=jar:file:/C:/Users/ACER/.m2/repository/org/apache/spark/spark-core_2.11/2.3.0/spark-core_2.11-2.3.0.jar!/org/apache/spark/ui/static/vis.min.css,gz=false}
2021-12-06 14:56:28,991 [SparkUI-63] WARN [org.spark_project.jetty.servlet.ServletHandler] - Error for /static/vis.min.css
java.lang.NoSuchMethodError: javax.servlet.http.HttpServletRequest.isAsyncSupported()Z
	at org.spark_project.jetty.servlet.DefaultServlet.sendData(DefaultServlet.java:909)
	at org.spark_project.jetty.servlet.DefaultServlet.doGet(DefaultServlet.java:526)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:707)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:820)
	at org.spark_project.jetty.servlet.ServletHolder.handle(ServletHolder.java:848)
	at org.spark_project.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:584)
	at org.spark_project.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
	at org.spark_project.jetty.servlet.ServletHandler.doScope(ServletHandler.java:512)
	at org.spark_project.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
	at org.spark_project.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.spark_project.jetty.server.handler.gzip.GzipHandler.handle(GzipHandler.java:493)
	at org.spark_project.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:213)
	at org.spark_project.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
	at org.spark_project.jetty.server.Server.handle(Server.java:534)
	at org.spark_project.jetty.server.HttpChannel.handle(HttpChannel.java:320)
	at org.spark_project.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
	at org.spark_project.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
	at org.spark_project.jetty.io.FillInterest.fillable(FillInterest.java:108)
	at org.spark_project.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
	at org.spark_project.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
	at org.spark_project.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
	at java.lang.Thread.run(Thread.java:745)
2021-12-06 14:56:28,992 [SparkUI-63] WARN [org.spark_project.jetty.server.HttpChannel] - //qb:4040/static/vis.min.css
java.lang.NoSuchMethodError: javax.servlet.http.HttpServletRequest.isAsyncStarted()Z
	at org.spark_project.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:688)
	at org.spark_project.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
	at org.spark_project.jetty.servlet.ServletHandler.doScope(ServletHandler.java:512)
	at org.spark_project.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
	at org.spark_project.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.spark_project.jetty.server.handler.gzip.GzipHandler.handle(GzipHandler.java:493)
	at org.spark_project.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:213)
	at org.spark_project.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
	at org.spark_project.jetty.server.Server.handle(Server.java:534)
	at org.spark_project.jetty.server.HttpChannel.handle(HttpChannel.java:320)
	at org.spark_project.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
	at org.spark_project.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
	at org.spark_project.jetty.io.FillInterest.fillable(FillInterest.java:108)
	at org.spark_project.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
	at org.spark_project.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
	at org.spark_project.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
	at java.lang.Thread.run(Thread.java:745)
2021-12-06 14:56:28,992 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ShuffleMapStage 1 (MapPartitionsRDD[6] at distinct at PaidPromotionAdjustParameter.scala:252), which has no missing parents
2021-12-06 14:56:28,996 [SparkUI-56] INFO [org.spark_project.jetty.servlet.DefaultServlet] - content=ResourceHttpContent@11fbfb1d{r=jar:file:/C:/Users/ACER/.m2/repository/org/apache/spark/spark-core_2.11/2.3.0/spark-core_2.11-2.3.0.jar!/org/apache/spark/ui/static/sorttable.js,gz=false}
2021-12-06 14:56:28,996 [SparkUI-55] INFO [org.spark_project.jetty.servlet.DefaultServlet] - content=ResourceHttpContent@2a12c583{r=jar:file:/C:/Users/ACER/.m2/repository/org/apache/spark/spark-core_2.11/2.3.0/spark-core_2.11-2.3.0.jar!/org/apache/spark/ui/static/jquery-1.11.1.min.js,gz=false}
2021-12-06 14:56:28,996 [SparkUI-56] WARN [org.spark_project.jetty.servlet.ServletHandler] - Error for /static/sorttable.js
java.lang.NoSuchMethodError: javax.servlet.http.HttpServletRequest.isAsyncSupported()Z
	at org.spark_project.jetty.servlet.DefaultServlet.sendData(DefaultServlet.java:909)
	at org.spark_project.jetty.servlet.DefaultServlet.doGet(DefaultServlet.java:526)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:707)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:820)
	at org.spark_project.jetty.servlet.ServletHolder.handle(ServletHolder.java:848)
	at org.spark_project.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:584)
	at org.spark_project.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
	at org.spark_project.jetty.servlet.ServletHandler.doScope(ServletHandler.java:512)
	at org.spark_project.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
	at org.spark_project.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.spark_project.jetty.server.handler.gzip.GzipHandler.handle(GzipHandler.java:493)
	at org.spark_project.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:213)
	at org.spark_project.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
	at org.spark_project.jetty.server.Server.handle(Server.java:534)
	at org.spark_project.jetty.server.HttpChannel.handle(HttpChannel.java:320)
	at org.spark_project.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
	at org.spark_project.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
	at org.spark_project.jetty.io.FillInterest.fillable(FillInterest.java:108)
	at org.spark_project.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
	at org.spark_project.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
	at org.spark_project.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
	at java.lang.Thread.run(Thread.java:745)
2021-12-06 14:56:28,997 [SparkUI-55] WARN [org.spark_project.jetty.servlet.ServletHandler] - Error for /static/jquery-1.11.1.min.js
java.lang.NoSuchMethodError: javax.servlet.http.HttpServletRequest.isAsyncSupported()Z
	at org.spark_project.jetty.servlet.DefaultServlet.sendData(DefaultServlet.java:909)
	at org.spark_project.jetty.servlet.DefaultServlet.doGet(DefaultServlet.java:526)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:707)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:820)
	at org.spark_project.jetty.servlet.ServletHolder.handle(ServletHolder.java:848)
	at org.spark_project.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:584)
	at org.spark_project.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
	at org.spark_project.jetty.servlet.ServletHandler.doScope(ServletHandler.java:512)
	at org.spark_project.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
	at org.spark_project.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.spark_project.jetty.server.handler.gzip.GzipHandler.handle(GzipHandler.java:493)
	at org.spark_project.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:213)
	at org.spark_project.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
	at org.spark_project.jetty.server.Server.handle(Server.java:534)
	at org.spark_project.jetty.server.HttpChannel.handle(HttpChannel.java:320)
	at org.spark_project.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
	at org.spark_project.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
	at org.spark_project.jetty.io.FillInterest.fillable(FillInterest.java:108)
	at org.spark_project.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
	at org.spark_project.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
	at org.spark_project.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
	at java.lang.Thread.run(Thread.java:745)
2021-12-06 14:56:28,997 [SparkUI-61] INFO [org.spark_project.jetty.servlet.DefaultServlet] - content=ResourceHttpContent@78ffae67{r=jar:file:/C:/Users/ACER/.m2/repository/org/apache/spark/spark-core_2.11/2.3.0/spark-core_2.11-2.3.0.jar!/org/apache/spark/ui/static/vis.min.js,gz=false}
2021-12-06 14:56:28,997 [SparkUI-56] WARN [org.spark_project.jetty.server.HttpChannel] - //qb:4040/static/sorttable.js
java.lang.NoSuchMethodError: javax.servlet.http.HttpServletRequest.isAsyncStarted()Z
	at org.spark_project.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:688)
	at org.spark_project.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
	at org.spark_project.jetty.servlet.ServletHandler.doScope(ServletHandler.java:512)
	at org.spark_project.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
	at org.spark_project.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.spark_project.jetty.server.handler.gzip.GzipHandler.handle(GzipHandler.java:493)
	at org.spark_project.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:213)
	at org.spark_project.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
	at org.spark_project.jetty.server.Server.handle(Server.java:534)
	at org.spark_project.jetty.server.HttpChannel.handle(HttpChannel.java:320)
	at org.spark_project.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
	at org.spark_project.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
	at org.spark_project.jetty.io.FillInterest.fillable(FillInterest.java:108)
	at org.spark_project.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
	at org.spark_project.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
	at org.spark_project.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
	at java.lang.Thread.run(Thread.java:745)
2021-12-06 14:56:28,997 [SparkUI-61] WARN [org.spark_project.jetty.servlet.ServletHandler] - Error for /static/vis.min.js
java.lang.NoSuchMethodError: javax.servlet.http.HttpServletRequest.isAsyncSupported()Z
	at org.spark_project.jetty.servlet.DefaultServlet.sendData(DefaultServlet.java:909)
	at org.spark_project.jetty.servlet.DefaultServlet.doGet(DefaultServlet.java:526)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:707)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:820)
	at org.spark_project.jetty.servlet.ServletHolder.handle(ServletHolder.java:848)
	at org.spark_project.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:584)
	at org.spark_project.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
	at org.spark_project.jetty.servlet.ServletHandler.doScope(ServletHandler.java:512)
	at org.spark_project.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
	at org.spark_project.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.spark_project.jetty.server.handler.gzip.GzipHandler.handle(GzipHandler.java:493)
	at org.spark_project.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:213)
	at org.spark_project.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
	at org.spark_project.jetty.server.Server.handle(Server.java:534)
	at org.spark_project.jetty.server.HttpChannel.handle(HttpChannel.java:320)
	at org.spark_project.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
	at org.spark_project.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
	at org.spark_project.jetty.io.FillInterest.fillable(FillInterest.java:108)
	at org.spark_project.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
	at org.spark_project.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
	at org.spark_project.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
	at java.lang.Thread.run(Thread.java:745)
2021-12-06 14:56:28,997 [SparkUI-55] WARN [org.spark_project.jetty.server.HttpChannel] - //qb:4040/static/jquery-1.11.1.min.js
java.lang.NoSuchMethodError: javax.servlet.http.HttpServletRequest.isAsyncStarted()Z
	at org.spark_project.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:688)
	at org.spark_project.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
	at org.spark_project.jetty.servlet.ServletHandler.doScope(ServletHandler.java:512)
	at org.spark_project.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
	at org.spark_project.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.spark_project.jetty.server.handler.gzip.GzipHandler.handle(GzipHandler.java:493)
	at org.spark_project.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:213)
	at org.spark_project.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
	at org.spark_project.jetty.server.Server.handle(Server.java:534)
	at org.spark_project.jetty.server.HttpChannel.handle(HttpChannel.java:320)
	at org.spark_project.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
	at org.spark_project.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
	at org.spark_project.jetty.io.FillInterest.fillable(FillInterest.java:108)
	at org.spark_project.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
	at org.spark_project.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
	at org.spark_project.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
	at java.lang.Thread.run(Thread.java:745)
2021-12-06 14:56:28,998 [SparkUI-61] WARN [org.spark_project.jetty.server.HttpChannel] - //qb:4040/static/vis.min.js
java.lang.NoSuchMethodError: javax.servlet.http.HttpServletRequest.isAsyncStarted()Z
	at org.spark_project.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:688)
	at org.spark_project.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
	at org.spark_project.jetty.servlet.ServletHandler.doScope(ServletHandler.java:512)
	at org.spark_project.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
	at org.spark_project.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.spark_project.jetty.server.handler.gzip.GzipHandler.handle(GzipHandler.java:493)
	at org.spark_project.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:213)
	at org.spark_project.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
	at org.spark_project.jetty.server.Server.handle(Server.java:534)
	at org.spark_project.jetty.server.HttpChannel.handle(HttpChannel.java:320)
	at org.spark_project.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
	at org.spark_project.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
	at org.spark_project.jetty.io.FillInterest.fillable(FillInterest.java:108)
	at org.spark_project.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
	at org.spark_project.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
	at org.spark_project.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
	at java.lang.Thread.run(Thread.java:745)
2021-12-06 14:56:28,998 [SparkUI-41] INFO [org.spark_project.jetty.servlet.DefaultServlet] - content=ResourceHttpContent@5efd9e4c{r=jar:file:/C:/Users/ACER/.m2/repository/org/apache/spark/spark-core_2.11/2.3.0/spark-core_2.11-2.3.0.jar!/org/apache/spark/ui/static/bootstrap-tooltip.js,gz=false}
2021-12-06 14:56:28,998 [SparkUI-41] WARN [org.spark_project.jetty.servlet.ServletHandler] - Error for /static/bootstrap-tooltip.js
java.lang.NoSuchMethodError: javax.servlet.http.HttpServletRequest.isAsyncSupported()Z
	at org.spark_project.jetty.servlet.DefaultServlet.sendData(DefaultServlet.java:909)
	at org.spark_project.jetty.servlet.DefaultServlet.doGet(DefaultServlet.java:526)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:707)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:820)
	at org.spark_project.jetty.servlet.ServletHolder.handle(ServletHolder.java:848)
	at org.spark_project.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:584)
	at org.spark_project.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
	at org.spark_project.jetty.servlet.ServletHandler.doScope(ServletHandler.java:512)
	at org.spark_project.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
	at org.spark_project.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.spark_project.jetty.server.handler.gzip.GzipHandler.handle(GzipHandler.java:493)
	at org.spark_project.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:213)
	at org.spark_project.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
	at org.spark_project.jetty.server.Server.handle(Server.java:534)
	at org.spark_project.jetty.server.HttpChannel.handle(HttpChannel.java:320)
	at org.spark_project.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
	at org.spark_project.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
	at org.spark_project.jetty.io.FillInterest.fillable(FillInterest.java:108)
	at org.spark_project.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
	at org.spark_project.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
	at org.spark_project.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
	at java.lang.Thread.run(Thread.java:745)
2021-12-06 14:56:28,998 [SparkUI-41] WARN [org.spark_project.jetty.server.HttpChannel] - //qb:4040/static/bootstrap-tooltip.js
java.lang.NoSuchMethodError: javax.servlet.http.HttpServletRequest.isAsyncStarted()Z
	at org.spark_project.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:688)
	at org.spark_project.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
	at org.spark_project.jetty.servlet.ServletHandler.doScope(ServletHandler.java:512)
	at org.spark_project.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
	at org.spark_project.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.spark_project.jetty.server.handler.gzip.GzipHandler.handle(GzipHandler.java:493)
	at org.spark_project.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:213)
	at org.spark_project.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
	at org.spark_project.jetty.server.Server.handle(Server.java:534)
	at org.spark_project.jetty.server.HttpChannel.handle(HttpChannel.java:320)
	at org.spark_project.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
	at org.spark_project.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
	at org.spark_project.jetty.io.FillInterest.fillable(FillInterest.java:108)
	at org.spark_project.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
	at org.spark_project.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
	at org.spark_project.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
	at java.lang.Thread.run(Thread.java:745)
2021-12-06 14:56:28,999 [SparkUI-67] INFO [org.spark_project.jetty.servlet.DefaultServlet] - content=ResourceHttpContent@63ffafec{r=jar:file:/C:/Users/ACER/.m2/repository/org/apache/spark/spark-core_2.11/2.3.0/spark-core_2.11-2.3.0.jar!/org/apache/spark/ui/static/table.js,gz=false}
2021-12-06 14:56:28,999 [SparkUI-67] WARN [org.spark_project.jetty.servlet.ServletHandler] - Error for /static/table.js
java.lang.NoSuchMethodError: javax.servlet.http.HttpServletRequest.isAsyncSupported()Z
	at org.spark_project.jetty.servlet.DefaultServlet.sendData(DefaultServlet.java:909)
	at org.spark_project.jetty.servlet.DefaultServlet.doGet(DefaultServlet.java:526)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:707)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:820)
	at org.spark_project.jetty.servlet.ServletHolder.handle(ServletHolder.java:848)
	at org.spark_project.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:584)
	at org.spark_project.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
	at org.spark_project.jetty.servlet.ServletHandler.doScope(ServletHandler.java:512)
	at org.spark_project.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
	at org.spark_project.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.spark_project.jetty.server.handler.gzip.GzipHandler.handle(GzipHandler.java:493)
	at org.spark_project.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:213)
	at org.spark_project.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
	at org.spark_project.jetty.server.Server.handle(Server.java:534)
	at org.spark_project.jetty.server.HttpChannel.handle(HttpChannel.java:320)
	at org.spark_project.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
	at org.spark_project.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
	at org.spark_project.jetty.io.FillInterest.fillable(FillInterest.java:108)
	at org.spark_project.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
	at org.spark_project.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
	at org.spark_project.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
	at java.lang.Thread.run(Thread.java:745)
2021-12-06 14:56:28,999 [SparkUI-46] INFO [org.spark_project.jetty.servlet.DefaultServlet] - content=ResourceHttpContent@7089e344{r=jar:file:/C:/Users/ACER/.m2/repository/org/apache/spark/spark-core_2.11/2.3.0/spark-core_2.11-2.3.0.jar!/org/apache/spark/ui/static/initialize-tooltips.js,gz=false}
2021-12-06 14:56:28,999 [SparkUI-46] WARN [org.spark_project.jetty.servlet.ServletHandler] - Error for /static/initialize-tooltips.js
java.lang.NoSuchMethodError: javax.servlet.http.HttpServletRequest.isAsyncSupported()Z
	at org.spark_project.jetty.servlet.DefaultServlet.sendData(DefaultServlet.java:909)
	at org.spark_project.jetty.servlet.DefaultServlet.doGet(DefaultServlet.java:526)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:707)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:820)
	at org.spark_project.jetty.servlet.ServletHolder.handle(ServletHolder.java:848)
	at org.spark_project.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:584)
	at org.spark_project.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
	at org.spark_project.jetty.servlet.ServletHandler.doScope(ServletHandler.java:512)
	at org.spark_project.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
	at org.spark_project.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.spark_project.jetty.server.handler.gzip.GzipHandler.handle(GzipHandler.java:493)
	at org.spark_project.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:213)
	at org.spark_project.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
	at org.spark_project.jetty.server.Server.handle(Server.java:534)
	at org.spark_project.jetty.server.HttpChannel.handle(HttpChannel.java:320)
	at org.spark_project.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
	at org.spark_project.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
	at org.spark_project.jetty.io.FillInterest.fillable(FillInterest.java:108)
	at org.spark_project.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
	at org.spark_project.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
	at org.spark_project.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
	at java.lang.Thread.run(Thread.java:745)
2021-12-06 14:56:29,000 [SparkUI-46] WARN [org.spark_project.jetty.server.HttpChannel] - //qb:4040/static/initialize-tooltips.js
java.lang.NoSuchMethodError: javax.servlet.http.HttpServletRequest.isAsyncStarted()Z
	at org.spark_project.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:688)
	at org.spark_project.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
	at org.spark_project.jetty.servlet.ServletHandler.doScope(ServletHandler.java:512)
	at org.spark_project.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
	at org.spark_project.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.spark_project.jetty.server.handler.gzip.GzipHandler.handle(GzipHandler.java:493)
	at org.spark_project.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:213)
	at org.spark_project.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
	at org.spark_project.jetty.server.Server.handle(Server.java:534)
	at org.spark_project.jetty.server.HttpChannel.handle(HttpChannel.java:320)
	at org.spark_project.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
	at org.spark_project.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
	at org.spark_project.jetty.io.FillInterest.fillable(FillInterest.java:108)
	at org.spark_project.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
	at org.spark_project.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
	at org.spark_project.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
	at java.lang.Thread.run(Thread.java:745)
2021-12-06 14:56:29,002 [SparkUI-67] WARN [org.spark_project.jetty.server.HttpChannel] - //qb:4040/static/table.js
java.lang.NoSuchMethodError: javax.servlet.http.HttpServletRequest.isAsyncStarted()Z
	at org.spark_project.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:688)
	at org.spark_project.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
	at org.spark_project.jetty.servlet.ServletHandler.doScope(ServletHandler.java:512)
	at org.spark_project.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
	at org.spark_project.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.spark_project.jetty.server.handler.gzip.GzipHandler.handle(GzipHandler.java:493)
	at org.spark_project.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:213)
	at org.spark_project.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
	at org.spark_project.jetty.server.Server.handle(Server.java:534)
	at org.spark_project.jetty.server.HttpChannel.handle(HttpChannel.java:320)
	at org.spark_project.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
	at org.spark_project.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
	at org.spark_project.jetty.io.FillInterest.fillable(FillInterest.java:108)
	at org.spark_project.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
	at org.spark_project.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
	at org.spark_project.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
	at java.lang.Thread.run(Thread.java:745)
2021-12-06 14:56:29,006 [SparkUI-56] INFO [org.spark_project.jetty.servlet.DefaultServlet] - content=ResourceHttpContent@5bb3ed67{r=jar:file:/C:/Users/ACER/.m2/repository/org/apache/spark/spark-core_2.11/2.3.0/spark-core_2.11-2.3.0.jar!/org/apache/spark/ui/static/additional-metrics.js,gz=false}
2021-12-06 14:56:29,006 [SparkUI-46] INFO [org.spark_project.jetty.servlet.DefaultServlet] - content=ResourceHttpContent@7f0ac253{r=jar:file:/C:/Users/ACER/.m2/repository/org/apache/spark/spark-core_2.11/2.3.0/spark-core_2.11-2.3.0.jar!/org/apache/spark/ui/static/timeline-view.js,gz=false}
2021-12-06 14:56:29,006 [SparkUI-66] INFO [org.spark_project.jetty.servlet.DefaultServlet] - content=ResourceHttpContent@702d9a8b{r=jar:file:/C:/Users/ACER/.m2/repository/org/apache/spark/spark-core_2.11/2.3.0/spark-core_2.11-2.3.0.jar!/org/apache/spark/ui/static/log-view.js,gz=false}
2021-12-06 14:56:29,006 [SparkUI-46] WARN [org.spark_project.jetty.servlet.ServletHandler] - Error for /static/timeline-view.js
java.lang.NoSuchMethodError: javax.servlet.http.HttpServletRequest.isAsyncSupported()Z
	at org.spark_project.jetty.servlet.DefaultServlet.sendData(DefaultServlet.java:909)
	at org.spark_project.jetty.servlet.DefaultServlet.doGet(DefaultServlet.java:526)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:707)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:820)
	at org.spark_project.jetty.servlet.ServletHolder.handle(ServletHolder.java:848)
	at org.spark_project.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:584)
	at org.spark_project.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
	at org.spark_project.jetty.servlet.ServletHandler.doScope(ServletHandler.java:512)
	at org.spark_project.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
	at org.spark_project.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.spark_project.jetty.server.handler.gzip.GzipHandler.handle(GzipHandler.java:493)
	at org.spark_project.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:213)
	at org.spark_project.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
	at org.spark_project.jetty.server.Server.handle(Server.java:534)
	at org.spark_project.jetty.server.HttpChannel.handle(HttpChannel.java:320)
	at org.spark_project.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
	at org.spark_project.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
	at org.spark_project.jetty.io.FillInterest.fillable(FillInterest.java:108)
	at org.spark_project.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
	at org.spark_project.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
	at org.spark_project.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
	at java.lang.Thread.run(Thread.java:745)
2021-12-06 14:56:29,006 [SparkUI-65] INFO [org.spark_project.jetty.servlet.DefaultServlet] - content=ResourceHttpContent@245271e7{r=jar:file:/C:/Users/ACER/.m2/repository/org/apache/spark/spark-core_2.11/2.3.0/spark-core_2.11-2.3.0.jar!/org/apache/spark/ui/static/webui.js,gz=false}
2021-12-06 14:56:29,006 [SparkUI-66] WARN [org.spark_project.jetty.servlet.ServletHandler] - Error for /static/log-view.js
java.lang.NoSuchMethodError: javax.servlet.http.HttpServletRequest.isAsyncSupported()Z
	at org.spark_project.jetty.servlet.DefaultServlet.sendData(DefaultServlet.java:909)
	at org.spark_project.jetty.servlet.DefaultServlet.doGet(DefaultServlet.java:526)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:707)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:820)
	at org.spark_project.jetty.servlet.ServletHolder.handle(ServletHolder.java:848)
	at org.spark_project.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:584)
	at org.spark_project.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
	at org.spark_project.jetty.servlet.ServletHandler.doScope(ServletHandler.java:512)
	at org.spark_project.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
	at org.spark_project.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.spark_project.jetty.server.handler.gzip.GzipHandler.handle(GzipHandler.java:493)
	at org.spark_project.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:213)
	at org.spark_project.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
	at org.spark_project.jetty.server.Server.handle(Server.java:534)
	at org.spark_project.jetty.server.HttpChannel.handle(HttpChannel.java:320)
	at org.spark_project.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
	at org.spark_project.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
	at org.spark_project.jetty.io.FillInterest.fillable(FillInterest.java:108)
	at org.spark_project.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
	at org.spark_project.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
	at org.spark_project.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
	at java.lang.Thread.run(Thread.java:745)
2021-12-06 14:56:29,006 [SparkUI-56] WARN [org.spark_project.jetty.servlet.ServletHandler] - Error for /static/additional-metrics.js
java.lang.NoSuchMethodError: javax.servlet.http.HttpServletRequest.isAsyncSupported()Z
	at org.spark_project.jetty.servlet.DefaultServlet.sendData(DefaultServlet.java:909)
	at org.spark_project.jetty.servlet.DefaultServlet.doGet(DefaultServlet.java:526)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:707)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:820)
	at org.spark_project.jetty.servlet.ServletHolder.handle(ServletHolder.java:848)
	at org.spark_project.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:584)
	at org.spark_project.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
	at org.spark_project.jetty.servlet.ServletHandler.doScope(ServletHandler.java:512)
	at org.spark_project.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
	at org.spark_project.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.spark_project.jetty.server.handler.gzip.GzipHandler.handle(GzipHandler.java:493)
	at org.spark_project.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:213)
	at org.spark_project.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
	at org.spark_project.jetty.server.Server.handle(Server.java:534)
	at org.spark_project.jetty.server.HttpChannel.handle(HttpChannel.java:320)
	at org.spark_project.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
	at org.spark_project.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
	at org.spark_project.jetty.io.FillInterest.fillable(FillInterest.java:108)
	at org.spark_project.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
	at org.spark_project.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
	at org.spark_project.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
	at java.lang.Thread.run(Thread.java:745)
2021-12-06 14:56:29,006 [SparkUI-46] WARN [org.spark_project.jetty.server.HttpChannel] - //qb:4040/static/timeline-view.js
java.lang.NoSuchMethodError: javax.servlet.http.HttpServletRequest.isAsyncStarted()Z
	at org.spark_project.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:688)
	at org.spark_project.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
	at org.spark_project.jetty.servlet.ServletHandler.doScope(ServletHandler.java:512)
	at org.spark_project.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
	at org.spark_project.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.spark_project.jetty.server.handler.gzip.GzipHandler.handle(GzipHandler.java:493)
	at org.spark_project.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:213)
	at org.spark_project.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
	at org.spark_project.jetty.server.Server.handle(Server.java:534)
	at org.spark_project.jetty.server.HttpChannel.handle(HttpChannel.java:320)
	at org.spark_project.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
	at org.spark_project.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
	at org.spark_project.jetty.io.FillInterest.fillable(FillInterest.java:108)
	at org.spark_project.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
	at org.spark_project.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
	at org.spark_project.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
	at java.lang.Thread.run(Thread.java:745)
2021-12-06 14:56:29,006 [SparkUI-65] WARN [org.spark_project.jetty.servlet.ServletHandler] - Error for /static/webui.js
java.lang.NoSuchMethodError: javax.servlet.http.HttpServletRequest.isAsyncSupported()Z
	at org.spark_project.jetty.servlet.DefaultServlet.sendData(DefaultServlet.java:909)
	at org.spark_project.jetty.servlet.DefaultServlet.doGet(DefaultServlet.java:526)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:707)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:820)
	at org.spark_project.jetty.servlet.ServletHolder.handle(ServletHolder.java:848)
	at org.spark_project.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:584)
	at org.spark_project.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
	at org.spark_project.jetty.servlet.ServletHandler.doScope(ServletHandler.java:512)
	at org.spark_project.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
	at org.spark_project.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.spark_project.jetty.server.handler.gzip.GzipHandler.handle(GzipHandler.java:493)
	at org.spark_project.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:213)
	at org.spark_project.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
	at org.spark_project.jetty.server.Server.handle(Server.java:534)
	at org.spark_project.jetty.server.HttpChannel.handle(HttpChannel.java:320)
	at org.spark_project.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
	at org.spark_project.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
	at org.spark_project.jetty.io.FillInterest.fillable(FillInterest.java:108)
	at org.spark_project.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
	at org.spark_project.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
	at org.spark_project.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
	at java.lang.Thread.run(Thread.java:745)
2021-12-06 14:56:29,007 [SparkUI-66] WARN [org.spark_project.jetty.server.HttpChannel] - //qb:4040/static/log-view.js
java.lang.NoSuchMethodError: javax.servlet.http.HttpServletRequest.isAsyncStarted()Z
	at org.spark_project.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:688)
	at org.spark_project.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
	at org.spark_project.jetty.servlet.ServletHandler.doScope(ServletHandler.java:512)
	at org.spark_project.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
	at org.spark_project.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.spark_project.jetty.server.handler.gzip.GzipHandler.handle(GzipHandler.java:493)
	at org.spark_project.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:213)
	at org.spark_project.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
	at org.spark_project.jetty.server.Server.handle(Server.java:534)
	at org.spark_project.jetty.server.HttpChannel.handle(HttpChannel.java:320)
	at org.spark_project.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
	at org.spark_project.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
	at org.spark_project.jetty.io.FillInterest.fillable(FillInterest.java:108)
	at org.spark_project.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
	at org.spark_project.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
	at org.spark_project.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
	at java.lang.Thread.run(Thread.java:745)
2021-12-06 14:56:29,007 [SparkUI-56] WARN [org.spark_project.jetty.server.HttpChannel] - //qb:4040/static/additional-metrics.js
java.lang.NoSuchMethodError: javax.servlet.http.HttpServletRequest.isAsyncStarted()Z
	at org.spark_project.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:688)
	at org.spark_project.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
	at org.spark_project.jetty.servlet.ServletHandler.doScope(ServletHandler.java:512)
	at org.spark_project.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
	at org.spark_project.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.spark_project.jetty.server.handler.gzip.GzipHandler.handle(GzipHandler.java:493)
	at org.spark_project.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:213)
	at org.spark_project.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
	at org.spark_project.jetty.server.Server.handle(Server.java:534)
	at org.spark_project.jetty.server.HttpChannel.handle(HttpChannel.java:320)
	at org.spark_project.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
	at org.spark_project.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
	at org.spark_project.jetty.io.FillInterest.fillable(FillInterest.java:108)
	at org.spark_project.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
	at org.spark_project.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
	at org.spark_project.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
	at java.lang.Thread.run(Thread.java:745)
2021-12-06 14:56:29,007 [SparkUI-65] WARN [org.spark_project.jetty.server.HttpChannel] - //qb:4040/static/webui.js
java.lang.NoSuchMethodError: javax.servlet.http.HttpServletRequest.isAsyncStarted()Z
	at org.spark_project.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:688)
	at org.spark_project.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
	at org.spark_project.jetty.servlet.ServletHandler.doScope(ServletHandler.java:512)
	at org.spark_project.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
	at org.spark_project.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.spark_project.jetty.server.handler.gzip.GzipHandler.handle(GzipHandler.java:493)
	at org.spark_project.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:213)
	at org.spark_project.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
	at org.spark_project.jetty.server.Server.handle(Server.java:534)
	at org.spark_project.jetty.server.HttpChannel.handle(HttpChannel.java:320)
	at org.spark_project.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
	at org.spark_project.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
	at org.spark_project.jetty.io.FillInterest.fillable(FillInterest.java:108)
	at org.spark_project.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
	at org.spark_project.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
	at org.spark_project.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
	at java.lang.Thread.run(Thread.java:745)
2021-12-06 14:56:29,012 [SparkUI-61] INFO [org.spark_project.jetty.servlet.DefaultServlet] - content=ResourceHttpContent@1dfe4e9c{r=jar:file:/C:/Users/ACER/.m2/repository/org/apache/spark/spark-core_2.11/2.3.0/spark-core_2.11-2.3.0.jar!/org/apache/spark/ui/static/spark-logo-77x50px-hd.png,gz=false}
2021-12-06 14:56:29,013 [SparkUI-61] WARN [org.spark_project.jetty.servlet.ServletHandler] - Error for /static/spark-logo-77x50px-hd.png
java.lang.NoSuchMethodError: javax.servlet.http.HttpServletRequest.isAsyncSupported()Z
	at org.spark_project.jetty.servlet.DefaultServlet.sendData(DefaultServlet.java:909)
	at org.spark_project.jetty.servlet.DefaultServlet.doGet(DefaultServlet.java:526)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:707)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:820)
	at org.spark_project.jetty.servlet.ServletHolder.handle(ServletHolder.java:848)
	at org.spark_project.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:584)
	at org.spark_project.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
	at org.spark_project.jetty.servlet.ServletHandler.doScope(ServletHandler.java:512)
	at org.spark_project.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
	at org.spark_project.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.spark_project.jetty.server.handler.gzip.GzipHandler.handle(GzipHandler.java:448)
	at org.spark_project.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:213)
	at org.spark_project.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
	at org.spark_project.jetty.server.Server.handle(Server.java:534)
	at org.spark_project.jetty.server.HttpChannel.handle(HttpChannel.java:320)
	at org.spark_project.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
	at org.spark_project.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
	at org.spark_project.jetty.io.FillInterest.fillable(FillInterest.java:108)
	at org.spark_project.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
	at org.spark_project.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
	at org.spark_project.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
	at java.lang.Thread.run(Thread.java:745)
2021-12-06 14:56:29,013 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_3 stored as values in memory (estimated size 4.9 KB, free 1990.1 MB)
2021-12-06 14:56:29,013 [SparkUI-61] WARN [org.spark_project.jetty.server.HttpChannel] - //qb:4040/static/spark-logo-77x50px-hd.png
java.lang.NoSuchMethodError: javax.servlet.http.HttpServletRequest.isAsyncStarted()Z
	at org.spark_project.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:688)
	at org.spark_project.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
	at org.spark_project.jetty.servlet.ServletHandler.doScope(ServletHandler.java:512)
	at org.spark_project.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
	at org.spark_project.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.spark_project.jetty.server.handler.gzip.GzipHandler.handle(GzipHandler.java:448)
	at org.spark_project.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:213)
	at org.spark_project.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
	at org.spark_project.jetty.server.Server.handle(Server.java:534)
	at org.spark_project.jetty.server.HttpChannel.handle(HttpChannel.java:320)
	at org.spark_project.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
	at org.spark_project.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
	at org.spark_project.jetty.io.FillInterest.fillable(FillInterest.java:108)
	at org.spark_project.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
	at org.spark_project.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
	at org.spark_project.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
	at java.lang.Thread.run(Thread.java:745)
2021-12-06 14:56:29,019 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_3_piece0 stored as bytes in memory (estimated size 2.8 KB, free 1990.1 MB)
2021-12-06 14:56:29,019 [dispatcher-event-loop-8] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_3_piece0 in memory on qb:60443 (size: 2.8 KB, free: 1990.7 MB)
2021-12-06 14:56:29,020 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 3 from broadcast at DAGScheduler.scala:1039
2021-12-06 14:56:29,022 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from ShuffleMapStage 1 (MapPartitionsRDD[6] at distinct at PaidPromotionAdjustParameter.scala:252) (first 15 tasks are for partitions Vector(0, 1))
2021-12-06 14:56:29,023 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 1.0 with 2 tasks
2021-12-06 14:56:29,024 [dispatcher-event-loop-9] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 1.0 (TID 2, localhost, executor driver, partition 0, ANY, 7921 bytes)
2021-12-06 14:56:29,025 [dispatcher-event-loop-9] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 1.0 (TID 3, localhost, executor driver, partition 1, ANY, 7921 bytes)
2021-12-06 14:56:29,025 [Executor task launch worker for task 3] INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 1.0 (TID 3)
2021-12-06 14:56:29,025 [Executor task launch worker for task 2] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 1.0 (TID 2)
2021-12-06 14:56:29,031 [Executor task launch worker for task 3] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/handle_data/set-train-device-production-data/part-00000:3235948+3235949
2021-12-06 14:56:29,031 [Executor task launch worker for task 2] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/handle_data/set-train-device-production-data/part-00000:0+3235948
2021-12-06 14:56:29,320 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 14
2021-12-06 14:56:29,320 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 7
2021-12-06 14:56:29,320 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 22
2021-12-06 14:56:29,320 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 13
2021-12-06 14:56:29,320 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 20
2021-12-06 14:56:29,320 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 5
2021-12-06 14:56:29,320 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 19
2021-12-06 14:56:29,320 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 2
2021-12-06 14:56:29,320 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 10
2021-12-06 14:56:29,320 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 18
2021-12-06 14:56:29,320 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 24
2021-12-06 14:56:29,320 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 6
2021-12-06 14:56:29,320 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 8
2021-12-06 14:56:29,320 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 17
2021-12-06 14:56:29,320 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 16
2021-12-06 14:56:29,320 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 12
2021-12-06 14:56:29,320 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 0
2021-12-06 14:56:29,321 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 23
2021-12-06 14:56:29,321 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 3
2021-12-06 14:56:29,321 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 21
2021-12-06 14:56:29,321 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 11
2021-12-06 14:56:29,321 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 15
2021-12-06 14:56:29,342 [dispatcher-event-loop-2] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_2_piece0 on qb:60443 in memory (size: 1994.0 B, free: 1990.7 MB)
2021-12-06 14:56:29,345 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 4
2021-12-06 14:56:29,345 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1
2021-12-06 14:56:29,345 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 9
2021-12-06 14:56:29,510 [Executor task launch worker for task 2] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 1.0 (TID 2). 1083 bytes result sent to driver
2021-12-06 14:56:29,527 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 1.0 (TID 2) in 504 ms on localhost (executor driver) (1/2)
2021-12-06 14:56:31,399 [Executor task launch worker for task 3] INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 1.0 (TID 3). 1083 bytes result sent to driver
2021-12-06 14:56:31,402 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 1.0 (TID 3) in 2378 ms on localhost (executor driver) (2/2)
2021-12-06 14:56:31,402 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 1.0, whose tasks have all completed, from pool 
2021-12-06 14:56:31,403 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ShuffleMapStage 1 (distinct at PaidPromotionAdjustParameter.scala:252) finished in 2.406 s
2021-12-06 14:56:31,403 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - looking for newly runnable stages
2021-12-06 14:56:31,404 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - running: Set()
2021-12-06 14:56:31,404 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - waiting: Set(ResultStage 2)
2021-12-06 14:56:31,404 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - failed: Set()
2021-12-06 14:56:31,407 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 2 (MapPartitionsRDD[8] at distinct at PaidPromotionAdjustParameter.scala:252), which has no missing parents
2021-12-06 14:56:31,412 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_4 stored as values in memory (estimated size 3.7 KB, free 1990.1 MB)
2021-12-06 14:56:31,416 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_4_piece0 stored as bytes in memory (estimated size 2.2 KB, free 1990.1 MB)
2021-12-06 14:56:31,416 [dispatcher-event-loop-4] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_4_piece0 in memory on qb:60443 (size: 2.2 KB, free: 1990.7 MB)
2021-12-06 14:56:31,417 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 4 from broadcast at DAGScheduler.scala:1039
2021-12-06 14:56:31,417 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 9 missing tasks from ResultStage 2 (MapPartitionsRDD[8] at distinct at PaidPromotionAdjustParameter.scala:252) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8))
2021-12-06 14:56:31,417 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 2.0 with 9 tasks
2021-12-06 14:56:31,418 [dispatcher-event-loop-6] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 2.0 (TID 4, localhost, executor driver, partition 0, ANY, 7649 bytes)
2021-12-06 14:56:31,419 [dispatcher-event-loop-6] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 2.0 (TID 5, localhost, executor driver, partition 1, ANY, 7649 bytes)
2021-12-06 14:56:31,419 [dispatcher-event-loop-6] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 2.0 in stage 2.0 (TID 6, localhost, executor driver, partition 2, ANY, 7649 bytes)
2021-12-06 14:56:31,419 [dispatcher-event-loop-6] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 3.0 in stage 2.0 (TID 7, localhost, executor driver, partition 3, ANY, 7649 bytes)
2021-12-06 14:56:31,419 [dispatcher-event-loop-6] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 4.0 in stage 2.0 (TID 8, localhost, executor driver, partition 4, ANY, 7649 bytes)
2021-12-06 14:56:31,419 [dispatcher-event-loop-6] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 5.0 in stage 2.0 (TID 9, localhost, executor driver, partition 5, ANY, 7649 bytes)
2021-12-06 14:56:31,419 [dispatcher-event-loop-6] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 6.0 in stage 2.0 (TID 10, localhost, executor driver, partition 6, ANY, 7649 bytes)
2021-12-06 14:56:31,420 [dispatcher-event-loop-6] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 7.0 in stage 2.0 (TID 11, localhost, executor driver, partition 7, ANY, 7649 bytes)
2021-12-06 14:56:31,420 [dispatcher-event-loop-6] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 8.0 in stage 2.0 (TID 12, localhost, executor driver, partition 8, ANY, 7649 bytes)
2021-12-06 14:56:31,420 [Executor task launch worker for task 4] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 2.0 (TID 4)
2021-12-06 14:56:31,420 [Executor task launch worker for task 5] INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 2.0 (TID 5)
2021-12-06 14:56:31,420 [Executor task launch worker for task 6] INFO [org.apache.spark.executor.Executor] - Running task 2.0 in stage 2.0 (TID 6)
2021-12-06 14:56:31,421 [Executor task launch worker for task 8] INFO [org.apache.spark.executor.Executor] - Running task 4.0 in stage 2.0 (TID 8)
2021-12-06 14:56:31,421 [Executor task launch worker for task 7] INFO [org.apache.spark.executor.Executor] - Running task 3.0 in stage 2.0 (TID 7)
2021-12-06 14:56:31,421 [Executor task launch worker for task 9] INFO [org.apache.spark.executor.Executor] - Running task 5.0 in stage 2.0 (TID 9)
2021-12-06 14:56:31,421 [Executor task launch worker for task 10] INFO [org.apache.spark.executor.Executor] - Running task 6.0 in stage 2.0 (TID 10)
2021-12-06 14:56:31,422 [Executor task launch worker for task 11] INFO [org.apache.spark.executor.Executor] - Running task 7.0 in stage 2.0 (TID 11)
2021-12-06 14:56:31,422 [Executor task launch worker for task 12] INFO [org.apache.spark.executor.Executor] - Running task 8.0 in stage 2.0 (TID 12)
2021-12-06 14:56:31,437 [Executor task launch worker for task 9] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 2 non-empty blocks out of 2 blocks
2021-12-06 14:56:31,437 [Executor task launch worker for task 5] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 2 non-empty blocks out of 2 blocks
2021-12-06 14:56:31,437 [Executor task launch worker for task 6] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 2 non-empty blocks out of 2 blocks
2021-12-06 14:56:31,437 [Executor task launch worker for task 7] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 2 non-empty blocks out of 2 blocks
2021-12-06 14:56:31,437 [Executor task launch worker for task 12] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 2 non-empty blocks out of 2 blocks
2021-12-06 14:56:31,437 [Executor task launch worker for task 4] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 2 non-empty blocks out of 2 blocks
2021-12-06 14:56:31,437 [Executor task launch worker for task 10] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 2 non-empty blocks out of 2 blocks
2021-12-06 14:56:31,437 [Executor task launch worker for task 8] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 2 non-empty blocks out of 2 blocks
2021-12-06 14:56:31,437 [Executor task launch worker for task 11] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 2 non-empty blocks out of 2 blocks
2021-12-06 14:56:31,438 [Executor task launch worker for task 11] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 5 ms
2021-12-06 14:56:31,438 [Executor task launch worker for task 5] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 5 ms
2021-12-06 14:56:31,438 [Executor task launch worker for task 6] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 5 ms
2021-12-06 14:56:31,438 [Executor task launch worker for task 7] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 5 ms
2021-12-06 14:56:31,438 [Executor task launch worker for task 12] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 5 ms
2021-12-06 14:56:31,438 [Executor task launch worker for task 8] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 5 ms
2021-12-06 14:56:31,438 [Executor task launch worker for task 10] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 5 ms
2021-12-06 14:56:31,438 [Executor task launch worker for task 4] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 5 ms
2021-12-06 14:56:31,438 [Executor task launch worker for task 9] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 5 ms
2021-12-06 14:56:31,482 [Executor task launch worker for task 7] INFO [org.apache.spark.executor.Executor] - Finished task 3.0 in stage 2.0 (TID 7). 1053 bytes result sent to driver
2021-12-06 14:56:31,482 [Executor task launch worker for task 5] INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 2.0 (TID 5). 1010 bytes result sent to driver
2021-12-06 14:56:31,483 [Executor task launch worker for task 12] INFO [org.apache.spark.executor.Executor] - Finished task 8.0 in stage 2.0 (TID 12). 1010 bytes result sent to driver
2021-12-06 14:56:31,483 [Executor task launch worker for task 8] INFO [org.apache.spark.executor.Executor] - Finished task 4.0 in stage 2.0 (TID 8). 1010 bytes result sent to driver
2021-12-06 14:56:31,483 [Executor task launch worker for task 4] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 2.0 (TID 4). 1010 bytes result sent to driver
2021-12-06 14:56:31,483 [Executor task launch worker for task 9] INFO [org.apache.spark.executor.Executor] - Finished task 5.0 in stage 2.0 (TID 9). 1010 bytes result sent to driver
2021-12-06 14:56:31,483 [Executor task launch worker for task 6] INFO [org.apache.spark.executor.Executor] - Finished task 2.0 in stage 2.0 (TID 6). 1010 bytes result sent to driver
2021-12-06 14:56:31,483 [Executor task launch worker for task 10] INFO [org.apache.spark.executor.Executor] - Finished task 6.0 in stage 2.0 (TID 10). 1010 bytes result sent to driver
2021-12-06 14:56:31,484 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 3.0 in stage 2.0 (TID 7) in 65 ms on localhost (executor driver) (1/9)
2021-12-06 14:56:31,484 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 2.0 (TID 5) in 66 ms on localhost (executor driver) (2/9)
2021-12-06 14:56:31,484 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 8.0 in stage 2.0 (TID 12) in 64 ms on localhost (executor driver) (3/9)
2021-12-06 14:56:31,484 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 4.0 in stage 2.0 (TID 8) in 65 ms on localhost (executor driver) (4/9)
2021-12-06 14:56:31,484 [Executor task launch worker for task 11] INFO [org.apache.spark.executor.Executor] - Finished task 7.0 in stage 2.0 (TID 11). 1053 bytes result sent to driver
2021-12-06 14:56:31,484 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 2.0 (TID 4) in 66 ms on localhost (executor driver) (5/9)
2021-12-06 14:56:31,485 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 5.0 in stage 2.0 (TID 9) in 66 ms on localhost (executor driver) (6/9)
2021-12-06 14:56:31,485 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 6.0 in stage 2.0 (TID 10) in 66 ms on localhost (executor driver) (7/9)
2021-12-06 14:56:31,485 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 2.0 in stage 2.0 (TID 6) in 66 ms on localhost (executor driver) (8/9)
2021-12-06 14:56:31,485 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 7.0 in stage 2.0 (TID 11) in 66 ms on localhost (executor driver) (9/9)
2021-12-06 14:56:31,485 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 2.0, whose tasks have all completed, from pool 
2021-12-06 14:56:31,487 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 2 (zipWithIndex at PaidPromotionAdjustParameter.scala:253) finished in 0.077 s
2021-12-06 14:56:31,487 [main] INFO [org.apache.spark.scheduler.DAGScheduler] - Job 1 finished: zipWithIndex at PaidPromotionAdjustParameter.scala:253, took 2.518377 s
2021-12-06 14:56:31,944 [main] INFO [org.apache.spark.SparkContext] - Starting job: take at PaidPromotionAdjustParameter.scala:259
2021-12-06 14:56:31,944 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 10 (map at PaidPromotionAdjustParameter.scala:256)
2021-12-06 14:56:31,944 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 2 (take at PaidPromotionAdjustParameter.scala:259) with 1 output partitions
2021-12-06 14:56:31,944 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 5 (take at PaidPromotionAdjustParameter.scala:259)
2021-12-06 14:56:31,944 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 4)
2021-12-06 14:56:31,945 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List(ShuffleMapStage 4)
2021-12-06 14:56:31,945 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ShuffleMapStage 4 (MapPartitionsRDD[10] at map at PaidPromotionAdjustParameter.scala:256), which has no missing parents
2021-12-06 14:56:31,948 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_5 stored as values in memory (estimated size 4.0 KB, free 1990.1 MB)
2021-12-06 14:56:31,951 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_5_piece0 stored as bytes in memory (estimated size 2.3 KB, free 1990.1 MB)
2021-12-06 14:56:31,952 [dispatcher-event-loop-2] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_5_piece0 in memory on qb:60443 (size: 2.3 KB, free: 1990.7 MB)
2021-12-06 14:56:31,952 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 5 from broadcast at DAGScheduler.scala:1039
2021-12-06 14:56:31,952 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 10 missing tasks from ShuffleMapStage 4 (MapPartitionsRDD[10] at map at PaidPromotionAdjustParameter.scala:256) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
2021-12-06 14:56:31,952 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 4.0 with 10 tasks
2021-12-06 14:56:31,954 [dispatcher-event-loop-6] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 4.0 (TID 13, localhost, executor driver, partition 0, ANY, 7748 bytes)
2021-12-06 14:56:31,954 [dispatcher-event-loop-6] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 4.0 (TID 14, localhost, executor driver, partition 1, ANY, 7748 bytes)
2021-12-06 14:56:31,954 [dispatcher-event-loop-6] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 2.0 in stage 4.0 (TID 15, localhost, executor driver, partition 2, ANY, 7748 bytes)
2021-12-06 14:56:31,954 [dispatcher-event-loop-6] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 3.0 in stage 4.0 (TID 16, localhost, executor driver, partition 3, ANY, 7748 bytes)
2021-12-06 14:56:31,954 [dispatcher-event-loop-6] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 4.0 in stage 4.0 (TID 17, localhost, executor driver, partition 4, ANY, 7748 bytes)
2021-12-06 14:56:31,954 [dispatcher-event-loop-6] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 5.0 in stage 4.0 (TID 18, localhost, executor driver, partition 5, ANY, 7748 bytes)
2021-12-06 14:56:31,955 [dispatcher-event-loop-6] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 6.0 in stage 4.0 (TID 19, localhost, executor driver, partition 6, ANY, 7748 bytes)
2021-12-06 14:56:31,955 [dispatcher-event-loop-6] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 7.0 in stage 4.0 (TID 20, localhost, executor driver, partition 7, ANY, 7748 bytes)
2021-12-06 14:56:31,955 [dispatcher-event-loop-6] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 8.0 in stage 4.0 (TID 21, localhost, executor driver, partition 8, ANY, 7748 bytes)
2021-12-06 14:56:31,955 [dispatcher-event-loop-6] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 9.0 in stage 4.0 (TID 22, localhost, executor driver, partition 9, ANY, 7748 bytes)
2021-12-06 14:56:31,955 [Executor task launch worker for task 13] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 4.0 (TID 13)
2021-12-06 14:56:31,955 [Executor task launch worker for task 17] INFO [org.apache.spark.executor.Executor] - Running task 4.0 in stage 4.0 (TID 17)
2021-12-06 14:56:31,955 [Executor task launch worker for task 21] INFO [org.apache.spark.executor.Executor] - Running task 8.0 in stage 4.0 (TID 21)
2021-12-06 14:56:31,955 [Executor task launch worker for task 20] INFO [org.apache.spark.executor.Executor] - Running task 7.0 in stage 4.0 (TID 20)
2021-12-06 14:56:31,955 [Executor task launch worker for task 19] INFO [org.apache.spark.executor.Executor] - Running task 6.0 in stage 4.0 (TID 19)
2021-12-06 14:56:31,955 [Executor task launch worker for task 18] INFO [org.apache.spark.executor.Executor] - Running task 5.0 in stage 4.0 (TID 18)
2021-12-06 14:56:31,955 [Executor task launch worker for task 15] INFO [org.apache.spark.executor.Executor] - Running task 2.0 in stage 4.0 (TID 15)
2021-12-06 14:56:31,955 [Executor task launch worker for task 14] INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 4.0 (TID 14)
2021-12-06 14:56:31,955 [Executor task launch worker for task 16] INFO [org.apache.spark.executor.Executor] - Running task 3.0 in stage 4.0 (TID 16)
2021-12-06 14:56:31,957 [Executor task launch worker for task 22] INFO [org.apache.spark.executor.Executor] - Running task 9.0 in stage 4.0 (TID 22)
2021-12-06 14:56:31,958 [Executor task launch worker for task 15] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 2 non-empty blocks out of 2 blocks
2021-12-06 14:56:31,958 [Executor task launch worker for task 21] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 2 non-empty blocks out of 2 blocks
2021-12-06 14:56:31,958 [Executor task launch worker for task 15] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-06 14:56:31,958 [Executor task launch worker for task 21] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-06 14:56:31,959 [Executor task launch worker for task 20] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 2 non-empty blocks out of 2 blocks
2021-12-06 14:56:31,959 [Executor task launch worker for task 17] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 2 non-empty blocks out of 2 blocks
2021-12-06 14:56:31,959 [Executor task launch worker for task 20] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 1 ms
2021-12-06 14:56:31,959 [Executor task launch worker for task 18] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 2 non-empty blocks out of 2 blocks
2021-12-06 14:56:31,959 [Executor task launch worker for task 18] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-06 14:56:31,959 [Executor task launch worker for task 17] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 1 ms
2021-12-06 14:56:31,959 [Executor task launch worker for task 22] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 2 non-empty blocks out of 2 blocks
2021-12-06 14:56:31,959 [Executor task launch worker for task 22] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-06 14:56:31,959 [Executor task launch worker for task 14] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 2 non-empty blocks out of 2 blocks
2021-12-06 14:56:31,959 [Executor task launch worker for task 14] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-06 14:56:31,959 [Executor task launch worker for task 16] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 2 non-empty blocks out of 2 blocks
2021-12-06 14:56:31,959 [Executor task launch worker for task 19] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 2 non-empty blocks out of 2 blocks
2021-12-06 14:56:31,959 [Executor task launch worker for task 16] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-06 14:56:31,959 [Executor task launch worker for task 19] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-06 14:56:31,959 [Executor task launch worker for task 13] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 2 non-empty blocks out of 2 blocks
2021-12-06 14:56:31,959 [Executor task launch worker for task 13] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-06 14:56:31,984 [Executor task launch worker for task 14] INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 4.0 (TID 14). 1212 bytes result sent to driver
2021-12-06 14:56:31,985 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 4.0 (TID 14) in 31 ms on localhost (executor driver) (1/10)
2021-12-06 14:56:31,986 [Executor task launch worker for task 22] INFO [org.apache.spark.executor.Executor] - Finished task 9.0 in stage 4.0 (TID 22). 1212 bytes result sent to driver
2021-12-06 14:56:31,986 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 9.0 in stage 4.0 (TID 22) in 31 ms on localhost (executor driver) (2/10)
2021-12-06 14:56:31,987 [Executor task launch worker for task 20] INFO [org.apache.spark.executor.Executor] - Finished task 7.0 in stage 4.0 (TID 20). 1169 bytes result sent to driver
2021-12-06 14:56:31,988 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 7.0 in stage 4.0 (TID 20) in 33 ms on localhost (executor driver) (3/10)
2021-12-06 14:56:31,988 [Executor task launch worker for task 16] INFO [org.apache.spark.executor.Executor] - Finished task 3.0 in stage 4.0 (TID 16). 1212 bytes result sent to driver
2021-12-06 14:56:31,988 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 3.0 in stage 4.0 (TID 16) in 34 ms on localhost (executor driver) (4/10)
2021-12-06 14:56:31,990 [Executor task launch worker for task 21] INFO [org.apache.spark.executor.Executor] - Finished task 8.0 in stage 4.0 (TID 21). 1212 bytes result sent to driver
2021-12-06 14:56:31,990 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 8.0 in stage 4.0 (TID 21) in 35 ms on localhost (executor driver) (5/10)
2021-12-06 14:56:31,991 [Executor task launch worker for task 13] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 4.0 (TID 13). 1212 bytes result sent to driver
2021-12-06 14:56:31,992 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 4.0 (TID 13) in 39 ms on localhost (executor driver) (6/10)
2021-12-06 14:56:31,992 [Executor task launch worker for task 17] INFO [org.apache.spark.executor.Executor] - Finished task 4.0 in stage 4.0 (TID 17). 1169 bytes result sent to driver
2021-12-06 14:56:31,993 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 4.0 in stage 4.0 (TID 17) in 39 ms on localhost (executor driver) (7/10)
2021-12-06 14:56:31,994 [Executor task launch worker for task 18] INFO [org.apache.spark.executor.Executor] - Finished task 5.0 in stage 4.0 (TID 18). 1169 bytes result sent to driver
2021-12-06 14:56:31,994 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 5.0 in stage 4.0 (TID 18) in 40 ms on localhost (executor driver) (8/10)
2021-12-06 14:56:31,995 [Executor task launch worker for task 15] INFO [org.apache.spark.executor.Executor] - Finished task 2.0 in stage 4.0 (TID 15). 1255 bytes result sent to driver
2021-12-06 14:56:31,995 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 2.0 in stage 4.0 (TID 15) in 41 ms on localhost (executor driver) (9/10)
2021-12-06 14:56:31,996 [Executor task launch worker for task 19] INFO [org.apache.spark.executor.Executor] - Finished task 6.0 in stage 4.0 (TID 19). 1255 bytes result sent to driver
2021-12-06 14:56:31,996 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 6.0 in stage 4.0 (TID 19) in 42 ms on localhost (executor driver) (10/10)
2021-12-06 14:56:31,996 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 4.0, whose tasks have all completed, from pool 
2021-12-06 14:56:31,997 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ShuffleMapStage 4 (map at PaidPromotionAdjustParameter.scala:256) finished in 0.050 s
2021-12-06 14:56:31,997 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - looking for newly runnable stages
2021-12-06 14:56:31,997 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - running: Set()
2021-12-06 14:56:31,997 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - waiting: Set(ResultStage 5)
2021-12-06 14:56:31,997 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - failed: Set()
2021-12-06 14:56:31,997 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 5 (MapPartitionsRDD[12] at map at PaidPromotionAdjustParameter.scala:258), which has no missing parents
2021-12-06 14:56:31,998 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_6 stored as values in memory (estimated size 3.6 KB, free 1990.1 MB)
2021-12-06 14:56:32,002 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_6_piece0 stored as bytes in memory (estimated size 2.1 KB, free 1990.1 MB)
2021-12-06 14:56:32,003 [dispatcher-event-loop-1] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_6_piece0 in memory on qb:60443 (size: 2.1 KB, free: 1990.7 MB)
2021-12-06 14:56:32,003 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 6 from broadcast at DAGScheduler.scala:1039
2021-12-06 14:56:32,004 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 5 (MapPartitionsRDD[12] at map at PaidPromotionAdjustParameter.scala:258) (first 15 tasks are for partitions Vector(0))
2021-12-06 14:56:32,004 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 5.0 with 1 tasks
2021-12-06 14:56:32,004 [dispatcher-event-loop-5] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 5.0 (TID 23, localhost, executor driver, partition 0, PROCESS_LOCAL, 7649 bytes)
2021-12-06 14:56:32,005 [Executor task launch worker for task 23] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 5.0 (TID 23)
2021-12-06 14:56:32,007 [Executor task launch worker for task 23] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 0 non-empty blocks out of 10 blocks
2021-12-06 14:56:32,007 [Executor task launch worker for task 23] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-06 14:56:32,012 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 40
2021-12-06 14:56:32,012 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 67
2021-12-06 14:56:32,012 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 72
2021-12-06 14:56:32,012 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 33
2021-12-06 14:56:32,012 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 36
2021-12-06 14:56:32,012 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 46
2021-12-06 14:56:32,012 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 55
2021-12-06 14:56:32,012 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 65
2021-12-06 14:56:32,012 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 26
2021-12-06 14:56:32,013 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 62
2021-12-06 14:56:32,013 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 56
2021-12-06 14:56:32,013 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 59
2021-12-06 14:56:32,013 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 43
2021-12-06 14:56:32,013 [dispatcher-event-loop-7] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_4_piece0 on qb:60443 in memory (size: 2.2 KB, free: 1990.7 MB)
2021-12-06 14:56:32,014 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 60
2021-12-06 14:56:32,014 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 58
2021-12-06 14:56:32,014 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 39
2021-12-06 14:56:32,014 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 32
2021-12-06 14:56:32,014 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 41
2021-12-06 14:56:32,014 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 70
2021-12-06 14:56:32,014 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 42
2021-12-06 14:56:32,014 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 28
2021-12-06 14:56:32,014 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 47
2021-12-06 14:56:32,014 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 48
2021-12-06 14:56:32,014 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 50
2021-12-06 14:56:32,014 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 73
2021-12-06 14:56:32,014 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 45
2021-12-06 14:56:32,014 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 49
2021-12-06 14:56:32,014 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 66
2021-12-06 14:56:32,014 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 29
2021-12-06 14:56:32,014 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 68
2021-12-06 14:56:32,014 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 64
2021-12-06 14:56:32,014 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 38
2021-12-06 14:56:32,015 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 51
2021-12-06 14:56:32,015 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 34
2021-12-06 14:56:32,015 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 71
2021-12-06 14:56:32,015 [dispatcher-event-loop-9] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_5_piece0 on qb:60443 in memory (size: 2.3 KB, free: 1990.7 MB)
2021-12-06 14:56:32,016 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 74
2021-12-06 14:56:32,016 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 27
2021-12-06 14:56:32,016 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 63
2021-12-06 14:56:32,016 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 35
2021-12-06 14:56:32,016 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 61
2021-12-06 14:56:32,016 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 54
2021-12-06 14:56:32,016 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 57
2021-12-06 14:56:32,016 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 37
2021-12-06 14:56:32,016 [dispatcher-event-loop-0] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_3_piece0 on qb:60443 in memory (size: 2.8 KB, free: 1990.7 MB)
2021-12-06 14:56:32,017 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 52
2021-12-06 14:56:32,017 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 53
2021-12-06 14:56:32,017 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 30
2021-12-06 14:56:32,017 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 25
2021-12-06 14:56:32,017 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 44
2021-12-06 14:56:32,017 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 31
2021-12-06 14:56:32,017 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 69
2021-12-06 14:56:32,021 [Executor task launch worker for task 23] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 5.0 (TID 23). 1097 bytes result sent to driver
2021-12-06 14:56:32,021 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 5.0 (TID 23) in 17 ms on localhost (executor driver) (1/1)
2021-12-06 14:56:32,021 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 5.0, whose tasks have all completed, from pool 
2021-12-06 14:56:32,022 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 5 (take at PaidPromotionAdjustParameter.scala:259) finished in 0.025 s
2021-12-06 14:56:32,022 [main] INFO [org.apache.spark.scheduler.DAGScheduler] - Job 2 finished: take at PaidPromotionAdjustParameter.scala:259, took 0.078100 s
2021-12-06 14:56:32,029 [main] INFO [org.apache.spark.SparkContext] - Starting job: take at PaidPromotionAdjustParameter.scala:259
2021-12-06 14:56:32,029 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 3 (take at PaidPromotionAdjustParameter.scala:259) with 4 output partitions
2021-12-06 14:56:32,029 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 8 (take at PaidPromotionAdjustParameter.scala:259)
2021-12-06 14:56:32,029 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 7)
2021-12-06 14:56:32,030 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2021-12-06 14:56:32,030 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 8 (MapPartitionsRDD[12] at map at PaidPromotionAdjustParameter.scala:258), which has no missing parents
2021-12-06 14:56:32,031 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_7 stored as values in memory (estimated size 3.6 KB, free 1990.1 MB)
2021-12-06 14:56:32,034 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_7_piece0 stored as bytes in memory (estimated size 2.1 KB, free 1990.1 MB)
2021-12-06 14:56:32,034 [dispatcher-event-loop-5] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_7_piece0 in memory on qb:60443 (size: 2.1 KB, free: 1990.7 MB)
2021-12-06 14:56:32,035 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 7 from broadcast at DAGScheduler.scala:1039
2021-12-06 14:56:32,035 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 4 missing tasks from ResultStage 8 (MapPartitionsRDD[12] at map at PaidPromotionAdjustParameter.scala:258) (first 15 tasks are for partitions Vector(1, 2, 3, 4))
2021-12-06 14:56:32,035 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 8.0 with 4 tasks
2021-12-06 14:56:32,036 [dispatcher-event-loop-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 8.0 (TID 24, localhost, executor driver, partition 2, PROCESS_LOCAL, 7649 bytes)
2021-12-06 14:56:32,036 [dispatcher-event-loop-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 2.0 in stage 8.0 (TID 25, localhost, executor driver, partition 3, PROCESS_LOCAL, 7649 bytes)
2021-12-06 14:56:32,036 [dispatcher-event-loop-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 3.0 in stage 8.0 (TID 26, localhost, executor driver, partition 4, PROCESS_LOCAL, 7649 bytes)
2021-12-06 14:56:32,036 [dispatcher-event-loop-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 8.0 (TID 27, localhost, executor driver, partition 1, ANY, 7649 bytes)
2021-12-06 14:56:32,036 [Executor task launch worker for task 25] INFO [org.apache.spark.executor.Executor] - Running task 2.0 in stage 8.0 (TID 25)
2021-12-06 14:56:32,036 [Executor task launch worker for task 26] INFO [org.apache.spark.executor.Executor] - Running task 3.0 in stage 8.0 (TID 26)
2021-12-06 14:56:32,036 [Executor task launch worker for task 27] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 8.0 (TID 27)
2021-12-06 14:56:32,036 [Executor task launch worker for task 24] INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 8.0 (TID 24)
2021-12-06 14:56:32,038 [Executor task launch worker for task 25] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 0 non-empty blocks out of 10 blocks
2021-12-06 14:56:32,038 [Executor task launch worker for task 24] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 0 non-empty blocks out of 10 blocks
2021-12-06 14:56:32,038 [Executor task launch worker for task 26] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 0 non-empty blocks out of 10 blocks
2021-12-06 14:56:32,038 [Executor task launch worker for task 24] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-06 14:56:32,038 [Executor task launch worker for task 26] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-06 14:56:32,038 [Executor task launch worker for task 25] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-06 14:56:32,038 [Executor task launch worker for task 27] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 10 non-empty blocks out of 10 blocks
2021-12-06 14:56:32,038 [Executor task launch worker for task 27] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-06 14:56:32,047 [Executor task launch worker for task 26] INFO [org.apache.spark.executor.Executor] - Finished task 3.0 in stage 8.0 (TID 26). 1054 bytes result sent to driver
2021-12-06 14:56:32,047 [Executor task launch worker for task 24] INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 8.0 (TID 24). 1054 bytes result sent to driver
2021-12-06 14:56:32,047 [Executor task launch worker for task 25] INFO [org.apache.spark.executor.Executor] - Finished task 2.0 in stage 8.0 (TID 25). 1054 bytes result sent to driver
2021-12-06 14:56:32,048 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 8.0 (TID 24) in 13 ms on localhost (executor driver) (1/4)
2021-12-06 14:56:32,048 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 3.0 in stage 8.0 (TID 26) in 12 ms on localhost (executor driver) (2/4)
2021-12-06 14:56:32,048 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 2.0 in stage 8.0 (TID 25) in 12 ms on localhost (executor driver) (3/4)
2021-12-06 14:56:32,089 [Executor task launch worker for task 27] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 8.0 (TID 27). 1056 bytes result sent to driver
2021-12-06 14:56:32,090 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 8.0 (TID 27) in 53 ms on localhost (executor driver) (4/4)
2021-12-06 14:56:32,090 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 8.0, whose tasks have all completed, from pool 
2021-12-06 14:56:32,090 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 8 (take at PaidPromotionAdjustParameter.scala:259) finished in 0.060 s
2021-12-06 14:56:32,090 [main] INFO [org.apache.spark.scheduler.DAGScheduler] - Job 3 finished: take at PaidPromotionAdjustParameter.scala:259, took 0.061292 s
2021-12-06 14:56:32,091 [main] INFO [PaidPromotion$] -  131
2021-12-06 14:56:32,197 [Thread-1] INFO [org.apache.spark.SparkContext] - Invoking stop() from shutdown hook
2021-12-06 14:56:32,202 [Thread-1] INFO [org.spark_project.jetty.server.AbstractConnector] - Stopped Spark@68d651f2{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2021-12-06 14:56:32,204 [Thread-1] INFO [org.apache.spark.ui.SparkUI] - Stopped Spark web UI at http://qb:4040
2021-12-06 14:56:32,215 [dispatcher-event-loop-5] INFO [org.apache.spark.MapOutputTrackerMasterEndpoint] - MapOutputTrackerMasterEndpoint stopped!
2021-12-06 14:56:32,260 [Thread-1] INFO [org.apache.spark.storage.memory.MemoryStore] - MemoryStore cleared
2021-12-06 14:56:32,261 [Thread-1] INFO [org.apache.spark.storage.BlockManager] - BlockManager stopped
2021-12-06 14:56:32,262 [Thread-1] INFO [org.apache.spark.storage.BlockManagerMaster] - BlockManagerMaster stopped
2021-12-06 14:56:32,265 [dispatcher-event-loop-6] INFO [org.apache.spark.scheduler.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint] - OutputCommitCoordinator stopped!
2021-12-06 14:56:32,269 [Thread-1] INFO [org.apache.spark.SparkContext] - Successfully stopped SparkContext
2021-12-06 14:56:32,269 [Thread-1] INFO [org.apache.spark.util.ShutdownHookManager] - Shutdown hook called
2021-12-06 14:56:32,270 [Thread-1] INFO [org.apache.spark.util.ShutdownHookManager] - Deleting directory C:\Users\ACER\AppData\Local\Temp\spark-c4de79bf-dc71-4bd6-9f15-37a428d7f31e
2021-12-06 14:58:12,390 [main] INFO [org.apache.spark.SparkContext] - Running Spark version 2.3.0
2021-12-06 14:58:12,656 [main] INFO [org.apache.spark.SparkContext] - Submitted application: PaidPromotion
2021-12-06 14:58:12,700 [main] INFO [org.apache.spark.SecurityManager] - Changing view acls to: ACER,root
2021-12-06 14:58:12,701 [main] INFO [org.apache.spark.SecurityManager] - Changing modify acls to: ACER,root
2021-12-06 14:58:12,701 [main] INFO [org.apache.spark.SecurityManager] - Changing view acls groups to: 
2021-12-06 14:58:12,701 [main] INFO [org.apache.spark.SecurityManager] - Changing modify acls groups to: 
2021-12-06 14:58:12,702 [main] INFO [org.apache.spark.SecurityManager] - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(ACER, root); groups with view permissions: Set(); users  with modify permissions: Set(ACER, root); groups with modify permissions: Set()
2021-12-06 14:58:13,262 [main] INFO [org.apache.spark.util.Utils] - Successfully started service 'sparkDriver' on port 60635.
2021-12-06 14:58:13,281 [main] INFO [org.apache.spark.SparkEnv] - Registering MapOutputTracker
2021-12-06 14:58:13,295 [main] INFO [org.apache.spark.SparkEnv] - Registering BlockManagerMaster
2021-12-06 14:58:13,297 [main] INFO [org.apache.spark.storage.BlockManagerMasterEndpoint] - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2021-12-06 14:58:13,298 [main] INFO [org.apache.spark.storage.BlockManagerMasterEndpoint] - BlockManagerMasterEndpoint up
2021-12-06 14:58:13,305 [main] INFO [org.apache.spark.storage.DiskBlockManager] - Created local directory at C:\Users\ACER\AppData\Local\Temp\blockmgr-e449101f-d124-414f-a2bb-4d09ac25d568
2021-12-06 14:58:13,320 [main] INFO [org.apache.spark.storage.memory.MemoryStore] - MemoryStore started with capacity 1990.8 MB
2021-12-06 14:58:13,329 [main] INFO [org.apache.spark.SparkEnv] - Registering OutputCommitCoordinator
2021-12-06 14:58:13,384 [main] INFO [org.spark_project.jetty.util.log] - Logging initialized @1820ms
2021-12-06 14:58:13,433 [main] INFO [org.spark_project.jetty.server.Server] - jetty-9.3.z-SNAPSHOT
2021-12-06 14:58:13,443 [main] INFO [org.spark_project.jetty.server.Server] - Started @1879ms
2021-12-06 14:58:13,468 [main] INFO [org.spark_project.jetty.server.AbstractConnector] - Started ServerConnector@2e185cd7{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2021-12-06 14:58:13,468 [main] INFO [org.apache.spark.util.Utils] - Successfully started service 'SparkUI' on port 4040.
2021-12-06 14:58:13,487 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@4fcee388{/jobs,null,AVAILABLE,@Spark}
2021-12-06 14:58:13,488 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@40dd3977{/jobs/json,null,AVAILABLE,@Spark}
2021-12-06 14:58:13,489 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@2f94c4db{/jobs/job,null,AVAILABLE,@Spark}
2021-12-06 14:58:13,491 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@64bc21ac{/jobs/job/json,null,AVAILABLE,@Spark}
2021-12-06 14:58:13,492 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@4a8a60bc{/stages,null,AVAILABLE,@Spark}
2021-12-06 14:58:13,493 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@314b8f2d{/stages/json,null,AVAILABLE,@Spark}
2021-12-06 14:58:13,494 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@4a3e3e8b{/stages/stage,null,AVAILABLE,@Spark}
2021-12-06 14:58:13,496 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@72f46e16{/stages/stage/json,null,AVAILABLE,@Spark}
2021-12-06 14:58:13,497 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@32232e55{/stages/pool,null,AVAILABLE,@Spark}
2021-12-06 14:58:13,497 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@2416a51{/stages/pool/json,null,AVAILABLE,@Spark}
2021-12-06 14:58:13,498 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@47874b25{/storage,null,AVAILABLE,@Spark}
2021-12-06 14:58:13,499 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@209775a9{/storage/json,null,AVAILABLE,@Spark}
2021-12-06 14:58:13,500 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@4f8969b0{/storage/rdd,null,AVAILABLE,@Spark}
2021-12-06 14:58:13,501 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@c65a5ef{/storage/rdd/json,null,AVAILABLE,@Spark}
2021-12-06 14:58:13,502 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@29cfd92b{/environment,null,AVAILABLE,@Spark}
2021-12-06 14:58:13,504 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@460f76a6{/environment/json,null,AVAILABLE,@Spark}
2021-12-06 14:58:13,505 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@644c78d4{/executors,null,AVAILABLE,@Spark}
2021-12-06 14:58:13,507 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@7cbee484{/executors/json,null,AVAILABLE,@Spark}
2021-12-06 14:58:13,508 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@7807ac2c{/executors/threadDump,null,AVAILABLE,@Spark}
2021-12-06 14:58:13,510 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@4fd4cae3{/executors/threadDump/json,null,AVAILABLE,@Spark}
2021-12-06 14:58:13,517 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@2baa8d82{/static,null,AVAILABLE,@Spark}
2021-12-06 14:58:13,519 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@114a85c2{/,null,AVAILABLE,@Spark}
2021-12-06 14:58:13,521 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@c9413d8{/api,null,AVAILABLE,@Spark}
2021-12-06 14:58:13,522 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@5ae81e1{/jobs/job/kill,null,AVAILABLE,@Spark}
2021-12-06 14:58:13,524 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@54709809{/stages/stage/kill,null,AVAILABLE,@Spark}
2021-12-06 14:58:13,526 [main] INFO [org.apache.spark.ui.SparkUI] - Bound SparkUI to 0.0.0.0, and started at http://qb:4040
2021-12-06 14:58:13,606 [main] INFO [org.apache.spark.executor.Executor] - Starting executor ID driver on host localhost
2021-12-06 14:58:13,648 [main] INFO [org.apache.spark.util.Utils] - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 60678.
2021-12-06 14:58:13,649 [main] INFO [org.apache.spark.network.netty.NettyBlockTransferService] - Server created on qb:60678
2021-12-06 14:58:13,650 [main] INFO [org.apache.spark.storage.BlockManager] - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2021-12-06 14:58:13,651 [main] INFO [org.apache.spark.storage.BlockManagerMaster] - Registering BlockManager BlockManagerId(driver, qb, 60678, None)
2021-12-06 14:58:13,654 [dispatcher-event-loop-10] INFO [org.apache.spark.storage.BlockManagerMasterEndpoint] - Registering block manager qb:60678 with 1990.8 MB RAM, BlockManagerId(driver, qb, 60678, None)
2021-12-06 14:58:13,656 [main] INFO [org.apache.spark.storage.BlockManagerMaster] - Registered BlockManager BlockManagerId(driver, qb, 60678, None)
2021-12-06 14:58:13,656 [main] INFO [org.apache.spark.storage.BlockManager] - Initialized BlockManager: BlockManagerId(driver, qb, 60678, None)
2021-12-06 14:58:13,783 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@591fd34d{/metrics/json,null,AVAILABLE,@Spark}
2021-12-06 14:58:14,312 [main] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_0 stored as values in memory (estimated size 312.7 KB, free 1990.5 MB)
2021-12-06 14:58:14,517 [main] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_0_piece0 stored as bytes in memory (estimated size 27.3 KB, free 1990.5 MB)
2021-12-06 14:58:14,518 [dispatcher-event-loop-0] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_0_piece0 in memory on qb:60678 (size: 27.3 KB, free: 1990.8 MB)
2021-12-06 14:58:14,521 [main] INFO [org.apache.spark.SparkContext] - Created broadcast 0 from textFile at PaidPromotionAdjustParameter.scala:98
2021-12-06 14:58:14,847 [main] WARN [org.apache.hadoop.hdfs.shortcircuit.DomainSocketFactory] - The short-circuit local reads feature cannot be used because UNIX Domain sockets are not available on Windows.
2021-12-06 14:58:15,010 [main] INFO [org.apache.hadoop.mapred.FileInputFormat] - Total input paths to process : 1
2021-12-06 14:58:15,122 [main] INFO [org.apache.spark.SparkContext] - Starting job: count at PaidPromotionAdjustParameter.scala:100
2021-12-06 14:58:15,131 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 0 (count at PaidPromotionAdjustParameter.scala:100) with 2 output partitions
2021-12-06 14:58:15,131 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 0 (count at PaidPromotionAdjustParameter.scala:100)
2021-12-06 14:58:15,132 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List()
2021-12-06 14:58:15,132 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2021-12-06 14:58:15,138 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 0 (/sk/chongqing/data/order_data.bcp MapPartitionsRDD[1] at textFile at PaidPromotionAdjustParameter.scala:98), which has no missing parents
2021-12-06 14:58:15,168 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_1 stored as values in memory (estimated size 3.1 KB, free 1990.5 MB)
2021-12-06 14:58:15,173 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_1_piece0 stored as bytes in memory (estimated size 1900.0 B, free 1990.5 MB)
2021-12-06 14:58:15,173 [dispatcher-event-loop-1] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_1_piece0 in memory on qb:60678 (size: 1900.0 B, free: 1990.8 MB)
2021-12-06 14:58:15,174 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 1 from broadcast at DAGScheduler.scala:1039
2021-12-06 14:58:15,183 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from ResultStage 0 (/sk/chongqing/data/order_data.bcp MapPartitionsRDD[1] at textFile at PaidPromotionAdjustParameter.scala:98) (first 15 tasks are for partitions Vector(0, 1))
2021-12-06 14:58:15,184 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 0.0 with 2 tasks
2021-12-06 14:58:15,214 [dispatcher-event-loop-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 0.0 (TID 0, localhost, executor driver, partition 0, ANY, 7896 bytes)
2021-12-06 14:58:15,215 [dispatcher-event-loop-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 0.0 (TID 1, localhost, executor driver, partition 1, ANY, 7896 bytes)
2021-12-06 14:58:15,220 [Executor task launch worker for task 0] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 0.0 (TID 0)
2021-12-06 14:58:15,220 [Executor task launch worker for task 1] INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 0.0 (TID 1)
2021-12-06 14:58:15,256 [Executor task launch worker for task 0] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/order_data.bcp:0+3442194
2021-12-06 14:58:15,256 [Executor task launch worker for task 1] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/order_data.bcp:3442194+3442195
2021-12-06 14:58:17,345 [Executor task launch worker for task 1] INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 0.0 (TID 1). 711 bytes result sent to driver
2021-12-06 14:58:17,353 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 0.0 (TID 1) in 2137 ms on localhost (executor driver) (1/2)
2021-12-06 14:58:18,393 [Executor task launch worker for task 0] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 0.0 (TID 0). 711 bytes result sent to driver
2021-12-06 14:58:18,396 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 0.0 (TID 0) in 3191 ms on localhost (executor driver) (2/2)
2021-12-06 14:58:18,397 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 0.0, whose tasks have all completed, from pool 
2021-12-06 14:58:18,397 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 0 (count at PaidPromotionAdjustParameter.scala:100) finished in 3.245 s
2021-12-06 14:58:18,401 [main] INFO [org.apache.spark.scheduler.DAGScheduler] - Job 0 finished: count at PaidPromotionAdjustParameter.scala:100, took 3.278540 s
2021-12-06 14:58:18,403 [main] INFO [PaidPromotion$] - 107294
2021-12-06 14:58:18,407 [main] INFO [org.apache.spark.SparkContext] - Starting job: count at PaidPromotionAdjustParameter.scala:108
2021-12-06 14:58:18,408 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 1 (count at PaidPromotionAdjustParameter.scala:108) with 2 output partitions
2021-12-06 14:58:18,408 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 1 (count at PaidPromotionAdjustParameter.scala:108)
2021-12-06 14:58:18,408 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List()
2021-12-06 14:58:18,408 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2021-12-06 14:58:18,408 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 1 (MapPartitionsRDD[2] at map at PaidPromotionAdjustParameter.scala:104), which has no missing parents
2021-12-06 14:58:18,410 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_2 stored as values in memory (estimated size 3.3 KB, free 1990.5 MB)
2021-12-06 14:58:18,415 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_2_piece0 stored as bytes in memory (estimated size 1985.0 B, free 1990.5 MB)
2021-12-06 14:58:18,415 [dispatcher-event-loop-7] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_2_piece0 in memory on qb:60678 (size: 1985.0 B, free: 1990.8 MB)
2021-12-06 14:58:18,416 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 2 from broadcast at DAGScheduler.scala:1039
2021-12-06 14:58:18,417 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from ResultStage 1 (MapPartitionsRDD[2] at map at PaidPromotionAdjustParameter.scala:104) (first 15 tasks are for partitions Vector(0, 1))
2021-12-06 14:58:18,417 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 1.0 with 2 tasks
2021-12-06 14:58:18,418 [dispatcher-event-loop-8] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 1.0 (TID 2, localhost, executor driver, partition 0, ANY, 7896 bytes)
2021-12-06 14:58:18,418 [dispatcher-event-loop-8] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 1.0 (TID 3, localhost, executor driver, partition 1, ANY, 7896 bytes)
2021-12-06 14:58:18,418 [Executor task launch worker for task 3] INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 1.0 (TID 3)
2021-12-06 14:58:18,418 [Executor task launch worker for task 2] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 1.0 (TID 2)
2021-12-06 14:58:18,421 [Executor task launch worker for task 3] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/order_data.bcp:3442194+3442195
2021-12-06 14:58:18,421 [Executor task launch worker for task 2] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/order_data.bcp:0+3442194
2021-12-06 14:58:19,049 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 5
2021-12-06 14:58:19,049 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 15
2021-12-06 14:58:19,049 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 8
2021-12-06 14:58:19,049 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 19
2021-12-06 14:58:19,049 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 11
2021-12-06 14:58:19,049 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1
2021-12-06 14:58:19,049 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 12
2021-12-06 14:58:19,049 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 24
2021-12-06 14:58:19,049 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 16
2021-12-06 14:58:19,061 [dispatcher-event-loop-1] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_1_piece0 on qb:60678 in memory (size: 1900.0 B, free: 1990.8 MB)
2021-12-06 14:58:19,064 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 2
2021-12-06 14:58:19,064 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 3
2021-12-06 14:58:19,064 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 4
2021-12-06 14:58:19,064 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 18
2021-12-06 14:58:19,064 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 23
2021-12-06 14:58:19,064 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 0
2021-12-06 14:58:19,064 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 7
2021-12-06 14:58:19,064 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 17
2021-12-06 14:58:19,064 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 20
2021-12-06 14:58:19,064 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 13
2021-12-06 14:58:19,064 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 10
2021-12-06 14:58:19,064 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 9
2021-12-06 14:58:19,064 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 6
2021-12-06 14:58:19,064 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 22
2021-12-06 14:58:19,064 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 14
2021-12-06 14:58:19,064 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 21
2021-12-06 14:58:21,074 [Executor task launch worker for task 3] INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 1.0 (TID 3). 797 bytes result sent to driver
2021-12-06 14:58:21,076 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 1.0 (TID 3) in 2658 ms on localhost (executor driver) (1/2)
2021-12-06 14:58:21,146 [Executor task launch worker for task 2] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 1.0 (TID 2). 797 bytes result sent to driver
2021-12-06 14:58:21,149 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 1.0 (TID 2) in 2731 ms on localhost (executor driver) (2/2)
2021-12-06 14:58:21,149 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 1.0, whose tasks have all completed, from pool 
2021-12-06 14:58:21,149 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 1 (count at PaidPromotionAdjustParameter.scala:108) finished in 2.740 s
2021-12-06 14:58:21,149 [main] INFO [org.apache.spark.scheduler.DAGScheduler] - Job 1 finished: count at PaidPromotionAdjustParameter.scala:108, took 2.742548 s
2021-12-06 14:58:21,150 [main] INFO [PaidPromotion$] - 107294
2021-12-06 14:58:21,164 [main] INFO [org.apache.spark.SparkContext] - Starting job: count at PaidPromotionAdjustParameter.scala:121
2021-12-06 14:58:21,164 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 2 (count at PaidPromotionAdjustParameter.scala:121) with 2 output partitions
2021-12-06 14:58:21,164 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 2 (count at PaidPromotionAdjustParameter.scala:121)
2021-12-06 14:58:21,164 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List()
2021-12-06 14:58:21,164 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2021-12-06 14:58:21,165 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 2 (MapPartitionsRDD[3] at randomSplit at PaidPromotionAdjustParameter.scala:114), which has no missing parents
2021-12-06 14:58:21,166 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_3 stored as values in memory (estimated size 3.6 KB, free 1990.5 MB)
2021-12-06 14:58:21,170 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_3_piece0 stored as bytes in memory (estimated size 2.1 KB, free 1990.5 MB)
2021-12-06 14:58:21,170 [dispatcher-event-loop-3] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_3_piece0 in memory on qb:60678 (size: 2.1 KB, free: 1990.8 MB)
2021-12-06 14:58:21,170 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 3 from broadcast at DAGScheduler.scala:1039
2021-12-06 14:58:21,171 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from ResultStage 2 (MapPartitionsRDD[3] at randomSplit at PaidPromotionAdjustParameter.scala:114) (first 15 tasks are for partitions Vector(0, 1))
2021-12-06 14:58:21,171 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 2.0 with 2 tasks
2021-12-06 14:58:21,172 [dispatcher-event-loop-5] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 2.0 (TID 4, localhost, executor driver, partition 0, ANY, 7896 bytes)
2021-12-06 14:58:21,172 [dispatcher-event-loop-5] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 2.0 (TID 5, localhost, executor driver, partition 1, ANY, 7896 bytes)
2021-12-06 14:58:21,172 [Executor task launch worker for task 5] INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 2.0 (TID 5)
2021-12-06 14:58:21,172 [Executor task launch worker for task 4] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 2.0 (TID 4)
2021-12-06 14:58:21,176 [Executor task launch worker for task 5] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/order_data.bcp:3442194+3442195
2021-12-06 14:58:21,176 [Executor task launch worker for task 4] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/order_data.bcp:0+3442194
2021-12-06 14:58:21,300 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 25
2021-12-06 14:58:21,300 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 26
2021-12-06 14:58:21,301 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 42
2021-12-06 14:58:21,301 [dispatcher-event-loop-10] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_2_piece0 on qb:60678 in memory (size: 1985.0 B, free: 1990.8 MB)
2021-12-06 14:58:21,302 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 33
2021-12-06 14:58:21,302 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 44
2021-12-06 14:58:21,302 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 43
2021-12-06 14:58:21,302 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 40
2021-12-06 14:58:21,302 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 49
2021-12-06 14:58:21,302 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 36
2021-12-06 14:58:21,303 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 27
2021-12-06 14:58:21,303 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 30
2021-12-06 14:58:21,303 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 35
2021-12-06 14:58:21,303 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 48
2021-12-06 14:58:21,303 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 34
2021-12-06 14:58:21,303 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 46
2021-12-06 14:58:21,303 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 28
2021-12-06 14:58:21,303 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 45
2021-12-06 14:58:21,303 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 37
2021-12-06 14:58:21,303 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 39
2021-12-06 14:58:21,303 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 47
2021-12-06 14:58:21,303 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 29
2021-12-06 14:58:21,303 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 31
2021-12-06 14:58:21,303 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 32
2021-12-06 14:58:21,304 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 41
2021-12-06 14:58:21,304 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 38
2021-12-06 14:58:22,433 [Executor task launch worker for task 5] INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 2.0 (TID 5). 754 bytes result sent to driver
2021-12-06 14:58:22,433 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 2.0 (TID 5) in 1261 ms on localhost (executor driver) (1/2)
2021-12-06 14:58:22,586 [Executor task launch worker for task 4] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 2.0 (TID 4). 754 bytes result sent to driver
2021-12-06 14:58:22,587 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 2.0 (TID 4) in 1415 ms on localhost (executor driver) (2/2)
2021-12-06 14:58:22,587 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 2.0, whose tasks have all completed, from pool 
2021-12-06 14:58:22,587 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 2 (count at PaidPromotionAdjustParameter.scala:121) finished in 1.422 s
2021-12-06 14:58:22,587 [main] INFO [org.apache.spark.scheduler.DAGScheduler] - Job 2 finished: count at PaidPromotionAdjustParameter.scala:121, took 1.422505 s
2021-12-06 14:58:22,587 [main] INFO [PaidPromotion$] - 47420
2021-12-06 14:58:22,589 [main] INFO [org.apache.spark.SparkContext] - Starting job: count at PaidPromotionAdjustParameter.scala:122
2021-12-06 14:58:22,590 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 3 (count at PaidPromotionAdjustParameter.scala:122) with 2 output partitions
2021-12-06 14:58:22,590 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 3 (count at PaidPromotionAdjustParameter.scala:122)
2021-12-06 14:58:22,590 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List()
2021-12-06 14:58:22,590 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2021-12-06 14:58:22,590 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 3 (MapPartitionsRDD[4] at randomSplit at PaidPromotionAdjustParameter.scala:114), which has no missing parents
2021-12-06 14:58:22,591 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_4 stored as values in memory (estimated size 3.6 KB, free 1990.5 MB)
2021-12-06 14:58:22,593 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_4_piece0 stored as bytes in memory (estimated size 2.1 KB, free 1990.5 MB)
2021-12-06 14:58:22,594 [dispatcher-event-loop-1] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_4_piece0 in memory on qb:60678 (size: 2.1 KB, free: 1990.8 MB)
2021-12-06 14:58:22,594 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 4 from broadcast at DAGScheduler.scala:1039
2021-12-06 14:58:22,594 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from ResultStage 3 (MapPartitionsRDD[4] at randomSplit at PaidPromotionAdjustParameter.scala:114) (first 15 tasks are for partitions Vector(0, 1))
2021-12-06 14:58:22,595 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 3.0 with 2 tasks
2021-12-06 14:58:22,595 [dispatcher-event-loop-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 3.0 (TID 6, localhost, executor driver, partition 0, ANY, 7896 bytes)
2021-12-06 14:58:22,595 [dispatcher-event-loop-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 3.0 (TID 7, localhost, executor driver, partition 1, ANY, 7896 bytes)
2021-12-06 14:58:22,596 [Executor task launch worker for task 6] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 3.0 (TID 6)
2021-12-06 14:58:22,596 [Executor task launch worker for task 7] INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 3.0 (TID 7)
2021-12-06 14:58:22,598 [Executor task launch worker for task 6] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/order_data.bcp:0+3442194
2021-12-06 14:58:22,598 [Executor task launch worker for task 7] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/order_data.bcp:3442194+3442195
2021-12-06 14:58:23,492 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 64
2021-12-06 14:58:23,492 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 65
2021-12-06 14:58:23,493 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 68
2021-12-06 14:58:23,493 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 51
2021-12-06 14:58:23,493 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 74
2021-12-06 14:58:23,493 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 67
2021-12-06 14:58:23,493 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 50
2021-12-06 14:58:23,493 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 54
2021-12-06 14:58:23,493 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 63
2021-12-06 14:58:23,493 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 52
2021-12-06 14:58:23,493 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 58
2021-12-06 14:58:23,493 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 57
2021-12-06 14:58:23,493 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 69
2021-12-06 14:58:23,493 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 59
2021-12-06 14:58:23,493 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 60
2021-12-06 14:58:23,493 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 71
2021-12-06 14:58:23,493 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 61
2021-12-06 14:58:23,494 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 62
2021-12-06 14:58:23,494 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 72
2021-12-06 14:58:23,494 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 56
2021-12-06 14:58:23,494 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 73
2021-12-06 14:58:23,494 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 53
2021-12-06 14:58:23,494 [dispatcher-event-loop-7] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_3_piece0 on qb:60678 in memory (size: 2.1 KB, free: 1990.8 MB)
2021-12-06 14:58:23,495 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 70
2021-12-06 14:58:23,495 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 55
2021-12-06 14:58:23,495 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 66
2021-12-06 14:58:23,895 [Executor task launch worker for task 6] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 3.0 (TID 6). 754 bytes result sent to driver
2021-12-06 14:58:23,896 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 3.0 (TID 6) in 1301 ms on localhost (executor driver) (1/2)
2021-12-06 14:58:23,996 [Executor task launch worker for task 7] INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 3.0 (TID 7). 797 bytes result sent to driver
2021-12-06 14:58:23,996 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 3.0 (TID 7) in 1401 ms on localhost (executor driver) (2/2)
2021-12-06 14:58:23,996 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 3.0, whose tasks have all completed, from pool 
2021-12-06 14:58:23,997 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 3 (count at PaidPromotionAdjustParameter.scala:122) finished in 1.406 s
2021-12-06 14:58:23,997 [main] INFO [org.apache.spark.scheduler.DAGScheduler] - Job 3 finished: count at PaidPromotionAdjustParameter.scala:122, took 1.407432 s
2021-12-06 14:58:23,997 [main] INFO [PaidPromotion$] - 59874
2021-12-06 14:58:24,054 [main] INFO [PaidPromotion$] - -----------------------------------
2021-12-06 14:58:24,055 [main] INFO [org.apache.spark.SparkContext] - Starting job: count at PaidPromotionAdjustParameter.scala:138
2021-12-06 14:58:24,061 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 6 (distinct at PaidPromotionAdjustParameter.scala:128)
2021-12-06 14:58:24,062 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 4 (count at PaidPromotionAdjustParameter.scala:138) with 2 output partitions
2021-12-06 14:58:24,062 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 5 (count at PaidPromotionAdjustParameter.scala:138)
2021-12-06 14:58:24,062 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 4)
2021-12-06 14:58:24,062 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List(ShuffleMapStage 4)
2021-12-06 14:58:24,063 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ShuffleMapStage 4 (MapPartitionsRDD[6] at distinct at PaidPromotionAdjustParameter.scala:128), which has no missing parents
2021-12-06 14:58:24,073 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_5 stored as values in memory (estimated size 5.2 KB, free 1990.5 MB)
2021-12-06 14:58:24,076 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_5_piece0 stored as bytes in memory (estimated size 2.9 KB, free 1990.5 MB)
2021-12-06 14:58:24,076 [dispatcher-event-loop-10] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_5_piece0 in memory on qb:60678 (size: 2.9 KB, free: 1990.8 MB)
2021-12-06 14:58:24,077 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 5 from broadcast at DAGScheduler.scala:1039
2021-12-06 14:58:24,078 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from ShuffleMapStage 4 (MapPartitionsRDD[6] at distinct at PaidPromotionAdjustParameter.scala:128) (first 15 tasks are for partitions Vector(0, 1))
2021-12-06 14:58:24,078 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 4.0 with 2 tasks
2021-12-06 14:58:24,080 [dispatcher-event-loop-11] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 4.0 (TID 8, localhost, executor driver, partition 0, ANY, 7885 bytes)
2021-12-06 14:58:24,080 [dispatcher-event-loop-11] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 4.0 (TID 9, localhost, executor driver, partition 1, ANY, 7885 bytes)
2021-12-06 14:58:24,080 [Executor task launch worker for task 9] INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 4.0 (TID 9)
2021-12-06 14:58:24,080 [Executor task launch worker for task 8] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 4.0 (TID 8)
2021-12-06 14:58:24,084 [Executor task launch worker for task 8] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/order_data.bcp:0+3442194
2021-12-06 14:58:24,084 [Executor task launch worker for task 9] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/order_data.bcp:3442194+3442195
2021-12-06 14:58:24,769 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 77
2021-12-06 14:58:24,770 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 99
2021-12-06 14:58:24,770 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 96
2021-12-06 14:58:24,770 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 82
2021-12-06 14:58:24,770 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 79
2021-12-06 14:58:24,770 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 80
2021-12-06 14:58:24,770 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 81
2021-12-06 14:58:24,770 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 83
2021-12-06 14:58:24,770 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 88
2021-12-06 14:58:24,771 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 75
2021-12-06 14:58:24,771 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 90
2021-12-06 14:58:24,771 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 89
2021-12-06 14:58:24,771 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 98
2021-12-06 14:58:24,771 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 78
2021-12-06 14:58:24,771 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 84
2021-12-06 14:58:24,771 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 92
2021-12-06 14:58:24,771 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 91
2021-12-06 14:58:24,771 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 95
2021-12-06 14:58:24,771 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 86
2021-12-06 14:58:24,771 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 93
2021-12-06 14:58:24,771 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 94
2021-12-06 14:58:24,771 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 85
2021-12-06 14:58:24,771 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 97
2021-12-06 14:58:24,771 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 87
2021-12-06 14:58:24,772 [dispatcher-event-loop-3] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_4_piece0 on qb:60678 in memory (size: 2.1 KB, free: 1990.8 MB)
2021-12-06 14:58:24,772 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 76
2021-12-06 14:58:25,168 [Executor task launch worker for task 8] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 4.0 (TID 8). 1032 bytes result sent to driver
2021-12-06 14:58:25,182 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 4.0 (TID 8) in 1103 ms on localhost (executor driver) (1/2)
2021-12-06 14:58:25,241 [SparkUI-43] INFO [org.spark_project.jetty.servlet.DefaultServlet] - content=ResourceHttpContent@81eaa95{r=jar:file:/C:/Users/ACER/.m2/repository/org/apache/spark/spark-core_2.11/2.3.0/spark-core_2.11-2.3.0.jar!/org/apache/spark/ui/static/vis.min.css,gz=false}
2021-12-06 14:58:25,241 [SparkUI-37] INFO [org.spark_project.jetty.servlet.DefaultServlet] - content=ResourceHttpContent@1386b323{r=jar:file:/C:/Users/ACER/.m2/repository/org/apache/spark/spark-core_2.11/2.3.0/spark-core_2.11-2.3.0.jar!/org/apache/spark/ui/static/webui.css,gz=false}
2021-12-06 14:58:25,241 [SparkUI-44] INFO [org.spark_project.jetty.servlet.DefaultServlet] - content=ResourceHttpContent@155d2e2e{r=jar:file:/C:/Users/ACER/.m2/repository/org/apache/spark/spark-core_2.11/2.3.0/spark-core_2.11-2.3.0.jar!/org/apache/spark/ui/static/bootstrap.min.css,gz=false}
2021-12-06 14:58:25,241 [SparkUI-71] INFO [org.spark_project.jetty.servlet.DefaultServlet] - content=ResourceHttpContent@36167223{r=jar:file:/C:/Users/ACER/.m2/repository/org/apache/spark/spark-core_2.11/2.3.0/spark-core_2.11-2.3.0.jar!/org/apache/spark/ui/static/timeline-view.css,gz=false}
2021-12-06 14:58:25,242 [SparkUI-44] WARN [org.spark_project.jetty.servlet.ServletHandler] - Error for /static/bootstrap.min.css
java.lang.NoSuchMethodError: javax.servlet.http.HttpServletRequest.isAsyncSupported()Z
	at org.spark_project.jetty.servlet.DefaultServlet.sendData(DefaultServlet.java:909)
	at org.spark_project.jetty.servlet.DefaultServlet.doGet(DefaultServlet.java:526)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:707)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:820)
	at org.spark_project.jetty.servlet.ServletHolder.handle(ServletHolder.java:848)
	at org.spark_project.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:584)
	at org.spark_project.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
	at org.spark_project.jetty.servlet.ServletHandler.doScope(ServletHandler.java:512)
	at org.spark_project.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
	at org.spark_project.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.spark_project.jetty.server.handler.gzip.GzipHandler.handle(GzipHandler.java:493)
	at org.spark_project.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:213)
	at org.spark_project.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
	at org.spark_project.jetty.server.Server.handle(Server.java:534)
	at org.spark_project.jetty.server.HttpChannel.handle(HttpChannel.java:320)
	at org.spark_project.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
	at org.spark_project.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
	at org.spark_project.jetty.io.FillInterest.fillable(FillInterest.java:108)
	at org.spark_project.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
	at org.spark_project.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
	at org.spark_project.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
	at java.lang.Thread.run(Thread.java:745)
2021-12-06 14:58:25,242 [SparkUI-43] WARN [org.spark_project.jetty.servlet.ServletHandler] - Error for /static/vis.min.css
java.lang.NoSuchMethodError: javax.servlet.http.HttpServletRequest.isAsyncSupported()Z
	at org.spark_project.jetty.servlet.DefaultServlet.sendData(DefaultServlet.java:909)
	at org.spark_project.jetty.servlet.DefaultServlet.doGet(DefaultServlet.java:526)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:707)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:820)
	at org.spark_project.jetty.servlet.ServletHolder.handle(ServletHolder.java:848)
	at org.spark_project.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:584)
	at org.spark_project.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
	at org.spark_project.jetty.servlet.ServletHandler.doScope(ServletHandler.java:512)
	at org.spark_project.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
	at org.spark_project.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.spark_project.jetty.server.handler.gzip.GzipHandler.handle(GzipHandler.java:493)
	at org.spark_project.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:213)
	at org.spark_project.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
	at org.spark_project.jetty.server.Server.handle(Server.java:534)
	at org.spark_project.jetty.server.HttpChannel.handle(HttpChannel.java:320)
	at org.spark_project.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
	at org.spark_project.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
	at org.spark_project.jetty.io.FillInterest.fillable(FillInterest.java:108)
	at org.spark_project.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
	at org.spark_project.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
	at org.spark_project.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
	at java.lang.Thread.run(Thread.java:745)
2021-12-06 14:58:25,242 [SparkUI-37] WARN [org.spark_project.jetty.servlet.ServletHandler] - Error for /static/webui.css
java.lang.NoSuchMethodError: javax.servlet.http.HttpServletRequest.isAsyncSupported()Z
	at org.spark_project.jetty.servlet.DefaultServlet.sendData(DefaultServlet.java:909)
	at org.spark_project.jetty.servlet.DefaultServlet.doGet(DefaultServlet.java:526)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:707)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:820)
	at org.spark_project.jetty.servlet.ServletHolder.handle(ServletHolder.java:848)
	at org.spark_project.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:584)
	at org.spark_project.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
	at org.spark_project.jetty.servlet.ServletHandler.doScope(ServletHandler.java:512)
	at org.spark_project.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
	at org.spark_project.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.spark_project.jetty.server.handler.gzip.GzipHandler.handle(GzipHandler.java:493)
	at org.spark_project.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:213)
	at org.spark_project.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
	at org.spark_project.jetty.server.Server.handle(Server.java:534)
	at org.spark_project.jetty.server.HttpChannel.handle(HttpChannel.java:320)
	at org.spark_project.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
	at org.spark_project.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
	at org.spark_project.jetty.io.FillInterest.fillable(FillInterest.java:108)
	at org.spark_project.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
	at org.spark_project.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
	at org.spark_project.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
	at java.lang.Thread.run(Thread.java:745)
2021-12-06 14:58:25,242 [SparkUI-71] WARN [org.spark_project.jetty.servlet.ServletHandler] - Error for /static/timeline-view.css
java.lang.NoSuchMethodError: javax.servlet.http.HttpServletRequest.isAsyncSupported()Z
	at org.spark_project.jetty.servlet.DefaultServlet.sendData(DefaultServlet.java:909)
	at org.spark_project.jetty.servlet.DefaultServlet.doGet(DefaultServlet.java:526)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:707)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:820)
	at org.spark_project.jetty.servlet.ServletHolder.handle(ServletHolder.java:848)
	at org.spark_project.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:584)
	at org.spark_project.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
	at org.spark_project.jetty.servlet.ServletHandler.doScope(ServletHandler.java:512)
	at org.spark_project.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
	at org.spark_project.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.spark_project.jetty.server.handler.gzip.GzipHandler.handle(GzipHandler.java:493)
	at org.spark_project.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:213)
	at org.spark_project.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
	at org.spark_project.jetty.server.Server.handle(Server.java:534)
	at org.spark_project.jetty.server.HttpChannel.handle(HttpChannel.java:320)
	at org.spark_project.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
	at org.spark_project.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
	at org.spark_project.jetty.io.FillInterest.fillable(FillInterest.java:108)
	at org.spark_project.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
	at org.spark_project.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
	at org.spark_project.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
	at java.lang.Thread.run(Thread.java:745)
2021-12-06 14:58:25,246 [Executor task launch worker for task 9] INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 4.0 (TID 9). 1032 bytes result sent to driver
2021-12-06 14:58:25,246 [SparkUI-37] WARN [org.spark_project.jetty.server.HttpChannel] - //qb:4040/static/webui.css
java.lang.NoSuchMethodError: javax.servlet.http.HttpServletRequest.isAsyncStarted()Z
	at org.spark_project.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:688)
	at org.spark_project.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
	at org.spark_project.jetty.servlet.ServletHandler.doScope(ServletHandler.java:512)
	at org.spark_project.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
	at org.spark_project.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.spark_project.jetty.server.handler.gzip.GzipHandler.handle(GzipHandler.java:493)
	at org.spark_project.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:213)
	at org.spark_project.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
	at org.spark_project.jetty.server.Server.handle(Server.java:534)
	at org.spark_project.jetty.server.HttpChannel.handle(HttpChannel.java:320)
	at org.spark_project.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
	at org.spark_project.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
	at org.spark_project.jetty.io.FillInterest.fillable(FillInterest.java:108)
	at org.spark_project.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
	at org.spark_project.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
	at org.spark_project.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
	at java.lang.Thread.run(Thread.java:745)
2021-12-06 14:58:25,246 [SparkUI-71] WARN [org.spark_project.jetty.server.HttpChannel] - //qb:4040/static/timeline-view.css
java.lang.NoSuchMethodError: javax.servlet.http.HttpServletRequest.isAsyncStarted()Z
	at org.spark_project.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:688)
	at org.spark_project.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
	at org.spark_project.jetty.servlet.ServletHandler.doScope(ServletHandler.java:512)
	at org.spark_project.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
	at org.spark_project.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.spark_project.jetty.server.handler.gzip.GzipHandler.handle(GzipHandler.java:493)
	at org.spark_project.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:213)
	at org.spark_project.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
	at org.spark_project.jetty.server.Server.handle(Server.java:534)
	at org.spark_project.jetty.server.HttpChannel.handle(HttpChannel.java:320)
	at org.spark_project.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
	at org.spark_project.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
	at org.spark_project.jetty.io.FillInterest.fillable(FillInterest.java:108)
	at org.spark_project.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
	at org.spark_project.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
	at org.spark_project.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
	at java.lang.Thread.run(Thread.java:745)
2021-12-06 14:58:25,246 [SparkUI-44] WARN [org.spark_project.jetty.server.HttpChannel] - //qb:4040/static/bootstrap.min.css
java.lang.NoSuchMethodError: javax.servlet.http.HttpServletRequest.isAsyncStarted()Z
	at org.spark_project.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:688)
	at org.spark_project.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
	at org.spark_project.jetty.servlet.ServletHandler.doScope(ServletHandler.java:512)
	at org.spark_project.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
	at org.spark_project.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.spark_project.jetty.server.handler.gzip.GzipHandler.handle(GzipHandler.java:493)
	at org.spark_project.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:213)
	at org.spark_project.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
	at org.spark_project.jetty.server.Server.handle(Server.java:534)
	at org.spark_project.jetty.server.HttpChannel.handle(HttpChannel.java:320)
	at org.spark_project.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
	at org.spark_project.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
	at org.spark_project.jetty.io.FillInterest.fillable(FillInterest.java:108)
	at org.spark_project.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
	at org.spark_project.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
	at org.spark_project.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
	at java.lang.Thread.run(Thread.java:745)
2021-12-06 14:58:25,246 [SparkUI-43] WARN [org.spark_project.jetty.server.HttpChannel] - //qb:4040/static/vis.min.css
java.lang.NoSuchMethodError: javax.servlet.http.HttpServletRequest.isAsyncStarted()Z
	at org.spark_project.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:688)
	at org.spark_project.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
	at org.spark_project.jetty.servlet.ServletHandler.doScope(ServletHandler.java:512)
	at org.spark_project.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
	at org.spark_project.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.spark_project.jetty.server.handler.gzip.GzipHandler.handle(GzipHandler.java:493)
	at org.spark_project.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:213)
	at org.spark_project.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
	at org.spark_project.jetty.server.Server.handle(Server.java:534)
	at org.spark_project.jetty.server.HttpChannel.handle(HttpChannel.java:320)
	at org.spark_project.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
	at org.spark_project.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
	at org.spark_project.jetty.io.FillInterest.fillable(FillInterest.java:108)
	at org.spark_project.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
	at org.spark_project.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
	at org.spark_project.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
	at java.lang.Thread.run(Thread.java:745)
2021-12-06 14:58:25,247 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 4.0 (TID 9) in 1167 ms on localhost (executor driver) (2/2)
2021-12-06 14:58:25,247 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 4.0, whose tasks have all completed, from pool 
2021-12-06 14:58:25,248 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ShuffleMapStage 4 (distinct at PaidPromotionAdjustParameter.scala:128) finished in 1.182 s
2021-12-06 14:58:25,249 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - looking for newly runnable stages
2021-12-06 14:58:25,250 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - running: Set()
2021-12-06 14:58:25,251 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - waiting: Set(ResultStage 5)
2021-12-06 14:58:25,251 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - failed: Set()
2021-12-06 14:58:25,253 [SparkUI-71] INFO [org.spark_project.jetty.servlet.DefaultServlet] - content=ResourceHttpContent@239d7625{r=jar:file:/C:/Users/ACER/.m2/repository/org/apache/spark/spark-core_2.11/2.3.0/spark-core_2.11-2.3.0.jar!/org/apache/spark/ui/static/vis.min.css,gz=false}
2021-12-06 14:58:25,253 [SparkUI-71] WARN [org.spark_project.jetty.servlet.ServletHandler] - Error for /static/vis.min.css
java.lang.NoSuchMethodError: javax.servlet.http.HttpServletRequest.isAsyncSupported()Z
	at org.spark_project.jetty.servlet.DefaultServlet.sendData(DefaultServlet.java:909)
	at org.spark_project.jetty.servlet.DefaultServlet.doGet(DefaultServlet.java:526)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:707)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:820)
	at org.spark_project.jetty.servlet.ServletHolder.handle(ServletHolder.java:848)
	at org.spark_project.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:584)
	at org.spark_project.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
	at org.spark_project.jetty.servlet.ServletHandler.doScope(ServletHandler.java:512)
	at org.spark_project.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
	at org.spark_project.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.spark_project.jetty.server.handler.gzip.GzipHandler.handle(GzipHandler.java:493)
	at org.spark_project.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:213)
	at org.spark_project.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
	at org.spark_project.jetty.server.Server.handle(Server.java:534)
	at org.spark_project.jetty.server.HttpChannel.handle(HttpChannel.java:320)
	at org.spark_project.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
	at org.spark_project.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
	at org.spark_project.jetty.io.FillInterest.fillable(FillInterest.java:108)
	at org.spark_project.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
	at org.spark_project.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
	at org.spark_project.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
	at java.lang.Thread.run(Thread.java:745)
2021-12-06 14:58:25,253 [SparkUI-37] INFO [org.spark_project.jetty.servlet.DefaultServlet] - content=ResourceHttpContent@6d8ad6cc{r=jar:file:/C:/Users/ACER/.m2/repository/org/apache/spark/spark-core_2.11/2.3.0/spark-core_2.11-2.3.0.jar!/org/apache/spark/ui/static/bootstrap.min.css,gz=false}
2021-12-06 14:58:25,254 [SparkUI-37] WARN [org.spark_project.jetty.servlet.ServletHandler] - Error for /static/bootstrap.min.css
java.lang.NoSuchMethodError: javax.servlet.http.HttpServletRequest.isAsyncSupported()Z
	at org.spark_project.jetty.servlet.DefaultServlet.sendData(DefaultServlet.java:909)
	at org.spark_project.jetty.servlet.DefaultServlet.doGet(DefaultServlet.java:526)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:707)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:820)
	at org.spark_project.jetty.servlet.ServletHolder.handle(ServletHolder.java:848)
	at org.spark_project.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:584)
	at org.spark_project.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
	at org.spark_project.jetty.servlet.ServletHandler.doScope(ServletHandler.java:512)
	at org.spark_project.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
	at org.spark_project.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.spark_project.jetty.server.handler.gzip.GzipHandler.handle(GzipHandler.java:493)
	at org.spark_project.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:213)
	at org.spark_project.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
	at org.spark_project.jetty.server.Server.handle(Server.java:534)
	at org.spark_project.jetty.server.HttpChannel.handle(HttpChannel.java:320)
	at org.spark_project.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
	at org.spark_project.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
	at org.spark_project.jetty.io.FillInterest.fillable(FillInterest.java:108)
	at org.spark_project.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
	at org.spark_project.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
	at org.spark_project.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
	at java.lang.Thread.run(Thread.java:745)
2021-12-06 14:58:25,254 [SparkUI-71] WARN [org.spark_project.jetty.server.HttpChannel] - //qb:4040/static/vis.min.css
java.lang.NoSuchMethodError: javax.servlet.http.HttpServletRequest.isAsyncStarted()Z
	at org.spark_project.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:688)
	at org.spark_project.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
	at org.spark_project.jetty.servlet.ServletHandler.doScope(ServletHandler.java:512)
	at org.spark_project.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
	at org.spark_project.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.spark_project.jetty.server.handler.gzip.GzipHandler.handle(GzipHandler.java:493)
	at org.spark_project.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:213)
	at org.spark_project.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
	at org.spark_project.jetty.server.Server.handle(Server.java:534)
	at org.spark_project.jetty.server.HttpChannel.handle(HttpChannel.java:320)
	at org.spark_project.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
	at org.spark_project.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
	at org.spark_project.jetty.io.FillInterest.fillable(FillInterest.java:108)
	at org.spark_project.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
	at org.spark_project.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
	at org.spark_project.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
	at java.lang.Thread.run(Thread.java:745)
2021-12-06 14:58:25,254 [SparkUI-37] WARN [org.spark_project.jetty.server.HttpChannel] - //qb:4040/static/bootstrap.min.css
java.lang.NoSuchMethodError: javax.servlet.http.HttpServletRequest.isAsyncStarted()Z
	at org.spark_project.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:688)
	at org.spark_project.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
	at org.spark_project.jetty.servlet.ServletHandler.doScope(ServletHandler.java:512)
	at org.spark_project.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
	at org.spark_project.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.spark_project.jetty.server.handler.gzip.GzipHandler.handle(GzipHandler.java:493)
	at org.spark_project.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:213)
	at org.spark_project.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
	at org.spark_project.jetty.server.Server.handle(Server.java:534)
	at org.spark_project.jetty.server.HttpChannel.handle(HttpChannel.java:320)
	at org.spark_project.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
	at org.spark_project.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
	at org.spark_project.jetty.io.FillInterest.fillable(FillInterest.java:108)
	at org.spark_project.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
	at org.spark_project.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
	at org.spark_project.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
	at java.lang.Thread.run(Thread.java:745)
2021-12-06 14:58:25,257 [SparkUI-74] INFO [org.spark_project.jetty.servlet.DefaultServlet] - content=ResourceHttpContent@703d4f9b{r=jar:file:/C:/Users/ACER/.m2/repository/org/apache/spark/spark-core_2.11/2.3.0/spark-core_2.11-2.3.0.jar!/org/apache/spark/ui/static/sorttable.js,gz=false}
2021-12-06 14:58:25,257 [SparkUI-74] WARN [org.spark_project.jetty.servlet.ServletHandler] - Error for /static/sorttable.js
java.lang.NoSuchMethodError: javax.servlet.http.HttpServletRequest.isAsyncSupported()Z
	at org.spark_project.jetty.servlet.DefaultServlet.sendData(DefaultServlet.java:909)
	at org.spark_project.jetty.servlet.DefaultServlet.doGet(DefaultServlet.java:526)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:707)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:820)
	at org.spark_project.jetty.servlet.ServletHolder.handle(ServletHolder.java:848)
	at org.spark_project.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:584)
	at org.spark_project.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
	at org.spark_project.jetty.servlet.ServletHandler.doScope(ServletHandler.java:512)
	at org.spark_project.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
	at org.spark_project.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.spark_project.jetty.server.handler.gzip.GzipHandler.handle(GzipHandler.java:493)
	at org.spark_project.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:213)
	at org.spark_project.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
	at org.spark_project.jetty.server.Server.handle(Server.java:534)
	at org.spark_project.jetty.server.HttpChannel.handle(HttpChannel.java:320)
	at org.spark_project.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
	at org.spark_project.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
	at org.spark_project.jetty.io.FillInterest.fillable(FillInterest.java:108)
	at org.spark_project.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
	at org.spark_project.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
	at org.spark_project.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
	at java.lang.Thread.run(Thread.java:745)
2021-12-06 14:58:25,257 [SparkUI-74] WARN [org.spark_project.jetty.server.HttpChannel] - //qb:4040/static/sorttable.js
java.lang.NoSuchMethodError: javax.servlet.http.HttpServletRequest.isAsyncStarted()Z
	at org.spark_project.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:688)
	at org.spark_project.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
	at org.spark_project.jetty.servlet.ServletHandler.doScope(ServletHandler.java:512)
	at org.spark_project.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
	at org.spark_project.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.spark_project.jetty.server.handler.gzip.GzipHandler.handle(GzipHandler.java:493)
	at org.spark_project.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:213)
	at org.spark_project.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
	at org.spark_project.jetty.server.Server.handle(Server.java:534)
	at org.spark_project.jetty.server.HttpChannel.handle(HttpChannel.java:320)
	at org.spark_project.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
	at org.spark_project.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
	at org.spark_project.jetty.io.FillInterest.fillable(FillInterest.java:108)
	at org.spark_project.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
	at org.spark_project.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
	at org.spark_project.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
	at java.lang.Thread.run(Thread.java:745)
2021-12-06 14:58:25,257 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 5 (MapPartitionsRDD[8] at distinct at PaidPromotionAdjustParameter.scala:128), which has no missing parents
2021-12-06 14:58:25,258 [SparkUI-43] INFO [org.spark_project.jetty.servlet.DefaultServlet] - content=ResourceHttpContent@79e1feb9{r=jar:file:/C:/Users/ACER/.m2/repository/org/apache/spark/spark-core_2.11/2.3.0/spark-core_2.11-2.3.0.jar!/org/apache/spark/ui/static/jquery-1.11.1.min.js,gz=false}
2021-12-06 14:58:25,258 [SparkUI-38] INFO [org.spark_project.jetty.servlet.DefaultServlet] - content=ResourceHttpContent@106d6eae{r=jar:file:/C:/Users/ACER/.m2/repository/org/apache/spark/spark-core_2.11/2.3.0/spark-core_2.11-2.3.0.jar!/org/apache/spark/ui/static/vis.min.js,gz=false}
2021-12-06 14:58:25,258 [SparkUI-43] WARN [org.spark_project.jetty.servlet.ServletHandler] - Error for /static/jquery-1.11.1.min.js
java.lang.NoSuchMethodError: javax.servlet.http.HttpServletRequest.isAsyncSupported()Z
	at org.spark_project.jetty.servlet.DefaultServlet.sendData(DefaultServlet.java:909)
	at org.spark_project.jetty.servlet.DefaultServlet.doGet(DefaultServlet.java:526)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:707)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:820)
	at org.spark_project.jetty.servlet.ServletHolder.handle(ServletHolder.java:848)
	at org.spark_project.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:584)
	at org.spark_project.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
	at org.spark_project.jetty.servlet.ServletHandler.doScope(ServletHandler.java:512)
	at org.spark_project.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
	at org.spark_project.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.spark_project.jetty.server.handler.gzip.GzipHandler.handle(GzipHandler.java:493)
	at org.spark_project.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:213)
	at org.spark_project.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
	at org.spark_project.jetty.server.Server.handle(Server.java:534)
	at org.spark_project.jetty.server.HttpChannel.handle(HttpChannel.java:320)
	at org.spark_project.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
	at org.spark_project.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
	at org.spark_project.jetty.io.FillInterest.fillable(FillInterest.java:108)
	at org.spark_project.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
	at org.spark_project.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
	at org.spark_project.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
	at java.lang.Thread.run(Thread.java:745)
2021-12-06 14:58:25,258 [SparkUI-38] WARN [org.spark_project.jetty.servlet.ServletHandler] - Error for /static/vis.min.js
java.lang.NoSuchMethodError: javax.servlet.http.HttpServletRequest.isAsyncSupported()Z
	at org.spark_project.jetty.servlet.DefaultServlet.sendData(DefaultServlet.java:909)
	at org.spark_project.jetty.servlet.DefaultServlet.doGet(DefaultServlet.java:526)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:707)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:820)
	at org.spark_project.jetty.servlet.ServletHolder.handle(ServletHolder.java:848)
	at org.spark_project.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:584)
	at org.spark_project.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
	at org.spark_project.jetty.servlet.ServletHandler.doScope(ServletHandler.java:512)
	at org.spark_project.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
	at org.spark_project.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.spark_project.jetty.server.handler.gzip.GzipHandler.handle(GzipHandler.java:493)
	at org.spark_project.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:213)
	at org.spark_project.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
	at org.spark_project.jetty.server.Server.handle(Server.java:534)
	at org.spark_project.jetty.server.HttpChannel.handle(HttpChannel.java:320)
	at org.spark_project.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
	at org.spark_project.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
	at org.spark_project.jetty.io.FillInterest.fillable(FillInterest.java:108)
	at org.spark_project.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
	at org.spark_project.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
	at org.spark_project.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
	at java.lang.Thread.run(Thread.java:745)
2021-12-06 14:58:25,258 [SparkUI-38] WARN [org.spark_project.jetty.server.HttpChannel] - //qb:4040/static/vis.min.js
java.lang.NoSuchMethodError: javax.servlet.http.HttpServletRequest.isAsyncStarted()Z
	at org.spark_project.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:688)
	at org.spark_project.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
	at org.spark_project.jetty.servlet.ServletHandler.doScope(ServletHandler.java:512)
	at org.spark_project.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
	at org.spark_project.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.spark_project.jetty.server.handler.gzip.GzipHandler.handle(GzipHandler.java:493)
	at org.spark_project.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:213)
	at org.spark_project.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
	at org.spark_project.jetty.server.Server.handle(Server.java:534)
	at org.spark_project.jetty.server.HttpChannel.handle(HttpChannel.java:320)
	at org.spark_project.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
	at org.spark_project.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
	at org.spark_project.jetty.io.FillInterest.fillable(FillInterest.java:108)
	at org.spark_project.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
	at org.spark_project.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
	at org.spark_project.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
	at java.lang.Thread.run(Thread.java:745)
2021-12-06 14:58:25,258 [SparkUI-43] WARN [org.spark_project.jetty.server.HttpChannel] - //qb:4040/static/jquery-1.11.1.min.js
java.lang.NoSuchMethodError: javax.servlet.http.HttpServletRequest.isAsyncStarted()Z
	at org.spark_project.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:688)
	at org.spark_project.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
	at org.spark_project.jetty.servlet.ServletHandler.doScope(ServletHandler.java:512)
	at org.spark_project.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
	at org.spark_project.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.spark_project.jetty.server.handler.gzip.GzipHandler.handle(GzipHandler.java:493)
	at org.spark_project.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:213)
	at org.spark_project.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
	at org.spark_project.jetty.server.Server.handle(Server.java:534)
	at org.spark_project.jetty.server.HttpChannel.handle(HttpChannel.java:320)
	at org.spark_project.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
	at org.spark_project.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
	at org.spark_project.jetty.io.FillInterest.fillable(FillInterest.java:108)
	at org.spark_project.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
	at org.spark_project.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
	at org.spark_project.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
	at java.lang.Thread.run(Thread.java:745)
2021-12-06 14:58:25,261 [SparkUI-39] INFO [org.spark_project.jetty.servlet.DefaultServlet] - content=ResourceHttpContent@4bd8b0dd{r=jar:file:/C:/Users/ACER/.m2/repository/org/apache/spark/spark-core_2.11/2.3.0/spark-core_2.11-2.3.0.jar!/org/apache/spark/ui/static/bootstrap-tooltip.js,gz=false}
2021-12-06 14:58:25,261 [SparkUI-75] INFO [org.spark_project.jetty.servlet.DefaultServlet] - content=ResourceHttpContent@6095cb33{r=jar:file:/C:/Users/ACER/.m2/repository/org/apache/spark/spark-core_2.11/2.3.0/spark-core_2.11-2.3.0.jar!/org/apache/spark/ui/static/initialize-tooltips.js,gz=false}
2021-12-06 14:58:25,261 [SparkUI-39] WARN [org.spark_project.jetty.servlet.ServletHandler] - Error for /static/bootstrap-tooltip.js
java.lang.NoSuchMethodError: javax.servlet.http.HttpServletRequest.isAsyncSupported()Z
	at org.spark_project.jetty.servlet.DefaultServlet.sendData(DefaultServlet.java:909)
	at org.spark_project.jetty.servlet.DefaultServlet.doGet(DefaultServlet.java:526)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:707)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:820)
	at org.spark_project.jetty.servlet.ServletHolder.handle(ServletHolder.java:848)
	at org.spark_project.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:584)
	at org.spark_project.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
	at org.spark_project.jetty.servlet.ServletHandler.doScope(ServletHandler.java:512)
	at org.spark_project.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
	at org.spark_project.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.spark_project.jetty.server.handler.gzip.GzipHandler.handle(GzipHandler.java:493)
	at org.spark_project.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:213)
	at org.spark_project.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
	at org.spark_project.jetty.server.Server.handle(Server.java:534)
	at org.spark_project.jetty.server.HttpChannel.handle(HttpChannel.java:320)
	at org.spark_project.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
	at org.spark_project.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
	at org.spark_project.jetty.io.FillInterest.fillable(FillInterest.java:108)
	at org.spark_project.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
	at org.spark_project.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
	at org.spark_project.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
	at java.lang.Thread.run(Thread.java:745)
2021-12-06 14:58:25,261 [SparkUI-75] WARN [org.spark_project.jetty.servlet.ServletHandler] - Error for /static/initialize-tooltips.js
java.lang.NoSuchMethodError: javax.servlet.http.HttpServletRequest.isAsyncSupported()Z
	at org.spark_project.jetty.servlet.DefaultServlet.sendData(DefaultServlet.java:909)
	at org.spark_project.jetty.servlet.DefaultServlet.doGet(DefaultServlet.java:526)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:707)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:820)
	at org.spark_project.jetty.servlet.ServletHolder.handle(ServletHolder.java:848)
	at org.spark_project.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:584)
	at org.spark_project.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
	at org.spark_project.jetty.servlet.ServletHandler.doScope(ServletHandler.java:512)
	at org.spark_project.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
	at org.spark_project.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.spark_project.jetty.server.handler.gzip.GzipHandler.handle(GzipHandler.java:493)
	at org.spark_project.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:213)
	at org.spark_project.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
	at org.spark_project.jetty.server.Server.handle(Server.java:534)
	at org.spark_project.jetty.server.HttpChannel.handle(HttpChannel.java:320)
	at org.spark_project.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
	at org.spark_project.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
	at org.spark_project.jetty.io.FillInterest.fillable(FillInterest.java:108)
	at org.spark_project.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
	at org.spark_project.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
	at org.spark_project.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
	at java.lang.Thread.run(Thread.java:745)
2021-12-06 14:58:25,262 [SparkUI-39] WARN [org.spark_project.jetty.server.HttpChannel] - //qb:4040/static/bootstrap-tooltip.js
java.lang.NoSuchMethodError: javax.servlet.http.HttpServletRequest.isAsyncStarted()Z
	at org.spark_project.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:688)
	at org.spark_project.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
	at org.spark_project.jetty.servlet.ServletHandler.doScope(ServletHandler.java:512)
	at org.spark_project.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
	at org.spark_project.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.spark_project.jetty.server.handler.gzip.GzipHandler.handle(GzipHandler.java:493)
	at org.spark_project.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:213)
	at org.spark_project.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
	at org.spark_project.jetty.server.Server.handle(Server.java:534)
	at org.spark_project.jetty.server.HttpChannel.handle(HttpChannel.java:320)
	at org.spark_project.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
	at org.spark_project.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
	at org.spark_project.jetty.io.FillInterest.fillable(FillInterest.java:108)
	at org.spark_project.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
	at org.spark_project.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
	at org.spark_project.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
	at java.lang.Thread.run(Thread.java:745)
2021-12-06 14:58:25,262 [SparkUI-75] WARN [org.spark_project.jetty.server.HttpChannel] - //qb:4040/static/initialize-tooltips.js
java.lang.NoSuchMethodError: javax.servlet.http.HttpServletRequest.isAsyncStarted()Z
	at org.spark_project.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:688)
	at org.spark_project.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
	at org.spark_project.jetty.servlet.ServletHandler.doScope(ServletHandler.java:512)
	at org.spark_project.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
	at org.spark_project.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.spark_project.jetty.server.handler.gzip.GzipHandler.handle(GzipHandler.java:493)
	at org.spark_project.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:213)
	at org.spark_project.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
	at org.spark_project.jetty.server.Server.handle(Server.java:534)
	at org.spark_project.jetty.server.HttpChannel.handle(HttpChannel.java:320)
	at org.spark_project.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
	at org.spark_project.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
	at org.spark_project.jetty.io.FillInterest.fillable(FillInterest.java:108)
	at org.spark_project.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
	at org.spark_project.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
	at org.spark_project.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
	at java.lang.Thread.run(Thread.java:745)
2021-12-06 14:58:25,263 [SparkUI-71] INFO [org.spark_project.jetty.servlet.DefaultServlet] - content=ResourceHttpContent@14c6469a{r=jar:file:/C:/Users/ACER/.m2/repository/org/apache/spark/spark-core_2.11/2.3.0/spark-core_2.11-2.3.0.jar!/org/apache/spark/ui/static/table.js,gz=false}
2021-12-06 14:58:25,263 [SparkUI-71] WARN [org.spark_project.jetty.servlet.ServletHandler] - Error for /static/table.js
java.lang.NoSuchMethodError: javax.servlet.http.HttpServletRequest.isAsyncSupported()Z
	at org.spark_project.jetty.servlet.DefaultServlet.sendData(DefaultServlet.java:909)
	at org.spark_project.jetty.servlet.DefaultServlet.doGet(DefaultServlet.java:526)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:707)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:820)
	at org.spark_project.jetty.servlet.ServletHolder.handle(ServletHolder.java:848)
	at org.spark_project.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:584)
	at org.spark_project.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
	at org.spark_project.jetty.servlet.ServletHandler.doScope(ServletHandler.java:512)
	at org.spark_project.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
	at org.spark_project.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.spark_project.jetty.server.handler.gzip.GzipHandler.handle(GzipHandler.java:493)
	at org.spark_project.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:213)
	at org.spark_project.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
	at org.spark_project.jetty.server.Server.handle(Server.java:534)
	at org.spark_project.jetty.server.HttpChannel.handle(HttpChannel.java:320)
	at org.spark_project.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
	at org.spark_project.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
	at org.spark_project.jetty.io.FillInterest.fillable(FillInterest.java:108)
	at org.spark_project.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
	at org.spark_project.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
	at org.spark_project.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
	at java.lang.Thread.run(Thread.java:745)
2021-12-06 14:58:25,264 [SparkUI-71] WARN [org.spark_project.jetty.server.HttpChannel] - //qb:4040/static/table.js
java.lang.NoSuchMethodError: javax.servlet.http.HttpServletRequest.isAsyncStarted()Z
	at org.spark_project.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:688)
	at org.spark_project.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
	at org.spark_project.jetty.servlet.ServletHandler.doScope(ServletHandler.java:512)
	at org.spark_project.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
	at org.spark_project.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.spark_project.jetty.server.handler.gzip.GzipHandler.handle(GzipHandler.java:493)
	at org.spark_project.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:213)
	at org.spark_project.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
	at org.spark_project.jetty.server.Server.handle(Server.java:534)
	at org.spark_project.jetty.server.HttpChannel.handle(HttpChannel.java:320)
	at org.spark_project.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
	at org.spark_project.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
	at org.spark_project.jetty.io.FillInterest.fillable(FillInterest.java:108)
	at org.spark_project.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
	at org.spark_project.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
	at org.spark_project.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
	at java.lang.Thread.run(Thread.java:745)
2021-12-06 14:58:25,266 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_6 stored as values in memory (estimated size 3.7 KB, free 1990.5 MB)
2021-12-06 14:58:25,267 [SparkUI-73] INFO [org.spark_project.jetty.servlet.DefaultServlet] - content=ResourceHttpContent@25b06f2a{r=jar:file:/C:/Users/ACER/.m2/repository/org/apache/spark/spark-core_2.11/2.3.0/spark-core_2.11-2.3.0.jar!/org/apache/spark/ui/static/additional-metrics.js,gz=false}
2021-12-06 14:58:25,267 [SparkUI-44] INFO [org.spark_project.jetty.servlet.DefaultServlet] - content=ResourceHttpContent@521204d0{r=jar:file:/C:/Users/ACER/.m2/repository/org/apache/spark/spark-core_2.11/2.3.0/spark-core_2.11-2.3.0.jar!/org/apache/spark/ui/static/log-view.js,gz=false}
2021-12-06 14:58:25,267 [SparkUI-75] INFO [org.spark_project.jetty.servlet.DefaultServlet] - content=ResourceHttpContent@4f4487f{r=jar:file:/C:/Users/ACER/.m2/repository/org/apache/spark/spark-core_2.11/2.3.0/spark-core_2.11-2.3.0.jar!/org/apache/spark/ui/static/timeline-view.js,gz=false}
2021-12-06 14:58:25,267 [SparkUI-44] WARN [org.spark_project.jetty.servlet.ServletHandler] - Error for /static/log-view.js
java.lang.NoSuchMethodError: javax.servlet.http.HttpServletRequest.isAsyncSupported()Z
	at org.spark_project.jetty.servlet.DefaultServlet.sendData(DefaultServlet.java:909)
	at org.spark_project.jetty.servlet.DefaultServlet.doGet(DefaultServlet.java:526)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:707)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:820)
	at org.spark_project.jetty.servlet.ServletHolder.handle(ServletHolder.java:848)
	at org.spark_project.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:584)
	at org.spark_project.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
	at org.spark_project.jetty.servlet.ServletHandler.doScope(ServletHandler.java:512)
	at org.spark_project.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
	at org.spark_project.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.spark_project.jetty.server.handler.gzip.GzipHandler.handle(GzipHandler.java:493)
	at org.spark_project.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:213)
	at org.spark_project.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
	at org.spark_project.jetty.server.Server.handle(Server.java:534)
	at org.spark_project.jetty.server.HttpChannel.handle(HttpChannel.java:320)
	at org.spark_project.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
	at org.spark_project.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
	at org.spark_project.jetty.io.FillInterest.fillable(FillInterest.java:108)
	at org.spark_project.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
	at org.spark_project.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
	at org.spark_project.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
	at java.lang.Thread.run(Thread.java:745)
2021-12-06 14:58:25,267 [SparkUI-75] WARN [org.spark_project.jetty.servlet.ServletHandler] - Error for /static/timeline-view.js
java.lang.NoSuchMethodError: javax.servlet.http.HttpServletRequest.isAsyncSupported()Z
	at org.spark_project.jetty.servlet.DefaultServlet.sendData(DefaultServlet.java:909)
	at org.spark_project.jetty.servlet.DefaultServlet.doGet(DefaultServlet.java:526)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:707)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:820)
	at org.spark_project.jetty.servlet.ServletHolder.handle(ServletHolder.java:848)
	at org.spark_project.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:584)
	at org.spark_project.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
	at org.spark_project.jetty.servlet.ServletHandler.doScope(ServletHandler.java:512)
	at org.spark_project.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
	at org.spark_project.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.spark_project.jetty.server.handler.gzip.GzipHandler.handle(GzipHandler.java:493)
	at org.spark_project.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:213)
	at org.spark_project.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
	at org.spark_project.jetty.server.Server.handle(Server.java:534)
	at org.spark_project.jetty.server.HttpChannel.handle(HttpChannel.java:320)
	at org.spark_project.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
	at org.spark_project.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
	at org.spark_project.jetty.io.FillInterest.fillable(FillInterest.java:108)
	at org.spark_project.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
	at org.spark_project.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
	at org.spark_project.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
	at java.lang.Thread.run(Thread.java:745)
2021-12-06 14:58:25,267 [SparkUI-73] WARN [org.spark_project.jetty.servlet.ServletHandler] - Error for /static/additional-metrics.js
java.lang.NoSuchMethodError: javax.servlet.http.HttpServletRequest.isAsyncSupported()Z
	at org.spark_project.jetty.servlet.DefaultServlet.sendData(DefaultServlet.java:909)
	at org.spark_project.jetty.servlet.DefaultServlet.doGet(DefaultServlet.java:526)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:707)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:820)
	at org.spark_project.jetty.servlet.ServletHolder.handle(ServletHolder.java:848)
	at org.spark_project.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:584)
	at org.spark_project.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
	at org.spark_project.jetty.servlet.ServletHandler.doScope(ServletHandler.java:512)
	at org.spark_project.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
	at org.spark_project.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.spark_project.jetty.server.handler.gzip.GzipHandler.handle(GzipHandler.java:493)
	at org.spark_project.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:213)
	at org.spark_project.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
	at org.spark_project.jetty.server.Server.handle(Server.java:534)
	at org.spark_project.jetty.server.HttpChannel.handle(HttpChannel.java:320)
	at org.spark_project.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
	at org.spark_project.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
	at org.spark_project.jetty.io.FillInterest.fillable(FillInterest.java:108)
	at org.spark_project.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
	at org.spark_project.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
	at org.spark_project.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
	at java.lang.Thread.run(Thread.java:745)
2021-12-06 14:58:25,267 [SparkUI-75] WARN [org.spark_project.jetty.server.HttpChannel] - //qb:4040/static/timeline-view.js
java.lang.NoSuchMethodError: javax.servlet.http.HttpServletRequest.isAsyncStarted()Z
	at org.spark_project.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:688)
	at org.spark_project.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
	at org.spark_project.jetty.servlet.ServletHandler.doScope(ServletHandler.java:512)
	at org.spark_project.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
	at org.spark_project.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.spark_project.jetty.server.handler.gzip.GzipHandler.handle(GzipHandler.java:493)
	at org.spark_project.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:213)
	at org.spark_project.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
	at org.spark_project.jetty.server.Server.handle(Server.java:534)
	at org.spark_project.jetty.server.HttpChannel.handle(HttpChannel.java:320)
	at org.spark_project.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
	at org.spark_project.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
	at org.spark_project.jetty.io.FillInterest.fillable(FillInterest.java:108)
	at org.spark_project.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
	at org.spark_project.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
	at org.spark_project.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
	at java.lang.Thread.run(Thread.java:745)
2021-12-06 14:58:25,267 [SparkUI-73] WARN [org.spark_project.jetty.server.HttpChannel] - //qb:4040/static/additional-metrics.js
java.lang.NoSuchMethodError: javax.servlet.http.HttpServletRequest.isAsyncStarted()Z
	at org.spark_project.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:688)
	at org.spark_project.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
	at org.spark_project.jetty.servlet.ServletHandler.doScope(ServletHandler.java:512)
	at org.spark_project.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
	at org.spark_project.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.spark_project.jetty.server.handler.gzip.GzipHandler.handle(GzipHandler.java:493)
	at org.spark_project.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:213)
	at org.spark_project.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
	at org.spark_project.jetty.server.Server.handle(Server.java:534)
	at org.spark_project.jetty.server.HttpChannel.handle(HttpChannel.java:320)
	at org.spark_project.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
	at org.spark_project.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
	at org.spark_project.jetty.io.FillInterest.fillable(FillInterest.java:108)
	at org.spark_project.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
	at org.spark_project.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
	at org.spark_project.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
	at java.lang.Thread.run(Thread.java:745)
2021-12-06 14:58:25,267 [SparkUI-44] WARN [org.spark_project.jetty.server.HttpChannel] - //qb:4040/static/log-view.js
java.lang.NoSuchMethodError: javax.servlet.http.HttpServletRequest.isAsyncStarted()Z
	at org.spark_project.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:688)
	at org.spark_project.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
	at org.spark_project.jetty.servlet.ServletHandler.doScope(ServletHandler.java:512)
	at org.spark_project.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
	at org.spark_project.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.spark_project.jetty.server.handler.gzip.GzipHandler.handle(GzipHandler.java:493)
	at org.spark_project.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:213)
	at org.spark_project.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
	at org.spark_project.jetty.server.Server.handle(Server.java:534)
	at org.spark_project.jetty.server.HttpChannel.handle(HttpChannel.java:320)
	at org.spark_project.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
	at org.spark_project.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
	at org.spark_project.jetty.io.FillInterest.fillable(FillInterest.java:108)
	at org.spark_project.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
	at org.spark_project.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
	at org.spark_project.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
	at java.lang.Thread.run(Thread.java:745)
2021-12-06 14:58:25,269 [SparkUI-38] INFO [org.spark_project.jetty.servlet.DefaultServlet] - content=ResourceHttpContent@3f76de96{r=jar:file:/C:/Users/ACER/.m2/repository/org/apache/spark/spark-core_2.11/2.3.0/spark-core_2.11-2.3.0.jar!/org/apache/spark/ui/static/webui.js,gz=false}
2021-12-06 14:58:25,269 [SparkUI-38] WARN [org.spark_project.jetty.servlet.ServletHandler] - Error for /static/webui.js
java.lang.NoSuchMethodError: javax.servlet.http.HttpServletRequest.isAsyncSupported()Z
	at org.spark_project.jetty.servlet.DefaultServlet.sendData(DefaultServlet.java:909)
	at org.spark_project.jetty.servlet.DefaultServlet.doGet(DefaultServlet.java:526)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:707)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:820)
	at org.spark_project.jetty.servlet.ServletHolder.handle(ServletHolder.java:848)
	at org.spark_project.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:584)
	at org.spark_project.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
	at org.spark_project.jetty.servlet.ServletHandler.doScope(ServletHandler.java:512)
	at org.spark_project.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
	at org.spark_project.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.spark_project.jetty.server.handler.gzip.GzipHandler.handle(GzipHandler.java:493)
	at org.spark_project.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:213)
	at org.spark_project.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
	at org.spark_project.jetty.server.Server.handle(Server.java:534)
	at org.spark_project.jetty.server.HttpChannel.handle(HttpChannel.java:320)
	at org.spark_project.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
	at org.spark_project.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
	at org.spark_project.jetty.io.FillInterest.fillable(FillInterest.java:108)
	at org.spark_project.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
	at org.spark_project.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
	at org.spark_project.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
	at java.lang.Thread.run(Thread.java:745)
2021-12-06 14:58:25,269 [SparkUI-38] WARN [org.spark_project.jetty.server.HttpChannel] - //qb:4040/static/webui.js
java.lang.NoSuchMethodError: javax.servlet.http.HttpServletRequest.isAsyncStarted()Z
	at org.spark_project.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:688)
	at org.spark_project.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
	at org.spark_project.jetty.servlet.ServletHandler.doScope(ServletHandler.java:512)
	at org.spark_project.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
	at org.spark_project.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.spark_project.jetty.server.handler.gzip.GzipHandler.handle(GzipHandler.java:493)
	at org.spark_project.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:213)
	at org.spark_project.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
	at org.spark_project.jetty.server.Server.handle(Server.java:534)
	at org.spark_project.jetty.server.HttpChannel.handle(HttpChannel.java:320)
	at org.spark_project.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
	at org.spark_project.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
	at org.spark_project.jetty.io.FillInterest.fillable(FillInterest.java:108)
	at org.spark_project.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
	at org.spark_project.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
	at org.spark_project.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
	at java.lang.Thread.run(Thread.java:745)
2021-12-06 14:58:25,270 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_6_piece0 stored as bytes in memory (estimated size 2.2 KB, free 1990.5 MB)
2021-12-06 14:58:25,271 [dispatcher-event-loop-7] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_6_piece0 in memory on qb:60678 (size: 2.2 KB, free: 1990.8 MB)
2021-12-06 14:58:25,272 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 6 from broadcast at DAGScheduler.scala:1039
2021-12-06 14:58:25,272 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from ResultStage 5 (MapPartitionsRDD[8] at distinct at PaidPromotionAdjustParameter.scala:128) (first 15 tasks are for partitions Vector(0, 1))
2021-12-06 14:58:25,272 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 5.0 with 2 tasks
2021-12-06 14:58:25,274 [SparkUI-74] INFO [org.spark_project.jetty.servlet.DefaultServlet] - content=ResourceHttpContent@42241ef5{r=jar:file:/C:/Users/ACER/.m2/repository/org/apache/spark/spark-core_2.11/2.3.0/spark-core_2.11-2.3.0.jar!/org/apache/spark/ui/static/spark-logo-77x50px-hd.png,gz=false}
2021-12-06 14:58:25,274 [SparkUI-74] WARN [org.spark_project.jetty.servlet.ServletHandler] - Error for /static/spark-logo-77x50px-hd.png
java.lang.NoSuchMethodError: javax.servlet.http.HttpServletRequest.isAsyncSupported()Z
	at org.spark_project.jetty.servlet.DefaultServlet.sendData(DefaultServlet.java:909)
	at org.spark_project.jetty.servlet.DefaultServlet.doGet(DefaultServlet.java:526)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:707)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:820)
	at org.spark_project.jetty.servlet.ServletHolder.handle(ServletHolder.java:848)
	at org.spark_project.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:584)
	at org.spark_project.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
	at org.spark_project.jetty.servlet.ServletHandler.doScope(ServletHandler.java:512)
	at org.spark_project.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
	at org.spark_project.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.spark_project.jetty.server.handler.gzip.GzipHandler.handle(GzipHandler.java:448)
	at org.spark_project.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:213)
	at org.spark_project.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
	at org.spark_project.jetty.server.Server.handle(Server.java:534)
	at org.spark_project.jetty.server.HttpChannel.handle(HttpChannel.java:320)
	at org.spark_project.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
	at org.spark_project.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
	at org.spark_project.jetty.io.FillInterest.fillable(FillInterest.java:108)
	at org.spark_project.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
	at org.spark_project.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
	at org.spark_project.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
	at java.lang.Thread.run(Thread.java:745)
2021-12-06 14:58:25,274 [dispatcher-event-loop-9] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 5.0 (TID 10, localhost, executor driver, partition 0, ANY, 7649 bytes)
2021-12-06 14:58:25,274 [SparkUI-74] WARN [org.spark_project.jetty.server.HttpChannel] - //qb:4040/static/spark-logo-77x50px-hd.png
java.lang.NoSuchMethodError: javax.servlet.http.HttpServletRequest.isAsyncStarted()Z
	at org.spark_project.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:688)
	at org.spark_project.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
	at org.spark_project.jetty.servlet.ServletHandler.doScope(ServletHandler.java:512)
	at org.spark_project.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
	at org.spark_project.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.spark_project.jetty.server.handler.gzip.GzipHandler.handle(GzipHandler.java:448)
	at org.spark_project.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:213)
	at org.spark_project.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
	at org.spark_project.jetty.server.Server.handle(Server.java:534)
	at org.spark_project.jetty.server.HttpChannel.handle(HttpChannel.java:320)
	at org.spark_project.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
	at org.spark_project.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
	at org.spark_project.jetty.io.FillInterest.fillable(FillInterest.java:108)
	at org.spark_project.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
	at org.spark_project.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
	at org.spark_project.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
	at java.lang.Thread.run(Thread.java:745)
2021-12-06 14:58:25,274 [dispatcher-event-loop-9] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 5.0 (TID 11, localhost, executor driver, partition 1, ANY, 7649 bytes)
2021-12-06 14:58:25,274 [Executor task launch worker for task 10] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 5.0 (TID 10)
2021-12-06 14:58:25,274 [Executor task launch worker for task 11] INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 5.0 (TID 11)
2021-12-06 14:58:25,285 [Executor task launch worker for task 11] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 2 non-empty blocks out of 2 blocks
2021-12-06 14:58:25,285 [Executor task launch worker for task 10] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 2 non-empty blocks out of 2 blocks
2021-12-06 14:58:25,287 [Executor task launch worker for task 11] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 5 ms
2021-12-06 14:58:25,287 [Executor task launch worker for task 10] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 5 ms
2021-12-06 14:58:25,420 [Executor task launch worker for task 11] INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 5.0 (TID 11). 1055 bytes result sent to driver
2021-12-06 14:58:25,420 [Executor task launch worker for task 10] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 5.0 (TID 10). 1055 bytes result sent to driver
2021-12-06 14:58:25,421 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 5.0 (TID 10) in 148 ms on localhost (executor driver) (1/2)
2021-12-06 14:58:25,421 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 5.0 (TID 11) in 147 ms on localhost (executor driver) (2/2)
2021-12-06 14:58:25,422 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 5.0, whose tasks have all completed, from pool 
2021-12-06 14:58:25,422 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 5 (count at PaidPromotionAdjustParameter.scala:138) finished in 0.161 s
2021-12-06 14:58:25,423 [main] INFO [org.apache.spark.scheduler.DAGScheduler] - Job 4 finished: count at PaidPromotionAdjustParameter.scala:138, took 1.367081 s
2021-12-06 14:58:25,423 [main] INFO [PaidPromotion$] -  = 44705
2021-12-06 14:58:25,425 [main] INFO [org.apache.spark.SparkContext] - Starting job: count at PaidPromotionAdjustParameter.scala:139
2021-12-06 14:58:25,426 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 10 (distinct at PaidPromotionAdjustParameter.scala:129)
2021-12-06 14:58:25,426 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 5 (count at PaidPromotionAdjustParameter.scala:139) with 2 output partitions
2021-12-06 14:58:25,426 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 7 (count at PaidPromotionAdjustParameter.scala:139)
2021-12-06 14:58:25,426 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 6)
2021-12-06 14:58:25,426 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List(ShuffleMapStage 6)
2021-12-06 14:58:25,426 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ShuffleMapStage 6 (MapPartitionsRDD[10] at distinct at PaidPromotionAdjustParameter.scala:129), which has no missing parents
2021-12-06 14:58:25,428 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_7 stored as values in memory (estimated size 5.2 KB, free 1990.4 MB)
2021-12-06 14:58:25,432 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_7_piece0 stored as bytes in memory (estimated size 2.9 KB, free 1990.4 MB)
2021-12-06 14:58:25,433 [dispatcher-event-loop-1] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_7_piece0 in memory on qb:60678 (size: 2.9 KB, free: 1990.8 MB)
2021-12-06 14:58:25,433 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 7 from broadcast at DAGScheduler.scala:1039
2021-12-06 14:58:25,434 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from ShuffleMapStage 6 (MapPartitionsRDD[10] at distinct at PaidPromotionAdjustParameter.scala:129) (first 15 tasks are for partitions Vector(0, 1))
2021-12-06 14:58:25,434 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 6.0 with 2 tasks
2021-12-06 14:58:25,435 [dispatcher-event-loop-4] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 6.0 (TID 12, localhost, executor driver, partition 0, ANY, 7885 bytes)
2021-12-06 14:58:25,435 [dispatcher-event-loop-4] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 6.0 (TID 13, localhost, executor driver, partition 1, ANY, 7885 bytes)
2021-12-06 14:58:25,435 [Executor task launch worker for task 12] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 6.0 (TID 12)
2021-12-06 14:58:25,435 [Executor task launch worker for task 13] INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 6.0 (TID 13)
2021-12-06 14:58:25,437 [Executor task launch worker for task 12] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/order_data.bcp:0+3442194
2021-12-06 14:58:25,437 [Executor task launch worker for task 13] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/order_data.bcp:3442194+3442195
2021-12-06 14:58:25,923 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 119
2021-12-06 14:58:25,923 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 134
2021-12-06 14:58:25,923 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 113
2021-12-06 14:58:25,924 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 133
2021-12-06 14:58:25,926 [dispatcher-event-loop-7] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_5_piece0 on qb:60678 in memory (size: 2.9 KB, free: 1990.8 MB)
2021-12-06 14:58:25,926 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 117
2021-12-06 14:58:25,926 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 124
2021-12-06 14:58:25,926 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 149
2021-12-06 14:58:25,926 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 109
2021-12-06 14:58:25,927 [dispatcher-event-loop-10] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_6_piece0 on qb:60678 in memory (size: 2.2 KB, free: 1990.8 MB)
2021-12-06 14:58:25,927 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 102
2021-12-06 14:58:25,927 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 141
2021-12-06 14:58:25,927 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 144
2021-12-06 14:58:25,927 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 132
2021-12-06 14:58:25,927 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 121
2021-12-06 14:58:25,927 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 108
2021-12-06 14:58:25,927 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 110
2021-12-06 14:58:25,927 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 120
2021-12-06 14:58:25,927 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 115
2021-12-06 14:58:25,927 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 107
2021-12-06 14:58:25,927 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 126
2021-12-06 14:58:25,927 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 103
2021-12-06 14:58:25,927 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 138
2021-12-06 14:58:25,927 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 106
2021-12-06 14:58:25,927 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 135
2021-12-06 14:58:25,927 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 111
2021-12-06 14:58:25,927 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 143
2021-12-06 14:58:25,927 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 128
2021-12-06 14:58:25,927 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 105
2021-12-06 14:58:25,927 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 140
2021-12-06 14:58:25,927 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 136
2021-12-06 14:58:25,927 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 123
2021-12-06 14:58:25,927 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 131
2021-12-06 14:58:25,927 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 137
2021-12-06 14:58:25,927 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 125
2021-12-06 14:58:25,927 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 127
2021-12-06 14:58:25,927 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 145
2021-12-06 14:58:25,927 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 116
2021-12-06 14:58:25,927 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 147
2021-12-06 14:58:25,927 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 148
2021-12-06 14:58:25,927 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 118
2021-12-06 14:58:25,928 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 101
2021-12-06 14:58:25,928 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 122
2021-12-06 14:58:25,928 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 129
2021-12-06 14:58:25,928 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 130
2021-12-06 14:58:25,928 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 112
2021-12-06 14:58:25,928 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 104
2021-12-06 14:58:25,928 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 142
2021-12-06 14:58:25,928 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 146
2021-12-06 14:58:25,928 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 139
2021-12-06 14:58:25,928 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 100
2021-12-06 14:58:25,928 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 114
2021-12-06 14:58:26,157 [Executor task launch worker for task 13] INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 6.0 (TID 13). 1075 bytes result sent to driver
2021-12-06 14:58:26,157 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 6.0 (TID 13) in 722 ms on localhost (executor driver) (1/2)
2021-12-06 14:58:27,749 [Executor task launch worker for task 12] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 6.0 (TID 12). 1032 bytes result sent to driver
2021-12-06 14:58:27,750 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 6.0 (TID 12) in 2316 ms on localhost (executor driver) (2/2)
2021-12-06 14:58:27,750 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 6.0, whose tasks have all completed, from pool 
2021-12-06 14:58:27,750 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ShuffleMapStage 6 (distinct at PaidPromotionAdjustParameter.scala:129) finished in 2.323 s
2021-12-06 14:58:27,750 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - looking for newly runnable stages
2021-12-06 14:58:27,750 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - running: Set()
2021-12-06 14:58:27,750 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - waiting: Set(ResultStage 7)
2021-12-06 14:58:27,750 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - failed: Set()
2021-12-06 14:58:27,750 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 7 (MapPartitionsRDD[12] at distinct at PaidPromotionAdjustParameter.scala:129), which has no missing parents
2021-12-06 14:58:27,751 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_8 stored as values in memory (estimated size 3.7 KB, free 1990.5 MB)
2021-12-06 14:58:27,754 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_8_piece0 stored as bytes in memory (estimated size 2.2 KB, free 1990.5 MB)
2021-12-06 14:58:27,754 [dispatcher-event-loop-1] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_8_piece0 in memory on qb:60678 (size: 2.2 KB, free: 1990.8 MB)
2021-12-06 14:58:27,754 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 8 from broadcast at DAGScheduler.scala:1039
2021-12-06 14:58:27,755 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from ResultStage 7 (MapPartitionsRDD[12] at distinct at PaidPromotionAdjustParameter.scala:129) (first 15 tasks are for partitions Vector(0, 1))
2021-12-06 14:58:27,755 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 7.0 with 2 tasks
2021-12-06 14:58:27,755 [dispatcher-event-loop-4] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 7.0 (TID 14, localhost, executor driver, partition 0, ANY, 7649 bytes)
2021-12-06 14:58:27,755 [dispatcher-event-loop-4] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 7.0 (TID 15, localhost, executor driver, partition 1, ANY, 7649 bytes)
2021-12-06 14:58:27,756 [Executor task launch worker for task 15] INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 7.0 (TID 15)
2021-12-06 14:58:27,756 [Executor task launch worker for task 14] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 7.0 (TID 14)
2021-12-06 14:58:27,757 [Executor task launch worker for task 15] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 2 non-empty blocks out of 2 blocks
2021-12-06 14:58:27,757 [Executor task launch worker for task 15] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-06 14:58:27,757 [Executor task launch worker for task 14] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 2 non-empty blocks out of 2 blocks
2021-12-06 14:58:27,757 [Executor task launch worker for task 14] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-06 14:58:27,799 [Executor task launch worker for task 15] INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 7.0 (TID 15). 1055 bytes result sent to driver
2021-12-06 14:58:27,799 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 7.0 (TID 15) in 44 ms on localhost (executor driver) (1/2)
2021-12-06 14:58:27,802 [Executor task launch worker for task 14] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 7.0 (TID 14). 1055 bytes result sent to driver
2021-12-06 14:58:27,802 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 7.0 (TID 14) in 47 ms on localhost (executor driver) (2/2)
2021-12-06 14:58:27,802 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 7.0, whose tasks have all completed, from pool 
2021-12-06 14:58:27,802 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 7 (count at PaidPromotionAdjustParameter.scala:139) finished in 0.051 s
2021-12-06 14:58:27,802 [main] INFO [org.apache.spark.scheduler.DAGScheduler] - Job 5 finished: count at PaidPromotionAdjustParameter.scala:139, took 2.376966 s
2021-12-06 14:58:27,803 [main] INFO [PaidPromotion$] -  = 55793
2021-12-06 14:58:27,807 [main] INFO [org.apache.spark.SparkContext] - Starting job: count at PaidPromotionAdjustParameter.scala:140
2021-12-06 14:58:27,808 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 14 (intersection at PaidPromotionAdjustParameter.scala:130)
2021-12-06 14:58:27,808 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 13 (intersection at PaidPromotionAdjustParameter.scala:130)
2021-12-06 14:58:27,808 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 6 (count at PaidPromotionAdjustParameter.scala:140) with 2 output partitions
2021-12-06 14:58:27,808 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 12 (count at PaidPromotionAdjustParameter.scala:140)
2021-12-06 14:58:27,808 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 9, ShuffleMapStage 11)
2021-12-06 14:58:27,808 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List(ShuffleMapStage 9, ShuffleMapStage 11)
2021-12-06 14:58:27,808 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ShuffleMapStage 9 (MapPartitionsRDD[14] at intersection at PaidPromotionAdjustParameter.scala:130), which has no missing parents
2021-12-06 14:58:27,810 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_9 stored as values in memory (estimated size 4.0 KB, free 1990.5 MB)
2021-12-06 14:58:27,812 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_9_piece0 stored as bytes in memory (estimated size 2.3 KB, free 1990.4 MB)
2021-12-06 14:58:27,813 [dispatcher-event-loop-7] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_9_piece0 in memory on qb:60678 (size: 2.3 KB, free: 1990.8 MB)
2021-12-06 14:58:27,813 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 9 from broadcast at DAGScheduler.scala:1039
2021-12-06 14:58:27,813 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from ShuffleMapStage 9 (MapPartitionsRDD[14] at intersection at PaidPromotionAdjustParameter.scala:130) (first 15 tasks are for partitions Vector(0, 1))
2021-12-06 14:58:27,813 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 9.0 with 2 tasks
2021-12-06 14:58:27,814 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ShuffleMapStage 11 (MapPartitionsRDD[13] at intersection at PaidPromotionAdjustParameter.scala:130), which has no missing parents
2021-12-06 14:58:27,814 [dispatcher-event-loop-8] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 9.0 (TID 16, localhost, executor driver, partition 0, ANY, 7638 bytes)
2021-12-06 14:58:27,814 [dispatcher-event-loop-8] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 9.0 (TID 17, localhost, executor driver, partition 1, ANY, 7638 bytes)
2021-12-06 14:58:27,814 [Executor task launch worker for task 17] INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 9.0 (TID 17)
2021-12-06 14:58:27,814 [Executor task launch worker for task 16] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 9.0 (TID 16)
2021-12-06 14:58:27,815 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_10 stored as values in memory (estimated size 4.0 KB, free 1990.4 MB)
2021-12-06 14:58:27,816 [Executor task launch worker for task 16] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 2 non-empty blocks out of 2 blocks
2021-12-06 14:58:27,816 [Executor task launch worker for task 16] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-06 14:58:27,816 [Executor task launch worker for task 17] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 2 non-empty blocks out of 2 blocks
2021-12-06 14:58:27,816 [Executor task launch worker for task 17] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-06 14:58:27,818 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_10_piece0 stored as bytes in memory (estimated size 2.3 KB, free 1990.4 MB)
2021-12-06 14:58:27,818 [dispatcher-event-loop-0] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_10_piece0 in memory on qb:60678 (size: 2.3 KB, free: 1990.8 MB)
2021-12-06 14:58:27,819 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 10 from broadcast at DAGScheduler.scala:1039
2021-12-06 14:58:27,819 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from ShuffleMapStage 11 (MapPartitionsRDD[13] at intersection at PaidPromotionAdjustParameter.scala:130) (first 15 tasks are for partitions Vector(0, 1))
2021-12-06 14:58:27,819 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 11.0 with 2 tasks
2021-12-06 14:58:27,820 [dispatcher-event-loop-11] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 11.0 (TID 18, localhost, executor driver, partition 0, ANY, 7638 bytes)
2021-12-06 14:58:27,820 [dispatcher-event-loop-11] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 11.0 (TID 19, localhost, executor driver, partition 1, ANY, 7638 bytes)
2021-12-06 14:58:27,820 [Executor task launch worker for task 18] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 11.0 (TID 18)
2021-12-06 14:58:27,821 [Executor task launch worker for task 19] INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 11.0 (TID 19)
2021-12-06 14:58:27,822 [Executor task launch worker for task 18] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 2 non-empty blocks out of 2 blocks
2021-12-06 14:58:27,822 [Executor task launch worker for task 19] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 2 non-empty blocks out of 2 blocks
2021-12-06 14:58:27,822 [Executor task launch worker for task 18] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-06 14:58:27,822 [Executor task launch worker for task 19] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-06 14:58:27,909 [Executor task launch worker for task 18] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 11.0 (TID 18). 1204 bytes result sent to driver
2021-12-06 14:58:27,909 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 11.0 (TID 18) in 90 ms on localhost (executor driver) (1/2)
2021-12-06 14:58:27,918 [Executor task launch worker for task 19] INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 11.0 (TID 19). 1204 bytes result sent to driver
2021-12-06 14:58:27,918 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 11.0 (TID 19) in 98 ms on localhost (executor driver) (2/2)
2021-12-06 14:58:27,918 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 11.0, whose tasks have all completed, from pool 
2021-12-06 14:58:27,919 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ShuffleMapStage 11 (intersection at PaidPromotionAdjustParameter.scala:130) finished in 0.105 s
2021-12-06 14:58:27,919 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - looking for newly runnable stages
2021-12-06 14:58:27,919 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - running: Set(ShuffleMapStage 9)
2021-12-06 14:58:27,919 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - waiting: Set(ResultStage 12)
2021-12-06 14:58:27,919 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - failed: Set()
2021-12-06 14:58:27,922 [Executor task launch worker for task 17] INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 9.0 (TID 17). 1204 bytes result sent to driver
2021-12-06 14:58:27,922 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 9.0 (TID 17) in 108 ms on localhost (executor driver) (1/2)
2021-12-06 14:58:27,924 [Executor task launch worker for task 16] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 9.0 (TID 16). 1204 bytes result sent to driver
2021-12-06 14:58:27,924 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 9.0 (TID 16) in 110 ms on localhost (executor driver) (2/2)
2021-12-06 14:58:27,924 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 9.0, whose tasks have all completed, from pool 
2021-12-06 14:58:27,925 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ShuffleMapStage 9 (intersection at PaidPromotionAdjustParameter.scala:130) finished in 0.116 s
2021-12-06 14:58:27,925 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - looking for newly runnable stages
2021-12-06 14:58:27,925 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - running: Set()
2021-12-06 14:58:27,925 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - waiting: Set(ResultStage 12)
2021-12-06 14:58:27,925 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - failed: Set()
2021-12-06 14:58:27,925 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 12 (MapPartitionsRDD[18] at intersection at PaidPromotionAdjustParameter.scala:130), which has no missing parents
2021-12-06 14:58:27,927 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_11 stored as values in memory (estimated size 3.6 KB, free 1990.4 MB)
2021-12-06 14:58:27,932 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 183
2021-12-06 14:58:27,932 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 172
2021-12-06 14:58:27,932 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 191
2021-12-06 14:58:27,932 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 189
2021-12-06 14:58:27,932 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 153
2021-12-06 14:58:27,932 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 169
2021-12-06 14:58:27,932 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 181
2021-12-06 14:58:27,932 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 171
2021-12-06 14:58:27,932 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 162
2021-12-06 14:58:27,932 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 198
2021-12-06 14:58:27,932 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 160
2021-12-06 14:58:27,932 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 188
2021-12-06 14:58:27,932 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_11_piece0 stored as bytes in memory (estimated size 2.1 KB, free 1990.4 MB)
2021-12-06 14:58:27,932 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 193
2021-12-06 14:58:27,932 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 187
2021-12-06 14:58:27,932 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 150
2021-12-06 14:58:27,932 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 152
2021-12-06 14:58:27,932 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 185
2021-12-06 14:58:27,932 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 175
2021-12-06 14:58:27,932 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 192
2021-12-06 14:58:27,932 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 165
2021-12-06 14:58:27,932 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 163
2021-12-06 14:58:27,932 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 170
2021-12-06 14:58:27,932 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 186
2021-12-06 14:58:27,932 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 156
2021-12-06 14:58:27,932 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 190
2021-12-06 14:58:27,932 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 196
2021-12-06 14:58:27,932 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 199
2021-12-06 14:58:27,932 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 176
2021-12-06 14:58:27,932 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 182
2021-12-06 14:58:27,932 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 168
2021-12-06 14:58:27,932 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 167
2021-12-06 14:58:27,932 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 166
2021-12-06 14:58:27,932 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 179
2021-12-06 14:58:27,933 [dispatcher-event-loop-7] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_11_piece0 in memory on qb:60678 (size: 2.1 KB, free: 1990.8 MB)
2021-12-06 14:58:27,933 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 11 from broadcast at DAGScheduler.scala:1039
2021-12-06 14:58:27,933 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from ResultStage 12 (MapPartitionsRDD[18] at intersection at PaidPromotionAdjustParameter.scala:130) (first 15 tasks are for partitions Vector(0, 1))
2021-12-06 14:58:27,933 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 12.0 with 2 tasks
2021-12-06 14:58:27,933 [dispatcher-event-loop-9] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_10_piece0 on qb:60678 in memory (size: 2.3 KB, free: 1990.8 MB)
2021-12-06 14:58:27,934 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 164
2021-12-06 14:58:27,934 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 158
2021-12-06 14:58:27,934 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 173
2021-12-06 14:58:27,934 [dispatcher-event-loop-1] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_8_piece0 on qb:60678 in memory (size: 2.2 KB, free: 1990.8 MB)
2021-12-06 14:58:27,935 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 161
2021-12-06 14:58:27,935 [dispatcher-event-loop-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 12.0 (TID 20, localhost, executor driver, partition 0, PROCESS_LOCAL, 7712 bytes)
2021-12-06 14:58:27,935 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 157
2021-12-06 14:58:27,935 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 159
2021-12-06 14:58:27,935 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 174
2021-12-06 14:58:27,935 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 177
2021-12-06 14:58:27,935 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 180
2021-12-06 14:58:27,935 [dispatcher-event-loop-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 12.0 (TID 21, localhost, executor driver, partition 1, PROCESS_LOCAL, 7712 bytes)
2021-12-06 14:58:27,935 [dispatcher-event-loop-5] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_7_piece0 on qb:60678 in memory (size: 2.9 KB, free: 1990.8 MB)
2021-12-06 14:58:27,936 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 184
2021-12-06 14:58:27,936 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 194
2021-12-06 14:58:27,936 [Executor task launch worker for task 20] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 12.0 (TID 20)
2021-12-06 14:58:27,936 [Executor task launch worker for task 21] INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 12.0 (TID 21)
2021-12-06 14:58:27,936 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 151
2021-12-06 14:58:27,936 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 155
2021-12-06 14:58:27,936 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 197
2021-12-06 14:58:27,936 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 154
2021-12-06 14:58:27,936 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 178
2021-12-06 14:58:27,936 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 195
2021-12-06 14:58:27,938 [Executor task launch worker for task 21] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2021-12-06 14:58:27,938 [Executor task launch worker for task 20] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2021-12-06 14:58:27,938 [Executor task launch worker for task 21] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-06 14:58:27,938 [Executor task launch worker for task 20] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-06 14:58:27,941 [Executor task launch worker for task 21] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2021-12-06 14:58:27,941 [Executor task launch worker for task 20] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2021-12-06 14:58:27,941 [Executor task launch worker for task 21] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-06 14:58:27,941 [Executor task launch worker for task 20] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-06 14:58:28,089 [Executor task launch worker for task 21] INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 12.0 (TID 21). 1054 bytes result sent to driver
2021-12-06 14:58:28,089 [Executor task launch worker for task 20] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 12.0 (TID 20). 1054 bytes result sent to driver
2021-12-06 14:58:28,090 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 12.0 (TID 21) in 155 ms on localhost (executor driver) (1/2)
2021-12-06 14:58:28,090 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 12.0 (TID 20) in 156 ms on localhost (executor driver) (2/2)
2021-12-06 14:58:28,090 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 12.0, whose tasks have all completed, from pool 
2021-12-06 14:58:28,091 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 12 (count at PaidPromotionAdjustParameter.scala:140) finished in 0.166 s
2021-12-06 14:58:28,091 [main] INFO [org.apache.spark.scheduler.DAGScheduler] - Job 6 finished: count at PaidPromotionAdjustParameter.scala:140, took 0.284064 s
2021-12-06 14:58:28,092 [main] INFO [PaidPromotion$] -    = 5175
2021-12-06 14:58:28,094 [main] INFO [org.apache.spark.SparkContext] - Starting job: count at PaidPromotionAdjustParameter.scala:141
2021-12-06 14:58:28,094 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 20 (distinct at PaidPromotionAdjustParameter.scala:133)
2021-12-06 14:58:28,094 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 7 (count at PaidPromotionAdjustParameter.scala:141) with 2 output partitions
2021-12-06 14:58:28,094 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 14 (count at PaidPromotionAdjustParameter.scala:141)
2021-12-06 14:58:28,095 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 13)
2021-12-06 14:58:28,095 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List(ShuffleMapStage 13)
2021-12-06 14:58:28,095 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ShuffleMapStage 13 (MapPartitionsRDD[20] at distinct at PaidPromotionAdjustParameter.scala:133), which has no missing parents
2021-12-06 14:58:28,096 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_12 stored as values in memory (estimated size 5.2 KB, free 1990.5 MB)
2021-12-06 14:58:28,098 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_12_piece0 stored as bytes in memory (estimated size 2.9 KB, free 1990.4 MB)
2021-12-06 14:58:28,098 [dispatcher-event-loop-9] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_12_piece0 in memory on qb:60678 (size: 2.9 KB, free: 1990.8 MB)
2021-12-06 14:58:28,099 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 12 from broadcast at DAGScheduler.scala:1039
2021-12-06 14:58:28,099 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from ShuffleMapStage 13 (MapPartitionsRDD[20] at distinct at PaidPromotionAdjustParameter.scala:133) (first 15 tasks are for partitions Vector(0, 1))
2021-12-06 14:58:28,099 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 13.0 with 2 tasks
2021-12-06 14:58:28,099 [dispatcher-event-loop-4] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 13.0 (TID 22, localhost, executor driver, partition 0, ANY, 7885 bytes)
2021-12-06 14:58:28,100 [dispatcher-event-loop-4] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 13.0 (TID 23, localhost, executor driver, partition 1, ANY, 7885 bytes)
2021-12-06 14:58:28,100 [Executor task launch worker for task 22] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 13.0 (TID 22)
2021-12-06 14:58:28,100 [Executor task launch worker for task 23] INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 13.0 (TID 23)
2021-12-06 14:58:28,101 [Executor task launch worker for task 22] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/order_data.bcp:0+3442194
2021-12-06 14:58:28,101 [Executor task launch worker for task 23] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/order_data.bcp:3442194+3442195
2021-12-06 14:58:28,599 [Executor task launch worker for task 22] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 13.0 (TID 22). 989 bytes result sent to driver
2021-12-06 14:58:28,599 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 13.0 (TID 22) in 500 ms on localhost (executor driver) (1/2)
2021-12-06 14:58:29,860 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 234
2021-12-06 14:58:29,860 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 268
2021-12-06 14:58:29,860 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 238
2021-12-06 14:58:29,860 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 259
2021-12-06 14:58:29,860 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 205
2021-12-06 14:58:29,860 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 226
2021-12-06 14:58:29,860 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 206
2021-12-06 14:58:29,860 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 224
2021-12-06 14:58:29,860 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 243
2021-12-06 14:58:29,860 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 218
2021-12-06 14:58:29,860 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 204
2021-12-06 14:58:29,860 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 241
2021-12-06 14:58:29,860 [dispatcher-event-loop-8] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_9_piece0 on qb:60678 in memory (size: 2.3 KB, free: 1990.8 MB)
2021-12-06 14:58:29,861 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 272
2021-12-06 14:58:29,861 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 222
2021-12-06 14:58:29,861 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 235
2021-12-06 14:58:29,861 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 242
2021-12-06 14:58:29,861 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 231
2021-12-06 14:58:29,861 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 270
2021-12-06 14:58:29,861 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 255
2021-12-06 14:58:29,861 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 225
2021-12-06 14:58:29,861 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 228
2021-12-06 14:58:29,861 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 267
2021-12-06 14:58:29,861 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 236
2021-12-06 14:58:29,861 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 200
2021-12-06 14:58:29,861 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 219
2021-12-06 14:58:29,861 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 252
2021-12-06 14:58:29,861 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 227
2021-12-06 14:58:29,861 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 263
2021-12-06 14:58:29,861 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 229
2021-12-06 14:58:29,861 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 271
2021-12-06 14:58:29,861 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 264
2021-12-06 14:58:29,861 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 203
2021-12-06 14:58:29,862 [dispatcher-event-loop-9] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_11_piece0 on qb:60678 in memory (size: 2.1 KB, free: 1990.8 MB)
2021-12-06 14:58:29,862 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 213
2021-12-06 14:58:29,862 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 244
2021-12-06 14:58:29,862 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 230
2021-12-06 14:58:29,862 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 262
2021-12-06 14:58:29,862 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 208
2021-12-06 14:58:29,862 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 215
2021-12-06 14:58:29,862 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 209
2021-12-06 14:58:29,862 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 254
2021-12-06 14:58:29,862 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 214
2021-12-06 14:58:29,862 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 232
2021-12-06 14:58:29,862 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 273
2021-12-06 14:58:29,862 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 253
2021-12-06 14:58:29,862 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 245
2021-12-06 14:58:29,862 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 239
2021-12-06 14:58:29,862 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 223
2021-12-06 14:58:29,862 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 217
2021-12-06 14:58:29,862 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 274
2021-12-06 14:58:29,862 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 220
2021-12-06 14:58:29,862 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 265
2021-12-06 14:58:29,862 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 257
2021-12-06 14:58:29,862 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 210
2021-12-06 14:58:29,862 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 266
2021-12-06 14:58:29,862 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 201
2021-12-06 14:58:29,862 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 250
2021-12-06 14:58:29,862 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 251
2021-12-06 14:58:29,862 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 240
2021-12-06 14:58:29,862 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 256
2021-12-06 14:58:29,863 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 233
2021-12-06 14:58:29,863 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 237
2021-12-06 14:58:29,863 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 248
2021-12-06 14:58:29,863 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 258
2021-12-06 14:58:29,863 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 249
2021-12-06 14:58:29,863 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 207
2021-12-06 14:58:29,863 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 216
2021-12-06 14:58:29,863 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 211
2021-12-06 14:58:29,863 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 221
2021-12-06 14:58:29,863 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 212
2021-12-06 14:58:29,863 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 202
2021-12-06 14:58:29,863 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 261
2021-12-06 14:58:29,863 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 246
2021-12-06 14:58:29,863 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 247
2021-12-06 14:58:29,863 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 260
2021-12-06 14:58:29,863 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 269
2021-12-06 14:58:30,080 [Executor task launch worker for task 23] INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 13.0 (TID 23). 1032 bytes result sent to driver
2021-12-06 14:58:30,080 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 13.0 (TID 23) in 1980 ms on localhost (executor driver) (2/2)
2021-12-06 14:58:30,080 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 13.0, whose tasks have all completed, from pool 
2021-12-06 14:58:30,080 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ShuffleMapStage 13 (distinct at PaidPromotionAdjustParameter.scala:133) finished in 1.984 s
2021-12-06 14:58:30,080 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - looking for newly runnable stages
2021-12-06 14:58:30,080 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - running: Set()
2021-12-06 14:58:30,080 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - waiting: Set(ResultStage 14)
2021-12-06 14:58:30,080 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - failed: Set()
2021-12-06 14:58:30,081 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 14 (MapPartitionsRDD[22] at distinct at PaidPromotionAdjustParameter.scala:133), which has no missing parents
2021-12-06 14:58:30,082 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_13 stored as values in memory (estimated size 3.7 KB, free 1990.5 MB)
2021-12-06 14:58:30,084 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_13_piece0 stored as bytes in memory (estimated size 2.2 KB, free 1990.5 MB)
2021-12-06 14:58:30,085 [dispatcher-event-loop-11] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_13_piece0 in memory on qb:60678 (size: 2.2 KB, free: 1990.8 MB)
2021-12-06 14:58:30,085 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 13 from broadcast at DAGScheduler.scala:1039
2021-12-06 14:58:30,085 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from ResultStage 14 (MapPartitionsRDD[22] at distinct at PaidPromotionAdjustParameter.scala:133) (first 15 tasks are for partitions Vector(0, 1))
2021-12-06 14:58:30,085 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 14.0 with 2 tasks
2021-12-06 14:58:30,086 [dispatcher-event-loop-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 14.0 (TID 24, localhost, executor driver, partition 0, ANY, 7649 bytes)
2021-12-06 14:58:30,086 [dispatcher-event-loop-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 14.0 (TID 25, localhost, executor driver, partition 1, ANY, 7649 bytes)
2021-12-06 14:58:30,086 [Executor task launch worker for task 24] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 14.0 (TID 24)
2021-12-06 14:58:30,086 [Executor task launch worker for task 25] INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 14.0 (TID 25)
2021-12-06 14:58:30,087 [Executor task launch worker for task 24] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 2 non-empty blocks out of 2 blocks
2021-12-06 14:58:30,087 [Executor task launch worker for task 25] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 2 non-empty blocks out of 2 blocks
2021-12-06 14:58:30,087 [Executor task launch worker for task 24] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-06 14:58:30,087 [Executor task launch worker for task 25] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-06 14:58:30,101 [Executor task launch worker for task 25] INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 14.0 (TID 25). 1010 bytes result sent to driver
2021-12-06 14:58:30,102 [Executor task launch worker for task 24] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 14.0 (TID 24). 1053 bytes result sent to driver
2021-12-06 14:58:30,102 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 14.0 (TID 25) in 16 ms on localhost (executor driver) (1/2)
2021-12-06 14:58:30,102 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 14.0 (TID 24) in 17 ms on localhost (executor driver) (2/2)
2021-12-06 14:58:30,102 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 14.0, whose tasks have all completed, from pool 
2021-12-06 14:58:30,102 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 14 (count at PaidPromotionAdjustParameter.scala:141) finished in 0.021 s
2021-12-06 14:58:30,103 [main] INFO [org.apache.spark.scheduler.DAGScheduler] - Job 7 finished: count at PaidPromotionAdjustParameter.scala:141, took 2.008289 s
2021-12-06 14:58:30,103 [main] INFO [PaidPromotion$] -  = 122
2021-12-06 14:58:30,106 [main] INFO [org.apache.spark.SparkContext] - Starting job: count at PaidPromotionAdjustParameter.scala:142
2021-12-06 14:58:30,107 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 24 (distinct at PaidPromotionAdjustParameter.scala:134)
2021-12-06 14:58:30,107 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 8 (count at PaidPromotionAdjustParameter.scala:142) with 2 output partitions
2021-12-06 14:58:30,107 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 16 (count at PaidPromotionAdjustParameter.scala:142)
2021-12-06 14:58:30,107 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 15)
2021-12-06 14:58:30,107 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List(ShuffleMapStage 15)
2021-12-06 14:58:30,107 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ShuffleMapStage 15 (MapPartitionsRDD[24] at distinct at PaidPromotionAdjustParameter.scala:134), which has no missing parents
2021-12-06 14:58:30,108 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_14 stored as values in memory (estimated size 5.2 KB, free 1990.4 MB)
2021-12-06 14:58:30,110 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_14_piece0 stored as bytes in memory (estimated size 2.9 KB, free 1990.4 MB)
2021-12-06 14:58:30,111 [dispatcher-event-loop-0] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_14_piece0 in memory on qb:60678 (size: 2.9 KB, free: 1990.8 MB)
2021-12-06 14:58:30,111 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 14 from broadcast at DAGScheduler.scala:1039
2021-12-06 14:58:30,111 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from ShuffleMapStage 15 (MapPartitionsRDD[24] at distinct at PaidPromotionAdjustParameter.scala:134) (first 15 tasks are for partitions Vector(0, 1))
2021-12-06 14:58:30,111 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 15.0 with 2 tasks
2021-12-06 14:58:30,112 [dispatcher-event-loop-8] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 15.0 (TID 26, localhost, executor driver, partition 0, ANY, 7885 bytes)
2021-12-06 14:58:30,112 [dispatcher-event-loop-8] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 15.0 (TID 27, localhost, executor driver, partition 1, ANY, 7885 bytes)
2021-12-06 14:58:30,112 [Executor task launch worker for task 27] INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 15.0 (TID 27)
2021-12-06 14:58:30,112 [Executor task launch worker for task 26] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 15.0 (TID 26)
2021-12-06 14:58:30,114 [Executor task launch worker for task 26] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/order_data.bcp:0+3442194
2021-12-06 14:58:30,114 [Executor task launch worker for task 27] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/order_data.bcp:3442194+3442195
2021-12-06 14:58:31,132 [Executor task launch worker for task 27] INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 15.0 (TID 27). 989 bytes result sent to driver
2021-12-06 14:58:31,133 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 15.0 (TID 27) in 1021 ms on localhost (executor driver) (1/2)
2021-12-06 14:58:31,894 [SparkUI-77] INFO [org.spark_project.jetty.servlet.DefaultServlet] - content=ResourceHttpContent@3eb37ab6{r=jar:file:/C:/Users/ACER/.m2/repository/org/apache/spark/spark-core_2.11/2.3.0/spark-core_2.11-2.3.0.jar!/org/apache/spark/ui/static/bootstrap.min.css,gz=false}
2021-12-06 14:58:31,894 [SparkUI-44] INFO [org.spark_project.jetty.servlet.DefaultServlet] - content=ResourceHttpContent@6d5e5f1b{r=jar:file:/C:/Users/ACER/.m2/repository/org/apache/spark/spark-core_2.11/2.3.0/spark-core_2.11-2.3.0.jar!/org/apache/spark/ui/static/vis.min.css,gz=false}
2021-12-06 14:58:31,895 [SparkUI-77] WARN [org.spark_project.jetty.servlet.ServletHandler] - Error for /static/bootstrap.min.css
java.lang.NoSuchMethodError: javax.servlet.http.HttpServletRequest.isAsyncSupported()Z
	at org.spark_project.jetty.servlet.DefaultServlet.sendData(DefaultServlet.java:909)
	at org.spark_project.jetty.servlet.DefaultServlet.doGet(DefaultServlet.java:526)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:707)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:820)
	at org.spark_project.jetty.servlet.ServletHolder.handle(ServletHolder.java:848)
	at org.spark_project.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:584)
	at org.spark_project.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
	at org.spark_project.jetty.servlet.ServletHandler.doScope(ServletHandler.java:512)
	at org.spark_project.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
	at org.spark_project.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.spark_project.jetty.server.handler.gzip.GzipHandler.handle(GzipHandler.java:493)
	at org.spark_project.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:213)
	at org.spark_project.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
	at org.spark_project.jetty.server.Server.handle(Server.java:534)
	at org.spark_project.jetty.server.HttpChannel.handle(HttpChannel.java:320)
	at org.spark_project.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
	at org.spark_project.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
	at org.spark_project.jetty.io.FillInterest.fillable(FillInterest.java:108)
	at org.spark_project.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
	at org.spark_project.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
	at org.spark_project.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
	at java.lang.Thread.run(Thread.java:745)
2021-12-06 14:58:31,895 [SparkUI-44] WARN [org.spark_project.jetty.servlet.ServletHandler] - Error for /static/vis.min.css
java.lang.NoSuchMethodError: javax.servlet.http.HttpServletRequest.isAsyncSupported()Z
	at org.spark_project.jetty.servlet.DefaultServlet.sendData(DefaultServlet.java:909)
	at org.spark_project.jetty.servlet.DefaultServlet.doGet(DefaultServlet.java:526)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:707)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:820)
	at org.spark_project.jetty.servlet.ServletHolder.handle(ServletHolder.java:848)
	at org.spark_project.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:584)
	at org.spark_project.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
	at org.spark_project.jetty.servlet.ServletHandler.doScope(ServletHandler.java:512)
	at org.spark_project.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
	at org.spark_project.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.spark_project.jetty.server.handler.gzip.GzipHandler.handle(GzipHandler.java:493)
	at org.spark_project.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:213)
	at org.spark_project.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
	at org.spark_project.jetty.server.Server.handle(Server.java:534)
	at org.spark_project.jetty.server.HttpChannel.handle(HttpChannel.java:320)
	at org.spark_project.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
	at org.spark_project.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
	at org.spark_project.jetty.io.FillInterest.fillable(FillInterest.java:108)
	at org.spark_project.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
	at org.spark_project.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
	at org.spark_project.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
	at java.lang.Thread.run(Thread.java:745)
2021-12-06 14:58:31,895 [SparkUI-77] WARN [org.spark_project.jetty.server.HttpChannel] - //qb:4040/static/bootstrap.min.css
java.lang.NoSuchMethodError: javax.servlet.http.HttpServletRequest.isAsyncStarted()Z
	at org.spark_project.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:688)
	at org.spark_project.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
	at org.spark_project.jetty.servlet.ServletHandler.doScope(ServletHandler.java:512)
	at org.spark_project.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
	at org.spark_project.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.spark_project.jetty.server.handler.gzip.GzipHandler.handle(GzipHandler.java:493)
	at org.spark_project.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:213)
	at org.spark_project.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
	at org.spark_project.jetty.server.Server.handle(Server.java:534)
	at org.spark_project.jetty.server.HttpChannel.handle(HttpChannel.java:320)
	at org.spark_project.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
	at org.spark_project.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
	at org.spark_project.jetty.io.FillInterest.fillable(FillInterest.java:108)
	at org.spark_project.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
	at org.spark_project.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
	at org.spark_project.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
	at java.lang.Thread.run(Thread.java:745)
2021-12-06 14:58:31,896 [SparkUI-44] WARN [org.spark_project.jetty.server.HttpChannel] - //qb:4040/static/vis.min.css
java.lang.NoSuchMethodError: javax.servlet.http.HttpServletRequest.isAsyncStarted()Z
	at org.spark_project.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:688)
	at org.spark_project.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
	at org.spark_project.jetty.servlet.ServletHandler.doScope(ServletHandler.java:512)
	at org.spark_project.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
	at org.spark_project.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.spark_project.jetty.server.handler.gzip.GzipHandler.handle(GzipHandler.java:493)
	at org.spark_project.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:213)
	at org.spark_project.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
	at org.spark_project.jetty.server.Server.handle(Server.java:534)
	at org.spark_project.jetty.server.HttpChannel.handle(HttpChannel.java:320)
	at org.spark_project.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
	at org.spark_project.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
	at org.spark_project.jetty.io.FillInterest.fillable(FillInterest.java:108)
	at org.spark_project.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
	at org.spark_project.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
	at org.spark_project.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
	at java.lang.Thread.run(Thread.java:745)
2021-12-06 14:58:31,897 [SparkUI-74] INFO [org.spark_project.jetty.servlet.DefaultServlet] - content=ResourceHttpContent@3bb5c38f{r=jar:file:/C:/Users/ACER/.m2/repository/org/apache/spark/spark-core_2.11/2.3.0/spark-core_2.11-2.3.0.jar!/org/apache/spark/ui/static/timeline-view.css,gz=false}
2021-12-06 14:58:31,897 [SparkUI-74] WARN [org.spark_project.jetty.servlet.ServletHandler] - Error for /static/timeline-view.css
java.lang.NoSuchMethodError: javax.servlet.http.HttpServletRequest.isAsyncSupported()Z
	at org.spark_project.jetty.servlet.DefaultServlet.sendData(DefaultServlet.java:909)
	at org.spark_project.jetty.servlet.DefaultServlet.doGet(DefaultServlet.java:526)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:707)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:820)
	at org.spark_project.jetty.servlet.ServletHolder.handle(ServletHolder.java:848)
	at org.spark_project.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:584)
	at org.spark_project.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
	at org.spark_project.jetty.servlet.ServletHandler.doScope(ServletHandler.java:512)
	at org.spark_project.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
	at org.spark_project.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.spark_project.jetty.server.handler.gzip.GzipHandler.handle(GzipHandler.java:493)
	at org.spark_project.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:213)
	at org.spark_project.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
	at org.spark_project.jetty.server.Server.handle(Server.java:534)
	at org.spark_project.jetty.server.HttpChannel.handle(HttpChannel.java:320)
	at org.spark_project.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
	at org.spark_project.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
	at org.spark_project.jetty.io.FillInterest.fillable(FillInterest.java:108)
	at org.spark_project.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
	at org.spark_project.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
	at org.spark_project.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
	at java.lang.Thread.run(Thread.java:745)
2021-12-06 14:58:31,897 [SparkUI-42] INFO [org.spark_project.jetty.servlet.DefaultServlet] - content=ResourceHttpContent@12e0417d{r=jar:file:/C:/Users/ACER/.m2/repository/org/apache/spark/spark-core_2.11/2.3.0/spark-core_2.11-2.3.0.jar!/org/apache/spark/ui/static/webui.css,gz=false}
2021-12-06 14:58:31,897 [SparkUI-42] WARN [org.spark_project.jetty.servlet.ServletHandler] - Error for /static/webui.css
java.lang.NoSuchMethodError: javax.servlet.http.HttpServletRequest.isAsyncSupported()Z
	at org.spark_project.jetty.servlet.DefaultServlet.sendData(DefaultServlet.java:909)
	at org.spark_project.jetty.servlet.DefaultServlet.doGet(DefaultServlet.java:526)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:707)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:820)
	at org.spark_project.jetty.servlet.ServletHolder.handle(ServletHolder.java:848)
	at org.spark_project.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:584)
	at org.spark_project.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
	at org.spark_project.jetty.servlet.ServletHandler.doScope(ServletHandler.java:512)
	at org.spark_project.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
	at org.spark_project.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.spark_project.jetty.server.handler.gzip.GzipHandler.handle(GzipHandler.java:493)
	at org.spark_project.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:213)
	at org.spark_project.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
	at org.spark_project.jetty.server.Server.handle(Server.java:534)
	at org.spark_project.jetty.server.HttpChannel.handle(HttpChannel.java:320)
	at org.spark_project.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
	at org.spark_project.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
	at org.spark_project.jetty.io.FillInterest.fillable(FillInterest.java:108)
	at org.spark_project.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
	at org.spark_project.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
	at org.spark_project.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
	at java.lang.Thread.run(Thread.java:745)
2021-12-06 14:58:31,897 [SparkUI-74] WARN [org.spark_project.jetty.server.HttpChannel] - //qb:4040/static/timeline-view.css
java.lang.NoSuchMethodError: javax.servlet.http.HttpServletRequest.isAsyncStarted()Z
	at org.spark_project.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:688)
	at org.spark_project.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
	at org.spark_project.jetty.servlet.ServletHandler.doScope(ServletHandler.java:512)
	at org.spark_project.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
	at org.spark_project.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.spark_project.jetty.server.handler.gzip.GzipHandler.handle(GzipHandler.java:493)
	at org.spark_project.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:213)
	at org.spark_project.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
	at org.spark_project.jetty.server.Server.handle(Server.java:534)
	at org.spark_project.jetty.server.HttpChannel.handle(HttpChannel.java:320)
	at org.spark_project.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
	at org.spark_project.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
	at org.spark_project.jetty.io.FillInterest.fillable(FillInterest.java:108)
	at org.spark_project.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
	at org.spark_project.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
	at org.spark_project.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
	at java.lang.Thread.run(Thread.java:745)
2021-12-06 14:58:31,899 [SparkUI-42] WARN [org.spark_project.jetty.server.HttpChannel] - //qb:4040/static/webui.css
java.lang.NoSuchMethodError: javax.servlet.http.HttpServletRequest.isAsyncStarted()Z
	at org.spark_project.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:688)
	at org.spark_project.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
	at org.spark_project.jetty.servlet.ServletHandler.doScope(ServletHandler.java:512)
	at org.spark_project.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
	at org.spark_project.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.spark_project.jetty.server.handler.gzip.GzipHandler.handle(GzipHandler.java:493)
	at org.spark_project.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:213)
	at org.spark_project.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
	at org.spark_project.jetty.server.Server.handle(Server.java:534)
	at org.spark_project.jetty.server.HttpChannel.handle(HttpChannel.java:320)
	at org.spark_project.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
	at org.spark_project.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
	at org.spark_project.jetty.io.FillInterest.fillable(FillInterest.java:108)
	at org.spark_project.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
	at org.spark_project.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
	at org.spark_project.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
	at java.lang.Thread.run(Thread.java:745)
2021-12-06 14:58:31,900 [SparkUI-38] INFO [org.spark_project.jetty.servlet.DefaultServlet] - content=ResourceHttpContent@182a48a1{r=jar:file:/C:/Users/ACER/.m2/repository/org/apache/spark/spark-core_2.11/2.3.0/spark-core_2.11-2.3.0.jar!/org/apache/spark/ui/static/bootstrap.min.css,gz=false}
2021-12-06 14:58:31,900 [SparkUI-38] WARN [org.spark_project.jetty.servlet.ServletHandler] - Error for /static/bootstrap.min.css
java.lang.NoSuchMethodError: javax.servlet.http.HttpServletRequest.isAsyncSupported()Z
	at org.spark_project.jetty.servlet.DefaultServlet.sendData(DefaultServlet.java:909)
	at org.spark_project.jetty.servlet.DefaultServlet.doGet(DefaultServlet.java:526)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:707)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:820)
	at org.spark_project.jetty.servlet.ServletHolder.handle(ServletHolder.java:848)
	at org.spark_project.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:584)
	at org.spark_project.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
	at org.spark_project.jetty.servlet.ServletHandler.doScope(ServletHandler.java:512)
	at org.spark_project.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
	at org.spark_project.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.spark_project.jetty.server.handler.gzip.GzipHandler.handle(GzipHandler.java:493)
	at org.spark_project.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:213)
	at org.spark_project.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
	at org.spark_project.jetty.server.Server.handle(Server.java:534)
	at org.spark_project.jetty.server.HttpChannel.handle(HttpChannel.java:320)
	at org.spark_project.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
	at org.spark_project.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
	at org.spark_project.jetty.io.FillInterest.fillable(FillInterest.java:108)
	at org.spark_project.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
	at org.spark_project.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
	at org.spark_project.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
	at java.lang.Thread.run(Thread.java:745)
2021-12-06 14:58:31,901 [SparkUI-38] WARN [org.spark_project.jetty.server.HttpChannel] - //qb:4040/static/bootstrap.min.css
java.lang.NoSuchMethodError: javax.servlet.http.HttpServletRequest.isAsyncStarted()Z
	at org.spark_project.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:688)
	at org.spark_project.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
	at org.spark_project.jetty.servlet.ServletHandler.doScope(ServletHandler.java:512)
	at org.spark_project.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
	at org.spark_project.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.spark_project.jetty.server.handler.gzip.GzipHandler.handle(GzipHandler.java:493)
	at org.spark_project.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:213)
	at org.spark_project.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
	at org.spark_project.jetty.server.Server.handle(Server.java:534)
	at org.spark_project.jetty.server.HttpChannel.handle(HttpChannel.java:320)
	at org.spark_project.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
	at org.spark_project.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
	at org.spark_project.jetty.io.FillInterest.fillable(FillInterest.java:108)
	at org.spark_project.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
	at org.spark_project.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
	at org.spark_project.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
	at java.lang.Thread.run(Thread.java:745)
2021-12-06 14:58:31,901 [SparkUI-37] INFO [org.spark_project.jetty.servlet.DefaultServlet] - content=ResourceHttpContent@478bcff2{r=jar:file:/C:/Users/ACER/.m2/repository/org/apache/spark/spark-core_2.11/2.3.0/spark-core_2.11-2.3.0.jar!/org/apache/spark/ui/static/vis.min.css,gz=false}
2021-12-06 14:58:31,901 [SparkUI-37] WARN [org.spark_project.jetty.servlet.ServletHandler] - Error for /static/vis.min.css
java.lang.NoSuchMethodError: javax.servlet.http.HttpServletRequest.isAsyncSupported()Z
	at org.spark_project.jetty.servlet.DefaultServlet.sendData(DefaultServlet.java:909)
	at org.spark_project.jetty.servlet.DefaultServlet.doGet(DefaultServlet.java:526)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:707)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:820)
	at org.spark_project.jetty.servlet.ServletHolder.handle(ServletHolder.java:848)
	at org.spark_project.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:584)
	at org.spark_project.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
	at org.spark_project.jetty.servlet.ServletHandler.doScope(ServletHandler.java:512)
	at org.spark_project.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
	at org.spark_project.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.spark_project.jetty.server.handler.gzip.GzipHandler.handle(GzipHandler.java:493)
	at org.spark_project.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:213)
	at org.spark_project.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
	at org.spark_project.jetty.server.Server.handle(Server.java:534)
	at org.spark_project.jetty.server.HttpChannel.handle(HttpChannel.java:320)
	at org.spark_project.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
	at org.spark_project.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
	at org.spark_project.jetty.io.FillInterest.fillable(FillInterest.java:108)
	at org.spark_project.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
	at org.spark_project.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
	at org.spark_project.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
	at java.lang.Thread.run(Thread.java:745)
2021-12-06 14:58:31,901 [SparkUI-37] WARN [org.spark_project.jetty.server.HttpChannel] - //qb:4040/static/vis.min.css
java.lang.NoSuchMethodError: javax.servlet.http.HttpServletRequest.isAsyncStarted()Z
	at org.spark_project.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:688)
	at org.spark_project.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
	at org.spark_project.jetty.servlet.ServletHandler.doScope(ServletHandler.java:512)
	at org.spark_project.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
	at org.spark_project.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.spark_project.jetty.server.handler.gzip.GzipHandler.handle(GzipHandler.java:493)
	at org.spark_project.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:213)
	at org.spark_project.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
	at org.spark_project.jetty.server.Server.handle(Server.java:534)
	at org.spark_project.jetty.server.HttpChannel.handle(HttpChannel.java:320)
	at org.spark_project.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
	at org.spark_project.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
	at org.spark_project.jetty.io.FillInterest.fillable(FillInterest.java:108)
	at org.spark_project.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
	at org.spark_project.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
	at org.spark_project.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
	at java.lang.Thread.run(Thread.java:745)
2021-12-06 14:58:31,905 [SparkUI-71] INFO [org.spark_project.jetty.servlet.DefaultServlet] - content=ResourceHttpContent@6c2b7fcd{r=jar:file:/C:/Users/ACER/.m2/repository/org/apache/spark/spark-core_2.11/2.3.0/spark-core_2.11-2.3.0.jar!/org/apache/spark/ui/static/sorttable.js,gz=false}
2021-12-06 14:58:31,905 [SparkUI-76] INFO [org.spark_project.jetty.servlet.DefaultServlet] - content=ResourceHttpContent@2ec9969{r=jar:file:/C:/Users/ACER/.m2/repository/org/apache/spark/spark-core_2.11/2.3.0/spark-core_2.11-2.3.0.jar!/org/apache/spark/ui/static/jquery-1.11.1.min.js,gz=false}
2021-12-06 14:58:31,905 [SparkUI-71] WARN [org.spark_project.jetty.servlet.ServletHandler] - Error for /static/sorttable.js
java.lang.NoSuchMethodError: javax.servlet.http.HttpServletRequest.isAsyncSupported()Z
	at org.spark_project.jetty.servlet.DefaultServlet.sendData(DefaultServlet.java:909)
	at org.spark_project.jetty.servlet.DefaultServlet.doGet(DefaultServlet.java:526)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:707)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:820)
	at org.spark_project.jetty.servlet.ServletHolder.handle(ServletHolder.java:848)
	at org.spark_project.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:584)
	at org.spark_project.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
	at org.spark_project.jetty.servlet.ServletHandler.doScope(ServletHandler.java:512)
	at org.spark_project.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
	at org.spark_project.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.spark_project.jetty.server.handler.gzip.GzipHandler.handle(GzipHandler.java:493)
	at org.spark_project.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:213)
	at org.spark_project.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
	at org.spark_project.jetty.server.Server.handle(Server.java:534)
	at org.spark_project.jetty.server.HttpChannel.handle(HttpChannel.java:320)
	at org.spark_project.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
	at org.spark_project.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
	at org.spark_project.jetty.io.FillInterest.fillable(FillInterest.java:108)
	at org.spark_project.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
	at org.spark_project.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
	at org.spark_project.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
	at java.lang.Thread.run(Thread.java:745)
2021-12-06 14:58:31,905 [SparkUI-76] WARN [org.spark_project.jetty.servlet.ServletHandler] - Error for /static/jquery-1.11.1.min.js
java.lang.NoSuchMethodError: javax.servlet.http.HttpServletRequest.isAsyncSupported()Z
	at org.spark_project.jetty.servlet.DefaultServlet.sendData(DefaultServlet.java:909)
	at org.spark_project.jetty.servlet.DefaultServlet.doGet(DefaultServlet.java:526)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:707)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:820)
	at org.spark_project.jetty.servlet.ServletHolder.handle(ServletHolder.java:848)
	at org.spark_project.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:584)
	at org.spark_project.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
	at org.spark_project.jetty.servlet.ServletHandler.doScope(ServletHandler.java:512)
	at org.spark_project.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
	at org.spark_project.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.spark_project.jetty.server.handler.gzip.GzipHandler.handle(GzipHandler.java:493)
	at org.spark_project.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:213)
	at org.spark_project.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
	at org.spark_project.jetty.server.Server.handle(Server.java:534)
	at org.spark_project.jetty.server.HttpChannel.handle(HttpChannel.java:320)
	at org.spark_project.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
	at org.spark_project.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
	at org.spark_project.jetty.io.FillInterest.fillable(FillInterest.java:108)
	at org.spark_project.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
	at org.spark_project.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
	at org.spark_project.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
	at java.lang.Thread.run(Thread.java:745)
2021-12-06 14:58:31,905 [SparkUI-71] WARN [org.spark_project.jetty.server.HttpChannel] - //qb:4040/static/sorttable.js
java.lang.NoSuchMethodError: javax.servlet.http.HttpServletRequest.isAsyncStarted()Z
	at org.spark_project.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:688)
	at org.spark_project.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
	at org.spark_project.jetty.servlet.ServletHandler.doScope(ServletHandler.java:512)
	at org.spark_project.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
	at org.spark_project.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.spark_project.jetty.server.handler.gzip.GzipHandler.handle(GzipHandler.java:493)
	at org.spark_project.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:213)
	at org.spark_project.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
	at org.spark_project.jetty.server.Server.handle(Server.java:534)
	at org.spark_project.jetty.server.HttpChannel.handle(HttpChannel.java:320)
	at org.spark_project.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
	at org.spark_project.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
	at org.spark_project.jetty.io.FillInterest.fillable(FillInterest.java:108)
	at org.spark_project.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
	at org.spark_project.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
	at org.spark_project.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
	at java.lang.Thread.run(Thread.java:745)
2021-12-06 14:58:31,907 [SparkUI-76] WARN [org.spark_project.jetty.server.HttpChannel] - //qb:4040/static/jquery-1.11.1.min.js
java.lang.NoSuchMethodError: javax.servlet.http.HttpServletRequest.isAsyncStarted()Z
	at org.spark_project.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:688)
	at org.spark_project.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
	at org.spark_project.jetty.servlet.ServletHandler.doScope(ServletHandler.java:512)
	at org.spark_project.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
	at org.spark_project.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.spark_project.jetty.server.handler.gzip.GzipHandler.handle(GzipHandler.java:493)
	at org.spark_project.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:213)
	at org.spark_project.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
	at org.spark_project.jetty.server.Server.handle(Server.java:534)
	at org.spark_project.jetty.server.HttpChannel.handle(HttpChannel.java:320)
	at org.spark_project.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
	at org.spark_project.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
	at org.spark_project.jetty.io.FillInterest.fillable(FillInterest.java:108)
	at org.spark_project.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
	at org.spark_project.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
	at org.spark_project.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
	at java.lang.Thread.run(Thread.java:745)
2021-12-06 14:58:31,907 [SparkUI-73] INFO [org.spark_project.jetty.servlet.DefaultServlet] - content=ResourceHttpContent@2db8797f{r=jar:file:/C:/Users/ACER/.m2/repository/org/apache/spark/spark-core_2.11/2.3.0/spark-core_2.11-2.3.0.jar!/org/apache/spark/ui/static/bootstrap-tooltip.js,gz=false}
2021-12-06 14:58:31,907 [SparkUI-73] WARN [org.spark_project.jetty.servlet.ServletHandler] - Error for /static/bootstrap-tooltip.js
java.lang.NoSuchMethodError: javax.servlet.http.HttpServletRequest.isAsyncSupported()Z
	at org.spark_project.jetty.servlet.DefaultServlet.sendData(DefaultServlet.java:909)
	at org.spark_project.jetty.servlet.DefaultServlet.doGet(DefaultServlet.java:526)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:707)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:820)
	at org.spark_project.jetty.servlet.ServletHolder.handle(ServletHolder.java:848)
	at org.spark_project.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:584)
	at org.spark_project.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
	at org.spark_project.jetty.servlet.ServletHandler.doScope(ServletHandler.java:512)
	at org.spark_project.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
	at org.spark_project.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.spark_project.jetty.server.handler.gzip.GzipHandler.handle(GzipHandler.java:493)
	at org.spark_project.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:213)
	at org.spark_project.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
	at org.spark_project.jetty.server.Server.handle(Server.java:534)
	at org.spark_project.jetty.server.HttpChannel.handle(HttpChannel.java:320)
	at org.spark_project.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
	at org.spark_project.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
	at org.spark_project.jetty.io.FillInterest.fillable(FillInterest.java:108)
	at org.spark_project.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
	at org.spark_project.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
	at org.spark_project.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
	at java.lang.Thread.run(Thread.java:745)
2021-12-06 14:58:31,907 [SparkUI-43] INFO [org.spark_project.jetty.servlet.DefaultServlet] - content=ResourceHttpContent@28c11bf1{r=jar:file:/C:/Users/ACER/.m2/repository/org/apache/spark/spark-core_2.11/2.3.0/spark-core_2.11-2.3.0.jar!/org/apache/spark/ui/static/vis.min.js,gz=false}
2021-12-06 14:58:31,908 [SparkUI-43] WARN [org.spark_project.jetty.servlet.ServletHandler] - Error for /static/vis.min.js
java.lang.NoSuchMethodError: javax.servlet.http.HttpServletRequest.isAsyncSupported()Z
	at org.spark_project.jetty.servlet.DefaultServlet.sendData(DefaultServlet.java:909)
	at org.spark_project.jetty.servlet.DefaultServlet.doGet(DefaultServlet.java:526)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:707)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:820)
	at org.spark_project.jetty.servlet.ServletHolder.handle(ServletHolder.java:848)
	at org.spark_project.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:584)
	at org.spark_project.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
	at org.spark_project.jetty.servlet.ServletHandler.doScope(ServletHandler.java:512)
	at org.spark_project.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
	at org.spark_project.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.spark_project.jetty.server.handler.gzip.GzipHandler.handle(GzipHandler.java:493)
	at org.spark_project.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:213)
	at org.spark_project.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
	at org.spark_project.jetty.server.Server.handle(Server.java:534)
	at org.spark_project.jetty.server.HttpChannel.handle(HttpChannel.java:320)
	at org.spark_project.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
	at org.spark_project.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
	at org.spark_project.jetty.io.FillInterest.fillable(FillInterest.java:108)
	at org.spark_project.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
	at org.spark_project.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
	at org.spark_project.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
	at java.lang.Thread.run(Thread.java:745)
2021-12-06 14:58:31,908 [SparkUI-43] WARN [org.spark_project.jetty.server.HttpChannel] - //qb:4040/static/vis.min.js
java.lang.NoSuchMethodError: javax.servlet.http.HttpServletRequest.isAsyncStarted()Z
	at org.spark_project.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:688)
	at org.spark_project.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
	at org.spark_project.jetty.servlet.ServletHandler.doScope(ServletHandler.java:512)
	at org.spark_project.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
	at org.spark_project.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.spark_project.jetty.server.handler.gzip.GzipHandler.handle(GzipHandler.java:493)
	at org.spark_project.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:213)
	at org.spark_project.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
	at org.spark_project.jetty.server.Server.handle(Server.java:534)
	at org.spark_project.jetty.server.HttpChannel.handle(HttpChannel.java:320)
	at org.spark_project.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
	at org.spark_project.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
	at org.spark_project.jetty.io.FillInterest.fillable(FillInterest.java:108)
	at org.spark_project.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
	at org.spark_project.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
	at org.spark_project.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
	at java.lang.Thread.run(Thread.java:745)
2021-12-06 14:58:31,909 [SparkUI-73] WARN [org.spark_project.jetty.server.HttpChannel] - //qb:4040/static/bootstrap-tooltip.js
java.lang.NoSuchMethodError: javax.servlet.http.HttpServletRequest.isAsyncStarted()Z
	at org.spark_project.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:688)
	at org.spark_project.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
	at org.spark_project.jetty.servlet.ServletHandler.doScope(ServletHandler.java:512)
	at org.spark_project.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
	at org.spark_project.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.spark_project.jetty.server.handler.gzip.GzipHandler.handle(GzipHandler.java:493)
	at org.spark_project.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:213)
	at org.spark_project.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
	at org.spark_project.jetty.server.Server.handle(Server.java:534)
	at org.spark_project.jetty.server.HttpChannel.handle(HttpChannel.java:320)
	at org.spark_project.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
	at org.spark_project.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
	at org.spark_project.jetty.io.FillInterest.fillable(FillInterest.java:108)
	at org.spark_project.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
	at org.spark_project.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
	at org.spark_project.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
	at java.lang.Thread.run(Thread.java:745)
2021-12-06 14:58:31,909 [SparkUI-39] INFO [org.spark_project.jetty.servlet.DefaultServlet] - content=ResourceHttpContent@3b8c1833{r=jar:file:/C:/Users/ACER/.m2/repository/org/apache/spark/spark-core_2.11/2.3.0/spark-core_2.11-2.3.0.jar!/org/apache/spark/ui/static/table.js,gz=false}
2021-12-06 14:58:31,909 [SparkUI-39] WARN [org.spark_project.jetty.servlet.ServletHandler] - Error for /static/table.js
java.lang.NoSuchMethodError: javax.servlet.http.HttpServletRequest.isAsyncSupported()Z
	at org.spark_project.jetty.servlet.DefaultServlet.sendData(DefaultServlet.java:909)
	at org.spark_project.jetty.servlet.DefaultServlet.doGet(DefaultServlet.java:526)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:707)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:820)
	at org.spark_project.jetty.servlet.ServletHolder.handle(ServletHolder.java:848)
	at org.spark_project.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:584)
	at org.spark_project.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
	at org.spark_project.jetty.servlet.ServletHandler.doScope(ServletHandler.java:512)
	at org.spark_project.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
	at org.spark_project.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.spark_project.jetty.server.handler.gzip.GzipHandler.handle(GzipHandler.java:493)
	at org.spark_project.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:213)
	at org.spark_project.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
	at org.spark_project.jetty.server.Server.handle(Server.java:534)
	at org.spark_project.jetty.server.HttpChannel.handle(HttpChannel.java:320)
	at org.spark_project.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
	at org.spark_project.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
	at org.spark_project.jetty.io.FillInterest.fillable(FillInterest.java:108)
	at org.spark_project.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
	at org.spark_project.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
	at org.spark_project.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
	at java.lang.Thread.run(Thread.java:745)
2021-12-06 14:58:31,910 [SparkUI-39] WARN [org.spark_project.jetty.server.HttpChannel] - //qb:4040/static/table.js
java.lang.NoSuchMethodError: javax.servlet.http.HttpServletRequest.isAsyncStarted()Z
	at org.spark_project.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:688)
	at org.spark_project.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
	at org.spark_project.jetty.servlet.ServletHandler.doScope(ServletHandler.java:512)
	at org.spark_project.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
	at org.spark_project.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.spark_project.jetty.server.handler.gzip.GzipHandler.handle(GzipHandler.java:493)
	at org.spark_project.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:213)
	at org.spark_project.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
	at org.spark_project.jetty.server.Server.handle(Server.java:534)
	at org.spark_project.jetty.server.HttpChannel.handle(HttpChannel.java:320)
	at org.spark_project.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
	at org.spark_project.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
	at org.spark_project.jetty.io.FillInterest.fillable(FillInterest.java:108)
	at org.spark_project.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
	at org.spark_project.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
	at org.spark_project.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
	at java.lang.Thread.run(Thread.java:745)
2021-12-06 14:58:31,910 [SparkUI-41] INFO [org.spark_project.jetty.servlet.DefaultServlet] - content=ResourceHttpContent@16229b9f{r=jar:file:/C:/Users/ACER/.m2/repository/org/apache/spark/spark-core_2.11/2.3.0/spark-core_2.11-2.3.0.jar!/org/apache/spark/ui/static/initialize-tooltips.js,gz=false}
2021-12-06 14:58:31,912 [SparkUI-41] WARN [org.spark_project.jetty.servlet.ServletHandler] - Error for /static/initialize-tooltips.js
java.lang.NoSuchMethodError: javax.servlet.http.HttpServletRequest.isAsyncSupported()Z
	at org.spark_project.jetty.servlet.DefaultServlet.sendData(DefaultServlet.java:909)
	at org.spark_project.jetty.servlet.DefaultServlet.doGet(DefaultServlet.java:526)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:707)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:820)
	at org.spark_project.jetty.servlet.ServletHolder.handle(ServletHolder.java:848)
	at org.spark_project.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:584)
	at org.spark_project.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
	at org.spark_project.jetty.servlet.ServletHandler.doScope(ServletHandler.java:512)
	at org.spark_project.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
	at org.spark_project.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.spark_project.jetty.server.handler.gzip.GzipHandler.handle(GzipHandler.java:493)
	at org.spark_project.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:213)
	at org.spark_project.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
	at org.spark_project.jetty.server.Server.handle(Server.java:534)
	at org.spark_project.jetty.server.HttpChannel.handle(HttpChannel.java:320)
	at org.spark_project.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
	at org.spark_project.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
	at org.spark_project.jetty.io.FillInterest.fillable(FillInterest.java:108)
	at org.spark_project.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
	at org.spark_project.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
	at org.spark_project.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
	at java.lang.Thread.run(Thread.java:745)
2021-12-06 14:58:31,913 [SparkUI-41] WARN [org.spark_project.jetty.server.HttpChannel] - //qb:4040/static/initialize-tooltips.js
java.lang.NoSuchMethodError: javax.servlet.http.HttpServletRequest.isAsyncStarted()Z
	at org.spark_project.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:688)
	at org.spark_project.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
	at org.spark_project.jetty.servlet.ServletHandler.doScope(ServletHandler.java:512)
	at org.spark_project.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
	at org.spark_project.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.spark_project.jetty.server.handler.gzip.GzipHandler.handle(GzipHandler.java:493)
	at org.spark_project.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:213)
	at org.spark_project.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
	at org.spark_project.jetty.server.Server.handle(Server.java:534)
	at org.spark_project.jetty.server.HttpChannel.handle(HttpChannel.java:320)
	at org.spark_project.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
	at org.spark_project.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
	at org.spark_project.jetty.io.FillInterest.fillable(FillInterest.java:108)
	at org.spark_project.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
	at org.spark_project.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
	at org.spark_project.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
	at java.lang.Thread.run(Thread.java:745)
2021-12-06 14:58:31,915 [SparkUI-77] INFO [org.spark_project.jetty.servlet.DefaultServlet] - content=ResourceHttpContent@222c0d18{r=jar:file:/C:/Users/ACER/.m2/repository/org/apache/spark/spark-core_2.11/2.3.0/spark-core_2.11-2.3.0.jar!/org/apache/spark/ui/static/timeline-view.js,gz=false}
2021-12-06 14:58:31,915 [SparkUI-77] WARN [org.spark_project.jetty.servlet.ServletHandler] - Error for /static/timeline-view.js
java.lang.NoSuchMethodError: javax.servlet.http.HttpServletRequest.isAsyncSupported()Z
	at org.spark_project.jetty.servlet.DefaultServlet.sendData(DefaultServlet.java:909)
	at org.spark_project.jetty.servlet.DefaultServlet.doGet(DefaultServlet.java:526)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:707)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:820)
	at org.spark_project.jetty.servlet.ServletHolder.handle(ServletHolder.java:848)
	at org.spark_project.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:584)
	at org.spark_project.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
	at org.spark_project.jetty.servlet.ServletHandler.doScope(ServletHandler.java:512)
	at org.spark_project.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
	at org.spark_project.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.spark_project.jetty.server.handler.gzip.GzipHandler.handle(GzipHandler.java:493)
	at org.spark_project.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:213)
	at org.spark_project.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
	at org.spark_project.jetty.server.Server.handle(Server.java:534)
	at org.spark_project.jetty.server.HttpChannel.handle(HttpChannel.java:320)
	at org.spark_project.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
	at org.spark_project.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
	at org.spark_project.jetty.io.FillInterest.fillable(FillInterest.java:108)
	at org.spark_project.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
	at org.spark_project.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
	at org.spark_project.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
	at java.lang.Thread.run(Thread.java:745)
2021-12-06 14:58:31,915 [SparkUI-77] WARN [org.spark_project.jetty.server.HttpChannel] - //qb:4040/static/timeline-view.js
java.lang.NoSuchMethodError: javax.servlet.http.HttpServletRequest.isAsyncStarted()Z
	at org.spark_project.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:688)
	at org.spark_project.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
	at org.spark_project.jetty.servlet.ServletHandler.doScope(ServletHandler.java:512)
	at org.spark_project.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
	at org.spark_project.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.spark_project.jetty.server.handler.gzip.GzipHandler.handle(GzipHandler.java:493)
	at org.spark_project.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:213)
	at org.spark_project.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
	at org.spark_project.jetty.server.Server.handle(Server.java:534)
	at org.spark_project.jetty.server.HttpChannel.handle(HttpChannel.java:320)
	at org.spark_project.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
	at org.spark_project.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
	at org.spark_project.jetty.io.FillInterest.fillable(FillInterest.java:108)
	at org.spark_project.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
	at org.spark_project.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
	at org.spark_project.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
	at java.lang.Thread.run(Thread.java:745)
2021-12-06 14:58:31,915 [SparkUI-39] INFO [org.spark_project.jetty.servlet.DefaultServlet] - content=ResourceHttpContent@527c32d6{r=jar:file:/C:/Users/ACER/.m2/repository/org/apache/spark/spark-core_2.11/2.3.0/spark-core_2.11-2.3.0.jar!/org/apache/spark/ui/static/additional-metrics.js,gz=false}
2021-12-06 14:58:31,915 [SparkUI-39] WARN [org.spark_project.jetty.servlet.ServletHandler] - Error for /static/additional-metrics.js
java.lang.NoSuchMethodError: javax.servlet.http.HttpServletRequest.isAsyncSupported()Z
	at org.spark_project.jetty.servlet.DefaultServlet.sendData(DefaultServlet.java:909)
	at org.spark_project.jetty.servlet.DefaultServlet.doGet(DefaultServlet.java:526)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:707)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:820)
	at org.spark_project.jetty.servlet.ServletHolder.handle(ServletHolder.java:848)
	at org.spark_project.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:584)
	at org.spark_project.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
	at org.spark_project.jetty.servlet.ServletHandler.doScope(ServletHandler.java:512)
	at org.spark_project.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
	at org.spark_project.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.spark_project.jetty.server.handler.gzip.GzipHandler.handle(GzipHandler.java:493)
	at org.spark_project.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:213)
	at org.spark_project.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
	at org.spark_project.jetty.server.Server.handle(Server.java:534)
	at org.spark_project.jetty.server.HttpChannel.handle(HttpChannel.java:320)
	at org.spark_project.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
	at org.spark_project.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
	at org.spark_project.jetty.io.FillInterest.fillable(FillInterest.java:108)
	at org.spark_project.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
	at org.spark_project.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
	at org.spark_project.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
	at java.lang.Thread.run(Thread.java:745)
2021-12-06 14:58:31,916 [SparkUI-39] WARN [org.spark_project.jetty.server.HttpChannel] - //qb:4040/static/additional-metrics.js
java.lang.NoSuchMethodError: javax.servlet.http.HttpServletRequest.isAsyncStarted()Z
	at org.spark_project.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:688)
	at org.spark_project.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
	at org.spark_project.jetty.servlet.ServletHandler.doScope(ServletHandler.java:512)
	at org.spark_project.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
	at org.spark_project.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.spark_project.jetty.server.handler.gzip.GzipHandler.handle(GzipHandler.java:493)
	at org.spark_project.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:213)
	at org.spark_project.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
	at org.spark_project.jetty.server.Server.handle(Server.java:534)
	at org.spark_project.jetty.server.HttpChannel.handle(HttpChannel.java:320)
	at org.spark_project.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
	at org.spark_project.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
	at org.spark_project.jetty.io.FillInterest.fillable(FillInterest.java:108)
	at org.spark_project.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
	at org.spark_project.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
	at org.spark_project.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
	at java.lang.Thread.run(Thread.java:745)
2021-12-06 14:58:31,916 [SparkUI-37] INFO [org.spark_project.jetty.servlet.DefaultServlet] - content=ResourceHttpContent@1ec009d6{r=jar:file:/C:/Users/ACER/.m2/repository/org/apache/spark/spark-core_2.11/2.3.0/spark-core_2.11-2.3.0.jar!/org/apache/spark/ui/static/webui.js,gz=false}
2021-12-06 14:58:31,917 [SparkUI-37] WARN [org.spark_project.jetty.servlet.ServletHandler] - Error for /static/webui.js
java.lang.NoSuchMethodError: javax.servlet.http.HttpServletRequest.isAsyncSupported()Z
	at org.spark_project.jetty.servlet.DefaultServlet.sendData(DefaultServlet.java:909)
	at org.spark_project.jetty.servlet.DefaultServlet.doGet(DefaultServlet.java:526)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:707)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:820)
	at org.spark_project.jetty.servlet.ServletHolder.handle(ServletHolder.java:848)
	at org.spark_project.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:584)
	at org.spark_project.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
	at org.spark_project.jetty.servlet.ServletHandler.doScope(ServletHandler.java:512)
	at org.spark_project.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
	at org.spark_project.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.spark_project.jetty.server.handler.gzip.GzipHandler.handle(GzipHandler.java:493)
	at org.spark_project.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:213)
	at org.spark_project.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
	at org.spark_project.jetty.server.Server.handle(Server.java:534)
	at org.spark_project.jetty.server.HttpChannel.handle(HttpChannel.java:320)
	at org.spark_project.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
	at org.spark_project.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
	at org.spark_project.jetty.io.FillInterest.fillable(FillInterest.java:108)
	at org.spark_project.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
	at org.spark_project.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
	at org.spark_project.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
	at java.lang.Thread.run(Thread.java:745)
2021-12-06 14:58:31,917 [SparkUI-37] WARN [org.spark_project.jetty.server.HttpChannel] - //qb:4040/static/webui.js
java.lang.NoSuchMethodError: javax.servlet.http.HttpServletRequest.isAsyncStarted()Z
	at org.spark_project.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:688)
	at org.spark_project.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
	at org.spark_project.jetty.servlet.ServletHandler.doScope(ServletHandler.java:512)
	at org.spark_project.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
	at org.spark_project.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.spark_project.jetty.server.handler.gzip.GzipHandler.handle(GzipHandler.java:493)
	at org.spark_project.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:213)
	at org.spark_project.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
	at org.spark_project.jetty.server.Server.handle(Server.java:534)
	at org.spark_project.jetty.server.HttpChannel.handle(HttpChannel.java:320)
	at org.spark_project.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
	at org.spark_project.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
	at org.spark_project.jetty.io.FillInterest.fillable(FillInterest.java:108)
	at org.spark_project.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
	at org.spark_project.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
	at org.spark_project.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
	at java.lang.Thread.run(Thread.java:745)
2021-12-06 14:58:31,917 [SparkUI-76] INFO [org.spark_project.jetty.servlet.DefaultServlet] - content=ResourceHttpContent@2c0dfa7e{r=jar:file:/C:/Users/ACER/.m2/repository/org/apache/spark/spark-core_2.11/2.3.0/spark-core_2.11-2.3.0.jar!/org/apache/spark/ui/static/log-view.js,gz=false}
2021-12-06 14:58:31,917 [SparkUI-76] WARN [org.spark_project.jetty.servlet.ServletHandler] - Error for /static/log-view.js
java.lang.NoSuchMethodError: javax.servlet.http.HttpServletRequest.isAsyncSupported()Z
	at org.spark_project.jetty.servlet.DefaultServlet.sendData(DefaultServlet.java:909)
	at org.spark_project.jetty.servlet.DefaultServlet.doGet(DefaultServlet.java:526)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:707)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:820)
	at org.spark_project.jetty.servlet.ServletHolder.handle(ServletHolder.java:848)
	at org.spark_project.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:584)
	at org.spark_project.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
	at org.spark_project.jetty.servlet.ServletHandler.doScope(ServletHandler.java:512)
	at org.spark_project.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
	at org.spark_project.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.spark_project.jetty.server.handler.gzip.GzipHandler.handle(GzipHandler.java:493)
	at org.spark_project.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:213)
	at org.spark_project.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
	at org.spark_project.jetty.server.Server.handle(Server.java:534)
	at org.spark_project.jetty.server.HttpChannel.handle(HttpChannel.java:320)
	at org.spark_project.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
	at org.spark_project.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
	at org.spark_project.jetty.io.FillInterest.fillable(FillInterest.java:108)
	at org.spark_project.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
	at org.spark_project.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
	at org.spark_project.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
	at java.lang.Thread.run(Thread.java:745)
2021-12-06 14:58:31,918 [SparkUI-76] WARN [org.spark_project.jetty.server.HttpChannel] - //qb:4040/static/log-view.js
java.lang.NoSuchMethodError: javax.servlet.http.HttpServletRequest.isAsyncStarted()Z
	at org.spark_project.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:688)
	at org.spark_project.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
	at org.spark_project.jetty.servlet.ServletHandler.doScope(ServletHandler.java:512)
	at org.spark_project.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
	at org.spark_project.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.spark_project.jetty.server.handler.gzip.GzipHandler.handle(GzipHandler.java:493)
	at org.spark_project.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:213)
	at org.spark_project.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
	at org.spark_project.jetty.server.Server.handle(Server.java:534)
	at org.spark_project.jetty.server.HttpChannel.handle(HttpChannel.java:320)
	at org.spark_project.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
	at org.spark_project.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
	at org.spark_project.jetty.io.FillInterest.fillable(FillInterest.java:108)
	at org.spark_project.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
	at org.spark_project.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
	at org.spark_project.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
	at java.lang.Thread.run(Thread.java:745)
2021-12-06 14:58:31,921 [SparkUI-38] INFO [org.spark_project.jetty.servlet.DefaultServlet] - content=ResourceHttpContent@40d3efeb{r=jar:file:/C:/Users/ACER/.m2/repository/org/apache/spark/spark-core_2.11/2.3.0/spark-core_2.11-2.3.0.jar!/org/apache/spark/ui/static/spark-logo-77x50px-hd.png,gz=false}
2021-12-06 14:58:31,921 [SparkUI-38] WARN [org.spark_project.jetty.servlet.ServletHandler] - Error for /static/spark-logo-77x50px-hd.png
java.lang.NoSuchMethodError: javax.servlet.http.HttpServletRequest.isAsyncSupported()Z
	at org.spark_project.jetty.servlet.DefaultServlet.sendData(DefaultServlet.java:909)
	at org.spark_project.jetty.servlet.DefaultServlet.doGet(DefaultServlet.java:526)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:707)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:820)
	at org.spark_project.jetty.servlet.ServletHolder.handle(ServletHolder.java:848)
	at org.spark_project.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:584)
	at org.spark_project.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
	at org.spark_project.jetty.servlet.ServletHandler.doScope(ServletHandler.java:512)
	at org.spark_project.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
	at org.spark_project.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.spark_project.jetty.server.handler.gzip.GzipHandler.handle(GzipHandler.java:448)
	at org.spark_project.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:213)
	at org.spark_project.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
	at org.spark_project.jetty.server.Server.handle(Server.java:534)
	at org.spark_project.jetty.server.HttpChannel.handle(HttpChannel.java:320)
	at org.spark_project.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
	at org.spark_project.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
	at org.spark_project.jetty.io.FillInterest.fillable(FillInterest.java:108)
	at org.spark_project.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
	at org.spark_project.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
	at org.spark_project.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
	at java.lang.Thread.run(Thread.java:745)
2021-12-06 14:58:31,922 [SparkUI-38] WARN [org.spark_project.jetty.server.HttpChannel] - //qb:4040/static/spark-logo-77x50px-hd.png
java.lang.NoSuchMethodError: javax.servlet.http.HttpServletRequest.isAsyncStarted()Z
	at org.spark_project.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:688)
	at org.spark_project.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
	at org.spark_project.jetty.servlet.ServletHandler.doScope(ServletHandler.java:512)
	at org.spark_project.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
	at org.spark_project.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.spark_project.jetty.server.handler.gzip.GzipHandler.handle(GzipHandler.java:448)
	at org.spark_project.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:213)
	at org.spark_project.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
	at org.spark_project.jetty.server.Server.handle(Server.java:534)
	at org.spark_project.jetty.server.HttpChannel.handle(HttpChannel.java:320)
	at org.spark_project.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
	at org.spark_project.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
	at org.spark_project.jetty.io.FillInterest.fillable(FillInterest.java:108)
	at org.spark_project.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
	at org.spark_project.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
	at org.spark_project.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
	at java.lang.Thread.run(Thread.java:745)
2021-12-06 14:58:32,351 [Executor task launch worker for task 26] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 15.0 (TID 26). 989 bytes result sent to driver
2021-12-06 14:58:32,352 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 15.0 (TID 26) in 2240 ms on localhost (executor driver) (2/2)
2021-12-06 14:58:32,352 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 15.0, whose tasks have all completed, from pool 
2021-12-06 14:58:32,352 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ShuffleMapStage 15 (distinct at PaidPromotionAdjustParameter.scala:134) finished in 2.244 s
2021-12-06 14:58:32,352 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - looking for newly runnable stages
2021-12-06 14:58:32,352 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - running: Set()
2021-12-06 14:58:32,352 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - waiting: Set(ResultStage 16)
2021-12-06 14:58:32,352 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - failed: Set()
2021-12-06 14:58:32,352 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 16 (MapPartitionsRDD[26] at distinct at PaidPromotionAdjustParameter.scala:134), which has no missing parents
2021-12-06 14:58:32,353 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_15 stored as values in memory (estimated size 3.7 KB, free 1990.4 MB)
2021-12-06 14:58:32,356 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_15_piece0 stored as bytes in memory (estimated size 2.2 KB, free 1990.4 MB)
2021-12-06 14:58:32,356 [dispatcher-event-loop-11] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_15_piece0 in memory on qb:60678 (size: 2.2 KB, free: 1990.8 MB)
2021-12-06 14:58:32,356 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 15 from broadcast at DAGScheduler.scala:1039
2021-12-06 14:58:32,357 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from ResultStage 16 (MapPartitionsRDD[26] at distinct at PaidPromotionAdjustParameter.scala:134) (first 15 tasks are for partitions Vector(0, 1))
2021-12-06 14:58:32,357 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 16.0 with 2 tasks
2021-12-06 14:58:32,357 [dispatcher-event-loop-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 16.0 (TID 28, localhost, executor driver, partition 0, ANY, 7649 bytes)
2021-12-06 14:58:32,357 [dispatcher-event-loop-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 16.0 (TID 29, localhost, executor driver, partition 1, ANY, 7649 bytes)
2021-12-06 14:58:32,357 [Executor task launch worker for task 29] INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 16.0 (TID 29)
2021-12-06 14:58:32,357 [Executor task launch worker for task 28] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 16.0 (TID 28)
2021-12-06 14:58:32,359 [Executor task launch worker for task 29] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 2 non-empty blocks out of 2 blocks
2021-12-06 14:58:32,359 [Executor task launch worker for task 28] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 2 non-empty blocks out of 2 blocks
2021-12-06 14:58:32,359 [Executor task launch worker for task 29] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-06 14:58:32,359 [Executor task launch worker for task 28] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-06 14:58:32,371 [Executor task launch worker for task 29] INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 16.0 (TID 29). 1010 bytes result sent to driver
2021-12-06 14:58:32,371 [Executor task launch worker for task 28] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 16.0 (TID 28). 1010 bytes result sent to driver
2021-12-06 14:58:32,372 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 16.0 (TID 28) in 15 ms on localhost (executor driver) (1/2)
2021-12-06 14:58:32,372 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 16.0 (TID 29) in 15 ms on localhost (executor driver) (2/2)
2021-12-06 14:58:32,372 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 16.0, whose tasks have all completed, from pool 
2021-12-06 14:58:32,372 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 16 (count at PaidPromotionAdjustParameter.scala:142) finished in 0.019 s
2021-12-06 14:58:32,372 [main] INFO [org.apache.spark.scheduler.DAGScheduler] - Job 8 finished: count at PaidPromotionAdjustParameter.scala:142, took 2.266448 s
2021-12-06 14:58:32,373 [main] INFO [PaidPromotion$] -  = 123
2021-12-06 14:58:32,375 [main] INFO [org.apache.spark.SparkContext] - Starting job: count at PaidPromotionAdjustParameter.scala:143
2021-12-06 14:58:32,376 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 27 (intersection at PaidPromotionAdjustParameter.scala:135)
2021-12-06 14:58:32,376 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 28 (intersection at PaidPromotionAdjustParameter.scala:135)
2021-12-06 14:58:32,376 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 9 (count at PaidPromotionAdjustParameter.scala:143) with 2 output partitions
2021-12-06 14:58:32,376 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 21 (count at PaidPromotionAdjustParameter.scala:143)
2021-12-06 14:58:32,376 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 20, ShuffleMapStage 18)
2021-12-06 14:58:32,376 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List(ShuffleMapStage 20, ShuffleMapStage 18)
2021-12-06 14:58:32,377 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ShuffleMapStage 18 (MapPartitionsRDD[27] at intersection at PaidPromotionAdjustParameter.scala:135), which has no missing parents
2021-12-06 14:58:32,378 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_16 stored as values in memory (estimated size 4.0 KB, free 1990.4 MB)
2021-12-06 14:58:32,379 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_16_piece0 stored as bytes in memory (estimated size 2.3 KB, free 1990.4 MB)
2021-12-06 14:58:32,380 [dispatcher-event-loop-0] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_16_piece0 in memory on qb:60678 (size: 2.3 KB, free: 1990.8 MB)
2021-12-06 14:58:32,380 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 16 from broadcast at DAGScheduler.scala:1039
2021-12-06 14:58:32,381 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from ShuffleMapStage 18 (MapPartitionsRDD[27] at intersection at PaidPromotionAdjustParameter.scala:135) (first 15 tasks are for partitions Vector(0, 1))
2021-12-06 14:58:32,381 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 18.0 with 2 tasks
2021-12-06 14:58:32,381 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ShuffleMapStage 20 (MapPartitionsRDD[28] at intersection at PaidPromotionAdjustParameter.scala:135), which has no missing parents
2021-12-06 14:58:32,381 [dispatcher-event-loop-8] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 18.0 (TID 30, localhost, executor driver, partition 0, ANY, 7638 bytes)
2021-12-06 14:58:32,381 [dispatcher-event-loop-8] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 18.0 (TID 31, localhost, executor driver, partition 1, ANY, 7638 bytes)
2021-12-06 14:58:32,381 [Executor task launch worker for task 31] INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 18.0 (TID 31)
2021-12-06 14:58:32,381 [Executor task launch worker for task 30] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 18.0 (TID 30)
2021-12-06 14:58:32,382 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_17 stored as values in memory (estimated size 4.0 KB, free 1990.4 MB)
2021-12-06 14:58:32,382 [Executor task launch worker for task 31] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 2 non-empty blocks out of 2 blocks
2021-12-06 14:58:32,383 [Executor task launch worker for task 31] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 1 ms
2021-12-06 14:58:32,383 [Executor task launch worker for task 30] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 2 non-empty blocks out of 2 blocks
2021-12-06 14:58:32,383 [Executor task launch worker for task 30] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-06 14:58:32,384 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_17_piece0 stored as bytes in memory (estimated size 2.3 KB, free 1990.4 MB)
2021-12-06 14:58:32,384 [dispatcher-event-loop-9] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_17_piece0 in memory on qb:60678 (size: 2.3 KB, free: 1990.8 MB)
2021-12-06 14:58:32,384 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 17 from broadcast at DAGScheduler.scala:1039
2021-12-06 14:58:32,385 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from ShuffleMapStage 20 (MapPartitionsRDD[28] at intersection at PaidPromotionAdjustParameter.scala:135) (first 15 tasks are for partitions Vector(0, 1))
2021-12-06 14:58:32,385 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 20.0 with 2 tasks
2021-12-06 14:58:32,385 [dispatcher-event-loop-4] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 20.0 (TID 32, localhost, executor driver, partition 0, ANY, 7638 bytes)
2021-12-06 14:58:32,385 [dispatcher-event-loop-4] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 20.0 (TID 33, localhost, executor driver, partition 1, ANY, 7638 bytes)
2021-12-06 14:58:32,386 [Executor task launch worker for task 32] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 20.0 (TID 32)
2021-12-06 14:58:32,386 [Executor task launch worker for task 33] INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 20.0 (TID 33)
2021-12-06 14:58:32,387 [Executor task launch worker for task 33] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 2 non-empty blocks out of 2 blocks
2021-12-06 14:58:32,387 [Executor task launch worker for task 33] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-06 14:58:32,387 [Executor task launch worker for task 32] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 2 non-empty blocks out of 2 blocks
2021-12-06 14:58:32,387 [Executor task launch worker for task 32] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-06 14:58:32,400 [Executor task launch worker for task 31] INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 18.0 (TID 31). 1204 bytes result sent to driver
2021-12-06 14:58:32,401 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 18.0 (TID 31) in 20 ms on localhost (executor driver) (1/2)
2021-12-06 14:58:32,401 [Executor task launch worker for task 30] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 18.0 (TID 30). 1204 bytes result sent to driver
2021-12-06 14:58:32,402 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 18.0 (TID 30) in 21 ms on localhost (executor driver) (2/2)
2021-12-06 14:58:32,402 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 18.0, whose tasks have all completed, from pool 
2021-12-06 14:58:32,403 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ShuffleMapStage 18 (intersection at PaidPromotionAdjustParameter.scala:135) finished in 0.026 s
2021-12-06 14:58:32,403 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - looking for newly runnable stages
2021-12-06 14:58:32,403 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - running: Set(ShuffleMapStage 20)
2021-12-06 14:58:32,403 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - waiting: Set(ResultStage 21)
2021-12-06 14:58:32,403 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - failed: Set()
2021-12-06 14:58:32,403 [Executor task launch worker for task 33] INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 20.0 (TID 33). 1161 bytes result sent to driver
2021-12-06 14:58:32,403 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 20.0 (TID 33) in 18 ms on localhost (executor driver) (1/2)
2021-12-06 14:58:32,404 [Executor task launch worker for task 32] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 20.0 (TID 32). 1161 bytes result sent to driver
2021-12-06 14:58:32,405 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 20.0 (TID 32) in 20 ms on localhost (executor driver) (2/2)
2021-12-06 14:58:32,405 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 20.0, whose tasks have all completed, from pool 
2021-12-06 14:58:32,405 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ShuffleMapStage 20 (intersection at PaidPromotionAdjustParameter.scala:135) finished in 0.023 s
2021-12-06 14:58:32,405 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - looking for newly runnable stages
2021-12-06 14:58:32,405 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - running: Set()
2021-12-06 14:58:32,405 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - waiting: Set(ResultStage 21)
2021-12-06 14:58:32,405 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - failed: Set()
2021-12-06 14:58:32,405 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 21 (MapPartitionsRDD[32] at intersection at PaidPromotionAdjustParameter.scala:135), which has no missing parents
2021-12-06 14:58:32,406 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_18 stored as values in memory (estimated size 3.6 KB, free 1990.4 MB)
2021-12-06 14:58:32,408 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_18_piece0 stored as bytes in memory (estimated size 2.1 KB, free 1990.4 MB)
2021-12-06 14:58:32,408 [dispatcher-event-loop-0] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_18_piece0 in memory on qb:60678 (size: 2.1 KB, free: 1990.8 MB)
2021-12-06 14:58:32,408 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 18 from broadcast at DAGScheduler.scala:1039
2021-12-06 14:58:32,408 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from ResultStage 21 (MapPartitionsRDD[32] at intersection at PaidPromotionAdjustParameter.scala:135) (first 15 tasks are for partitions Vector(0, 1))
2021-12-06 14:58:32,408 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 21.0 with 2 tasks
2021-12-06 14:58:32,409 [dispatcher-event-loop-8] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 21.0 (TID 34, localhost, executor driver, partition 0, PROCESS_LOCAL, 7712 bytes)
2021-12-06 14:58:32,409 [dispatcher-event-loop-8] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 21.0 (TID 35, localhost, executor driver, partition 1, PROCESS_LOCAL, 7712 bytes)
2021-12-06 14:58:32,409 [Executor task launch worker for task 34] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 21.0 (TID 34)
2021-12-06 14:58:32,409 [Executor task launch worker for task 35] INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 21.0 (TID 35)
2021-12-06 14:58:32,411 [Executor task launch worker for task 34] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2021-12-06 14:58:32,411 [Executor task launch worker for task 35] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2021-12-06 14:58:32,411 [Executor task launch worker for task 34] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 1 ms
2021-12-06 14:58:32,411 [Executor task launch worker for task 35] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-06 14:58:32,412 [Executor task launch worker for task 34] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2021-12-06 14:58:32,412 [Executor task launch worker for task 35] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2021-12-06 14:58:32,412 [Executor task launch worker for task 34] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-06 14:58:32,412 [Executor task launch worker for task 35] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-06 14:58:32,419 [Executor task launch worker for task 34] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 21.0 (TID 34). 967 bytes result sent to driver
2021-12-06 14:58:32,419 [Executor task launch worker for task 35] INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 21.0 (TID 35). 967 bytes result sent to driver
2021-12-06 14:58:32,420 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 21.0 (TID 34) in 11 ms on localhost (executor driver) (1/2)
2021-12-06 14:58:32,420 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 21.0 (TID 35) in 11 ms on localhost (executor driver) (2/2)
2021-12-06 14:58:32,420 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 21.0, whose tasks have all completed, from pool 
2021-12-06 14:58:32,420 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 21 (count at PaidPromotionAdjustParameter.scala:143) finished in 0.015 s
2021-12-06 14:58:32,420 [main] INFO [org.apache.spark.scheduler.DAGScheduler] - Job 9 finished: count at PaidPromotionAdjustParameter.scala:143, took 0.044719 s
2021-12-06 14:58:32,421 [main] INFO [PaidPromotion$] -    = 113
2021-12-06 14:58:32,428 [main] INFO [org.apache.spark.SparkContext] - Starting job: collect at PaidPromotionAdjustParameter.scala:146
2021-12-06 14:58:32,429 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 10 (collect at PaidPromotionAdjustParameter.scala:146) with 2 output partitions
2021-12-06 14:58:32,429 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 26 (collect at PaidPromotionAdjustParameter.scala:146)
2021-12-06 14:58:32,429 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 25, ShuffleMapStage 23)
2021-12-06 14:58:32,429 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2021-12-06 14:58:32,429 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 26 (MapPartitionsRDD[18] at intersection at PaidPromotionAdjustParameter.scala:130), which has no missing parents
2021-12-06 14:58:32,430 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_19 stored as values in memory (estimated size 3.8 KB, free 1990.4 MB)
2021-12-06 14:58:32,431 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_19_piece0 stored as bytes in memory (estimated size 2.2 KB, free 1990.4 MB)
2021-12-06 14:58:32,432 [dispatcher-event-loop-1] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_19_piece0 in memory on qb:60678 (size: 2.2 KB, free: 1990.8 MB)
2021-12-06 14:58:32,433 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 19 from broadcast at DAGScheduler.scala:1039
2021-12-06 14:58:32,433 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from ResultStage 26 (MapPartitionsRDD[18] at intersection at PaidPromotionAdjustParameter.scala:130) (first 15 tasks are for partitions Vector(0, 1))
2021-12-06 14:58:32,433 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 26.0 with 2 tasks
2021-12-06 14:58:32,434 [dispatcher-event-loop-11] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 26.0 (TID 36, localhost, executor driver, partition 0, PROCESS_LOCAL, 7712 bytes)
2021-12-06 14:58:32,434 [dispatcher-event-loop-11] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 26.0 (TID 37, localhost, executor driver, partition 1, PROCESS_LOCAL, 7712 bytes)
2021-12-06 14:58:32,434 [Executor task launch worker for task 37] INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 26.0 (TID 37)
2021-12-06 14:58:32,434 [Executor task launch worker for task 36] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 26.0 (TID 36)
2021-12-06 14:58:32,435 [Executor task launch worker for task 37] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2021-12-06 14:58:32,435 [Executor task launch worker for task 36] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2021-12-06 14:58:32,436 [Executor task launch worker for task 37] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 1 ms
2021-12-06 14:58:32,436 [Executor task launch worker for task 36] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 1 ms
2021-12-06 14:58:32,437 [Executor task launch worker for task 36] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2021-12-06 14:58:32,437 [Executor task launch worker for task 36] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-06 14:58:32,437 [Executor task launch worker for task 37] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2021-12-06 14:58:32,437 [Executor task launch worker for task 37] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-06 14:58:32,447 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 328
2021-12-06 14:58:32,447 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 326
2021-12-06 14:58:32,447 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 346
2021-12-06 14:58:32,447 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 356
2021-12-06 14:58:32,447 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 290
2021-12-06 14:58:32,447 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 403
2021-12-06 14:58:32,447 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 440
2021-12-06 14:58:32,447 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 398
2021-12-06 14:58:32,447 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 296
2021-12-06 14:58:32,447 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 391
2021-12-06 14:58:32,447 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 298
2021-12-06 14:58:32,447 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 278
2021-12-06 14:58:32,447 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 405
2021-12-06 14:58:32,447 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 316
2021-12-06 14:58:32,447 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 276
2021-12-06 14:58:32,447 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 386
2021-12-06 14:58:32,447 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 364
2021-12-06 14:58:32,447 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 289
2021-12-06 14:58:32,447 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 432
2021-12-06 14:58:32,447 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 388
2021-12-06 14:58:32,447 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 314
2021-12-06 14:58:32,448 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 291
2021-12-06 14:58:32,448 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 323
2021-12-06 14:58:32,448 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 392
2021-12-06 14:58:32,448 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 424
2021-12-06 14:58:32,448 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 320
2021-12-06 14:58:32,448 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 354
2021-12-06 14:58:32,448 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 348
2021-12-06 14:58:32,448 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 340
2021-12-06 14:58:32,448 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 406
2021-12-06 14:58:32,448 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 295
2021-12-06 14:58:32,448 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 302
2021-12-06 14:58:32,448 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 412
2021-12-06 14:58:32,448 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 304
2021-12-06 14:58:32,448 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 435
2021-12-06 14:58:32,448 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 336
2021-12-06 14:58:32,448 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 389
2021-12-06 14:58:32,448 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 436
2021-12-06 14:58:32,448 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 368
2021-12-06 14:58:32,448 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 445
2021-12-06 14:58:32,448 [dispatcher-event-loop-0] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_12_piece0 on qb:60678 in memory (size: 2.9 KB, free: 1990.8 MB)
2021-12-06 14:58:32,449 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 361
2021-12-06 14:58:32,449 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 448
2021-12-06 14:58:32,449 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 353
2021-12-06 14:58:32,449 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 282
2021-12-06 14:58:32,449 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 420
2021-12-06 14:58:32,449 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 396
2021-12-06 14:58:32,449 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 359
2021-12-06 14:58:32,449 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 343
2021-12-06 14:58:32,449 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 413
2021-12-06 14:58:32,449 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 407
2021-12-06 14:58:32,449 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 325
2021-12-06 14:58:32,449 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 280
2021-12-06 14:58:32,449 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 275
2021-12-06 14:58:32,449 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 309
2021-12-06 14:58:32,449 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 357
2021-12-06 14:58:32,449 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 433
2021-12-06 14:58:32,449 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 443
2021-12-06 14:58:32,449 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 380
2021-12-06 14:58:32,449 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 428
2021-12-06 14:58:32,449 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 300
2021-12-06 14:58:32,450 [dispatcher-event-loop-10] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_14_piece0 on qb:60678 in memory (size: 2.9 KB, free: 1990.8 MB)
2021-12-06 14:58:32,450 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 419
2021-12-06 14:58:32,450 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 308
2021-12-06 14:58:32,450 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 367
2021-12-06 14:58:32,450 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 285
2021-12-06 14:58:32,450 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 358
2021-12-06 14:58:32,450 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 402
2021-12-06 14:58:32,450 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 390
2021-12-06 14:58:32,450 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 362
2021-12-06 14:58:32,450 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 310
2021-12-06 14:58:32,450 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 338
2021-12-06 14:58:32,450 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 339
2021-12-06 14:58:32,450 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 395
2021-12-06 14:58:32,451 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 324
2021-12-06 14:58:32,451 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 399
2021-12-06 14:58:32,451 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 335
2021-12-06 14:58:32,451 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 332
2021-12-06 14:58:32,451 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 319
2021-12-06 14:58:32,451 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 430
2021-12-06 14:58:32,451 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 318
2021-12-06 14:58:32,451 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 438
2021-12-06 14:58:32,451 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 384
2021-12-06 14:58:32,451 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 426
2021-12-06 14:58:32,451 [dispatcher-event-loop-1] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_18_piece0 on qb:60678 in memory (size: 2.1 KB, free: 1990.8 MB)
2021-12-06 14:58:32,452 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 344
2021-12-06 14:58:32,452 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 331
2021-12-06 14:58:32,452 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 387
2021-12-06 14:58:32,452 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 313
2021-12-06 14:58:32,452 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 371
2021-12-06 14:58:32,452 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 327
2021-12-06 14:58:32,452 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 375
2021-12-06 14:58:32,452 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 305
2021-12-06 14:58:32,452 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 383
2021-12-06 14:58:32,452 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 321
2021-12-06 14:58:32,452 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 414
2021-12-06 14:58:32,452 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 366
2021-12-06 14:58:32,452 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 315
2021-12-06 14:58:32,452 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 347
2021-12-06 14:58:32,452 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 342
2021-12-06 14:58:32,452 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 360
2021-12-06 14:58:32,452 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 401
2021-12-06 14:58:32,452 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 421
2021-12-06 14:58:32,452 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 437
2021-12-06 14:58:32,452 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 299
2021-12-06 14:58:32,452 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 411
2021-12-06 14:58:32,452 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 415
2021-12-06 14:58:32,452 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 369
2021-12-06 14:58:32,452 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 301
2021-12-06 14:58:32,452 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 381
2021-12-06 14:58:32,452 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 417
2021-12-06 14:58:32,452 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 409
2021-12-06 14:58:32,452 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 279
2021-12-06 14:58:32,452 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 329
2021-12-06 14:58:32,452 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 442
2021-12-06 14:58:32,452 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 333
2021-12-06 14:58:32,452 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 307
2021-12-06 14:58:32,452 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 283
2021-12-06 14:58:32,452 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 350
2021-12-06 14:58:32,452 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 372
2021-12-06 14:58:32,452 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 341
2021-12-06 14:58:32,452 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 312
2021-12-06 14:58:32,452 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 370
2021-12-06 14:58:32,453 [dispatcher-event-loop-2] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_16_piece0 on qb:60678 in memory (size: 2.3 KB, free: 1990.8 MB)
2021-12-06 14:58:32,453 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 330
2021-12-06 14:58:32,453 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 404
2021-12-06 14:58:32,454 [dispatcher-event-loop-0] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_17_piece0 on qb:60678 in memory (size: 2.3 KB, free: 1990.8 MB)
2021-12-06 14:58:32,454 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 322
2021-12-06 14:58:32,454 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 288
2021-12-06 14:58:32,454 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 351
2021-12-06 14:58:32,454 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 374
2021-12-06 14:58:32,454 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 349
2021-12-06 14:58:32,454 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 408
2021-12-06 14:58:32,455 [dispatcher-event-loop-10] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_13_piece0 on qb:60678 in memory (size: 2.2 KB, free: 1990.8 MB)
2021-12-06 14:58:32,455 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 377
2021-12-06 14:58:32,455 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 397
2021-12-06 14:58:32,455 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 292
2021-12-06 14:58:32,455 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 365
2021-12-06 14:58:32,455 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 293
2021-12-06 14:58:32,455 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 446
2021-12-06 14:58:32,455 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 427
2021-12-06 14:58:32,455 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 385
2021-12-06 14:58:32,455 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 422
2021-12-06 14:58:32,455 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 345
2021-12-06 14:58:32,455 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 394
2021-12-06 14:58:32,455 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 311
2021-12-06 14:58:32,455 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 337
2021-12-06 14:58:32,455 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 287
2021-12-06 14:58:32,455 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 281
2021-12-06 14:58:32,455 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 441
2021-12-06 14:58:32,455 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 429
2021-12-06 14:58:32,455 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 352
2021-12-06 14:58:32,455 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 303
2021-12-06 14:58:32,456 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 317
2021-12-06 14:58:32,456 [dispatcher-event-loop-1] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_15_piece0 on qb:60678 in memory (size: 2.2 KB, free: 1990.8 MB)
2021-12-06 14:58:32,456 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 449
2021-12-06 14:58:32,456 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 439
2021-12-06 14:58:32,456 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 393
2021-12-06 14:58:32,457 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 418
2021-12-06 14:58:32,457 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 376
2021-12-06 14:58:32,457 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 355
2021-12-06 14:58:32,457 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 416
2021-12-06 14:58:32,457 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 284
2021-12-06 14:58:32,457 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 379
2021-12-06 14:58:32,457 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 378
2021-12-06 14:58:32,457 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 334
2021-12-06 14:58:32,457 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 306
2021-12-06 14:58:32,457 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 382
2021-12-06 14:58:32,457 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 294
2021-12-06 14:58:32,457 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 363
2021-12-06 14:58:32,457 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 423
2021-12-06 14:58:32,457 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 400
2021-12-06 14:58:32,457 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 277
2021-12-06 14:58:32,457 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 444
2021-12-06 14:58:32,457 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 434
2021-12-06 14:58:32,457 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 447
2021-12-06 14:58:32,457 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 286
2021-12-06 14:58:32,457 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 431
2021-12-06 14:58:32,457 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 425
2021-12-06 14:58:32,457 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 297
2021-12-06 14:58:32,457 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 373
2021-12-06 14:58:32,457 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 410
2021-12-06 14:58:32,541 [Executor task launch worker for task 37] INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 26.0 (TID 37). 87635 bytes result sent to driver
2021-12-06 14:58:32,541 [Executor task launch worker for task 36] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 26.0 (TID 36). 86341 bytes result sent to driver
2021-12-06 14:58:32,543 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 26.0 (TID 36) in 109 ms on localhost (executor driver) (1/2)
2021-12-06 14:58:32,543 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 26.0 (TID 37) in 109 ms on localhost (executor driver) (2/2)
2021-12-06 14:58:32,543 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 26.0, whose tasks have all completed, from pool 
2021-12-06 14:58:32,543 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 26 (collect at PaidPromotionAdjustParameter.scala:146) finished in 0.114 s
2021-12-06 14:58:32,543 [main] INFO [org.apache.spark.scheduler.DAGScheduler] - Job 10 finished: collect at PaidPromotionAdjustParameter.scala:146, took 0.114846 s
2021-12-06 14:58:32,549 [main] INFO [org.apache.spark.SparkContext] - Starting job: collect at PaidPromotionAdjustParameter.scala:147
2021-12-06 14:58:32,549 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 11 (collect at PaidPromotionAdjustParameter.scala:147) with 2 output partitions
2021-12-06 14:58:32,549 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 31 (collect at PaidPromotionAdjustParameter.scala:147)
2021-12-06 14:58:32,549 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 30, ShuffleMapStage 28)
2021-12-06 14:58:32,549 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2021-12-06 14:58:32,549 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 31 (MapPartitionsRDD[32] at intersection at PaidPromotionAdjustParameter.scala:135), which has no missing parents
2021-12-06 14:58:32,550 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_20 stored as values in memory (estimated size 3.8 KB, free 1990.5 MB)
2021-12-06 14:58:32,552 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_20_piece0 stored as bytes in memory (estimated size 2.2 KB, free 1990.5 MB)
2021-12-06 14:58:32,552 [dispatcher-event-loop-2] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_20_piece0 in memory on qb:60678 (size: 2.2 KB, free: 1990.8 MB)
2021-12-06 14:58:32,553 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 20 from broadcast at DAGScheduler.scala:1039
2021-12-06 14:58:32,553 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from ResultStage 31 (MapPartitionsRDD[32] at intersection at PaidPromotionAdjustParameter.scala:135) (first 15 tasks are for partitions Vector(0, 1))
2021-12-06 14:58:32,553 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 31.0 with 2 tasks
2021-12-06 14:58:32,553 [dispatcher-event-loop-6] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 31.0 (TID 38, localhost, executor driver, partition 0, PROCESS_LOCAL, 7712 bytes)
2021-12-06 14:58:32,553 [dispatcher-event-loop-6] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 31.0 (TID 39, localhost, executor driver, partition 1, PROCESS_LOCAL, 7712 bytes)
2021-12-06 14:58:32,554 [Executor task launch worker for task 38] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 31.0 (TID 38)
2021-12-06 14:58:32,554 [Executor task launch worker for task 39] INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 31.0 (TID 39)
2021-12-06 14:58:32,555 [Executor task launch worker for task 38] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2021-12-06 14:58:32,555 [Executor task launch worker for task 38] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 1 ms
2021-12-06 14:58:32,555 [Executor task launch worker for task 39] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2021-12-06 14:58:32,555 [Executor task launch worker for task 39] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-06 14:58:32,556 [Executor task launch worker for task 38] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2021-12-06 14:58:32,556 [Executor task launch worker for task 38] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-06 14:58:32,556 [Executor task launch worker for task 39] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2021-12-06 14:58:32,556 [Executor task launch worker for task 39] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-06 14:58:32,561 [Executor task launch worker for task 39] INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 31.0 (TID 39). 2650 bytes result sent to driver
2021-12-06 14:58:32,561 [Executor task launch worker for task 38] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 31.0 (TID 38). 2749 bytes result sent to driver
2021-12-06 14:58:32,561 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 31.0 (TID 39) in 8 ms on localhost (executor driver) (1/2)
2021-12-06 14:58:32,562 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 31.0 (TID 38) in 9 ms on localhost (executor driver) (2/2)
2021-12-06 14:58:32,562 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 31.0, whose tasks have all completed, from pool 
2021-12-06 14:58:32,562 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 31 (collect at PaidPromotionAdjustParameter.scala:147) finished in 0.012 s
2021-12-06 14:58:32,562 [main] INFO [org.apache.spark.scheduler.DAGScheduler] - Job 11 finished: collect at PaidPromotionAdjustParameter.scala:147, took 0.013564 s
2021-12-06 14:58:32,581 [main] INFO [org.apache.spark.SparkContext] - Starting job: count at PaidPromotionAdjustParameter.scala:156
2021-12-06 14:58:32,583 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 12 (count at PaidPromotionAdjustParameter.scala:156) with 4 output partitions
2021-12-06 14:58:32,583 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 32 (count at PaidPromotionAdjustParameter.scala:156)
2021-12-06 14:58:32,583 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List()
2021-12-06 14:58:32,583 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2021-12-06 14:58:32,583 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 32 (UnionRDD[35] at union at PaidPromotionAdjustParameter.scala:154), which has no missing parents
2021-12-06 14:58:32,593 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_21 stored as values in memory (estimated size 184.8 KB, free 1990.3 MB)
2021-12-06 14:58:32,597 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_21_piece0 stored as bytes in memory (estimated size 65.5 KB, free 1990.2 MB)
2021-12-06 14:58:32,597 [dispatcher-event-loop-10] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_21_piece0 in memory on qb:60678 (size: 65.5 KB, free: 1990.7 MB)
2021-12-06 14:58:32,597 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 21 from broadcast at DAGScheduler.scala:1039
2021-12-06 14:58:32,598 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 4 missing tasks from ResultStage 32 (UnionRDD[35] at union at PaidPromotionAdjustParameter.scala:154) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
2021-12-06 14:58:32,598 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 32.0 with 4 tasks
2021-12-06 14:58:32,600 [dispatcher-event-loop-4] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 32.0 (TID 40, localhost, executor driver, partition 0, ANY, 8005 bytes)
2021-12-06 14:58:32,600 [dispatcher-event-loop-4] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 32.0 (TID 41, localhost, executor driver, partition 1, ANY, 8005 bytes)
2021-12-06 14:58:32,600 [dispatcher-event-loop-4] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 2.0 in stage 32.0 (TID 42, localhost, executor driver, partition 2, ANY, 8005 bytes)
2021-12-06 14:58:32,600 [dispatcher-event-loop-4] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 3.0 in stage 32.0 (TID 43, localhost, executor driver, partition 3, ANY, 8005 bytes)
2021-12-06 14:58:32,601 [Executor task launch worker for task 42] INFO [org.apache.spark.executor.Executor] - Running task 2.0 in stage 32.0 (TID 42)
2021-12-06 14:58:32,601 [Executor task launch worker for task 40] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 32.0 (TID 40)
2021-12-06 14:58:32,601 [Executor task launch worker for task 43] INFO [org.apache.spark.executor.Executor] - Running task 3.0 in stage 32.0 (TID 43)
2021-12-06 14:58:32,601 [Executor task launch worker for task 41] INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 32.0 (TID 41)
2021-12-06 14:58:32,606 [Executor task launch worker for task 43] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/order_data.bcp:3442194+3442195
2021-12-06 14:58:32,607 [Executor task launch worker for task 42] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/order_data.bcp:0+3442194
2021-12-06 14:58:32,607 [Executor task launch worker for task 41] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/order_data.bcp:3442194+3442195
2021-12-06 14:58:32,607 [Executor task launch worker for task 40] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/order_data.bcp:0+3442194
2021-12-06 14:58:33,573 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 455
2021-12-06 14:58:33,573 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 464
2021-12-06 14:58:33,573 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 466
2021-12-06 14:58:33,573 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 454
2021-12-06 14:58:33,573 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 452
2021-12-06 14:58:33,573 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 473
2021-12-06 14:58:33,573 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 495
2021-12-06 14:58:33,573 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 453
2021-12-06 14:58:33,573 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 491
2021-12-06 14:58:33,573 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 485
2021-12-06 14:58:33,573 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 457
2021-12-06 14:58:33,573 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 465
2021-12-06 14:58:33,573 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 490
2021-12-06 14:58:33,573 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 463
2021-12-06 14:58:33,573 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 484
2021-12-06 14:58:33,573 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 489
2021-12-06 14:58:33,573 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 487
2021-12-06 14:58:33,574 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 498
2021-12-06 14:58:33,574 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 476
2021-12-06 14:58:33,574 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 478
2021-12-06 14:58:33,574 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 494
2021-12-06 14:58:33,574 [dispatcher-event-loop-5] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_20_piece0 on qb:60678 in memory (size: 2.2 KB, free: 1990.7 MB)
2021-12-06 14:58:33,575 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 475
2021-12-06 14:58:33,575 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 483
2021-12-06 14:58:33,575 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 468
2021-12-06 14:58:33,575 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 458
2021-12-06 14:58:33,575 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 467
2021-12-06 14:58:33,575 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 499
2021-12-06 14:58:33,575 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 496
2021-12-06 14:58:33,575 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 482
2021-12-06 14:58:33,575 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 460
2021-12-06 14:58:33,575 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 456
2021-12-06 14:58:33,575 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 472
2021-12-06 14:58:33,575 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 481
2021-12-06 14:58:33,575 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 480
2021-12-06 14:58:33,575 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 474
2021-12-06 14:58:33,575 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 471
2021-12-06 14:58:33,575 [dispatcher-event-loop-8] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_19_piece0 on qb:60678 in memory (size: 2.2 KB, free: 1990.7 MB)
2021-12-06 14:58:33,576 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 488
2021-12-06 14:58:33,576 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 497
2021-12-06 14:58:33,576 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 479
2021-12-06 14:58:33,576 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 492
2021-12-06 14:58:33,576 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 451
2021-12-06 14:58:33,576 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 477
2021-12-06 14:58:33,576 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 469
2021-12-06 14:58:33,576 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 486
2021-12-06 14:58:33,576 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 461
2021-12-06 14:58:33,576 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 450
2021-12-06 14:58:33,576 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 462
2021-12-06 14:58:33,576 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 470
2021-12-06 14:58:33,576 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 493
2021-12-06 14:58:33,576 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 459
2021-12-06 14:58:33,755 [Executor task launch worker for task 43] INFO [org.apache.spark.executor.Executor] - Finished task 3.0 in stage 32.0 (TID 43). 754 bytes result sent to driver
2021-12-06 14:58:33,755 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 3.0 in stage 32.0 (TID 43) in 1155 ms on localhost (executor driver) (1/4)
2021-12-06 14:58:34,043 [Executor task launch worker for task 41] INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 32.0 (TID 41). 797 bytes result sent to driver
2021-12-06 14:58:34,044 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 32.0 (TID 41) in 1444 ms on localhost (executor driver) (2/4)
2021-12-06 14:58:34,080 [Executor task launch worker for task 42] INFO [org.apache.spark.executor.Executor] - Finished task 2.0 in stage 32.0 (TID 42). 797 bytes result sent to driver
2021-12-06 14:58:34,081 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 2.0 in stage 32.0 (TID 42) in 1481 ms on localhost (executor driver) (3/4)
2021-12-06 14:58:34,607 [Executor task launch worker for task 40] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 32.0 (TID 40). 797 bytes result sent to driver
2021-12-06 14:58:34,608 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 32.0 (TID 40) in 2009 ms on localhost (executor driver) (4/4)
2021-12-06 14:58:34,608 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 32.0, whose tasks have all completed, from pool 
2021-12-06 14:58:34,608 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 32 (count at PaidPromotionAdjustParameter.scala:156) finished in 2.024 s
2021-12-06 14:58:34,608 [main] INFO [org.apache.spark.scheduler.DAGScheduler] - Job 12 finished: count at PaidPromotionAdjustParameter.scala:156, took 2.026739 s
2021-12-06 14:58:34,608 [main] INFO [PaidPromotion$] - 100941
2021-12-06 14:58:34,610 [main] INFO [org.apache.spark.SparkContext] - Starting job: count at PaidPromotionAdjustParameter.scala:157
2021-12-06 14:58:34,610 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 13 (count at PaidPromotionAdjustParameter.scala:157) with 2 output partitions
2021-12-06 14:58:34,610 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 33 (count at PaidPromotionAdjustParameter.scala:157)
2021-12-06 14:58:34,610 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List()
2021-12-06 14:58:34,610 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2021-12-06 14:58:34,610 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 33 (MapPartitionsRDD[33] at filter at PaidPromotionAdjustParameter.scala:150), which has no missing parents
2021-12-06 14:58:34,612 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_22 stored as values in memory (estimated size 184.2 KB, free 1990.0 MB)
2021-12-06 14:58:34,614 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_22_piece0 stored as bytes in memory (estimated size 65.0 KB, free 1990.0 MB)
2021-12-06 14:58:34,614 [dispatcher-event-loop-11] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_22_piece0 in memory on qb:60678 (size: 65.0 KB, free: 1990.6 MB)
2021-12-06 14:58:34,614 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 22 from broadcast at DAGScheduler.scala:1039
2021-12-06 14:58:34,614 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from ResultStage 33 (MapPartitionsRDD[33] at filter at PaidPromotionAdjustParameter.scala:150) (first 15 tasks are for partitions Vector(0, 1))
2021-12-06 14:58:34,614 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 33.0 with 2 tasks
2021-12-06 14:58:34,615 [dispatcher-event-loop-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 33.0 (TID 44, localhost, executor driver, partition 0, ANY, 7896 bytes)
2021-12-06 14:58:34,615 [dispatcher-event-loop-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 33.0 (TID 45, localhost, executor driver, partition 1, ANY, 7896 bytes)
2021-12-06 14:58:34,615 [Executor task launch worker for task 45] INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 33.0 (TID 45)
2021-12-06 14:58:34,615 [Executor task launch worker for task 44] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 33.0 (TID 44)
2021-12-06 14:58:34,617 [Executor task launch worker for task 44] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/order_data.bcp:0+3442194
2021-12-06 14:58:34,617 [Executor task launch worker for task 45] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/order_data.bcp:3442194+3442195
2021-12-06 14:58:35,795 [Executor task launch worker for task 45] INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 33.0 (TID 45). 710 bytes result sent to driver
2021-12-06 14:58:35,796 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 33.0 (TID 45) in 1181 ms on localhost (executor driver) (1/2)
2021-12-06 14:58:35,807 [Executor task launch worker for task 44] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 33.0 (TID 44). 710 bytes result sent to driver
2021-12-06 14:58:35,807 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 33.0 (TID 44) in 1192 ms on localhost (executor driver) (2/2)
2021-12-06 14:58:35,807 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 33.0, whose tasks have all completed, from pool 
2021-12-06 14:58:35,807 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 33 (count at PaidPromotionAdjustParameter.scala:157) finished in 1.196 s
2021-12-06 14:58:35,807 [main] INFO [org.apache.spark.scheduler.DAGScheduler] - Job 13 finished: count at PaidPromotionAdjustParameter.scala:157, took 1.197620 s
2021-12-06 14:58:35,807 [main] INFO [PaidPromotion$] - 6353
2021-12-06 14:58:35,840 [main] INFO [PaidPromotion$] - -----------------------------------
2021-12-06 14:58:35,841 [main] INFO [org.apache.spark.SparkContext] - Starting job: count at PaidPromotionAdjustParameter.scala:169
2021-12-06 14:58:35,842 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 37 (distinct at PaidPromotionAdjustParameter.scala:160)
2021-12-06 14:58:35,842 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 14 (count at PaidPromotionAdjustParameter.scala:169) with 4 output partitions
2021-12-06 14:58:35,842 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 35 (count at PaidPromotionAdjustParameter.scala:169)
2021-12-06 14:58:35,842 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 34)
2021-12-06 14:58:35,842 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List(ShuffleMapStage 34)
2021-12-06 14:58:35,842 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ShuffleMapStage 34 (MapPartitionsRDD[37] at distinct at PaidPromotionAdjustParameter.scala:160), which has no missing parents
2021-12-06 14:58:35,844 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_23 stored as values in memory (estimated size 186.3 KB, free 1989.8 MB)
2021-12-06 14:58:35,849 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 539
2021-12-06 14:58:35,850 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 504
2021-12-06 14:58:35,850 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 531
2021-12-06 14:58:35,850 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 522
2021-12-06 14:58:35,850 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 500
2021-12-06 14:58:35,850 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 516
2021-12-06 14:58:35,850 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 518
2021-12-06 14:58:35,850 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 548
2021-12-06 14:58:35,850 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 506
2021-12-06 14:58:35,850 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 501
2021-12-06 14:58:35,850 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 549
2021-12-06 14:58:35,850 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 529
2021-12-06 14:58:35,850 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 511
2021-12-06 14:58:35,850 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 538
2021-12-06 14:58:35,850 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 507
2021-12-06 14:58:35,850 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 526
2021-12-06 14:58:35,850 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 527
2021-12-06 14:58:35,850 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 515
2021-12-06 14:58:35,850 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 521
2021-12-06 14:58:35,850 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 502
2021-12-06 14:58:35,850 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 534
2021-12-06 14:58:35,850 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 508
2021-12-06 14:58:35,850 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 535
2021-12-06 14:58:35,850 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 505
2021-12-06 14:58:35,850 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 530
2021-12-06 14:58:35,850 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 536
2021-12-06 14:58:35,850 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 540
2021-12-06 14:58:35,850 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 520
2021-12-06 14:58:35,850 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 525
2021-12-06 14:58:35,850 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 517
2021-12-06 14:58:35,850 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 546
2021-12-06 14:58:35,850 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_23_piece0 stored as bytes in memory (estimated size 66.4 KB, free 1989.7 MB)
2021-12-06 14:58:35,851 [dispatcher-event-loop-10] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_23_piece0 in memory on qb:60678 (size: 66.4 KB, free: 1990.6 MB)
2021-12-06 14:58:35,851 [dispatcher-event-loop-10] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_22_piece0 on qb:60678 in memory (size: 65.0 KB, free: 1990.6 MB)
2021-12-06 14:58:35,851 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 23 from broadcast at DAGScheduler.scala:1039
2021-12-06 14:58:35,851 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 524
2021-12-06 14:58:35,851 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 4 missing tasks from ShuffleMapStage 34 (MapPartitionsRDD[37] at distinct at PaidPromotionAdjustParameter.scala:160) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
2021-12-06 14:58:35,851 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 34.0 with 4 tasks
2021-12-06 14:58:35,851 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 514
2021-12-06 14:58:35,851 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 528
2021-12-06 14:58:35,851 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 510
2021-12-06 14:58:35,851 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 509
2021-12-06 14:58:35,851 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 523
2021-12-06 14:58:35,851 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 513
2021-12-06 14:58:35,851 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 512
2021-12-06 14:58:35,852 [dispatcher-event-loop-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 34.0 (TID 46, localhost, executor driver, partition 0, ANY, 7994 bytes)
2021-12-06 14:58:35,852 [dispatcher-event-loop-3] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_21_piece0 on qb:60678 in memory (size: 65.5 KB, free: 1990.7 MB)
2021-12-06 14:58:35,852 [dispatcher-event-loop-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 34.0 (TID 47, localhost, executor driver, partition 1, ANY, 7994 bytes)
2021-12-06 14:58:35,852 [dispatcher-event-loop-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 2.0 in stage 34.0 (TID 48, localhost, executor driver, partition 2, ANY, 7994 bytes)
2021-12-06 14:58:35,852 [dispatcher-event-loop-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 3.0 in stage 34.0 (TID 49, localhost, executor driver, partition 3, ANY, 7994 bytes)
2021-12-06 14:58:35,852 [Executor task launch worker for task 47] INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 34.0 (TID 47)
2021-12-06 14:58:35,852 [Executor task launch worker for task 48] INFO [org.apache.spark.executor.Executor] - Running task 2.0 in stage 34.0 (TID 48)
2021-12-06 14:58:35,852 [Executor task launch worker for task 46] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 34.0 (TID 46)
2021-12-06 14:58:35,852 [Executor task launch worker for task 49] INFO [org.apache.spark.executor.Executor] - Running task 3.0 in stage 34.0 (TID 49)
2021-12-06 14:58:35,852 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 519
2021-12-06 14:58:35,852 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 544
2021-12-06 14:58:35,852 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 541
2021-12-06 14:58:35,853 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 537
2021-12-06 14:58:35,853 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 545
2021-12-06 14:58:35,853 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 532
2021-12-06 14:58:35,853 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 543
2021-12-06 14:58:35,853 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 542
2021-12-06 14:58:35,853 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 503
2021-12-06 14:58:35,853 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 533
2021-12-06 14:58:35,853 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 547
2021-12-06 14:58:35,855 [Executor task launch worker for task 49] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/order_data.bcp:3442194+3442195
2021-12-06 14:58:35,856 [Executor task launch worker for task 46] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/order_data.bcp:0+3442194
2021-12-06 14:58:35,856 [Executor task launch worker for task 47] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/order_data.bcp:3442194+3442195
2021-12-06 14:58:35,856 [Executor task launch worker for task 48] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/order_data.bcp:0+3442194
2021-12-06 14:58:36,811 [Executor task launch worker for task 47] INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 34.0 (TID 47). 991 bytes result sent to driver
2021-12-06 14:58:36,811 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 34.0 (TID 47) in 959 ms on localhost (executor driver) (1/4)
2021-12-06 14:58:37,174 [Executor task launch worker for task 48] INFO [org.apache.spark.executor.Executor] - Finished task 2.0 in stage 34.0 (TID 48). 1034 bytes result sent to driver
2021-12-06 14:58:37,174 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 2.0 in stage 34.0 (TID 48) in 1322 ms on localhost (executor driver) (2/4)
2021-12-06 14:58:37,388 [Executor task launch worker for task 49] INFO [org.apache.spark.executor.Executor] - Finished task 3.0 in stage 34.0 (TID 49). 1034 bytes result sent to driver
2021-12-06 14:58:37,389 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 3.0 in stage 34.0 (TID 49) in 1537 ms on localhost (executor driver) (3/4)
2021-12-06 14:58:37,408 [Executor task launch worker for task 46] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 34.0 (TID 46). 1034 bytes result sent to driver
2021-12-06 14:58:37,408 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 34.0 (TID 46) in 1556 ms on localhost (executor driver) (4/4)
2021-12-06 14:58:37,408 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 34.0, whose tasks have all completed, from pool 
2021-12-06 14:58:37,409 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ShuffleMapStage 34 (distinct at PaidPromotionAdjustParameter.scala:160) finished in 1.566 s
2021-12-06 14:58:37,409 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - looking for newly runnable stages
2021-12-06 14:58:37,409 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - running: Set()
2021-12-06 14:58:37,409 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - waiting: Set(ResultStage 35)
2021-12-06 14:58:37,409 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - failed: Set()
2021-12-06 14:58:37,409 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 35 (MapPartitionsRDD[39] at distinct at PaidPromotionAdjustParameter.scala:160), which has no missing parents
2021-12-06 14:58:37,410 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_24 stored as values in memory (estimated size 3.7 KB, free 1990.2 MB)
2021-12-06 14:58:37,411 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_24_piece0 stored as bytes in memory (estimated size 2.2 KB, free 1990.2 MB)
2021-12-06 14:58:37,412 [dispatcher-event-loop-11] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_24_piece0 in memory on qb:60678 (size: 2.2 KB, free: 1990.7 MB)
2021-12-06 14:58:37,412 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 24 from broadcast at DAGScheduler.scala:1039
2021-12-06 14:58:37,412 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 4 missing tasks from ResultStage 35 (MapPartitionsRDD[39] at distinct at PaidPromotionAdjustParameter.scala:160) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
2021-12-06 14:58:37,412 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 35.0 with 4 tasks
2021-12-06 14:58:37,412 [dispatcher-event-loop-9] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 35.0 (TID 50, localhost, executor driver, partition 0, ANY, 7649 bytes)
2021-12-06 14:58:37,413 [dispatcher-event-loop-9] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 35.0 (TID 51, localhost, executor driver, partition 1, ANY, 7649 bytes)
2021-12-06 14:58:37,413 [dispatcher-event-loop-9] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 2.0 in stage 35.0 (TID 52, localhost, executor driver, partition 2, ANY, 7649 bytes)
2021-12-06 14:58:37,413 [dispatcher-event-loop-9] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 3.0 in stage 35.0 (TID 53, localhost, executor driver, partition 3, ANY, 7649 bytes)
2021-12-06 14:58:37,413 [Executor task launch worker for task 50] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 35.0 (TID 50)
2021-12-06 14:58:37,413 [Executor task launch worker for task 53] INFO [org.apache.spark.executor.Executor] - Running task 3.0 in stage 35.0 (TID 53)
2021-12-06 14:58:37,413 [Executor task launch worker for task 52] INFO [org.apache.spark.executor.Executor] - Running task 2.0 in stage 35.0 (TID 52)
2021-12-06 14:58:37,413 [Executor task launch worker for task 51] INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 35.0 (TID 51)
2021-12-06 14:58:37,414 [Executor task launch worker for task 50] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 4 non-empty blocks out of 4 blocks
2021-12-06 14:58:37,414 [Executor task launch worker for task 52] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 4 non-empty blocks out of 4 blocks
2021-12-06 14:58:37,414 [Executor task launch worker for task 50] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-06 14:58:37,414 [Executor task launch worker for task 52] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-06 14:58:37,414 [Executor task launch worker for task 51] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 4 non-empty blocks out of 4 blocks
2021-12-06 14:58:37,414 [Executor task launch worker for task 51] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-06 14:58:37,414 [Executor task launch worker for task 53] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 4 non-empty blocks out of 4 blocks
2021-12-06 14:58:37,414 [Executor task launch worker for task 53] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-06 14:58:37,459 [Executor task launch worker for task 51] INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 35.0 (TID 51). 1012 bytes result sent to driver
2021-12-06 14:58:37,459 [Executor task launch worker for task 52] INFO [org.apache.spark.executor.Executor] - Finished task 2.0 in stage 35.0 (TID 52). 1012 bytes result sent to driver
2021-12-06 14:58:37,459 [Executor task launch worker for task 53] INFO [org.apache.spark.executor.Executor] - Finished task 3.0 in stage 35.0 (TID 53). 1012 bytes result sent to driver
2021-12-06 14:58:37,459 [Executor task launch worker for task 50] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 35.0 (TID 50). 1055 bytes result sent to driver
2021-12-06 14:58:37,460 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 35.0 (TID 51) in 47 ms on localhost (executor driver) (1/4)
2021-12-06 14:58:37,460 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 2.0 in stage 35.0 (TID 52) in 47 ms on localhost (executor driver) (2/4)
2021-12-06 14:58:37,460 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 3.0 in stage 35.0 (TID 53) in 47 ms on localhost (executor driver) (3/4)
2021-12-06 14:58:37,460 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 35.0 (TID 50) in 48 ms on localhost (executor driver) (4/4)
2021-12-06 14:58:37,460 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 35.0, whose tasks have all completed, from pool 
2021-12-06 14:58:37,460 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 35 (count at PaidPromotionAdjustParameter.scala:169) finished in 0.051 s
2021-12-06 14:58:37,460 [main] INFO [org.apache.spark.scheduler.DAGScheduler] - Job 14 finished: count at PaidPromotionAdjustParameter.scala:169, took 1.618534 s
2021-12-06 14:58:37,461 [main] INFO [PaidPromotion$] -  = 95323
2021-12-06 14:58:37,463 [main] INFO [org.apache.spark.SparkContext] - Starting job: count at PaidPromotionAdjustParameter.scala:170
2021-12-06 14:58:37,463 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 41 (distinct at PaidPromotionAdjustParameter.scala:161)
2021-12-06 14:58:37,463 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 15 (count at PaidPromotionAdjustParameter.scala:170) with 2 output partitions
2021-12-06 14:58:37,463 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 37 (count at PaidPromotionAdjustParameter.scala:170)
2021-12-06 14:58:37,463 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 36)
2021-12-06 14:58:37,463 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List(ShuffleMapStage 36)
2021-12-06 14:58:37,463 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ShuffleMapStage 36 (MapPartitionsRDD[41] at distinct at PaidPromotionAdjustParameter.scala:161), which has no missing parents
2021-12-06 14:58:37,465 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_25 stored as values in memory (estimated size 185.8 KB, free 1990.0 MB)
2021-12-06 14:58:37,467 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_25_piece0 stored as bytes in memory (estimated size 66.0 KB, free 1990.0 MB)
2021-12-06 14:58:37,468 [dispatcher-event-loop-4] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_25_piece0 in memory on qb:60678 (size: 66.0 KB, free: 1990.6 MB)
2021-12-06 14:58:37,468 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 25 from broadcast at DAGScheduler.scala:1039
2021-12-06 14:58:37,468 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from ShuffleMapStage 36 (MapPartitionsRDD[41] at distinct at PaidPromotionAdjustParameter.scala:161) (first 15 tasks are for partitions Vector(0, 1))
2021-12-06 14:58:37,468 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 36.0 with 2 tasks
2021-12-06 14:58:37,468 [dispatcher-event-loop-10] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 36.0 (TID 54, localhost, executor driver, partition 0, ANY, 7885 bytes)
2021-12-06 14:58:37,469 [dispatcher-event-loop-10] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 36.0 (TID 55, localhost, executor driver, partition 1, ANY, 7885 bytes)
2021-12-06 14:58:37,469 [Executor task launch worker for task 55] INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 36.0 (TID 55)
2021-12-06 14:58:37,469 [Executor task launch worker for task 54] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 36.0 (TID 54)
2021-12-06 14:58:37,471 [Executor task launch worker for task 54] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/order_data.bcp:0+3442194
2021-12-06 14:58:37,471 [Executor task launch worker for task 55] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/order_data.bcp:3442194+3442195
2021-12-06 14:58:38,562 [Executor task launch worker for task 55] INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 36.0 (TID 55). 1032 bytes result sent to driver
2021-12-06 14:58:38,562 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 36.0 (TID 55) in 1093 ms on localhost (executor driver) (1/2)
2021-12-06 14:58:40,375 [Executor task launch worker for task 54] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 36.0 (TID 54). 989 bytes result sent to driver
2021-12-06 14:58:40,375 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 36.0 (TID 54) in 2907 ms on localhost (executor driver) (2/2)
2021-12-06 14:58:40,375 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 36.0, whose tasks have all completed, from pool 
2021-12-06 14:58:40,376 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ShuffleMapStage 36 (distinct at PaidPromotionAdjustParameter.scala:161) finished in 2.911 s
2021-12-06 14:58:40,376 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - looking for newly runnable stages
2021-12-06 14:58:40,376 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - running: Set()
2021-12-06 14:58:40,376 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - waiting: Set(ResultStage 37)
2021-12-06 14:58:40,376 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - failed: Set()
2021-12-06 14:58:40,376 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 37 (MapPartitionsRDD[43] at distinct at PaidPromotionAdjustParameter.scala:161), which has no missing parents
2021-12-06 14:58:40,376 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_26 stored as values in memory (estimated size 3.7 KB, free 1990.0 MB)
2021-12-06 14:58:40,378 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_26_piece0 stored as bytes in memory (estimated size 2.2 KB, free 1990.0 MB)
2021-12-06 14:58:40,378 [dispatcher-event-loop-7] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_26_piece0 in memory on qb:60678 (size: 2.2 KB, free: 1990.6 MB)
2021-12-06 14:58:40,378 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 26 from broadcast at DAGScheduler.scala:1039
2021-12-06 14:58:40,379 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from ResultStage 37 (MapPartitionsRDD[43] at distinct at PaidPromotionAdjustParameter.scala:161) (first 15 tasks are for partitions Vector(0, 1))
2021-12-06 14:58:40,379 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 37.0 with 2 tasks
2021-12-06 14:58:40,379 [dispatcher-event-loop-8] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 37.0 (TID 56, localhost, executor driver, partition 0, ANY, 7649 bytes)
2021-12-06 14:58:40,379 [dispatcher-event-loop-8] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 37.0 (TID 57, localhost, executor driver, partition 1, ANY, 7649 bytes)
2021-12-06 14:58:40,379 [Executor task launch worker for task 57] INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 37.0 (TID 57)
2021-12-06 14:58:40,379 [Executor task launch worker for task 56] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 37.0 (TID 56)
2021-12-06 14:58:40,380 [Executor task launch worker for task 56] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 2 non-empty blocks out of 2 blocks
2021-12-06 14:58:40,380 [Executor task launch worker for task 57] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 2 non-empty blocks out of 2 blocks
2021-12-06 14:58:40,380 [Executor task launch worker for task 56] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-06 14:58:40,380 [Executor task launch worker for task 57] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-06 14:58:40,397 [Executor task launch worker for task 57] INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 37.0 (TID 57). 1011 bytes result sent to driver
2021-12-06 14:58:40,397 [Executor task launch worker for task 56] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 37.0 (TID 56). 1011 bytes result sent to driver
2021-12-06 14:58:40,397 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 37.0 (TID 57) in 18 ms on localhost (executor driver) (1/2)
2021-12-06 14:58:40,397 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 37.0 (TID 56) in 18 ms on localhost (executor driver) (2/2)
2021-12-06 14:58:40,397 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 37.0, whose tasks have all completed, from pool 
2021-12-06 14:58:40,397 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 37 (count at PaidPromotionAdjustParameter.scala:170) finished in 0.021 s
2021-12-06 14:58:40,397 [main] INFO [org.apache.spark.scheduler.DAGScheduler] - Job 15 finished: count at PaidPromotionAdjustParameter.scala:170, took 2.935124 s
2021-12-06 14:58:40,398 [main] INFO [PaidPromotion$] -  = 5174
2021-12-06 14:58:40,400 [main] INFO [org.apache.spark.SparkContext] - Starting job: count at PaidPromotionAdjustParameter.scala:171
2021-12-06 14:58:40,400 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 45 (intersection at PaidPromotionAdjustParameter.scala:162)
2021-12-06 14:58:40,400 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 44 (intersection at PaidPromotionAdjustParameter.scala:162)
2021-12-06 14:58:40,401 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 16 (count at PaidPromotionAdjustParameter.scala:171) with 4 output partitions
2021-12-06 14:58:40,401 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 42 (count at PaidPromotionAdjustParameter.scala:171)
2021-12-06 14:58:40,401 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 39, ShuffleMapStage 41)
2021-12-06 14:58:40,401 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List(ShuffleMapStage 39, ShuffleMapStage 41)
2021-12-06 14:58:40,401 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ShuffleMapStage 39 (MapPartitionsRDD[45] at intersection at PaidPromotionAdjustParameter.scala:162), which has no missing parents
2021-12-06 14:58:40,401 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_27 stored as values in memory (estimated size 4.0 KB, free 1990.0 MB)
2021-12-06 14:58:40,403 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_27_piece0 stored as bytes in memory (estimated size 2.3 KB, free 1990.0 MB)
2021-12-06 14:58:40,403 [dispatcher-event-loop-11] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_27_piece0 in memory on qb:60678 (size: 2.3 KB, free: 1990.6 MB)
2021-12-06 14:58:40,404 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 27 from broadcast at DAGScheduler.scala:1039
2021-12-06 14:58:40,404 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from ShuffleMapStage 39 (MapPartitionsRDD[45] at intersection at PaidPromotionAdjustParameter.scala:162) (first 15 tasks are for partitions Vector(0, 1))
2021-12-06 14:58:40,404 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 39.0 with 2 tasks
2021-12-06 14:58:40,404 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ShuffleMapStage 41 (MapPartitionsRDD[44] at intersection at PaidPromotionAdjustParameter.scala:162), which has no missing parents
2021-12-06 14:58:40,404 [dispatcher-event-loop-9] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 39.0 (TID 58, localhost, executor driver, partition 0, ANY, 7638 bytes)
2021-12-06 14:58:40,404 [dispatcher-event-loop-9] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 39.0 (TID 59, localhost, executor driver, partition 1, ANY, 7638 bytes)
2021-12-06 14:58:40,404 [Executor task launch worker for task 59] INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 39.0 (TID 59)
2021-12-06 14:58:40,404 [Executor task launch worker for task 58] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 39.0 (TID 58)
2021-12-06 14:58:40,405 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_28 stored as values in memory (estimated size 4.0 KB, free 1990.0 MB)
2021-12-06 14:58:40,405 [Executor task launch worker for task 59] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 2 non-empty blocks out of 2 blocks
2021-12-06 14:58:40,405 [Executor task launch worker for task 58] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 2 non-empty blocks out of 2 blocks
2021-12-06 14:58:40,405 [Executor task launch worker for task 59] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-06 14:58:40,405 [Executor task launch worker for task 58] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-06 14:58:40,406 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_28_piece0 stored as bytes in memory (estimated size 2.3 KB, free 1990.0 MB)
2021-12-06 14:58:40,407 [dispatcher-event-loop-6] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_28_piece0 in memory on qb:60678 (size: 2.3 KB, free: 1990.6 MB)
2021-12-06 14:58:40,407 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 28 from broadcast at DAGScheduler.scala:1039
2021-12-06 14:58:40,407 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 4 missing tasks from ShuffleMapStage 41 (MapPartitionsRDD[44] at intersection at PaidPromotionAdjustParameter.scala:162) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
2021-12-06 14:58:40,407 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 41.0 with 4 tasks
2021-12-06 14:58:40,407 [dispatcher-event-loop-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 41.0 (TID 60, localhost, executor driver, partition 0, ANY, 7638 bytes)
2021-12-06 14:58:40,408 [dispatcher-event-loop-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 41.0 (TID 61, localhost, executor driver, partition 1, ANY, 7638 bytes)
2021-12-06 14:58:40,408 [dispatcher-event-loop-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 2.0 in stage 41.0 (TID 62, localhost, executor driver, partition 2, ANY, 7638 bytes)
2021-12-06 14:58:40,408 [dispatcher-event-loop-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 3.0 in stage 41.0 (TID 63, localhost, executor driver, partition 3, ANY, 7638 bytes)
2021-12-06 14:58:40,408 [Executor task launch worker for task 61] INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 41.0 (TID 61)
2021-12-06 14:58:40,408 [Executor task launch worker for task 60] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 41.0 (TID 60)
2021-12-06 14:58:40,408 [Executor task launch worker for task 63] INFO [org.apache.spark.executor.Executor] - Running task 3.0 in stage 41.0 (TID 63)
2021-12-06 14:58:40,408 [Executor task launch worker for task 62] INFO [org.apache.spark.executor.Executor] - Running task 2.0 in stage 41.0 (TID 62)
2021-12-06 14:58:40,409 [Executor task launch worker for task 60] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 4 non-empty blocks out of 4 blocks
2021-12-06 14:58:40,409 [Executor task launch worker for task 61] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 4 non-empty blocks out of 4 blocks
2021-12-06 14:58:40,409 [Executor task launch worker for task 63] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 4 non-empty blocks out of 4 blocks
2021-12-06 14:58:40,409 [Executor task launch worker for task 63] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-06 14:58:40,409 [Executor task launch worker for task 60] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-06 14:58:40,409 [Executor task launch worker for task 61] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-06 14:58:40,409 [Executor task launch worker for task 62] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 4 non-empty blocks out of 4 blocks
2021-12-06 14:58:40,409 [Executor task launch worker for task 62] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-06 14:58:40,440 [Executor task launch worker for task 59] INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 39.0 (TID 59). 1206 bytes result sent to driver
2021-12-06 14:58:40,440 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 39.0 (TID 59) in 36 ms on localhost (executor driver) (1/2)
2021-12-06 14:58:40,450 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 620
2021-12-06 14:58:40,450 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 649
2021-12-06 14:58:40,450 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 554
2021-12-06 14:58:40,450 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 556
2021-12-06 14:58:40,450 [Executor task launch worker for task 58] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 39.0 (TID 58). 1249 bytes result sent to driver
2021-12-06 14:58:40,451 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 39.0 (TID 58) in 47 ms on localhost (executor driver) (2/2)
2021-12-06 14:58:40,451 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 39.0, whose tasks have all completed, from pool 
2021-12-06 14:58:40,451 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ShuffleMapStage 39 (intersection at PaidPromotionAdjustParameter.scala:162) finished in 0.050 s
2021-12-06 14:58:40,451 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - looking for newly runnable stages
2021-12-06 14:58:40,451 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - running: Set(ShuffleMapStage 41)
2021-12-06 14:58:40,451 [dispatcher-event-loop-1] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_23_piece0 on qb:60678 in memory (size: 66.4 KB, free: 1990.7 MB)
2021-12-06 14:58:40,451 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - waiting: Set(ResultStage 42)
2021-12-06 14:58:40,451 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - failed: Set()
2021-12-06 14:58:40,452 [dispatcher-event-loop-7] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_24_piece0 on qb:60678 in memory (size: 2.2 KB, free: 1990.7 MB)
2021-12-06 14:58:40,452 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 614
2021-12-06 14:58:40,452 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 558
2021-12-06 14:58:40,452 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 609
2021-12-06 14:58:40,453 [dispatcher-event-loop-5] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_25_piece0 on qb:60678 in memory (size: 66.0 KB, free: 1990.8 MB)
2021-12-06 14:58:40,453 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 580
2021-12-06 14:58:40,453 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 608
2021-12-06 14:58:40,453 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 576
2021-12-06 14:58:40,453 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 585
2021-12-06 14:58:40,453 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 590
2021-12-06 14:58:40,453 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 596
2021-12-06 14:58:40,453 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 568
2021-12-06 14:58:40,453 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 619
2021-12-06 14:58:40,453 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 595
2021-12-06 14:58:40,453 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 569
2021-12-06 14:58:40,453 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 587
2021-12-06 14:58:40,453 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 600
2021-12-06 14:58:40,453 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 591
2021-12-06 14:58:40,453 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 570
2021-12-06 14:58:40,453 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 572
2021-12-06 14:58:40,453 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 647
2021-12-06 14:58:40,453 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 606
2021-12-06 14:58:40,453 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 551
2021-12-06 14:58:40,453 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 560
2021-12-06 14:58:40,453 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 599
2021-12-06 14:58:40,453 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 583
2021-12-06 14:58:40,453 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 573
2021-12-06 14:58:40,453 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 612
2021-12-06 14:58:40,453 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 581
2021-12-06 14:58:40,453 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 626
2021-12-06 14:58:40,453 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 643
2021-12-06 14:58:40,453 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 646
2021-12-06 14:58:40,453 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 622
2021-12-06 14:58:40,454 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 625
2021-12-06 14:58:40,454 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 638
2021-12-06 14:58:40,454 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 644
2021-12-06 14:58:40,454 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 592
2021-12-06 14:58:40,454 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 552
2021-12-06 14:58:40,454 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 571
2021-12-06 14:58:40,454 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 623
2021-12-06 14:58:40,454 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 565
2021-12-06 14:58:40,454 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 636
2021-12-06 14:58:40,454 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 642
2021-12-06 14:58:40,454 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 593
2021-12-06 14:58:40,454 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 624
2021-12-06 14:58:40,454 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 610
2021-12-06 14:58:40,454 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 584
2021-12-06 14:58:40,454 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 603
2021-12-06 14:58:40,454 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 562
2021-12-06 14:58:40,454 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 553
2021-12-06 14:58:40,454 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 550
2021-12-06 14:58:40,454 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 615
2021-12-06 14:58:40,455 [dispatcher-event-loop-11] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_26_piece0 on qb:60678 in memory (size: 2.2 KB, free: 1990.8 MB)
2021-12-06 14:58:40,455 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 555
2021-12-06 14:58:40,455 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 577
2021-12-06 14:58:40,455 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 563
2021-12-06 14:58:40,455 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 616
2021-12-06 14:58:40,455 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 618
2021-12-06 14:58:40,455 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 589
2021-12-06 14:58:40,455 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 635
2021-12-06 14:58:40,455 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 578
2021-12-06 14:58:40,455 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 559
2021-12-06 14:58:40,455 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 634
2021-12-06 14:58:40,455 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 645
2021-12-06 14:58:40,455 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 621
2021-12-06 14:58:40,455 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 597
2021-12-06 14:58:40,455 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 628
2021-12-06 14:58:40,455 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 582
2021-12-06 14:58:40,455 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 579
2021-12-06 14:58:40,455 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 631
2021-12-06 14:58:40,455 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 611
2021-12-06 14:58:40,455 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 567
2021-12-06 14:58:40,455 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 648
2021-12-06 14:58:40,455 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 627
2021-12-06 14:58:40,455 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 617
2021-12-06 14:58:40,455 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 605
2021-12-06 14:58:40,455 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 574
2021-12-06 14:58:40,455 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 633
2021-12-06 14:58:40,455 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 630
2021-12-06 14:58:40,455 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 586
2021-12-06 14:58:40,455 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 602
2021-12-06 14:58:40,455 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 561
2021-12-06 14:58:40,455 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 601
2021-12-06 14:58:40,455 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 613
2021-12-06 14:58:40,455 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 629
2021-12-06 14:58:40,455 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 564
2021-12-06 14:58:40,455 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 557
2021-12-06 14:58:40,455 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 575
2021-12-06 14:58:40,455 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 607
2021-12-06 14:58:40,455 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 598
2021-12-06 14:58:40,455 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 632
2021-12-06 14:58:40,455 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 637
2021-12-06 14:58:40,455 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 604
2021-12-06 14:58:40,455 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 566
2021-12-06 14:58:40,455 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 594
2021-12-06 14:58:40,455 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 640
2021-12-06 14:58:40,455 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 639
2021-12-06 14:58:40,455 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 641
2021-12-06 14:58:40,455 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 588
2021-12-06 14:58:40,474 [Executor task launch worker for task 63] INFO [org.apache.spark.executor.Executor] - Finished task 3.0 in stage 41.0 (TID 63). 1249 bytes result sent to driver
2021-12-06 14:58:40,474 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 3.0 in stage 41.0 (TID 63) in 66 ms on localhost (executor driver) (1/4)
2021-12-06 14:58:40,477 [Executor task launch worker for task 61] INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 41.0 (TID 61). 1206 bytes result sent to driver
2021-12-06 14:58:40,477 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 41.0 (TID 61) in 69 ms on localhost (executor driver) (2/4)
2021-12-06 14:58:40,478 [Executor task launch worker for task 60] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 41.0 (TID 60). 1206 bytes result sent to driver
2021-12-06 14:58:40,478 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 41.0 (TID 60) in 71 ms on localhost (executor driver) (3/4)
2021-12-06 14:58:40,479 [Executor task launch worker for task 62] INFO [org.apache.spark.executor.Executor] - Finished task 2.0 in stage 41.0 (TID 62). 1249 bytes result sent to driver
2021-12-06 14:58:40,479 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 2.0 in stage 41.0 (TID 62) in 71 ms on localhost (executor driver) (4/4)
2021-12-06 14:58:40,479 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 41.0, whose tasks have all completed, from pool 
2021-12-06 14:58:40,480 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ShuffleMapStage 41 (intersection at PaidPromotionAdjustParameter.scala:162) finished in 0.076 s
2021-12-06 14:58:40,480 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - looking for newly runnable stages
2021-12-06 14:58:40,480 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - running: Set()
2021-12-06 14:58:40,480 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - waiting: Set(ResultStage 42)
2021-12-06 14:58:40,480 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - failed: Set()
2021-12-06 14:58:40,480 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 42 (MapPartitionsRDD[49] at intersection at PaidPromotionAdjustParameter.scala:162), which has no missing parents
2021-12-06 14:58:40,481 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_29 stored as values in memory (estimated size 3.6 KB, free 1990.5 MB)
2021-12-06 14:58:40,482 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_29_piece0 stored as bytes in memory (estimated size 2.1 KB, free 1990.5 MB)
2021-12-06 14:58:40,483 [dispatcher-event-loop-3] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_29_piece0 in memory on qb:60678 (size: 2.1 KB, free: 1990.8 MB)
2021-12-06 14:58:40,483 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 29 from broadcast at DAGScheduler.scala:1039
2021-12-06 14:58:40,483 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 4 missing tasks from ResultStage 42 (MapPartitionsRDD[49] at intersection at PaidPromotionAdjustParameter.scala:162) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
2021-12-06 14:58:40,483 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 42.0 with 4 tasks
2021-12-06 14:58:40,484 [dispatcher-event-loop-7] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 42.0 (TID 64, localhost, executor driver, partition 0, PROCESS_LOCAL, 7712 bytes)
2021-12-06 14:58:40,484 [dispatcher-event-loop-7] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 42.0 (TID 65, localhost, executor driver, partition 1, PROCESS_LOCAL, 7712 bytes)
2021-12-06 14:58:40,484 [dispatcher-event-loop-7] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 2.0 in stage 42.0 (TID 66, localhost, executor driver, partition 2, PROCESS_LOCAL, 7712 bytes)
2021-12-06 14:58:40,484 [dispatcher-event-loop-7] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 3.0 in stage 42.0 (TID 67, localhost, executor driver, partition 3, PROCESS_LOCAL, 7712 bytes)
2021-12-06 14:58:40,484 [Executor task launch worker for task 67] INFO [org.apache.spark.executor.Executor] - Running task 3.0 in stage 42.0 (TID 67)
2021-12-06 14:58:40,484 [Executor task launch worker for task 64] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 42.0 (TID 64)
2021-12-06 14:58:40,484 [Executor task launch worker for task 65] INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 42.0 (TID 65)
2021-12-06 14:58:40,484 [Executor task launch worker for task 66] INFO [org.apache.spark.executor.Executor] - Running task 2.0 in stage 42.0 (TID 66)
2021-12-06 14:58:40,486 [Executor task launch worker for task 67] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 4 blocks
2021-12-06 14:58:40,486 [Executor task launch worker for task 64] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 4 blocks
2021-12-06 14:58:40,486 [Executor task launch worker for task 64] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 1 ms
2021-12-06 14:58:40,486 [Executor task launch worker for task 65] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 4 blocks
2021-12-06 14:58:40,486 [Executor task launch worker for task 67] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 1 ms
2021-12-06 14:58:40,486 [Executor task launch worker for task 65] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-06 14:58:40,486 [Executor task launch worker for task 66] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 4 blocks
2021-12-06 14:58:40,486 [Executor task launch worker for task 66] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-06 14:58:40,488 [Executor task launch worker for task 66] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2021-12-06 14:58:40,488 [Executor task launch worker for task 66] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-06 14:58:40,488 [Executor task launch worker for task 67] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2021-12-06 14:58:40,488 [Executor task launch worker for task 65] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2021-12-06 14:58:40,488 [Executor task launch worker for task 67] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-06 14:58:40,488 [Executor task launch worker for task 65] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-06 14:58:40,488 [Executor task launch worker for task 64] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2021-12-06 14:58:40,488 [Executor task launch worker for task 64] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-06 14:58:40,538 [Executor task launch worker for task 64] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 42.0 (TID 64). 1011 bytes result sent to driver
2021-12-06 14:58:40,538 [Executor task launch worker for task 66] INFO [org.apache.spark.executor.Executor] - Finished task 2.0 in stage 42.0 (TID 66). 1011 bytes result sent to driver
2021-12-06 14:58:40,538 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 42.0 (TID 64) in 54 ms on localhost (executor driver) (1/4)
2021-12-06 14:58:40,538 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 2.0 in stage 42.0 (TID 66) in 54 ms on localhost (executor driver) (2/4)
2021-12-06 14:58:40,538 [Executor task launch worker for task 67] INFO [org.apache.spark.executor.Executor] - Finished task 3.0 in stage 42.0 (TID 67). 1011 bytes result sent to driver
2021-12-06 14:58:40,538 [Executor task launch worker for task 65] INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 42.0 (TID 65). 1011 bytes result sent to driver
2021-12-06 14:58:40,538 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 3.0 in stage 42.0 (TID 67) in 54 ms on localhost (executor driver) (3/4)
2021-12-06 14:58:40,538 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 42.0 (TID 65) in 54 ms on localhost (executor driver) (4/4)
2021-12-06 14:58:40,538 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 42.0, whose tasks have all completed, from pool 
2021-12-06 14:58:40,539 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 42 (count at PaidPromotionAdjustParameter.scala:171) finished in 0.059 s
2021-12-06 14:58:40,539 [main] INFO [org.apache.spark.scheduler.DAGScheduler] - Job 16 finished: count at PaidPromotionAdjustParameter.scala:171, took 0.138489 s
2021-12-06 14:58:40,539 [main] INFO [PaidPromotion$] -    = 5174
2021-12-06 14:58:40,541 [main] INFO [org.apache.spark.SparkContext] - Starting job: count at PaidPromotionAdjustParameter.scala:172
2021-12-06 14:58:40,542 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 51 (distinct at PaidPromotionAdjustParameter.scala:164)
2021-12-06 14:58:40,542 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 17 (count at PaidPromotionAdjustParameter.scala:172) with 4 output partitions
2021-12-06 14:58:40,542 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 44 (count at PaidPromotionAdjustParameter.scala:172)
2021-12-06 14:58:40,542 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 43)
2021-12-06 14:58:40,542 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List(ShuffleMapStage 43)
2021-12-06 14:58:40,542 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ShuffleMapStage 43 (MapPartitionsRDD[51] at distinct at PaidPromotionAdjustParameter.scala:164), which has no missing parents
2021-12-06 14:58:40,543 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_30 stored as values in memory (estimated size 186.3 KB, free 1990.3 MB)
2021-12-06 14:58:40,545 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_30_piece0 stored as bytes in memory (estimated size 66.4 KB, free 1990.2 MB)
2021-12-06 14:58:40,546 [dispatcher-event-loop-1] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_30_piece0 in memory on qb:60678 (size: 66.4 KB, free: 1990.7 MB)
2021-12-06 14:58:40,546 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 30 from broadcast at DAGScheduler.scala:1039
2021-12-06 14:58:40,546 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 4 missing tasks from ShuffleMapStage 43 (MapPartitionsRDD[51] at distinct at PaidPromotionAdjustParameter.scala:164) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
2021-12-06 14:58:40,546 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 43.0 with 4 tasks
2021-12-06 14:58:40,547 [dispatcher-event-loop-6] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 43.0 (TID 68, localhost, executor driver, partition 0, ANY, 7994 bytes)
2021-12-06 14:58:40,547 [dispatcher-event-loop-6] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 43.0 (TID 69, localhost, executor driver, partition 1, ANY, 7994 bytes)
2021-12-06 14:58:40,547 [dispatcher-event-loop-6] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 2.0 in stage 43.0 (TID 70, localhost, executor driver, partition 2, ANY, 7994 bytes)
2021-12-06 14:58:40,547 [dispatcher-event-loop-6] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 3.0 in stage 43.0 (TID 71, localhost, executor driver, partition 3, ANY, 7994 bytes)
2021-12-06 14:58:40,547 [Executor task launch worker for task 68] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 43.0 (TID 68)
2021-12-06 14:58:40,547 [Executor task launch worker for task 71] INFO [org.apache.spark.executor.Executor] - Running task 3.0 in stage 43.0 (TID 71)
2021-12-06 14:58:40,547 [Executor task launch worker for task 70] INFO [org.apache.spark.executor.Executor] - Running task 2.0 in stage 43.0 (TID 70)
2021-12-06 14:58:40,547 [Executor task launch worker for task 69] INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 43.0 (TID 69)
2021-12-06 14:58:40,549 [Executor task launch worker for task 69] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/order_data.bcp:3442194+3442195
2021-12-06 14:58:40,550 [Executor task launch worker for task 71] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/order_data.bcp:3442194+3442195
2021-12-06 14:58:40,550 [Executor task launch worker for task 68] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/order_data.bcp:0+3442194
2021-12-06 14:58:40,551 [Executor task launch worker for task 70] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/order_data.bcp:0+3442194
2021-12-06 14:58:41,546 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 684
2021-12-06 14:58:41,546 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 675
2021-12-06 14:58:41,546 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 674
2021-12-06 14:58:41,546 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 655
2021-12-06 14:58:41,546 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 658
2021-12-06 14:58:41,546 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 695
2021-12-06 14:58:41,546 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 652
2021-12-06 14:58:41,546 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 681
2021-12-06 14:58:41,546 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 693
2021-12-06 14:58:41,546 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 676
2021-12-06 14:58:41,546 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 654
2021-12-06 14:58:41,546 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 665
2021-12-06 14:58:41,546 [Executor task launch worker for task 69] INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 43.0 (TID 69). 1077 bytes result sent to driver
2021-12-06 14:58:41,546 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 715
2021-12-06 14:58:41,546 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 657
2021-12-06 14:58:41,546 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 669
2021-12-06 14:58:41,546 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 694
2021-12-06 14:58:41,546 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 721
2021-12-06 14:58:41,546 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 719
2021-12-06 14:58:41,546 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 670
2021-12-06 14:58:41,546 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 691
2021-12-06 14:58:41,546 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 706
2021-12-06 14:58:41,546 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 677
2021-12-06 14:58:41,546 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 711
2021-12-06 14:58:41,546 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 671
2021-12-06 14:58:41,546 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 720
2021-12-06 14:58:41,546 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 708
2021-12-06 14:58:41,546 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 704
2021-12-06 14:58:41,546 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 688
2021-12-06 14:58:41,546 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 702
2021-12-06 14:58:41,546 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 700
2021-12-06 14:58:41,546 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 713
2021-12-06 14:58:41,546 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 664
2021-12-06 14:58:41,546 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 682
2021-12-06 14:58:41,546 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 660
2021-12-06 14:58:41,546 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 678
2021-12-06 14:58:41,546 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 705
2021-12-06 14:58:41,546 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 651
2021-12-06 14:58:41,546 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 662
2021-12-06 14:58:41,546 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 703
2021-12-06 14:58:41,546 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 673
2021-12-06 14:58:41,546 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 43.0 (TID 69) in 999 ms on localhost (executor driver) (1/4)
2021-12-06 14:58:41,547 [dispatcher-event-loop-0] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_29_piece0 on qb:60678 in memory (size: 2.1 KB, free: 1990.7 MB)
2021-12-06 14:58:41,547 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 701
2021-12-06 14:58:41,547 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 659
2021-12-06 14:58:41,547 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 710
2021-12-06 14:58:41,547 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 714
2021-12-06 14:58:41,547 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 668
2021-12-06 14:58:41,547 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 685
2021-12-06 14:58:41,548 [dispatcher-event-loop-1] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_28_piece0 on qb:60678 in memory (size: 2.3 KB, free: 1990.7 MB)
2021-12-06 14:58:41,548 [dispatcher-event-loop-7] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_27_piece0 on qb:60678 in memory (size: 2.3 KB, free: 1990.7 MB)
2021-12-06 14:58:41,549 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 661
2021-12-06 14:58:41,549 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 683
2021-12-06 14:58:41,549 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 679
2021-12-06 14:58:41,549 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 712
2021-12-06 14:58:41,549 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 722
2021-12-06 14:58:41,549 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 686
2021-12-06 14:58:41,549 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 723
2021-12-06 14:58:41,549 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 663
2021-12-06 14:58:41,549 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 717
2021-12-06 14:58:41,549 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 687
2021-12-06 14:58:41,549 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 697
2021-12-06 14:58:41,549 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 698
2021-12-06 14:58:41,549 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 707
2021-12-06 14:58:41,549 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 672
2021-12-06 14:58:41,549 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 653
2021-12-06 14:58:41,549 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 709
2021-12-06 14:58:41,549 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 724
2021-12-06 14:58:41,549 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 689
2021-12-06 14:58:41,549 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 696
2021-12-06 14:58:41,549 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 650
2021-12-06 14:58:41,549 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 666
2021-12-06 14:58:41,549 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 656
2021-12-06 14:58:41,549 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 699
2021-12-06 14:58:41,549 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 718
2021-12-06 14:58:41,549 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 667
2021-12-06 14:58:41,549 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 680
2021-12-06 14:58:41,549 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 716
2021-12-06 14:58:41,549 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 692
2021-12-06 14:58:41,549 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 690
2021-12-06 14:58:42,740 [Executor task launch worker for task 71] INFO [org.apache.spark.executor.Executor] - Finished task 3.0 in stage 43.0 (TID 71). 1034 bytes result sent to driver
2021-12-06 14:58:42,741 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 3.0 in stage 43.0 (TID 71) in 2194 ms on localhost (executor driver) (2/4)
2021-12-06 14:58:42,755 [Executor task launch worker for task 68] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 43.0 (TID 68). 1034 bytes result sent to driver
2021-12-06 14:58:42,755 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 43.0 (TID 68) in 2209 ms on localhost (executor driver) (3/4)
2021-12-06 14:58:42,756 [Executor task launch worker for task 70] INFO [org.apache.spark.executor.Executor] - Finished task 2.0 in stage 43.0 (TID 70). 1034 bytes result sent to driver
2021-12-06 14:58:42,756 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 2.0 in stage 43.0 (TID 70) in 2209 ms on localhost (executor driver) (4/4)
2021-12-06 14:58:42,756 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 43.0, whose tasks have all completed, from pool 
2021-12-06 14:58:42,756 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ShuffleMapStage 43 (distinct at PaidPromotionAdjustParameter.scala:164) finished in 2.214 s
2021-12-06 14:58:42,756 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - looking for newly runnable stages
2021-12-06 14:58:42,756 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - running: Set()
2021-12-06 14:58:42,756 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - waiting: Set(ResultStage 44)
2021-12-06 14:58:42,756 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - failed: Set()
2021-12-06 14:58:42,756 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 44 (MapPartitionsRDD[53] at distinct at PaidPromotionAdjustParameter.scala:164), which has no missing parents
2021-12-06 14:58:42,757 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_31 stored as values in memory (estimated size 3.7 KB, free 1990.2 MB)
2021-12-06 14:58:42,759 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_31_piece0 stored as bytes in memory (estimated size 2.2 KB, free 1990.2 MB)
2021-12-06 14:58:42,759 [dispatcher-event-loop-11] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_31_piece0 in memory on qb:60678 (size: 2.2 KB, free: 1990.7 MB)
2021-12-06 14:58:42,759 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 31 from broadcast at DAGScheduler.scala:1039
2021-12-06 14:58:42,760 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 4 missing tasks from ResultStage 44 (MapPartitionsRDD[53] at distinct at PaidPromotionAdjustParameter.scala:164) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
2021-12-06 14:58:42,760 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 44.0 with 4 tasks
2021-12-06 14:58:42,760 [dispatcher-event-loop-10] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 44.0 (TID 72, localhost, executor driver, partition 0, ANY, 7649 bytes)
2021-12-06 14:58:42,760 [dispatcher-event-loop-10] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 44.0 (TID 73, localhost, executor driver, partition 1, ANY, 7649 bytes)
2021-12-06 14:58:42,760 [dispatcher-event-loop-10] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 2.0 in stage 44.0 (TID 74, localhost, executor driver, partition 2, ANY, 7649 bytes)
2021-12-06 14:58:42,760 [dispatcher-event-loop-10] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 3.0 in stage 44.0 (TID 75, localhost, executor driver, partition 3, ANY, 7649 bytes)
2021-12-06 14:58:42,760 [Executor task launch worker for task 72] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 44.0 (TID 72)
2021-12-06 14:58:42,760 [Executor task launch worker for task 74] INFO [org.apache.spark.executor.Executor] - Running task 2.0 in stage 44.0 (TID 74)
2021-12-06 14:58:42,760 [Executor task launch worker for task 73] INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 44.0 (TID 73)
2021-12-06 14:58:42,760 [Executor task launch worker for task 75] INFO [org.apache.spark.executor.Executor] - Running task 3.0 in stage 44.0 (TID 75)
2021-12-06 14:58:42,762 [Executor task launch worker for task 72] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 4 non-empty blocks out of 4 blocks
2021-12-06 14:58:42,762 [Executor task launch worker for task 73] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 4 non-empty blocks out of 4 blocks
2021-12-06 14:58:42,762 [Executor task launch worker for task 72] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-06 14:58:42,762 [Executor task launch worker for task 73] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-06 14:58:42,762 [Executor task launch worker for task 74] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 4 non-empty blocks out of 4 blocks
2021-12-06 14:58:42,762 [Executor task launch worker for task 75] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 4 non-empty blocks out of 4 blocks
2021-12-06 14:58:42,762 [Executor task launch worker for task 74] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-06 14:58:42,762 [Executor task launch worker for task 75] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-06 14:58:42,782 [Executor task launch worker for task 74] INFO [org.apache.spark.executor.Executor] - Finished task 2.0 in stage 44.0 (TID 74). 1010 bytes result sent to driver
2021-12-06 14:58:42,782 [Executor task launch worker for task 73] INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 44.0 (TID 73). 1053 bytes result sent to driver
2021-12-06 14:58:42,782 [Executor task launch worker for task 72] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 44.0 (TID 72). 1053 bytes result sent to driver
2021-12-06 14:58:42,782 [Executor task launch worker for task 75] INFO [org.apache.spark.executor.Executor] - Finished task 3.0 in stage 44.0 (TID 75). 1053 bytes result sent to driver
2021-12-06 14:58:42,783 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 2.0 in stage 44.0 (TID 74) in 23 ms on localhost (executor driver) (1/4)
2021-12-06 14:58:42,783 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 44.0 (TID 73) in 23 ms on localhost (executor driver) (2/4)
2021-12-06 14:58:42,783 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 44.0 (TID 72) in 23 ms on localhost (executor driver) (3/4)
2021-12-06 14:58:42,783 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 3.0 in stage 44.0 (TID 75) in 23 ms on localhost (executor driver) (4/4)
2021-12-06 14:58:42,783 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 44.0, whose tasks have all completed, from pool 
2021-12-06 14:58:42,783 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 44 (count at PaidPromotionAdjustParameter.scala:172) finished in 0.026 s
2021-12-06 14:58:42,783 [main] INFO [org.apache.spark.scheduler.DAGScheduler] - Job 17 finished: count at PaidPromotionAdjustParameter.scala:172, took 2.242106 s
2021-12-06 14:58:42,784 [main] INFO [PaidPromotion$] -  = 132
2021-12-06 14:58:42,786 [main] INFO [org.apache.spark.SparkContext] - Starting job: count at PaidPromotionAdjustParameter.scala:173
2021-12-06 14:58:42,786 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 55 (distinct at PaidPromotionAdjustParameter.scala:165)
2021-12-06 14:58:42,786 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 18 (count at PaidPromotionAdjustParameter.scala:173) with 2 output partitions
2021-12-06 14:58:42,786 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 46 (count at PaidPromotionAdjustParameter.scala:173)
2021-12-06 14:58:42,786 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 45)
2021-12-06 14:58:42,786 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List(ShuffleMapStage 45)
2021-12-06 14:58:42,786 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ShuffleMapStage 45 (MapPartitionsRDD[55] at distinct at PaidPromotionAdjustParameter.scala:165), which has no missing parents
2021-12-06 14:58:42,788 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_32 stored as values in memory (estimated size 185.8 KB, free 1990.0 MB)
2021-12-06 14:58:42,790 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_32_piece0 stored as bytes in memory (estimated size 66.0 KB, free 1990.0 MB)
2021-12-06 14:58:42,790 [dispatcher-event-loop-2] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_32_piece0 in memory on qb:60678 (size: 66.0 KB, free: 1990.6 MB)
2021-12-06 14:58:42,790 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 32 from broadcast at DAGScheduler.scala:1039
2021-12-06 14:58:42,791 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from ShuffleMapStage 45 (MapPartitionsRDD[55] at distinct at PaidPromotionAdjustParameter.scala:165) (first 15 tasks are for partitions Vector(0, 1))
2021-12-06 14:58:42,791 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 45.0 with 2 tasks
2021-12-06 14:58:42,791 [dispatcher-event-loop-5] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 45.0 (TID 76, localhost, executor driver, partition 0, ANY, 7885 bytes)
2021-12-06 14:58:42,791 [dispatcher-event-loop-5] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 45.0 (TID 77, localhost, executor driver, partition 1, ANY, 7885 bytes)
2021-12-06 14:58:42,791 [Executor task launch worker for task 76] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 45.0 (TID 76)
2021-12-06 14:58:42,791 [Executor task launch worker for task 77] INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 45.0 (TID 77)
2021-12-06 14:58:42,794 [Executor task launch worker for task 77] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/order_data.bcp:3442194+3442195
2021-12-06 14:58:42,794 [Executor task launch worker for task 76] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/order_data.bcp:0+3442194
2021-12-06 14:58:43,185 [SparkUI-76] INFO [org.spark_project.jetty.servlet.DefaultServlet] - content=ResourceHttpContent@7a95cc8f{r=jar:file:/C:/Users/ACER/.m2/repository/org/apache/spark/spark-core_2.11/2.3.0/spark-core_2.11-2.3.0.jar!/org/apache/spark/ui/static/bootstrap.min.css,gz=false}
2021-12-06 14:58:43,185 [SparkUI-76] WARN [org.spark_project.jetty.servlet.ServletHandler] - Error for /static/bootstrap.min.css
java.lang.NoSuchMethodError: javax.servlet.http.HttpServletRequest.isAsyncSupported()Z
	at org.spark_project.jetty.servlet.DefaultServlet.sendData(DefaultServlet.java:909)
	at org.spark_project.jetty.servlet.DefaultServlet.doGet(DefaultServlet.java:526)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:707)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:820)
	at org.spark_project.jetty.servlet.ServletHolder.handle(ServletHolder.java:848)
	at org.spark_project.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:584)
	at org.spark_project.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
	at org.spark_project.jetty.servlet.ServletHandler.doScope(ServletHandler.java:512)
	at org.spark_project.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
	at org.spark_project.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.spark_project.jetty.server.handler.gzip.GzipHandler.handle(GzipHandler.java:493)
	at org.spark_project.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:213)
	at org.spark_project.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
	at org.spark_project.jetty.server.Server.handle(Server.java:534)
	at org.spark_project.jetty.server.HttpChannel.handle(HttpChannel.java:320)
	at org.spark_project.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
	at org.spark_project.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
	at org.spark_project.jetty.io.FillInterest.fillable(FillInterest.java:108)
	at org.spark_project.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
	at org.spark_project.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
	at org.spark_project.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
	at java.lang.Thread.run(Thread.java:745)
2021-12-06 14:58:43,185 [SparkUI-76] WARN [org.spark_project.jetty.server.HttpChannel] - //qb:4040/static/bootstrap.min.css
java.lang.NoSuchMethodError: javax.servlet.http.HttpServletRequest.isAsyncStarted()Z
	at org.spark_project.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:688)
	at org.spark_project.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
	at org.spark_project.jetty.servlet.ServletHandler.doScope(ServletHandler.java:512)
	at org.spark_project.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
	at org.spark_project.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.spark_project.jetty.server.handler.gzip.GzipHandler.handle(GzipHandler.java:493)
	at org.spark_project.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:213)
	at org.spark_project.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
	at org.spark_project.jetty.server.Server.handle(Server.java:534)
	at org.spark_project.jetty.server.HttpChannel.handle(HttpChannel.java:320)
	at org.spark_project.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
	at org.spark_project.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
	at org.spark_project.jetty.io.FillInterest.fillable(FillInterest.java:108)
	at org.spark_project.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
	at org.spark_project.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
	at org.spark_project.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
	at java.lang.Thread.run(Thread.java:745)
2021-12-06 14:58:43,186 [SparkUI-37] INFO [org.spark_project.jetty.servlet.DefaultServlet] - content=ResourceHttpContent@55c6fe42{r=jar:file:/C:/Users/ACER/.m2/repository/org/apache/spark/spark-core_2.11/2.3.0/spark-core_2.11-2.3.0.jar!/org/apache/spark/ui/static/vis.min.css,gz=false}
2021-12-06 14:58:43,186 [SparkUI-37] WARN [org.spark_project.jetty.servlet.ServletHandler] - Error for /static/vis.min.css
java.lang.NoSuchMethodError: javax.servlet.http.HttpServletRequest.isAsyncSupported()Z
	at org.spark_project.jetty.servlet.DefaultServlet.sendData(DefaultServlet.java:909)
	at org.spark_project.jetty.servlet.DefaultServlet.doGet(DefaultServlet.java:526)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:707)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:820)
	at org.spark_project.jetty.servlet.ServletHolder.handle(ServletHolder.java:848)
	at org.spark_project.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:584)
	at org.spark_project.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
	at org.spark_project.jetty.servlet.ServletHandler.doScope(ServletHandler.java:512)
	at org.spark_project.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
	at org.spark_project.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.spark_project.jetty.server.handler.gzip.GzipHandler.handle(GzipHandler.java:493)
	at org.spark_project.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:213)
	at org.spark_project.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
	at org.spark_project.jetty.server.Server.handle(Server.java:534)
	at org.spark_project.jetty.server.HttpChannel.handle(HttpChannel.java:320)
	at org.spark_project.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
	at org.spark_project.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
	at org.spark_project.jetty.io.FillInterest.fillable(FillInterest.java:108)
	at org.spark_project.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
	at org.spark_project.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
	at org.spark_project.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
	at java.lang.Thread.run(Thread.java:745)
2021-12-06 14:58:43,186 [SparkUI-37] WARN [org.spark_project.jetty.server.HttpChannel] - //qb:4040/static/vis.min.css
java.lang.NoSuchMethodError: javax.servlet.http.HttpServletRequest.isAsyncStarted()Z
	at org.spark_project.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:688)
	at org.spark_project.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
	at org.spark_project.jetty.servlet.ServletHandler.doScope(ServletHandler.java:512)
	at org.spark_project.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
	at org.spark_project.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.spark_project.jetty.server.handler.gzip.GzipHandler.handle(GzipHandler.java:493)
	at org.spark_project.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:213)
	at org.spark_project.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
	at org.spark_project.jetty.server.Server.handle(Server.java:534)
	at org.spark_project.jetty.server.HttpChannel.handle(HttpChannel.java:320)
	at org.spark_project.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
	at org.spark_project.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
	at org.spark_project.jetty.io.FillInterest.fillable(FillInterest.java:108)
	at org.spark_project.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
	at org.spark_project.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
	at org.spark_project.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
	at java.lang.Thread.run(Thread.java:745)
2021-12-06 14:58:43,187 [SparkUI-38] INFO [org.spark_project.jetty.servlet.DefaultServlet] - content=ResourceHttpContent@27d456a8{r=jar:file:/C:/Users/ACER/.m2/repository/org/apache/spark/spark-core_2.11/2.3.0/spark-core_2.11-2.3.0.jar!/org/apache/spark/ui/static/webui.css,gz=false}
2021-12-06 14:58:43,188 [SparkUI-38] WARN [org.spark_project.jetty.servlet.ServletHandler] - Error for /static/webui.css
java.lang.NoSuchMethodError: javax.servlet.http.HttpServletRequest.isAsyncSupported()Z
	at org.spark_project.jetty.servlet.DefaultServlet.sendData(DefaultServlet.java:909)
	at org.spark_project.jetty.servlet.DefaultServlet.doGet(DefaultServlet.java:526)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:707)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:820)
	at org.spark_project.jetty.servlet.ServletHolder.handle(ServletHolder.java:848)
	at org.spark_project.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:584)
	at org.spark_project.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
	at org.spark_project.jetty.servlet.ServletHandler.doScope(ServletHandler.java:512)
	at org.spark_project.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
	at org.spark_project.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.spark_project.jetty.server.handler.gzip.GzipHandler.handle(GzipHandler.java:493)
	at org.spark_project.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:213)
	at org.spark_project.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
	at org.spark_project.jetty.server.Server.handle(Server.java:534)
	at org.spark_project.jetty.server.HttpChannel.handle(HttpChannel.java:320)
	at org.spark_project.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
	at org.spark_project.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
	at org.spark_project.jetty.io.FillInterest.fillable(FillInterest.java:108)
	at org.spark_project.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
	at org.spark_project.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
	at org.spark_project.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
	at java.lang.Thread.run(Thread.java:745)
2021-12-06 14:58:43,188 [SparkUI-38] WARN [org.spark_project.jetty.server.HttpChannel] - //qb:4040/static/webui.css
java.lang.NoSuchMethodError: javax.servlet.http.HttpServletRequest.isAsyncStarted()Z
	at org.spark_project.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:688)
	at org.spark_project.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
	at org.spark_project.jetty.servlet.ServletHandler.doScope(ServletHandler.java:512)
	at org.spark_project.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
	at org.spark_project.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.spark_project.jetty.server.handler.gzip.GzipHandler.handle(GzipHandler.java:493)
	at org.spark_project.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:213)
	at org.spark_project.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
	at org.spark_project.jetty.server.Server.handle(Server.java:534)
	at org.spark_project.jetty.server.HttpChannel.handle(HttpChannel.java:320)
	at org.spark_project.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
	at org.spark_project.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
	at org.spark_project.jetty.io.FillInterest.fillable(FillInterest.java:108)
	at org.spark_project.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
	at org.spark_project.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
	at org.spark_project.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
	at java.lang.Thread.run(Thread.java:745)
2021-12-06 14:58:43,188 [SparkUI-74] INFO [org.spark_project.jetty.servlet.DefaultServlet] - content=ResourceHttpContent@26a51c0{r=jar:file:/C:/Users/ACER/.m2/repository/org/apache/spark/spark-core_2.11/2.3.0/spark-core_2.11-2.3.0.jar!/org/apache/spark/ui/static/timeline-view.css,gz=false}
2021-12-06 14:58:43,188 [SparkUI-74] WARN [org.spark_project.jetty.servlet.ServletHandler] - Error for /static/timeline-view.css
java.lang.NoSuchMethodError: javax.servlet.http.HttpServletRequest.isAsyncSupported()Z
	at org.spark_project.jetty.servlet.DefaultServlet.sendData(DefaultServlet.java:909)
	at org.spark_project.jetty.servlet.DefaultServlet.doGet(DefaultServlet.java:526)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:707)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:820)
	at org.spark_project.jetty.servlet.ServletHolder.handle(ServletHolder.java:848)
	at org.spark_project.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:584)
	at org.spark_project.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
	at org.spark_project.jetty.servlet.ServletHandler.doScope(ServletHandler.java:512)
	at org.spark_project.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
	at org.spark_project.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.spark_project.jetty.server.handler.gzip.GzipHandler.handle(GzipHandler.java:493)
	at org.spark_project.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:213)
	at org.spark_project.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
	at org.spark_project.jetty.server.Server.handle(Server.java:534)
	at org.spark_project.jetty.server.HttpChannel.handle(HttpChannel.java:320)
	at org.spark_project.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
	at org.spark_project.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
	at org.spark_project.jetty.io.FillInterest.fillable(FillInterest.java:108)
	at org.spark_project.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
	at org.spark_project.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
	at org.spark_project.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
	at java.lang.Thread.run(Thread.java:745)
2021-12-06 14:58:43,189 [SparkUI-74] WARN [org.spark_project.jetty.server.HttpChannel] - //qb:4040/static/timeline-view.css
java.lang.NoSuchMethodError: javax.servlet.http.HttpServletRequest.isAsyncStarted()Z
	at org.spark_project.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:688)
	at org.spark_project.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
	at org.spark_project.jetty.servlet.ServletHandler.doScope(ServletHandler.java:512)
	at org.spark_project.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
	at org.spark_project.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.spark_project.jetty.server.handler.gzip.GzipHandler.handle(GzipHandler.java:493)
	at org.spark_project.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:213)
	at org.spark_project.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
	at org.spark_project.jetty.server.Server.handle(Server.java:534)
	at org.spark_project.jetty.server.HttpChannel.handle(HttpChannel.java:320)
	at org.spark_project.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
	at org.spark_project.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
	at org.spark_project.jetty.io.FillInterest.fillable(FillInterest.java:108)
	at org.spark_project.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
	at org.spark_project.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
	at org.spark_project.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
	at java.lang.Thread.run(Thread.java:745)
2021-12-06 14:58:43,189 [SparkUI-76] INFO [org.spark_project.jetty.servlet.DefaultServlet] - content=ResourceHttpContent@4f6cc961{r=jar:file:/C:/Users/ACER/.m2/repository/org/apache/spark/spark-core_2.11/2.3.0/spark-core_2.11-2.3.0.jar!/org/apache/spark/ui/static/bootstrap.min.css,gz=false}
2021-12-06 14:58:43,189 [SparkUI-76] WARN [org.spark_project.jetty.servlet.ServletHandler] - Error for /static/bootstrap.min.css
java.lang.NoSuchMethodError: javax.servlet.http.HttpServletRequest.isAsyncSupported()Z
	at org.spark_project.jetty.servlet.DefaultServlet.sendData(DefaultServlet.java:909)
	at org.spark_project.jetty.servlet.DefaultServlet.doGet(DefaultServlet.java:526)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:707)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:820)
	at org.spark_project.jetty.servlet.ServletHolder.handle(ServletHolder.java:848)
	at org.spark_project.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:584)
	at org.spark_project.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
	at org.spark_project.jetty.servlet.ServletHandler.doScope(ServletHandler.java:512)
	at org.spark_project.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
	at org.spark_project.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.spark_project.jetty.server.handler.gzip.GzipHandler.handle(GzipHandler.java:493)
	at org.spark_project.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:213)
	at org.spark_project.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
	at org.spark_project.jetty.server.Server.handle(Server.java:534)
	at org.spark_project.jetty.server.HttpChannel.handle(HttpChannel.java:320)
	at org.spark_project.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
	at org.spark_project.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
	at org.spark_project.jetty.io.FillInterest.fillable(FillInterest.java:108)
	at org.spark_project.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
	at org.spark_project.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
	at org.spark_project.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
	at java.lang.Thread.run(Thread.java:745)
2021-12-06 14:58:43,189 [SparkUI-76] WARN [org.spark_project.jetty.server.HttpChannel] - //qb:4040/static/bootstrap.min.css
java.lang.NoSuchMethodError: javax.servlet.http.HttpServletRequest.isAsyncStarted()Z
	at org.spark_project.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:688)
	at org.spark_project.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
	at org.spark_project.jetty.servlet.ServletHandler.doScope(ServletHandler.java:512)
	at org.spark_project.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
	at org.spark_project.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.spark_project.jetty.server.handler.gzip.GzipHandler.handle(GzipHandler.java:493)
	at org.spark_project.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:213)
	at org.spark_project.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
	at org.spark_project.jetty.server.Server.handle(Server.java:534)
	at org.spark_project.jetty.server.HttpChannel.handle(HttpChannel.java:320)
	at org.spark_project.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
	at org.spark_project.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
	at org.spark_project.jetty.io.FillInterest.fillable(FillInterest.java:108)
	at org.spark_project.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
	at org.spark_project.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
	at org.spark_project.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
	at java.lang.Thread.run(Thread.java:745)
2021-12-06 14:58:43,193 [SparkUI-73] INFO [org.spark_project.jetty.servlet.DefaultServlet] - content=ResourceHttpContent@688b7baf{r=jar:file:/C:/Users/ACER/.m2/repository/org/apache/spark/spark-core_2.11/2.3.0/spark-core_2.11-2.3.0.jar!/org/apache/spark/ui/static/vis.min.css,gz=false}
2021-12-06 14:58:43,193 [SparkUI-73] WARN [org.spark_project.jetty.servlet.ServletHandler] - Error for /static/vis.min.css
java.lang.NoSuchMethodError: javax.servlet.http.HttpServletRequest.isAsyncSupported()Z
	at org.spark_project.jetty.servlet.DefaultServlet.sendData(DefaultServlet.java:909)
	at org.spark_project.jetty.servlet.DefaultServlet.doGet(DefaultServlet.java:526)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:707)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:820)
	at org.spark_project.jetty.servlet.ServletHolder.handle(ServletHolder.java:848)
	at org.spark_project.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:584)
	at org.spark_project.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
	at org.spark_project.jetty.servlet.ServletHandler.doScope(ServletHandler.java:512)
	at org.spark_project.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
	at org.spark_project.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.spark_project.jetty.server.handler.gzip.GzipHandler.handle(GzipHandler.java:493)
	at org.spark_project.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:213)
	at org.spark_project.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
	at org.spark_project.jetty.server.Server.handle(Server.java:534)
	at org.spark_project.jetty.server.HttpChannel.handle(HttpChannel.java:320)
	at org.spark_project.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
	at org.spark_project.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
	at org.spark_project.jetty.io.FillInterest.fillable(FillInterest.java:108)
	at org.spark_project.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
	at org.spark_project.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
	at org.spark_project.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
	at java.lang.Thread.run(Thread.java:745)
2021-12-06 14:58:43,193 [SparkUI-73] WARN [org.spark_project.jetty.server.HttpChannel] - //qb:4040/static/vis.min.css
java.lang.NoSuchMethodError: javax.servlet.http.HttpServletRequest.isAsyncStarted()Z
	at org.spark_project.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:688)
	at org.spark_project.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
	at org.spark_project.jetty.servlet.ServletHandler.doScope(ServletHandler.java:512)
	at org.spark_project.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
	at org.spark_project.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.spark_project.jetty.server.handler.gzip.GzipHandler.handle(GzipHandler.java:493)
	at org.spark_project.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:213)
	at org.spark_project.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
	at org.spark_project.jetty.server.Server.handle(Server.java:534)
	at org.spark_project.jetty.server.HttpChannel.handle(HttpChannel.java:320)
	at org.spark_project.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
	at org.spark_project.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
	at org.spark_project.jetty.io.FillInterest.fillable(FillInterest.java:108)
	at org.spark_project.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
	at org.spark_project.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
	at org.spark_project.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
	at java.lang.Thread.run(Thread.java:745)
2021-12-06 14:58:43,196 [SparkUI-42] INFO [org.spark_project.jetty.servlet.DefaultServlet] - content=ResourceHttpContent@48f56b57{r=jar:file:/C:/Users/ACER/.m2/repository/org/apache/spark/spark-core_2.11/2.3.0/spark-core_2.11-2.3.0.jar!/org/apache/spark/ui/static/spark-dag-viz.css,gz=false}
2021-12-06 14:58:43,196 [SparkUI-42] WARN [org.spark_project.jetty.servlet.ServletHandler] - Error for /static/spark-dag-viz.css
java.lang.NoSuchMethodError: javax.servlet.http.HttpServletRequest.isAsyncSupported()Z
	at org.spark_project.jetty.servlet.DefaultServlet.sendData(DefaultServlet.java:909)
	at org.spark_project.jetty.servlet.DefaultServlet.doGet(DefaultServlet.java:526)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:707)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:820)
	at org.spark_project.jetty.servlet.ServletHolder.handle(ServletHolder.java:848)
	at org.spark_project.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:584)
	at org.spark_project.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
	at org.spark_project.jetty.servlet.ServletHandler.doScope(ServletHandler.java:512)
	at org.spark_project.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
	at org.spark_project.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.spark_project.jetty.server.handler.gzip.GzipHandler.handle(GzipHandler.java:493)
	at org.spark_project.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:213)
	at org.spark_project.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
	at org.spark_project.jetty.server.Server.handle(Server.java:534)
	at org.spark_project.jetty.server.HttpChannel.handle(HttpChannel.java:320)
	at org.spark_project.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
	at org.spark_project.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
	at org.spark_project.jetty.io.FillInterest.fillable(FillInterest.java:108)
	at org.spark_project.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
	at org.spark_project.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
	at org.spark_project.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
	at java.lang.Thread.run(Thread.java:745)
2021-12-06 14:58:43,196 [SparkUI-42] WARN [org.spark_project.jetty.server.HttpChannel] - //qb:4040/static/spark-dag-viz.css
java.lang.NoSuchMethodError: javax.servlet.http.HttpServletRequest.isAsyncStarted()Z
	at org.spark_project.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:688)
	at org.spark_project.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
	at org.spark_project.jetty.servlet.ServletHandler.doScope(ServletHandler.java:512)
	at org.spark_project.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
	at org.spark_project.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.spark_project.jetty.server.handler.gzip.GzipHandler.handle(GzipHandler.java:493)
	at org.spark_project.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:213)
	at org.spark_project.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
	at org.spark_project.jetty.server.Server.handle(Server.java:534)
	at org.spark_project.jetty.server.HttpChannel.handle(HttpChannel.java:320)
	at org.spark_project.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
	at org.spark_project.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
	at org.spark_project.jetty.io.FillInterest.fillable(FillInterest.java:108)
	at org.spark_project.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
	at org.spark_project.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
	at org.spark_project.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
	at java.lang.Thread.run(Thread.java:745)
2021-12-06 14:58:43,201 [SparkUI-74] INFO [org.spark_project.jetty.servlet.DefaultServlet] - content=ResourceHttpContent@7fc54710{r=jar:file:/C:/Users/ACER/.m2/repository/org/apache/spark/spark-core_2.11/2.3.0/spark-core_2.11-2.3.0.jar!/org/apache/spark/ui/static/vis.min.js,gz=false}
2021-12-06 14:58:43,201 [SparkUI-44] INFO [org.spark_project.jetty.servlet.DefaultServlet] - content=ResourceHttpContent@78dcf06e{r=jar:file:/C:/Users/ACER/.m2/repository/org/apache/spark/spark-core_2.11/2.3.0/spark-core_2.11-2.3.0.jar!/org/apache/spark/ui/static/sorttable.js,gz=false}
2021-12-06 14:58:43,201 [SparkUI-73] INFO [org.spark_project.jetty.servlet.DefaultServlet] - content=ResourceHttpContent@5c3106d4{r=jar:file:/C:/Users/ACER/.m2/repository/org/apache/spark/spark-core_2.11/2.3.0/spark-core_2.11-2.3.0.jar!/org/apache/spark/ui/static/jquery-1.11.1.min.js,gz=false}
2021-12-06 14:58:43,201 [SparkUI-74] WARN [org.spark_project.jetty.servlet.ServletHandler] - Error for /static/vis.min.js
java.lang.NoSuchMethodError: javax.servlet.http.HttpServletRequest.isAsyncSupported()Z
	at org.spark_project.jetty.servlet.DefaultServlet.sendData(DefaultServlet.java:909)
	at org.spark_project.jetty.servlet.DefaultServlet.doGet(DefaultServlet.java:526)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:707)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:820)
	at org.spark_project.jetty.servlet.ServletHolder.handle(ServletHolder.java:848)
	at org.spark_project.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:584)
	at org.spark_project.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
	at org.spark_project.jetty.servlet.ServletHandler.doScope(ServletHandler.java:512)
	at org.spark_project.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
	at org.spark_project.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.spark_project.jetty.server.handler.gzip.GzipHandler.handle(GzipHandler.java:493)
	at org.spark_project.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:213)
	at org.spark_project.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
	at org.spark_project.jetty.server.Server.handle(Server.java:534)
	at org.spark_project.jetty.server.HttpChannel.handle(HttpChannel.java:320)
	at org.spark_project.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
	at org.spark_project.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
	at org.spark_project.jetty.io.FillInterest.fillable(FillInterest.java:108)
	at org.spark_project.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
	at org.spark_project.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
	at org.spark_project.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
	at java.lang.Thread.run(Thread.java:745)
2021-12-06 14:58:43,201 [SparkUI-73] WARN [org.spark_project.jetty.servlet.ServletHandler] - Error for /static/jquery-1.11.1.min.js
java.lang.NoSuchMethodError: javax.servlet.http.HttpServletRequest.isAsyncSupported()Z
	at org.spark_project.jetty.servlet.DefaultServlet.sendData(DefaultServlet.java:909)
	at org.spark_project.jetty.servlet.DefaultServlet.doGet(DefaultServlet.java:526)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:707)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:820)
	at org.spark_project.jetty.servlet.ServletHolder.handle(ServletHolder.java:848)
	at org.spark_project.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:584)
	at org.spark_project.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
	at org.spark_project.jetty.servlet.ServletHandler.doScope(ServletHandler.java:512)
	at org.spark_project.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
	at org.spark_project.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.spark_project.jetty.server.handler.gzip.GzipHandler.handle(GzipHandler.java:493)
	at org.spark_project.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:213)
	at org.spark_project.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
	at org.spark_project.jetty.server.Server.handle(Server.java:534)
	at org.spark_project.jetty.server.HttpChannel.handle(HttpChannel.java:320)
	at org.spark_project.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
	at org.spark_project.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
	at org.spark_project.jetty.io.FillInterest.fillable(FillInterest.java:108)
	at org.spark_project.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
	at org.spark_project.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
	at org.spark_project.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
	at java.lang.Thread.run(Thread.java:745)
2021-12-06 14:58:43,201 [SparkUI-39] INFO [org.spark_project.jetty.servlet.DefaultServlet] - content=ResourceHttpContent@2f48d378{r=jar:file:/C:/Users/ACER/.m2/repository/org/apache/spark/spark-core_2.11/2.3.0/spark-core_2.11-2.3.0.jar!/org/apache/spark/ui/static/bootstrap-tooltip.js,gz=false}
2021-12-06 14:58:43,201 [SparkUI-44] WARN [org.spark_project.jetty.servlet.ServletHandler] - Error for /static/sorttable.js
java.lang.NoSuchMethodError: javax.servlet.http.HttpServletRequest.isAsyncSupported()Z
	at org.spark_project.jetty.servlet.DefaultServlet.sendData(DefaultServlet.java:909)
	at org.spark_project.jetty.servlet.DefaultServlet.doGet(DefaultServlet.java:526)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:707)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:820)
	at org.spark_project.jetty.servlet.ServletHolder.handle(ServletHolder.java:848)
	at org.spark_project.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:584)
	at org.spark_project.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
	at org.spark_project.jetty.servlet.ServletHandler.doScope(ServletHandler.java:512)
	at org.spark_project.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
	at org.spark_project.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.spark_project.jetty.server.handler.gzip.GzipHandler.handle(GzipHandler.java:493)
	at org.spark_project.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:213)
	at org.spark_project.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
	at org.spark_project.jetty.server.Server.handle(Server.java:534)
	at org.spark_project.jetty.server.HttpChannel.handle(HttpChannel.java:320)
	at org.spark_project.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
	at org.spark_project.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
	at org.spark_project.jetty.io.FillInterest.fillable(FillInterest.java:108)
	at org.spark_project.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
	at org.spark_project.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
	at org.spark_project.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
	at java.lang.Thread.run(Thread.java:745)
2021-12-06 14:58:43,202 [SparkUI-39] WARN [org.spark_project.jetty.servlet.ServletHandler] - Error for /static/bootstrap-tooltip.js
java.lang.NoSuchMethodError: javax.servlet.http.HttpServletRequest.isAsyncSupported()Z
	at org.spark_project.jetty.servlet.DefaultServlet.sendData(DefaultServlet.java:909)
	at org.spark_project.jetty.servlet.DefaultServlet.doGet(DefaultServlet.java:526)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:707)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:820)
	at org.spark_project.jetty.servlet.ServletHolder.handle(ServletHolder.java:848)
	at org.spark_project.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:584)
	at org.spark_project.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
	at org.spark_project.jetty.servlet.ServletHandler.doScope(ServletHandler.java:512)
	at org.spark_project.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
	at org.spark_project.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.spark_project.jetty.server.handler.gzip.GzipHandler.handle(GzipHandler.java:493)
	at org.spark_project.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:213)
	at org.spark_project.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
	at org.spark_project.jetty.server.Server.handle(Server.java:534)
	at org.spark_project.jetty.server.HttpChannel.handle(HttpChannel.java:320)
	at org.spark_project.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
	at org.spark_project.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
	at org.spark_project.jetty.io.FillInterest.fillable(FillInterest.java:108)
	at org.spark_project.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
	at org.spark_project.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
	at org.spark_project.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
	at java.lang.Thread.run(Thread.java:745)
2021-12-06 14:58:43,202 [SparkUI-74] WARN [org.spark_project.jetty.server.HttpChannel] - //qb:4040/static/vis.min.js
java.lang.NoSuchMethodError: javax.servlet.http.HttpServletRequest.isAsyncStarted()Z
	at org.spark_project.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:688)
	at org.spark_project.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
	at org.spark_project.jetty.servlet.ServletHandler.doScope(ServletHandler.java:512)
	at org.spark_project.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
	at org.spark_project.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.spark_project.jetty.server.handler.gzip.GzipHandler.handle(GzipHandler.java:493)
	at org.spark_project.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:213)
	at org.spark_project.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
	at org.spark_project.jetty.server.Server.handle(Server.java:534)
	at org.spark_project.jetty.server.HttpChannel.handle(HttpChannel.java:320)
	at org.spark_project.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
	at org.spark_project.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
	at org.spark_project.jetty.io.FillInterest.fillable(FillInterest.java:108)
	at org.spark_project.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
	at org.spark_project.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
	at org.spark_project.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
	at java.lang.Thread.run(Thread.java:745)
2021-12-06 14:58:43,202 [SparkUI-73] WARN [org.spark_project.jetty.server.HttpChannel] - //qb:4040/static/jquery-1.11.1.min.js
java.lang.NoSuchMethodError: javax.servlet.http.HttpServletRequest.isAsyncStarted()Z
	at org.spark_project.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:688)
	at org.spark_project.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
	at org.spark_project.jetty.servlet.ServletHandler.doScope(ServletHandler.java:512)
	at org.spark_project.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
	at org.spark_project.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.spark_project.jetty.server.handler.gzip.GzipHandler.handle(GzipHandler.java:493)
	at org.spark_project.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:213)
	at org.spark_project.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
	at org.spark_project.jetty.server.Server.handle(Server.java:534)
	at org.spark_project.jetty.server.HttpChannel.handle(HttpChannel.java:320)
	at org.spark_project.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
	at org.spark_project.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
	at org.spark_project.jetty.io.FillInterest.fillable(FillInterest.java:108)
	at org.spark_project.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
	at org.spark_project.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
	at org.spark_project.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
	at java.lang.Thread.run(Thread.java:745)
2021-12-06 14:58:43,202 [SparkUI-39] WARN [org.spark_project.jetty.server.HttpChannel] - //qb:4040/static/bootstrap-tooltip.js
java.lang.NoSuchMethodError: javax.servlet.http.HttpServletRequest.isAsyncStarted()Z
	at org.spark_project.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:688)
	at org.spark_project.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
	at org.spark_project.jetty.servlet.ServletHandler.doScope(ServletHandler.java:512)
	at org.spark_project.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
	at org.spark_project.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.spark_project.jetty.server.handler.gzip.GzipHandler.handle(GzipHandler.java:493)
	at org.spark_project.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:213)
	at org.spark_project.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
	at org.spark_project.jetty.server.Server.handle(Server.java:534)
	at org.spark_project.jetty.server.HttpChannel.handle(HttpChannel.java:320)
	at org.spark_project.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
	at org.spark_project.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
	at org.spark_project.jetty.io.FillInterest.fillable(FillInterest.java:108)
	at org.spark_project.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
	at org.spark_project.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
	at org.spark_project.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
	at java.lang.Thread.run(Thread.java:745)
2021-12-06 14:58:43,203 [SparkUI-44] WARN [org.spark_project.jetty.server.HttpChannel] - //qb:4040/static/sorttable.js
java.lang.NoSuchMethodError: javax.servlet.http.HttpServletRequest.isAsyncStarted()Z
	at org.spark_project.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:688)
	at org.spark_project.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
	at org.spark_project.jetty.servlet.ServletHandler.doScope(ServletHandler.java:512)
	at org.spark_project.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
	at org.spark_project.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.spark_project.jetty.server.handler.gzip.GzipHandler.handle(GzipHandler.java:493)
	at org.spark_project.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:213)
	at org.spark_project.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
	at org.spark_project.jetty.server.Server.handle(Server.java:534)
	at org.spark_project.jetty.server.HttpChannel.handle(HttpChannel.java:320)
	at org.spark_project.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
	at org.spark_project.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
	at org.spark_project.jetty.io.FillInterest.fillable(FillInterest.java:108)
	at org.spark_project.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
	at org.spark_project.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
	at org.spark_project.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
	at java.lang.Thread.run(Thread.java:745)
2021-12-06 14:58:43,203 [SparkUI-43] INFO [org.spark_project.jetty.servlet.DefaultServlet] - content=ResourceHttpContent@36add5e7{r=jar:file:/C:/Users/ACER/.m2/repository/org/apache/spark/spark-core_2.11/2.3.0/spark-core_2.11-2.3.0.jar!/org/apache/spark/ui/static/table.js,gz=false}
2021-12-06 14:58:43,204 [SparkUI-37] INFO [org.spark_project.jetty.servlet.DefaultServlet] - content=ResourceHttpContent@6b073bd9{r=jar:file:/C:/Users/ACER/.m2/repository/org/apache/spark/spark-core_2.11/2.3.0/spark-core_2.11-2.3.0.jar!/org/apache/spark/ui/static/initialize-tooltips.js,gz=false}
2021-12-06 14:58:43,204 [SparkUI-37] WARN [org.spark_project.jetty.servlet.ServletHandler] - Error for /static/initialize-tooltips.js
java.lang.NoSuchMethodError: javax.servlet.http.HttpServletRequest.isAsyncSupported()Z
	at org.spark_project.jetty.servlet.DefaultServlet.sendData(DefaultServlet.java:909)
	at org.spark_project.jetty.servlet.DefaultServlet.doGet(DefaultServlet.java:526)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:707)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:820)
	at org.spark_project.jetty.servlet.ServletHolder.handle(ServletHolder.java:848)
	at org.spark_project.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:584)
	at org.spark_project.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
	at org.spark_project.jetty.servlet.ServletHandler.doScope(ServletHandler.java:512)
	at org.spark_project.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
	at org.spark_project.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.spark_project.jetty.server.handler.gzip.GzipHandler.handle(GzipHandler.java:493)
	at org.spark_project.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:213)
	at org.spark_project.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
	at org.spark_project.jetty.server.Server.handle(Server.java:534)
	at org.spark_project.jetty.server.HttpChannel.handle(HttpChannel.java:320)
	at org.spark_project.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
	at org.spark_project.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
	at org.spark_project.jetty.io.FillInterest.fillable(FillInterest.java:108)
	at org.spark_project.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
	at org.spark_project.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
	at org.spark_project.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
	at java.lang.Thread.run(Thread.java:745)
2021-12-06 14:58:43,204 [SparkUI-43] WARN [org.spark_project.jetty.servlet.ServletHandler] - Error for /static/table.js
java.lang.NoSuchMethodError: javax.servlet.http.HttpServletRequest.isAsyncSupported()Z
	at org.spark_project.jetty.servlet.DefaultServlet.sendData(DefaultServlet.java:909)
	at org.spark_project.jetty.servlet.DefaultServlet.doGet(DefaultServlet.java:526)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:707)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:820)
	at org.spark_project.jetty.servlet.ServletHolder.handle(ServletHolder.java:848)
	at org.spark_project.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:584)
	at org.spark_project.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
	at org.spark_project.jetty.servlet.ServletHandler.doScope(ServletHandler.java:512)
	at org.spark_project.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
	at org.spark_project.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.spark_project.jetty.server.handler.gzip.GzipHandler.handle(GzipHandler.java:493)
	at org.spark_project.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:213)
	at org.spark_project.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
	at org.spark_project.jetty.server.Server.handle(Server.java:534)
	at org.spark_project.jetty.server.HttpChannel.handle(HttpChannel.java:320)
	at org.spark_project.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
	at org.spark_project.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
	at org.spark_project.jetty.io.FillInterest.fillable(FillInterest.java:108)
	at org.spark_project.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
	at org.spark_project.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
	at org.spark_project.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
	at java.lang.Thread.run(Thread.java:745)
2021-12-06 14:58:43,206 [SparkUI-43] WARN [org.spark_project.jetty.server.HttpChannel] - //qb:4040/static/table.js
java.lang.NoSuchMethodError: javax.servlet.http.HttpServletRequest.isAsyncStarted()Z
	at org.spark_project.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:688)
	at org.spark_project.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
	at org.spark_project.jetty.servlet.ServletHandler.doScope(ServletHandler.java:512)
	at org.spark_project.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
	at org.spark_project.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.spark_project.jetty.server.handler.gzip.GzipHandler.handle(GzipHandler.java:493)
	at org.spark_project.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:213)
	at org.spark_project.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
	at org.spark_project.jetty.server.Server.handle(Server.java:534)
	at org.spark_project.jetty.server.HttpChannel.handle(HttpChannel.java:320)
	at org.spark_project.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
	at org.spark_project.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
	at org.spark_project.jetty.io.FillInterest.fillable(FillInterest.java:108)
	at org.spark_project.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
	at org.spark_project.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
	at org.spark_project.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
	at java.lang.Thread.run(Thread.java:745)
2021-12-06 14:58:43,207 [SparkUI-37] WARN [org.spark_project.jetty.server.HttpChannel] - //qb:4040/static/initialize-tooltips.js
java.lang.NoSuchMethodError: javax.servlet.http.HttpServletRequest.isAsyncStarted()Z
	at org.spark_project.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:688)
	at org.spark_project.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
	at org.spark_project.jetty.servlet.ServletHandler.doScope(ServletHandler.java:512)
	at org.spark_project.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
	at org.spark_project.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.spark_project.jetty.server.handler.gzip.GzipHandler.handle(GzipHandler.java:493)
	at org.spark_project.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:213)
	at org.spark_project.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
	at org.spark_project.jetty.server.Server.handle(Server.java:534)
	at org.spark_project.jetty.server.HttpChannel.handle(HttpChannel.java:320)
	at org.spark_project.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
	at org.spark_project.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
	at org.spark_project.jetty.io.FillInterest.fillable(FillInterest.java:108)
	at org.spark_project.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
	at org.spark_project.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
	at org.spark_project.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
	at java.lang.Thread.run(Thread.java:745)
2021-12-06 14:58:43,209 [SparkUI-44] INFO [org.spark_project.jetty.servlet.DefaultServlet] - content=ResourceHttpContent@3fa4fdb{r=jar:file:/C:/Users/ACER/.m2/repository/org/apache/spark/spark-core_2.11/2.3.0/spark-core_2.11-2.3.0.jar!/org/apache/spark/ui/static/timeline-view.js,gz=false}
2021-12-06 14:58:43,209 [SparkUI-75] INFO [org.spark_project.jetty.servlet.DefaultServlet] - content=ResourceHttpContent@7e1d91fe{r=jar:file:/C:/Users/ACER/.m2/repository/org/apache/spark/spark-core_2.11/2.3.0/spark-core_2.11-2.3.0.jar!/org/apache/spark/ui/static/additional-metrics.js,gz=false}
2021-12-06 14:58:43,209 [SparkUI-44] WARN [org.spark_project.jetty.servlet.ServletHandler] - Error for /static/timeline-view.js
java.lang.NoSuchMethodError: javax.servlet.http.HttpServletRequest.isAsyncSupported()Z
	at org.spark_project.jetty.servlet.DefaultServlet.sendData(DefaultServlet.java:909)
	at org.spark_project.jetty.servlet.DefaultServlet.doGet(DefaultServlet.java:526)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:707)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:820)
	at org.spark_project.jetty.servlet.ServletHolder.handle(ServletHolder.java:848)
	at org.spark_project.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:584)
	at org.spark_project.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
	at org.spark_project.jetty.servlet.ServletHandler.doScope(ServletHandler.java:512)
	at org.spark_project.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
	at org.spark_project.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.spark_project.jetty.server.handler.gzip.GzipHandler.handle(GzipHandler.java:493)
	at org.spark_project.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:213)
	at org.spark_project.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
	at org.spark_project.jetty.server.Server.handle(Server.java:534)
	at org.spark_project.jetty.server.HttpChannel.handle(HttpChannel.java:320)
	at org.spark_project.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
	at org.spark_project.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
	at org.spark_project.jetty.io.FillInterest.fillable(FillInterest.java:108)
	at org.spark_project.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
	at org.spark_project.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
	at org.spark_project.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
	at java.lang.Thread.run(Thread.java:745)
2021-12-06 14:58:43,209 [SparkUI-75] WARN [org.spark_project.jetty.servlet.ServletHandler] - Error for /static/additional-metrics.js
java.lang.NoSuchMethodError: javax.servlet.http.HttpServletRequest.isAsyncSupported()Z
	at org.spark_project.jetty.servlet.DefaultServlet.sendData(DefaultServlet.java:909)
	at org.spark_project.jetty.servlet.DefaultServlet.doGet(DefaultServlet.java:526)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:707)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:820)
	at org.spark_project.jetty.servlet.ServletHolder.handle(ServletHolder.java:848)
	at org.spark_project.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:584)
	at org.spark_project.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
	at org.spark_project.jetty.servlet.ServletHandler.doScope(ServletHandler.java:512)
	at org.spark_project.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
	at org.spark_project.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.spark_project.jetty.server.handler.gzip.GzipHandler.handle(GzipHandler.java:493)
	at org.spark_project.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:213)
	at org.spark_project.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
	at org.spark_project.jetty.server.Server.handle(Server.java:534)
	at org.spark_project.jetty.server.HttpChannel.handle(HttpChannel.java:320)
	at org.spark_project.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
	at org.spark_project.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
	at org.spark_project.jetty.io.FillInterest.fillable(FillInterest.java:108)
	at org.spark_project.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
	at org.spark_project.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
	at org.spark_project.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
	at java.lang.Thread.run(Thread.java:745)
2021-12-06 14:58:43,210 [SparkUI-44] WARN [org.spark_project.jetty.server.HttpChannel] - //qb:4040/static/timeline-view.js
java.lang.NoSuchMethodError: javax.servlet.http.HttpServletRequest.isAsyncStarted()Z
	at org.spark_project.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:688)
	at org.spark_project.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
	at org.spark_project.jetty.servlet.ServletHandler.doScope(ServletHandler.java:512)
	at org.spark_project.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
	at org.spark_project.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.spark_project.jetty.server.handler.gzip.GzipHandler.handle(GzipHandler.java:493)
	at org.spark_project.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:213)
	at org.spark_project.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
	at org.spark_project.jetty.server.Server.handle(Server.java:534)
	at org.spark_project.jetty.server.HttpChannel.handle(HttpChannel.java:320)
	at org.spark_project.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
	at org.spark_project.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
	at org.spark_project.jetty.io.FillInterest.fillable(FillInterest.java:108)
	at org.spark_project.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
	at org.spark_project.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
	at org.spark_project.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
	at java.lang.Thread.run(Thread.java:745)
2021-12-06 14:58:43,210 [SparkUI-75] WARN [org.spark_project.jetty.server.HttpChannel] - //qb:4040/static/additional-metrics.js
java.lang.NoSuchMethodError: javax.servlet.http.HttpServletRequest.isAsyncStarted()Z
	at org.spark_project.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:688)
	at org.spark_project.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
	at org.spark_project.jetty.servlet.ServletHandler.doScope(ServletHandler.java:512)
	at org.spark_project.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
	at org.spark_project.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.spark_project.jetty.server.handler.gzip.GzipHandler.handle(GzipHandler.java:493)
	at org.spark_project.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:213)
	at org.spark_project.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
	at org.spark_project.jetty.server.Server.handle(Server.java:534)
	at org.spark_project.jetty.server.HttpChannel.handle(HttpChannel.java:320)
	at org.spark_project.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
	at org.spark_project.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
	at org.spark_project.jetty.io.FillInterest.fillable(FillInterest.java:108)
	at org.spark_project.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
	at org.spark_project.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
	at org.spark_project.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
	at java.lang.Thread.run(Thread.java:745)
2021-12-06 14:58:43,211 [SparkUI-76] INFO [org.spark_project.jetty.servlet.DefaultServlet] - content=ResourceHttpContent@74ed55f1{r=jar:file:/C:/Users/ACER/.m2/repository/org/apache/spark/spark-core_2.11/2.3.0/spark-core_2.11-2.3.0.jar!/org/apache/spark/ui/static/log-view.js,gz=false}
2021-12-06 14:58:43,211 [SparkUI-39] INFO [org.spark_project.jetty.servlet.DefaultServlet] - content=ResourceHttpContent@782c1840{r=jar:file:/C:/Users/ACER/.m2/repository/org/apache/spark/spark-core_2.11/2.3.0/spark-core_2.11-2.3.0.jar!/org/apache/spark/ui/static/webui.js,gz=false}
2021-12-06 14:58:43,211 [SparkUI-76] WARN [org.spark_project.jetty.servlet.ServletHandler] - Error for /static/log-view.js
java.lang.NoSuchMethodError: javax.servlet.http.HttpServletRequest.isAsyncSupported()Z
	at org.spark_project.jetty.servlet.DefaultServlet.sendData(DefaultServlet.java:909)
	at org.spark_project.jetty.servlet.DefaultServlet.doGet(DefaultServlet.java:526)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:707)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:820)
	at org.spark_project.jetty.servlet.ServletHolder.handle(ServletHolder.java:848)
	at org.spark_project.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:584)
	at org.spark_project.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
	at org.spark_project.jetty.servlet.ServletHandler.doScope(ServletHandler.java:512)
	at org.spark_project.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
	at org.spark_project.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.spark_project.jetty.server.handler.gzip.GzipHandler.handle(GzipHandler.java:493)
	at org.spark_project.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:213)
	at org.spark_project.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
	at org.spark_project.jetty.server.Server.handle(Server.java:534)
	at org.spark_project.jetty.server.HttpChannel.handle(HttpChannel.java:320)
	at org.spark_project.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
	at org.spark_project.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
	at org.spark_project.jetty.io.FillInterest.fillable(FillInterest.java:108)
	at org.spark_project.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
	at org.spark_project.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
	at org.spark_project.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
	at java.lang.Thread.run(Thread.java:745)
2021-12-06 14:58:43,211 [SparkUI-39] WARN [org.spark_project.jetty.servlet.ServletHandler] - Error for /static/webui.js
java.lang.NoSuchMethodError: javax.servlet.http.HttpServletRequest.isAsyncSupported()Z
	at org.spark_project.jetty.servlet.DefaultServlet.sendData(DefaultServlet.java:909)
	at org.spark_project.jetty.servlet.DefaultServlet.doGet(DefaultServlet.java:526)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:707)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:820)
	at org.spark_project.jetty.servlet.ServletHolder.handle(ServletHolder.java:848)
	at org.spark_project.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:584)
	at org.spark_project.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
	at org.spark_project.jetty.servlet.ServletHandler.doScope(ServletHandler.java:512)
	at org.spark_project.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
	at org.spark_project.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.spark_project.jetty.server.handler.gzip.GzipHandler.handle(GzipHandler.java:493)
	at org.spark_project.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:213)
	at org.spark_project.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
	at org.spark_project.jetty.server.Server.handle(Server.java:534)
	at org.spark_project.jetty.server.HttpChannel.handle(HttpChannel.java:320)
	at org.spark_project.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
	at org.spark_project.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
	at org.spark_project.jetty.io.FillInterest.fillable(FillInterest.java:108)
	at org.spark_project.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
	at org.spark_project.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
	at org.spark_project.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
	at java.lang.Thread.run(Thread.java:745)
2021-12-06 14:58:43,212 [SparkUI-76] WARN [org.spark_project.jetty.server.HttpChannel] - //qb:4040/static/log-view.js
java.lang.NoSuchMethodError: javax.servlet.http.HttpServletRequest.isAsyncStarted()Z
	at org.spark_project.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:688)
	at org.spark_project.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
	at org.spark_project.jetty.servlet.ServletHandler.doScope(ServletHandler.java:512)
	at org.spark_project.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
	at org.spark_project.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.spark_project.jetty.server.handler.gzip.GzipHandler.handle(GzipHandler.java:493)
	at org.spark_project.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:213)
	at org.spark_project.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
	at org.spark_project.jetty.server.Server.handle(Server.java:534)
	at org.spark_project.jetty.server.HttpChannel.handle(HttpChannel.java:320)
	at org.spark_project.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
	at org.spark_project.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
	at org.spark_project.jetty.io.FillInterest.fillable(FillInterest.java:108)
	at org.spark_project.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
	at org.spark_project.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
	at org.spark_project.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
	at java.lang.Thread.run(Thread.java:745)
2021-12-06 14:58:43,213 [SparkUI-76] INFO [org.spark_project.jetty.servlet.DefaultServlet] - content=ResourceHttpContent@c303a4b{r=jar:file:/C:/Users/ACER/.m2/repository/org/apache/spark/spark-core_2.11/2.3.0/spark-core_2.11-2.3.0.jar!/org/apache/spark/ui/static/dagre-d3.min.js,gz=false}
2021-12-06 14:58:43,213 [SparkUI-38] INFO [org.spark_project.jetty.servlet.DefaultServlet] - content=ResourceHttpContent@6a7e3632{r=jar:file:/C:/Users/ACER/.m2/repository/org/apache/spark/spark-core_2.11/2.3.0/spark-core_2.11-2.3.0.jar!/org/apache/spark/ui/static/d3.min.js,gz=false}
2021-12-06 14:58:43,214 [SparkUI-76] WARN [org.spark_project.jetty.servlet.ServletHandler] - Error for /static/dagre-d3.min.js
java.lang.NoSuchMethodError: javax.servlet.http.HttpServletRequest.isAsyncSupported()Z
	at org.spark_project.jetty.servlet.DefaultServlet.sendData(DefaultServlet.java:909)
	at org.spark_project.jetty.servlet.DefaultServlet.doGet(DefaultServlet.java:526)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:707)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:820)
	at org.spark_project.jetty.servlet.ServletHolder.handle(ServletHolder.java:848)
	at org.spark_project.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:584)
	at org.spark_project.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
	at org.spark_project.jetty.servlet.ServletHandler.doScope(ServletHandler.java:512)
	at org.spark_project.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
	at org.spark_project.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.spark_project.jetty.server.handler.gzip.GzipHandler.handle(GzipHandler.java:493)
	at org.spark_project.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:213)
	at org.spark_project.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
	at org.spark_project.jetty.server.Server.handle(Server.java:534)
	at org.spark_project.jetty.server.HttpChannel.handle(HttpChannel.java:320)
	at org.spark_project.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
	at org.spark_project.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
	at org.spark_project.jetty.io.FillInterest.fillable(FillInterest.java:108)
	at org.spark_project.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
	at org.spark_project.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
	at org.spark_project.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
	at java.lang.Thread.run(Thread.java:745)
2021-12-06 14:58:43,214 [SparkUI-39] WARN [org.spark_project.jetty.server.HttpChannel] - //qb:4040/static/webui.js
java.lang.NoSuchMethodError: javax.servlet.http.HttpServletRequest.isAsyncStarted()Z
	at org.spark_project.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:688)
	at org.spark_project.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
	at org.spark_project.jetty.servlet.ServletHandler.doScope(ServletHandler.java:512)
	at org.spark_project.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
	at org.spark_project.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.spark_project.jetty.server.handler.gzip.GzipHandler.handle(GzipHandler.java:493)
	at org.spark_project.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:213)
	at org.spark_project.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
	at org.spark_project.jetty.server.Server.handle(Server.java:534)
	at org.spark_project.jetty.server.HttpChannel.handle(HttpChannel.java:320)
	at org.spark_project.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
	at org.spark_project.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
	at org.spark_project.jetty.io.FillInterest.fillable(FillInterest.java:108)
	at org.spark_project.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
	at org.spark_project.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
	at org.spark_project.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
	at java.lang.Thread.run(Thread.java:745)
2021-12-06 14:58:43,214 [SparkUI-38] WARN [org.spark_project.jetty.servlet.ServletHandler] - Error for /static/d3.min.js
java.lang.NoSuchMethodError: javax.servlet.http.HttpServletRequest.isAsyncSupported()Z
	at org.spark_project.jetty.servlet.DefaultServlet.sendData(DefaultServlet.java:909)
	at org.spark_project.jetty.servlet.DefaultServlet.doGet(DefaultServlet.java:526)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:707)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:820)
	at org.spark_project.jetty.servlet.ServletHolder.handle(ServletHolder.java:848)
	at org.spark_project.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:584)
	at org.spark_project.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
	at org.spark_project.jetty.servlet.ServletHandler.doScope(ServletHandler.java:512)
	at org.spark_project.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
	at org.spark_project.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.spark_project.jetty.server.handler.gzip.GzipHandler.handle(GzipHandler.java:493)
	at org.spark_project.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:213)
	at org.spark_project.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
	at org.spark_project.jetty.server.Server.handle(Server.java:534)
	at org.spark_project.jetty.server.HttpChannel.handle(HttpChannel.java:320)
	at org.spark_project.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
	at org.spark_project.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
	at org.spark_project.jetty.io.FillInterest.fillable(FillInterest.java:108)
	at org.spark_project.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
	at org.spark_project.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
	at org.spark_project.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
	at java.lang.Thread.run(Thread.java:745)
2021-12-06 14:58:43,214 [SparkUI-38] WARN [org.spark_project.jetty.server.HttpChannel] - //qb:4040/static/d3.min.js
java.lang.NoSuchMethodError: javax.servlet.http.HttpServletRequest.isAsyncStarted()Z
	at org.spark_project.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:688)
	at org.spark_project.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
	at org.spark_project.jetty.servlet.ServletHandler.doScope(ServletHandler.java:512)
	at org.spark_project.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
	at org.spark_project.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.spark_project.jetty.server.handler.gzip.GzipHandler.handle(GzipHandler.java:493)
	at org.spark_project.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:213)
	at org.spark_project.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
	at org.spark_project.jetty.server.Server.handle(Server.java:534)
	at org.spark_project.jetty.server.HttpChannel.handle(HttpChannel.java:320)
	at org.spark_project.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
	at org.spark_project.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
	at org.spark_project.jetty.io.FillInterest.fillable(FillInterest.java:108)
	at org.spark_project.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
	at org.spark_project.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
	at org.spark_project.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
	at java.lang.Thread.run(Thread.java:745)
2021-12-06 14:58:43,214 [SparkUI-76] WARN [org.spark_project.jetty.server.HttpChannel] - //qb:4040/static/dagre-d3.min.js
java.lang.NoSuchMethodError: javax.servlet.http.HttpServletRequest.isAsyncStarted()Z
	at org.spark_project.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:688)
	at org.spark_project.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
	at org.spark_project.jetty.servlet.ServletHandler.doScope(ServletHandler.java:512)
	at org.spark_project.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
	at org.spark_project.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.spark_project.jetty.server.handler.gzip.GzipHandler.handle(GzipHandler.java:493)
	at org.spark_project.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:213)
	at org.spark_project.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
	at org.spark_project.jetty.server.Server.handle(Server.java:534)
	at org.spark_project.jetty.server.HttpChannel.handle(HttpChannel.java:320)
	at org.spark_project.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
	at org.spark_project.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
	at org.spark_project.jetty.io.FillInterest.fillable(FillInterest.java:108)
	at org.spark_project.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
	at org.spark_project.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
	at org.spark_project.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
	at java.lang.Thread.run(Thread.java:745)
2021-12-06 14:58:43,216 [SparkUI-75] INFO [org.spark_project.jetty.servlet.DefaultServlet] - content=ResourceHttpContent@44080d07{r=jar:file:/C:/Users/ACER/.m2/repository/org/apache/spark/spark-core_2.11/2.3.0/spark-core_2.11-2.3.0.jar!/org/apache/spark/ui/static/graphlib-dot.min.js,gz=false}
2021-12-06 14:58:43,216 [SparkUI-75] WARN [org.spark_project.jetty.servlet.ServletHandler] - Error for /static/graphlib-dot.min.js
java.lang.NoSuchMethodError: javax.servlet.http.HttpServletRequest.isAsyncSupported()Z
	at org.spark_project.jetty.servlet.DefaultServlet.sendData(DefaultServlet.java:909)
	at org.spark_project.jetty.servlet.DefaultServlet.doGet(DefaultServlet.java:526)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:707)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:820)
	at org.spark_project.jetty.servlet.ServletHolder.handle(ServletHolder.java:848)
	at org.spark_project.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:584)
	at org.spark_project.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
	at org.spark_project.jetty.servlet.ServletHandler.doScope(ServletHandler.java:512)
	at org.spark_project.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
	at org.spark_project.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.spark_project.jetty.server.handler.gzip.GzipHandler.handle(GzipHandler.java:493)
	at org.spark_project.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:213)
	at org.spark_project.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
	at org.spark_project.jetty.server.Server.handle(Server.java:534)
	at org.spark_project.jetty.server.HttpChannel.handle(HttpChannel.java:320)
	at org.spark_project.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
	at org.spark_project.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
	at org.spark_project.jetty.io.FillInterest.fillable(FillInterest.java:108)
	at org.spark_project.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
	at org.spark_project.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
	at org.spark_project.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
	at java.lang.Thread.run(Thread.java:745)
2021-12-06 14:58:43,216 [SparkUI-74] INFO [org.spark_project.jetty.servlet.DefaultServlet] - content=ResourceHttpContent@3ecd8685{r=jar:file:/C:/Users/ACER/.m2/repository/org/apache/spark/spark-core_2.11/2.3.0/spark-core_2.11-2.3.0.jar!/org/apache/spark/ui/static/spark-dag-viz.js,gz=false}
2021-12-06 14:58:43,216 [SparkUI-74] WARN [org.spark_project.jetty.servlet.ServletHandler] - Error for /static/spark-dag-viz.js
java.lang.NoSuchMethodError: javax.servlet.http.HttpServletRequest.isAsyncSupported()Z
	at org.spark_project.jetty.servlet.DefaultServlet.sendData(DefaultServlet.java:909)
	at org.spark_project.jetty.servlet.DefaultServlet.doGet(DefaultServlet.java:526)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:707)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:820)
	at org.spark_project.jetty.servlet.ServletHolder.handle(ServletHolder.java:848)
	at org.spark_project.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:584)
	at org.spark_project.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
	at org.spark_project.jetty.servlet.ServletHandler.doScope(ServletHandler.java:512)
	at org.spark_project.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
	at org.spark_project.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.spark_project.jetty.server.handler.gzip.GzipHandler.handle(GzipHandler.java:493)
	at org.spark_project.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:213)
	at org.spark_project.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
	at org.spark_project.jetty.server.Server.handle(Server.java:534)
	at org.spark_project.jetty.server.HttpChannel.handle(HttpChannel.java:320)
	at org.spark_project.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
	at org.spark_project.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
	at org.spark_project.jetty.io.FillInterest.fillable(FillInterest.java:108)
	at org.spark_project.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
	at org.spark_project.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
	at org.spark_project.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
	at java.lang.Thread.run(Thread.java:745)
2021-12-06 14:58:43,216 [SparkUI-75] WARN [org.spark_project.jetty.server.HttpChannel] - //qb:4040/static/graphlib-dot.min.js
java.lang.NoSuchMethodError: javax.servlet.http.HttpServletRequest.isAsyncStarted()Z
	at org.spark_project.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:688)
	at org.spark_project.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
	at org.spark_project.jetty.servlet.ServletHandler.doScope(ServletHandler.java:512)
	at org.spark_project.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
	at org.spark_project.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.spark_project.jetty.server.handler.gzip.GzipHandler.handle(GzipHandler.java:493)
	at org.spark_project.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:213)
	at org.spark_project.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
	at org.spark_project.jetty.server.Server.handle(Server.java:534)
	at org.spark_project.jetty.server.HttpChannel.handle(HttpChannel.java:320)
	at org.spark_project.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
	at org.spark_project.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
	at org.spark_project.jetty.io.FillInterest.fillable(FillInterest.java:108)
	at org.spark_project.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
	at org.spark_project.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
	at org.spark_project.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
	at java.lang.Thread.run(Thread.java:745)
2021-12-06 14:58:43,217 [SparkUI-74] WARN [org.spark_project.jetty.server.HttpChannel] - //qb:4040/static/spark-dag-viz.js
java.lang.NoSuchMethodError: javax.servlet.http.HttpServletRequest.isAsyncStarted()Z
	at org.spark_project.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:688)
	at org.spark_project.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
	at org.spark_project.jetty.servlet.ServletHandler.doScope(ServletHandler.java:512)
	at org.spark_project.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
	at org.spark_project.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.spark_project.jetty.server.handler.gzip.GzipHandler.handle(GzipHandler.java:493)
	at org.spark_project.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:213)
	at org.spark_project.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
	at org.spark_project.jetty.server.Server.handle(Server.java:534)
	at org.spark_project.jetty.server.HttpChannel.handle(HttpChannel.java:320)
	at org.spark_project.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
	at org.spark_project.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
	at org.spark_project.jetty.io.FillInterest.fillable(FillInterest.java:108)
	at org.spark_project.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
	at org.spark_project.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
	at org.spark_project.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
	at java.lang.Thread.run(Thread.java:745)
2021-12-06 14:58:43,223 [SparkUI-43] INFO [org.spark_project.jetty.servlet.DefaultServlet] - content=ResourceHttpContent@22de2dd6{r=jar:file:/C:/Users/ACER/.m2/repository/org/apache/spark/spark-core_2.11/2.3.0/spark-core_2.11-2.3.0.jar!/org/apache/spark/ui/static/spark-logo-77x50px-hd.png,gz=false}
2021-12-06 14:58:43,223 [SparkUI-43] WARN [org.spark_project.jetty.servlet.ServletHandler] - Error for /static/spark-logo-77x50px-hd.png
java.lang.NoSuchMethodError: javax.servlet.http.HttpServletRequest.isAsyncSupported()Z
	at org.spark_project.jetty.servlet.DefaultServlet.sendData(DefaultServlet.java:909)
	at org.spark_project.jetty.servlet.DefaultServlet.doGet(DefaultServlet.java:526)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:707)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:820)
	at org.spark_project.jetty.servlet.ServletHolder.handle(ServletHolder.java:848)
	at org.spark_project.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:584)
	at org.spark_project.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
	at org.spark_project.jetty.servlet.ServletHandler.doScope(ServletHandler.java:512)
	at org.spark_project.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
	at org.spark_project.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.spark_project.jetty.server.handler.gzip.GzipHandler.handle(GzipHandler.java:448)
	at org.spark_project.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:213)
	at org.spark_project.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
	at org.spark_project.jetty.server.Server.handle(Server.java:534)
	at org.spark_project.jetty.server.HttpChannel.handle(HttpChannel.java:320)
	at org.spark_project.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
	at org.spark_project.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
	at org.spark_project.jetty.io.FillInterest.fillable(FillInterest.java:108)
	at org.spark_project.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
	at org.spark_project.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
	at org.spark_project.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
	at java.lang.Thread.run(Thread.java:745)
2021-12-06 14:58:43,223 [SparkUI-43] WARN [org.spark_project.jetty.server.HttpChannel] - //qb:4040/static/spark-logo-77x50px-hd.png
java.lang.NoSuchMethodError: javax.servlet.http.HttpServletRequest.isAsyncStarted()Z
	at org.spark_project.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:688)
	at org.spark_project.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
	at org.spark_project.jetty.servlet.ServletHandler.doScope(ServletHandler.java:512)
	at org.spark_project.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
	at org.spark_project.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.spark_project.jetty.server.handler.gzip.GzipHandler.handle(GzipHandler.java:448)
	at org.spark_project.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:213)
	at org.spark_project.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
	at org.spark_project.jetty.server.Server.handle(Server.java:534)
	at org.spark_project.jetty.server.HttpChannel.handle(HttpChannel.java:320)
	at org.spark_project.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
	at org.spark_project.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
	at org.spark_project.jetty.io.FillInterest.fillable(FillInterest.java:108)
	at org.spark_project.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
	at org.spark_project.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
	at org.spark_project.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
	at java.lang.Thread.run(Thread.java:745)
2021-12-06 14:58:43,456 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 774
2021-12-06 14:58:43,457 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 762
2021-12-06 14:58:43,457 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 731
2021-12-06 14:58:43,458 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 726
2021-12-06 14:58:43,459 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 755
2021-12-06 14:58:43,459 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 770
2021-12-06 14:58:43,459 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 729
2021-12-06 14:58:43,459 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 748
2021-12-06 14:58:43,459 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 772
2021-12-06 14:58:43,459 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 728
2021-12-06 14:58:43,459 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 760
2021-12-06 14:58:43,459 [dispatcher-event-loop-9] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_31_piece0 on qb:60678 in memory (size: 2.2 KB, free: 1990.6 MB)
2021-12-06 14:58:43,460 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 737
2021-12-06 14:58:43,460 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 761
2021-12-06 14:58:43,460 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 743
2021-12-06 14:58:43,460 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 751
2021-12-06 14:58:43,460 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 750
2021-12-06 14:58:43,460 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 753
2021-12-06 14:58:43,460 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 741
2021-12-06 14:58:43,460 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 746
2021-12-06 14:58:43,460 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 768
2021-12-06 14:58:43,460 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 759
2021-12-06 14:58:43,460 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 740
2021-12-06 14:58:43,460 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 742
2021-12-06 14:58:43,460 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 769
2021-12-06 14:58:43,460 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 735
2021-12-06 14:58:43,460 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 744
2021-12-06 14:58:43,460 [dispatcher-event-loop-7] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_30_piece0 on qb:60678 in memory (size: 66.4 KB, free: 1990.7 MB)
2021-12-06 14:58:43,461 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 736
2021-12-06 14:58:43,461 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 739
2021-12-06 14:58:43,461 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 756
2021-12-06 14:58:43,461 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 758
2021-12-06 14:58:43,461 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 749
2021-12-06 14:58:43,461 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 738
2021-12-06 14:58:43,461 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 752
2021-12-06 14:58:43,461 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 734
2021-12-06 14:58:43,461 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 732
2021-12-06 14:58:43,461 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 765
2021-12-06 14:58:43,461 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 766
2021-12-06 14:58:43,461 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 733
2021-12-06 14:58:43,461 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 747
2021-12-06 14:58:43,461 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 725
2021-12-06 14:58:43,461 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 763
2021-12-06 14:58:43,461 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 773
2021-12-06 14:58:43,461 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 764
2021-12-06 14:58:43,461 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 727
2021-12-06 14:58:43,461 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 754
2021-12-06 14:58:43,461 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 745
2021-12-06 14:58:43,461 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 771
2021-12-06 14:58:43,461 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 730
2021-12-06 14:58:43,461 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 757
2021-12-06 14:58:43,461 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 767
2021-12-06 14:58:43,781 [Executor task launch worker for task 76] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 45.0 (TID 76). 1075 bytes result sent to driver
2021-12-06 14:58:43,781 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 45.0 (TID 76) in 990 ms on localhost (executor driver) (1/2)
2021-12-06 14:58:43,788 [Executor task launch worker for task 77] INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 45.0 (TID 77). 1075 bytes result sent to driver
2021-12-06 14:58:43,788 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 45.0 (TID 77) in 997 ms on localhost (executor driver) (2/2)
2021-12-06 14:58:43,788 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 45.0, whose tasks have all completed, from pool 
2021-12-06 14:58:43,789 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ShuffleMapStage 45 (distinct at PaidPromotionAdjustParameter.scala:165) finished in 1.002 s
2021-12-06 14:58:43,789 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - looking for newly runnable stages
2021-12-06 14:58:43,789 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - running: Set()
2021-12-06 14:58:43,789 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - waiting: Set(ResultStage 46)
2021-12-06 14:58:43,789 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - failed: Set()
2021-12-06 14:58:43,789 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 46 (MapPartitionsRDD[57] at distinct at PaidPromotionAdjustParameter.scala:165), which has no missing parents
2021-12-06 14:58:43,789 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_33 stored as values in memory (estimated size 3.7 KB, free 1990.2 MB)
2021-12-06 14:58:43,791 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_33_piece0 stored as bytes in memory (estimated size 2.2 KB, free 1990.2 MB)
2021-12-06 14:58:43,791 [dispatcher-event-loop-2] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_33_piece0 in memory on qb:60678 (size: 2.2 KB, free: 1990.7 MB)
2021-12-06 14:58:43,791 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 33 from broadcast at DAGScheduler.scala:1039
2021-12-06 14:58:43,791 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from ResultStage 46 (MapPartitionsRDD[57] at distinct at PaidPromotionAdjustParameter.scala:165) (first 15 tasks are for partitions Vector(0, 1))
2021-12-06 14:58:43,791 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 46.0 with 2 tasks
2021-12-06 14:58:43,792 [dispatcher-event-loop-5] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 46.0 (TID 78, localhost, executor driver, partition 0, ANY, 7649 bytes)
2021-12-06 14:58:43,792 [dispatcher-event-loop-5] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 46.0 (TID 79, localhost, executor driver, partition 1, ANY, 7649 bytes)
2021-12-06 14:58:43,792 [Executor task launch worker for task 79] INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 46.0 (TID 79)
2021-12-06 14:58:43,792 [Executor task launch worker for task 78] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 46.0 (TID 78)
2021-12-06 14:58:43,793 [Executor task launch worker for task 78] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 2 non-empty blocks out of 2 blocks
2021-12-06 14:58:43,793 [Executor task launch worker for task 79] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 2 non-empty blocks out of 2 blocks
2021-12-06 14:58:43,793 [Executor task launch worker for task 78] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-06 14:58:43,793 [Executor task launch worker for task 79] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-06 14:58:43,804 [Executor task launch worker for task 78] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 46.0 (TID 78). 1010 bytes result sent to driver
2021-12-06 14:58:43,804 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 46.0 (TID 78) in 13 ms on localhost (executor driver) (1/2)
2021-12-06 14:58:43,806 [Executor task launch worker for task 79] INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 46.0 (TID 79). 967 bytes result sent to driver
2021-12-06 14:58:43,807 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 46.0 (TID 79) in 15 ms on localhost (executor driver) (2/2)
2021-12-06 14:58:43,807 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 46.0, whose tasks have all completed, from pool 
2021-12-06 14:58:43,807 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 46 (count at PaidPromotionAdjustParameter.scala:173) finished in 0.018 s
2021-12-06 14:58:43,807 [main] INFO [org.apache.spark.scheduler.DAGScheduler] - Job 18 finished: count at PaidPromotionAdjustParameter.scala:173, took 1.021577 s
2021-12-06 14:58:43,807 [main] INFO [PaidPromotion$] -  = 80
2021-12-06 14:58:43,809 [main] INFO [org.apache.spark.SparkContext] - Starting job: count at PaidPromotionAdjustParameter.scala:174
2021-12-06 14:58:43,810 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 58 (intersection at PaidPromotionAdjustParameter.scala:166)
2021-12-06 14:58:43,810 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 59 (intersection at PaidPromotionAdjustParameter.scala:166)
2021-12-06 14:58:43,810 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 19 (count at PaidPromotionAdjustParameter.scala:174) with 4 output partitions
2021-12-06 14:58:43,810 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 51 (count at PaidPromotionAdjustParameter.scala:174)
2021-12-06 14:58:43,810 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 48, ShuffleMapStage 50)
2021-12-06 14:58:43,810 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List(ShuffleMapStage 48, ShuffleMapStage 50)
2021-12-06 14:58:43,810 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ShuffleMapStage 48 (MapPartitionsRDD[58] at intersection at PaidPromotionAdjustParameter.scala:166), which has no missing parents
2021-12-06 14:58:43,811 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_34 stored as values in memory (estimated size 4.0 KB, free 1990.2 MB)
2021-12-06 14:58:43,812 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_34_piece0 stored as bytes in memory (estimated size 2.3 KB, free 1990.2 MB)
2021-12-06 14:58:43,812 [dispatcher-event-loop-9] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_34_piece0 in memory on qb:60678 (size: 2.3 KB, free: 1990.7 MB)
2021-12-06 14:58:43,813 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 34 from broadcast at DAGScheduler.scala:1039
2021-12-06 14:58:43,813 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 4 missing tasks from ShuffleMapStage 48 (MapPartitionsRDD[58] at intersection at PaidPromotionAdjustParameter.scala:166) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
2021-12-06 14:58:43,813 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 48.0 with 4 tasks
2021-12-06 14:58:43,813 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ShuffleMapStage 50 (MapPartitionsRDD[59] at intersection at PaidPromotionAdjustParameter.scala:166), which has no missing parents
2021-12-06 14:58:43,813 [dispatcher-event-loop-6] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 48.0 (TID 80, localhost, executor driver, partition 0, ANY, 7638 bytes)
2021-12-06 14:58:43,813 [dispatcher-event-loop-6] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 48.0 (TID 81, localhost, executor driver, partition 1, ANY, 7638 bytes)
2021-12-06 14:58:43,813 [dispatcher-event-loop-6] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 2.0 in stage 48.0 (TID 82, localhost, executor driver, partition 2, ANY, 7638 bytes)
2021-12-06 14:58:43,814 [dispatcher-event-loop-6] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 3.0 in stage 48.0 (TID 83, localhost, executor driver, partition 3, ANY, 7638 bytes)
2021-12-06 14:58:43,814 [Executor task launch worker for task 82] INFO [org.apache.spark.executor.Executor] - Running task 2.0 in stage 48.0 (TID 82)
2021-12-06 14:58:43,814 [Executor task launch worker for task 83] INFO [org.apache.spark.executor.Executor] - Running task 3.0 in stage 48.0 (TID 83)
2021-12-06 14:58:43,814 [Executor task launch worker for task 80] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 48.0 (TID 80)
2021-12-06 14:58:43,814 [Executor task launch worker for task 81] INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 48.0 (TID 81)
2021-12-06 14:58:43,814 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_35 stored as values in memory (estimated size 4.0 KB, free 1990.2 MB)
2021-12-06 14:58:43,814 [Executor task launch worker for task 80] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 4 non-empty blocks out of 4 blocks
2021-12-06 14:58:43,815 [Executor task launch worker for task 80] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 1 ms
2021-12-06 14:58:43,815 [Executor task launch worker for task 82] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 4 non-empty blocks out of 4 blocks
2021-12-06 14:58:43,815 [Executor task launch worker for task 83] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 4 non-empty blocks out of 4 blocks
2021-12-06 14:58:43,815 [Executor task launch worker for task 82] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 1 ms
2021-12-06 14:58:43,815 [Executor task launch worker for task 83] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 1 ms
2021-12-06 14:58:43,815 [Executor task launch worker for task 81] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 4 non-empty blocks out of 4 blocks
2021-12-06 14:58:43,815 [Executor task launch worker for task 81] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-06 14:58:43,816 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_35_piece0 stored as bytes in memory (estimated size 2.3 KB, free 1990.2 MB)
2021-12-06 14:58:43,816 [dispatcher-event-loop-2] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_35_piece0 in memory on qb:60678 (size: 2.3 KB, free: 1990.7 MB)
2021-12-06 14:58:43,817 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 35 from broadcast at DAGScheduler.scala:1039
2021-12-06 14:58:43,817 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from ShuffleMapStage 50 (MapPartitionsRDD[59] at intersection at PaidPromotionAdjustParameter.scala:166) (first 15 tasks are for partitions Vector(0, 1))
2021-12-06 14:58:43,817 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 50.0 with 2 tasks
2021-12-06 14:58:43,817 [dispatcher-event-loop-5] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 50.0 (TID 84, localhost, executor driver, partition 0, ANY, 7638 bytes)
2021-12-06 14:58:43,817 [dispatcher-event-loop-5] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 50.0 (TID 85, localhost, executor driver, partition 1, ANY, 7638 bytes)
2021-12-06 14:58:43,817 [Executor task launch worker for task 85] INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 50.0 (TID 85)
2021-12-06 14:58:43,817 [Executor task launch worker for task 84] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 50.0 (TID 84)
2021-12-06 14:58:43,818 [Executor task launch worker for task 84] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 2 non-empty blocks out of 2 blocks
2021-12-06 14:58:43,818 [Executor task launch worker for task 85] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 2 non-empty blocks out of 2 blocks
2021-12-06 14:58:43,819 [Executor task launch worker for task 84] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 1 ms
2021-12-06 14:58:43,819 [Executor task launch worker for task 85] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 1 ms
2021-12-06 14:58:43,836 [Executor task launch worker for task 83] INFO [org.apache.spark.executor.Executor] - Finished task 3.0 in stage 48.0 (TID 83). 1120 bytes result sent to driver
2021-12-06 14:58:43,836 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 3.0 in stage 48.0 (TID 83) in 23 ms on localhost (executor driver) (1/4)
2021-12-06 14:58:43,837 [Executor task launch worker for task 81] INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 48.0 (TID 81). 1120 bytes result sent to driver
2021-12-06 14:58:43,837 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 48.0 (TID 81) in 24 ms on localhost (executor driver) (2/4)
2021-12-06 14:58:43,838 [Executor task launch worker for task 80] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 48.0 (TID 80). 1120 bytes result sent to driver
2021-12-06 14:58:43,838 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 48.0 (TID 80) in 25 ms on localhost (executor driver) (3/4)
2021-12-06 14:58:43,839 [Executor task launch worker for task 82] INFO [org.apache.spark.executor.Executor] - Finished task 2.0 in stage 48.0 (TID 82). 1120 bytes result sent to driver
2021-12-06 14:58:43,840 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 2.0 in stage 48.0 (TID 82) in 27 ms on localhost (executor driver) (4/4)
2021-12-06 14:58:43,840 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 48.0, whose tasks have all completed, from pool 
2021-12-06 14:58:43,840 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ShuffleMapStage 48 (intersection at PaidPromotionAdjustParameter.scala:166) finished in 0.030 s
2021-12-06 14:58:43,840 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - looking for newly runnable stages
2021-12-06 14:58:43,840 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - running: Set(ShuffleMapStage 50)
2021-12-06 14:58:43,840 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - waiting: Set(ResultStage 51)
2021-12-06 14:58:43,840 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - failed: Set()
2021-12-06 14:58:43,842 [Executor task launch worker for task 84] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 50.0 (TID 84). 1206 bytes result sent to driver
2021-12-06 14:58:43,842 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 50.0 (TID 84) in 25 ms on localhost (executor driver) (1/2)
2021-12-06 14:58:43,843 [Executor task launch worker for task 85] INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 50.0 (TID 85). 1163 bytes result sent to driver
2021-12-06 14:58:43,843 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 50.0 (TID 85) in 26 ms on localhost (executor driver) (2/2)
2021-12-06 14:58:43,843 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 50.0, whose tasks have all completed, from pool 
2021-12-06 14:58:43,843 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ShuffleMapStage 50 (intersection at PaidPromotionAdjustParameter.scala:166) finished in 0.029 s
2021-12-06 14:58:43,843 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - looking for newly runnable stages
2021-12-06 14:58:43,843 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - running: Set()
2021-12-06 14:58:43,843 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - waiting: Set(ResultStage 51)
2021-12-06 14:58:43,843 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - failed: Set()
2021-12-06 14:58:43,844 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 51 (MapPartitionsRDD[63] at intersection at PaidPromotionAdjustParameter.scala:166), which has no missing parents
2021-12-06 14:58:43,844 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_36 stored as values in memory (estimated size 3.6 KB, free 1990.2 MB)
2021-12-06 14:58:43,846 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_36_piece0 stored as bytes in memory (estimated size 2.1 KB, free 1990.2 MB)
2021-12-06 14:58:43,846 [dispatcher-event-loop-8] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_36_piece0 in memory on qb:60678 (size: 2.1 KB, free: 1990.7 MB)
2021-12-06 14:58:43,847 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 36 from broadcast at DAGScheduler.scala:1039
2021-12-06 14:58:43,847 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 4 missing tasks from ResultStage 51 (MapPartitionsRDD[63] at intersection at PaidPromotionAdjustParameter.scala:166) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
2021-12-06 14:58:43,847 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 51.0 with 4 tasks
2021-12-06 14:58:43,847 [dispatcher-event-loop-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 51.0 (TID 86, localhost, executor driver, partition 0, PROCESS_LOCAL, 7712 bytes)
2021-12-06 14:58:43,847 [dispatcher-event-loop-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 51.0 (TID 87, localhost, executor driver, partition 1, PROCESS_LOCAL, 7712 bytes)
2021-12-06 14:58:43,847 [dispatcher-event-loop-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 2.0 in stage 51.0 (TID 88, localhost, executor driver, partition 2, PROCESS_LOCAL, 7712 bytes)
2021-12-06 14:58:43,847 [dispatcher-event-loop-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 3.0 in stage 51.0 (TID 89, localhost, executor driver, partition 3, PROCESS_LOCAL, 7712 bytes)
2021-12-06 14:58:43,848 [Executor task launch worker for task 87] INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 51.0 (TID 87)
2021-12-06 14:58:43,848 [Executor task launch worker for task 86] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 51.0 (TID 86)
2021-12-06 14:58:43,848 [Executor task launch worker for task 88] INFO [org.apache.spark.executor.Executor] - Running task 2.0 in stage 51.0 (TID 88)
2021-12-06 14:58:43,848 [Executor task launch worker for task 89] INFO [org.apache.spark.executor.Executor] - Running task 3.0 in stage 51.0 (TID 89)
2021-12-06 14:58:43,849 [Executor task launch worker for task 87] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 4 blocks
2021-12-06 14:58:43,849 [Executor task launch worker for task 87] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 1 ms
2021-12-06 14:58:43,849 [Executor task launch worker for task 86] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 4 blocks
2021-12-06 14:58:43,849 [Executor task launch worker for task 86] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-06 14:58:43,849 [Executor task launch worker for task 88] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 4 blocks
2021-12-06 14:58:43,849 [Executor task launch worker for task 88] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-06 14:58:43,849 [Executor task launch worker for task 89] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 4 blocks
2021-12-06 14:58:43,849 [Executor task launch worker for task 89] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-06 14:58:43,850 [Executor task launch worker for task 88] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2021-12-06 14:58:43,850 [Executor task launch worker for task 89] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2021-12-06 14:58:43,850 [Executor task launch worker for task 88] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-06 14:58:43,850 [Executor task launch worker for task 89] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-06 14:58:43,850 [Executor task launch worker for task 86] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2021-12-06 14:58:43,851 [Executor task launch worker for task 86] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 1 ms
2021-12-06 14:58:43,851 [Executor task launch worker for task 87] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2021-12-06 14:58:43,851 [Executor task launch worker for task 87] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-06 14:58:43,858 [Executor task launch worker for task 89] INFO [org.apache.spark.executor.Executor] - Finished task 3.0 in stage 51.0 (TID 89). 1010 bytes result sent to driver
2021-12-06 14:58:43,858 [Executor task launch worker for task 86] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 51.0 (TID 86). 967 bytes result sent to driver
2021-12-06 14:58:43,858 [Executor task launch worker for task 88] INFO [org.apache.spark.executor.Executor] - Finished task 2.0 in stage 51.0 (TID 88). 1010 bytes result sent to driver
2021-12-06 14:58:43,858 [Executor task launch worker for task 87] INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 51.0 (TID 87). 967 bytes result sent to driver
2021-12-06 14:58:43,859 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 3.0 in stage 51.0 (TID 89) in 12 ms on localhost (executor driver) (1/4)
2021-12-06 14:58:43,859 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 51.0 (TID 86) in 12 ms on localhost (executor driver) (2/4)
2021-12-06 14:58:43,859 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 2.0 in stage 51.0 (TID 88) in 12 ms on localhost (executor driver) (3/4)
2021-12-06 14:58:43,859 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 51.0 (TID 87) in 12 ms on localhost (executor driver) (4/4)
2021-12-06 14:58:43,859 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 51.0, whose tasks have all completed, from pool 
2021-12-06 14:58:43,859 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 51 (count at PaidPromotionAdjustParameter.scala:174) finished in 0.015 s
2021-12-06 14:58:43,859 [main] INFO [org.apache.spark.scheduler.DAGScheduler] - Job 19 finished: count at PaidPromotionAdjustParameter.scala:174, took 0.049827 s
2021-12-06 14:58:43,860 [main] INFO [PaidPromotion$] -    = 80
2021-12-06 14:58:43,878 [main] INFO [org.apache.hadoop.conf.Configuration.deprecation] - mapred.output.dir is deprecated. Instead, use mapreduce.output.fileoutputformat.outputdir
2021-12-06 14:58:43,880 [main] INFO [org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter] - File Output Committer Algorithm version is 1
2021-12-06 14:58:44,273 [main] INFO [org.apache.spark.SparkContext] - Starting job: runJob at SparkHadoopWriter.scala:78
2021-12-06 14:58:44,273 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 20 (runJob at SparkHadoopWriter.scala:78) with 1 output partitions
2021-12-06 14:58:44,273 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 52 (runJob at SparkHadoopWriter.scala:78)
2021-12-06 14:58:44,273 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List()
2021-12-06 14:58:44,274 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2021-12-06 14:58:44,274 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 52 (MapPartitionsRDD[66] at saveAsTextFile at PaidPromotionAdjustParameter.scala:179), which has no missing parents
2021-12-06 14:58:44,285 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_37 stored as values in memory (estimated size 261.4 KB, free 1989.9 MB)
2021-12-06 14:58:44,288 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_37_piece0 stored as bytes in memory (estimated size 94.5 KB, free 1989.9 MB)
2021-12-06 14:58:44,288 [dispatcher-event-loop-1] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_37_piece0 in memory on qb:60678 (size: 94.5 KB, free: 1990.6 MB)
2021-12-06 14:58:44,288 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 37 from broadcast at DAGScheduler.scala:1039
2021-12-06 14:58:44,289 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 52 (MapPartitionsRDD[66] at saveAsTextFile at PaidPromotionAdjustParameter.scala:179) (first 15 tasks are for partitions Vector(0))
2021-12-06 14:58:44,289 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 52.0 with 1 tasks
2021-12-06 14:58:44,292 [dispatcher-event-loop-7] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 52.0 (TID 90, localhost, executor driver, partition 0, ANY, 8509 bytes)
2021-12-06 14:58:44,292 [Executor task launch worker for task 90] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 52.0 (TID 90)
2021-12-06 14:58:44,307 [Executor task launch worker for task 90] INFO [org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter] - File Output Committer Algorithm version is 1
2021-12-06 14:58:44,401 [Executor task launch worker for task 90] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/order_data.bcp:0+3442194
2021-12-06 14:58:45,408 [Executor task launch worker for task 90] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/order_data.bcp:3442194+3442195
2021-12-06 14:58:45,956 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 897
2021-12-06 14:58:45,956 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 822
2021-12-06 14:58:45,956 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 782
2021-12-06 14:58:45,956 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 833
2021-12-06 14:58:45,956 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 787
2021-12-06 14:58:45,956 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 820
2021-12-06 14:58:45,956 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 839
2021-12-06 14:58:45,956 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 883
2021-12-06 14:58:45,956 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 786
2021-12-06 14:58:45,956 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 840
2021-12-06 14:58:45,956 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 777
2021-12-06 14:58:45,956 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 784
2021-12-06 14:58:45,956 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 863
2021-12-06 14:58:45,957 [dispatcher-event-loop-5] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_34_piece0 on qb:60678 in memory (size: 2.3 KB, free: 1990.6 MB)
2021-12-06 14:58:45,957 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 790
2021-12-06 14:58:45,957 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 858
2021-12-06 14:58:45,957 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 815
2021-12-06 14:58:45,957 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 876
2021-12-06 14:58:45,957 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 821
2021-12-06 14:58:45,957 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 796
2021-12-06 14:58:45,957 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 808
2021-12-06 14:58:45,957 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 798
2021-12-06 14:58:45,957 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 877
2021-12-06 14:58:45,957 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 779
2021-12-06 14:58:45,957 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 829
2021-12-06 14:58:45,957 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 891
2021-12-06 14:58:45,957 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 837
2021-12-06 14:58:45,957 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 789
2021-12-06 14:58:45,957 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 885
2021-12-06 14:58:45,957 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 781
2021-12-06 14:58:45,957 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 823
2021-12-06 14:58:45,957 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 794
2021-12-06 14:58:45,957 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 856
2021-12-06 14:58:45,957 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 887
2021-12-06 14:58:45,957 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 801
2021-12-06 14:58:45,957 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 780
2021-12-06 14:58:45,957 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 898
2021-12-06 14:58:45,957 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 799
2021-12-06 14:58:45,957 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 865
2021-12-06 14:58:45,957 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 809
2021-12-06 14:58:45,957 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 872
2021-12-06 14:58:45,957 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 873
2021-12-06 14:58:45,957 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 889
2021-12-06 14:58:45,957 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 848
2021-12-06 14:58:45,957 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 834
2021-12-06 14:58:45,957 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 842
2021-12-06 14:58:45,957 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 778
2021-12-06 14:58:45,957 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 854
2021-12-06 14:58:45,957 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 817
2021-12-06 14:58:45,957 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 881
2021-12-06 14:58:45,957 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 855
2021-12-06 14:58:45,957 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 888
2021-12-06 14:58:45,957 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 859
2021-12-06 14:58:45,957 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 875
2021-12-06 14:58:45,957 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 810
2021-12-06 14:58:45,957 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 886
2021-12-06 14:58:45,957 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 812
2021-12-06 14:58:45,957 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 878
2021-12-06 14:58:45,957 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 813
2021-12-06 14:58:45,957 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 850
2021-12-06 14:58:45,957 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 893
2021-12-06 14:58:45,957 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 844
2021-12-06 14:58:45,957 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 835
2021-12-06 14:58:45,957 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 870
2021-12-06 14:58:45,957 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 788
2021-12-06 14:58:45,957 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 818
2021-12-06 14:58:45,957 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 824
2021-12-06 14:58:45,957 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 802
2021-12-06 14:58:45,957 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 830
2021-12-06 14:58:45,957 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 827
2021-12-06 14:58:45,957 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 871
2021-12-06 14:58:45,957 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 776
2021-12-06 14:58:45,957 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 843
2021-12-06 14:58:45,957 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 804
2021-12-06 14:58:45,957 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 867
2021-12-06 14:58:45,957 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 793
2021-12-06 14:58:45,958 [dispatcher-event-loop-0] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_32_piece0 on qb:60678 in memory (size: 66.0 KB, free: 1990.7 MB)
2021-12-06 14:58:45,958 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 825
2021-12-06 14:58:45,958 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 785
2021-12-06 14:58:45,958 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 819
2021-12-06 14:58:45,958 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 797
2021-12-06 14:58:45,958 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 775
2021-12-06 14:58:45,958 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 806
2021-12-06 14:58:45,958 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 880
2021-12-06 14:58:45,958 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 846
2021-12-06 14:58:45,958 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 864
2021-12-06 14:58:45,958 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 896
2021-12-06 14:58:45,958 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 811
2021-12-06 14:58:45,959 [dispatcher-event-loop-4] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_36_piece0 on qb:60678 in memory (size: 2.1 KB, free: 1990.7 MB)
2021-12-06 14:58:45,959 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 826
2021-12-06 14:58:45,959 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 807
2021-12-06 14:58:45,959 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 874
2021-12-06 14:58:45,959 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 832
2021-12-06 14:58:45,959 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 792
2021-12-06 14:58:45,959 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 879
2021-12-06 14:58:45,959 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 831
2021-12-06 14:58:45,959 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 894
2021-12-06 14:58:45,959 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 791
2021-12-06 14:58:45,959 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 783
2021-12-06 14:58:45,959 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 851
2021-12-06 14:58:45,959 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 882
2021-12-06 14:58:45,959 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 869
2021-12-06 14:58:45,959 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 847
2021-12-06 14:58:45,959 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 838
2021-12-06 14:58:45,959 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 814
2021-12-06 14:58:45,959 [dispatcher-event-loop-8] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_33_piece0 on qb:60678 in memory (size: 2.2 KB, free: 1990.7 MB)
2021-12-06 14:58:45,960 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 866
2021-12-06 14:58:45,960 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 862
2021-12-06 14:58:45,960 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 860
2021-12-06 14:58:45,960 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 868
2021-12-06 14:58:45,960 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 857
2021-12-06 14:58:45,960 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 805
2021-12-06 14:58:45,960 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 861
2021-12-06 14:58:45,960 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 841
2021-12-06 14:58:45,960 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 852
2021-12-06 14:58:45,960 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 836
2021-12-06 14:58:45,960 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 895
2021-12-06 14:58:45,960 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 890
2021-12-06 14:58:45,960 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 849
2021-12-06 14:58:45,960 [dispatcher-event-loop-5] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_35_piece0 on qb:60678 in memory (size: 2.3 KB, free: 1990.7 MB)
2021-12-06 14:58:45,960 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 884
2021-12-06 14:58:45,960 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 892
2021-12-06 14:58:45,960 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 853
2021-12-06 14:58:45,960 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 845
2021-12-06 14:58:45,960 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 803
2021-12-06 14:58:45,960 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 899
2021-12-06 14:58:45,960 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 795
2021-12-06 14:58:45,960 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 800
2021-12-06 14:58:45,960 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 828
2021-12-06 14:58:45,960 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 816
2021-12-06 14:58:46,338 [Executor task launch worker for task 90] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/order_data.bcp:0+3442194
2021-12-06 14:58:46,992 [Executor task launch worker for task 90] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/order_data.bcp:3442194+3442195
2021-12-06 14:58:50,981 [Executor task launch worker for task 90] INFO [org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter] - Saved output of task 'attempt_20211206145843_0066_m_000000_0' to hdfs://hdp1:8020/sk/chongqing/handle_data/set-train-device-production-data/_temporary/0/task_20211206145843_0066_m_000000
2021-12-06 14:58:50,981 [Executor task launch worker for task 90] INFO [org.apache.spark.mapred.SparkHadoopMapRedUtil] - attempt_20211206145843_0066_m_000000_0: Committed
2021-12-06 14:58:50,983 [Executor task launch worker for task 90] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 52.0 (TID 90). 1041 bytes result sent to driver
2021-12-06 14:58:50,986 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 52.0 (TID 90) in 6697 ms on localhost (executor driver) (1/1)
2021-12-06 14:58:50,986 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 52.0, whose tasks have all completed, from pool 
2021-12-06 14:58:50,987 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 52 (runJob at SparkHadoopWriter.scala:78) finished in 6.712 s
2021-12-06 14:58:50,987 [main] INFO [org.apache.spark.scheduler.DAGScheduler] - Job 20 finished: runJob at SparkHadoopWriter.scala:78, took 6.714529 s
2021-12-06 14:58:51,101 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 913
2021-12-06 14:58:51,101 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 917
2021-12-06 14:58:51,101 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 900
2021-12-06 14:58:51,101 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 908
2021-12-06 14:58:51,101 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 901
2021-12-06 14:58:51,101 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 911
2021-12-06 14:58:51,101 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 921
2021-12-06 14:58:51,101 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 907
2021-12-06 14:58:51,101 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 906
2021-12-06 14:58:51,101 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 904
2021-12-06 14:58:51,101 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 920
2021-12-06 14:58:51,101 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 912
2021-12-06 14:58:51,101 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 910
2021-12-06 14:58:51,101 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 905
2021-12-06 14:58:51,101 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 909
2021-12-06 14:58:51,101 [dispatcher-event-loop-7] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_37_piece0 on qb:60678 in memory (size: 94.5 KB, free: 1990.8 MB)
2021-12-06 14:58:51,102 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 919
2021-12-06 14:58:51,102 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 915
2021-12-06 14:58:51,102 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 918
2021-12-06 14:58:51,102 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 916
2021-12-06 14:58:51,102 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 903
2021-12-06 14:58:51,102 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 923
2021-12-06 14:58:51,102 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 914
2021-12-06 14:58:51,102 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 924
2021-12-06 14:58:51,102 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 922
2021-12-06 14:58:51,102 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 902
2021-12-06 14:58:51,153 [main] INFO [org.apache.spark.internal.io.SparkHadoopWriter] - Job job_20211206145843_0066 committed.
2021-12-06 14:58:51,157 [main] INFO [org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter] - File Output Committer Algorithm version is 1
2021-12-06 14:58:51,182 [main] INFO [org.apache.spark.SparkContext] - Starting job: runJob at SparkHadoopWriter.scala:78
2021-12-06 14:58:51,183 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 21 (runJob at SparkHadoopWriter.scala:78) with 1 output partitions
2021-12-06 14:58:51,183 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 53 (runJob at SparkHadoopWriter.scala:78)
2021-12-06 14:58:51,183 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List()
2021-12-06 14:58:51,183 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2021-12-06 14:58:51,183 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 53 (MapPartitionsRDD[69] at saveAsTextFile at PaidPromotionAdjustParameter.scala:182), which has no missing parents
2021-12-06 14:58:51,196 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_38 stored as values in memory (estimated size 260.8 KB, free 1990.2 MB)
2021-12-06 14:58:51,198 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_38_piece0 stored as bytes in memory (estimated size 94.2 KB, free 1990.1 MB)
2021-12-06 14:58:51,198 [dispatcher-event-loop-1] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_38_piece0 in memory on qb:60678 (size: 94.2 KB, free: 1990.7 MB)
2021-12-06 14:58:51,198 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 38 from broadcast at DAGScheduler.scala:1039
2021-12-06 14:58:51,198 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 53 (MapPartitionsRDD[69] at saveAsTextFile at PaidPromotionAdjustParameter.scala:182) (first 15 tasks are for partitions Vector(0))
2021-12-06 14:58:51,198 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 53.0 with 1 tasks
2021-12-06 14:58:51,199 [dispatcher-event-loop-8] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 53.0 (TID 91, localhost, executor driver, partition 0, ANY, 8337 bytes)
2021-12-06 14:58:51,199 [Executor task launch worker for task 91] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 53.0 (TID 91)
2021-12-06 14:58:51,204 [Executor task launch worker for task 91] INFO [org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter] - File Output Committer Algorithm version is 1
2021-12-06 14:58:51,222 [Executor task launch worker for task 91] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/order_data.bcp:0+3442194
2021-12-06 14:58:52,094 [Executor task launch worker for task 91] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/order_data.bcp:3442194+3442195
2021-12-06 14:58:53,728 [Executor task launch worker for task 91] INFO [org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter] - Saved output of task 'attempt_20211206145851_0069_m_000000_0' to hdfs://hdp1:8020/sk/chongqing/handle_data/set-validation-device-production-data/_temporary/0/task_20211206145851_0069_m_000000
2021-12-06 14:58:53,729 [Executor task launch worker for task 91] INFO [org.apache.spark.mapred.SparkHadoopMapRedUtil] - attempt_20211206145851_0069_m_000000_0: Committed
2021-12-06 14:58:53,730 [Executor task launch worker for task 91] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 53.0 (TID 91). 998 bytes result sent to driver
2021-12-06 14:58:53,731 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 53.0 (TID 91) in 2532 ms on localhost (executor driver) (1/1)
2021-12-06 14:58:53,731 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 53.0, whose tasks have all completed, from pool 
2021-12-06 14:58:53,731 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 53 (runJob at SparkHadoopWriter.scala:78) finished in 2.548 s
2021-12-06 14:58:53,731 [main] INFO [org.apache.spark.scheduler.DAGScheduler] - Job 21 finished: runJob at SparkHadoopWriter.scala:78, took 2.548494 s
2021-12-06 14:58:54,322 [main] INFO [org.apache.spark.internal.io.SparkHadoopWriter] - Job job_20211206145851_0069 committed.
2021-12-06 14:58:54,334 [main] INFO [PaidPromotion$] - -----------------------------------
2021-12-06 14:58:54,335 [main] INFO [org.apache.spark.SparkContext] - Starting job: count at PaidPromotionAdjustParameter.scala:192
2021-12-06 14:58:54,335 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 33 (filter at PaidPromotionAdjustParameter.scala:150)
2021-12-06 14:58:54,335 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 22 (count at PaidPromotionAdjustParameter.scala:192) with 2 output partitions
2021-12-06 14:58:54,335 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 55 (count at PaidPromotionAdjustParameter.scala:192)
2021-12-06 14:58:54,335 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 54)
2021-12-06 14:58:54,335 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List(ShuffleMapStage 54)
2021-12-06 14:58:54,336 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ShuffleMapStage 54 (MapPartitionsRDD[33] at filter at PaidPromotionAdjustParameter.scala:150), which has no missing parents
2021-12-06 14:58:54,337 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_39 stored as values in memory (estimated size 186.2 KB, free 1989.9 MB)
2021-12-06 14:58:54,339 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_39_piece0 stored as bytes in memory (estimated size 66.1 KB, free 1989.9 MB)
2021-12-06 14:58:54,339 [dispatcher-event-loop-11] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_39_piece0 in memory on qb:60678 (size: 66.1 KB, free: 1990.6 MB)
2021-12-06 14:58:54,339 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 39 from broadcast at DAGScheduler.scala:1039
2021-12-06 14:58:54,339 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from ShuffleMapStage 54 (MapPartitionsRDD[33] at filter at PaidPromotionAdjustParameter.scala:150) (first 15 tasks are for partitions Vector(0, 1))
2021-12-06 14:58:54,339 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 54.0 with 2 tasks
2021-12-06 14:58:54,340 [dispatcher-event-loop-10] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 54.0 (TID 92, localhost, executor driver, partition 0, ANY, 7885 bytes)
2021-12-06 14:58:54,340 [dispatcher-event-loop-10] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 54.0 (TID 93, localhost, executor driver, partition 1, ANY, 7885 bytes)
2021-12-06 14:58:54,340 [Executor task launch worker for task 92] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 54.0 (TID 92)
2021-12-06 14:58:54,340 [Executor task launch worker for task 93] INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 54.0 (TID 93)
2021-12-06 14:58:54,342 [Executor task launch worker for task 92] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/order_data.bcp:0+3442194
2021-12-06 14:58:54,342 [Executor task launch worker for task 93] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/order_data.bcp:3442194+3442195
2021-12-06 14:58:55,146 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 949
2021-12-06 14:58:55,146 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 938
2021-12-06 14:58:55,146 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 928
2021-12-06 14:58:55,147 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 936
2021-12-06 14:58:55,147 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 937
2021-12-06 14:58:55,147 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 946
2021-12-06 14:58:55,147 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 929
2021-12-06 14:58:55,148 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 927
2021-12-06 14:58:55,148 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 939
2021-12-06 14:58:55,148 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 945
2021-12-06 14:58:55,148 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 926
2021-12-06 14:58:55,148 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 942
2021-12-06 14:58:55,148 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 933
2021-12-06 14:58:55,148 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 944
2021-12-06 14:58:55,149 [dispatcher-event-loop-7] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_38_piece0 on qb:60678 in memory (size: 94.2 KB, free: 1990.7 MB)
2021-12-06 14:58:55,149 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 932
2021-12-06 14:58:55,149 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 948
2021-12-06 14:58:55,149 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 934
2021-12-06 14:58:55,149 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 930
2021-12-06 14:58:55,149 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 940
2021-12-06 14:58:55,149 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 947
2021-12-06 14:58:55,149 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 935
2021-12-06 14:58:55,149 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 943
2021-12-06 14:58:55,149 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 941
2021-12-06 14:58:55,149 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 925
2021-12-06 14:58:55,149 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 931
2021-12-06 14:58:55,306 [Executor task launch worker for task 93] INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 54.0 (TID 93). 946 bytes result sent to driver
2021-12-06 14:58:55,306 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 54.0 (TID 93) in 966 ms on localhost (executor driver) (1/2)
2021-12-06 14:58:55,350 [Executor task launch worker for task 92] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 54.0 (TID 92). 946 bytes result sent to driver
2021-12-06 14:58:55,350 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 54.0 (TID 92) in 1010 ms on localhost (executor driver) (2/2)
2021-12-06 14:58:55,350 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 54.0, whose tasks have all completed, from pool 
2021-12-06 14:58:55,350 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ShuffleMapStage 54 (filter at PaidPromotionAdjustParameter.scala:150) finished in 1.014 s
2021-12-06 14:58:55,350 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - looking for newly runnable stages
2021-12-06 14:58:55,350 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - running: Set()
2021-12-06 14:58:55,350 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - waiting: Set(ResultStage 55)
2021-12-06 14:58:55,350 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - failed: Set()
2021-12-06 14:58:55,350 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 55 (MapPartitionsRDD[71] at map at PaidPromotionAdjustParameter.scala:186), which has no missing parents
2021-12-06 14:58:55,353 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_40 stored as values in memory (estimated size 187.1 KB, free 1990.0 MB)
2021-12-06 14:58:55,355 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_40_piece0 stored as bytes in memory (estimated size 66.5 KB, free 1990.0 MB)
2021-12-06 14:58:55,355 [dispatcher-event-loop-3] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_40_piece0 in memory on qb:60678 (size: 66.5 KB, free: 1990.6 MB)
2021-12-06 14:58:55,355 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 40 from broadcast at DAGScheduler.scala:1039
2021-12-06 14:58:55,355 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from ResultStage 55 (MapPartitionsRDD[71] at map at PaidPromotionAdjustParameter.scala:186) (first 15 tasks are for partitions Vector(0, 1))
2021-12-06 14:58:55,355 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 55.0 with 2 tasks
2021-12-06 14:58:55,356 [dispatcher-event-loop-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 55.0 (TID 94, localhost, executor driver, partition 0, ANY, 7649 bytes)
2021-12-06 14:58:55,356 [dispatcher-event-loop-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 55.0 (TID 95, localhost, executor driver, partition 1, ANY, 7649 bytes)
2021-12-06 14:58:55,356 [Executor task launch worker for task 94] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 55.0 (TID 94)
2021-12-06 14:58:55,356 [Executor task launch worker for task 95] INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 55.0 (TID 95)
2021-12-06 14:58:55,358 [Executor task launch worker for task 95] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 2 non-empty blocks out of 2 blocks
2021-12-06 14:58:55,358 [Executor task launch worker for task 95] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-06 14:58:55,358 [Executor task launch worker for task 94] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 2 non-empty blocks out of 2 blocks
2021-12-06 14:58:55,358 [Executor task launch worker for task 94] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-06 14:58:55,393 [Executor task launch worker for task 95] INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 55.0 (TID 95). 1097 bytes result sent to driver
2021-12-06 14:58:55,393 [Executor task launch worker for task 94] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 55.0 (TID 94). 1097 bytes result sent to driver
2021-12-06 14:58:55,394 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 55.0 (TID 95) in 38 ms on localhost (executor driver) (1/2)
2021-12-06 14:58:55,394 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 55.0 (TID 94) in 38 ms on localhost (executor driver) (2/2)
2021-12-06 14:58:55,394 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 55.0, whose tasks have all completed, from pool 
2021-12-06 14:58:55,394 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 55 (count at PaidPromotionAdjustParameter.scala:192) finished in 0.043 s
2021-12-06 14:58:55,394 [main] INFO [org.apache.spark.scheduler.DAGScheduler] - Job 22 finished: count at PaidPromotionAdjustParameter.scala:192, took 1.059268 s
2021-12-06 14:58:55,394 [main] INFO [PaidPromotion$] - 5174
2021-12-06 14:58:55,402 [main] INFO [org.apache.spark.SparkContext] - Starting job: take at PaidPromotionAdjustParameter.scala:193
2021-12-06 14:58:55,402 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 23 (take at PaidPromotionAdjustParameter.scala:193) with 1 output partitions
2021-12-06 14:58:55,402 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 57 (take at PaidPromotionAdjustParameter.scala:193)
2021-12-06 14:58:55,402 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 56)
2021-12-06 14:58:55,402 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2021-12-06 14:58:55,402 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 57 (MapPartitionsRDD[71] at map at PaidPromotionAdjustParameter.scala:186), which has no missing parents
2021-12-06 14:58:55,404 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_41 stored as values in memory (estimated size 187.3 KB, free 1989.8 MB)
2021-12-06 14:58:55,406 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_41_piece0 stored as bytes in memory (estimated size 66.6 KB, free 1989.7 MB)
2021-12-06 14:58:55,406 [dispatcher-event-loop-6] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_41_piece0 in memory on qb:60678 (size: 66.6 KB, free: 1990.6 MB)
2021-12-06 14:58:55,406 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 41 from broadcast at DAGScheduler.scala:1039
2021-12-06 14:58:55,407 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 57 (MapPartitionsRDD[71] at map at PaidPromotionAdjustParameter.scala:186) (first 15 tasks are for partitions Vector(0))
2021-12-06 14:58:55,407 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 57.0 with 1 tasks
2021-12-06 14:58:55,408 [dispatcher-event-loop-9] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 57.0 (TID 96, localhost, executor driver, partition 0, ANY, 7649 bytes)
2021-12-06 14:58:55,408 [Executor task launch worker for task 96] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 57.0 (TID 96)
2021-12-06 14:58:55,410 [Executor task launch worker for task 96] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 2 non-empty blocks out of 2 blocks
2021-12-06 14:58:55,410 [Executor task launch worker for task 96] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-06 14:58:55,427 [Executor task launch worker for task 96] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 57.0 (TID 96). 2441 bytes result sent to driver
2021-12-06 14:58:55,428 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 57.0 (TID 96) in 21 ms on localhost (executor driver) (1/1)
2021-12-06 14:58:55,428 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 57.0, whose tasks have all completed, from pool 
2021-12-06 14:58:55,428 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 57 (take at PaidPromotionAdjustParameter.scala:193) finished in 0.025 s
2021-12-06 14:58:55,428 [main] INFO [org.apache.spark.scheduler.DAGScheduler] - Job 23 finished: take at PaidPromotionAdjustParameter.scala:193, took 0.025962 s
2021-12-06 14:58:55,439 [main] INFO [PaidPromotion$] - -----------------------------------
2021-12-06 14:58:55,440 [main] INFO [org.apache.spark.SparkContext] - Starting job: count at PaidPromotionAdjustParameter.scala:204
2021-12-06 14:58:55,441 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 72 (map at PaidPromotionAdjustParameter.scala:196)
2021-12-06 14:58:55,441 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 24 (count at PaidPromotionAdjustParameter.scala:204) with 2 output partitions
2021-12-06 14:58:55,441 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 59 (count at PaidPromotionAdjustParameter.scala:204)
2021-12-06 14:58:55,441 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 58)
2021-12-06 14:58:55,441 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List(ShuffleMapStage 58)
2021-12-06 14:58:55,441 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ShuffleMapStage 58 (MapPartitionsRDD[72] at map at PaidPromotionAdjustParameter.scala:196), which has no missing parents
2021-12-06 14:58:55,442 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_42 stored as values in memory (estimated size 186.4 KB, free 1989.5 MB)
2021-12-06 14:58:55,444 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_42_piece0 stored as bytes in memory (estimated size 66.2 KB, free 1989.5 MB)
2021-12-06 14:58:55,444 [dispatcher-event-loop-1] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_42_piece0 in memory on qb:60678 (size: 66.2 KB, free: 1990.5 MB)
2021-12-06 14:58:55,445 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 42 from broadcast at DAGScheduler.scala:1039
2021-12-06 14:58:55,445 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from ShuffleMapStage 58 (MapPartitionsRDD[72] at map at PaidPromotionAdjustParameter.scala:196) (first 15 tasks are for partitions Vector(0, 1))
2021-12-06 14:58:55,445 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 58.0 with 2 tasks
2021-12-06 14:58:55,445 [dispatcher-event-loop-8] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 58.0 (TID 97, localhost, executor driver, partition 0, ANY, 7885 bytes)
2021-12-06 14:58:55,445 [dispatcher-event-loop-8] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 58.0 (TID 98, localhost, executor driver, partition 1, ANY, 7885 bytes)
2021-12-06 14:58:55,445 [Executor task launch worker for task 97] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 58.0 (TID 97)
2021-12-06 14:58:55,445 [Executor task launch worker for task 98] INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 58.0 (TID 98)
2021-12-06 14:58:55,447 [Executor task launch worker for task 97] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/order_data.bcp:0+3442194
2021-12-06 14:58:55,447 [Executor task launch worker for task 98] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/order_data.bcp:3442194+3442195
2021-12-06 14:58:56,439 [Executor task launch worker for task 98] INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 58.0 (TID 98). 860 bytes result sent to driver
2021-12-06 14:58:56,439 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 58.0 (TID 98) in 994 ms on localhost (executor driver) (1/2)
2021-12-06 14:58:56,672 [Executor task launch worker for task 97] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 58.0 (TID 97). 860 bytes result sent to driver
2021-12-06 14:58:56,672 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 58.0 (TID 97) in 1227 ms on localhost (executor driver) (2/2)
2021-12-06 14:58:56,672 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 58.0, whose tasks have all completed, from pool 
2021-12-06 14:58:56,673 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ShuffleMapStage 58 (map at PaidPromotionAdjustParameter.scala:196) finished in 1.231 s
2021-12-06 14:58:56,673 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - looking for newly runnable stages
2021-12-06 14:58:56,673 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - running: Set()
2021-12-06 14:58:56,673 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - waiting: Set(ResultStage 59)
2021-12-06 14:58:56,673 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - failed: Set()
2021-12-06 14:58:56,673 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 59 (MapPartitionsRDD[74] at map at PaidPromotionAdjustParameter.scala:198), which has no missing parents
2021-12-06 14:58:56,674 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_43 stored as values in memory (estimated size 187.2 KB, free 1989.3 MB)
2021-12-06 14:58:56,676 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_43_piece0 stored as bytes in memory (estimated size 66.5 KB, free 1989.2 MB)
2021-12-06 14:58:56,676 [dispatcher-event-loop-0] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_43_piece0 in memory on qb:60678 (size: 66.5 KB, free: 1990.4 MB)
2021-12-06 14:58:56,676 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 43 from broadcast at DAGScheduler.scala:1039
2021-12-06 14:58:56,677 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from ResultStage 59 (MapPartitionsRDD[74] at map at PaidPromotionAdjustParameter.scala:198) (first 15 tasks are for partitions Vector(0, 1))
2021-12-06 14:58:56,677 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 59.0 with 2 tasks
2021-12-06 14:58:56,677 [dispatcher-event-loop-10] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 59.0 (TID 99, localhost, executor driver, partition 0, ANY, 7649 bytes)
2021-12-06 14:58:56,677 [dispatcher-event-loop-10] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 59.0 (TID 100, localhost, executor driver, partition 1, ANY, 7649 bytes)
2021-12-06 14:58:56,677 [Executor task launch worker for task 99] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 59.0 (TID 99)
2021-12-06 14:58:56,677 [Executor task launch worker for task 100] INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 59.0 (TID 100)
2021-12-06 14:58:56,679 [Executor task launch worker for task 100] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 2 non-empty blocks out of 2 blocks
2021-12-06 14:58:56,679 [Executor task launch worker for task 100] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-06 14:58:56,679 [Executor task launch worker for task 99] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 2 non-empty blocks out of 2 blocks
2021-12-06 14:58:56,679 [Executor task launch worker for task 99] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-06 14:58:56,699 [Executor task launch worker for task 99] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 59.0 (TID 99). 1010 bytes result sent to driver
2021-12-06 14:58:56,699 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 59.0 (TID 99) in 22 ms on localhost (executor driver) (1/2)
2021-12-06 14:58:56,701 [Executor task launch worker for task 100] INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 59.0 (TID 100). 1053 bytes result sent to driver
2021-12-06 14:58:56,702 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 59.0 (TID 100) in 25 ms on localhost (executor driver) (2/2)
2021-12-06 14:58:56,702 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 59.0, whose tasks have all completed, from pool 
2021-12-06 14:58:56,702 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 59 (count at PaidPromotionAdjustParameter.scala:204) finished in 0.029 s
2021-12-06 14:58:56,702 [main] INFO [org.apache.spark.scheduler.DAGScheduler] - Job 24 finished: count at PaidPromotionAdjustParameter.scala:204, took 1.261757 s
2021-12-06 14:58:56,702 [main] INFO [PaidPromotion$] - 80
2021-12-06 14:58:56,709 [main] INFO [org.apache.spark.SparkContext] - Starting job: take at PaidPromotionAdjustParameter.scala:205
2021-12-06 14:58:56,709 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 25 (take at PaidPromotionAdjustParameter.scala:205) with 1 output partitions
2021-12-06 14:58:56,709 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 61 (take at PaidPromotionAdjustParameter.scala:205)
2021-12-06 14:58:56,709 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 60)
2021-12-06 14:58:56,709 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2021-12-06 14:58:56,709 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 61 (MapPartitionsRDD[74] at map at PaidPromotionAdjustParameter.scala:198), which has no missing parents
2021-12-06 14:58:56,710 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_44 stored as values in memory (estimated size 187.4 KB, free 1989.0 MB)
2021-12-06 14:58:56,712 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_44_piece0 stored as bytes in memory (estimated size 66.6 KB, free 1989.0 MB)
2021-12-06 14:58:56,712 [dispatcher-event-loop-1] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_44_piece0 in memory on qb:60678 (size: 66.6 KB, free: 1990.4 MB)
2021-12-06 14:58:56,713 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 44 from broadcast at DAGScheduler.scala:1039
2021-12-06 14:58:56,713 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 61 (MapPartitionsRDD[74] at map at PaidPromotionAdjustParameter.scala:198) (first 15 tasks are for partitions Vector(0))
2021-12-06 14:58:56,713 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 61.0 with 1 tasks
2021-12-06 14:58:56,713 [dispatcher-event-loop-8] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 61.0 (TID 101, localhost, executor driver, partition 0, ANY, 7649 bytes)
2021-12-06 14:58:56,713 [Executor task launch worker for task 101] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 61.0 (TID 101)
2021-12-06 14:58:56,715 [Executor task launch worker for task 101] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 2 non-empty blocks out of 2 blocks
2021-12-06 14:58:56,715 [Executor task launch worker for task 101] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-06 14:58:56,725 [Executor task launch worker for task 101] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 61.0 (TID 101). 41315 bytes result sent to driver
2021-12-06 14:58:56,725 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 61.0 (TID 101) in 12 ms on localhost (executor driver) (1/1)
2021-12-06 14:58:56,725 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 61.0, whose tasks have all completed, from pool 
2021-12-06 14:58:56,726 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 61 (take at PaidPromotionAdjustParameter.scala:205) finished in 0.017 s
2021-12-06 14:58:56,726 [main] INFO [org.apache.spark.scheduler.DAGScheduler] - Job 25 finished: take at PaidPromotionAdjustParameter.scala:205, took 0.017050 s
2021-12-06 14:58:56,734 [main] INFO [PaidPromotion$] - -----------------------------------
2021-12-06 14:58:56,735 [main] INFO [org.apache.spark.SparkContext] - Starting job: count at PaidPromotionAdjustParameter.scala:215
2021-12-06 14:58:56,735 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 35 (union at PaidPromotionAdjustParameter.scala:154)
2021-12-06 14:58:56,735 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 26 (count at PaidPromotionAdjustParameter.scala:215) with 4 output partitions
2021-12-06 14:58:56,735 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 63 (count at PaidPromotionAdjustParameter.scala:215)
2021-12-06 14:58:56,735 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 62)
2021-12-06 14:58:56,736 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List(ShuffleMapStage 62)
2021-12-06 14:58:56,736 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ShuffleMapStage 62 (UnionRDD[35] at union at PaidPromotionAdjustParameter.scala:154), which has no missing parents
2021-12-06 14:58:56,737 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_45 stored as values in memory (estimated size 186.8 KB, free 1988.8 MB)
2021-12-06 14:58:56,741 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 954
2021-12-06 14:58:56,741 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1056
2021-12-06 14:58:56,741 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1013
2021-12-06 14:58:56,741 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1017
2021-12-06 14:58:56,741 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 958
2021-12-06 14:58:56,741 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 989
2021-12-06 14:58:56,741 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1090
2021-12-06 14:58:56,741 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1002
2021-12-06 14:58:56,741 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1074
2021-12-06 14:58:56,741 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 965
2021-12-06 14:58:56,741 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1083
2021-12-06 14:58:56,741 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1010
2021-12-06 14:58:56,741 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1015
2021-12-06 14:58:56,741 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1085
2021-12-06 14:58:56,741 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 979
2021-12-06 14:58:56,741 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1081
2021-12-06 14:58:56,741 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1084
2021-12-06 14:58:56,741 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1093
2021-12-06 14:58:56,741 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 959
2021-12-06 14:58:56,741 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 962
2021-12-06 14:58:56,741 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 995
2021-12-06 14:58:56,741 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1011
2021-12-06 14:58:56,741 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 990
2021-12-06 14:58:56,741 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_45_piece0 stored as bytes in memory (estimated size 66.5 KB, free 1988.8 MB)
2021-12-06 14:58:56,741 [dispatcher-event-loop-0] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_41_piece0 on qb:60678 in memory (size: 66.6 KB, free: 1990.4 MB)
2021-12-06 14:58:56,741 [dispatcher-event-loop-0] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_45_piece0 in memory on qb:60678 (size: 66.5 KB, free: 1990.4 MB)
2021-12-06 14:58:56,742 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 45 from broadcast at DAGScheduler.scala:1039
2021-12-06 14:58:56,742 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1087
2021-12-06 14:58:56,742 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1051
2021-12-06 14:58:56,742 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1052
2021-12-06 14:58:56,742 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1079
2021-12-06 14:58:56,742 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 994
2021-12-06 14:58:56,742 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 952
2021-12-06 14:58:56,742 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1040
2021-12-06 14:58:56,742 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1026
2021-12-06 14:58:56,742 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1016
2021-12-06 14:58:56,742 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 950
2021-12-06 14:58:56,742 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1096
2021-12-06 14:58:56,742 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1020
2021-12-06 14:58:56,742 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1045
2021-12-06 14:58:56,742 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1048
2021-12-06 14:58:56,742 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1041
2021-12-06 14:58:56,742 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1027
2021-12-06 14:58:56,742 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 974
2021-12-06 14:58:56,742 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 4 missing tasks from ShuffleMapStage 62 (UnionRDD[35] at union at PaidPromotionAdjustParameter.scala:154) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
2021-12-06 14:58:56,742 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1066
2021-12-06 14:58:56,742 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 62.0 with 4 tasks
2021-12-06 14:58:56,742 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 972
2021-12-06 14:58:56,742 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 982
2021-12-06 14:58:56,742 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1008
2021-12-06 14:58:56,742 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 961
2021-12-06 14:58:56,742 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1038
2021-12-06 14:58:56,742 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 955
2021-12-06 14:58:56,742 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1049
2021-12-06 14:58:56,742 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1068
2021-12-06 14:58:56,742 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1089
2021-12-06 14:58:56,742 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1071
2021-12-06 14:58:56,742 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1076
2021-12-06 14:58:56,742 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1073
2021-12-06 14:58:56,742 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1021
2021-12-06 14:58:56,742 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 976
2021-12-06 14:58:56,742 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1009
2021-12-06 14:58:56,742 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 988
2021-12-06 14:58:56,742 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1065
2021-12-06 14:58:56,742 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 980
2021-12-06 14:58:56,742 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1080
2021-12-06 14:58:56,742 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1000
2021-12-06 14:58:56,742 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1007
2021-12-06 14:58:56,742 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1028
2021-12-06 14:58:56,742 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 985
2021-12-06 14:58:56,742 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1095
2021-12-06 14:58:56,742 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1082
2021-12-06 14:58:56,742 [dispatcher-event-loop-7] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_40_piece0 on qb:60678 in memory (size: 66.5 KB, free: 1990.4 MB)
2021-12-06 14:58:56,742 [dispatcher-event-loop-4] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 62.0 (TID 102, localhost, executor driver, partition 0, ANY, 7994 bytes)
2021-12-06 14:58:56,742 [dispatcher-event-loop-4] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 62.0 (TID 103, localhost, executor driver, partition 1, ANY, 7994 bytes)
2021-12-06 14:58:56,743 [dispatcher-event-loop-4] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 2.0 in stage 62.0 (TID 104, localhost, executor driver, partition 2, ANY, 7994 bytes)
2021-12-06 14:58:56,743 [dispatcher-event-loop-4] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 3.0 in stage 62.0 (TID 105, localhost, executor driver, partition 3, ANY, 7994 bytes)
2021-12-06 14:58:56,743 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1035
2021-12-06 14:58:56,743 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1053
2021-12-06 14:58:56,743 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1030
2021-12-06 14:58:56,743 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 957
2021-12-06 14:58:56,743 [Executor task launch worker for task 102] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 62.0 (TID 102)
2021-12-06 14:58:56,743 [Executor task launch worker for task 103] INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 62.0 (TID 103)
2021-12-06 14:58:56,743 [Executor task launch worker for task 104] INFO [org.apache.spark.executor.Executor] - Running task 2.0 in stage 62.0 (TID 104)
2021-12-06 14:58:56,743 [Executor task launch worker for task 105] INFO [org.apache.spark.executor.Executor] - Running task 3.0 in stage 62.0 (TID 105)
2021-12-06 14:58:56,743 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1044
2021-12-06 14:58:56,743 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 996
2021-12-06 14:58:56,743 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 971
2021-12-06 14:58:56,743 [dispatcher-event-loop-10] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_44_piece0 on qb:60678 in memory (size: 66.6 KB, free: 1990.5 MB)
2021-12-06 14:58:56,744 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 973
2021-12-06 14:58:56,744 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1018
2021-12-06 14:58:56,744 [dispatcher-event-loop-6] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_43_piece0 on qb:60678 in memory (size: 66.5 KB, free: 1990.6 MB)
2021-12-06 14:58:56,744 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1014
2021-12-06 14:58:56,744 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1001
2021-12-06 14:58:56,744 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 963
2021-12-06 14:58:56,744 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 951
2021-12-06 14:58:56,744 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1062
2021-12-06 14:58:56,744 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1004
2021-12-06 14:58:56,744 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 956
2021-12-06 14:58:56,744 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1097
2021-12-06 14:58:56,744 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 998
2021-12-06 14:58:56,744 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1086
2021-12-06 14:58:56,744 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1050
2021-12-06 14:58:56,744 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1034
2021-12-06 14:58:56,744 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1064
2021-12-06 14:58:56,744 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1060
2021-12-06 14:58:56,744 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1023
2021-12-06 14:58:56,744 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 978
2021-12-06 14:58:56,744 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1098
2021-12-06 14:58:56,744 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 968
2021-12-06 14:58:56,744 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 960
2021-12-06 14:58:56,744 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1022
2021-12-06 14:58:56,744 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 999
2021-12-06 14:58:56,744 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 975
2021-12-06 14:58:56,744 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1070
2021-12-06 14:58:56,744 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 984
2021-12-06 14:58:56,744 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 970
2021-12-06 14:58:56,744 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1005
2021-12-06 14:58:56,745 [Executor task launch worker for task 102] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/order_data.bcp:0+3442194
2021-12-06 14:58:56,745 [Executor task launch worker for task 105] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/order_data.bcp:3442194+3442195
2021-12-06 14:58:56,745 [Executor task launch worker for task 104] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/order_data.bcp:0+3442194
2021-12-06 14:58:56,745 [dispatcher-event-loop-1] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_42_piece0 on qb:60678 in memory (size: 66.2 KB, free: 1990.6 MB)
2021-12-06 14:58:56,745 [Executor task launch worker for task 103] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/order_data.bcp:3442194+3442195
2021-12-06 14:58:56,745 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 967
2021-12-06 14:58:56,745 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 992
2021-12-06 14:58:56,745 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1003
2021-12-06 14:58:56,745 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1057
2021-12-06 14:58:56,745 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 991
2021-12-06 14:58:56,745 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 997
2021-12-06 14:58:56,745 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 966
2021-12-06 14:58:56,745 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1055
2021-12-06 14:58:56,745 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1058
2021-12-06 14:58:56,745 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1033
2021-12-06 14:58:56,745 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 964
2021-12-06 14:58:56,745 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1094
2021-12-06 14:58:56,745 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1067
2021-12-06 14:58:56,745 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1054
2021-12-06 14:58:56,745 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1069
2021-12-06 14:58:56,745 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1042
2021-12-06 14:58:56,745 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1072
2021-12-06 14:58:56,745 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1046
2021-12-06 14:58:56,745 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1037
2021-12-06 14:58:56,745 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1063
2021-12-06 14:58:56,745 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1091
2021-12-06 14:58:56,745 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 981
2021-12-06 14:58:56,745 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1078
2021-12-06 14:58:56,745 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1024
2021-12-06 14:58:56,745 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1039
2021-12-06 14:58:56,745 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1059
2021-12-06 14:58:56,745 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1043
2021-12-06 14:58:56,746 [dispatcher-event-loop-2] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_39_piece0 on qb:60678 in memory (size: 66.1 KB, free: 1990.7 MB)
2021-12-06 14:58:56,746 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 953
2021-12-06 14:58:56,746 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 986
2021-12-06 14:58:56,746 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1031
2021-12-06 14:58:56,746 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 983
2021-12-06 14:58:56,746 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 993
2021-12-06 14:58:56,746 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1012
2021-12-06 14:58:56,746 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 977
2021-12-06 14:58:56,746 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 987
2021-12-06 14:58:56,746 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1019
2021-12-06 14:58:56,746 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1047
2021-12-06 14:58:56,746 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1075
2021-12-06 14:58:56,746 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1092
2021-12-06 14:58:56,746 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1025
2021-12-06 14:58:56,746 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1036
2021-12-06 14:58:56,746 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1029
2021-12-06 14:58:56,746 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1077
2021-12-06 14:58:56,746 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 969
2021-12-06 14:58:56,746 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1088
2021-12-06 14:58:56,746 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1099
2021-12-06 14:58:56,746 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1006
2021-12-06 14:58:56,746 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1032
2021-12-06 14:58:56,746 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1061
2021-12-06 14:58:57,799 [Executor task launch worker for task 103] INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 62.0 (TID 103). 862 bytes result sent to driver
2021-12-06 14:58:57,800 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 62.0 (TID 103) in 1058 ms on localhost (executor driver) (1/4)
2021-12-06 14:58:57,807 [Executor task launch worker for task 102] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 62.0 (TID 102). 862 bytes result sent to driver
2021-12-06 14:58:57,807 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 62.0 (TID 102) in 1065 ms on localhost (executor driver) (2/4)
2021-12-06 14:59:01,136 [Executor task launch worker for task 105] INFO [org.apache.spark.executor.Executor] - Finished task 3.0 in stage 62.0 (TID 105). 862 bytes result sent to driver
2021-12-06 14:59:01,137 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 3.0 in stage 62.0 (TID 105) in 4393 ms on localhost (executor driver) (3/4)
2021-12-06 14:59:01,251 [Executor task launch worker for task 104] INFO [org.apache.spark.executor.Executor] - Finished task 2.0 in stage 62.0 (TID 104). 862 bytes result sent to driver
2021-12-06 14:59:01,251 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 2.0 in stage 62.0 (TID 104) in 4508 ms on localhost (executor driver) (4/4)
2021-12-06 14:59:01,251 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 62.0, whose tasks have all completed, from pool 
2021-12-06 14:59:01,251 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ShuffleMapStage 62 (union at PaidPromotionAdjustParameter.scala:154) finished in 4.515 s
2021-12-06 14:59:01,251 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - looking for newly runnable stages
2021-12-06 14:59:01,251 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - running: Set()
2021-12-06 14:59:01,251 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - waiting: Set(ResultStage 63)
2021-12-06 14:59:01,251 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - failed: Set()
2021-12-06 14:59:01,251 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 63 (MapPartitionsRDD[76] at map at PaidPromotionAdjustParameter.scala:209), which has no missing parents
2021-12-06 14:59:01,253 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_46 stored as values in memory (estimated size 187.7 KB, free 1990.0 MB)
2021-12-06 14:59:01,256 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_46_piece0 stored as bytes in memory (estimated size 66.9 KB, free 1990.0 MB)
2021-12-06 14:59:01,256 [dispatcher-event-loop-4] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_46_piece0 in memory on qb:60678 (size: 66.9 KB, free: 1990.6 MB)
2021-12-06 14:59:01,257 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 46 from broadcast at DAGScheduler.scala:1039
2021-12-06 14:59:01,257 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 4 missing tasks from ResultStage 63 (MapPartitionsRDD[76] at map at PaidPromotionAdjustParameter.scala:209) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
2021-12-06 14:59:01,257 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 63.0 with 4 tasks
2021-12-06 14:59:01,257 [dispatcher-event-loop-7] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 63.0 (TID 106, localhost, executor driver, partition 0, ANY, 7649 bytes)
2021-12-06 14:59:01,257 [dispatcher-event-loop-7] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 63.0 (TID 107, localhost, executor driver, partition 1, ANY, 7649 bytes)
2021-12-06 14:59:01,257 [dispatcher-event-loop-7] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 2.0 in stage 63.0 (TID 108, localhost, executor driver, partition 2, ANY, 7649 bytes)
2021-12-06 14:59:01,257 [dispatcher-event-loop-7] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 3.0 in stage 63.0 (TID 109, localhost, executor driver, partition 3, ANY, 7649 bytes)
2021-12-06 14:59:01,257 [Executor task launch worker for task 108] INFO [org.apache.spark.executor.Executor] - Running task 2.0 in stage 63.0 (TID 108)
2021-12-06 14:59:01,257 [Executor task launch worker for task 106] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 63.0 (TID 106)
2021-12-06 14:59:01,257 [Executor task launch worker for task 109] INFO [org.apache.spark.executor.Executor] - Running task 3.0 in stage 63.0 (TID 109)
2021-12-06 14:59:01,257 [Executor task launch worker for task 107] INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 63.0 (TID 107)
2021-12-06 14:59:01,260 [Executor task launch worker for task 106] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 4 non-empty blocks out of 4 blocks
2021-12-06 14:59:01,260 [Executor task launch worker for task 106] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-06 14:59:01,260 [Executor task launch worker for task 108] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 4 non-empty blocks out of 4 blocks
2021-12-06 14:59:01,260 [Executor task launch worker for task 108] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-06 14:59:01,260 [Executor task launch worker for task 107] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 4 non-empty blocks out of 4 blocks
2021-12-06 14:59:01,260 [Executor task launch worker for task 107] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-06 14:59:01,260 [Executor task launch worker for task 109] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 4 non-empty blocks out of 4 blocks
2021-12-06 14:59:01,260 [Executor task launch worker for task 109] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-06 14:59:01,378 [Executor task launch worker for task 106] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 63.0 (TID 106). 1055 bytes result sent to driver
2021-12-06 14:59:01,378 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 63.0 (TID 106) in 121 ms on localhost (executor driver) (1/4)
2021-12-06 14:59:01,378 [Executor task launch worker for task 108] INFO [org.apache.spark.executor.Executor] - Finished task 2.0 in stage 63.0 (TID 108). 1055 bytes result sent to driver
2021-12-06 14:59:01,378 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 2.0 in stage 63.0 (TID 108) in 121 ms on localhost (executor driver) (2/4)
2021-12-06 14:59:01,381 [Executor task launch worker for task 107] INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 63.0 (TID 107). 1055 bytes result sent to driver
2021-12-06 14:59:01,381 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 63.0 (TID 107) in 124 ms on localhost (executor driver) (3/4)
2021-12-06 14:59:01,382 [Executor task launch worker for task 109] INFO [org.apache.spark.executor.Executor] - Finished task 3.0 in stage 63.0 (TID 109). 1055 bytes result sent to driver
2021-12-06 14:59:01,383 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 3.0 in stage 63.0 (TID 109) in 126 ms on localhost (executor driver) (4/4)
2021-12-06 14:59:01,383 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 63.0, whose tasks have all completed, from pool 
2021-12-06 14:59:01,383 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 63 (count at PaidPromotionAdjustParameter.scala:215) finished in 0.131 s
2021-12-06 14:59:01,383 [main] INFO [org.apache.spark.scheduler.DAGScheduler] - Job 26 finished: count at PaidPromotionAdjustParameter.scala:215, took 4.648473 s
2021-12-06 14:59:01,383 [main] INFO [PaidPromotion$] - 95323
2021-12-06 14:59:01,391 [main] INFO [org.apache.spark.SparkContext] - Starting job: take at PaidPromotionAdjustParameter.scala:216
2021-12-06 14:59:01,392 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 27 (take at PaidPromotionAdjustParameter.scala:216) with 1 output partitions
2021-12-06 14:59:01,392 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 65 (take at PaidPromotionAdjustParameter.scala:216)
2021-12-06 14:59:01,392 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 64)
2021-12-06 14:59:01,392 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2021-12-06 14:59:01,392 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 65 (MapPartitionsRDD[76] at map at PaidPromotionAdjustParameter.scala:209), which has no missing parents
2021-12-06 14:59:01,393 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_47 stored as values in memory (estimated size 187.8 KB, free 1989.8 MB)
2021-12-06 14:59:01,396 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1135
2021-12-06 14:59:01,396 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1122
2021-12-06 14:59:01,396 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1124
2021-12-06 14:59:01,396 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1113
2021-12-06 14:59:01,396 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1117
2021-12-06 14:59:01,396 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1115
2021-12-06 14:59:01,396 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1148
2021-12-06 14:59:01,396 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1103
2021-12-06 14:59:01,397 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_47_piece0 stored as bytes in memory (estimated size 66.9 KB, free 1989.8 MB)
2021-12-06 14:59:01,397 [dispatcher-event-loop-4] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_45_piece0 on qb:60678 in memory (size: 66.5 KB, free: 1990.7 MB)
2021-12-06 14:59:01,397 [dispatcher-event-loop-4] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_47_piece0 in memory on qb:60678 (size: 66.9 KB, free: 1990.6 MB)
2021-12-06 14:59:01,397 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1100
2021-12-06 14:59:01,397 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1109
2021-12-06 14:59:01,397 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1104
2021-12-06 14:59:01,397 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 47 from broadcast at DAGScheduler.scala:1039
2021-12-06 14:59:01,398 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1144
2021-12-06 14:59:01,398 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1118
2021-12-06 14:59:01,398 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1112
2021-12-06 14:59:01,398 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1123
2021-12-06 14:59:01,398 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1134
2021-12-06 14:59:01,398 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1140
2021-12-06 14:59:01,398 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1145
2021-12-06 14:59:01,398 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1132
2021-12-06 14:59:01,398 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1126
2021-12-06 14:59:01,398 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1101
2021-12-06 14:59:01,398 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1133
2021-12-06 14:59:01,398 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1128
2021-12-06 14:59:01,398 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1116
2021-12-06 14:59:01,398 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1120
2021-12-06 14:59:01,398 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1102
2021-12-06 14:59:01,398 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1139
2021-12-06 14:59:01,398 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1111
2021-12-06 14:59:01,398 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1121
2021-12-06 14:59:01,398 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1142
2021-12-06 14:59:01,398 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1146
2021-12-06 14:59:01,398 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1108
2021-12-06 14:59:01,398 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1119
2021-12-06 14:59:01,398 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1129
2021-12-06 14:59:01,398 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 65 (MapPartitionsRDD[76] at map at PaidPromotionAdjustParameter.scala:209) (first 15 tasks are for partitions Vector(0))
2021-12-06 14:59:01,398 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1137
2021-12-06 14:59:01,398 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 65.0 with 1 tasks
2021-12-06 14:59:01,398 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1136
2021-12-06 14:59:01,399 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1131
2021-12-06 14:59:01,399 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1110
2021-12-06 14:59:01,399 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1125
2021-12-06 14:59:01,399 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1127
2021-12-06 14:59:01,399 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1106
2021-12-06 14:59:01,399 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1138
2021-12-06 14:59:01,399 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1107
2021-12-06 14:59:01,399 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1141
2021-12-06 14:59:01,399 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1149
2021-12-06 14:59:01,399 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1147
2021-12-06 14:59:01,399 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1114
2021-12-06 14:59:01,399 [dispatcher-event-loop-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 65.0 (TID 110, localhost, executor driver, partition 0, ANY, 7649 bytes)
2021-12-06 14:59:01,399 [Executor task launch worker for task 110] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 65.0 (TID 110)
2021-12-06 14:59:01,399 [dispatcher-event-loop-2] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_46_piece0 on qb:60678 in memory (size: 66.9 KB, free: 1990.7 MB)
2021-12-06 14:59:01,399 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1130
2021-12-06 14:59:01,399 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1143
2021-12-06 14:59:01,399 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1105
2021-12-06 14:59:01,401 [Executor task launch worker for task 110] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 4 non-empty blocks out of 4 blocks
2021-12-06 14:59:01,401 [Executor task launch worker for task 110] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-06 14:59:01,434 [Executor task launch worker for task 110] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 65.0 (TID 110). 2431 bytes result sent to driver
2021-12-06 14:59:01,434 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 65.0 (TID 110) in 35 ms on localhost (executor driver) (1/1)
2021-12-06 14:59:01,434 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 65.0, whose tasks have all completed, from pool 
2021-12-06 14:59:01,434 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 65 (take at PaidPromotionAdjustParameter.scala:216) finished in 0.042 s
2021-12-06 14:59:01,434 [main] INFO [org.apache.spark.scheduler.DAGScheduler] - Job 27 finished: take at PaidPromotionAdjustParameter.scala:216, took 0.042983 s
2021-12-06 14:59:01,443 [main] INFO [PaidPromotion$] - -----------------------------------
2021-12-06 14:59:01,444 [main] INFO [org.apache.spark.SparkContext] - Starting job: count at PaidPromotionAdjustParameter.scala:227
2021-12-06 14:59:01,444 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 77 (map at PaidPromotionAdjustParameter.scala:219)
2021-12-06 14:59:01,444 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 28 (count at PaidPromotionAdjustParameter.scala:227) with 4 output partitions
2021-12-06 14:59:01,444 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 67 (count at PaidPromotionAdjustParameter.scala:227)
2021-12-06 14:59:01,444 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 66)
2021-12-06 14:59:01,444 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List(ShuffleMapStage 66)
2021-12-06 14:59:01,444 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ShuffleMapStage 66 (MapPartitionsRDD[77] at map at PaidPromotionAdjustParameter.scala:219), which has no missing parents
2021-12-06 14:59:01,446 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_48 stored as values in memory (estimated size 186.9 KB, free 1990.0 MB)
2021-12-06 14:59:01,447 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_48_piece0 stored as bytes in memory (estimated size 66.6 KB, free 1990.0 MB)
2021-12-06 14:59:01,448 [dispatcher-event-loop-10] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_48_piece0 in memory on qb:60678 (size: 66.6 KB, free: 1990.6 MB)
2021-12-06 14:59:01,448 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 48 from broadcast at DAGScheduler.scala:1039
2021-12-06 14:59:01,448 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 4 missing tasks from ShuffleMapStage 66 (MapPartitionsRDD[77] at map at PaidPromotionAdjustParameter.scala:219) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
2021-12-06 14:59:01,448 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 66.0 with 4 tasks
2021-12-06 14:59:01,448 [dispatcher-event-loop-9] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 66.0 (TID 111, localhost, executor driver, partition 0, ANY, 7994 bytes)
2021-12-06 14:59:01,448 [dispatcher-event-loop-9] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 66.0 (TID 112, localhost, executor driver, partition 1, ANY, 7994 bytes)
2021-12-06 14:59:01,449 [dispatcher-event-loop-9] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 2.0 in stage 66.0 (TID 113, localhost, executor driver, partition 2, ANY, 7994 bytes)
2021-12-06 14:59:01,449 [dispatcher-event-loop-9] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 3.0 in stage 66.0 (TID 114, localhost, executor driver, partition 3, ANY, 7994 bytes)
2021-12-06 14:59:01,449 [Executor task launch worker for task 112] INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 66.0 (TID 112)
2021-12-06 14:59:01,449 [Executor task launch worker for task 113] INFO [org.apache.spark.executor.Executor] - Running task 2.0 in stage 66.0 (TID 113)
2021-12-06 14:59:01,449 [Executor task launch worker for task 114] INFO [org.apache.spark.executor.Executor] - Running task 3.0 in stage 66.0 (TID 114)
2021-12-06 14:59:01,449 [Executor task launch worker for task 111] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 66.0 (TID 111)
2021-12-06 14:59:01,451 [Executor task launch worker for task 113] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/order_data.bcp:0+3442194
2021-12-06 14:59:01,451 [Executor task launch worker for task 112] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/order_data.bcp:3442194+3442195
2021-12-06 14:59:01,451 [Executor task launch worker for task 114] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/order_data.bcp:3442194+3442195
2021-12-06 14:59:01,451 [Executor task launch worker for task 111] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/order_data.bcp:0+3442194
2021-12-06 14:59:02,465 [Executor task launch worker for task 112] INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 66.0 (TID 112). 905 bytes result sent to driver
2021-12-06 14:59:02,466 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 66.0 (TID 112) in 1018 ms on localhost (executor driver) (1/4)
2021-12-06 14:59:03,951 [Executor task launch worker for task 114] INFO [org.apache.spark.executor.Executor] - Finished task 3.0 in stage 66.0 (TID 114). 862 bytes result sent to driver
2021-12-06 14:59:03,951 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 3.0 in stage 66.0 (TID 114) in 2502 ms on localhost (executor driver) (2/4)
2021-12-06 14:59:06,110 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1169
2021-12-06 14:59:06,110 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1164
2021-12-06 14:59:06,110 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1166
2021-12-06 14:59:06,110 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1155
2021-12-06 14:59:06,110 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1163
2021-12-06 14:59:06,110 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1165
2021-12-06 14:59:06,110 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1160
2021-12-06 14:59:06,110 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1172
2021-12-06 14:59:06,110 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1174
2021-12-06 14:59:06,110 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1168
2021-12-06 14:59:06,110 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1152
2021-12-06 14:59:06,110 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1173
2021-12-06 14:59:06,110 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1153
2021-12-06 14:59:06,110 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1171
2021-12-06 14:59:06,110 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1161
2021-12-06 14:59:06,111 [dispatcher-event-loop-2] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_47_piece0 on qb:60678 in memory (size: 66.9 KB, free: 1990.7 MB)
2021-12-06 14:59:06,111 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1158
2021-12-06 14:59:06,111 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1151
2021-12-06 14:59:06,111 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1162
2021-12-06 14:59:06,111 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1170
2021-12-06 14:59:06,111 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1154
2021-12-06 14:59:06,111 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1167
2021-12-06 14:59:06,111 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1159
2021-12-06 14:59:06,111 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1156
2021-12-06 14:59:06,111 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1150
2021-12-06 14:59:06,111 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1157
2021-12-06 14:59:06,531 [Executor task launch worker for task 113] INFO [org.apache.spark.executor.Executor] - Finished task 2.0 in stage 66.0 (TID 113). 905 bytes result sent to driver
2021-12-06 14:59:06,531 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 2.0 in stage 66.0 (TID 113) in 5083 ms on localhost (executor driver) (3/4)
2021-12-06 14:59:06,531 [Executor task launch worker for task 111] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 66.0 (TID 111). 905 bytes result sent to driver
2021-12-06 14:59:06,532 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 66.0 (TID 111) in 5084 ms on localhost (executor driver) (4/4)
2021-12-06 14:59:06,532 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 66.0, whose tasks have all completed, from pool 
2021-12-06 14:59:06,532 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ShuffleMapStage 66 (map at PaidPromotionAdjustParameter.scala:219) finished in 5.087 s
2021-12-06 14:59:06,532 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - looking for newly runnable stages
2021-12-06 14:59:06,532 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - running: Set()
2021-12-06 14:59:06,532 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - waiting: Set(ResultStage 67)
2021-12-06 14:59:06,532 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - failed: Set()
2021-12-06 14:59:06,532 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 67 (MapPartitionsRDD[79] at map at PaidPromotionAdjustParameter.scala:221), which has no missing parents
2021-12-06 14:59:06,533 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_49 stored as values in memory (estimated size 187.8 KB, free 1990.0 MB)
2021-12-06 14:59:06,535 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_49_piece0 stored as bytes in memory (estimated size 66.9 KB, free 1990.0 MB)
2021-12-06 14:59:06,535 [dispatcher-event-loop-9] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_49_piece0 in memory on qb:60678 (size: 66.9 KB, free: 1990.6 MB)
2021-12-06 14:59:06,535 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 49 from broadcast at DAGScheduler.scala:1039
2021-12-06 14:59:06,535 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 4 missing tasks from ResultStage 67 (MapPartitionsRDD[79] at map at PaidPromotionAdjustParameter.scala:221) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
2021-12-06 14:59:06,535 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 67.0 with 4 tasks
2021-12-06 14:59:06,536 [dispatcher-event-loop-6] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 67.0 (TID 115, localhost, executor driver, partition 0, ANY, 7649 bytes)
2021-12-06 14:59:06,536 [dispatcher-event-loop-6] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 67.0 (TID 116, localhost, executor driver, partition 1, ANY, 7649 bytes)
2021-12-06 14:59:06,536 [dispatcher-event-loop-6] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 2.0 in stage 67.0 (TID 117, localhost, executor driver, partition 2, ANY, 7649 bytes)
2021-12-06 14:59:06,536 [dispatcher-event-loop-6] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 3.0 in stage 67.0 (TID 118, localhost, executor driver, partition 3, ANY, 7649 bytes)
2021-12-06 14:59:06,536 [Executor task launch worker for task 116] INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 67.0 (TID 116)
2021-12-06 14:59:06,536 [Executor task launch worker for task 115] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 67.0 (TID 115)
2021-12-06 14:59:06,536 [Executor task launch worker for task 118] INFO [org.apache.spark.executor.Executor] - Running task 3.0 in stage 67.0 (TID 118)
2021-12-06 14:59:06,536 [Executor task launch worker for task 117] INFO [org.apache.spark.executor.Executor] - Running task 2.0 in stage 67.0 (TID 117)
2021-12-06 14:59:06,538 [Executor task launch worker for task 116] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 4 non-empty blocks out of 4 blocks
2021-12-06 14:59:06,538 [Executor task launch worker for task 117] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 4 non-empty blocks out of 4 blocks
2021-12-06 14:59:06,538 [Executor task launch worker for task 116] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-06 14:59:06,538 [Executor task launch worker for task 117] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-06 14:59:06,538 [Executor task launch worker for task 115] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 4 non-empty blocks out of 4 blocks
2021-12-06 14:59:06,538 [Executor task launch worker for task 118] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 4 non-empty blocks out of 4 blocks
2021-12-06 14:59:06,538 [Executor task launch worker for task 115] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-06 14:59:06,538 [Executor task launch worker for task 118] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-06 14:59:06,571 [Executor task launch worker for task 115] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 67.0 (TID 115). 1010 bytes result sent to driver
2021-12-06 14:59:06,571 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 67.0 (TID 115) in 36 ms on localhost (executor driver) (1/4)
2021-12-06 14:59:06,578 [Executor task launch worker for task 117] INFO [org.apache.spark.executor.Executor] - Finished task 2.0 in stage 67.0 (TID 117). 1053 bytes result sent to driver
2021-12-06 14:59:06,578 [Executor task launch worker for task 116] INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 67.0 (TID 116). 1053 bytes result sent to driver
2021-12-06 14:59:06,579 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 2.0 in stage 67.0 (TID 117) in 43 ms on localhost (executor driver) (2/4)
2021-12-06 14:59:06,579 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 67.0 (TID 116) in 43 ms on localhost (executor driver) (3/4)
2021-12-06 14:59:06,606 [Executor task launch worker for task 118] INFO [org.apache.spark.executor.Executor] - Finished task 3.0 in stage 67.0 (TID 118). 1053 bytes result sent to driver
2021-12-06 14:59:06,607 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 3.0 in stage 67.0 (TID 118) in 70 ms on localhost (executor driver) (4/4)
2021-12-06 14:59:06,607 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 67.0, whose tasks have all completed, from pool 
2021-12-06 14:59:06,607 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 67 (count at PaidPromotionAdjustParameter.scala:227) finished in 0.075 s
2021-12-06 14:59:06,607 [main] INFO [org.apache.spark.scheduler.DAGScheduler] - Job 28 finished: count at PaidPromotionAdjustParameter.scala:227, took 5.163265 s
2021-12-06 14:59:06,607 [main] INFO [PaidPromotion$] - 132
2021-12-06 14:59:06,613 [main] INFO [org.apache.spark.SparkContext] - Starting job: take at PaidPromotionAdjustParameter.scala:228
2021-12-06 14:59:06,613 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 29 (take at PaidPromotionAdjustParameter.scala:228) with 1 output partitions
2021-12-06 14:59:06,613 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 69 (take at PaidPromotionAdjustParameter.scala:228)
2021-12-06 14:59:06,613 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 68)
2021-12-06 14:59:06,613 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2021-12-06 14:59:06,613 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 69 (MapPartitionsRDD[79] at map at PaidPromotionAdjustParameter.scala:221), which has no missing parents
2021-12-06 14:59:06,614 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_50 stored as values in memory (estimated size 188.0 KB, free 1989.8 MB)
2021-12-06 14:59:06,616 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_50_piece0 stored as bytes in memory (estimated size 67.0 KB, free 1989.7 MB)
2021-12-06 14:59:06,616 [dispatcher-event-loop-5] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_50_piece0 in memory on qb:60678 (size: 67.0 KB, free: 1990.6 MB)
2021-12-06 14:59:06,616 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 50 from broadcast at DAGScheduler.scala:1039
2021-12-06 14:59:06,616 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 69 (MapPartitionsRDD[79] at map at PaidPromotionAdjustParameter.scala:221) (first 15 tasks are for partitions Vector(0))
2021-12-06 14:59:06,616 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 69.0 with 1 tasks
2021-12-06 14:59:06,617 [dispatcher-event-loop-10] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 69.0 (TID 119, localhost, executor driver, partition 0, ANY, 7649 bytes)
2021-12-06 14:59:06,617 [Executor task launch worker for task 119] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 69.0 (TID 119)
2021-12-06 14:59:06,619 [Executor task launch worker for task 119] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 4 non-empty blocks out of 4 blocks
2021-12-06 14:59:06,619 [Executor task launch worker for task 119] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-06 14:59:06,629 [Executor task launch worker for task 119] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 69.0 (TID 119). 18192 bytes result sent to driver
2021-12-06 14:59:06,630 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 69.0 (TID 119) in 13 ms on localhost (executor driver) (1/1)
2021-12-06 14:59:06,630 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 69.0, whose tasks have all completed, from pool 
2021-12-06 14:59:06,630 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 69 (take at PaidPromotionAdjustParameter.scala:228) finished in 0.017 s
2021-12-06 14:59:06,630 [main] INFO [org.apache.spark.scheduler.DAGScheduler] - Job 29 finished: take at PaidPromotionAdjustParameter.scala:228, took 0.016952 s
2021-12-06 14:59:06,633 [main] INFO [org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter] - File Output Committer Algorithm version is 1
2021-12-06 14:59:06,777 [main] INFO [org.apache.spark.SparkContext] - Starting job: runJob at SparkHadoopWriter.scala:78
2021-12-06 14:59:06,777 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 30 (runJob at SparkHadoopWriter.scala:78) with 1 output partitions
2021-12-06 14:59:06,777 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 71 (runJob at SparkHadoopWriter.scala:78)
2021-12-06 14:59:06,777 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 70)
2021-12-06 14:59:06,777 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2021-12-06 14:59:06,777 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 71 (MapPartitionsRDD[81] at saveAsTextFile at PaidPromotionAdjustParameter.scala:230), which has no missing parents
2021-12-06 14:59:06,787 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_51 stored as values in memory (estimated size 263.6 KB, free 1989.5 MB)
2021-12-06 14:59:06,788 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_51_piece0 stored as bytes in memory (estimated size 95.3 KB, free 1989.4 MB)
2021-12-06 14:59:06,788 [dispatcher-event-loop-0] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_51_piece0 in memory on qb:60678 (size: 95.3 KB, free: 1990.5 MB)
2021-12-06 14:59:06,789 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 51 from broadcast at DAGScheduler.scala:1039
2021-12-06 14:59:06,789 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 71 (MapPartitionsRDD[81] at saveAsTextFile at PaidPromotionAdjustParameter.scala:230) (first 15 tasks are for partitions Vector(0))
2021-12-06 14:59:06,789 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 71.0 with 1 tasks
2021-12-06 14:59:06,789 [dispatcher-event-loop-7] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 71.0 (TID 120, localhost, executor driver, partition 0, ANY, 7943 bytes)
2021-12-06 14:59:06,789 [Executor task launch worker for task 120] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 71.0 (TID 120)
2021-12-06 14:59:06,795 [Executor task launch worker for task 120] INFO [org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter] - File Output Committer Algorithm version is 1
2021-12-06 14:59:06,906 [Executor task launch worker for task 120] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 2 non-empty blocks out of 2 blocks
2021-12-06 14:59:06,906 [Executor task launch worker for task 120] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-06 14:59:06,921 [Executor task launch worker for task 120] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 2 non-empty blocks out of 2 blocks
2021-12-06 14:59:06,921 [Executor task launch worker for task 120] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-06 14:59:08,468 [Executor task launch worker for task 120] INFO [org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter] - Saved output of task 'attempt_20211206145906_0081_m_000000_0' to hdfs://hdp1:8020/sk/chongqing/list/validation-device/_temporary/0/task_20211206145906_0081_m_000000
2021-12-06 14:59:08,468 [Executor task launch worker for task 120] INFO [org.apache.spark.mapred.SparkHadoopMapRedUtil] - attempt_20211206145906_0081_m_000000_0: Committed
2021-12-06 14:59:08,469 [Executor task launch worker for task 120] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 71.0 (TID 120). 1299 bytes result sent to driver
2021-12-06 14:59:08,470 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 71.0 (TID 120) in 1681 ms on localhost (executor driver) (1/1)
2021-12-06 14:59:08,470 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 71.0, whose tasks have all completed, from pool 
2021-12-06 14:59:08,470 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 71 (runJob at SparkHadoopWriter.scala:78) finished in 1.693 s
2021-12-06 14:59:08,471 [main] INFO [org.apache.spark.scheduler.DAGScheduler] - Job 30 finished: runJob at SparkHadoopWriter.scala:78, took 1.693799 s
2021-12-06 14:59:08,694 [main] INFO [org.apache.spark.internal.io.SparkHadoopWriter] - Job job_20211206145906_0081 committed.
2021-12-06 14:59:08,698 [main] INFO [org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter] - File Output Committer Algorithm version is 1
2021-12-06 14:59:08,761 [main] INFO [org.apache.spark.SparkContext] - Starting job: runJob at SparkHadoopWriter.scala:78
2021-12-06 14:59:08,762 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 31 (runJob at SparkHadoopWriter.scala:78) with 1 output partitions
2021-12-06 14:59:08,762 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 73 (runJob at SparkHadoopWriter.scala:78)
2021-12-06 14:59:08,762 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 72)
2021-12-06 14:59:08,762 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2021-12-06 14:59:08,762 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 73 (MapPartitionsRDD[83] at saveAsTextFile at PaidPromotionAdjustParameter.scala:231), which has no missing parents
2021-12-06 14:59:08,772 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_52 stored as values in memory (estimated size 263.7 KB, free 1989.1 MB)
2021-12-06 14:59:08,774 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_52_piece0 stored as bytes in memory (estimated size 95.4 KB, free 1989.0 MB)
2021-12-06 14:59:08,775 [dispatcher-event-loop-2] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_52_piece0 in memory on qb:60678 (size: 95.4 KB, free: 1990.4 MB)
2021-12-06 14:59:08,775 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 52 from broadcast at DAGScheduler.scala:1039
2021-12-06 14:59:08,775 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 73 (MapPartitionsRDD[83] at saveAsTextFile at PaidPromotionAdjustParameter.scala:231) (first 15 tasks are for partitions Vector(0))
2021-12-06 14:59:08,775 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 73.0 with 1 tasks
2021-12-06 14:59:08,775 [dispatcher-event-loop-5] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 73.0 (TID 121, localhost, executor driver, partition 0, ANY, 7943 bytes)
2021-12-06 14:59:08,776 [Executor task launch worker for task 121] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 73.0 (TID 121)
2021-12-06 14:59:08,781 [Executor task launch worker for task 121] INFO [org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter] - File Output Committer Algorithm version is 1
2021-12-06 14:59:08,841 [Executor task launch worker for task 121] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 2 non-empty blocks out of 2 blocks
2021-12-06 14:59:08,841 [Executor task launch worker for task 121] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 1 ms
2021-12-06 14:59:08,849 [Executor task launch worker for task 121] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 2 non-empty blocks out of 2 blocks
2021-12-06 14:59:08,849 [Executor task launch worker for task 121] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-06 14:59:13,136 [Executor task launch worker for task 121] INFO [org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter] - Saved output of task 'attempt_20211206145908_0083_m_000000_0' to hdfs://hdp1:8020/sk/chongqing/list/validation-production/_temporary/0/task_20211206145908_0083_m_000000
2021-12-06 14:59:13,136 [Executor task launch worker for task 121] INFO [org.apache.spark.mapred.SparkHadoopMapRedUtil] - attempt_20211206145908_0083_m_000000_0: Committed
2021-12-06 14:59:13,137 [Executor task launch worker for task 121] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 73.0 (TID 121). 1342 bytes result sent to driver
2021-12-06 14:59:13,138 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 73.0 (TID 121) in 4363 ms on localhost (executor driver) (1/1)
2021-12-06 14:59:13,138 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 73.0, whose tasks have all completed, from pool 
2021-12-06 14:59:13,138 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 73 (runJob at SparkHadoopWriter.scala:78) finished in 4.376 s
2021-12-06 14:59:13,138 [main] INFO [org.apache.spark.scheduler.DAGScheduler] - Job 31 finished: runJob at SparkHadoopWriter.scala:78, took 4.376126 s
2021-12-06 14:59:13,655 [main] INFO [org.apache.spark.internal.io.SparkHadoopWriter] - Job job_20211206145908_0083 committed.
2021-12-06 14:59:13,658 [main] INFO [org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter] - File Output Committer Algorithm version is 1
2021-12-06 14:59:13,686 [main] INFO [org.apache.spark.SparkContext] - Starting job: runJob at SparkHadoopWriter.scala:78
2021-12-06 14:59:13,686 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 32 (runJob at SparkHadoopWriter.scala:78) with 1 output partitions
2021-12-06 14:59:13,686 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 75 (runJob at SparkHadoopWriter.scala:78)
2021-12-06 14:59:13,686 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 74)
2021-12-06 14:59:13,686 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2021-12-06 14:59:13,686 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 75 (MapPartitionsRDD[85] at saveAsTextFile at PaidPromotionAdjustParameter.scala:232), which has no missing parents
2021-12-06 14:59:13,698 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_53 stored as values in memory (estimated size 264.1 KB, free 1988.8 MB)
2021-12-06 14:59:13,703 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_53_piece0 stored as bytes in memory (estimated size 95.6 KB, free 1988.7 MB)
2021-12-06 14:59:13,703 [dispatcher-event-loop-7] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_53_piece0 in memory on qb:60678 (size: 95.6 KB, free: 1990.3 MB)
2021-12-06 14:59:13,703 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 53 from broadcast at DAGScheduler.scala:1039
2021-12-06 14:59:13,703 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1285
2021-12-06 14:59:13,703 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1204
2021-12-06 14:59:13,703 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1195
2021-12-06 14:59:13,703 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1182
2021-12-06 14:59:13,703 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1201
2021-12-06 14:59:13,703 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1263
2021-12-06 14:59:13,703 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1188
2021-12-06 14:59:13,703 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1242
2021-12-06 14:59:13,703 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1223
2021-12-06 14:59:13,703 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1256
2021-12-06 14:59:13,703 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1202
2021-12-06 14:59:13,703 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1262
2021-12-06 14:59:13,703 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1257
2021-12-06 14:59:13,703 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1286
2021-12-06 14:59:13,703 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1227
2021-12-06 14:59:13,703 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1178
2021-12-06 14:59:13,703 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 75 (MapPartitionsRDD[85] at saveAsTextFile at PaidPromotionAdjustParameter.scala:232) (first 15 tasks are for partitions Vector(0))
2021-12-06 14:59:13,703 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1246
2021-12-06 14:59:13,703 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 75.0 with 1 tasks
2021-12-06 14:59:13,703 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1245
2021-12-06 14:59:13,703 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1222
2021-12-06 14:59:13,703 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1275
2021-12-06 14:59:13,703 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1185
2021-12-06 14:59:13,703 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1183
2021-12-06 14:59:13,703 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1299
2021-12-06 14:59:13,703 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1265
2021-12-06 14:59:13,704 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1194
2021-12-06 14:59:13,704 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1243
2021-12-06 14:59:13,704 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1289
2021-12-06 14:59:13,704 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1211
2021-12-06 14:59:13,704 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1279
2021-12-06 14:59:13,704 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1280
2021-12-06 14:59:13,704 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1268
2021-12-06 14:59:13,704 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1209
2021-12-06 14:59:13,704 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1288
2021-12-06 14:59:13,704 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1276
2021-12-06 14:59:13,704 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1217
2021-12-06 14:59:13,704 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1282
2021-12-06 14:59:13,704 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1200
2021-12-06 14:59:13,704 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1226
2021-12-06 14:59:13,704 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1234
2021-12-06 14:59:13,704 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1181
2021-12-06 14:59:13,704 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1251
2021-12-06 14:59:13,704 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1193
2021-12-06 14:59:13,704 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1235
2021-12-06 14:59:13,704 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1228
2021-12-06 14:59:13,704 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1254
2021-12-06 14:59:13,704 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1186
2021-12-06 14:59:13,704 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1281
2021-12-06 14:59:13,704 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1264
2021-12-06 14:59:13,704 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1287
2021-12-06 14:59:13,704 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1187
2021-12-06 14:59:13,704 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1270
2021-12-06 14:59:13,704 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1244
2021-12-06 14:59:13,704 [dispatcher-event-loop-4] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 75.0 (TID 122, localhost, executor driver, partition 0, ANY, 7979 bytes)
2021-12-06 14:59:13,704 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1198
2021-12-06 14:59:13,704 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1249
2021-12-06 14:59:13,704 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1229
2021-12-06 14:59:13,704 [Executor task launch worker for task 122] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 75.0 (TID 122)
2021-12-06 14:59:13,704 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1239
2021-12-06 14:59:13,704 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1267
2021-12-06 14:59:13,704 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1189
2021-12-06 14:59:13,704 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1175
2021-12-06 14:59:13,704 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1214
2021-12-06 14:59:13,704 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1233
2021-12-06 14:59:13,704 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1250
2021-12-06 14:59:13,704 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1272
2021-12-06 14:59:13,704 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1297
2021-12-06 14:59:13,704 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1293
2021-12-06 14:59:13,704 [dispatcher-event-loop-11] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_49_piece0 on qb:60678 in memory (size: 66.9 KB, free: 1990.4 MB)
2021-12-06 14:59:13,705 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1269
2021-12-06 14:59:13,705 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1252
2021-12-06 14:59:13,705 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1177
2021-12-06 14:59:13,705 [dispatcher-event-loop-10] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_48_piece0 on qb:60678 in memory (size: 66.6 KB, free: 1990.4 MB)
2021-12-06 14:59:13,705 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1191
2021-12-06 14:59:13,705 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1274
2021-12-06 14:59:13,705 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1212
2021-12-06 14:59:13,706 [dispatcher-event-loop-0] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_50_piece0 on qb:60678 in memory (size: 67.0 KB, free: 1990.5 MB)
2021-12-06 14:59:13,706 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1278
2021-12-06 14:59:13,706 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1266
2021-12-06 14:59:13,706 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1260
2021-12-06 14:59:13,706 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1210
2021-12-06 14:59:13,706 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1216
2021-12-06 14:59:13,706 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1253
2021-12-06 14:59:13,706 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1273
2021-12-06 14:59:13,706 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1215
2021-12-06 14:59:13,706 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1203
2021-12-06 14:59:13,706 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1207
2021-12-06 14:59:13,706 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1298
2021-12-06 14:59:13,706 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1180
2021-12-06 14:59:13,706 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1238
2021-12-06 14:59:13,706 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1225
2021-12-06 14:59:13,706 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1208
2021-12-06 14:59:13,706 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1291
2021-12-06 14:59:13,706 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1236
2021-12-06 14:59:13,706 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1218
2021-12-06 14:59:13,706 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1224
2021-12-06 14:59:13,706 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1206
2021-12-06 14:59:13,706 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1271
2021-12-06 14:59:13,706 [dispatcher-event-loop-8] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_52_piece0 on qb:60678 in memory (size: 95.4 KB, free: 1990.6 MB)
2021-12-06 14:59:13,707 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1292
2021-12-06 14:59:13,707 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1232
2021-12-06 14:59:13,707 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1255
2021-12-06 14:59:13,707 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1213
2021-12-06 14:59:13,707 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1261
2021-12-06 14:59:13,707 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1230
2021-12-06 14:59:13,707 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1296
2021-12-06 14:59:13,707 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1176
2021-12-06 14:59:13,707 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1259
2021-12-06 14:59:13,707 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1196
2021-12-06 14:59:13,707 [dispatcher-event-loop-11] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_51_piece0 on qb:60678 in memory (size: 95.3 KB, free: 1990.7 MB)
2021-12-06 14:59:13,707 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1184
2021-12-06 14:59:13,707 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1294
2021-12-06 14:59:13,707 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1247
2021-12-06 14:59:13,707 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1283
2021-12-06 14:59:13,707 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1179
2021-12-06 14:59:13,707 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1199
2021-12-06 14:59:13,707 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1290
2021-12-06 14:59:13,707 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1277
2021-12-06 14:59:13,707 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1231
2021-12-06 14:59:13,707 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1197
2021-12-06 14:59:13,707 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1190
2021-12-06 14:59:13,707 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1237
2021-12-06 14:59:13,707 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1284
2021-12-06 14:59:13,707 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1220
2021-12-06 14:59:13,707 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1258
2021-12-06 14:59:13,707 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1219
2021-12-06 14:59:13,707 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1221
2021-12-06 14:59:13,707 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1192
2021-12-06 14:59:13,707 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1205
2021-12-06 14:59:13,707 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1248
2021-12-06 14:59:13,707 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1295
2021-12-06 14:59:13,707 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1241
2021-12-06 14:59:13,707 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1240
2021-12-06 14:59:13,711 [Executor task launch worker for task 122] INFO [org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter] - File Output Committer Algorithm version is 1
2021-12-06 14:59:13,725 [Executor task launch worker for task 122] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 4 non-empty blocks out of 4 blocks
2021-12-06 14:59:13,725 [Executor task launch worker for task 122] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-06 14:59:13,779 [Executor task launch worker for task 122] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 4 non-empty blocks out of 4 blocks
2021-12-06 14:59:13,779 [Executor task launch worker for task 122] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-06 14:59:13,832 [Executor task launch worker for task 122] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 4 non-empty blocks out of 4 blocks
2021-12-06 14:59:13,832 [Executor task launch worker for task 122] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-06 14:59:13,885 [Executor task launch worker for task 122] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 4 non-empty blocks out of 4 blocks
2021-12-06 14:59:13,885 [Executor task launch worker for task 122] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-06 14:59:32,254 [Executor task launch worker for task 122] INFO [org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter] - Saved output of task 'attempt_20211206145913_0085_m_000000_0' to hdfs://hdp1:8020/sk/chongqing/list/train-device/_temporary/0/task_20211206145913_0085_m_000000
2021-12-06 14:59:32,254 [Executor task launch worker for task 122] INFO [org.apache.spark.mapred.SparkHadoopMapRedUtil] - attempt_20211206145913_0085_m_000000_0: Committed
2021-12-06 14:59:32,255 [Executor task launch worker for task 122] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 75.0 (TID 122). 1299 bytes result sent to driver
2021-12-06 14:59:32,255 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 75.0 (TID 122) in 18551 ms on localhost (executor driver) (1/1)
2021-12-06 14:59:32,255 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 75.0, whose tasks have all completed, from pool 
2021-12-06 14:59:32,255 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 75 (runJob at SparkHadoopWriter.scala:78) finished in 18.568 s
2021-12-06 14:59:32,255 [main] INFO [org.apache.spark.scheduler.DAGScheduler] - Job 32 finished: runJob at SparkHadoopWriter.scala:78, took 18.569130 s
2021-12-06 14:59:33,056 [main] INFO [org.apache.spark.internal.io.SparkHadoopWriter] - Job job_20211206145913_0085 committed.
2021-12-06 14:59:33,059 [main] INFO [org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter] - File Output Committer Algorithm version is 1
2021-12-06 14:59:33,106 [main] INFO [org.apache.spark.SparkContext] - Starting job: runJob at SparkHadoopWriter.scala:78
2021-12-06 14:59:33,106 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 33 (runJob at SparkHadoopWriter.scala:78) with 1 output partitions
2021-12-06 14:59:33,106 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 77 (runJob at SparkHadoopWriter.scala:78)
2021-12-06 14:59:33,106 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 76)
2021-12-06 14:59:33,107 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2021-12-06 14:59:33,107 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 77 (MapPartitionsRDD[87] at saveAsTextFile at PaidPromotionAdjustParameter.scala:233), which has no missing parents
2021-12-06 14:59:33,117 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_54 stored as values in memory (estimated size 264.3 KB, free 1989.9 MB)
2021-12-06 14:59:33,119 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_54_piece0 stored as bytes in memory (estimated size 95.7 KB, free 1989.8 MB)
2021-12-06 14:59:33,119 [dispatcher-event-loop-4] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_54_piece0 in memory on qb:60678 (size: 95.7 KB, free: 1990.6 MB)
2021-12-06 14:59:33,120 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 54 from broadcast at DAGScheduler.scala:1039
2021-12-06 14:59:33,120 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 77 (MapPartitionsRDD[87] at saveAsTextFile at PaidPromotionAdjustParameter.scala:233) (first 15 tasks are for partitions Vector(0))
2021-12-06 14:59:33,120 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 77.0 with 1 tasks
2021-12-06 14:59:33,120 [dispatcher-event-loop-7] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 77.0 (TID 123, localhost, executor driver, partition 0, ANY, 7979 bytes)
2021-12-06 14:59:33,120 [Executor task launch worker for task 123] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 77.0 (TID 123)
2021-12-06 14:59:33,125 [Executor task launch worker for task 123] INFO [org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter] - File Output Committer Algorithm version is 1
2021-12-06 14:59:33,162 [Executor task launch worker for task 123] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 4 non-empty blocks out of 4 blocks
2021-12-06 14:59:33,162 [Executor task launch worker for task 123] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-06 14:59:33,176 [Executor task launch worker for task 123] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 4 non-empty blocks out of 4 blocks
2021-12-06 14:59:33,176 [Executor task launch worker for task 123] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-06 14:59:33,209 [Executor task launch worker for task 123] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 4 non-empty blocks out of 4 blocks
2021-12-06 14:59:33,209 [Executor task launch worker for task 123] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-06 14:59:33,244 [Executor task launch worker for task 123] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 4 non-empty blocks out of 4 blocks
2021-12-06 14:59:33,244 [Executor task launch worker for task 123] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-06 14:59:45,624 [Executor task launch worker for task 123] INFO [org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter] - Saved output of task 'attempt_20211206145933_0087_m_000000_0' to hdfs://hdp1:8020/sk/chongqing/list/train-production/_temporary/0/task_20211206145933_0087_m_000000
2021-12-06 14:59:45,624 [Executor task launch worker for task 123] INFO [org.apache.spark.mapred.SparkHadoopMapRedUtil] - attempt_20211206145933_0087_m_000000_0: Committed
2021-12-06 14:59:45,624 [Executor task launch worker for task 123] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 77.0 (TID 123). 1299 bytes result sent to driver
2021-12-06 14:59:45,625 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 77.0 (TID 123) in 12505 ms on localhost (executor driver) (1/1)
2021-12-06 14:59:45,625 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 77.0, whose tasks have all completed, from pool 
2021-12-06 14:59:45,625 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 77 (runJob at SparkHadoopWriter.scala:78) finished in 12.518 s
2021-12-06 14:59:45,625 [main] INFO [org.apache.spark.scheduler.DAGScheduler] - Job 33 finished: runJob at SparkHadoopWriter.scala:78, took 12.518385 s
2021-12-06 14:59:46,296 [main] INFO [org.apache.spark.internal.io.SparkHadoopWriter] - Job job_20211206145933_0087 committed.
2021-12-06 14:59:46,299 [main] INFO [org.spark_project.jetty.server.AbstractConnector] - Stopped Spark@2e185cd7{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2021-12-06 14:59:46,301 [main] INFO [org.apache.spark.ui.SparkUI] - Stopped Spark web UI at http://qb:4040
2021-12-06 14:59:46,309 [dispatcher-event-loop-6] INFO [org.apache.spark.MapOutputTrackerMasterEndpoint] - MapOutputTrackerMasterEndpoint stopped!
2021-12-06 14:59:46,394 [main] INFO [org.apache.spark.storage.memory.MemoryStore] - MemoryStore cleared
2021-12-06 14:59:46,394 [main] INFO [org.apache.spark.storage.BlockManager] - BlockManager stopped
2021-12-06 14:59:46,394 [main] INFO [org.apache.spark.storage.BlockManagerMaster] - BlockManagerMaster stopped
2021-12-06 14:59:46,396 [dispatcher-event-loop-8] INFO [org.apache.spark.scheduler.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint] - OutputCommitCoordinator stopped!
2021-12-06 14:59:46,399 [main] INFO [org.apache.spark.SparkContext] - Successfully stopped SparkContext
2021-12-06 14:59:46,400 [Thread-1] INFO [org.apache.spark.util.ShutdownHookManager] - Shutdown hook called
2021-12-06 14:59:46,401 [Thread-1] INFO [org.apache.spark.util.ShutdownHookManager] - Deleting directory C:\Users\ACER\AppData\Local\Temp\spark-22388a6e-7541-4940-ac5f-f1431917ccc6
2021-12-06 15:10:27,614 [main] INFO [org.apache.spark.SparkContext] - Running Spark version 2.3.0
2021-12-06 15:10:27,892 [main] INFO [org.apache.spark.SparkContext] - Submitted application: PaidPromotion
2021-12-06 15:10:27,942 [main] INFO [org.apache.spark.SecurityManager] - Changing view acls to: ACER,root
2021-12-06 15:10:27,943 [main] INFO [org.apache.spark.SecurityManager] - Changing modify acls to: ACER,root
2021-12-06 15:10:27,943 [main] INFO [org.apache.spark.SecurityManager] - Changing view acls groups to: 
2021-12-06 15:10:27,943 [main] INFO [org.apache.spark.SecurityManager] - Changing modify acls groups to: 
2021-12-06 15:10:27,944 [main] INFO [org.apache.spark.SecurityManager] - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(ACER, root); groups with view permissions: Set(); users  with modify permissions: Set(ACER, root); groups with modify permissions: Set()
2021-12-06 15:10:28,507 [main] INFO [org.apache.spark.util.Utils] - Successfully started service 'sparkDriver' on port 52163.
2021-12-06 15:10:28,522 [main] INFO [org.apache.spark.SparkEnv] - Registering MapOutputTracker
2021-12-06 15:10:28,536 [main] INFO [org.apache.spark.SparkEnv] - Registering BlockManagerMaster
2021-12-06 15:10:28,538 [main] INFO [org.apache.spark.storage.BlockManagerMasterEndpoint] - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2021-12-06 15:10:28,539 [main] INFO [org.apache.spark.storage.BlockManagerMasterEndpoint] - BlockManagerMasterEndpoint up
2021-12-06 15:10:28,546 [main] INFO [org.apache.spark.storage.DiskBlockManager] - Created local directory at C:\Users\ACER\AppData\Local\Temp\blockmgr-3782ea9f-c5b3-48e6-932d-4043113113ec
2021-12-06 15:10:28,560 [main] INFO [org.apache.spark.storage.memory.MemoryStore] - MemoryStore started with capacity 1990.8 MB
2021-12-06 15:10:28,569 [main] INFO [org.apache.spark.SparkEnv] - Registering OutputCommitCoordinator
2021-12-06 15:10:28,619 [main] INFO [org.spark_project.jetty.util.log] - Logging initialized @1820ms
2021-12-06 15:10:28,663 [main] INFO [org.spark_project.jetty.server.Server] - jetty-9.3.z-SNAPSHOT
2021-12-06 15:10:28,674 [main] INFO [org.spark_project.jetty.server.Server] - Started @1875ms
2021-12-06 15:10:28,698 [main] INFO [org.spark_project.jetty.server.AbstractConnector] - Started ServerConnector@5b800468{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2021-12-06 15:10:28,698 [main] INFO [org.apache.spark.util.Utils] - Successfully started service 'SparkUI' on port 4040.
2021-12-06 15:10:28,716 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@1568159{/jobs,null,AVAILABLE,@Spark}
2021-12-06 15:10:28,716 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@63cd604c{/jobs/json,null,AVAILABLE,@Spark}
2021-12-06 15:10:28,718 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@3954d008{/jobs/job,null,AVAILABLE,@Spark}
2021-12-06 15:10:28,719 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@6d8792db{/jobs/job/json,null,AVAILABLE,@Spark}
2021-12-06 15:10:28,720 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@3a1d593e{/stages,null,AVAILABLE,@Spark}
2021-12-06 15:10:28,721 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@285d851a{/stages/json,null,AVAILABLE,@Spark}
2021-12-06 15:10:28,722 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@7876d598{/stages/stage,null,AVAILABLE,@Spark}
2021-12-06 15:10:28,724 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@4985cbcb{/stages/stage/json,null,AVAILABLE,@Spark}
2021-12-06 15:10:28,725 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@54361a9{/stages/pool,null,AVAILABLE,@Spark}
2021-12-06 15:10:28,726 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@293bb8a5{/stages/pool/json,null,AVAILABLE,@Spark}
2021-12-06 15:10:28,727 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@290b1b2e{/storage,null,AVAILABLE,@Spark}
2021-12-06 15:10:28,728 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@5db4c359{/storage/json,null,AVAILABLE,@Spark}
2021-12-06 15:10:28,729 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@6fefce9e{/storage/rdd,null,AVAILABLE,@Spark}
2021-12-06 15:10:28,730 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@8a589a2{/storage/rdd/json,null,AVAILABLE,@Spark}
2021-12-06 15:10:28,731 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@5cc69cfe{/environment,null,AVAILABLE,@Spark}
2021-12-06 15:10:28,732 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@11dee337{/environment/json,null,AVAILABLE,@Spark}
2021-12-06 15:10:28,733 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@74bdc168{/executors,null,AVAILABLE,@Spark}
2021-12-06 15:10:28,734 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@7bb3a9fe{/executors/json,null,AVAILABLE,@Spark}
2021-12-06 15:10:28,735 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@f19c9d2{/executors/threadDump,null,AVAILABLE,@Spark}
2021-12-06 15:10:28,736 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@a77614d{/executors/threadDump/json,null,AVAILABLE,@Spark}
2021-12-06 15:10:28,741 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@523424b5{/static,null,AVAILABLE,@Spark}
2021-12-06 15:10:28,743 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@12cd9150{/,null,AVAILABLE,@Spark}
2021-12-06 15:10:28,744 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@32fe9d0a{/api,null,AVAILABLE,@Spark}
2021-12-06 15:10:28,745 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@59fc684e{/jobs/job/kill,null,AVAILABLE,@Spark}
2021-12-06 15:10:28,746 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@355e34c7{/stages/stage/kill,null,AVAILABLE,@Spark}
2021-12-06 15:10:28,748 [main] INFO [org.apache.spark.ui.SparkUI] - Bound SparkUI to 0.0.0.0, and started at http://qb:4040
2021-12-06 15:10:28,815 [main] INFO [org.apache.spark.executor.Executor] - Starting executor ID driver on host localhost
2021-12-06 15:10:28,857 [main] INFO [org.apache.spark.util.Utils] - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 52204.
2021-12-06 15:10:28,858 [main] INFO [org.apache.spark.network.netty.NettyBlockTransferService] - Server created on qb:52204
2021-12-06 15:10:28,859 [main] INFO [org.apache.spark.storage.BlockManager] - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2021-12-06 15:10:28,860 [main] INFO [org.apache.spark.storage.BlockManagerMaster] - Registering BlockManager BlockManagerId(driver, qb, 52204, None)
2021-12-06 15:10:28,862 [dispatcher-event-loop-10] INFO [org.apache.spark.storage.BlockManagerMasterEndpoint] - Registering block manager qb:52204 with 1990.8 MB RAM, BlockManagerId(driver, qb, 52204, None)
2021-12-06 15:10:28,863 [main] INFO [org.apache.spark.storage.BlockManagerMaster] - Registered BlockManager BlockManagerId(driver, qb, 52204, None)
2021-12-06 15:10:28,863 [main] INFO [org.apache.spark.storage.BlockManager] - Initialized BlockManager: BlockManagerId(driver, qb, 52204, None)
2021-12-06 15:10:28,980 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@6fe46b62{/metrics/json,null,AVAILABLE,@Spark}
2021-12-06 15:10:29,391 [main] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_0 stored as values in memory (estimated size 312.7 KB, free 1990.5 MB)
2021-12-06 15:10:29,567 [main] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_0_piece0 stored as bytes in memory (estimated size 27.3 KB, free 1990.5 MB)
2021-12-06 15:10:29,568 [dispatcher-event-loop-0] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_0_piece0 in memory on qb:52204 (size: 27.3 KB, free: 1990.8 MB)
2021-12-06 15:10:29,571 [main] INFO [org.apache.spark.SparkContext] - Created broadcast 0 from textFile at PaidPromotionAdjustParameter.scala:57
2021-12-06 15:10:29,874 [main] WARN [org.apache.hadoop.hdfs.shortcircuit.DomainSocketFactory] - The short-circuit local reads feature cannot be used because UNIX Domain sockets are not available on Windows.
2021-12-06 15:10:29,941 [main] INFO [org.apache.hadoop.mapred.FileInputFormat] - Total input paths to process : 1
2021-12-06 15:10:29,980 [main] INFO [org.apache.spark.SparkContext] - Starting job: count at PaidPromotionAdjustParameter.scala:59
2021-12-06 15:10:29,989 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 0 (count at PaidPromotionAdjustParameter.scala:59) with 20 output partitions
2021-12-06 15:10:29,990 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 0 (count at PaidPromotionAdjustParameter.scala:59)
2021-12-06 15:10:29,990 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List()
2021-12-06 15:10:29,991 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2021-12-06 15:10:29,996 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 0 (/sk/chongqing/data/behavior_data.bcp MapPartitionsRDD[1] at textFile at PaidPromotionAdjustParameter.scala:57), which has no missing parents
2021-12-06 15:10:30,027 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_1 stored as values in memory (estimated size 3.1 KB, free 1990.5 MB)
2021-12-06 15:10:30,032 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_1_piece0 stored as bytes in memory (estimated size 1903.0 B, free 1990.5 MB)
2021-12-06 15:10:30,033 [dispatcher-event-loop-1] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_1_piece0 in memory on qb:52204 (size: 1903.0 B, free: 1990.8 MB)
2021-12-06 15:10:30,033 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 1 from broadcast at DAGScheduler.scala:1039
2021-12-06 15:10:30,043 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 20 missing tasks from ResultStage 0 (/sk/chongqing/data/behavior_data.bcp MapPartitionsRDD[1] at textFile at PaidPromotionAdjustParameter.scala:57) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14))
2021-12-06 15:10:30,043 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 0.0 with 20 tasks
2021-12-06 15:10:30,077 [dispatcher-event-loop-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 0.0 (TID 0, localhost, executor driver, partition 0, ANY, 7899 bytes)
2021-12-06 15:10:30,078 [dispatcher-event-loop-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 0.0 (TID 1, localhost, executor driver, partition 1, ANY, 7899 bytes)
2021-12-06 15:10:30,079 [dispatcher-event-loop-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 2.0 in stage 0.0 (TID 2, localhost, executor driver, partition 2, ANY, 7899 bytes)
2021-12-06 15:10:30,079 [dispatcher-event-loop-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 3.0 in stage 0.0 (TID 3, localhost, executor driver, partition 3, ANY, 7899 bytes)
2021-12-06 15:10:30,079 [dispatcher-event-loop-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 4.0 in stage 0.0 (TID 4, localhost, executor driver, partition 4, ANY, 7899 bytes)
2021-12-06 15:10:30,079 [dispatcher-event-loop-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 5.0 in stage 0.0 (TID 5, localhost, executor driver, partition 5, ANY, 7899 bytes)
2021-12-06 15:10:30,080 [dispatcher-event-loop-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 6.0 in stage 0.0 (TID 6, localhost, executor driver, partition 6, ANY, 7899 bytes)
2021-12-06 15:10:30,080 [dispatcher-event-loop-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 7.0 in stage 0.0 (TID 7, localhost, executor driver, partition 7, ANY, 7899 bytes)
2021-12-06 15:10:30,080 [dispatcher-event-loop-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 8.0 in stage 0.0 (TID 8, localhost, executor driver, partition 8, ANY, 7899 bytes)
2021-12-06 15:10:30,080 [dispatcher-event-loop-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 9.0 in stage 0.0 (TID 9, localhost, executor driver, partition 9, ANY, 7899 bytes)
2021-12-06 15:10:30,081 [dispatcher-event-loop-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 10.0 in stage 0.0 (TID 10, localhost, executor driver, partition 10, ANY, 7899 bytes)
2021-12-06 15:10:30,081 [dispatcher-event-loop-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 11.0 in stage 0.0 (TID 11, localhost, executor driver, partition 11, ANY, 7899 bytes)
2021-12-06 15:10:30,086 [Executor task launch worker for task 7] INFO [org.apache.spark.executor.Executor] - Running task 7.0 in stage 0.0 (TID 7)
2021-12-06 15:10:30,086 [Executor task launch worker for task 5] INFO [org.apache.spark.executor.Executor] - Running task 5.0 in stage 0.0 (TID 5)
2021-12-06 15:10:30,086 [Executor task launch worker for task 1] INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 0.0 (TID 1)
2021-12-06 15:10:30,086 [Executor task launch worker for task 6] INFO [org.apache.spark.executor.Executor] - Running task 6.0 in stage 0.0 (TID 6)
2021-12-06 15:10:30,086 [Executor task launch worker for task 8] INFO [org.apache.spark.executor.Executor] - Running task 8.0 in stage 0.0 (TID 8)
2021-12-06 15:10:30,086 [Executor task launch worker for task 4] INFO [org.apache.spark.executor.Executor] - Running task 4.0 in stage 0.0 (TID 4)
2021-12-06 15:10:30,086 [Executor task launch worker for task 11] INFO [org.apache.spark.executor.Executor] - Running task 11.0 in stage 0.0 (TID 11)
2021-12-06 15:10:30,086 [Executor task launch worker for task 10] INFO [org.apache.spark.executor.Executor] - Running task 10.0 in stage 0.0 (TID 10)
2021-12-06 15:10:30,086 [Executor task launch worker for task 2] INFO [org.apache.spark.executor.Executor] - Running task 2.0 in stage 0.0 (TID 2)
2021-12-06 15:10:30,086 [Executor task launch worker for task 3] INFO [org.apache.spark.executor.Executor] - Running task 3.0 in stage 0.0 (TID 3)
2021-12-06 15:10:30,086 [Executor task launch worker for task 0] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 0.0 (TID 0)
2021-12-06 15:10:30,086 [Executor task launch worker for task 9] INFO [org.apache.spark.executor.Executor] - Running task 9.0 in stage 0.0 (TID 9)
2021-12-06 15:10:30,131 [Executor task launch worker for task 8] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:1073741824+134217728
2021-12-06 15:10:30,131 [Executor task launch worker for task 2] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:268435456+134217728
2021-12-06 15:10:30,131 [Executor task launch worker for task 4] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:536870912+134217728
2021-12-06 15:10:30,131 [Executor task launch worker for task 11] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:1476395008+134217728
2021-12-06 15:10:30,131 [Executor task launch worker for task 9] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:1207959552+134217728
2021-12-06 15:10:30,131 [Executor task launch worker for task 10] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:1342177280+134217728
2021-12-06 15:10:30,131 [Executor task launch worker for task 6] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:805306368+134217728
2021-12-06 15:10:30,131 [Executor task launch worker for task 0] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:0+134217728
2021-12-06 15:10:30,131 [Executor task launch worker for task 7] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:939524096+134217728
2021-12-06 15:10:30,131 [Executor task launch worker for task 5] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:671088640+134217728
2021-12-06 15:10:30,131 [Executor task launch worker for task 3] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:402653184+134217728
2021-12-06 15:10:30,131 [Executor task launch worker for task 1] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:134217728+134217728
2021-12-06 15:13:09,938 [Executor task launch worker for task 11] INFO [org.apache.spark.executor.Executor] - Finished task 11.0 in stage 0.0 (TID 11). 798 bytes result sent to driver
2021-12-06 15:13:09,939 [dispatcher-event-loop-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 12.0 in stage 0.0 (TID 12, localhost, executor driver, partition 12, ANY, 7899 bytes)
2021-12-06 15:13:09,940 [Executor task launch worker for task 12] INFO [org.apache.spark.executor.Executor] - Running task 12.0 in stage 0.0 (TID 12)
2021-12-06 15:13:09,941 [Executor task launch worker for task 12] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:1610612736+134217728
2021-12-06 15:13:09,947 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 11.0 in stage 0.0 (TID 11) in 159865 ms on localhost (executor driver) (1/20)
2021-12-06 15:13:16,271 [Executor task launch worker for task 3] INFO [org.apache.spark.executor.Executor] - Finished task 3.0 in stage 0.0 (TID 3). 755 bytes result sent to driver
2021-12-06 15:13:16,271 [dispatcher-event-loop-6] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 13.0 in stage 0.0 (TID 13, localhost, executor driver, partition 13, ANY, 7899 bytes)
2021-12-06 15:13:16,271 [Executor task launch worker for task 13] INFO [org.apache.spark.executor.Executor] - Running task 13.0 in stage 0.0 (TID 13)
2021-12-06 15:13:16,273 [Executor task launch worker for task 13] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:1744830464+134217728
2021-12-06 15:13:16,274 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 3.0 in stage 0.0 (TID 3) in 166195 ms on localhost (executor driver) (2/20)
2021-12-06 15:13:20,555 [Executor task launch worker for task 6] INFO [org.apache.spark.executor.Executor] - Finished task 6.0 in stage 0.0 (TID 6). 798 bytes result sent to driver
2021-12-06 15:13:20,556 [dispatcher-event-loop-8] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 14.0 in stage 0.0 (TID 14, localhost, executor driver, partition 14, ANY, 7899 bytes)
2021-12-06 15:13:20,556 [Executor task launch worker for task 14] INFO [org.apache.spark.executor.Executor] - Running task 14.0 in stage 0.0 (TID 14)
2021-12-06 15:13:20,557 [Executor task launch worker for task 14] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:1879048192+134217728
2021-12-06 15:13:20,558 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 6.0 in stage 0.0 (TID 6) in 170479 ms on localhost (executor driver) (3/20)
2021-12-06 15:13:33,076 [Executor task launch worker for task 7] INFO [org.apache.spark.executor.Executor] - Finished task 7.0 in stage 0.0 (TID 7). 798 bytes result sent to driver
2021-12-06 15:13:33,077 [dispatcher-event-loop-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 15.0 in stage 0.0 (TID 15, localhost, executor driver, partition 15, ANY, 7899 bytes)
2021-12-06 15:13:33,077 [Executor task launch worker for task 15] INFO [org.apache.spark.executor.Executor] - Running task 15.0 in stage 0.0 (TID 15)
2021-12-06 15:13:33,079 [Executor task launch worker for task 15] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:2013265920+134217728
2021-12-06 15:13:33,080 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 7.0 in stage 0.0 (TID 7) in 183000 ms on localhost (executor driver) (4/20)
2021-12-06 15:13:37,944 [Executor task launch worker for task 1] INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 0.0 (TID 1). 755 bytes result sent to driver
2021-12-06 15:13:37,944 [dispatcher-event-loop-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 16.0 in stage 0.0 (TID 16, localhost, executor driver, partition 16, ANY, 7899 bytes)
2021-12-06 15:13:37,944 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 0.0 (TID 1) in 187866 ms on localhost (executor driver) (5/20)
2021-12-06 15:13:37,944 [Executor task launch worker for task 16] INFO [org.apache.spark.executor.Executor] - Running task 16.0 in stage 0.0 (TID 16)
2021-12-06 15:13:37,945 [Executor task launch worker for task 16] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:2147483648+134217728
2021-12-06 15:13:38,900 [Executor task launch worker for task 0] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 0.0 (TID 0). 755 bytes result sent to driver
2021-12-06 15:13:38,900 [dispatcher-event-loop-7] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 17.0 in stage 0.0 (TID 17, localhost, executor driver, partition 17, ANY, 7899 bytes)
2021-12-06 15:13:38,901 [Executor task launch worker for task 17] INFO [org.apache.spark.executor.Executor] - Running task 17.0 in stage 0.0 (TID 17)
2021-12-06 15:13:38,901 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 0.0 (TID 0) in 188833 ms on localhost (executor driver) (6/20)
2021-12-06 15:13:38,902 [Executor task launch worker for task 17] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:2281701376+134217728
2021-12-06 15:13:40,269 [Executor task launch worker for task 8] INFO [org.apache.spark.executor.Executor] - Finished task 8.0 in stage 0.0 (TID 8). 755 bytes result sent to driver
2021-12-06 15:13:40,270 [dispatcher-event-loop-9] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 18.0 in stage 0.0 (TID 18, localhost, executor driver, partition 18, ANY, 7899 bytes)
2021-12-06 15:13:40,270 [Executor task launch worker for task 18] INFO [org.apache.spark.executor.Executor] - Running task 18.0 in stage 0.0 (TID 18)
2021-12-06 15:13:40,270 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 8.0 in stage 0.0 (TID 8) in 190190 ms on localhost (executor driver) (7/20)
2021-12-06 15:13:40,272 [Executor task launch worker for task 18] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:2415919104+134217728
2021-12-06 15:13:42,822 [Executor task launch worker for task 9] INFO [org.apache.spark.executor.Executor] - Finished task 9.0 in stage 0.0 (TID 9). 755 bytes result sent to driver
2021-12-06 15:13:42,822 [dispatcher-event-loop-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 19.0 in stage 0.0 (TID 19, localhost, executor driver, partition 19, ANY, 7899 bytes)
2021-12-06 15:13:42,822 [Executor task launch worker for task 19] INFO [org.apache.spark.executor.Executor] - Running task 19.0 in stage 0.0 (TID 19)
2021-12-06 15:13:42,823 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 9.0 in stage 0.0 (TID 9) in 192742 ms on localhost (executor driver) (8/20)
2021-12-06 15:13:42,823 [Executor task launch worker for task 19] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:2550136832+85027535
2021-12-06 15:13:49,344 [Executor task launch worker for task 5] INFO [org.apache.spark.executor.Executor] - Finished task 5.0 in stage 0.0 (TID 5). 755 bytes result sent to driver
2021-12-06 15:13:49,346 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 5.0 in stage 0.0 (TID 5) in 199267 ms on localhost (executor driver) (9/20)
2021-12-06 15:13:56,185 [Executor task launch worker for task 10] INFO [org.apache.spark.executor.Executor] - Finished task 10.0 in stage 0.0 (TID 10). 755 bytes result sent to driver
2021-12-06 15:13:56,185 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 10.0 in stage 0.0 (TID 10) in 206105 ms on localhost (executor driver) (10/20)
2021-12-06 15:13:56,554 [Executor task launch worker for task 4] INFO [org.apache.spark.executor.Executor] - Finished task 4.0 in stage 0.0 (TID 4). 798 bytes result sent to driver
2021-12-06 15:13:56,554 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 4.0 in stage 0.0 (TID 4) in 206475 ms on localhost (executor driver) (11/20)
2021-12-06 15:13:56,594 [Executor task launch worker for task 2] INFO [org.apache.spark.executor.Executor] - Finished task 2.0 in stage 0.0 (TID 2). 755 bytes result sent to driver
2021-12-06 15:13:56,594 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 2.0 in stage 0.0 (TID 2) in 206516 ms on localhost (executor driver) (12/20)
2021-12-06 15:14:37,895 [Executor task launch worker for task 19] INFO [org.apache.spark.executor.Executor] - Finished task 19.0 in stage 0.0 (TID 19). 755 bytes result sent to driver
2021-12-06 15:14:37,896 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 19.0 in stage 0.0 (TID 19) in 55074 ms on localhost (executor driver) (13/20)
2021-12-06 15:15:17,926 [Executor task launch worker for task 12] INFO [org.apache.spark.executor.Executor] - Finished task 12.0 in stage 0.0 (TID 12). 712 bytes result sent to driver
2021-12-06 15:15:17,926 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 12.0 in stage 0.0 (TID 12) in 127987 ms on localhost (executor driver) (14/20)
2021-12-06 15:15:17,985 [Executor task launch worker for task 14] INFO [org.apache.spark.executor.Executor] - Finished task 14.0 in stage 0.0 (TID 14). 798 bytes result sent to driver
2021-12-06 15:15:17,985 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 14.0 in stage 0.0 (TID 14) in 117430 ms on localhost (executor driver) (15/20)
2021-12-06 15:15:25,438 [Executor task launch worker for task 13] INFO [org.apache.spark.executor.Executor] - Finished task 13.0 in stage 0.0 (TID 13). 755 bytes result sent to driver
2021-12-06 15:15:25,439 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 13.0 in stage 0.0 (TID 13) in 129168 ms on localhost (executor driver) (16/20)
2021-12-06 15:15:25,857 [Executor task launch worker for task 15] INFO [org.apache.spark.executor.Executor] - Finished task 15.0 in stage 0.0 (TID 15). 755 bytes result sent to driver
2021-12-06 15:15:25,857 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 15.0 in stage 0.0 (TID 15) in 112780 ms on localhost (executor driver) (17/20)
2021-12-06 15:15:25,888 [Executor task launch worker for task 16] INFO [org.apache.spark.executor.Executor] - Finished task 16.0 in stage 0.0 (TID 16). 755 bytes result sent to driver
2021-12-06 15:15:25,888 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 16.0 in stage 0.0 (TID 16) in 107944 ms on localhost (executor driver) (18/20)
2021-12-06 15:15:28,417 [Executor task launch worker for task 17] INFO [org.apache.spark.executor.Executor] - Finished task 17.0 in stage 0.0 (TID 17). 755 bytes result sent to driver
2021-12-06 15:15:28,417 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 17.0 in stage 0.0 (TID 17) in 109517 ms on localhost (executor driver) (19/20)
2021-12-06 15:15:30,147 [Executor task launch worker for task 18] INFO [org.apache.spark.executor.Executor] - Finished task 18.0 in stage 0.0 (TID 18). 755 bytes result sent to driver
2021-12-06 15:15:30,148 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 18.0 in stage 0.0 (TID 18) in 109878 ms on localhost (executor driver) (20/20)
2021-12-06 15:15:30,149 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 0.0, whose tasks have all completed, from pool 
2021-12-06 15:15:30,149 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 0 (count at PaidPromotionAdjustParameter.scala:59) finished in 300.139 s
2021-12-06 15:15:30,154 [main] INFO [org.apache.spark.scheduler.DAGScheduler] - Job 0 finished: count at PaidPromotionAdjustParameter.scala:59, took 300.174341 s
2021-12-06 15:15:30,155 [main] INFO [PaidPromotion$] - 60870678
2021-12-06 15:15:30,174 [main] INFO [org.apache.spark.SparkContext] - Starting job: count at PaidPromotionAdjustParameter.scala:68
2021-12-06 15:15:30,180 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 3 (map at PaidPromotionAdjustParameter.scala:67)
2021-12-06 15:15:30,181 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 1 (count at PaidPromotionAdjustParameter.scala:68) with 20 output partitions
2021-12-06 15:15:30,181 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 2 (count at PaidPromotionAdjustParameter.scala:68)
2021-12-06 15:15:30,181 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 1)
2021-12-06 15:15:30,182 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List(ShuffleMapStage 1)
2021-12-06 15:15:30,183 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ShuffleMapStage 1 (MapPartitionsRDD[3] at map at PaidPromotionAdjustParameter.scala:67), which has no missing parents
2021-12-06 15:15:30,192 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_2 stored as values in memory (estimated size 4.7 KB, free 1990.5 MB)
2021-12-06 15:15:30,195 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_2_piece0 stored as bytes in memory (estimated size 2.7 KB, free 1990.5 MB)
2021-12-06 15:15:30,196 [dispatcher-event-loop-0] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_2_piece0 in memory on qb:52204 (size: 2.7 KB, free: 1990.8 MB)
2021-12-06 15:15:30,196 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 2 from broadcast at DAGScheduler.scala:1039
2021-12-06 15:15:30,198 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 20 missing tasks from ShuffleMapStage 1 (MapPartitionsRDD[3] at map at PaidPromotionAdjustParameter.scala:67) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14))
2021-12-06 15:15:30,198 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 1.0 with 20 tasks
2021-12-06 15:15:30,199 [dispatcher-event-loop-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 1.0 (TID 20, localhost, executor driver, partition 0, ANY, 7888 bytes)
2021-12-06 15:15:30,200 [dispatcher-event-loop-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 1.0 (TID 21, localhost, executor driver, partition 1, ANY, 7888 bytes)
2021-12-06 15:15:30,200 [dispatcher-event-loop-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 2.0 in stage 1.0 (TID 22, localhost, executor driver, partition 2, ANY, 7888 bytes)
2021-12-06 15:15:30,200 [dispatcher-event-loop-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 3.0 in stage 1.0 (TID 23, localhost, executor driver, partition 3, ANY, 7888 bytes)
2021-12-06 15:15:30,200 [dispatcher-event-loop-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 4.0 in stage 1.0 (TID 24, localhost, executor driver, partition 4, ANY, 7888 bytes)
2021-12-06 15:15:30,200 [dispatcher-event-loop-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 5.0 in stage 1.0 (TID 25, localhost, executor driver, partition 5, ANY, 7888 bytes)
2021-12-06 15:15:30,201 [dispatcher-event-loop-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 6.0 in stage 1.0 (TID 26, localhost, executor driver, partition 6, ANY, 7888 bytes)
2021-12-06 15:15:30,201 [dispatcher-event-loop-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 7.0 in stage 1.0 (TID 27, localhost, executor driver, partition 7, ANY, 7888 bytes)
2021-12-06 15:15:30,201 [dispatcher-event-loop-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 8.0 in stage 1.0 (TID 28, localhost, executor driver, partition 8, ANY, 7888 bytes)
2021-12-06 15:15:30,201 [dispatcher-event-loop-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 9.0 in stage 1.0 (TID 29, localhost, executor driver, partition 9, ANY, 7888 bytes)
2021-12-06 15:15:30,201 [dispatcher-event-loop-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 10.0 in stage 1.0 (TID 30, localhost, executor driver, partition 10, ANY, 7888 bytes)
2021-12-06 15:15:30,201 [dispatcher-event-loop-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 11.0 in stage 1.0 (TID 31, localhost, executor driver, partition 11, ANY, 7888 bytes)
2021-12-06 15:15:30,202 [Executor task launch worker for task 20] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 1.0 (TID 20)
2021-12-06 15:15:30,202 [Executor task launch worker for task 22] INFO [org.apache.spark.executor.Executor] - Running task 2.0 in stage 1.0 (TID 22)
2021-12-06 15:15:30,202 [Executor task launch worker for task 27] INFO [org.apache.spark.executor.Executor] - Running task 7.0 in stage 1.0 (TID 27)
2021-12-06 15:15:30,202 [Executor task launch worker for task 26] INFO [org.apache.spark.executor.Executor] - Running task 6.0 in stage 1.0 (TID 26)
2021-12-06 15:15:30,202 [Executor task launch worker for task 21] INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 1.0 (TID 21)
2021-12-06 15:15:30,202 [Executor task launch worker for task 24] INFO [org.apache.spark.executor.Executor] - Running task 4.0 in stage 1.0 (TID 24)
2021-12-06 15:15:30,202 [Executor task launch worker for task 23] INFO [org.apache.spark.executor.Executor] - Running task 3.0 in stage 1.0 (TID 23)
2021-12-06 15:15:30,203 [Executor task launch worker for task 28] INFO [org.apache.spark.executor.Executor] - Running task 8.0 in stage 1.0 (TID 28)
2021-12-06 15:15:30,202 [Executor task launch worker for task 25] INFO [org.apache.spark.executor.Executor] - Running task 5.0 in stage 1.0 (TID 25)
2021-12-06 15:15:30,204 [Executor task launch worker for task 29] INFO [org.apache.spark.executor.Executor] - Running task 9.0 in stage 1.0 (TID 29)
2021-12-06 15:15:30,205 [Executor task launch worker for task 31] INFO [org.apache.spark.executor.Executor] - Running task 11.0 in stage 1.0 (TID 31)
2021-12-06 15:15:30,205 [Executor task launch worker for task 30] INFO [org.apache.spark.executor.Executor] - Running task 10.0 in stage 1.0 (TID 30)
2021-12-06 15:15:30,209 [Executor task launch worker for task 26] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:805306368+134217728
2021-12-06 15:15:30,209 [Executor task launch worker for task 23] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:402653184+134217728
2021-12-06 15:15:30,209 [Executor task launch worker for task 24] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:536870912+134217728
2021-12-06 15:15:30,209 [Executor task launch worker for task 20] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:0+134217728
2021-12-06 15:15:30,209 [Executor task launch worker for task 28] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:1073741824+134217728
2021-12-06 15:15:30,209 [Executor task launch worker for task 22] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:268435456+134217728
2021-12-06 15:15:30,209 [Executor task launch worker for task 21] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:134217728+134217728
2021-12-06 15:15:30,209 [Executor task launch worker for task 27] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:939524096+134217728
2021-12-06 15:15:30,209 [Executor task launch worker for task 30] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:1342177280+134217728
2021-12-06 15:15:30,209 [Executor task launch worker for task 31] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:1476395008+134217728
2021-12-06 15:15:30,209 [Executor task launch worker for task 25] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:671088640+134217728
2021-12-06 15:15:30,209 [Executor task launch worker for task 29] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:1207959552+134217728
2021-12-06 15:18:06,982 [Executor task launch worker for task 30] INFO [org.apache.spark.executor.Executor] - Finished task 10.0 in stage 1.0 (TID 30). 1050 bytes result sent to driver
2021-12-06 15:18:06,983 [dispatcher-event-loop-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 12.0 in stage 1.0 (TID 32, localhost, executor driver, partition 12, ANY, 7888 bytes)
2021-12-06 15:18:06,983 [Executor task launch worker for task 32] INFO [org.apache.spark.executor.Executor] - Running task 12.0 in stage 1.0 (TID 32)
2021-12-06 15:18:06,984 [Executor task launch worker for task 32] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:1610612736+134217728
2021-12-06 15:18:06,998 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 10.0 in stage 1.0 (TID 30) in 156797 ms on localhost (executor driver) (1/20)
2021-12-06 15:18:13,408 [Executor task launch worker for task 25] INFO [org.apache.spark.executor.Executor] - Finished task 5.0 in stage 1.0 (TID 25). 1093 bytes result sent to driver
2021-12-06 15:18:13,408 [dispatcher-event-loop-6] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 13.0 in stage 1.0 (TID 33, localhost, executor driver, partition 13, ANY, 7888 bytes)
2021-12-06 15:18:13,408 [Executor task launch worker for task 33] INFO [org.apache.spark.executor.Executor] - Running task 13.0 in stage 1.0 (TID 33)
2021-12-06 15:18:13,409 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 5.0 in stage 1.0 (TID 25) in 163209 ms on localhost (executor driver) (2/20)
2021-12-06 15:18:13,410 [Executor task launch worker for task 33] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:1744830464+134217728
2021-12-06 15:18:13,678 [Executor task launch worker for task 20] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 1.0 (TID 20). 1050 bytes result sent to driver
2021-12-06 15:18:13,678 [dispatcher-event-loop-7] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 14.0 in stage 1.0 (TID 34, localhost, executor driver, partition 14, ANY, 7888 bytes)
2021-12-06 15:18:13,679 [Executor task launch worker for task 34] INFO [org.apache.spark.executor.Executor] - Running task 14.0 in stage 1.0 (TID 34)
2021-12-06 15:18:13,679 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 1.0 (TID 20) in 163480 ms on localhost (executor driver) (3/20)
2021-12-06 15:18:13,680 [Executor task launch worker for task 34] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:1879048192+134217728
2021-12-06 15:18:13,836 [Executor task launch worker for task 26] INFO [org.apache.spark.executor.Executor] - Finished task 6.0 in stage 1.0 (TID 26). 1050 bytes result sent to driver
2021-12-06 15:18:13,836 [dispatcher-event-loop-9] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 15.0 in stage 1.0 (TID 35, localhost, executor driver, partition 15, ANY, 7888 bytes)
2021-12-06 15:18:13,836 [Executor task launch worker for task 35] INFO [org.apache.spark.executor.Executor] - Running task 15.0 in stage 1.0 (TID 35)
2021-12-06 15:18:13,837 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 6.0 in stage 1.0 (TID 26) in 163637 ms on localhost (executor driver) (4/20)
2021-12-06 15:18:13,837 [Executor task launch worker for task 35] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:2013265920+134217728
2021-12-06 15:18:19,972 [Executor task launch worker for task 24] INFO [org.apache.spark.executor.Executor] - Finished task 4.0 in stage 1.0 (TID 24). 1050 bytes result sent to driver
2021-12-06 15:18:19,972 [dispatcher-event-loop-11] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 16.0 in stage 1.0 (TID 36, localhost, executor driver, partition 16, ANY, 7888 bytes)
2021-12-06 15:18:19,972 [Executor task launch worker for task 36] INFO [org.apache.spark.executor.Executor] - Running task 16.0 in stage 1.0 (TID 36)
2021-12-06 15:18:19,972 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 4.0 in stage 1.0 (TID 24) in 169772 ms on localhost (executor driver) (5/20)
2021-12-06 15:18:19,973 [Executor task launch worker for task 36] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:2147483648+134217728
2021-12-06 15:18:30,356 [Executor task launch worker for task 21] INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 1.0 (TID 21). 1050 bytes result sent to driver
2021-12-06 15:18:30,356 [dispatcher-event-loop-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 17.0 in stage 1.0 (TID 37, localhost, executor driver, partition 17, ANY, 7888 bytes)
2021-12-06 15:18:30,356 [Executor task launch worker for task 37] INFO [org.apache.spark.executor.Executor] - Running task 17.0 in stage 1.0 (TID 37)
2021-12-06 15:18:30,356 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 1.0 (TID 21) in 180156 ms on localhost (executor driver) (6/20)
2021-12-06 15:18:30,357 [Executor task launch worker for task 37] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:2281701376+134217728
2021-12-06 15:18:30,791 [Executor task launch worker for task 22] INFO [org.apache.spark.executor.Executor] - Finished task 2.0 in stage 1.0 (TID 22). 1093 bytes result sent to driver
2021-12-06 15:18:30,791 [dispatcher-event-loop-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 18.0 in stage 1.0 (TID 38, localhost, executor driver, partition 18, ANY, 7888 bytes)
2021-12-06 15:18:30,792 [Executor task launch worker for task 38] INFO [org.apache.spark.executor.Executor] - Running task 18.0 in stage 1.0 (TID 38)
2021-12-06 15:18:30,792 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 2.0 in stage 1.0 (TID 22) in 180592 ms on localhost (executor driver) (7/20)
2021-12-06 15:18:30,792 [Executor task launch worker for task 38] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:2415919104+134217728
2021-12-06 15:18:34,541 [Executor task launch worker for task 23] INFO [org.apache.spark.executor.Executor] - Finished task 3.0 in stage 1.0 (TID 23). 1050 bytes result sent to driver
2021-12-06 15:18:34,542 [dispatcher-event-loop-4] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 19.0 in stage 1.0 (TID 39, localhost, executor driver, partition 19, ANY, 7888 bytes)
2021-12-06 15:18:34,542 [Executor task launch worker for task 39] INFO [org.apache.spark.executor.Executor] - Running task 19.0 in stage 1.0 (TID 39)
2021-12-06 15:18:34,542 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 3.0 in stage 1.0 (TID 23) in 184342 ms on localhost (executor driver) (8/20)
2021-12-06 15:18:34,543 [Executor task launch worker for task 39] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:2550136832+85027535
2021-12-06 15:18:42,404 [Executor task launch worker for task 27] INFO [org.apache.spark.executor.Executor] - Finished task 7.0 in stage 1.0 (TID 27). 1050 bytes result sent to driver
2021-12-06 15:18:42,478 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 7.0 in stage 1.0 (TID 27) in 192277 ms on localhost (executor driver) (9/20)
2021-12-06 15:18:42,881 [Executor task launch worker for task 31] INFO [org.apache.spark.executor.Executor] - Finished task 11.0 in stage 1.0 (TID 31). 1050 bytes result sent to driver
2021-12-06 15:18:42,882 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 11.0 in stage 1.0 (TID 31) in 192681 ms on localhost (executor driver) (10/20)
2021-12-06 15:18:46,567 [Executor task launch worker for task 29] INFO [org.apache.spark.executor.Executor] - Finished task 9.0 in stage 1.0 (TID 29). 1050 bytes result sent to driver
2021-12-06 15:18:46,568 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 9.0 in stage 1.0 (TID 29) in 196367 ms on localhost (executor driver) (11/20)
2021-12-06 15:18:46,644 [Executor task launch worker for task 28] INFO [org.apache.spark.executor.Executor] - Finished task 8.0 in stage 1.0 (TID 28). 1050 bytes result sent to driver
2021-12-06 15:18:46,645 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 8.0 in stage 1.0 (TID 28) in 196444 ms on localhost (executor driver) (12/20)
2021-12-06 15:19:59,019 [Executor task launch worker for task 32] INFO [org.apache.spark.executor.Executor] - Finished task 12.0 in stage 1.0 (TID 32). 1050 bytes result sent to driver
2021-12-06 15:19:59,020 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 12.0 in stage 1.0 (TID 32) in 112038 ms on localhost (executor driver) (13/20)
2021-12-06 15:20:09,370 [Executor task launch worker for task 35] INFO [org.apache.spark.executor.Executor] - Finished task 15.0 in stage 1.0 (TID 35). 1050 bytes result sent to driver
2021-12-06 15:20:09,370 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 15.0 in stage 1.0 (TID 35) in 115534 ms on localhost (executor driver) (14/20)
2021-12-06 15:20:12,649 [Executor task launch worker for task 36] INFO [org.apache.spark.executor.Executor] - Finished task 16.0 in stage 1.0 (TID 36). 1007 bytes result sent to driver
2021-12-06 15:20:12,649 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 16.0 in stage 1.0 (TID 36) in 112677 ms on localhost (executor driver) (15/20)
2021-12-06 15:20:13,838 [Executor task launch worker for task 39] INFO [org.apache.spark.executor.Executor] - Finished task 19.0 in stage 1.0 (TID 39). 1050 bytes result sent to driver
2021-12-06 15:20:13,838 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 19.0 in stage 1.0 (TID 39) in 99296 ms on localhost (executor driver) (16/20)
2021-12-06 15:20:19,219 [Executor task launch worker for task 34] INFO [org.apache.spark.executor.Executor] - Finished task 14.0 in stage 1.0 (TID 34). 1050 bytes result sent to driver
2021-12-06 15:20:19,220 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 14.0 in stage 1.0 (TID 34) in 125542 ms on localhost (executor driver) (17/20)
2021-12-06 15:20:23,997 [Executor task launch worker for task 38] INFO [org.apache.spark.executor.Executor] - Finished task 18.0 in stage 1.0 (TID 38). 1007 bytes result sent to driver
2021-12-06 15:20:23,997 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 18.0 in stage 1.0 (TID 38) in 113206 ms on localhost (executor driver) (18/20)
2021-12-06 15:20:25,820 [Executor task launch worker for task 33] INFO [org.apache.spark.executor.Executor] - Finished task 13.0 in stage 1.0 (TID 33). 1050 bytes result sent to driver
2021-12-06 15:20:25,820 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 13.0 in stage 1.0 (TID 33) in 132412 ms on localhost (executor driver) (19/20)
2021-12-06 15:20:27,746 [Executor task launch worker for task 37] INFO [org.apache.spark.executor.Executor] - Finished task 17.0 in stage 1.0 (TID 37). 1093 bytes result sent to driver
2021-12-06 15:20:27,747 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 17.0 in stage 1.0 (TID 37) in 117391 ms on localhost (executor driver) (20/20)
2021-12-06 15:20:27,747 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 1.0, whose tasks have all completed, from pool 
2021-12-06 15:20:27,747 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ShuffleMapStage 1 (map at PaidPromotionAdjustParameter.scala:67) finished in 297.562 s
2021-12-06 15:20:27,748 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - looking for newly runnable stages
2021-12-06 15:20:27,748 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - running: Set()
2021-12-06 15:20:27,748 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - waiting: Set(ResultStage 2)
2021-12-06 15:20:27,749 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - failed: Set()
2021-12-06 15:20:27,751 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 2 (ShuffledRDD[4] at reduceByKey at PaidPromotionAdjustParameter.scala:67), which has no missing parents
2021-12-06 15:20:27,756 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_3 stored as values in memory (estimated size 3.0 KB, free 1990.5 MB)
2021-12-06 15:20:27,758 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_3_piece0 stored as bytes in memory (estimated size 1907.0 B, free 1990.5 MB)
2021-12-06 15:20:27,758 [dispatcher-event-loop-11] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_3_piece0 in memory on qb:52204 (size: 1907.0 B, free: 1990.8 MB)
2021-12-06 15:20:27,759 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 3 from broadcast at DAGScheduler.scala:1039
2021-12-06 15:20:27,759 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 20 missing tasks from ResultStage 2 (ShuffledRDD[4] at reduceByKey at PaidPromotionAdjustParameter.scala:67) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14))
2021-12-06 15:20:27,759 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 2.0 with 20 tasks
2021-12-06 15:20:27,760 [dispatcher-event-loop-10] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 2.0 (TID 40, localhost, executor driver, partition 0, ANY, 7649 bytes)
2021-12-06 15:20:27,760 [dispatcher-event-loop-10] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 2.0 (TID 41, localhost, executor driver, partition 1, ANY, 7649 bytes)
2021-12-06 15:20:27,761 [dispatcher-event-loop-10] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 2.0 in stage 2.0 (TID 42, localhost, executor driver, partition 2, ANY, 7649 bytes)
2021-12-06 15:20:27,761 [dispatcher-event-loop-10] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 3.0 in stage 2.0 (TID 43, localhost, executor driver, partition 3, ANY, 7649 bytes)
2021-12-06 15:20:27,761 [dispatcher-event-loop-10] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 4.0 in stage 2.0 (TID 44, localhost, executor driver, partition 4, ANY, 7649 bytes)
2021-12-06 15:20:27,761 [dispatcher-event-loop-10] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 5.0 in stage 2.0 (TID 45, localhost, executor driver, partition 5, ANY, 7649 bytes)
2021-12-06 15:20:27,761 [dispatcher-event-loop-10] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 6.0 in stage 2.0 (TID 46, localhost, executor driver, partition 6, ANY, 7649 bytes)
2021-12-06 15:20:27,761 [dispatcher-event-loop-10] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 7.0 in stage 2.0 (TID 47, localhost, executor driver, partition 7, ANY, 7649 bytes)
2021-12-06 15:20:27,761 [dispatcher-event-loop-10] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 8.0 in stage 2.0 (TID 48, localhost, executor driver, partition 8, ANY, 7649 bytes)
2021-12-06 15:20:27,761 [dispatcher-event-loop-10] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 9.0 in stage 2.0 (TID 49, localhost, executor driver, partition 9, ANY, 7649 bytes)
2021-12-06 15:20:27,762 [dispatcher-event-loop-10] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 10.0 in stage 2.0 (TID 50, localhost, executor driver, partition 10, ANY, 7649 bytes)
2021-12-06 15:20:27,762 [dispatcher-event-loop-10] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 11.0 in stage 2.0 (TID 51, localhost, executor driver, partition 11, ANY, 7649 bytes)
2021-12-06 15:20:27,762 [Executor task launch worker for task 41] INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 2.0 (TID 41)
2021-12-06 15:20:27,762 [Executor task launch worker for task 42] INFO [org.apache.spark.executor.Executor] - Running task 2.0 in stage 2.0 (TID 42)
2021-12-06 15:20:27,762 [Executor task launch worker for task 47] INFO [org.apache.spark.executor.Executor] - Running task 7.0 in stage 2.0 (TID 47)
2021-12-06 15:20:27,762 [Executor task launch worker for task 46] INFO [org.apache.spark.executor.Executor] - Running task 6.0 in stage 2.0 (TID 46)
2021-12-06 15:20:27,762 [Executor task launch worker for task 45] INFO [org.apache.spark.executor.Executor] - Running task 5.0 in stage 2.0 (TID 45)
2021-12-06 15:20:27,762 [Executor task launch worker for task 44] INFO [org.apache.spark.executor.Executor] - Running task 4.0 in stage 2.0 (TID 44)
2021-12-06 15:20:27,762 [Executor task launch worker for task 43] INFO [org.apache.spark.executor.Executor] - Running task 3.0 in stage 2.0 (TID 43)
2021-12-06 15:20:27,762 [Executor task launch worker for task 40] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 2.0 (TID 40)
2021-12-06 15:20:27,763 [Executor task launch worker for task 50] INFO [org.apache.spark.executor.Executor] - Running task 10.0 in stage 2.0 (TID 50)
2021-12-06 15:20:27,763 [Executor task launch worker for task 48] INFO [org.apache.spark.executor.Executor] - Running task 8.0 in stage 2.0 (TID 48)
2021-12-06 15:20:27,763 [Executor task launch worker for task 49] INFO [org.apache.spark.executor.Executor] - Running task 9.0 in stage 2.0 (TID 49)
2021-12-06 15:20:27,763 [Executor task launch worker for task 51] INFO [org.apache.spark.executor.Executor] - Running task 11.0 in stage 2.0 (TID 51)
2021-12-06 15:20:27,777 [Executor task launch worker for task 43] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 20 non-empty blocks out of 20 blocks
2021-12-06 15:20:27,777 [Executor task launch worker for task 51] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 20 non-empty blocks out of 20 blocks
2021-12-06 15:20:27,777 [Executor task launch worker for task 41] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 20 non-empty blocks out of 20 blocks
2021-12-06 15:20:27,777 [Executor task launch worker for task 49] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 20 non-empty blocks out of 20 blocks
2021-12-06 15:20:27,777 [Executor task launch worker for task 44] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 20 non-empty blocks out of 20 blocks
2021-12-06 15:20:27,777 [Executor task launch worker for task 45] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 20 non-empty blocks out of 20 blocks
2021-12-06 15:20:27,777 [Executor task launch worker for task 40] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 20 non-empty blocks out of 20 blocks
2021-12-06 15:20:27,777 [Executor task launch worker for task 47] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 20 non-empty blocks out of 20 blocks
2021-12-06 15:20:27,777 [Executor task launch worker for task 50] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 20 non-empty blocks out of 20 blocks
2021-12-06 15:20:27,777 [Executor task launch worker for task 42] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 20 non-empty blocks out of 20 blocks
2021-12-06 15:20:27,777 [Executor task launch worker for task 48] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 20 non-empty blocks out of 20 blocks
2021-12-06 15:20:27,777 [Executor task launch worker for task 46] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 20 non-empty blocks out of 20 blocks
2021-12-06 15:20:27,779 [Executor task launch worker for task 40] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 7 ms
2021-12-06 15:20:27,779 [Executor task launch worker for task 43] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 7 ms
2021-12-06 15:20:27,779 [Executor task launch worker for task 47] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 7 ms
2021-12-06 15:20:27,779 [Executor task launch worker for task 46] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 7 ms
2021-12-06 15:20:27,779 [Executor task launch worker for task 42] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 6 ms
2021-12-06 15:20:27,779 [Executor task launch worker for task 48] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 7 ms
2021-12-06 15:20:27,779 [Executor task launch worker for task 49] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 7 ms
2021-12-06 15:20:27,779 [Executor task launch worker for task 41] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 7 ms
2021-12-06 15:20:27,779 [Executor task launch worker for task 50] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 7 ms
2021-12-06 15:20:27,779 [Executor task launch worker for task 51] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 7 ms
2021-12-06 15:20:27,779 [Executor task launch worker for task 44] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 7 ms
2021-12-06 15:20:27,780 [Executor task launch worker for task 45] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 8 ms
2021-12-06 15:20:27,926 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 2
2021-12-06 15:20:27,926 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 4
2021-12-06 15:20:27,926 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1
2021-12-06 15:20:27,926 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 3
2021-12-06 15:20:27,926 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 16
2021-12-06 15:20:27,926 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 18
2021-12-06 15:20:27,926 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 6
2021-12-06 15:20:27,927 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 21
2021-12-06 15:20:27,927 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 19
2021-12-06 15:20:27,927 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 15
2021-12-06 15:20:27,927 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 0
2021-12-06 15:20:27,927 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 11
2021-12-06 15:20:27,927 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 7
2021-12-06 15:20:27,944 [dispatcher-event-loop-2] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_1_piece0 on qb:52204 in memory (size: 1903.0 B, free: 1990.8 MB)
2021-12-06 15:20:27,947 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 14
2021-12-06 15:20:27,947 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 22
2021-12-06 15:20:27,947 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 13
2021-12-06 15:20:27,947 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 23
2021-12-06 15:20:27,947 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 20
2021-12-06 15:20:27,947 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 5
2021-12-06 15:20:27,947 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 12
2021-12-06 15:20:27,947 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 8
2021-12-06 15:20:27,947 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 24
2021-12-06 15:20:27,947 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 9
2021-12-06 15:20:27,954 [dispatcher-event-loop-7] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_2_piece0 on qb:52204 in memory (size: 2.7 KB, free: 1990.8 MB)
2021-12-06 15:20:27,956 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 17
2021-12-06 15:20:27,956 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 10
2021-12-06 15:20:28,217 [Executor task launch worker for task 45] INFO [org.apache.spark.executor.Executor] - Finished task 5.0 in stage 2.0 (TID 45). 1098 bytes result sent to driver
2021-12-06 15:20:28,219 [dispatcher-event-loop-8] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 12.0 in stage 2.0 (TID 52, localhost, executor driver, partition 12, ANY, 7649 bytes)
2021-12-06 15:20:28,219 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 5.0 in stage 2.0 (TID 45) in 458 ms on localhost (executor driver) (1/20)
2021-12-06 15:20:28,219 [Executor task launch worker for task 52] INFO [org.apache.spark.executor.Executor] - Running task 12.0 in stage 2.0 (TID 52)
2021-12-06 15:20:28,220 [Executor task launch worker for task 52] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 20 non-empty blocks out of 20 blocks
2021-12-06 15:20:28,221 [Executor task launch worker for task 52] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 1 ms
2021-12-06 15:20:28,222 [Executor task launch worker for task 50] INFO [org.apache.spark.executor.Executor] - Finished task 10.0 in stage 2.0 (TID 50). 1098 bytes result sent to driver
2021-12-06 15:20:28,222 [Executor task launch worker for task 48] INFO [org.apache.spark.executor.Executor] - Finished task 8.0 in stage 2.0 (TID 48). 1055 bytes result sent to driver
2021-12-06 15:20:28,223 [dispatcher-event-loop-9] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 13.0 in stage 2.0 (TID 53, localhost, executor driver, partition 13, ANY, 7649 bytes)
2021-12-06 15:20:28,223 [dispatcher-event-loop-9] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 14.0 in stage 2.0 (TID 54, localhost, executor driver, partition 14, ANY, 7649 bytes)
2021-12-06 15:20:28,224 [Executor task launch worker for task 54] INFO [org.apache.spark.executor.Executor] - Running task 14.0 in stage 2.0 (TID 54)
2021-12-06 15:20:28,224 [Executor task launch worker for task 53] INFO [org.apache.spark.executor.Executor] - Running task 13.0 in stage 2.0 (TID 53)
2021-12-06 15:20:28,224 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 8.0 in stage 2.0 (TID 48) in 463 ms on localhost (executor driver) (2/20)
2021-12-06 15:20:28,225 [Executor task launch worker for task 54] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 20 non-empty blocks out of 20 blocks
2021-12-06 15:20:28,225 [Executor task launch worker for task 54] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 1 ms
2021-12-06 15:20:28,225 [Executor task launch worker for task 53] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 20 non-empty blocks out of 20 blocks
2021-12-06 15:20:28,225 [Executor task launch worker for task 53] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-06 15:20:28,225 [Executor task launch worker for task 49] INFO [org.apache.spark.executor.Executor] - Finished task 9.0 in stage 2.0 (TID 49). 1098 bytes result sent to driver
2021-12-06 15:20:28,225 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 10.0 in stage 2.0 (TID 50) in 464 ms on localhost (executor driver) (3/20)
2021-12-06 15:20:28,226 [dispatcher-event-loop-5] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 15.0 in stage 2.0 (TID 55, localhost, executor driver, partition 15, ANY, 7649 bytes)
2021-12-06 15:20:28,226 [Executor task launch worker for task 55] INFO [org.apache.spark.executor.Executor] - Running task 15.0 in stage 2.0 (TID 55)
2021-12-06 15:20:28,226 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 9.0 in stage 2.0 (TID 49) in 465 ms on localhost (executor driver) (4/20)
2021-12-06 15:20:28,227 [Executor task launch worker for task 55] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 20 non-empty blocks out of 20 blocks
2021-12-06 15:20:28,227 [Executor task launch worker for task 55] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-06 15:20:28,228 [Executor task launch worker for task 44] INFO [org.apache.spark.executor.Executor] - Finished task 4.0 in stage 2.0 (TID 44). 1098 bytes result sent to driver
2021-12-06 15:20:28,229 [dispatcher-event-loop-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 16.0 in stage 2.0 (TID 56, localhost, executor driver, partition 16, ANY, 7649 bytes)
2021-12-06 15:20:28,229 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 4.0 in stage 2.0 (TID 44) in 468 ms on localhost (executor driver) (5/20)
2021-12-06 15:20:28,230 [Executor task launch worker for task 56] INFO [org.apache.spark.executor.Executor] - Running task 16.0 in stage 2.0 (TID 56)
2021-12-06 15:20:28,230 [Executor task launch worker for task 42] INFO [org.apache.spark.executor.Executor] - Finished task 2.0 in stage 2.0 (TID 42). 1098 bytes result sent to driver
2021-12-06 15:20:28,231 [Executor task launch worker for task 56] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 20 non-empty blocks out of 20 blocks
2021-12-06 15:20:28,231 [Executor task launch worker for task 56] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-06 15:20:28,231 [dispatcher-event-loop-6] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 17.0 in stage 2.0 (TID 57, localhost, executor driver, partition 17, ANY, 7649 bytes)
2021-12-06 15:20:28,232 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 2.0 in stage 2.0 (TID 42) in 471 ms on localhost (executor driver) (6/20)
2021-12-06 15:20:28,232 [Executor task launch worker for task 57] INFO [org.apache.spark.executor.Executor] - Running task 17.0 in stage 2.0 (TID 57)
2021-12-06 15:20:28,233 [Executor task launch worker for task 57] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 20 non-empty blocks out of 20 blocks
2021-12-06 15:20:28,233 [Executor task launch worker for task 57] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-06 15:20:28,234 [Executor task launch worker for task 43] INFO [org.apache.spark.executor.Executor] - Finished task 3.0 in stage 2.0 (TID 43). 1098 bytes result sent to driver
2021-12-06 15:20:28,234 [dispatcher-event-loop-8] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 18.0 in stage 2.0 (TID 58, localhost, executor driver, partition 18, ANY, 7649 bytes)
2021-12-06 15:20:28,235 [Executor task launch worker for task 58] INFO [org.apache.spark.executor.Executor] - Running task 18.0 in stage 2.0 (TID 58)
2021-12-06 15:20:28,235 [Executor task launch worker for task 41] INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 2.0 (TID 41). 1098 bytes result sent to driver
2021-12-06 15:20:28,236 [Executor task launch worker for task 47] INFO [org.apache.spark.executor.Executor] - Finished task 7.0 in stage 2.0 (TID 47). 1098 bytes result sent to driver
2021-12-06 15:20:28,236 [Executor task launch worker for task 58] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 20 non-empty blocks out of 20 blocks
2021-12-06 15:20:28,236 [Executor task launch worker for task 58] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-06 15:20:28,236 [Executor task launch worker for task 40] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 2.0 (TID 40). 1098 bytes result sent to driver
2021-12-06 15:20:28,237 [Executor task launch worker for task 51] INFO [org.apache.spark.executor.Executor] - Finished task 11.0 in stage 2.0 (TID 51). 1098 bytes result sent to driver
2021-12-06 15:20:28,237 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 3.0 in stage 2.0 (TID 43) in 476 ms on localhost (executor driver) (7/20)
2021-12-06 15:20:28,238 [dispatcher-event-loop-10] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 19.0 in stage 2.0 (TID 59, localhost, executor driver, partition 19, ANY, 7649 bytes)
2021-12-06 15:20:28,238 [Executor task launch worker for task 59] INFO [org.apache.spark.executor.Executor] - Running task 19.0 in stage 2.0 (TID 59)
2021-12-06 15:20:28,238 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 2.0 (TID 41) in 478 ms on localhost (executor driver) (8/20)
2021-12-06 15:20:28,239 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 7.0 in stage 2.0 (TID 47) in 478 ms on localhost (executor driver) (9/20)
2021-12-06 15:20:28,239 [Executor task launch worker for task 59] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 20 non-empty blocks out of 20 blocks
2021-12-06 15:20:28,239 [Executor task launch worker for task 59] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-06 15:20:28,239 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 2.0 (TID 40) in 479 ms on localhost (executor driver) (10/20)
2021-12-06 15:20:28,239 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 11.0 in stage 2.0 (TID 51) in 477 ms on localhost (executor driver) (11/20)
2021-12-06 15:20:28,240 [Executor task launch worker for task 46] INFO [org.apache.spark.executor.Executor] - Finished task 6.0 in stage 2.0 (TID 46). 1098 bytes result sent to driver
2021-12-06 15:20:28,241 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 6.0 in stage 2.0 (TID 46) in 480 ms on localhost (executor driver) (12/20)
2021-12-06 15:20:28,311 [Executor task launch worker for task 52] INFO [org.apache.spark.executor.Executor] - Finished task 12.0 in stage 2.0 (TID 52). 1098 bytes result sent to driver
2021-12-06 15:20:28,312 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 12.0 in stage 2.0 (TID 52) in 92 ms on localhost (executor driver) (13/20)
2021-12-06 15:20:28,319 [Executor task launch worker for task 54] INFO [org.apache.spark.executor.Executor] - Finished task 14.0 in stage 2.0 (TID 54). 1055 bytes result sent to driver
2021-12-06 15:20:28,319 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 14.0 in stage 2.0 (TID 54) in 96 ms on localhost (executor driver) (14/20)
2021-12-06 15:20:28,333 [Executor task launch worker for task 53] INFO [org.apache.spark.executor.Executor] - Finished task 13.0 in stage 2.0 (TID 53). 1098 bytes result sent to driver
2021-12-06 15:20:28,334 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 13.0 in stage 2.0 (TID 53) in 111 ms on localhost (executor driver) (15/20)
2021-12-06 15:20:28,335 [Executor task launch worker for task 57] INFO [org.apache.spark.executor.Executor] - Finished task 17.0 in stage 2.0 (TID 57). 1098 bytes result sent to driver
2021-12-06 15:20:28,335 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 17.0 in stage 2.0 (TID 57) in 104 ms on localhost (executor driver) (16/20)
2021-12-06 15:20:28,335 [Executor task launch worker for task 55] INFO [org.apache.spark.executor.Executor] - Finished task 15.0 in stage 2.0 (TID 55). 1098 bytes result sent to driver
2021-12-06 15:20:28,336 [Executor task launch worker for task 59] INFO [org.apache.spark.executor.Executor] - Finished task 19.0 in stage 2.0 (TID 59). 1098 bytes result sent to driver
2021-12-06 15:20:28,336 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 15.0 in stage 2.0 (TID 55) in 111 ms on localhost (executor driver) (17/20)
2021-12-06 15:20:28,336 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 19.0 in stage 2.0 (TID 59) in 98 ms on localhost (executor driver) (18/20)
2021-12-06 15:20:28,337 [Executor task launch worker for task 58] INFO [org.apache.spark.executor.Executor] - Finished task 18.0 in stage 2.0 (TID 58). 1055 bytes result sent to driver
2021-12-06 15:20:28,337 [Executor task launch worker for task 56] INFO [org.apache.spark.executor.Executor] - Finished task 16.0 in stage 2.0 (TID 56). 1098 bytes result sent to driver
2021-12-06 15:20:28,337 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 18.0 in stage 2.0 (TID 58) in 103 ms on localhost (executor driver) (19/20)
2021-12-06 15:20:28,337 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 16.0 in stage 2.0 (TID 56) in 108 ms on localhost (executor driver) (20/20)
2021-12-06 15:20:28,337 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 2.0, whose tasks have all completed, from pool 
2021-12-06 15:20:28,337 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 2 (count at PaidPromotionAdjustParameter.scala:68) finished in 0.583 s
2021-12-06 15:20:28,337 [main] INFO [org.apache.spark.scheduler.DAGScheduler] - Job 1 finished: count at PaidPromotionAdjustParameter.scala:68, took 298.162826 s
2021-12-06 15:20:28,338 [main] INFO [PaidPromotion$] - 627740
2021-12-06 15:20:28,357 [main] INFO [org.apache.spark.SparkContext] - Starting job: sortByKey at PaidPromotionAdjustParameter.scala:73
2021-12-06 15:20:28,357 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 2 (sortByKey at PaidPromotionAdjustParameter.scala:73) with 20 output partitions
2021-12-06 15:20:28,357 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 4 (sortByKey at PaidPromotionAdjustParameter.scala:73)
2021-12-06 15:20:28,357 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 3)
2021-12-06 15:20:28,357 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2021-12-06 15:20:28,358 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 4 (MapPartitionsRDD[7] at sortByKey at PaidPromotionAdjustParameter.scala:73), which has no missing parents
2021-12-06 15:20:28,360 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_4 stored as values in memory (estimated size 4.1 KB, free 1990.5 MB)
2021-12-06 15:20:28,362 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_4_piece0 stored as bytes in memory (estimated size 2.4 KB, free 1990.5 MB)
2021-12-06 15:20:28,363 [dispatcher-event-loop-0] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_4_piece0 in memory on qb:52204 (size: 2.4 KB, free: 1990.8 MB)
2021-12-06 15:20:28,363 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 4 from broadcast at DAGScheduler.scala:1039
2021-12-06 15:20:28,363 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 20 missing tasks from ResultStage 4 (MapPartitionsRDD[7] at sortByKey at PaidPromotionAdjustParameter.scala:73) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14))
2021-12-06 15:20:28,363 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 4.0 with 20 tasks
2021-12-06 15:20:28,364 [dispatcher-event-loop-5] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 4.0 (TID 60, localhost, executor driver, partition 0, ANY, 7649 bytes)
2021-12-06 15:20:28,364 [dispatcher-event-loop-5] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 4.0 (TID 61, localhost, executor driver, partition 1, ANY, 7649 bytes)
2021-12-06 15:20:28,364 [dispatcher-event-loop-5] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 2.0 in stage 4.0 (TID 62, localhost, executor driver, partition 2, ANY, 7649 bytes)
2021-12-06 15:20:28,364 [dispatcher-event-loop-5] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 3.0 in stage 4.0 (TID 63, localhost, executor driver, partition 3, ANY, 7649 bytes)
2021-12-06 15:20:28,364 [dispatcher-event-loop-5] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 4.0 in stage 4.0 (TID 64, localhost, executor driver, partition 4, ANY, 7649 bytes)
2021-12-06 15:20:28,364 [dispatcher-event-loop-5] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 5.0 in stage 4.0 (TID 65, localhost, executor driver, partition 5, ANY, 7649 bytes)
2021-12-06 15:20:28,364 [dispatcher-event-loop-5] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 6.0 in stage 4.0 (TID 66, localhost, executor driver, partition 6, ANY, 7649 bytes)
2021-12-06 15:20:28,364 [dispatcher-event-loop-5] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 7.0 in stage 4.0 (TID 67, localhost, executor driver, partition 7, ANY, 7649 bytes)
2021-12-06 15:20:28,364 [dispatcher-event-loop-5] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 8.0 in stage 4.0 (TID 68, localhost, executor driver, partition 8, ANY, 7649 bytes)
2021-12-06 15:20:28,365 [dispatcher-event-loop-5] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 9.0 in stage 4.0 (TID 69, localhost, executor driver, partition 9, ANY, 7649 bytes)
2021-12-06 15:20:28,365 [dispatcher-event-loop-5] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 10.0 in stage 4.0 (TID 70, localhost, executor driver, partition 10, ANY, 7649 bytes)
2021-12-06 15:20:28,365 [dispatcher-event-loop-5] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 11.0 in stage 4.0 (TID 71, localhost, executor driver, partition 11, ANY, 7649 bytes)
2021-12-06 15:20:28,365 [Executor task launch worker for task 60] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 4.0 (TID 60)
2021-12-06 15:20:28,365 [Executor task launch worker for task 63] INFO [org.apache.spark.executor.Executor] - Running task 3.0 in stage 4.0 (TID 63)
2021-12-06 15:20:28,365 [Executor task launch worker for task 68] INFO [org.apache.spark.executor.Executor] - Running task 8.0 in stage 4.0 (TID 68)
2021-12-06 15:20:28,365 [Executor task launch worker for task 65] INFO [org.apache.spark.executor.Executor] - Running task 5.0 in stage 4.0 (TID 65)
2021-12-06 15:20:28,365 [Executor task launch worker for task 67] INFO [org.apache.spark.executor.Executor] - Running task 7.0 in stage 4.0 (TID 67)
2021-12-06 15:20:28,365 [Executor task launch worker for task 64] INFO [org.apache.spark.executor.Executor] - Running task 4.0 in stage 4.0 (TID 64)
2021-12-06 15:20:28,365 [Executor task launch worker for task 62] INFO [org.apache.spark.executor.Executor] - Running task 2.0 in stage 4.0 (TID 62)
2021-12-06 15:20:28,365 [Executor task launch worker for task 66] INFO [org.apache.spark.executor.Executor] - Running task 6.0 in stage 4.0 (TID 66)
2021-12-06 15:20:28,365 [Executor task launch worker for task 61] INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 4.0 (TID 61)
2021-12-06 15:20:28,365 [Executor task launch worker for task 70] INFO [org.apache.spark.executor.Executor] - Running task 10.0 in stage 4.0 (TID 70)
2021-12-06 15:20:28,365 [Executor task launch worker for task 69] INFO [org.apache.spark.executor.Executor] - Running task 9.0 in stage 4.0 (TID 69)
2021-12-06 15:20:28,365 [Executor task launch worker for task 71] INFO [org.apache.spark.executor.Executor] - Running task 11.0 in stage 4.0 (TID 71)
2021-12-06 15:20:28,367 [Executor task launch worker for task 63] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 20 non-empty blocks out of 20 blocks
2021-12-06 15:20:28,367 [Executor task launch worker for task 63] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-06 15:20:28,367 [Executor task launch worker for task 71] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 20 non-empty blocks out of 20 blocks
2021-12-06 15:20:28,367 [Executor task launch worker for task 67] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 20 non-empty blocks out of 20 blocks
2021-12-06 15:20:28,367 [Executor task launch worker for task 71] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-06 15:20:28,367 [Executor task launch worker for task 65] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 20 non-empty blocks out of 20 blocks
2021-12-06 15:20:28,367 [Executor task launch worker for task 67] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-06 15:20:28,367 [Executor task launch worker for task 65] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-06 15:20:28,367 [Executor task launch worker for task 70] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 20 non-empty blocks out of 20 blocks
2021-12-06 15:20:28,367 [Executor task launch worker for task 70] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-06 15:20:28,367 [Executor task launch worker for task 68] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 20 non-empty blocks out of 20 blocks
2021-12-06 15:20:28,367 [Executor task launch worker for task 66] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 20 non-empty blocks out of 20 blocks
2021-12-06 15:20:28,367 [Executor task launch worker for task 68] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-06 15:20:28,367 [Executor task launch worker for task 62] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 20 non-empty blocks out of 20 blocks
2021-12-06 15:20:28,367 [Executor task launch worker for task 60] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 20 non-empty blocks out of 20 blocks
2021-12-06 15:20:28,367 [Executor task launch worker for task 66] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-06 15:20:28,367 [Executor task launch worker for task 60] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-06 15:20:28,367 [Executor task launch worker for task 62] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-06 15:20:28,367 [Executor task launch worker for task 69] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 20 non-empty blocks out of 20 blocks
2021-12-06 15:20:28,367 [Executor task launch worker for task 69] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-06 15:20:28,367 [Executor task launch worker for task 61] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 20 non-empty blocks out of 20 blocks
2021-12-06 15:20:28,367 [Executor task launch worker for task 64] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 20 non-empty blocks out of 20 blocks
2021-12-06 15:20:28,367 [Executor task launch worker for task 61] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-06 15:20:28,367 [Executor task launch worker for task 64] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-06 15:20:28,459 [Executor task launch worker for task 63] INFO [org.apache.spark.executor.Executor] - Finished task 3.0 in stage 4.0 (TID 63). 1164 bytes result sent to driver
2021-12-06 15:20:28,459 [Executor task launch worker for task 67] INFO [org.apache.spark.executor.Executor] - Finished task 7.0 in stage 4.0 (TID 67). 1153 bytes result sent to driver
2021-12-06 15:20:28,478 [dispatcher-event-loop-10] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 12.0 in stage 4.0 (TID 72, localhost, executor driver, partition 12, ANY, 7649 bytes)
2021-12-06 15:20:28,478 [Executor task launch worker for task 72] INFO [org.apache.spark.executor.Executor] - Running task 12.0 in stage 4.0 (TID 72)
2021-12-06 15:20:28,479 [dispatcher-event-loop-10] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 13.0 in stage 4.0 (TID 73, localhost, executor driver, partition 13, ANY, 7649 bytes)
2021-12-06 15:20:28,479 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 3.0 in stage 4.0 (TID 63) in 115 ms on localhost (executor driver) (1/20)
2021-12-06 15:20:28,479 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 7.0 in stage 4.0 (TID 67) in 115 ms on localhost (executor driver) (2/20)
2021-12-06 15:20:28,480 [Executor task launch worker for task 65] INFO [org.apache.spark.executor.Executor] - Finished task 5.0 in stage 4.0 (TID 65). 1161 bytes result sent to driver
2021-12-06 15:20:28,480 [Executor task launch worker for task 70] INFO [org.apache.spark.executor.Executor] - Finished task 10.0 in stage 4.0 (TID 70). 1193 bytes result sent to driver
2021-12-06 15:20:28,480 [dispatcher-event-loop-10] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 14.0 in stage 4.0 (TID 74, localhost, executor driver, partition 14, ANY, 7649 bytes)
2021-12-06 15:20:28,481 [Executor task launch worker for task 71] INFO [org.apache.spark.executor.Executor] - Finished task 11.0 in stage 4.0 (TID 71). 1203 bytes result sent to driver
2021-12-06 15:20:28,481 [dispatcher-event-loop-10] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 15.0 in stage 4.0 (TID 75, localhost, executor driver, partition 15, ANY, 7649 bytes)
2021-12-06 15:20:28,481 [Executor task launch worker for task 69] INFO [org.apache.spark.executor.Executor] - Finished task 9.0 in stage 4.0 (TID 69). 1203 bytes result sent to driver
2021-12-06 15:20:28,481 [Executor task launch worker for task 72] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 20 non-empty blocks out of 20 blocks
2021-12-06 15:20:28,481 [Executor task launch worker for task 73] INFO [org.apache.spark.executor.Executor] - Running task 13.0 in stage 4.0 (TID 73)
2021-12-06 15:20:28,481 [Executor task launch worker for task 72] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-06 15:20:28,481 [dispatcher-event-loop-10] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 16.0 in stage 4.0 (TID 76, localhost, executor driver, partition 16, ANY, 7649 bytes)
2021-12-06 15:20:28,481 [Executor task launch worker for task 74] INFO [org.apache.spark.executor.Executor] - Running task 14.0 in stage 4.0 (TID 74)
2021-12-06 15:20:28,482 [Executor task launch worker for task 75] INFO [org.apache.spark.executor.Executor] - Running task 15.0 in stage 4.0 (TID 75)
2021-12-06 15:20:28,482 [Executor task launch worker for task 76] INFO [org.apache.spark.executor.Executor] - Running task 16.0 in stage 4.0 (TID 76)
2021-12-06 15:20:28,481 [dispatcher-event-loop-10] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 17.0 in stage 4.0 (TID 77, localhost, executor driver, partition 17, ANY, 7649 bytes)
2021-12-06 15:20:28,483 [Executor task launch worker for task 73] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 20 non-empty blocks out of 20 blocks
2021-12-06 15:20:28,483 [Executor task launch worker for task 77] INFO [org.apache.spark.executor.Executor] - Running task 17.0 in stage 4.0 (TID 77)
2021-12-06 15:20:28,483 [Executor task launch worker for task 75] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 20 non-empty blocks out of 20 blocks
2021-12-06 15:20:28,483 [Executor task launch worker for task 75] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-06 15:20:28,484 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 5.0 in stage 4.0 (TID 65) in 120 ms on localhost (executor driver) (3/20)
2021-12-06 15:20:28,484 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 11.0 in stage 4.0 (TID 71) in 119 ms on localhost (executor driver) (4/20)
2021-12-06 15:20:28,486 [Executor task launch worker for task 61] INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 4.0 (TID 61). 1205 bytes result sent to driver
2021-12-06 15:20:28,486 [Executor task launch worker for task 74] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 20 non-empty blocks out of 20 blocks
2021-12-06 15:20:28,486 [Executor task launch worker for task 74] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-06 15:20:28,486 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 9.0 in stage 4.0 (TID 69) in 122 ms on localhost (executor driver) (5/20)
2021-12-06 15:20:28,483 [Executor task launch worker for task 73] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-06 15:20:28,487 [dispatcher-event-loop-6] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 18.0 in stage 4.0 (TID 78, localhost, executor driver, partition 18, ANY, 7649 bytes)
2021-12-06 15:20:28,487 [Executor task launch worker for task 77] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 20 non-empty blocks out of 20 blocks
2021-12-06 15:20:28,487 [Executor task launch worker for task 77] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-06 15:20:28,483 [Executor task launch worker for task 76] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 20 non-empty blocks out of 20 blocks
2021-12-06 15:20:28,487 [Executor task launch worker for task 76] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 4 ms
2021-12-06 15:20:28,487 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 10.0 in stage 4.0 (TID 70) in 122 ms on localhost (executor driver) (6/20)
2021-12-06 15:20:28,488 [Executor task launch worker for task 78] INFO [org.apache.spark.executor.Executor] - Running task 18.0 in stage 4.0 (TID 78)
2021-12-06 15:20:28,488 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 4.0 (TID 61) in 124 ms on localhost (executor driver) (7/20)
2021-12-06 15:20:28,488 [Executor task launch worker for task 68] INFO [org.apache.spark.executor.Executor] - Finished task 8.0 in stage 4.0 (TID 68). 1201 bytes result sent to driver
2021-12-06 15:20:28,488 [Executor task launch worker for task 64] INFO [org.apache.spark.executor.Executor] - Finished task 4.0 in stage 4.0 (TID 64). 1201 bytes result sent to driver
2021-12-06 15:20:28,489 [dispatcher-event-loop-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 19.0 in stage 4.0 (TID 79, localhost, executor driver, partition 19, ANY, 7649 bytes)
2021-12-06 15:20:28,489 [Executor task launch worker for task 78] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 20 non-empty blocks out of 20 blocks
2021-12-06 15:20:28,489 [Executor task launch worker for task 78] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-06 15:20:28,489 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 8.0 in stage 4.0 (TID 68) in 125 ms on localhost (executor driver) (8/20)
2021-12-06 15:20:28,490 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 4.0 in stage 4.0 (TID 64) in 126 ms on localhost (executor driver) (9/20)
2021-12-06 15:20:28,490 [Executor task launch worker for task 79] INFO [org.apache.spark.executor.Executor] - Running task 19.0 in stage 4.0 (TID 79)
2021-12-06 15:20:28,491 [Executor task launch worker for task 79] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 20 non-empty blocks out of 20 blocks
2021-12-06 15:20:28,491 [Executor task launch worker for task 79] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-06 15:20:28,495 [Executor task launch worker for task 66] INFO [org.apache.spark.executor.Executor] - Finished task 6.0 in stage 4.0 (TID 66). 1158 bytes result sent to driver
2021-12-06 15:20:28,495 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 6.0 in stage 4.0 (TID 66) in 131 ms on localhost (executor driver) (10/20)
2021-12-06 15:20:28,496 [Executor task launch worker for task 62] INFO [org.apache.spark.executor.Executor] - Finished task 2.0 in stage 4.0 (TID 62). 1153 bytes result sent to driver
2021-12-06 15:20:28,496 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 2.0 in stage 4.0 (TID 62) in 132 ms on localhost (executor driver) (11/20)
2021-12-06 15:20:28,499 [Executor task launch worker for task 60] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 4.0 (TID 60). 1201 bytes result sent to driver
2021-12-06 15:20:28,504 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 4.0 (TID 60) in 141 ms on localhost (executor driver) (12/20)
2021-12-06 15:20:28,553 [Executor task launch worker for task 72] INFO [org.apache.spark.executor.Executor] - Finished task 12.0 in stage 4.0 (TID 72). 1243 bytes result sent to driver
2021-12-06 15:20:28,554 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 12.0 in stage 4.0 (TID 72) in 76 ms on localhost (executor driver) (13/20)
2021-12-06 15:20:28,564 [Executor task launch worker for task 76] INFO [org.apache.spark.executor.Executor] - Finished task 16.0 in stage 4.0 (TID 76). 1198 bytes result sent to driver
2021-12-06 15:20:28,564 [Executor task launch worker for task 75] INFO [org.apache.spark.executor.Executor] - Finished task 15.0 in stage 4.0 (TID 75). 1159 bytes result sent to driver
2021-12-06 15:20:28,565 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 16.0 in stage 4.0 (TID 76) in 84 ms on localhost (executor driver) (14/20)
2021-12-06 15:20:28,565 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 15.0 in stage 4.0 (TID 75) in 84 ms on localhost (executor driver) (15/20)
2021-12-06 15:20:28,565 [Executor task launch worker for task 77] INFO [org.apache.spark.executor.Executor] - Finished task 17.0 in stage 4.0 (TID 77). 1205 bytes result sent to driver
2021-12-06 15:20:28,565 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 17.0 in stage 4.0 (TID 77) in 84 ms on localhost (executor driver) (16/20)
2021-12-06 15:20:28,567 [Executor task launch worker for task 73] INFO [org.apache.spark.executor.Executor] - Finished task 13.0 in stage 4.0 (TID 73). 1200 bytes result sent to driver
2021-12-06 15:20:28,567 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 13.0 in stage 4.0 (TID 73) in 89 ms on localhost (executor driver) (17/20)
2021-12-06 15:20:28,567 [Executor task launch worker for task 78] INFO [org.apache.spark.executor.Executor] - Finished task 18.0 in stage 4.0 (TID 78). 1160 bytes result sent to driver
2021-12-06 15:20:28,567 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 18.0 in stage 4.0 (TID 78) in 80 ms on localhost (executor driver) (18/20)
2021-12-06 15:20:28,569 [Executor task launch worker for task 74] INFO [org.apache.spark.executor.Executor] - Finished task 14.0 in stage 4.0 (TID 74). 1205 bytes result sent to driver
2021-12-06 15:20:28,570 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 14.0 in stage 4.0 (TID 74) in 90 ms on localhost (executor driver) (19/20)
2021-12-06 15:20:28,572 [Executor task launch worker for task 79] INFO [org.apache.spark.executor.Executor] - Finished task 19.0 in stage 4.0 (TID 79). 1200 bytes result sent to driver
2021-12-06 15:20:28,573 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 19.0 in stage 4.0 (TID 79) in 84 ms on localhost (executor driver) (20/20)
2021-12-06 15:20:28,573 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 4.0, whose tasks have all completed, from pool 
2021-12-06 15:20:28,573 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 4 (sortByKey at PaidPromotionAdjustParameter.scala:73) finished in 0.213 s
2021-12-06 15:20:28,573 [main] INFO [org.apache.spark.scheduler.DAGScheduler] - Job 2 finished: sortByKey at PaidPromotionAdjustParameter.scala:73, took 0.216562 s
2021-12-06 15:20:28,587 [main] INFO [org.apache.spark.SparkContext] - Starting job: zipWithIndex at PaidPromotionAdjustParameter.scala:74
2021-12-06 15:20:28,588 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 5 (map at PaidPromotionAdjustParameter.scala:72)
2021-12-06 15:20:28,588 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 3 (zipWithIndex at PaidPromotionAdjustParameter.scala:74) with 19 output partitions
2021-12-06 15:20:28,588 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 7 (zipWithIndex at PaidPromotionAdjustParameter.scala:74)
2021-12-06 15:20:28,588 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 6)
2021-12-06 15:20:28,588 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List(ShuffleMapStage 6)
2021-12-06 15:20:28,588 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ShuffleMapStage 6 (MapPartitionsRDD[5] at map at PaidPromotionAdjustParameter.scala:72), which has no missing parents
2021-12-06 15:20:28,594 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_5 stored as values in memory (estimated size 4.1 KB, free 1990.5 MB)
2021-12-06 15:20:28,596 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_5_piece0 stored as bytes in memory (estimated size 2.4 KB, free 1990.5 MB)
2021-12-06 15:20:28,596 [dispatcher-event-loop-7] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_5_piece0 in memory on qb:52204 (size: 2.4 KB, free: 1990.8 MB)
2021-12-06 15:20:28,596 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 5 from broadcast at DAGScheduler.scala:1039
2021-12-06 15:20:28,597 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 20 missing tasks from ShuffleMapStage 6 (MapPartitionsRDD[5] at map at PaidPromotionAdjustParameter.scala:72) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14))
2021-12-06 15:20:28,597 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 6.0 with 20 tasks
2021-12-06 15:20:28,597 [dispatcher-event-loop-8] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 6.0 (TID 80, localhost, executor driver, partition 0, ANY, 7638 bytes)
2021-12-06 15:20:28,597 [dispatcher-event-loop-8] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 6.0 (TID 81, localhost, executor driver, partition 1, ANY, 7638 bytes)
2021-12-06 15:20:28,597 [dispatcher-event-loop-8] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 2.0 in stage 6.0 (TID 82, localhost, executor driver, partition 2, ANY, 7638 bytes)
2021-12-06 15:20:28,597 [dispatcher-event-loop-8] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 3.0 in stage 6.0 (TID 83, localhost, executor driver, partition 3, ANY, 7638 bytes)
2021-12-06 15:20:28,597 [dispatcher-event-loop-8] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 4.0 in stage 6.0 (TID 84, localhost, executor driver, partition 4, ANY, 7638 bytes)
2021-12-06 15:20:28,597 [dispatcher-event-loop-8] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 5.0 in stage 6.0 (TID 85, localhost, executor driver, partition 5, ANY, 7638 bytes)
2021-12-06 15:20:28,598 [dispatcher-event-loop-8] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 6.0 in stage 6.0 (TID 86, localhost, executor driver, partition 6, ANY, 7638 bytes)
2021-12-06 15:20:28,598 [dispatcher-event-loop-8] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 7.0 in stage 6.0 (TID 87, localhost, executor driver, partition 7, ANY, 7638 bytes)
2021-12-06 15:20:28,598 [dispatcher-event-loop-8] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 8.0 in stage 6.0 (TID 88, localhost, executor driver, partition 8, ANY, 7638 bytes)
2021-12-06 15:20:28,598 [dispatcher-event-loop-8] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 9.0 in stage 6.0 (TID 89, localhost, executor driver, partition 9, ANY, 7638 bytes)
2021-12-06 15:20:28,598 [dispatcher-event-loop-8] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 10.0 in stage 6.0 (TID 90, localhost, executor driver, partition 10, ANY, 7638 bytes)
2021-12-06 15:20:28,598 [dispatcher-event-loop-8] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 11.0 in stage 6.0 (TID 91, localhost, executor driver, partition 11, ANY, 7638 bytes)
2021-12-06 15:20:28,598 [Executor task launch worker for task 80] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 6.0 (TID 80)
2021-12-06 15:20:28,598 [Executor task launch worker for task 81] INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 6.0 (TID 81)
2021-12-06 15:20:28,598 [Executor task launch worker for task 88] INFO [org.apache.spark.executor.Executor] - Running task 8.0 in stage 6.0 (TID 88)
2021-12-06 15:20:28,598 [Executor task launch worker for task 90] INFO [org.apache.spark.executor.Executor] - Running task 10.0 in stage 6.0 (TID 90)
2021-12-06 15:20:28,598 [Executor task launch worker for task 83] INFO [org.apache.spark.executor.Executor] - Running task 3.0 in stage 6.0 (TID 83)
2021-12-06 15:20:28,598 [Executor task launch worker for task 86] INFO [org.apache.spark.executor.Executor] - Running task 6.0 in stage 6.0 (TID 86)
2021-12-06 15:20:28,598 [Executor task launch worker for task 84] INFO [org.apache.spark.executor.Executor] - Running task 4.0 in stage 6.0 (TID 84)
2021-12-06 15:20:28,598 [Executor task launch worker for task 85] INFO [org.apache.spark.executor.Executor] - Running task 5.0 in stage 6.0 (TID 85)
2021-12-06 15:20:28,598 [Executor task launch worker for task 82] INFO [org.apache.spark.executor.Executor] - Running task 2.0 in stage 6.0 (TID 82)
2021-12-06 15:20:28,598 [Executor task launch worker for task 87] INFO [org.apache.spark.executor.Executor] - Running task 7.0 in stage 6.0 (TID 87)
2021-12-06 15:20:28,598 [Executor task launch worker for task 89] INFO [org.apache.spark.executor.Executor] - Running task 9.0 in stage 6.0 (TID 89)
2021-12-06 15:20:28,598 [Executor task launch worker for task 91] INFO [org.apache.spark.executor.Executor] - Running task 11.0 in stage 6.0 (TID 91)
2021-12-06 15:20:28,606 [Executor task launch worker for task 89] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 20 non-empty blocks out of 20 blocks
2021-12-06 15:20:28,606 [Executor task launch worker for task 91] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 20 non-empty blocks out of 20 blocks
2021-12-06 15:20:28,606 [Executor task launch worker for task 89] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-06 15:20:28,606 [Executor task launch worker for task 91] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-06 15:20:28,606 [Executor task launch worker for task 81] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 20 non-empty blocks out of 20 blocks
2021-12-06 15:20:28,606 [Executor task launch worker for task 86] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 20 non-empty blocks out of 20 blocks
2021-12-06 15:20:28,606 [Executor task launch worker for task 83] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 20 non-empty blocks out of 20 blocks
2021-12-06 15:20:28,606 [Executor task launch worker for task 86] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-06 15:20:28,606 [Executor task launch worker for task 83] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-06 15:20:28,606 [Executor task launch worker for task 87] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 20 non-empty blocks out of 20 blocks
2021-12-06 15:20:28,606 [Executor task launch worker for task 81] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-06 15:20:28,606 [Executor task launch worker for task 87] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-06 15:20:28,606 [Executor task launch worker for task 90] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 20 non-empty blocks out of 20 blocks
2021-12-06 15:20:28,606 [Executor task launch worker for task 85] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 20 non-empty blocks out of 20 blocks
2021-12-06 15:20:28,606 [Executor task launch worker for task 90] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-06 15:20:28,606 [Executor task launch worker for task 88] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 20 non-empty blocks out of 20 blocks
2021-12-06 15:20:28,606 [Executor task launch worker for task 84] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 20 non-empty blocks out of 20 blocks
2021-12-06 15:20:28,606 [Executor task launch worker for task 88] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-06 15:20:28,606 [Executor task launch worker for task 82] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 20 non-empty blocks out of 20 blocks
2021-12-06 15:20:28,606 [Executor task launch worker for task 85] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-06 15:20:28,606 [Executor task launch worker for task 82] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-06 15:20:28,606 [Executor task launch worker for task 80] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 20 non-empty blocks out of 20 blocks
2021-12-06 15:20:28,606 [Executor task launch worker for task 84] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-06 15:20:28,606 [Executor task launch worker for task 80] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-06 15:20:29,013 [Executor task launch worker for task 87] INFO [org.apache.spark.executor.Executor] - Finished task 7.0 in stage 6.0 (TID 87). 1265 bytes result sent to driver
2021-12-06 15:20:29,014 [dispatcher-event-loop-11] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 12.0 in stage 6.0 (TID 92, localhost, executor driver, partition 12, ANY, 7638 bytes)
2021-12-06 15:20:29,014 [Executor task launch worker for task 92] INFO [org.apache.spark.executor.Executor] - Running task 12.0 in stage 6.0 (TID 92)
2021-12-06 15:20:29,014 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 7.0 in stage 6.0 (TID 87) in 416 ms on localhost (executor driver) (1/20)
2021-12-06 15:20:29,018 [Executor task launch worker for task 92] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 20 non-empty blocks out of 20 blocks
2021-12-06 15:20:29,018 [Executor task launch worker for task 92] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 1 ms
2021-12-06 15:20:29,019 [Executor task launch worker for task 80] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 6.0 (TID 80). 1265 bytes result sent to driver
2021-12-06 15:20:29,019 [dispatcher-event-loop-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 13.0 in stage 6.0 (TID 93, localhost, executor driver, partition 13, ANY, 7638 bytes)
2021-12-06 15:20:29,019 [Executor task launch worker for task 93] INFO [org.apache.spark.executor.Executor] - Running task 13.0 in stage 6.0 (TID 93)
2021-12-06 15:20:29,020 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 6.0 (TID 80) in 422 ms on localhost (executor driver) (2/20)
2021-12-06 15:20:29,026 [Executor task launch worker for task 93] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 20 non-empty blocks out of 20 blocks
2021-12-06 15:20:29,026 [Executor task launch worker for task 93] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-06 15:20:29,033 [Executor task launch worker for task 89] INFO [org.apache.spark.executor.Executor] - Finished task 9.0 in stage 6.0 (TID 89). 1265 bytes result sent to driver
2021-12-06 15:20:29,033 [Executor task launch worker for task 88] INFO [org.apache.spark.executor.Executor] - Finished task 8.0 in stage 6.0 (TID 88). 1265 bytes result sent to driver
2021-12-06 15:20:29,035 [Executor task launch worker for task 82] INFO [org.apache.spark.executor.Executor] - Finished task 2.0 in stage 6.0 (TID 82). 1265 bytes result sent to driver
2021-12-06 15:20:29,036 [dispatcher-event-loop-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 14.0 in stage 6.0 (TID 94, localhost, executor driver, partition 14, ANY, 7638 bytes)
2021-12-06 15:20:29,037 [Executor task launch worker for task 94] INFO [org.apache.spark.executor.Executor] - Running task 14.0 in stage 6.0 (TID 94)
2021-12-06 15:20:29,037 [dispatcher-event-loop-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 15.0 in stage 6.0 (TID 95, localhost, executor driver, partition 15, ANY, 7638 bytes)
2021-12-06 15:20:29,037 [dispatcher-event-loop-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 16.0 in stage 6.0 (TID 96, localhost, executor driver, partition 16, ANY, 7638 bytes)
2021-12-06 15:20:29,037 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 9.0 in stage 6.0 (TID 89) in 439 ms on localhost (executor driver) (3/20)
2021-12-06 15:20:29,037 [Executor task launch worker for task 95] INFO [org.apache.spark.executor.Executor] - Running task 15.0 in stage 6.0 (TID 95)
2021-12-06 15:20:29,037 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 2.0 in stage 6.0 (TID 82) in 440 ms on localhost (executor driver) (4/20)
2021-12-06 15:20:29,038 [Executor task launch worker for task 96] INFO [org.apache.spark.executor.Executor] - Running task 16.0 in stage 6.0 (TID 96)
2021-12-06 15:20:29,039 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 8.0 in stage 6.0 (TID 88) in 441 ms on localhost (executor driver) (5/20)
2021-12-06 15:20:29,041 [Executor task launch worker for task 94] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 20 non-empty blocks out of 20 blocks
2021-12-06 15:20:29,041 [Executor task launch worker for task 94] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 1 ms
2021-12-06 15:20:29,041 [Executor task launch worker for task 95] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 20 non-empty blocks out of 20 blocks
2021-12-06 15:20:29,041 [Executor task launch worker for task 95] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 1 ms
2021-12-06 15:20:29,044 [Executor task launch worker for task 96] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 20 non-empty blocks out of 20 blocks
2021-12-06 15:20:29,044 [Executor task launch worker for task 96] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-06 15:20:29,048 [Executor task launch worker for task 81] INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 6.0 (TID 81). 1265 bytes result sent to driver
2021-12-06 15:20:29,048 [dispatcher-event-loop-8] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 17.0 in stage 6.0 (TID 97, localhost, executor driver, partition 17, ANY, 7638 bytes)
2021-12-06 15:20:29,048 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 6.0 (TID 81) in 451 ms on localhost (executor driver) (6/20)
2021-12-06 15:20:29,049 [Executor task launch worker for task 97] INFO [org.apache.spark.executor.Executor] - Running task 17.0 in stage 6.0 (TID 97)
2021-12-06 15:20:29,049 [Executor task launch worker for task 83] INFO [org.apache.spark.executor.Executor] - Finished task 3.0 in stage 6.0 (TID 83). 1265 bytes result sent to driver
2021-12-06 15:20:29,050 [dispatcher-event-loop-4] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 18.0 in stage 6.0 (TID 98, localhost, executor driver, partition 18, ANY, 7638 bytes)
2021-12-06 15:20:29,050 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 3.0 in stage 6.0 (TID 83) in 453 ms on localhost (executor driver) (7/20)
2021-12-06 15:20:29,050 [Executor task launch worker for task 98] INFO [org.apache.spark.executor.Executor] - Running task 18.0 in stage 6.0 (TID 98)
2021-12-06 15:20:29,052 [Executor task launch worker for task 97] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 20 non-empty blocks out of 20 blocks
2021-12-06 15:20:29,052 [Executor task launch worker for task 97] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-06 15:20:29,053 [Executor task launch worker for task 98] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 20 non-empty blocks out of 20 blocks
2021-12-06 15:20:29,053 [Executor task launch worker for task 98] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-06 15:20:29,054 [Executor task launch worker for task 85] INFO [org.apache.spark.executor.Executor] - Finished task 5.0 in stage 6.0 (TID 85). 1265 bytes result sent to driver
2021-12-06 15:20:29,057 [Executor task launch worker for task 86] INFO [org.apache.spark.executor.Executor] - Finished task 6.0 in stage 6.0 (TID 86). 1265 bytes result sent to driver
2021-12-06 15:20:29,060 [dispatcher-event-loop-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 19.0 in stage 6.0 (TID 99, localhost, executor driver, partition 19, ANY, 7638 bytes)
2021-12-06 15:20:29,060 [Executor task launch worker for task 99] INFO [org.apache.spark.executor.Executor] - Running task 19.0 in stage 6.0 (TID 99)
2021-12-06 15:20:29,062 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 5.0 in stage 6.0 (TID 85) in 465 ms on localhost (executor driver) (8/20)
2021-12-06 15:20:29,062 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 6.0 in stage 6.0 (TID 86) in 464 ms on localhost (executor driver) (9/20)
2021-12-06 15:20:29,063 [Executor task launch worker for task 99] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 20 non-empty blocks out of 20 blocks
2021-12-06 15:20:29,063 [Executor task launch worker for task 99] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-06 15:20:29,065 [Executor task launch worker for task 90] INFO [org.apache.spark.executor.Executor] - Finished task 10.0 in stage 6.0 (TID 90). 1308 bytes result sent to driver
2021-12-06 15:20:29,067 [Executor task launch worker for task 84] INFO [org.apache.spark.executor.Executor] - Finished task 4.0 in stage 6.0 (TID 84). 1265 bytes result sent to driver
2021-12-06 15:20:29,068 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 10.0 in stage 6.0 (TID 90) in 470 ms on localhost (executor driver) (10/20)
2021-12-06 15:20:29,068 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 4.0 in stage 6.0 (TID 84) in 471 ms on localhost (executor driver) (11/20)
2021-12-06 15:20:29,087 [Executor task launch worker for task 91] INFO [org.apache.spark.executor.Executor] - Finished task 11.0 in stage 6.0 (TID 91). 1265 bytes result sent to driver
2021-12-06 15:20:29,087 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 11.0 in stage 6.0 (TID 91) in 489 ms on localhost (executor driver) (12/20)
2021-12-06 15:20:29,318 [Executor task launch worker for task 92] INFO [org.apache.spark.executor.Executor] - Finished task 12.0 in stage 6.0 (TID 92). 1265 bytes result sent to driver
2021-12-06 15:20:29,319 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 12.0 in stage 6.0 (TID 92) in 305 ms on localhost (executor driver) (13/20)
2021-12-06 15:20:29,332 [Executor task launch worker for task 94] INFO [org.apache.spark.executor.Executor] - Finished task 14.0 in stage 6.0 (TID 94). 1265 bytes result sent to driver
2021-12-06 15:20:29,333 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 14.0 in stage 6.0 (TID 94) in 297 ms on localhost (executor driver) (14/20)
2021-12-06 15:20:29,354 [Executor task launch worker for task 93] INFO [org.apache.spark.executor.Executor] - Finished task 13.0 in stage 6.0 (TID 93). 1265 bytes result sent to driver
2021-12-06 15:20:29,354 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 13.0 in stage 6.0 (TID 93) in 335 ms on localhost (executor driver) (15/20)
2021-12-06 15:20:29,361 [Executor task launch worker for task 96] INFO [org.apache.spark.executor.Executor] - Finished task 16.0 in stage 6.0 (TID 96). 1265 bytes result sent to driver
2021-12-06 15:20:29,362 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 16.0 in stage 6.0 (TID 96) in 325 ms on localhost (executor driver) (16/20)
2021-12-06 15:20:29,365 [Executor task launch worker for task 98] INFO [org.apache.spark.executor.Executor] - Finished task 18.0 in stage 6.0 (TID 98). 1265 bytes result sent to driver
2021-12-06 15:20:29,365 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 18.0 in stage 6.0 (TID 98) in 315 ms on localhost (executor driver) (17/20)
2021-12-06 15:20:29,374 [Executor task launch worker for task 95] INFO [org.apache.spark.executor.Executor] - Finished task 15.0 in stage 6.0 (TID 95). 1265 bytes result sent to driver
2021-12-06 15:20:29,374 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 15.0 in stage 6.0 (TID 95) in 337 ms on localhost (executor driver) (18/20)
2021-12-06 15:20:29,386 [Executor task launch worker for task 97] INFO [org.apache.spark.executor.Executor] - Finished task 17.0 in stage 6.0 (TID 97). 1265 bytes result sent to driver
2021-12-06 15:20:29,387 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 17.0 in stage 6.0 (TID 97) in 339 ms on localhost (executor driver) (19/20)
2021-12-06 15:20:29,392 [Executor task launch worker for task 99] INFO [org.apache.spark.executor.Executor] - Finished task 19.0 in stage 6.0 (TID 99). 1265 bytes result sent to driver
2021-12-06 15:20:29,392 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 19.0 in stage 6.0 (TID 99) in 332 ms on localhost (executor driver) (20/20)
2021-12-06 15:20:29,392 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 6.0, whose tasks have all completed, from pool 
2021-12-06 15:20:29,392 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ShuffleMapStage 6 (map at PaidPromotionAdjustParameter.scala:72) finished in 0.803 s
2021-12-06 15:20:29,392 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - looking for newly runnable stages
2021-12-06 15:20:29,392 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - running: Set()
2021-12-06 15:20:29,392 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - waiting: Set(ResultStage 7)
2021-12-06 15:20:29,392 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - failed: Set()
2021-12-06 15:20:29,393 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 7 (ShuffledRDD[8] at sortByKey at PaidPromotionAdjustParameter.scala:73), which has no missing parents
2021-12-06 15:20:29,395 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_6 stored as values in memory (estimated size 3.4 KB, free 1990.4 MB)
2021-12-06 15:20:29,397 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_6_piece0 stored as bytes in memory (estimated size 2.0 KB, free 1990.4 MB)
2021-12-06 15:20:29,397 [dispatcher-event-loop-5] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_6_piece0 in memory on qb:52204 (size: 2.0 KB, free: 1990.8 MB)
2021-12-06 15:20:29,397 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 6 from broadcast at DAGScheduler.scala:1039
2021-12-06 15:20:29,397 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 19 missing tasks from ResultStage 7 (ShuffledRDD[8] at sortByKey at PaidPromotionAdjustParameter.scala:73) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14))
2021-12-06 15:20:29,398 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 7.0 with 19 tasks
2021-12-06 15:20:29,398 [dispatcher-event-loop-10] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 7.0 (TID 100, localhost, executor driver, partition 0, ANY, 7649 bytes)
2021-12-06 15:20:29,398 [dispatcher-event-loop-10] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 7.0 (TID 101, localhost, executor driver, partition 1, ANY, 7649 bytes)
2021-12-06 15:20:29,398 [dispatcher-event-loop-10] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 2.0 in stage 7.0 (TID 102, localhost, executor driver, partition 2, ANY, 7649 bytes)
2021-12-06 15:20:29,398 [dispatcher-event-loop-10] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 3.0 in stage 7.0 (TID 103, localhost, executor driver, partition 3, ANY, 7649 bytes)
2021-12-06 15:20:29,398 [dispatcher-event-loop-10] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 4.0 in stage 7.0 (TID 104, localhost, executor driver, partition 4, ANY, 7649 bytes)
2021-12-06 15:20:29,398 [dispatcher-event-loop-10] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 5.0 in stage 7.0 (TID 105, localhost, executor driver, partition 5, ANY, 7649 bytes)
2021-12-06 15:20:29,398 [dispatcher-event-loop-10] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 6.0 in stage 7.0 (TID 106, localhost, executor driver, partition 6, ANY, 7649 bytes)
2021-12-06 15:20:29,398 [dispatcher-event-loop-10] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 7.0 in stage 7.0 (TID 107, localhost, executor driver, partition 7, ANY, 7649 bytes)
2021-12-06 15:20:29,399 [dispatcher-event-loop-10] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 8.0 in stage 7.0 (TID 108, localhost, executor driver, partition 8, ANY, 7649 bytes)
2021-12-06 15:20:29,399 [dispatcher-event-loop-10] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 9.0 in stage 7.0 (TID 109, localhost, executor driver, partition 9, ANY, 7649 bytes)
2021-12-06 15:20:29,399 [dispatcher-event-loop-10] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 10.0 in stage 7.0 (TID 110, localhost, executor driver, partition 10, ANY, 7649 bytes)
2021-12-06 15:20:29,399 [dispatcher-event-loop-10] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 11.0 in stage 7.0 (TID 111, localhost, executor driver, partition 11, ANY, 7649 bytes)
2021-12-06 15:20:29,399 [Executor task launch worker for task 100] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 7.0 (TID 100)
2021-12-06 15:20:29,399 [Executor task launch worker for task 102] INFO [org.apache.spark.executor.Executor] - Running task 2.0 in stage 7.0 (TID 102)
2021-12-06 15:20:29,399 [Executor task launch worker for task 108] INFO [org.apache.spark.executor.Executor] - Running task 8.0 in stage 7.0 (TID 108)
2021-12-06 15:20:29,399 [Executor task launch worker for task 105] INFO [org.apache.spark.executor.Executor] - Running task 5.0 in stage 7.0 (TID 105)
2021-12-06 15:20:29,399 [Executor task launch worker for task 110] INFO [org.apache.spark.executor.Executor] - Running task 10.0 in stage 7.0 (TID 110)
2021-12-06 15:20:29,399 [Executor task launch worker for task 104] INFO [org.apache.spark.executor.Executor] - Running task 4.0 in stage 7.0 (TID 104)
2021-12-06 15:20:29,399 [Executor task launch worker for task 107] INFO [org.apache.spark.executor.Executor] - Running task 7.0 in stage 7.0 (TID 107)
2021-12-06 15:20:29,399 [Executor task launch worker for task 103] INFO [org.apache.spark.executor.Executor] - Running task 3.0 in stage 7.0 (TID 103)
2021-12-06 15:20:29,399 [Executor task launch worker for task 106] INFO [org.apache.spark.executor.Executor] - Running task 6.0 in stage 7.0 (TID 106)
2021-12-06 15:20:29,399 [Executor task launch worker for task 101] INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 7.0 (TID 101)
2021-12-06 15:20:29,399 [Executor task launch worker for task 111] INFO [org.apache.spark.executor.Executor] - Running task 11.0 in stage 7.0 (TID 111)
2021-12-06 15:20:29,399 [Executor task launch worker for task 109] INFO [org.apache.spark.executor.Executor] - Running task 9.0 in stage 7.0 (TID 109)
2021-12-06 15:20:29,402 [Executor task launch worker for task 100] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 20 non-empty blocks out of 20 blocks
2021-12-06 15:20:29,402 [Executor task launch worker for task 100] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-06 15:20:29,403 [Executor task launch worker for task 101] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 20 non-empty blocks out of 20 blocks
2021-12-06 15:20:29,403 [Executor task launch worker for task 101] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-06 15:20:29,403 [Executor task launch worker for task 102] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 20 non-empty blocks out of 20 blocks
2021-12-06 15:20:29,403 [Executor task launch worker for task 102] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-06 15:20:29,404 [Executor task launch worker for task 111] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 20 non-empty blocks out of 20 blocks
2021-12-06 15:20:29,404 [Executor task launch worker for task 111] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-06 15:20:29,404 [Executor task launch worker for task 110] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 20 non-empty blocks out of 20 blocks
2021-12-06 15:20:29,404 [Executor task launch worker for task 110] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-06 15:20:29,405 [Executor task launch worker for task 104] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 20 non-empty blocks out of 20 blocks
2021-12-06 15:20:29,405 [Executor task launch worker for task 104] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-06 15:20:29,405 [Executor task launch worker for task 105] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 20 non-empty blocks out of 20 blocks
2021-12-06 15:20:29,405 [Executor task launch worker for task 105] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-06 15:20:29,406 [Executor task launch worker for task 106] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 20 non-empty blocks out of 20 blocks
2021-12-06 15:20:29,406 [Executor task launch worker for task 106] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-06 15:20:29,406 [Executor task launch worker for task 109] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 20 non-empty blocks out of 20 blocks
2021-12-06 15:20:29,406 [Executor task launch worker for task 109] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-06 15:20:29,407 [Executor task launch worker for task 103] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 20 non-empty blocks out of 20 blocks
2021-12-06 15:20:29,407 [Executor task launch worker for task 103] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-06 15:20:29,407 [Executor task launch worker for task 107] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 20 non-empty blocks out of 20 blocks
2021-12-06 15:20:29,407 [Executor task launch worker for task 107] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-06 15:20:29,408 [Executor task launch worker for task 108] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 20 non-empty blocks out of 20 blocks
2021-12-06 15:20:29,408 [Executor task launch worker for task 108] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-06 15:20:29,716 [Executor task launch worker for task 110] INFO [org.apache.spark.executor.Executor] - Finished task 10.0 in stage 7.0 (TID 110). 1141 bytes result sent to driver
2021-12-06 15:20:29,716 [dispatcher-event-loop-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 12.0 in stage 7.0 (TID 112, localhost, executor driver, partition 12, ANY, 7649 bytes)
2021-12-06 15:20:29,717 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 10.0 in stage 7.0 (TID 110) in 318 ms on localhost (executor driver) (1/19)
2021-12-06 15:20:29,717 [Executor task launch worker for task 112] INFO [org.apache.spark.executor.Executor] - Running task 12.0 in stage 7.0 (TID 112)
2021-12-06 15:20:29,720 [Executor task launch worker for task 112] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 20 non-empty blocks out of 20 blocks
2021-12-06 15:20:29,720 [Executor task launch worker for task 112] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-06 15:20:29,723 [Executor task launch worker for task 104] INFO [org.apache.spark.executor.Executor] - Finished task 4.0 in stage 7.0 (TID 104). 1141 bytes result sent to driver
2021-12-06 15:20:29,723 [dispatcher-event-loop-7] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 13.0 in stage 7.0 (TID 113, localhost, executor driver, partition 13, ANY, 7649 bytes)
2021-12-06 15:20:29,724 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 4.0 in stage 7.0 (TID 104) in 326 ms on localhost (executor driver) (2/19)
2021-12-06 15:20:29,724 [Executor task launch worker for task 107] INFO [org.apache.spark.executor.Executor] - Finished task 7.0 in stage 7.0 (TID 107). 1098 bytes result sent to driver
2021-12-06 15:20:29,724 [dispatcher-event-loop-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 14.0 in stage 7.0 (TID 114, localhost, executor driver, partition 14, ANY, 7649 bytes)
2021-12-06 15:20:29,724 [Executor task launch worker for task 114] INFO [org.apache.spark.executor.Executor] - Running task 14.0 in stage 7.0 (TID 114)
2021-12-06 15:20:29,726 [Executor task launch worker for task 101] INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 7.0 (TID 101). 1098 bytes result sent to driver
2021-12-06 15:20:29,726 [Executor task launch worker for task 103] INFO [org.apache.spark.executor.Executor] - Finished task 3.0 in stage 7.0 (TID 103). 1098 bytes result sent to driver
2021-12-06 15:20:29,726 [Executor task launch worker for task 109] INFO [org.apache.spark.executor.Executor] - Finished task 9.0 in stage 7.0 (TID 109). 1098 bytes result sent to driver
2021-12-06 15:20:29,727 [Executor task launch worker for task 113] INFO [org.apache.spark.executor.Executor] - Running task 13.0 in stage 7.0 (TID 113)
2021-12-06 15:20:29,727 [Executor task launch worker for task 114] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 20 non-empty blocks out of 20 blocks
2021-12-06 15:20:29,727 [Executor task launch worker for task 114] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-06 15:20:29,727 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 7.0 in stage 7.0 (TID 107) in 329 ms on localhost (executor driver) (3/19)
2021-12-06 15:20:29,727 [dispatcher-event-loop-11] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 15.0 in stage 7.0 (TID 115, localhost, executor driver, partition 15, ANY, 7649 bytes)
2021-12-06 15:20:29,728 [dispatcher-event-loop-11] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 16.0 in stage 7.0 (TID 116, localhost, executor driver, partition 16, ANY, 7649 bytes)
2021-12-06 15:20:29,728 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 7.0 (TID 101) in 330 ms on localhost (executor driver) (4/19)
2021-12-06 15:20:29,728 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 3.0 in stage 7.0 (TID 103) in 330 ms on localhost (executor driver) (5/19)
2021-12-06 15:20:29,728 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 9.0 in stage 7.0 (TID 109) in 329 ms on localhost (executor driver) (6/19)
2021-12-06 15:20:29,728 [Executor task launch worker for task 115] INFO [org.apache.spark.executor.Executor] - Running task 15.0 in stage 7.0 (TID 115)
2021-12-06 15:20:29,729 [Executor task launch worker for task 102] INFO [org.apache.spark.executor.Executor] - Finished task 2.0 in stage 7.0 (TID 102). 1098 bytes result sent to driver
2021-12-06 15:20:29,729 [Executor task launch worker for task 113] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 20 non-empty blocks out of 20 blocks
2021-12-06 15:20:29,729 [Executor task launch worker for task 113] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-06 15:20:29,729 [dispatcher-event-loop-11] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 17.0 in stage 7.0 (TID 117, localhost, executor driver, partition 17, ANY, 7649 bytes)
2021-12-06 15:20:29,729 [Executor task launch worker for task 117] INFO [org.apache.spark.executor.Executor] - Running task 17.0 in stage 7.0 (TID 117)
2021-12-06 15:20:29,729 [Executor task launch worker for task 116] INFO [org.apache.spark.executor.Executor] - Running task 16.0 in stage 7.0 (TID 116)
2021-12-06 15:20:29,729 [dispatcher-event-loop-11] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 18.0 in stage 7.0 (TID 118, localhost, executor driver, partition 18, ANY, 7649 bytes)
2021-12-06 15:20:29,730 [Executor task launch worker for task 105] INFO [org.apache.spark.executor.Executor] - Finished task 5.0 in stage 7.0 (TID 105). 1098 bytes result sent to driver
2021-12-06 15:20:29,729 [Executor task launch worker for task 108] INFO [org.apache.spark.executor.Executor] - Finished task 8.0 in stage 7.0 (TID 108). 1098 bytes result sent to driver
2021-12-06 15:20:29,730 [Executor task launch worker for task 118] INFO [org.apache.spark.executor.Executor] - Running task 18.0 in stage 7.0 (TID 118)
2021-12-06 15:20:29,730 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 2.0 in stage 7.0 (TID 102) in 332 ms on localhost (executor driver) (7/19)
2021-12-06 15:20:29,731 [Executor task launch worker for task 111] INFO [org.apache.spark.executor.Executor] - Finished task 11.0 in stage 7.0 (TID 111). 1141 bytes result sent to driver
2021-12-06 15:20:29,731 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 5.0 in stage 7.0 (TID 105) in 333 ms on localhost (executor driver) (8/19)
2021-12-06 15:20:29,731 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 8.0 in stage 7.0 (TID 108) in 332 ms on localhost (executor driver) (9/19)
2021-12-06 15:20:29,731 [Executor task launch worker for task 115] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 20 non-empty blocks out of 20 blocks
2021-12-06 15:20:29,731 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 11.0 in stage 7.0 (TID 111) in 332 ms on localhost (executor driver) (10/19)
2021-12-06 15:20:29,731 [Executor task launch worker for task 115] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-06 15:20:29,732 [Executor task launch worker for task 106] INFO [org.apache.spark.executor.Executor] - Finished task 6.0 in stage 7.0 (TID 106). 1098 bytes result sent to driver
2021-12-06 15:20:29,732 [Executor task launch worker for task 116] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 20 non-empty blocks out of 20 blocks
2021-12-06 15:20:29,732 [Executor task launch worker for task 116] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-06 15:20:29,732 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 6.0 in stage 7.0 (TID 106) in 334 ms on localhost (executor driver) (11/19)
2021-12-06 15:20:29,732 [Executor task launch worker for task 117] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 20 non-empty blocks out of 20 blocks
2021-12-06 15:20:29,732 [Executor task launch worker for task 117] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-06 15:20:29,733 [Executor task launch worker for task 118] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 20 non-empty blocks out of 20 blocks
2021-12-06 15:20:29,733 [Executor task launch worker for task 118] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-06 15:20:29,734 [Executor task launch worker for task 100] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 7.0 (TID 100). 1098 bytes result sent to driver
2021-12-06 15:20:29,734 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 7.0 (TID 100) in 336 ms on localhost (executor driver) (12/19)
2021-12-06 15:20:29,791 [Executor task launch worker for task 112] INFO [org.apache.spark.executor.Executor] - Finished task 12.0 in stage 7.0 (TID 112). 1098 bytes result sent to driver
2021-12-06 15:20:29,791 [Executor task launch worker for task 117] INFO [org.apache.spark.executor.Executor] - Finished task 17.0 in stage 7.0 (TID 117). 1141 bytes result sent to driver
2021-12-06 15:20:29,792 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 12.0 in stage 7.0 (TID 112) in 76 ms on localhost (executor driver) (13/19)
2021-12-06 15:20:29,792 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 17.0 in stage 7.0 (TID 117) in 63 ms on localhost (executor driver) (14/19)
2021-12-06 15:20:29,792 [Executor task launch worker for task 114] INFO [org.apache.spark.executor.Executor] - Finished task 14.0 in stage 7.0 (TID 114). 1098 bytes result sent to driver
2021-12-06 15:20:29,793 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 14.0 in stage 7.0 (TID 114) in 69 ms on localhost (executor driver) (15/19)
2021-12-06 15:20:29,795 [Executor task launch worker for task 113] INFO [org.apache.spark.executor.Executor] - Finished task 13.0 in stage 7.0 (TID 113). 1098 bytes result sent to driver
2021-12-06 15:20:29,795 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 13.0 in stage 7.0 (TID 113) in 72 ms on localhost (executor driver) (16/19)
2021-12-06 15:20:29,796 [Executor task launch worker for task 118] INFO [org.apache.spark.executor.Executor] - Finished task 18.0 in stage 7.0 (TID 118). 1098 bytes result sent to driver
2021-12-06 15:20:29,796 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 18.0 in stage 7.0 (TID 118) in 67 ms on localhost (executor driver) (17/19)
2021-12-06 15:20:29,797 [Executor task launch worker for task 115] INFO [org.apache.spark.executor.Executor] - Finished task 15.0 in stage 7.0 (TID 115). 1098 bytes result sent to driver
2021-12-06 15:20:29,797 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 15.0 in stage 7.0 (TID 115) in 70 ms on localhost (executor driver) (18/19)
2021-12-06 15:20:29,799 [Executor task launch worker for task 116] INFO [org.apache.spark.executor.Executor] - Finished task 16.0 in stage 7.0 (TID 116). 1141 bytes result sent to driver
2021-12-06 15:20:29,799 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 16.0 in stage 7.0 (TID 116) in 71 ms on localhost (executor driver) (19/19)
2021-12-06 15:20:29,799 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 7.0, whose tasks have all completed, from pool 
2021-12-06 15:20:29,800 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 7 (zipWithIndex at PaidPromotionAdjustParameter.scala:74) finished in 0.406 s
2021-12-06 15:20:29,800 [main] INFO [org.apache.spark.scheduler.DAGScheduler] - Job 3 finished: zipWithIndex at PaidPromotionAdjustParameter.scala:74, took 1.212149 s
2021-12-06 15:20:29,810 [main] INFO [org.apache.spark.SparkContext] - Starting job: takeSample at PaidPromotionAdjustParameter.scala:77
2021-12-06 15:20:29,810 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 4 (takeSample at PaidPromotionAdjustParameter.scala:77) with 20 output partitions
2021-12-06 15:20:29,810 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 10 (takeSample at PaidPromotionAdjustParameter.scala:77)
2021-12-06 15:20:29,810 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 9)
2021-12-06 15:20:29,810 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2021-12-06 15:20:29,810 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 10 (MapPartitionsRDD[11] at map at PaidPromotionAdjustParameter.scala:76), which has no missing parents
2021-12-06 15:20:29,814 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_7 stored as values in memory (estimated size 4.2 KB, free 1990.4 MB)
2021-12-06 15:20:29,816 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_7_piece0 stored as bytes in memory (estimated size 2.4 KB, free 1990.4 MB)
2021-12-06 15:20:29,816 [dispatcher-event-loop-7] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_7_piece0 in memory on qb:52204 (size: 2.4 KB, free: 1990.8 MB)
2021-12-06 15:20:29,816 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 7 from broadcast at DAGScheduler.scala:1039
2021-12-06 15:20:29,817 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 20 missing tasks from ResultStage 10 (MapPartitionsRDD[11] at map at PaidPromotionAdjustParameter.scala:76) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14))
2021-12-06 15:20:29,817 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 10.0 with 20 tasks
2021-12-06 15:20:29,818 [dispatcher-event-loop-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 10.0 (TID 119, localhost, executor driver, partition 0, ANY, 7759 bytes)
2021-12-06 15:20:29,818 [dispatcher-event-loop-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 10.0 (TID 120, localhost, executor driver, partition 1, ANY, 7759 bytes)
2021-12-06 15:20:29,818 [dispatcher-event-loop-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 2.0 in stage 10.0 (TID 121, localhost, executor driver, partition 2, ANY, 7759 bytes)
2021-12-06 15:20:29,818 [dispatcher-event-loop-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 3.0 in stage 10.0 (TID 122, localhost, executor driver, partition 3, ANY, 7759 bytes)
2021-12-06 15:20:29,818 [dispatcher-event-loop-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 4.0 in stage 10.0 (TID 123, localhost, executor driver, partition 4, ANY, 7759 bytes)
2021-12-06 15:20:29,818 [dispatcher-event-loop-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 5.0 in stage 10.0 (TID 124, localhost, executor driver, partition 5, ANY, 7759 bytes)
2021-12-06 15:20:29,818 [dispatcher-event-loop-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 6.0 in stage 10.0 (TID 125, localhost, executor driver, partition 6, ANY, 7759 bytes)
2021-12-06 15:20:29,818 [dispatcher-event-loop-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 7.0 in stage 10.0 (TID 126, localhost, executor driver, partition 7, ANY, 7759 bytes)
2021-12-06 15:20:29,819 [dispatcher-event-loop-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 8.0 in stage 10.0 (TID 127, localhost, executor driver, partition 8, ANY, 7759 bytes)
2021-12-06 15:20:29,819 [dispatcher-event-loop-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 9.0 in stage 10.0 (TID 128, localhost, executor driver, partition 9, ANY, 7759 bytes)
2021-12-06 15:20:29,819 [dispatcher-event-loop-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 10.0 in stage 10.0 (TID 129, localhost, executor driver, partition 10, ANY, 7759 bytes)
2021-12-06 15:20:29,819 [dispatcher-event-loop-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 11.0 in stage 10.0 (TID 130, localhost, executor driver, partition 11, ANY, 7759 bytes)
2021-12-06 15:20:29,819 [Executor task launch worker for task 121] INFO [org.apache.spark.executor.Executor] - Running task 2.0 in stage 10.0 (TID 121)
2021-12-06 15:20:29,819 [Executor task launch worker for task 124] INFO [org.apache.spark.executor.Executor] - Running task 5.0 in stage 10.0 (TID 124)
2021-12-06 15:20:29,819 [Executor task launch worker for task 123] INFO [org.apache.spark.executor.Executor] - Running task 4.0 in stage 10.0 (TID 123)
2021-12-06 15:20:29,819 [Executor task launch worker for task 128] INFO [org.apache.spark.executor.Executor] - Running task 9.0 in stage 10.0 (TID 128)
2021-12-06 15:20:29,819 [Executor task launch worker for task 122] INFO [org.apache.spark.executor.Executor] - Running task 3.0 in stage 10.0 (TID 122)
2021-12-06 15:20:29,819 [Executor task launch worker for task 119] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 10.0 (TID 119)
2021-12-06 15:20:29,819 [Executor task launch worker for task 120] INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 10.0 (TID 120)
2021-12-06 15:20:29,819 [Executor task launch worker for task 127] INFO [org.apache.spark.executor.Executor] - Running task 8.0 in stage 10.0 (TID 127)
2021-12-06 15:20:29,819 [Executor task launch worker for task 130] INFO [org.apache.spark.executor.Executor] - Running task 11.0 in stage 10.0 (TID 130)
2021-12-06 15:20:29,819 [Executor task launch worker for task 129] INFO [org.apache.spark.executor.Executor] - Running task 10.0 in stage 10.0 (TID 129)
2021-12-06 15:20:29,819 [Executor task launch worker for task 125] INFO [org.apache.spark.executor.Executor] - Running task 6.0 in stage 10.0 (TID 125)
2021-12-06 15:20:29,819 [Executor task launch worker for task 126] INFO [org.apache.spark.executor.Executor] - Running task 7.0 in stage 10.0 (TID 126)
2021-12-06 15:20:29,822 [Executor task launch worker for task 124] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 20 non-empty blocks out of 20 blocks
2021-12-06 15:20:29,822 [Executor task launch worker for task 130] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 20 non-empty blocks out of 20 blocks
2021-12-06 15:20:29,822 [Executor task launch worker for task 124] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-06 15:20:29,822 [Executor task launch worker for task 130] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-06 15:20:29,822 [Executor task launch worker for task 120] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 20 non-empty blocks out of 20 blocks
2021-12-06 15:20:29,822 [Executor task launch worker for task 120] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-06 15:20:29,823 [Executor task launch worker for task 125] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 20 non-empty blocks out of 20 blocks
2021-12-06 15:20:29,823 [Executor task launch worker for task 125] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-06 15:20:29,823 [Executor task launch worker for task 129] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 20 non-empty blocks out of 20 blocks
2021-12-06 15:20:29,823 [Executor task launch worker for task 129] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-06 15:20:29,823 [Executor task launch worker for task 122] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 20 non-empty blocks out of 20 blocks
2021-12-06 15:20:29,823 [Executor task launch worker for task 122] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-06 15:20:29,824 [Executor task launch worker for task 128] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 20 non-empty blocks out of 20 blocks
2021-12-06 15:20:29,824 [Executor task launch worker for task 128] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-06 15:20:29,824 [Executor task launch worker for task 127] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 20 non-empty blocks out of 20 blocks
2021-12-06 15:20:29,824 [Executor task launch worker for task 127] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-06 15:20:29,824 [Executor task launch worker for task 121] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 20 non-empty blocks out of 20 blocks
2021-12-06 15:20:29,824 [Executor task launch worker for task 121] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-06 15:20:29,825 [Executor task launch worker for task 126] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 20 non-empty blocks out of 20 blocks
2021-12-06 15:20:29,825 [Executor task launch worker for task 126] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-06 15:20:29,825 [Executor task launch worker for task 123] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 20 non-empty blocks out of 20 blocks
2021-12-06 15:20:29,825 [Executor task launch worker for task 123] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-06 15:20:29,826 [Executor task launch worker for task 119] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 20 non-empty blocks out of 20 blocks
2021-12-06 15:20:29,826 [Executor task launch worker for task 119] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-06 15:20:29,942 [Executor task launch worker for task 129] INFO [org.apache.spark.executor.Executor] - Finished task 10.0 in stage 10.0 (TID 129). 1098 bytes result sent to driver
2021-12-06 15:20:29,942 [dispatcher-event-loop-4] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 12.0 in stage 10.0 (TID 131, localhost, executor driver, partition 12, ANY, 7759 bytes)
2021-12-06 15:20:29,942 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 10.0 in stage 10.0 (TID 129) in 123 ms on localhost (executor driver) (1/20)
2021-12-06 15:20:29,943 [Executor task launch worker for task 131] INFO [org.apache.spark.executor.Executor] - Running task 12.0 in stage 10.0 (TID 131)
2021-12-06 15:20:29,945 [Executor task launch worker for task 131] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 20 non-empty blocks out of 20 blocks
2021-12-06 15:20:29,946 [Executor task launch worker for task 131] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 1 ms
2021-12-06 15:20:29,954 [Executor task launch worker for task 128] INFO [org.apache.spark.executor.Executor] - Finished task 9.0 in stage 10.0 (TID 128). 1098 bytes result sent to driver
2021-12-06 15:20:29,955 [dispatcher-event-loop-9] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 13.0 in stage 10.0 (TID 132, localhost, executor driver, partition 13, ANY, 7759 bytes)
2021-12-06 15:20:29,955 [Executor task launch worker for task 132] INFO [org.apache.spark.executor.Executor] - Running task 13.0 in stage 10.0 (TID 132)
2021-12-06 15:20:29,956 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 9.0 in stage 10.0 (TID 128) in 137 ms on localhost (executor driver) (2/20)
2021-12-06 15:20:29,958 [Executor task launch worker for task 132] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 20 non-empty blocks out of 20 blocks
2021-12-06 15:20:29,958 [Executor task launch worker for task 132] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-06 15:20:29,959 [Executor task launch worker for task 120] INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 10.0 (TID 120). 1097 bytes result sent to driver
2021-12-06 15:20:29,960 [dispatcher-event-loop-6] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 14.0 in stage 10.0 (TID 133, localhost, executor driver, partition 14, ANY, 7759 bytes)
2021-12-06 15:20:29,960 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 10.0 (TID 120) in 142 ms on localhost (executor driver) (3/20)
2021-12-06 15:20:29,960 [Executor task launch worker for task 133] INFO [org.apache.spark.executor.Executor] - Running task 14.0 in stage 10.0 (TID 133)
2021-12-06 15:20:29,963 [Executor task launch worker for task 133] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 20 non-empty blocks out of 20 blocks
2021-12-06 15:20:29,963 [Executor task launch worker for task 133] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-06 15:20:29,966 [Executor task launch worker for task 126] INFO [org.apache.spark.executor.Executor] - Finished task 7.0 in stage 10.0 (TID 126). 1098 bytes result sent to driver
2021-12-06 15:20:29,968 [Executor task launch worker for task 123] INFO [org.apache.spark.executor.Executor] - Finished task 4.0 in stage 10.0 (TID 123). 1098 bytes result sent to driver
2021-12-06 15:20:29,970 [Executor task launch worker for task 121] INFO [org.apache.spark.executor.Executor] - Finished task 2.0 in stage 10.0 (TID 121). 1098 bytes result sent to driver
2021-12-06 15:20:29,971 [Executor task launch worker for task 119] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 10.0 (TID 119). 1096 bytes result sent to driver
2021-12-06 15:20:29,972 [dispatcher-event-loop-5] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 15.0 in stage 10.0 (TID 134, localhost, executor driver, partition 15, ANY, 7759 bytes)
2021-12-06 15:20:29,973 [dispatcher-event-loop-5] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 16.0 in stage 10.0 (TID 135, localhost, executor driver, partition 16, ANY, 7759 bytes)
2021-12-06 15:20:29,973 [Executor task launch worker for task 134] INFO [org.apache.spark.executor.Executor] - Running task 15.0 in stage 10.0 (TID 134)
2021-12-06 15:20:29,973 [Executor task launch worker for task 135] INFO [org.apache.spark.executor.Executor] - Running task 16.0 in stage 10.0 (TID 135)
2021-12-06 15:20:29,973 [dispatcher-event-loop-5] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 17.0 in stage 10.0 (TID 136, localhost, executor driver, partition 17, ANY, 7759 bytes)
2021-12-06 15:20:29,973 [Executor task launch worker for task 136] INFO [org.apache.spark.executor.Executor] - Running task 17.0 in stage 10.0 (TID 136)
2021-12-06 15:20:29,973 [dispatcher-event-loop-5] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 18.0 in stage 10.0 (TID 137, localhost, executor driver, partition 18, ANY, 7759 bytes)
2021-12-06 15:20:29,973 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 7.0 in stage 10.0 (TID 126) in 155 ms on localhost (executor driver) (4/20)
2021-12-06 15:20:29,974 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 2.0 in stage 10.0 (TID 121) in 156 ms on localhost (executor driver) (5/20)
2021-12-06 15:20:29,974 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 10.0 (TID 119) in 157 ms on localhost (executor driver) (6/20)
2021-12-06 15:20:29,974 [Executor task launch worker for task 137] INFO [org.apache.spark.executor.Executor] - Running task 18.0 in stage 10.0 (TID 137)
2021-12-06 15:20:29,975 [Executor task launch worker for task 127] INFO [org.apache.spark.executor.Executor] - Finished task 8.0 in stage 10.0 (TID 127). 1098 bytes result sent to driver
2021-12-06 15:20:29,975 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 4.0 in stage 10.0 (TID 123) in 157 ms on localhost (executor driver) (7/20)
2021-12-06 15:20:29,976 [dispatcher-event-loop-9] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 19.0 in stage 10.0 (TID 138, localhost, executor driver, partition 19, ANY, 7759 bytes)
2021-12-06 15:20:29,976 [Executor task launch worker for task 138] INFO [org.apache.spark.executor.Executor] - Running task 19.0 in stage 10.0 (TID 138)
2021-12-06 15:20:29,976 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 8.0 in stage 10.0 (TID 127) in 158 ms on localhost (executor driver) (8/20)
2021-12-06 15:20:29,977 [Executor task launch worker for task 134] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 20 non-empty blocks out of 20 blocks
2021-12-06 15:20:29,977 [Executor task launch worker for task 134] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 1 ms
2021-12-06 15:20:29,977 [Executor task launch worker for task 135] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 20 non-empty blocks out of 20 blocks
2021-12-06 15:20:29,977 [Executor task launch worker for task 135] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-06 15:20:29,977 [Executor task launch worker for task 136] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 20 non-empty blocks out of 20 blocks
2021-12-06 15:20:29,977 [Executor task launch worker for task 136] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-06 15:20:29,977 [Executor task launch worker for task 137] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 20 non-empty blocks out of 20 blocks
2021-12-06 15:20:29,977 [Executor task launch worker for task 137] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-06 15:20:29,978 [Executor task launch worker for task 124] INFO [org.apache.spark.executor.Executor] - Finished task 5.0 in stage 10.0 (TID 124). 1098 bytes result sent to driver
2021-12-06 15:20:29,978 [Executor task launch worker for task 138] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 20 non-empty blocks out of 20 blocks
2021-12-06 15:20:29,978 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 5.0 in stage 10.0 (TID 124) in 160 ms on localhost (executor driver) (9/20)
2021-12-06 15:20:29,978 [Executor task launch worker for task 138] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-06 15:20:29,981 [Executor task launch worker for task 125] INFO [org.apache.spark.executor.Executor] - Finished task 6.0 in stage 10.0 (TID 125). 1098 bytes result sent to driver
2021-12-06 15:20:29,981 [Executor task launch worker for task 130] INFO [org.apache.spark.executor.Executor] - Finished task 11.0 in stage 10.0 (TID 130). 1098 bytes result sent to driver
2021-12-06 15:20:29,981 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 11.0 in stage 10.0 (TID 130) in 162 ms on localhost (executor driver) (10/20)
2021-12-06 15:20:29,981 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 6.0 in stage 10.0 (TID 125) in 163 ms on localhost (executor driver) (11/20)
2021-12-06 15:20:29,981 [Executor task launch worker for task 122] INFO [org.apache.spark.executor.Executor] - Finished task 3.0 in stage 10.0 (TID 122). 1098 bytes result sent to driver
2021-12-06 15:20:29,982 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 3.0 in stage 10.0 (TID 122) in 164 ms on localhost (executor driver) (12/20)
2021-12-06 15:20:30,080 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 75
2021-12-06 15:20:30,081 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 147
2021-12-06 15:20:30,081 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 38
2021-12-06 15:20:30,081 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 128
2021-12-06 15:20:30,081 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 74
2021-12-06 15:20:30,081 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 123
2021-12-06 15:20:30,081 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 94
2021-12-06 15:20:30,081 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 145
2021-12-06 15:20:30,081 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 34
2021-12-06 15:20:30,081 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 69
2021-12-06 15:20:30,081 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 104
2021-12-06 15:20:30,081 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 40
2021-12-06 15:20:30,081 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 138
2021-12-06 15:20:30,081 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 79
2021-12-06 15:20:30,081 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 39
2021-12-06 15:20:30,081 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 48
2021-12-06 15:20:30,081 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 36
2021-12-06 15:20:30,081 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 60
2021-12-06 15:20:30,081 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 115
2021-12-06 15:20:30,081 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 109
2021-12-06 15:20:30,081 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 103
2021-12-06 15:20:30,081 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 100
2021-12-06 15:20:30,081 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 148
2021-12-06 15:20:30,081 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 144
2021-12-06 15:20:30,081 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 55
2021-12-06 15:20:30,081 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 45
2021-12-06 15:20:30,081 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 50
2021-12-06 15:20:30,081 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 80
2021-12-06 15:20:30,081 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 96
2021-12-06 15:20:30,081 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 28
2021-12-06 15:20:30,081 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 125
2021-12-06 15:20:30,081 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 35
2021-12-06 15:20:30,081 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 67
2021-12-06 15:20:30,081 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 143
2021-12-06 15:20:30,081 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 117
2021-12-06 15:20:30,081 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 127
2021-12-06 15:20:30,083 [dispatcher-event-loop-8] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_3_piece0 on qb:52204 in memory (size: 1907.0 B, free: 1990.8 MB)
2021-12-06 15:20:30,083 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 61
2021-12-06 15:20:30,083 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 37
2021-12-06 15:20:30,083 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 124
2021-12-06 15:20:30,083 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 42
2021-12-06 15:20:30,083 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 132
2021-12-06 15:20:30,083 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 32
2021-12-06 15:20:30,083 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 118
2021-12-06 15:20:30,083 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 53
2021-12-06 15:20:30,083 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 140
2021-12-06 15:20:30,083 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 120
2021-12-06 15:20:30,083 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 49
2021-12-06 15:20:30,083 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 126
2021-12-06 15:20:30,083 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 84
2021-12-06 15:20:30,083 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 27
2021-12-06 15:20:30,083 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 111
2021-12-06 15:20:30,083 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 26
2021-12-06 15:20:30,083 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 25
2021-12-06 15:20:30,083 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 88
2021-12-06 15:20:30,084 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 33
2021-12-06 15:20:30,084 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 141
2021-12-06 15:20:30,084 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 62
2021-12-06 15:20:30,084 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 77
2021-12-06 15:20:30,084 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 139
2021-12-06 15:20:30,084 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 135
2021-12-06 15:20:30,084 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 95
2021-12-06 15:20:30,084 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 90
2021-12-06 15:20:30,084 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 31
2021-12-06 15:20:30,084 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 91
2021-12-06 15:20:30,084 [Executor task launch worker for task 133] INFO [org.apache.spark.executor.Executor] - Finished task 14.0 in stage 10.0 (TID 133). 1098 bytes result sent to driver
2021-12-06 15:20:30,084 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 97
2021-12-06 15:20:30,084 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 131
2021-12-06 15:20:30,084 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 87
2021-12-06 15:20:30,084 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 78
2021-12-06 15:20:30,084 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 14.0 in stage 10.0 (TID 133) in 125 ms on localhost (executor driver) (13/20)
2021-12-06 15:20:30,085 [dispatcher-event-loop-9] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_4_piece0 on qb:52204 in memory (size: 2.4 KB, free: 1990.8 MB)
2021-12-06 15:20:30,085 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 46
2021-12-06 15:20:30,085 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 54
2021-12-06 15:20:30,085 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 122
2021-12-06 15:20:30,085 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 137
2021-12-06 15:20:30,085 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 63
2021-12-06 15:20:30,085 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 76
2021-12-06 15:20:30,085 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 142
2021-12-06 15:20:30,085 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 116
2021-12-06 15:20:30,085 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 41
2021-12-06 15:20:30,085 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 149
2021-12-06 15:20:30,085 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 51
2021-12-06 15:20:30,085 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 105
2021-12-06 15:20:30,085 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 66
2021-12-06 15:20:30,085 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 114
2021-12-06 15:20:30,085 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 52
2021-12-06 15:20:30,086 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 58
2021-12-06 15:20:30,086 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 119
2021-12-06 15:20:30,086 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 70
2021-12-06 15:20:30,086 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 102
2021-12-06 15:20:30,086 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 106
2021-12-06 15:20:30,086 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 99
2021-12-06 15:20:30,086 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 133
2021-12-06 15:20:30,086 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 112
2021-12-06 15:20:30,086 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 146
2021-12-06 15:20:30,086 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 134
2021-12-06 15:20:30,086 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 98
2021-12-06 15:20:30,086 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 30
2021-12-06 15:20:30,086 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 81
2021-12-06 15:20:30,086 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 57
2021-12-06 15:20:30,086 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 56
2021-12-06 15:20:30,086 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 47
2021-12-06 15:20:30,086 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 73
2021-12-06 15:20:30,086 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 92
2021-12-06 15:20:30,086 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 107
2021-12-06 15:20:30,086 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 86
2021-12-06 15:20:30,086 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 83
2021-12-06 15:20:30,086 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 43
2021-12-06 15:20:30,086 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 44
2021-12-06 15:20:30,086 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 93
2021-12-06 15:20:30,086 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 108
2021-12-06 15:20:30,086 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 65
2021-12-06 15:20:30,086 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 121
2021-12-06 15:20:30,086 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 85
2021-12-06 15:20:30,086 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 82
2021-12-06 15:20:30,086 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 59
2021-12-06 15:20:30,087 [dispatcher-event-loop-10] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_6_piece0 on qb:52204 in memory (size: 2.0 KB, free: 1990.8 MB)
2021-12-06 15:20:30,087 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 68
2021-12-06 15:20:30,087 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 136
2021-12-06 15:20:30,087 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 129
2021-12-06 15:20:30,087 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 29
2021-12-06 15:20:30,088 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 89
2021-12-06 15:20:30,088 [dispatcher-event-loop-1] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_5_piece0 on qb:52204 in memory (size: 2.4 KB, free: 1990.8 MB)
2021-12-06 15:20:30,089 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 72
2021-12-06 15:20:30,089 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 113
2021-12-06 15:20:30,089 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 130
2021-12-06 15:20:30,089 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 110
2021-12-06 15:20:30,089 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 64
2021-12-06 15:20:30,089 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 101
2021-12-06 15:20:30,089 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 71
2021-12-06 15:20:30,097 [Executor task launch worker for task 131] INFO [org.apache.spark.executor.Executor] - Finished task 12.0 in stage 10.0 (TID 131). 1098 bytes result sent to driver
2021-12-06 15:20:30,098 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 12.0 in stage 10.0 (TID 131) in 156 ms on localhost (executor driver) (14/20)
2021-12-06 15:20:30,103 [Executor task launch worker for task 136] INFO [org.apache.spark.executor.Executor] - Finished task 17.0 in stage 10.0 (TID 136). 1096 bytes result sent to driver
2021-12-06 15:20:30,103 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 17.0 in stage 10.0 (TID 136) in 130 ms on localhost (executor driver) (15/20)
2021-12-06 15:20:30,104 [Executor task launch worker for task 132] INFO [org.apache.spark.executor.Executor] - Finished task 13.0 in stage 10.0 (TID 132). 1098 bytes result sent to driver
2021-12-06 15:20:30,104 [Executor task launch worker for task 137] INFO [org.apache.spark.executor.Executor] - Finished task 18.0 in stage 10.0 (TID 137). 1096 bytes result sent to driver
2021-12-06 15:20:30,104 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 13.0 in stage 10.0 (TID 132) in 150 ms on localhost (executor driver) (16/20)
2021-12-06 15:20:30,104 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 18.0 in stage 10.0 (TID 137) in 131 ms on localhost (executor driver) (17/20)
2021-12-06 15:20:30,105 [Executor task launch worker for task 134] INFO [org.apache.spark.executor.Executor] - Finished task 15.0 in stage 10.0 (TID 134). 1098 bytes result sent to driver
2021-12-06 15:20:30,105 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 15.0 in stage 10.0 (TID 134) in 133 ms on localhost (executor driver) (18/20)
2021-12-06 15:20:30,108 [Executor task launch worker for task 135] INFO [org.apache.spark.executor.Executor] - Finished task 16.0 in stage 10.0 (TID 135). 1098 bytes result sent to driver
2021-12-06 15:20:30,109 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 16.0 in stage 10.0 (TID 135) in 137 ms on localhost (executor driver) (19/20)
2021-12-06 15:20:30,109 [Executor task launch worker for task 138] INFO [org.apache.spark.executor.Executor] - Finished task 19.0 in stage 10.0 (TID 138). 1096 bytes result sent to driver
2021-12-06 15:20:30,109 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 19.0 in stage 10.0 (TID 138) in 134 ms on localhost (executor driver) (20/20)
2021-12-06 15:20:30,109 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 10.0, whose tasks have all completed, from pool 
2021-12-06 15:20:30,109 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 10 (takeSample at PaidPromotionAdjustParameter.scala:77) finished in 0.297 s
2021-12-06 15:20:30,109 [main] INFO [org.apache.spark.scheduler.DAGScheduler] - Job 4 finished: takeSample at PaidPromotionAdjustParameter.scala:77, took 0.299756 s
2021-12-06 15:20:30,123 [main] INFO [org.apache.spark.SparkContext] - Starting job: takeSample at PaidPromotionAdjustParameter.scala:77
2021-12-06 15:20:30,123 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 5 (takeSample at PaidPromotionAdjustParameter.scala:77) with 20 output partitions
2021-12-06 15:20:30,123 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 13 (takeSample at PaidPromotionAdjustParameter.scala:77)
2021-12-06 15:20:30,123 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 12)
2021-12-06 15:20:30,123 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2021-12-06 15:20:30,123 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 13 (PartitionwiseSampledRDD[12] at takeSample at PaidPromotionAdjustParameter.scala:77), which has no missing parents
2021-12-06 15:20:30,126 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_8 stored as values in memory (estimated size 4.9 KB, free 1990.5 MB)
2021-12-06 15:20:30,127 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_8_piece0 stored as bytes in memory (estimated size 2.8 KB, free 1990.5 MB)
2021-12-06 15:20:30,128 [dispatcher-event-loop-6] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_8_piece0 in memory on qb:52204 (size: 2.8 KB, free: 1990.8 MB)
2021-12-06 15:20:30,128 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 8 from broadcast at DAGScheduler.scala:1039
2021-12-06 15:20:30,128 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 20 missing tasks from ResultStage 13 (PartitionwiseSampledRDD[12] at takeSample at PaidPromotionAdjustParameter.scala:77) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14))
2021-12-06 15:20:30,128 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 13.0 with 20 tasks
2021-12-06 15:20:30,129 [dispatcher-event-loop-10] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 13.0 (TID 139, localhost, executor driver, partition 0, ANY, 7868 bytes)
2021-12-06 15:20:30,129 [dispatcher-event-loop-10] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 13.0 (TID 140, localhost, executor driver, partition 1, ANY, 7868 bytes)
2021-12-06 15:20:30,129 [dispatcher-event-loop-10] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 2.0 in stage 13.0 (TID 141, localhost, executor driver, partition 2, ANY, 7868 bytes)
2021-12-06 15:20:30,129 [dispatcher-event-loop-10] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 3.0 in stage 13.0 (TID 142, localhost, executor driver, partition 3, ANY, 7868 bytes)
2021-12-06 15:20:30,129 [dispatcher-event-loop-10] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 4.0 in stage 13.0 (TID 143, localhost, executor driver, partition 4, ANY, 7868 bytes)
2021-12-06 15:20:30,129 [dispatcher-event-loop-10] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 5.0 in stage 13.0 (TID 144, localhost, executor driver, partition 5, ANY, 7868 bytes)
2021-12-06 15:20:30,130 [dispatcher-event-loop-10] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 6.0 in stage 13.0 (TID 145, localhost, executor driver, partition 6, ANY, 7868 bytes)
2021-12-06 15:20:30,130 [dispatcher-event-loop-10] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 7.0 in stage 13.0 (TID 146, localhost, executor driver, partition 7, ANY, 7868 bytes)
2021-12-06 15:20:30,130 [dispatcher-event-loop-10] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 8.0 in stage 13.0 (TID 147, localhost, executor driver, partition 8, ANY, 7868 bytes)
2021-12-06 15:20:30,130 [dispatcher-event-loop-10] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 9.0 in stage 13.0 (TID 148, localhost, executor driver, partition 9, ANY, 7868 bytes)
2021-12-06 15:20:30,130 [dispatcher-event-loop-10] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 10.0 in stage 13.0 (TID 149, localhost, executor driver, partition 10, ANY, 7868 bytes)
2021-12-06 15:20:30,130 [dispatcher-event-loop-10] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 11.0 in stage 13.0 (TID 150, localhost, executor driver, partition 11, ANY, 7868 bytes)
2021-12-06 15:20:30,130 [Executor task launch worker for task 139] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 13.0 (TID 139)
2021-12-06 15:20:30,130 [Executor task launch worker for task 144] INFO [org.apache.spark.executor.Executor] - Running task 5.0 in stage 13.0 (TID 144)
2021-12-06 15:20:30,130 [Executor task launch worker for task 148] INFO [org.apache.spark.executor.Executor] - Running task 9.0 in stage 13.0 (TID 148)
2021-12-06 15:20:30,130 [Executor task launch worker for task 147] INFO [org.apache.spark.executor.Executor] - Running task 8.0 in stage 13.0 (TID 147)
2021-12-06 15:20:30,130 [Executor task launch worker for task 145] INFO [org.apache.spark.executor.Executor] - Running task 6.0 in stage 13.0 (TID 145)
2021-12-06 15:20:30,130 [Executor task launch worker for task 140] INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 13.0 (TID 140)
2021-12-06 15:20:30,130 [Executor task launch worker for task 143] INFO [org.apache.spark.executor.Executor] - Running task 4.0 in stage 13.0 (TID 143)
2021-12-06 15:20:30,130 [Executor task launch worker for task 141] INFO [org.apache.spark.executor.Executor] - Running task 2.0 in stage 13.0 (TID 141)
2021-12-06 15:20:30,130 [Executor task launch worker for task 142] INFO [org.apache.spark.executor.Executor] - Running task 3.0 in stage 13.0 (TID 142)
2021-12-06 15:20:30,130 [Executor task launch worker for task 150] INFO [org.apache.spark.executor.Executor] - Running task 11.0 in stage 13.0 (TID 150)
2021-12-06 15:20:30,130 [Executor task launch worker for task 146] INFO [org.apache.spark.executor.Executor] - Running task 7.0 in stage 13.0 (TID 146)
2021-12-06 15:20:30,130 [Executor task launch worker for task 149] INFO [org.apache.spark.executor.Executor] - Running task 10.0 in stage 13.0 (TID 149)
2021-12-06 15:20:30,134 [Executor task launch worker for task 150] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 20 non-empty blocks out of 20 blocks
2021-12-06 15:20:30,134 [Executor task launch worker for task 146] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 20 non-empty blocks out of 20 blocks
2021-12-06 15:20:30,134 [Executor task launch worker for task 150] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-06 15:20:30,134 [Executor task launch worker for task 146] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-06 15:20:30,134 [Executor task launch worker for task 148] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 20 non-empty blocks out of 20 blocks
2021-12-06 15:20:30,134 [Executor task launch worker for task 148] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-06 15:20:30,135 [Executor task launch worker for task 149] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 20 non-empty blocks out of 20 blocks
2021-12-06 15:20:30,135 [Executor task launch worker for task 149] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 1 ms
2021-12-06 15:20:30,135 [Executor task launch worker for task 144] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 20 non-empty blocks out of 20 blocks
2021-12-06 15:20:30,135 [Executor task launch worker for task 144] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-06 15:20:30,136 [Executor task launch worker for task 147] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 20 non-empty blocks out of 20 blocks
2021-12-06 15:20:30,136 [Executor task launch worker for task 140] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 20 non-empty blocks out of 20 blocks
2021-12-06 15:20:30,136 [Executor task launch worker for task 147] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-06 15:20:30,136 [Executor task launch worker for task 140] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-06 15:20:30,136 [Executor task launch worker for task 139] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 20 non-empty blocks out of 20 blocks
2021-12-06 15:20:30,136 [Executor task launch worker for task 139] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-06 15:20:30,136 [Executor task launch worker for task 145] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 20 non-empty blocks out of 20 blocks
2021-12-06 15:20:30,137 [Executor task launch worker for task 145] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 1 ms
2021-12-06 15:20:30,137 [Executor task launch worker for task 141] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 20 non-empty blocks out of 20 blocks
2021-12-06 15:20:30,137 [Executor task launch worker for task 141] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-06 15:20:30,137 [Executor task launch worker for task 142] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 20 non-empty blocks out of 20 blocks
2021-12-06 15:20:30,137 [Executor task launch worker for task 142] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-06 15:20:30,138 [Executor task launch worker for task 143] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 20 non-empty blocks out of 20 blocks
2021-12-06 15:20:30,138 [Executor task launch worker for task 143] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-06 15:20:30,254 [Executor task launch worker for task 144] INFO [org.apache.spark.executor.Executor] - Finished task 5.0 in stage 13.0 (TID 144). 226469 bytes result sent to driver
2021-12-06 15:20:30,255 [Executor task launch worker for task 141] INFO [org.apache.spark.executor.Executor] - Finished task 2.0 in stage 13.0 (TID 141). 201203 bytes result sent to driver
2021-12-06 15:20:30,255 [dispatcher-event-loop-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 12.0 in stage 13.0 (TID 151, localhost, executor driver, partition 12, ANY, 7868 bytes)
2021-12-06 15:20:30,256 [dispatcher-event-loop-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 13.0 in stage 13.0 (TID 152, localhost, executor driver, partition 13, ANY, 7868 bytes)
2021-12-06 15:20:30,256 [Executor task launch worker for task 152] INFO [org.apache.spark.executor.Executor] - Running task 13.0 in stage 13.0 (TID 152)
2021-12-06 15:20:30,257 [Executor task launch worker for task 140] INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 13.0 (TID 140). 4014 bytes result sent to driver
2021-12-06 15:20:30,257 [dispatcher-event-loop-7] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 14.0 in stage 13.0 (TID 153, localhost, executor driver, partition 14, ANY, 7868 bytes)
2021-12-06 15:20:30,257 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 13.0 (TID 140) in 128 ms on localhost (executor driver) (1/20)
2021-12-06 15:20:30,259 [Executor task launch worker for task 152] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 20 non-empty blocks out of 20 blocks
2021-12-06 15:20:30,259 [Executor task launch worker for task 152] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-06 15:20:30,260 [Executor task launch worker for task 151] INFO [org.apache.spark.executor.Executor] - Running task 12.0 in stage 13.0 (TID 151)
2021-12-06 15:20:30,260 [Executor task launch worker for task 150] INFO [org.apache.spark.executor.Executor] - Finished task 11.0 in stage 13.0 (TID 150). 224149 bytes result sent to driver
2021-12-06 15:20:30,260 [dispatcher-event-loop-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 15.0 in stage 13.0 (TID 154, localhost, executor driver, partition 15, ANY, 7868 bytes)
2021-12-06 15:20:30,260 [Executor task launch worker for task 154] INFO [org.apache.spark.executor.Executor] - Running task 15.0 in stage 13.0 (TID 154)
2021-12-06 15:20:30,261 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 2.0 in stage 13.0 (TID 141) in 132 ms on localhost (executor driver) (2/20)
2021-12-06 15:20:30,261 [Executor task launch worker for task 145] INFO [org.apache.spark.executor.Executor] - Finished task 6.0 in stage 13.0 (TID 145). 255654 bytes result sent to driver
2021-12-06 15:20:30,262 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 5.0 in stage 13.0 (TID 144) in 133 ms on localhost (executor driver) (3/20)
2021-12-06 15:20:30,262 [Executor task launch worker for task 148] INFO [org.apache.spark.executor.Executor] - Finished task 9.0 in stage 13.0 (TID 148). 217552 bytes result sent to driver
2021-12-06 15:20:30,262 [Executor task launch worker for task 153] INFO [org.apache.spark.executor.Executor] - Running task 14.0 in stage 13.0 (TID 153)
2021-12-06 15:20:30,262 [Executor task launch worker for task 139] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 13.0 (TID 139). 1097 bytes result sent to driver
2021-12-06 15:20:30,263 [Executor task launch worker for task 146] INFO [org.apache.spark.executor.Executor] - Finished task 7.0 in stage 13.0 (TID 146). 246699 bytes result sent to driver
2021-12-06 15:20:30,263 [Executor task launch worker for task 154] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 20 non-empty blocks out of 20 blocks
2021-12-06 15:20:30,263 [Executor task launch worker for task 154] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-06 15:20:30,263 [dispatcher-event-loop-9] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 16.0 in stage 13.0 (TID 155, localhost, executor driver, partition 16, ANY, 7868 bytes)
2021-12-06 15:20:30,264 [dispatcher-event-loop-9] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 17.0 in stage 13.0 (TID 156, localhost, executor driver, partition 17, ANY, 7868 bytes)
2021-12-06 15:20:30,264 [Executor task launch worker for task 142] INFO [org.apache.spark.executor.Executor] - Finished task 3.0 in stage 13.0 (TID 142). 227365 bytes result sent to driver
2021-12-06 15:20:30,265 [Executor task launch worker for task 156] INFO [org.apache.spark.executor.Executor] - Running task 17.0 in stage 13.0 (TID 156)
2021-12-06 15:20:30,265 [dispatcher-event-loop-9] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 18.0 in stage 13.0 (TID 157, localhost, executor driver, partition 18, ANY, 7868 bytes)
2021-12-06 15:20:30,265 [dispatcher-event-loop-9] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 19.0 in stage 13.0 (TID 158, localhost, executor driver, partition 19, ANY, 7868 bytes)
2021-12-06 15:20:30,266 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 11.0 in stage 13.0 (TID 150) in 136 ms on localhost (executor driver) (4/20)
2021-12-06 15:20:30,266 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 13.0 (TID 139) in 137 ms on localhost (executor driver) (5/20)
2021-12-06 15:20:30,266 [Executor task launch worker for task 151] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 20 non-empty blocks out of 20 blocks
2021-12-06 15:20:30,266 [Executor task launch worker for task 151] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-06 15:20:30,266 [Executor task launch worker for task 147] INFO [org.apache.spark.executor.Executor] - Finished task 8.0 in stage 13.0 (TID 147). 249684 bytes result sent to driver
2021-12-06 15:20:30,265 [Executor task launch worker for task 153] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 20 non-empty blocks out of 20 blocks
2021-12-06 15:20:30,267 [Executor task launch worker for task 153] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 2 ms
2021-12-06 15:20:30,266 [Executor task launch worker for task 155] INFO [org.apache.spark.executor.Executor] - Running task 16.0 in stage 13.0 (TID 155)
2021-12-06 15:20:30,267 [Executor task launch worker for task 157] INFO [org.apache.spark.executor.Executor] - Running task 18.0 in stage 13.0 (TID 157)
2021-12-06 15:20:30,267 [Executor task launch worker for task 156] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 20 non-empty blocks out of 20 blocks
2021-12-06 15:20:30,267 [Executor task launch worker for task 156] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-06 15:20:30,267 [Executor task launch worker for task 149] INFO [org.apache.spark.executor.Executor] - Finished task 10.0 in stage 13.0 (TID 149). 203193 bytes result sent to driver
2021-12-06 15:20:30,269 [Executor task launch worker for task 158] INFO [org.apache.spark.executor.Executor] - Running task 19.0 in stage 13.0 (TID 158)
2021-12-06 15:20:30,271 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 9.0 in stage 13.0 (TID 148) in 141 ms on localhost (executor driver) (6/20)
2021-12-06 15:20:30,271 [Executor task launch worker for task 157] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 20 non-empty blocks out of 20 blocks
2021-12-06 15:20:30,271 [Executor task launch worker for task 157] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-06 15:20:30,272 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 6.0 in stage 13.0 (TID 145) in 142 ms on localhost (executor driver) (7/20)
2021-12-06 15:20:30,272 [Executor task launch worker for task 155] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 20 non-empty blocks out of 20 blocks
2021-12-06 15:20:30,272 [Executor task launch worker for task 155] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 1 ms
2021-12-06 15:20:30,273 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 7.0 in stage 13.0 (TID 146) in 143 ms on localhost (executor driver) (8/20)
2021-12-06 15:20:30,273 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 3.0 in stage 13.0 (TID 142) in 144 ms on localhost (executor driver) (9/20)
2021-12-06 15:20:30,275 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 10.0 in stage 13.0 (TID 149) in 145 ms on localhost (executor driver) (10/20)
2021-12-06 15:20:30,276 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 8.0 in stage 13.0 (TID 147) in 146 ms on localhost (executor driver) (11/20)
2021-12-06 15:20:30,277 [Executor task launch worker for task 158] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 20 non-empty blocks out of 20 blocks
2021-12-06 15:20:30,278 [Executor task launch worker for task 158] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 1 ms
2021-12-06 15:20:30,284 [Executor task launch worker for task 143] INFO [org.apache.spark.executor.Executor] - Finished task 4.0 in stage 13.0 (TID 143). 223895 bytes result sent to driver
2021-12-06 15:20:30,287 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 4.0 in stage 13.0 (TID 143) in 158 ms on localhost (executor driver) (12/20)
2021-12-06 15:20:30,339 [Executor task launch worker for task 156] INFO [org.apache.spark.executor.Executor] - Finished task 17.0 in stage 13.0 (TID 156). 1097 bytes result sent to driver
2021-12-06 15:20:30,339 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 17.0 in stage 13.0 (TID 156) in 75 ms on localhost (executor driver) (13/20)
2021-12-06 15:20:30,342 [Executor task launch worker for task 157] INFO [org.apache.spark.executor.Executor] - Finished task 18.0 in stage 13.0 (TID 157). 1097 bytes result sent to driver
2021-12-06 15:20:30,342 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 18.0 in stage 13.0 (TID 157) in 78 ms on localhost (executor driver) (14/20)
2021-12-06 15:20:30,344 [Executor task launch worker for task 151] INFO [org.apache.spark.executor.Executor] - Finished task 12.0 in stage 13.0 (TID 151). 195398 bytes result sent to driver
2021-12-06 15:20:30,346 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 12.0 in stage 13.0 (TID 151) in 91 ms on localhost (executor driver) (15/20)
2021-12-06 15:20:30,346 [Executor task launch worker for task 152] INFO [org.apache.spark.executor.Executor] - Finished task 13.0 in stage 13.0 (TID 152). 264241 bytes result sent to driver
2021-12-06 15:20:30,347 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 13.0 in stage 13.0 (TID 152) in 91 ms on localhost (executor driver) (16/20)
2021-12-06 15:20:30,348 [Executor task launch worker for task 154] INFO [org.apache.spark.executor.Executor] - Finished task 15.0 in stage 13.0 (TID 154). 246676 bytes result sent to driver
2021-12-06 15:20:30,349 [Executor task launch worker for task 153] INFO [org.apache.spark.executor.Executor] - Finished task 14.0 in stage 13.0 (TID 153). 167850 bytes result sent to driver
2021-12-06 15:20:30,349 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 15.0 in stage 13.0 (TID 154) in 89 ms on localhost (executor driver) (17/20)
2021-12-06 15:20:30,350 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 14.0 in stage 13.0 (TID 153) in 93 ms on localhost (executor driver) (18/20)
2021-12-06 15:20:30,352 [Executor task launch worker for task 155] INFO [org.apache.spark.executor.Executor] - Finished task 16.0 in stage 13.0 (TID 155). 223654 bytes result sent to driver
2021-12-06 15:20:30,353 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 16.0 in stage 13.0 (TID 155) in 90 ms on localhost (executor driver) (19/20)
2021-12-06 15:20:30,361 [Executor task launch worker for task 158] INFO [org.apache.spark.executor.Executor] - Finished task 19.0 in stage 13.0 (TID 158). 1097 bytes result sent to driver
2021-12-06 15:20:30,361 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 19.0 in stage 13.0 (TID 158) in 96 ms on localhost (executor driver) (20/20)
2021-12-06 15:20:30,362 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 13.0, whose tasks have all completed, from pool 
2021-12-06 15:20:30,362 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 13 (takeSample at PaidPromotionAdjustParameter.scala:77) finished in 0.237 s
2021-12-06 15:20:30,362 [main] INFO [org.apache.spark.scheduler.DAGScheduler] - Job 5 finished: takeSample at PaidPromotionAdjustParameter.scala:77, took 0.239371 s
2021-12-06 15:20:30,384 [main] INFO [PaidPromotion$] - 100000
2021-12-06 15:20:30,429 [main] INFO [org.apache.spark.SparkContext] - Starting job: count at PaidPromotionAdjustParameter.scala:85
2021-12-06 15:20:30,429 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 6 (count at PaidPromotionAdjustParameter.scala:85) with 20 output partitions
2021-12-06 15:20:30,430 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 14 (count at PaidPromotionAdjustParameter.scala:85)
2021-12-06 15:20:30,430 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List()
2021-12-06 15:20:30,430 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2021-12-06 15:20:30,430 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 14 (MapPartitionsRDD[14] at map at PaidPromotionAdjustParameter.scala:83), which has no missing parents
2021-12-06 15:20:30,463 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_9 stored as values in memory (estimated size 3.3 MB, free 1987.1 MB)
2021-12-06 15:20:30,471 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_9_piece0 stored as bytes in memory (estimated size 1172.5 KB, free 1986.0 MB)
2021-12-06 15:20:30,472 [dispatcher-event-loop-8] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_9_piece0 in memory on qb:52204 (size: 1172.5 KB, free: 1989.6 MB)
2021-12-06 15:20:30,472 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 9 from broadcast at DAGScheduler.scala:1039
2021-12-06 15:20:30,473 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 20 missing tasks from ResultStage 14 (MapPartitionsRDD[14] at map at PaidPromotionAdjustParameter.scala:83) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14))
2021-12-06 15:20:30,473 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 14.0 with 20 tasks
2021-12-06 15:20:30,473 [dispatcher-event-loop-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 14.0 (TID 159, localhost, executor driver, partition 0, ANY, 7899 bytes)
2021-12-06 15:20:30,473 [dispatcher-event-loop-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 14.0 (TID 160, localhost, executor driver, partition 1, ANY, 7899 bytes)
2021-12-06 15:20:30,473 [dispatcher-event-loop-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 2.0 in stage 14.0 (TID 161, localhost, executor driver, partition 2, ANY, 7899 bytes)
2021-12-06 15:20:30,473 [dispatcher-event-loop-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 3.0 in stage 14.0 (TID 162, localhost, executor driver, partition 3, ANY, 7899 bytes)
2021-12-06 15:20:30,474 [dispatcher-event-loop-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 4.0 in stage 14.0 (TID 163, localhost, executor driver, partition 4, ANY, 7899 bytes)
2021-12-06 15:20:30,474 [dispatcher-event-loop-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 5.0 in stage 14.0 (TID 164, localhost, executor driver, partition 5, ANY, 7899 bytes)
2021-12-06 15:20:30,474 [dispatcher-event-loop-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 6.0 in stage 14.0 (TID 165, localhost, executor driver, partition 6, ANY, 7899 bytes)
2021-12-06 15:20:30,474 [dispatcher-event-loop-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 7.0 in stage 14.0 (TID 166, localhost, executor driver, partition 7, ANY, 7899 bytes)
2021-12-06 15:20:30,474 [dispatcher-event-loop-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 8.0 in stage 14.0 (TID 167, localhost, executor driver, partition 8, ANY, 7899 bytes)
2021-12-06 15:20:30,474 [dispatcher-event-loop-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 9.0 in stage 14.0 (TID 168, localhost, executor driver, partition 9, ANY, 7899 bytes)
2021-12-06 15:20:30,474 [dispatcher-event-loop-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 10.0 in stage 14.0 (TID 169, localhost, executor driver, partition 10, ANY, 7899 bytes)
2021-12-06 15:20:30,474 [dispatcher-event-loop-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 11.0 in stage 14.0 (TID 170, localhost, executor driver, partition 11, ANY, 7899 bytes)
2021-12-06 15:20:30,474 [Executor task launch worker for task 159] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 14.0 (TID 159)
2021-12-06 15:20:30,474 [Executor task launch worker for task 165] INFO [org.apache.spark.executor.Executor] - Running task 6.0 in stage 14.0 (TID 165)
2021-12-06 15:20:30,474 [Executor task launch worker for task 169] INFO [org.apache.spark.executor.Executor] - Running task 10.0 in stage 14.0 (TID 169)
2021-12-06 15:20:30,474 [Executor task launch worker for task 163] INFO [org.apache.spark.executor.Executor] - Running task 4.0 in stage 14.0 (TID 163)
2021-12-06 15:20:30,474 [Executor task launch worker for task 162] INFO [org.apache.spark.executor.Executor] - Running task 3.0 in stage 14.0 (TID 162)
2021-12-06 15:20:30,474 [Executor task launch worker for task 161] INFO [org.apache.spark.executor.Executor] - Running task 2.0 in stage 14.0 (TID 161)
2021-12-06 15:20:30,474 [Executor task launch worker for task 160] INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 14.0 (TID 160)
2021-12-06 15:20:30,474 [Executor task launch worker for task 170] INFO [org.apache.spark.executor.Executor] - Running task 11.0 in stage 14.0 (TID 170)
2021-12-06 15:20:30,474 [Executor task launch worker for task 166] INFO [org.apache.spark.executor.Executor] - Running task 7.0 in stage 14.0 (TID 166)
2021-12-06 15:20:30,474 [Executor task launch worker for task 168] INFO [org.apache.spark.executor.Executor] - Running task 9.0 in stage 14.0 (TID 168)
2021-12-06 15:20:30,474 [Executor task launch worker for task 164] INFO [org.apache.spark.executor.Executor] - Running task 5.0 in stage 14.0 (TID 164)
2021-12-06 15:20:30,474 [Executor task launch worker for task 167] INFO [org.apache.spark.executor.Executor] - Running task 8.0 in stage 14.0 (TID 167)
2021-12-06 15:20:30,553 [Executor task launch worker for task 163] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:536870912+134217728
2021-12-06 15:20:30,554 [Executor task launch worker for task 169] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:1342177280+134217728
2021-12-06 15:20:30,554 [Executor task launch worker for task 160] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:134217728+134217728
2021-12-06 15:20:30,555 [Executor task launch worker for task 166] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:939524096+134217728
2021-12-06 15:20:30,556 [Executor task launch worker for task 161] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:268435456+134217728
2021-12-06 15:20:30,557 [Executor task launch worker for task 167] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:1073741824+134217728
2021-12-06 15:20:30,558 [Executor task launch worker for task 170] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:1476395008+134217728
2021-12-06 15:20:30,559 [Executor task launch worker for task 168] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:1207959552+134217728
2021-12-06 15:20:30,568 [Executor task launch worker for task 164] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:671088640+134217728
2021-12-06 15:20:30,573 [Executor task launch worker for task 165] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:805306368+134217728
2021-12-06 15:20:30,573 [Executor task launch worker for task 159] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:0+134217728
2021-12-06 15:20:30,573 [Executor task launch worker for task 162] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:402653184+134217728
2021-12-06 15:40:29,263 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 190
2021-12-06 15:40:29,263 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 151
2021-12-06 15:40:29,263 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 179
2021-12-06 15:40:29,263 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 182
2021-12-06 15:40:29,263 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 187
2021-12-06 15:40:29,263 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 160
2021-12-06 15:40:29,263 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 165
2021-12-06 15:40:29,263 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 189
2021-12-06 15:40:29,263 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 170
2021-12-06 15:40:29,263 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 169
2021-12-06 15:40:29,300 [dispatcher-event-loop-8] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_8_piece0 on qb:52204 in memory (size: 2.8 KB, free: 1989.6 MB)
2021-12-06 15:40:29,333 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 188
2021-12-06 15:40:29,333 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 155
2021-12-06 15:40:29,333 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 162
2021-12-06 15:40:29,333 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 158
2021-12-06 15:40:29,333 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 157
2021-12-06 15:40:29,333 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 154
2021-12-06 15:40:29,333 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 199
2021-12-06 15:40:29,334 [dispatcher-event-loop-5] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_7_piece0 on qb:52204 in memory (size: 2.4 KB, free: 1989.6 MB)
2021-12-06 15:40:29,334 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 152
2021-12-06 15:40:29,334 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 196
2021-12-06 15:40:29,334 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 161
2021-12-06 15:40:29,334 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 184
2021-12-06 15:40:29,334 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 163
2021-12-06 15:40:29,334 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 198
2021-12-06 15:40:29,334 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 185
2021-12-06 15:40:29,334 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 168
2021-12-06 15:40:29,334 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 150
2021-12-06 15:40:29,334 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 197
2021-12-06 15:40:29,334 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 178
2021-12-06 15:40:29,334 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 171
2021-12-06 15:40:29,334 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 177
2021-12-06 15:40:29,334 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 194
2021-12-06 15:40:29,334 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 166
2021-12-06 15:40:29,335 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 173
2021-12-06 15:40:29,335 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 180
2021-12-06 15:40:29,335 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 193
2021-12-06 15:40:29,335 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 176
2021-12-06 15:40:29,335 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 183
2021-12-06 15:40:29,335 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 195
2021-12-06 15:40:29,335 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 191
2021-12-06 15:40:29,335 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 181
2021-12-06 15:40:29,335 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 167
2021-12-06 15:40:29,335 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 175
2021-12-06 15:40:29,335 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 172
2021-12-06 15:40:29,335 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 153
2021-12-06 15:40:29,335 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 164
2021-12-06 15:40:29,335 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 159
2021-12-06 15:40:29,335 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 156
2021-12-06 15:40:29,335 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 192
2021-12-06 15:40:29,335 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 174
2021-12-06 15:40:29,335 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 186
2021-12-06 16:31:53,281 [SparkUI-42] INFO [org.spark_project.jetty.servlet.DefaultServlet] - content=ResourceHttpContent@715f34dc{r=jar:file:/C:/Users/ACER/.m2/repository/org/apache/spark/spark-core_2.11/2.3.0/spark-core_2.11-2.3.0.jar!/org/apache/spark/ui/static/vis.min.css,gz=false}
2021-12-06 16:31:53,281 [SparkUI-39] INFO [org.spark_project.jetty.servlet.DefaultServlet] - content=ResourceHttpContent@5084aaf7{r=jar:file:/C:/Users/ACER/.m2/repository/org/apache/spark/spark-core_2.11/2.3.0/spark-core_2.11-2.3.0.jar!/org/apache/spark/ui/static/webui.css,gz=false}
2021-12-06 16:31:53,282 [SparkUI-40] INFO [org.spark_project.jetty.servlet.DefaultServlet] - content=ResourceHttpContent@755b89ec{r=jar:file:/C:/Users/ACER/.m2/repository/org/apache/spark/spark-core_2.11/2.3.0/spark-core_2.11-2.3.0.jar!/org/apache/spark/ui/static/timeline-view.css,gz=false}
2021-12-06 16:31:53,283 [SparkUI-42] WARN [org.spark_project.jetty.servlet.ServletHandler] - Error for /static/vis.min.css
java.lang.NoSuchMethodError: javax.servlet.http.HttpServletRequest.isAsyncSupported()Z
	at org.spark_project.jetty.servlet.DefaultServlet.sendData(DefaultServlet.java:909)
	at org.spark_project.jetty.servlet.DefaultServlet.doGet(DefaultServlet.java:526)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:707)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:820)
	at org.spark_project.jetty.servlet.ServletHolder.handle(ServletHolder.java:848)
	at org.spark_project.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:584)
	at org.spark_project.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
	at org.spark_project.jetty.servlet.ServletHandler.doScope(ServletHandler.java:512)
	at org.spark_project.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
	at org.spark_project.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.spark_project.jetty.server.handler.gzip.GzipHandler.handle(GzipHandler.java:493)
	at org.spark_project.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:213)
	at org.spark_project.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
	at org.spark_project.jetty.server.Server.handle(Server.java:534)
	at org.spark_project.jetty.server.HttpChannel.handle(HttpChannel.java:320)
	at org.spark_project.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
	at org.spark_project.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
	at org.spark_project.jetty.io.FillInterest.fillable(FillInterest.java:108)
	at org.spark_project.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
	at org.spark_project.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
	at org.spark_project.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
	at java.lang.Thread.run(Thread.java:745)
2021-12-06 16:31:53,283 [SparkUI-39] WARN [org.spark_project.jetty.servlet.ServletHandler] - Error for /static/webui.css
java.lang.NoSuchMethodError: javax.servlet.http.HttpServletRequest.isAsyncSupported()Z
	at org.spark_project.jetty.servlet.DefaultServlet.sendData(DefaultServlet.java:909)
	at org.spark_project.jetty.servlet.DefaultServlet.doGet(DefaultServlet.java:526)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:707)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:820)
	at org.spark_project.jetty.servlet.ServletHolder.handle(ServletHolder.java:848)
	at org.spark_project.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:584)
	at org.spark_project.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
	at org.spark_project.jetty.servlet.ServletHandler.doScope(ServletHandler.java:512)
	at org.spark_project.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
	at org.spark_project.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.spark_project.jetty.server.handler.gzip.GzipHandler.handle(GzipHandler.java:493)
	at org.spark_project.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:213)
	at org.spark_project.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
	at org.spark_project.jetty.server.Server.handle(Server.java:534)
	at org.spark_project.jetty.server.HttpChannel.handle(HttpChannel.java:320)
	at org.spark_project.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
	at org.spark_project.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
	at org.spark_project.jetty.io.FillInterest.fillable(FillInterest.java:108)
	at org.spark_project.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.execute(ExecuteProduceConsume.java:100)
	at org.spark_project.jetty.io.ManagedSelector.run(ManagedSelector.java:147)
	at org.spark_project.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
	at org.spark_project.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
	at java.lang.Thread.run(Thread.java:745)
2021-12-06 16:31:53,283 [SparkUI-40] WARN [org.spark_project.jetty.servlet.ServletHandler] - Error for /static/timeline-view.css
java.lang.NoSuchMethodError: javax.servlet.http.HttpServletRequest.isAsyncSupported()Z
	at org.spark_project.jetty.servlet.DefaultServlet.sendData(DefaultServlet.java:909)
	at org.spark_project.jetty.servlet.DefaultServlet.doGet(DefaultServlet.java:526)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:707)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:820)
	at org.spark_project.jetty.servlet.ServletHolder.handle(ServletHolder.java:848)
	at org.spark_project.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:584)
	at org.spark_project.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
	at org.spark_project.jetty.servlet.ServletHandler.doScope(ServletHandler.java:512)
	at org.spark_project.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
	at org.spark_project.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.spark_project.jetty.server.handler.gzip.GzipHandler.handle(GzipHandler.java:493)
	at org.spark_project.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:213)
	at org.spark_project.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
	at org.spark_project.jetty.server.Server.handle(Server.java:534)
	at org.spark_project.jetty.server.HttpChannel.handle(HttpChannel.java:320)
	at org.spark_project.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
	at org.spark_project.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
	at org.spark_project.jetty.io.FillInterest.fillable(FillInterest.java:108)
	at org.spark_project.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.execute(ExecuteProduceConsume.java:100)
	at org.spark_project.jetty.io.ManagedSelector.run(ManagedSelector.java:147)
	at org.spark_project.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
	at org.spark_project.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
	at java.lang.Thread.run(Thread.java:745)
2021-12-06 16:31:53,287 [SparkUI-39] WARN [org.spark_project.jetty.server.HttpChannel] - //qb:4040/static/webui.css
java.lang.NoSuchMethodError: javax.servlet.http.HttpServletRequest.isAsyncStarted()Z
	at org.spark_project.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:688)
	at org.spark_project.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
	at org.spark_project.jetty.servlet.ServletHandler.doScope(ServletHandler.java:512)
	at org.spark_project.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
	at org.spark_project.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.spark_project.jetty.server.handler.gzip.GzipHandler.handle(GzipHandler.java:493)
	at org.spark_project.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:213)
	at org.spark_project.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
	at org.spark_project.jetty.server.Server.handle(Server.java:534)
	at org.spark_project.jetty.server.HttpChannel.handle(HttpChannel.java:320)
	at org.spark_project.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
	at org.spark_project.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
	at org.spark_project.jetty.io.FillInterest.fillable(FillInterest.java:108)
	at org.spark_project.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.execute(ExecuteProduceConsume.java:100)
	at org.spark_project.jetty.io.ManagedSelector.run(ManagedSelector.java:147)
	at org.spark_project.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
	at org.spark_project.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
	at java.lang.Thread.run(Thread.java:745)
2021-12-06 16:31:53,287 [SparkUI-42] WARN [org.spark_project.jetty.server.HttpChannel] - //qb:4040/static/vis.min.css
java.lang.NoSuchMethodError: javax.servlet.http.HttpServletRequest.isAsyncStarted()Z
	at org.spark_project.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:688)
	at org.spark_project.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
	at org.spark_project.jetty.servlet.ServletHandler.doScope(ServletHandler.java:512)
	at org.spark_project.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
	at org.spark_project.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.spark_project.jetty.server.handler.gzip.GzipHandler.handle(GzipHandler.java:493)
	at org.spark_project.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:213)
	at org.spark_project.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
	at org.spark_project.jetty.server.Server.handle(Server.java:534)
	at org.spark_project.jetty.server.HttpChannel.handle(HttpChannel.java:320)
	at org.spark_project.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
	at org.spark_project.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
	at org.spark_project.jetty.io.FillInterest.fillable(FillInterest.java:108)
	at org.spark_project.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
	at org.spark_project.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
	at org.spark_project.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
	at java.lang.Thread.run(Thread.java:745)
2021-12-06 16:31:53,287 [SparkUI-40] WARN [org.spark_project.jetty.server.HttpChannel] - //qb:4040/static/timeline-view.css
java.lang.NoSuchMethodError: javax.servlet.http.HttpServletRequest.isAsyncStarted()Z
	at org.spark_project.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:688)
	at org.spark_project.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
	at org.spark_project.jetty.servlet.ServletHandler.doScope(ServletHandler.java:512)
	at org.spark_project.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
	at org.spark_project.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.spark_project.jetty.server.handler.gzip.GzipHandler.handle(GzipHandler.java:493)
	at org.spark_project.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:213)
	at org.spark_project.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
	at org.spark_project.jetty.server.Server.handle(Server.java:534)
	at org.spark_project.jetty.server.HttpChannel.handle(HttpChannel.java:320)
	at org.spark_project.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
	at org.spark_project.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
	at org.spark_project.jetty.io.FillInterest.fillable(FillInterest.java:108)
	at org.spark_project.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.execute(ExecuteProduceConsume.java:100)
	at org.spark_project.jetty.io.ManagedSelector.run(ManagedSelector.java:147)
	at org.spark_project.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
	at org.spark_project.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
	at java.lang.Thread.run(Thread.java:745)
2021-12-06 16:31:53,291 [SparkUI-43] INFO [org.spark_project.jetty.servlet.DefaultServlet] - content=ResourceHttpContent@321692ae{r=jar:file:/C:/Users/ACER/.m2/repository/org/apache/spark/spark-core_2.11/2.3.0/spark-core_2.11-2.3.0.jar!/org/apache/spark/ui/static/bootstrap.min.css,gz=false}
2021-12-06 16:31:53,291 [SparkUI-43] WARN [org.spark_project.jetty.servlet.ServletHandler] - Error for /static/bootstrap.min.css
java.lang.NoSuchMethodError: javax.servlet.http.HttpServletRequest.isAsyncSupported()Z
	at org.spark_project.jetty.servlet.DefaultServlet.sendData(DefaultServlet.java:909)
	at org.spark_project.jetty.servlet.DefaultServlet.doGet(DefaultServlet.java:526)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:707)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:820)
	at org.spark_project.jetty.servlet.ServletHolder.handle(ServletHolder.java:848)
	at org.spark_project.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:584)
	at org.spark_project.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
	at org.spark_project.jetty.servlet.ServletHandler.doScope(ServletHandler.java:512)
	at org.spark_project.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
	at org.spark_project.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.spark_project.jetty.server.handler.gzip.GzipHandler.handle(GzipHandler.java:493)
	at org.spark_project.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:213)
	at org.spark_project.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
	at org.spark_project.jetty.server.Server.handle(Server.java:534)
	at org.spark_project.jetty.server.HttpChannel.handle(HttpChannel.java:320)
	at org.spark_project.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
	at org.spark_project.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
	at org.spark_project.jetty.io.FillInterest.fillable(FillInterest.java:108)
	at org.spark_project.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
	at org.spark_project.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
	at org.spark_project.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
	at java.lang.Thread.run(Thread.java:745)
2021-12-06 16:31:53,291 [SparkUI-43] WARN [org.spark_project.jetty.server.HttpChannel] - //qb:4040/static/bootstrap.min.css
java.lang.NoSuchMethodError: javax.servlet.http.HttpServletRequest.isAsyncStarted()Z
	at org.spark_project.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:688)
	at org.spark_project.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
	at org.spark_project.jetty.servlet.ServletHandler.doScope(ServletHandler.java:512)
	at org.spark_project.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
	at org.spark_project.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.spark_project.jetty.server.handler.gzip.GzipHandler.handle(GzipHandler.java:493)
	at org.spark_project.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:213)
	at org.spark_project.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
	at org.spark_project.jetty.server.Server.handle(Server.java:534)
	at org.spark_project.jetty.server.HttpChannel.handle(HttpChannel.java:320)
	at org.spark_project.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
	at org.spark_project.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
	at org.spark_project.jetty.io.FillInterest.fillable(FillInterest.java:108)
	at org.spark_project.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
	at org.spark_project.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
	at org.spark_project.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
	at java.lang.Thread.run(Thread.java:745)
2021-12-06 16:31:53,320 [SparkUI-38] INFO [org.spark_project.jetty.servlet.DefaultServlet] - content=ResourceHttpContent@6ef200c7{r=jar:file:/C:/Users/ACER/.m2/repository/org/apache/spark/spark-core_2.11/2.3.0/spark-core_2.11-2.3.0.jar!/org/apache/spark/ui/static/sorttable.js,gz=false}
2021-12-06 16:31:53,320 [SparkUI-39] INFO [org.spark_project.jetty.servlet.DefaultServlet] - content=ResourceHttpContent@27693db1{r=jar:file:/C:/Users/ACER/.m2/repository/org/apache/spark/spark-core_2.11/2.3.0/spark-core_2.11-2.3.0.jar!/org/apache/spark/ui/static/jquery-1.11.1.min.js,gz=false}
2021-12-06 16:31:53,320 [SparkUI-38] WARN [org.spark_project.jetty.servlet.ServletHandler] - Error for /static/sorttable.js
java.lang.NoSuchMethodError: javax.servlet.http.HttpServletRequest.isAsyncSupported()Z
	at org.spark_project.jetty.servlet.DefaultServlet.sendData(DefaultServlet.java:909)
	at org.spark_project.jetty.servlet.DefaultServlet.doGet(DefaultServlet.java:526)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:707)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:820)
	at org.spark_project.jetty.servlet.ServletHolder.handle(ServletHolder.java:848)
	at org.spark_project.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:584)
	at org.spark_project.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
	at org.spark_project.jetty.servlet.ServletHandler.doScope(ServletHandler.java:512)
	at org.spark_project.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
	at org.spark_project.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.spark_project.jetty.server.handler.gzip.GzipHandler.handle(GzipHandler.java:493)
	at org.spark_project.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:213)
	at org.spark_project.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
	at org.spark_project.jetty.server.Server.handle(Server.java:534)
	at org.spark_project.jetty.server.HttpChannel.handle(HttpChannel.java:320)
	at org.spark_project.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
	at org.spark_project.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
	at org.spark_project.jetty.io.FillInterest.fillable(FillInterest.java:108)
	at org.spark_project.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
	at org.spark_project.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
	at org.spark_project.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
	at java.lang.Thread.run(Thread.java:745)
2021-12-06 16:31:53,321 [SparkUI-37] INFO [org.spark_project.jetty.servlet.DefaultServlet] - content=ResourceHttpContent@49db4527{r=jar:file:/C:/Users/ACER/.m2/repository/org/apache/spark/spark-core_2.11/2.3.0/spark-core_2.11-2.3.0.jar!/org/apache/spark/ui/static/vis.min.css,gz=false}
2021-12-06 16:31:53,321 [SparkUI-37] WARN [org.spark_project.jetty.servlet.ServletHandler] - Error for /static/vis.min.css
java.lang.NoSuchMethodError: javax.servlet.http.HttpServletRequest.isAsyncSupported()Z
	at org.spark_project.jetty.servlet.DefaultServlet.sendData(DefaultServlet.java:909)
	at org.spark_project.jetty.servlet.DefaultServlet.doGet(DefaultServlet.java:526)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:707)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:820)
	at org.spark_project.jetty.servlet.ServletHolder.handle(ServletHolder.java:848)
	at org.spark_project.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:584)
	at org.spark_project.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
	at org.spark_project.jetty.servlet.ServletHandler.doScope(ServletHandler.java:512)
	at org.spark_project.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
	at org.spark_project.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.spark_project.jetty.server.handler.gzip.GzipHandler.handle(GzipHandler.java:493)
	at org.spark_project.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:213)
	at org.spark_project.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
	at org.spark_project.jetty.server.Server.handle(Server.java:534)
	at org.spark_project.jetty.server.HttpChannel.handle(HttpChannel.java:320)
	at org.spark_project.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
	at org.spark_project.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
	at org.spark_project.jetty.io.FillInterest.fillable(FillInterest.java:108)
	at org.spark_project.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
	at org.spark_project.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
	at org.spark_project.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
	at java.lang.Thread.run(Thread.java:745)
2021-12-06 16:31:53,336 [SparkUI-37] WARN [org.spark_project.jetty.server.HttpChannel] - //qb:4040/static/vis.min.css
java.lang.NoSuchMethodError: javax.servlet.http.HttpServletRequest.isAsyncStarted()Z
	at org.spark_project.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:688)
	at org.spark_project.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
	at org.spark_project.jetty.servlet.ServletHandler.doScope(ServletHandler.java:512)
	at org.spark_project.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
	at org.spark_project.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.spark_project.jetty.server.handler.gzip.GzipHandler.handle(GzipHandler.java:493)
	at org.spark_project.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:213)
	at org.spark_project.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
	at org.spark_project.jetty.server.Server.handle(Server.java:534)
	at org.spark_project.jetty.server.HttpChannel.handle(HttpChannel.java:320)
	at org.spark_project.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
	at org.spark_project.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
	at org.spark_project.jetty.io.FillInterest.fillable(FillInterest.java:108)
	at org.spark_project.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
	at org.spark_project.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
	at org.spark_project.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
	at java.lang.Thread.run(Thread.java:745)
2021-12-06 16:31:53,339 [SparkUI-37] INFO [org.spark_project.jetty.servlet.DefaultServlet] - content=ResourceHttpContent@3bb173e5{r=jar:file:/C:/Users/ACER/.m2/repository/org/apache/spark/spark-core_2.11/2.3.0/spark-core_2.11-2.3.0.jar!/org/apache/spark/ui/static/vis.min.js,gz=false}
2021-12-06 16:31:53,339 [SparkUI-37] WARN [org.spark_project.jetty.servlet.ServletHandler] - Error for /static/vis.min.js
java.lang.NoSuchMethodError: javax.servlet.http.HttpServletRequest.isAsyncSupported()Z
	at org.spark_project.jetty.servlet.DefaultServlet.sendData(DefaultServlet.java:909)
	at org.spark_project.jetty.servlet.DefaultServlet.doGet(DefaultServlet.java:526)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:707)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:820)
	at org.spark_project.jetty.servlet.ServletHolder.handle(ServletHolder.java:848)
	at org.spark_project.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:584)
	at org.spark_project.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
	at org.spark_project.jetty.servlet.ServletHandler.doScope(ServletHandler.java:512)
	at org.spark_project.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
	at org.spark_project.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.spark_project.jetty.server.handler.gzip.GzipHandler.handle(GzipHandler.java:493)
	at org.spark_project.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:213)
	at org.spark_project.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
	at org.spark_project.jetty.server.Server.handle(Server.java:534)
	at org.spark_project.jetty.server.HttpChannel.handle(HttpChannel.java:320)
	at org.spark_project.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
	at org.spark_project.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
	at org.spark_project.jetty.io.FillInterest.fillable(FillInterest.java:108)
	at org.spark_project.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
	at org.spark_project.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
	at org.spark_project.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
	at java.lang.Thread.run(Thread.java:745)
2021-12-06 16:31:53,340 [SparkUI-37] WARN [org.spark_project.jetty.server.HttpChannel] - //qb:4040/static/vis.min.js
java.lang.NoSuchMethodError: javax.servlet.http.HttpServletRequest.isAsyncStarted()Z
	at org.spark_project.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:688)
	at org.spark_project.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
	at org.spark_project.jetty.servlet.ServletHandler.doScope(ServletHandler.java:512)
	at org.spark_project.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
	at org.spark_project.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.spark_project.jetty.server.handler.gzip.GzipHandler.handle(GzipHandler.java:493)
	at org.spark_project.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:213)
	at org.spark_project.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
	at org.spark_project.jetty.server.Server.handle(Server.java:534)
	at org.spark_project.jetty.server.HttpChannel.handle(HttpChannel.java:320)
	at org.spark_project.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
	at org.spark_project.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
	at org.spark_project.jetty.io.FillInterest.fillable(FillInterest.java:108)
	at org.spark_project.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
	at org.spark_project.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
	at org.spark_project.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
	at java.lang.Thread.run(Thread.java:745)
2021-12-06 16:31:53,320 [SparkUI-39] WARN [org.spark_project.jetty.servlet.ServletHandler] - Error for /static/jquery-1.11.1.min.js
java.lang.NoSuchMethodError: javax.servlet.http.HttpServletRequest.isAsyncSupported()Z
	at org.spark_project.jetty.servlet.DefaultServlet.sendData(DefaultServlet.java:909)
	at org.spark_project.jetty.servlet.DefaultServlet.doGet(DefaultServlet.java:526)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:707)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:820)
	at org.spark_project.jetty.servlet.ServletHolder.handle(ServletHolder.java:848)
	at org.spark_project.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:584)
	at org.spark_project.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
	at org.spark_project.jetty.servlet.ServletHandler.doScope(ServletHandler.java:512)
	at org.spark_project.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
	at org.spark_project.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.spark_project.jetty.server.handler.gzip.GzipHandler.handle(GzipHandler.java:493)
	at org.spark_project.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:213)
	at org.spark_project.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
	at org.spark_project.jetty.server.Server.handle(Server.java:534)
	at org.spark_project.jetty.server.HttpChannel.handle(HttpChannel.java:320)
	at org.spark_project.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
	at org.spark_project.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
	at org.spark_project.jetty.io.FillInterest.fillable(FillInterest.java:108)
	at org.spark_project.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
	at org.spark_project.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
	at org.spark_project.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
	at java.lang.Thread.run(Thread.java:745)
2021-12-06 16:31:53,343 [SparkUI-39] WARN [org.spark_project.jetty.server.HttpChannel] - //qb:4040/static/jquery-1.11.1.min.js
java.lang.NoSuchMethodError: javax.servlet.http.HttpServletRequest.isAsyncStarted()Z
	at org.spark_project.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:688)
	at org.spark_project.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
	at org.spark_project.jetty.servlet.ServletHandler.doScope(ServletHandler.java:512)
	at org.spark_project.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
	at org.spark_project.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.spark_project.jetty.server.handler.gzip.GzipHandler.handle(GzipHandler.java:493)
	at org.spark_project.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:213)
	at org.spark_project.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
	at org.spark_project.jetty.server.Server.handle(Server.java:534)
	at org.spark_project.jetty.server.HttpChannel.handle(HttpChannel.java:320)
	at org.spark_project.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
	at org.spark_project.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
	at org.spark_project.jetty.io.FillInterest.fillable(FillInterest.java:108)
	at org.spark_project.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
	at org.spark_project.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
	at org.spark_project.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
	at java.lang.Thread.run(Thread.java:745)
2021-12-06 16:31:53,321 [SparkUI-38] WARN [org.spark_project.jetty.server.HttpChannel] - //qb:4040/static/sorttable.js
java.lang.NoSuchMethodError: javax.servlet.http.HttpServletRequest.isAsyncStarted()Z
	at org.spark_project.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:688)
	at org.spark_project.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
	at org.spark_project.jetty.servlet.ServletHandler.doScope(ServletHandler.java:512)
	at org.spark_project.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
	at org.spark_project.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.spark_project.jetty.server.handler.gzip.GzipHandler.handle(GzipHandler.java:493)
	at org.spark_project.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:213)
	at org.spark_project.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
	at org.spark_project.jetty.server.Server.handle(Server.java:534)
	at org.spark_project.jetty.server.HttpChannel.handle(HttpChannel.java:320)
	at org.spark_project.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
	at org.spark_project.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
	at org.spark_project.jetty.io.FillInterest.fillable(FillInterest.java:108)
	at org.spark_project.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
	at org.spark_project.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
	at org.spark_project.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
	at java.lang.Thread.run(Thread.java:745)
2021-12-06 16:31:53,348 [SparkUI-38] INFO [org.spark_project.jetty.servlet.DefaultServlet] - content=ResourceHttpContent@5d60a1d1{r=jar:file:/C:/Users/ACER/.m2/repository/org/apache/spark/spark-core_2.11/2.3.0/spark-core_2.11-2.3.0.jar!/org/apache/spark/ui/static/table.js,gz=false}
2021-12-06 16:31:53,348 [SparkUI-38] WARN [org.spark_project.jetty.servlet.ServletHandler] - Error for /static/table.js
java.lang.NoSuchMethodError: javax.servlet.http.HttpServletRequest.isAsyncSupported()Z
	at org.spark_project.jetty.servlet.DefaultServlet.sendData(DefaultServlet.java:909)
	at org.spark_project.jetty.servlet.DefaultServlet.doGet(DefaultServlet.java:526)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:707)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:820)
	at org.spark_project.jetty.servlet.ServletHolder.handle(ServletHolder.java:848)
	at org.spark_project.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:584)
	at org.spark_project.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
	at org.spark_project.jetty.servlet.ServletHandler.doScope(ServletHandler.java:512)
	at org.spark_project.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
	at org.spark_project.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.spark_project.jetty.server.handler.gzip.GzipHandler.handle(GzipHandler.java:493)
	at org.spark_project.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:213)
	at org.spark_project.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
	at org.spark_project.jetty.server.Server.handle(Server.java:534)
	at org.spark_project.jetty.server.HttpChannel.handle(HttpChannel.java:320)
	at org.spark_project.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
	at org.spark_project.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
	at org.spark_project.jetty.io.FillInterest.fillable(FillInterest.java:108)
	at org.spark_project.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
	at org.spark_project.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
	at org.spark_project.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
	at java.lang.Thread.run(Thread.java:745)
2021-12-06 16:31:53,379 [SparkUI-38] WARN [org.spark_project.jetty.server.HttpChannel] - //qb:4040/static/table.js
java.lang.NoSuchMethodError: javax.servlet.http.HttpServletRequest.isAsyncStarted()Z
	at org.spark_project.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:688)
	at org.spark_project.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
	at org.spark_project.jetty.servlet.ServletHandler.doScope(ServletHandler.java:512)
	at org.spark_project.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
	at org.spark_project.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.spark_project.jetty.server.handler.gzip.GzipHandler.handle(GzipHandler.java:493)
	at org.spark_project.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:213)
	at org.spark_project.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
	at org.spark_project.jetty.server.Server.handle(Server.java:534)
	at org.spark_project.jetty.server.HttpChannel.handle(HttpChannel.java:320)
	at org.spark_project.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
	at org.spark_project.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
	at org.spark_project.jetty.io.FillInterest.fillable(FillInterest.java:108)
	at org.spark_project.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
	at org.spark_project.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
	at org.spark_project.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
	at java.lang.Thread.run(Thread.java:745)
2021-12-06 16:31:53,382 [SparkUI-38] INFO [org.spark_project.jetty.servlet.DefaultServlet] - content=ResourceHttpContent@7125d4a7{r=jar:file:/C:/Users/ACER/.m2/repository/org/apache/spark/spark-core_2.11/2.3.0/spark-core_2.11-2.3.0.jar!/org/apache/spark/ui/static/initialize-tooltips.js,gz=false}
2021-12-06 16:31:53,382 [SparkUI-38] WARN [org.spark_project.jetty.servlet.ServletHandler] - Error for /static/initialize-tooltips.js
java.lang.NoSuchMethodError: javax.servlet.http.HttpServletRequest.isAsyncSupported()Z
	at org.spark_project.jetty.servlet.DefaultServlet.sendData(DefaultServlet.java:909)
	at org.spark_project.jetty.servlet.DefaultServlet.doGet(DefaultServlet.java:526)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:707)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:820)
	at org.spark_project.jetty.servlet.ServletHolder.handle(ServletHolder.java:848)
	at org.spark_project.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:584)
	at org.spark_project.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
	at org.spark_project.jetty.servlet.ServletHandler.doScope(ServletHandler.java:512)
	at org.spark_project.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
	at org.spark_project.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.spark_project.jetty.server.handler.gzip.GzipHandler.handle(GzipHandler.java:493)
	at org.spark_project.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:213)
	at org.spark_project.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
	at org.spark_project.jetty.server.Server.handle(Server.java:534)
	at org.spark_project.jetty.server.HttpChannel.handle(HttpChannel.java:320)
	at org.spark_project.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
	at org.spark_project.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
	at org.spark_project.jetty.io.FillInterest.fillable(FillInterest.java:108)
	at org.spark_project.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
	at org.spark_project.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
	at org.spark_project.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
	at java.lang.Thread.run(Thread.java:745)
2021-12-06 16:31:53,382 [SparkUI-38] WARN [org.spark_project.jetty.server.HttpChannel] - //qb:4040/static/initialize-tooltips.js
java.lang.NoSuchMethodError: javax.servlet.http.HttpServletRequest.isAsyncStarted()Z
	at org.spark_project.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:688)
	at org.spark_project.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
	at org.spark_project.jetty.servlet.ServletHandler.doScope(ServletHandler.java:512)
	at org.spark_project.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
	at org.spark_project.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.spark_project.jetty.server.handler.gzip.GzipHandler.handle(GzipHandler.java:493)
	at org.spark_project.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:213)
	at org.spark_project.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
	at org.spark_project.jetty.server.Server.handle(Server.java:534)
	at org.spark_project.jetty.server.HttpChannel.handle(HttpChannel.java:320)
	at org.spark_project.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
	at org.spark_project.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
	at org.spark_project.jetty.io.FillInterest.fillable(FillInterest.java:108)
	at org.spark_project.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
	at org.spark_project.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
	at org.spark_project.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
	at java.lang.Thread.run(Thread.java:745)
2021-12-06 16:31:53,387 [SparkUI-42] INFO [org.spark_project.jetty.servlet.DefaultServlet] - content=ResourceHttpContent@756ae499{r=jar:file:/C:/Users/ACER/.m2/repository/org/apache/spark/spark-core_2.11/2.3.0/spark-core_2.11-2.3.0.jar!/org/apache/spark/ui/static/bootstrap-tooltip.js,gz=false}
2021-12-06 16:31:53,387 [SparkUI-42] WARN [org.spark_project.jetty.servlet.ServletHandler] - Error for /static/bootstrap-tooltip.js
java.lang.NoSuchMethodError: javax.servlet.http.HttpServletRequest.isAsyncSupported()Z
	at org.spark_project.jetty.servlet.DefaultServlet.sendData(DefaultServlet.java:909)
	at org.spark_project.jetty.servlet.DefaultServlet.doGet(DefaultServlet.java:526)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:707)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:820)
	at org.spark_project.jetty.servlet.ServletHolder.handle(ServletHolder.java:848)
	at org.spark_project.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:584)
	at org.spark_project.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
	at org.spark_project.jetty.servlet.ServletHandler.doScope(ServletHandler.java:512)
	at org.spark_project.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
	at org.spark_project.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.spark_project.jetty.server.handler.gzip.GzipHandler.handle(GzipHandler.java:493)
	at org.spark_project.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:213)
	at org.spark_project.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
	at org.spark_project.jetty.server.Server.handle(Server.java:534)
	at org.spark_project.jetty.server.HttpChannel.handle(HttpChannel.java:320)
	at org.spark_project.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
	at org.spark_project.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
	at org.spark_project.jetty.io.FillInterest.fillable(FillInterest.java:108)
	at org.spark_project.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
	at org.spark_project.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
	at org.spark_project.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
	at java.lang.Thread.run(Thread.java:745)
2021-12-06 16:31:53,387 [SparkUI-42] WARN [org.spark_project.jetty.server.HttpChannel] - //qb:4040/static/bootstrap-tooltip.js
java.lang.NoSuchMethodError: javax.servlet.http.HttpServletRequest.isAsyncStarted()Z
	at org.spark_project.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:688)
	at org.spark_project.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
	at org.spark_project.jetty.servlet.ServletHandler.doScope(ServletHandler.java:512)
	at org.spark_project.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
	at org.spark_project.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.spark_project.jetty.server.handler.gzip.GzipHandler.handle(GzipHandler.java:493)
	at org.spark_project.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:213)
	at org.spark_project.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
	at org.spark_project.jetty.server.Server.handle(Server.java:534)
	at org.spark_project.jetty.server.HttpChannel.handle(HttpChannel.java:320)
	at org.spark_project.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
	at org.spark_project.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
	at org.spark_project.jetty.io.FillInterest.fillable(FillInterest.java:108)
	at org.spark_project.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
	at org.spark_project.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
	at org.spark_project.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
	at java.lang.Thread.run(Thread.java:745)
2021-12-06 16:31:53,382 [SparkUI-43] INFO [org.spark_project.jetty.servlet.DefaultServlet] - content=ResourceHttpContent@35f79789{r=jar:file:/C:/Users/ACER/.m2/repository/org/apache/spark/spark-core_2.11/2.3.0/spark-core_2.11-2.3.0.jar!/org/apache/spark/ui/static/additional-metrics.js,gz=false}
2021-12-06 16:31:53,395 [SparkUI-43] WARN [org.spark_project.jetty.servlet.ServletHandler] - Error for /static/additional-metrics.js
java.lang.NoSuchMethodError: javax.servlet.http.HttpServletRequest.isAsyncSupported()Z
	at org.spark_project.jetty.servlet.DefaultServlet.sendData(DefaultServlet.java:909)
	at org.spark_project.jetty.servlet.DefaultServlet.doGet(DefaultServlet.java:526)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:707)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:820)
	at org.spark_project.jetty.servlet.ServletHolder.handle(ServletHolder.java:848)
	at org.spark_project.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:584)
	at org.spark_project.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
	at org.spark_project.jetty.servlet.ServletHandler.doScope(ServletHandler.java:512)
	at org.spark_project.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
	at org.spark_project.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.spark_project.jetty.server.handler.gzip.GzipHandler.handle(GzipHandler.java:493)
	at org.spark_project.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:213)
	at org.spark_project.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
	at org.spark_project.jetty.server.Server.handle(Server.java:534)
	at org.spark_project.jetty.server.HttpChannel.handle(HttpChannel.java:320)
	at org.spark_project.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
	at org.spark_project.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
	at org.spark_project.jetty.io.FillInterest.fillable(FillInterest.java:108)
	at org.spark_project.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
	at org.spark_project.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
	at org.spark_project.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
	at java.lang.Thread.run(Thread.java:745)
2021-12-06 16:31:53,395 [SparkUI-43] WARN [org.spark_project.jetty.server.HttpChannel] - //qb:4040/static/additional-metrics.js
java.lang.NoSuchMethodError: javax.servlet.http.HttpServletRequest.isAsyncStarted()Z
	at org.spark_project.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:688)
	at org.spark_project.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
	at org.spark_project.jetty.servlet.ServletHandler.doScope(ServletHandler.java:512)
	at org.spark_project.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
	at org.spark_project.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.spark_project.jetty.server.handler.gzip.GzipHandler.handle(GzipHandler.java:493)
	at org.spark_project.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:213)
	at org.spark_project.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
	at org.spark_project.jetty.server.Server.handle(Server.java:534)
	at org.spark_project.jetty.server.HttpChannel.handle(HttpChannel.java:320)
	at org.spark_project.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
	at org.spark_project.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
	at org.spark_project.jetty.io.FillInterest.fillable(FillInterest.java:108)
	at org.spark_project.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
	at org.spark_project.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
	at org.spark_project.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
	at java.lang.Thread.run(Thread.java:745)
2021-12-06 16:31:53,400 [SparkUI-40] INFO [org.spark_project.jetty.servlet.DefaultServlet] - content=ResourceHttpContent@4d9c908b{r=jar:file:/C:/Users/ACER/.m2/repository/org/apache/spark/spark-core_2.11/2.3.0/spark-core_2.11-2.3.0.jar!/org/apache/spark/ui/static/log-view.js,gz=false}
2021-12-06 16:31:53,400 [SparkUI-40] WARN [org.spark_project.jetty.servlet.ServletHandler] - Error for /static/log-view.js
java.lang.NoSuchMethodError: javax.servlet.http.HttpServletRequest.isAsyncSupported()Z
	at org.spark_project.jetty.servlet.DefaultServlet.sendData(DefaultServlet.java:909)
	at org.spark_project.jetty.servlet.DefaultServlet.doGet(DefaultServlet.java:526)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:707)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:820)
	at org.spark_project.jetty.servlet.ServletHolder.handle(ServletHolder.java:848)
	at org.spark_project.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:584)
	at org.spark_project.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
	at org.spark_project.jetty.servlet.ServletHandler.doScope(ServletHandler.java:512)
	at org.spark_project.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
	at org.spark_project.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.spark_project.jetty.server.handler.gzip.GzipHandler.handle(GzipHandler.java:493)
	at org.spark_project.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:213)
	at org.spark_project.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
	at org.spark_project.jetty.server.Server.handle(Server.java:534)
	at org.spark_project.jetty.server.HttpChannel.handle(HttpChannel.java:320)
	at org.spark_project.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
	at org.spark_project.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
	at org.spark_project.jetty.io.FillInterest.fillable(FillInterest.java:108)
	at org.spark_project.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
	at org.spark_project.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
	at org.spark_project.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
	at java.lang.Thread.run(Thread.java:745)
2021-12-06 16:31:53,400 [SparkUI-40] WARN [org.spark_project.jetty.server.HttpChannel] - //qb:4040/static/log-view.js
java.lang.NoSuchMethodError: javax.servlet.http.HttpServletRequest.isAsyncStarted()Z
	at org.spark_project.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:688)
	at org.spark_project.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
	at org.spark_project.jetty.servlet.ServletHandler.doScope(ServletHandler.java:512)
	at org.spark_project.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
	at org.spark_project.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.spark_project.jetty.server.handler.gzip.GzipHandler.handle(GzipHandler.java:493)
	at org.spark_project.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:213)
	at org.spark_project.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
	at org.spark_project.jetty.server.Server.handle(Server.java:534)
	at org.spark_project.jetty.server.HttpChannel.handle(HttpChannel.java:320)
	at org.spark_project.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
	at org.spark_project.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
	at org.spark_project.jetty.io.FillInterest.fillable(FillInterest.java:108)
	at org.spark_project.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
	at org.spark_project.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
	at org.spark_project.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
	at java.lang.Thread.run(Thread.java:745)
2021-12-06 16:31:53,401 [SparkUI-38] INFO [org.spark_project.jetty.servlet.DefaultServlet] - content=ResourceHttpContent@5a48398b{r=jar:file:/C:/Users/ACER/.m2/repository/org/apache/spark/spark-core_2.11/2.3.0/spark-core_2.11-2.3.0.jar!/org/apache/spark/ui/static/timeline-view.js,gz=false}
2021-12-06 16:31:53,401 [SparkUI-38] WARN [org.spark_project.jetty.servlet.ServletHandler] - Error for /static/timeline-view.js
java.lang.NoSuchMethodError: javax.servlet.http.HttpServletRequest.isAsyncSupported()Z
	at org.spark_project.jetty.servlet.DefaultServlet.sendData(DefaultServlet.java:909)
	at org.spark_project.jetty.servlet.DefaultServlet.doGet(DefaultServlet.java:526)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:707)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:820)
	at org.spark_project.jetty.servlet.ServletHolder.handle(ServletHolder.java:848)
	at org.spark_project.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:584)
	at org.spark_project.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
	at org.spark_project.jetty.servlet.ServletHandler.doScope(ServletHandler.java:512)
	at org.spark_project.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
	at org.spark_project.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.spark_project.jetty.server.handler.gzip.GzipHandler.handle(GzipHandler.java:493)
	at org.spark_project.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:213)
	at org.spark_project.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
	at org.spark_project.jetty.server.Server.handle(Server.java:534)
	at org.spark_project.jetty.server.HttpChannel.handle(HttpChannel.java:320)
	at org.spark_project.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
	at org.spark_project.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
	at org.spark_project.jetty.io.FillInterest.fillable(FillInterest.java:108)
	at org.spark_project.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
	at org.spark_project.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
	at org.spark_project.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
	at java.lang.Thread.run(Thread.java:745)
2021-12-06 16:31:53,431 [SparkUI-39] INFO [org.spark_project.jetty.servlet.DefaultServlet] - content=ResourceHttpContent@147f87d0{r=jar:file:/C:/Users/ACER/.m2/repository/org/apache/spark/spark-core_2.11/2.3.0/spark-core_2.11-2.3.0.jar!/org/apache/spark/ui/static/bootstrap.min.css,gz=false}
2021-12-06 16:31:53,431 [SparkUI-38] WARN [org.spark_project.jetty.server.HttpChannel] - //qb:4040/static/timeline-view.js
java.lang.NoSuchMethodError: javax.servlet.http.HttpServletRequest.isAsyncStarted()Z
	at org.spark_project.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:688)
	at org.spark_project.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
	at org.spark_project.jetty.servlet.ServletHandler.doScope(ServletHandler.java:512)
	at org.spark_project.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
	at org.spark_project.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.spark_project.jetty.server.handler.gzip.GzipHandler.handle(GzipHandler.java:493)
	at org.spark_project.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:213)
	at org.spark_project.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
	at org.spark_project.jetty.server.Server.handle(Server.java:534)
	at org.spark_project.jetty.server.HttpChannel.handle(HttpChannel.java:320)
	at org.spark_project.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
	at org.spark_project.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
	at org.spark_project.jetty.io.FillInterest.fillable(FillInterest.java:108)
	at org.spark_project.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
	at org.spark_project.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
	at org.spark_project.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
	at java.lang.Thread.run(Thread.java:745)
2021-12-06 16:31:53,432 [SparkUI-42] INFO [org.spark_project.jetty.servlet.DefaultServlet] - content=ResourceHttpContent@62948598{r=jar:file:/C:/Users/ACER/.m2/repository/org/apache/spark/spark-core_2.11/2.3.0/spark-core_2.11-2.3.0.jar!/org/apache/spark/ui/static/webui.js,gz=false}
2021-12-06 16:31:53,432 [SparkUI-42] WARN [org.spark_project.jetty.servlet.ServletHandler] - Error for /static/webui.js
java.lang.NoSuchMethodError: javax.servlet.http.HttpServletRequest.isAsyncSupported()Z
	at org.spark_project.jetty.servlet.DefaultServlet.sendData(DefaultServlet.java:909)
	at org.spark_project.jetty.servlet.DefaultServlet.doGet(DefaultServlet.java:526)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:707)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:820)
	at org.spark_project.jetty.servlet.ServletHolder.handle(ServletHolder.java:848)
	at org.spark_project.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:584)
	at org.spark_project.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
	at org.spark_project.jetty.servlet.ServletHandler.doScope(ServletHandler.java:512)
	at org.spark_project.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
	at org.spark_project.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.spark_project.jetty.server.handler.gzip.GzipHandler.handle(GzipHandler.java:493)
	at org.spark_project.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:213)
	at org.spark_project.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
	at org.spark_project.jetty.server.Server.handle(Server.java:534)
	at org.spark_project.jetty.server.HttpChannel.handle(HttpChannel.java:320)
	at org.spark_project.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
	at org.spark_project.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
	at org.spark_project.jetty.io.FillInterest.fillable(FillInterest.java:108)
	at org.spark_project.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
	at org.spark_project.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
	at org.spark_project.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
	at java.lang.Thread.run(Thread.java:745)
2021-12-06 16:31:53,432 [SparkUI-42] WARN [org.spark_project.jetty.server.HttpChannel] - //qb:4040/static/webui.js
java.lang.NoSuchMethodError: javax.servlet.http.HttpServletRequest.isAsyncStarted()Z
	at org.spark_project.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:688)
	at org.spark_project.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
	at org.spark_project.jetty.servlet.ServletHandler.doScope(ServletHandler.java:512)
	at org.spark_project.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
	at org.spark_project.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.spark_project.jetty.server.handler.gzip.GzipHandler.handle(GzipHandler.java:493)
	at org.spark_project.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:213)
	at org.spark_project.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
	at org.spark_project.jetty.server.Server.handle(Server.java:534)
	at org.spark_project.jetty.server.HttpChannel.handle(HttpChannel.java:320)
	at org.spark_project.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
	at org.spark_project.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
	at org.spark_project.jetty.io.FillInterest.fillable(FillInterest.java:108)
	at org.spark_project.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
	at org.spark_project.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
	at org.spark_project.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
	at java.lang.Thread.run(Thread.java:745)
2021-12-06 16:31:53,431 [SparkUI-39] WARN [org.spark_project.jetty.servlet.ServletHandler] - Error for /static/bootstrap.min.css
java.lang.NoSuchMethodError: javax.servlet.http.HttpServletRequest.isAsyncSupported()Z
	at org.spark_project.jetty.servlet.DefaultServlet.sendData(DefaultServlet.java:909)
	at org.spark_project.jetty.servlet.DefaultServlet.doGet(DefaultServlet.java:526)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:707)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:820)
	at org.spark_project.jetty.servlet.ServletHolder.handle(ServletHolder.java:848)
	at org.spark_project.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:584)
	at org.spark_project.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
	at org.spark_project.jetty.servlet.ServletHandler.doScope(ServletHandler.java:512)
	at org.spark_project.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
	at org.spark_project.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.spark_project.jetty.server.handler.gzip.GzipHandler.handle(GzipHandler.java:493)
	at org.spark_project.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:213)
	at org.spark_project.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
	at org.spark_project.jetty.server.Server.handle(Server.java:534)
	at org.spark_project.jetty.server.HttpChannel.handle(HttpChannel.java:320)
	at org.spark_project.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
	at org.spark_project.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
	at org.spark_project.jetty.io.FillInterest.fillable(FillInterest.java:108)
	at org.spark_project.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
	at org.spark_project.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
	at org.spark_project.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
	at java.lang.Thread.run(Thread.java:745)
2021-12-06 16:31:53,462 [SparkUI-39] WARN [org.spark_project.jetty.server.HttpChannel] - //qb:4040/static/bootstrap.min.css
java.lang.NoSuchMethodError: javax.servlet.http.HttpServletRequest.isAsyncStarted()Z
	at org.spark_project.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:688)
	at org.spark_project.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
	at org.spark_project.jetty.servlet.ServletHandler.doScope(ServletHandler.java:512)
	at org.spark_project.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
	at org.spark_project.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.spark_project.jetty.server.handler.gzip.GzipHandler.handle(GzipHandler.java:493)
	at org.spark_project.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:213)
	at org.spark_project.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
	at org.spark_project.jetty.server.Server.handle(Server.java:534)
	at org.spark_project.jetty.server.HttpChannel.handle(HttpChannel.java:320)
	at org.spark_project.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
	at org.spark_project.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
	at org.spark_project.jetty.io.FillInterest.fillable(FillInterest.java:108)
	at org.spark_project.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
	at org.spark_project.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
	at org.spark_project.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
	at java.lang.Thread.run(Thread.java:745)
2021-12-06 16:31:53,465 [SparkUI-108] INFO [org.spark_project.jetty.servlet.DefaultServlet] - content=ResourceHttpContent@19d5c3f9{r=jar:file:/C:/Users/ACER/.m2/repository/org/apache/spark/spark-core_2.11/2.3.0/spark-core_2.11-2.3.0.jar!/org/apache/spark/ui/static/spark-logo-77x50px-hd.png,gz=false}
2021-12-06 16:31:53,465 [SparkUI-108] WARN [org.spark_project.jetty.servlet.ServletHandler] - Error for /static/spark-logo-77x50px-hd.png
java.lang.NoSuchMethodError: javax.servlet.http.HttpServletRequest.isAsyncSupported()Z
	at org.spark_project.jetty.servlet.DefaultServlet.sendData(DefaultServlet.java:909)
	at org.spark_project.jetty.servlet.DefaultServlet.doGet(DefaultServlet.java:526)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:707)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:820)
	at org.spark_project.jetty.servlet.ServletHolder.handle(ServletHolder.java:848)
	at org.spark_project.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:584)
	at org.spark_project.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
	at org.spark_project.jetty.servlet.ServletHandler.doScope(ServletHandler.java:512)
	at org.spark_project.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
	at org.spark_project.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.spark_project.jetty.server.handler.gzip.GzipHandler.handle(GzipHandler.java:448)
	at org.spark_project.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:213)
	at org.spark_project.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
	at org.spark_project.jetty.server.Server.handle(Server.java:534)
	at org.spark_project.jetty.server.HttpChannel.handle(HttpChannel.java:320)
	at org.spark_project.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
	at org.spark_project.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
	at org.spark_project.jetty.io.FillInterest.fillable(FillInterest.java:108)
	at org.spark_project.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
	at org.spark_project.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
	at org.spark_project.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
	at java.lang.Thread.run(Thread.java:745)
2021-12-06 16:31:53,465 [SparkUI-108] WARN [org.spark_project.jetty.server.HttpChannel] - //qb:4040/static/spark-logo-77x50px-hd.png
java.lang.NoSuchMethodError: javax.servlet.http.HttpServletRequest.isAsyncStarted()Z
	at org.spark_project.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:688)
	at org.spark_project.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
	at org.spark_project.jetty.servlet.ServletHandler.doScope(ServletHandler.java:512)
	at org.spark_project.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
	at org.spark_project.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.spark_project.jetty.server.handler.gzip.GzipHandler.handle(GzipHandler.java:448)
	at org.spark_project.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:213)
	at org.spark_project.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
	at org.spark_project.jetty.server.Server.handle(Server.java:534)
	at org.spark_project.jetty.server.HttpChannel.handle(HttpChannel.java:320)
	at org.spark_project.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
	at org.spark_project.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
	at org.spark_project.jetty.io.FillInterest.fillable(FillInterest.java:108)
	at org.spark_project.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
	at org.spark_project.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
	at org.spark_project.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
	at java.lang.Thread.run(Thread.java:745)
2021-12-06 16:31:56,215 [SparkUI-104] INFO [org.spark_project.jetty.servlet.DefaultServlet] - content=ResourceHttpContent@24d1eaa4{r=jar:file:/C:/Users/ACER/.m2/repository/org/apache/spark/spark-core_2.11/2.3.0/spark-core_2.11-2.3.0.jar!/org/apache/spark/ui/static/bootstrap.min.css,gz=false}
2021-12-06 16:31:56,215 [SparkUI-104] WARN [org.spark_project.jetty.servlet.ServletHandler] - Error for /static/bootstrap.min.css
java.lang.NoSuchMethodError: javax.servlet.http.HttpServletRequest.isAsyncSupported()Z
	at org.spark_project.jetty.servlet.DefaultServlet.sendData(DefaultServlet.java:909)
	at org.spark_project.jetty.servlet.DefaultServlet.doGet(DefaultServlet.java:526)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:707)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:820)
	at org.spark_project.jetty.servlet.ServletHolder.handle(ServletHolder.java:848)
	at org.spark_project.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:584)
	at org.spark_project.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
	at org.spark_project.jetty.servlet.ServletHandler.doScope(ServletHandler.java:512)
	at org.spark_project.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
	at org.spark_project.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.spark_project.jetty.server.handler.gzip.GzipHandler.handle(GzipHandler.java:493)
	at org.spark_project.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:213)
	at org.spark_project.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
	at org.spark_project.jetty.server.Server.handle(Server.java:534)
	at org.spark_project.jetty.server.HttpChannel.handle(HttpChannel.java:320)
	at org.spark_project.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
	at org.spark_project.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
	at org.spark_project.jetty.io.FillInterest.fillable(FillInterest.java:108)
	at org.spark_project.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
	at org.spark_project.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
	at org.spark_project.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
	at java.lang.Thread.run(Thread.java:745)
2021-12-06 16:31:56,216 [SparkUI-104] WARN [org.spark_project.jetty.server.HttpChannel] - //qb:4040/static/bootstrap.min.css
java.lang.NoSuchMethodError: javax.servlet.http.HttpServletRequest.isAsyncStarted()Z
	at org.spark_project.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:688)
	at org.spark_project.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
	at org.spark_project.jetty.servlet.ServletHandler.doScope(ServletHandler.java:512)
	at org.spark_project.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
	at org.spark_project.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.spark_project.jetty.server.handler.gzip.GzipHandler.handle(GzipHandler.java:493)
	at org.spark_project.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:213)
	at org.spark_project.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
	at org.spark_project.jetty.server.Server.handle(Server.java:534)
	at org.spark_project.jetty.server.HttpChannel.handle(HttpChannel.java:320)
	at org.spark_project.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
	at org.spark_project.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
	at org.spark_project.jetty.io.FillInterest.fillable(FillInterest.java:108)
	at org.spark_project.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
	at org.spark_project.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
	at org.spark_project.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
	at java.lang.Thread.run(Thread.java:745)
2021-12-06 16:31:56,217 [SparkUI-105] INFO [org.spark_project.jetty.servlet.DefaultServlet] - content=ResourceHttpContent@116fc7d{r=jar:file:/C:/Users/ACER/.m2/repository/org/apache/spark/spark-core_2.11/2.3.0/spark-core_2.11-2.3.0.jar!/org/apache/spark/ui/static/vis.min.css,gz=false}
2021-12-06 16:31:56,217 [SparkUI-105] WARN [org.spark_project.jetty.servlet.ServletHandler] - Error for /static/vis.min.css
java.lang.NoSuchMethodError: javax.servlet.http.HttpServletRequest.isAsyncSupported()Z
	at org.spark_project.jetty.servlet.DefaultServlet.sendData(DefaultServlet.java:909)
	at org.spark_project.jetty.servlet.DefaultServlet.doGet(DefaultServlet.java:526)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:707)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:820)
	at org.spark_project.jetty.servlet.ServletHolder.handle(ServletHolder.java:848)
	at org.spark_project.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:584)
	at org.spark_project.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
	at org.spark_project.jetty.servlet.ServletHandler.doScope(ServletHandler.java:512)
	at org.spark_project.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
	at org.spark_project.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.spark_project.jetty.server.handler.gzip.GzipHandler.handle(GzipHandler.java:493)
	at org.spark_project.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:213)
	at org.spark_project.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
	at org.spark_project.jetty.server.Server.handle(Server.java:534)
	at org.spark_project.jetty.server.HttpChannel.handle(HttpChannel.java:320)
	at org.spark_project.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
	at org.spark_project.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
	at org.spark_project.jetty.io.FillInterest.fillable(FillInterest.java:108)
	at org.spark_project.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
	at org.spark_project.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
	at org.spark_project.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
	at java.lang.Thread.run(Thread.java:745)
2021-12-06 16:31:56,231 [SparkUI-105] WARN [org.spark_project.jetty.server.HttpChannel] - //qb:4040/static/vis.min.css
java.lang.NoSuchMethodError: javax.servlet.http.HttpServletRequest.isAsyncStarted()Z
	at org.spark_project.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:688)
	at org.spark_project.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
	at org.spark_project.jetty.servlet.ServletHandler.doScope(ServletHandler.java:512)
	at org.spark_project.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
	at org.spark_project.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.spark_project.jetty.server.handler.gzip.GzipHandler.handle(GzipHandler.java:493)
	at org.spark_project.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:213)
	at org.spark_project.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
	at org.spark_project.jetty.server.Server.handle(Server.java:534)
	at org.spark_project.jetty.server.HttpChannel.handle(HttpChannel.java:320)
	at org.spark_project.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
	at org.spark_project.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
	at org.spark_project.jetty.io.FillInterest.fillable(FillInterest.java:108)
	at org.spark_project.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
	at org.spark_project.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
	at org.spark_project.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
	at java.lang.Thread.run(Thread.java:745)
2021-12-06 16:31:56,239 [SparkUI-103] INFO [org.spark_project.jetty.servlet.DefaultServlet] - content=ResourceHttpContent@484fa1a1{r=jar:file:/C:/Users/ACER/.m2/repository/org/apache/spark/spark-core_2.11/2.3.0/spark-core_2.11-2.3.0.jar!/org/apache/spark/ui/static/sorttable.js,gz=false}
2021-12-06 16:31:56,240 [SparkUI-103] WARN [org.spark_project.jetty.servlet.ServletHandler] - Error for /static/sorttable.js
java.lang.NoSuchMethodError: javax.servlet.http.HttpServletRequest.isAsyncSupported()Z
	at org.spark_project.jetty.servlet.DefaultServlet.sendData(DefaultServlet.java:909)
	at org.spark_project.jetty.servlet.DefaultServlet.doGet(DefaultServlet.java:526)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:707)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:820)
	at org.spark_project.jetty.servlet.ServletHolder.handle(ServletHolder.java:848)
	at org.spark_project.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:584)
	at org.spark_project.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
	at org.spark_project.jetty.servlet.ServletHandler.doScope(ServletHandler.java:512)
	at org.spark_project.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
	at org.spark_project.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.spark_project.jetty.server.handler.gzip.GzipHandler.handle(GzipHandler.java:493)
	at org.spark_project.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:213)
	at org.spark_project.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
	at org.spark_project.jetty.server.Server.handle(Server.java:534)
	at org.spark_project.jetty.server.HttpChannel.handle(HttpChannel.java:320)
	at org.spark_project.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
	at org.spark_project.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
	at org.spark_project.jetty.io.FillInterest.fillable(FillInterest.java:108)
	at org.spark_project.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
	at org.spark_project.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
	at org.spark_project.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
	at java.lang.Thread.run(Thread.java:745)
2021-12-06 16:31:56,240 [SparkUI-103] WARN [org.spark_project.jetty.server.HttpChannel] - //qb:4040/static/sorttable.js
java.lang.NoSuchMethodError: javax.servlet.http.HttpServletRequest.isAsyncStarted()Z
	at org.spark_project.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:688)
	at org.spark_project.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
	at org.spark_project.jetty.servlet.ServletHandler.doScope(ServletHandler.java:512)
	at org.spark_project.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
	at org.spark_project.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.spark_project.jetty.server.handler.gzip.GzipHandler.handle(GzipHandler.java:493)
	at org.spark_project.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:213)
	at org.spark_project.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
	at org.spark_project.jetty.server.Server.handle(Server.java:534)
	at org.spark_project.jetty.server.HttpChannel.handle(HttpChannel.java:320)
	at org.spark_project.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
	at org.spark_project.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
	at org.spark_project.jetty.io.FillInterest.fillable(FillInterest.java:108)
	at org.spark_project.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
	at org.spark_project.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
	at org.spark_project.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
	at java.lang.Thread.run(Thread.java:745)
2021-12-06 16:31:56,242 [SparkUI-39] INFO [org.spark_project.jetty.servlet.DefaultServlet] - content=ResourceHttpContent@f33dcc{r=jar:file:/C:/Users/ACER/.m2/repository/org/apache/spark/spark-core_2.11/2.3.0/spark-core_2.11-2.3.0.jar!/org/apache/spark/ui/static/webui.css,gz=false}
2021-12-06 16:31:56,242 [SparkUI-39] WARN [org.spark_project.jetty.servlet.ServletHandler] - Error for /static/webui.css
java.lang.NoSuchMethodError: javax.servlet.http.HttpServletRequest.isAsyncSupported()Z
	at org.spark_project.jetty.servlet.DefaultServlet.sendData(DefaultServlet.java:909)
	at org.spark_project.jetty.servlet.DefaultServlet.doGet(DefaultServlet.java:526)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:707)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:820)
	at org.spark_project.jetty.servlet.ServletHolder.handle(ServletHolder.java:848)
	at org.spark_project.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:584)
	at org.spark_project.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
	at org.spark_project.jetty.servlet.ServletHandler.doScope(ServletHandler.java:512)
	at org.spark_project.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
	at org.spark_project.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.spark_project.jetty.server.handler.gzip.GzipHandler.handle(GzipHandler.java:493)
	at org.spark_project.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:213)
	at org.spark_project.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
	at org.spark_project.jetty.server.Server.handle(Server.java:534)
	at org.spark_project.jetty.server.HttpChannel.handle(HttpChannel.java:320)
	at org.spark_project.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
	at org.spark_project.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
	at org.spark_project.jetty.io.FillInterest.fillable(FillInterest.java:108)
	at org.spark_project.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
	at org.spark_project.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
	at org.spark_project.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
	at java.lang.Thread.run(Thread.java:745)
2021-12-06 16:31:56,243 [SparkUI-39] WARN [org.spark_project.jetty.server.HttpChannel] - //qb:4040/static/webui.css
java.lang.NoSuchMethodError: javax.servlet.http.HttpServletRequest.isAsyncStarted()Z
	at org.spark_project.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:688)
	at org.spark_project.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
	at org.spark_project.jetty.servlet.ServletHandler.doScope(ServletHandler.java:512)
	at org.spark_project.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
	at org.spark_project.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.spark_project.jetty.server.handler.gzip.GzipHandler.handle(GzipHandler.java:493)
	at org.spark_project.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:213)
	at org.spark_project.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
	at org.spark_project.jetty.server.Server.handle(Server.java:534)
	at org.spark_project.jetty.server.HttpChannel.handle(HttpChannel.java:320)
	at org.spark_project.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
	at org.spark_project.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
	at org.spark_project.jetty.io.FillInterest.fillable(FillInterest.java:108)
	at org.spark_project.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
	at org.spark_project.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
	at org.spark_project.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
	at java.lang.Thread.run(Thread.java:745)
2021-12-06 16:31:56,245 [SparkUI-103] INFO [org.spark_project.jetty.servlet.DefaultServlet] - content=ResourceHttpContent@42900765{r=jar:file:/C:/Users/ACER/.m2/repository/org/apache/spark/spark-core_2.11/2.3.0/spark-core_2.11-2.3.0.jar!/org/apache/spark/ui/static/bootstrap.min.css,gz=false}
2021-12-06 16:31:56,245 [SparkUI-103] WARN [org.spark_project.jetty.servlet.ServletHandler] - Error for /static/bootstrap.min.css
java.lang.NoSuchMethodError: javax.servlet.http.HttpServletRequest.isAsyncSupported()Z
	at org.spark_project.jetty.servlet.DefaultServlet.sendData(DefaultServlet.java:909)
	at org.spark_project.jetty.servlet.DefaultServlet.doGet(DefaultServlet.java:526)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:707)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:820)
	at org.spark_project.jetty.servlet.ServletHolder.handle(ServletHolder.java:848)
	at org.spark_project.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:584)
	at org.spark_project.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
	at org.spark_project.jetty.servlet.ServletHandler.doScope(ServletHandler.java:512)
	at org.spark_project.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
	at org.spark_project.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.spark_project.jetty.server.handler.gzip.GzipHandler.handle(GzipHandler.java:493)
	at org.spark_project.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:213)
	at org.spark_project.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
	at org.spark_project.jetty.server.Server.handle(Server.java:534)
	at org.spark_project.jetty.server.HttpChannel.handle(HttpChannel.java:320)
	at org.spark_project.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
	at org.spark_project.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
	at org.spark_project.jetty.io.FillInterest.fillable(FillInterest.java:108)
	at org.spark_project.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
	at org.spark_project.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
	at org.spark_project.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
	at java.lang.Thread.run(Thread.java:745)
2021-12-06 16:31:56,245 [SparkUI-103] WARN [org.spark_project.jetty.server.HttpChannel] - //qb:4040/static/bootstrap.min.css
java.lang.NoSuchMethodError: javax.servlet.http.HttpServletRequest.isAsyncStarted()Z
	at org.spark_project.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:688)
	at org.spark_project.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
	at org.spark_project.jetty.servlet.ServletHandler.doScope(ServletHandler.java:512)
	at org.spark_project.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
	at org.spark_project.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.spark_project.jetty.server.handler.gzip.GzipHandler.handle(GzipHandler.java:493)
	at org.spark_project.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:213)
	at org.spark_project.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
	at org.spark_project.jetty.server.Server.handle(Server.java:534)
	at org.spark_project.jetty.server.HttpChannel.handle(HttpChannel.java:320)
	at org.spark_project.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
	at org.spark_project.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
	at org.spark_project.jetty.io.FillInterest.fillable(FillInterest.java:108)
	at org.spark_project.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
	at org.spark_project.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
	at org.spark_project.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
	at java.lang.Thread.run(Thread.java:745)
2021-12-06 16:31:56,246 [SparkUI-108] INFO [org.spark_project.jetty.servlet.DefaultServlet] - content=ResourceHttpContent@3a7f8dc4{r=jar:file:/C:/Users/ACER/.m2/repository/org/apache/spark/spark-core_2.11/2.3.0/spark-core_2.11-2.3.0.jar!/org/apache/spark/ui/static/vis.min.js,gz=false}
2021-12-06 16:31:56,246 [SparkUI-108] WARN [org.spark_project.jetty.servlet.ServletHandler] - Error for /static/vis.min.js
java.lang.NoSuchMethodError: javax.servlet.http.HttpServletRequest.isAsyncSupported()Z
	at org.spark_project.jetty.servlet.DefaultServlet.sendData(DefaultServlet.java:909)
	at org.spark_project.jetty.servlet.DefaultServlet.doGet(DefaultServlet.java:526)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:707)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:820)
	at org.spark_project.jetty.servlet.ServletHolder.handle(ServletHolder.java:848)
	at org.spark_project.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:584)
	at org.spark_project.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
	at org.spark_project.jetty.servlet.ServletHandler.doScope(ServletHandler.java:512)
	at org.spark_project.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
	at org.spark_project.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.spark_project.jetty.server.handler.gzip.GzipHandler.handle(GzipHandler.java:493)
	at org.spark_project.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:213)
	at org.spark_project.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
	at org.spark_project.jetty.server.Server.handle(Server.java:534)
	at org.spark_project.jetty.server.HttpChannel.handle(HttpChannel.java:320)
	at org.spark_project.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
	at org.spark_project.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
	at org.spark_project.jetty.io.FillInterest.fillable(FillInterest.java:108)
	at org.spark_project.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
	at org.spark_project.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
	at org.spark_project.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
	at java.lang.Thread.run(Thread.java:745)
2021-12-06 16:31:56,246 [SparkUI-108] WARN [org.spark_project.jetty.server.HttpChannel] - //qb:4040/static/vis.min.js
java.lang.NoSuchMethodError: javax.servlet.http.HttpServletRequest.isAsyncStarted()Z
	at org.spark_project.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:688)
	at org.spark_project.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
	at org.spark_project.jetty.servlet.ServletHandler.doScope(ServletHandler.java:512)
	at org.spark_project.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
	at org.spark_project.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.spark_project.jetty.server.handler.gzip.GzipHandler.handle(GzipHandler.java:493)
	at org.spark_project.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:213)
	at org.spark_project.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
	at org.spark_project.jetty.server.Server.handle(Server.java:534)
	at org.spark_project.jetty.server.HttpChannel.handle(HttpChannel.java:320)
	at org.spark_project.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
	at org.spark_project.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
	at org.spark_project.jetty.io.FillInterest.fillable(FillInterest.java:108)
	at org.spark_project.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
	at org.spark_project.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
	at org.spark_project.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
	at java.lang.Thread.run(Thread.java:745)
2021-12-06 16:31:56,247 [SparkUI-42] INFO [org.spark_project.jetty.servlet.DefaultServlet] - content=ResourceHttpContent@6aa903cb{r=jar:file:/C:/Users/ACER/.m2/repository/org/apache/spark/spark-core_2.11/2.3.0/spark-core_2.11-2.3.0.jar!/org/apache/spark/ui/static/vis.min.css,gz=false}
2021-12-06 16:31:56,247 [SparkUI-42] WARN [org.spark_project.jetty.servlet.ServletHandler] - Error for /static/vis.min.css
java.lang.NoSuchMethodError: javax.servlet.http.HttpServletRequest.isAsyncSupported()Z
	at org.spark_project.jetty.servlet.DefaultServlet.sendData(DefaultServlet.java:909)
	at org.spark_project.jetty.servlet.DefaultServlet.doGet(DefaultServlet.java:526)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:707)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:820)
	at org.spark_project.jetty.servlet.ServletHolder.handle(ServletHolder.java:848)
	at org.spark_project.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:584)
	at org.spark_project.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
	at org.spark_project.jetty.servlet.ServletHandler.doScope(ServletHandler.java:512)
	at org.spark_project.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
	at org.spark_project.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.spark_project.jetty.server.handler.gzip.GzipHandler.handle(GzipHandler.java:493)
	at org.spark_project.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:213)
	at org.spark_project.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
	at org.spark_project.jetty.server.Server.handle(Server.java:534)
	at org.spark_project.jetty.server.HttpChannel.handle(HttpChannel.java:320)
	at org.spark_project.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
	at org.spark_project.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
	at org.spark_project.jetty.io.FillInterest.fillable(FillInterest.java:108)
	at org.spark_project.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
	at org.spark_project.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
	at org.spark_project.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
	at java.lang.Thread.run(Thread.java:745)
2021-12-06 16:31:56,247 [SparkUI-42] WARN [org.spark_project.jetty.server.HttpChannel] - //qb:4040/static/vis.min.css
java.lang.NoSuchMethodError: javax.servlet.http.HttpServletRequest.isAsyncStarted()Z
	at org.spark_project.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:688)
	at org.spark_project.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
	at org.spark_project.jetty.servlet.ServletHandler.doScope(ServletHandler.java:512)
	at org.spark_project.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
	at org.spark_project.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.spark_project.jetty.server.handler.gzip.GzipHandler.handle(GzipHandler.java:493)
	at org.spark_project.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:213)
	at org.spark_project.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
	at org.spark_project.jetty.server.Server.handle(Server.java:534)
	at org.spark_project.jetty.server.HttpChannel.handle(HttpChannel.java:320)
	at org.spark_project.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
	at org.spark_project.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
	at org.spark_project.jetty.io.FillInterest.fillable(FillInterest.java:108)
	at org.spark_project.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
	at org.spark_project.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
	at org.spark_project.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
	at java.lang.Thread.run(Thread.java:745)
2021-12-06 16:31:56,249 [SparkUI-102] INFO [org.spark_project.jetty.servlet.DefaultServlet] - content=ResourceHttpContent@6b2264ba{r=jar:file:/C:/Users/ACER/.m2/repository/org/apache/spark/spark-core_2.11/2.3.0/spark-core_2.11-2.3.0.jar!/org/apache/spark/ui/static/bootstrap-tooltip.js,gz=false}
2021-12-06 16:31:56,249 [SparkUI-103] INFO [org.spark_project.jetty.servlet.DefaultServlet] - content=ResourceHttpContent@52275cf9{r=jar:file:/C:/Users/ACER/.m2/repository/org/apache/spark/spark-core_2.11/2.3.0/spark-core_2.11-2.3.0.jar!/org/apache/spark/ui/static/initialize-tooltips.js,gz=false}
2021-12-06 16:31:56,249 [SparkUI-103] WARN [org.spark_project.jetty.servlet.ServletHandler] - Error for /static/initialize-tooltips.js
java.lang.NoSuchMethodError: javax.servlet.http.HttpServletRequest.isAsyncSupported()Z
	at org.spark_project.jetty.servlet.DefaultServlet.sendData(DefaultServlet.java:909)
	at org.spark_project.jetty.servlet.DefaultServlet.doGet(DefaultServlet.java:526)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:707)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:820)
	at org.spark_project.jetty.servlet.ServletHolder.handle(ServletHolder.java:848)
	at org.spark_project.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:584)
	at org.spark_project.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
	at org.spark_project.jetty.servlet.ServletHandler.doScope(ServletHandler.java:512)
	at org.spark_project.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
	at org.spark_project.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.spark_project.jetty.server.handler.gzip.GzipHandler.handle(GzipHandler.java:493)
	at org.spark_project.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:213)
	at org.spark_project.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
	at org.spark_project.jetty.server.Server.handle(Server.java:534)
	at org.spark_project.jetty.server.HttpChannel.handle(HttpChannel.java:320)
	at org.spark_project.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
	at org.spark_project.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
	at org.spark_project.jetty.io.FillInterest.fillable(FillInterest.java:108)
	at org.spark_project.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
	at org.spark_project.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
	at org.spark_project.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
	at java.lang.Thread.run(Thread.java:745)
2021-12-06 16:31:56,249 [SparkUI-102] WARN [org.spark_project.jetty.servlet.ServletHandler] - Error for /static/bootstrap-tooltip.js
java.lang.NoSuchMethodError: javax.servlet.http.HttpServletRequest.isAsyncSupported()Z
	at org.spark_project.jetty.servlet.DefaultServlet.sendData(DefaultServlet.java:909)
	at org.spark_project.jetty.servlet.DefaultServlet.doGet(DefaultServlet.java:526)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:707)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:820)
	at org.spark_project.jetty.servlet.ServletHolder.handle(ServletHolder.java:848)
	at org.spark_project.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:584)
	at org.spark_project.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
	at org.spark_project.jetty.servlet.ServletHandler.doScope(ServletHandler.java:512)
	at org.spark_project.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
	at org.spark_project.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.spark_project.jetty.server.handler.gzip.GzipHandler.handle(GzipHandler.java:493)
	at org.spark_project.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:213)
	at org.spark_project.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
	at org.spark_project.jetty.server.Server.handle(Server.java:534)
	at org.spark_project.jetty.server.HttpChannel.handle(HttpChannel.java:320)
	at org.spark_project.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
	at org.spark_project.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
	at org.spark_project.jetty.io.FillInterest.fillable(FillInterest.java:108)
	at org.spark_project.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
	at org.spark_project.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
	at org.spark_project.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
	at java.lang.Thread.run(Thread.java:745)
2021-12-06 16:31:56,251 [SparkUI-102] WARN [org.spark_project.jetty.server.HttpChannel] - //qb:4040/static/bootstrap-tooltip.js
java.lang.NoSuchMethodError: javax.servlet.http.HttpServletRequest.isAsyncStarted()Z
	at org.spark_project.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:688)
	at org.spark_project.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
	at org.spark_project.jetty.servlet.ServletHandler.doScope(ServletHandler.java:512)
	at org.spark_project.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
	at org.spark_project.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.spark_project.jetty.server.handler.gzip.GzipHandler.handle(GzipHandler.java:493)
	at org.spark_project.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:213)
	at org.spark_project.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
	at org.spark_project.jetty.server.Server.handle(Server.java:534)
	at org.spark_project.jetty.server.HttpChannel.handle(HttpChannel.java:320)
	at org.spark_project.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
	at org.spark_project.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
	at org.spark_project.jetty.io.FillInterest.fillable(FillInterest.java:108)
	at org.spark_project.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
	at org.spark_project.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
	at org.spark_project.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
	at java.lang.Thread.run(Thread.java:745)
2021-12-06 16:31:56,251 [SparkUI-39] INFO [org.spark_project.jetty.servlet.DefaultServlet] - content=ResourceHttpContent@2399fe06{r=jar:file:/C:/Users/ACER/.m2/repository/org/apache/spark/spark-core_2.11/2.3.0/spark-core_2.11-2.3.0.jar!/org/apache/spark/ui/static/jquery-1.11.1.min.js,gz=false}
2021-12-06 16:31:56,251 [SparkUI-103] WARN [org.spark_project.jetty.server.HttpChannel] - //qb:4040/static/initialize-tooltips.js
java.lang.NoSuchMethodError: javax.servlet.http.HttpServletRequest.isAsyncStarted()Z
	at org.spark_project.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:688)
	at org.spark_project.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
	at org.spark_project.jetty.servlet.ServletHandler.doScope(ServletHandler.java:512)
	at org.spark_project.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
	at org.spark_project.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.spark_project.jetty.server.handler.gzip.GzipHandler.handle(GzipHandler.java:493)
	at org.spark_project.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:213)
	at org.spark_project.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
	at org.spark_project.jetty.server.Server.handle(Server.java:534)
	at org.spark_project.jetty.server.HttpChannel.handle(HttpChannel.java:320)
	at org.spark_project.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
	at org.spark_project.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
	at org.spark_project.jetty.io.FillInterest.fillable(FillInterest.java:108)
	at org.spark_project.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
	at org.spark_project.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
	at org.spark_project.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
	at java.lang.Thread.run(Thread.java:745)
2021-12-06 16:31:56,252 [SparkUI-39] WARN [org.spark_project.jetty.servlet.ServletHandler] - Error for /static/jquery-1.11.1.min.js
java.lang.NoSuchMethodError: javax.servlet.http.HttpServletRequest.isAsyncSupported()Z
	at org.spark_project.jetty.servlet.DefaultServlet.sendData(DefaultServlet.java:909)
	at org.spark_project.jetty.servlet.DefaultServlet.doGet(DefaultServlet.java:526)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:707)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:820)
	at org.spark_project.jetty.servlet.ServletHolder.handle(ServletHolder.java:848)
	at org.spark_project.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:584)
	at org.spark_project.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
	at org.spark_project.jetty.servlet.ServletHandler.doScope(ServletHandler.java:512)
	at org.spark_project.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
	at org.spark_project.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.spark_project.jetty.server.handler.gzip.GzipHandler.handle(GzipHandler.java:493)
	at org.spark_project.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:213)
	at org.spark_project.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
	at org.spark_project.jetty.server.Server.handle(Server.java:534)
	at org.spark_project.jetty.server.HttpChannel.handle(HttpChannel.java:320)
	at org.spark_project.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
	at org.spark_project.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
	at org.spark_project.jetty.io.FillInterest.fillable(FillInterest.java:108)
	at org.spark_project.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
	at org.spark_project.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
	at org.spark_project.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
	at java.lang.Thread.run(Thread.java:745)
2021-12-06 16:31:56,268 [SparkUI-42] INFO [org.spark_project.jetty.servlet.DefaultServlet] - content=ResourceHttpContent@3a282b51{r=jar:file:/C:/Users/ACER/.m2/repository/org/apache/spark/spark-core_2.11/2.3.0/spark-core_2.11-2.3.0.jar!/org/apache/spark/ui/static/timeline-view.css,gz=false}
2021-12-06 16:31:56,268 [SparkUI-39] WARN [org.spark_project.jetty.server.HttpChannel] - //qb:4040/static/jquery-1.11.1.min.js
java.lang.NoSuchMethodError: javax.servlet.http.HttpServletRequest.isAsyncStarted()Z
	at org.spark_project.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:688)
	at org.spark_project.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
	at org.spark_project.jetty.servlet.ServletHandler.doScope(ServletHandler.java:512)
	at org.spark_project.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
	at org.spark_project.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.spark_project.jetty.server.handler.gzip.GzipHandler.handle(GzipHandler.java:493)
	at org.spark_project.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:213)
	at org.spark_project.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
	at org.spark_project.jetty.server.Server.handle(Server.java:534)
	at org.spark_project.jetty.server.HttpChannel.handle(HttpChannel.java:320)
	at org.spark_project.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
	at org.spark_project.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
	at org.spark_project.jetty.io.FillInterest.fillable(FillInterest.java:108)
	at org.spark_project.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
	at org.spark_project.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
	at org.spark_project.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
	at java.lang.Thread.run(Thread.java:745)
2021-12-06 16:31:56,268 [SparkUI-42] WARN [org.spark_project.jetty.servlet.ServletHandler] - Error for /static/timeline-view.css
java.lang.NoSuchMethodError: javax.servlet.http.HttpServletRequest.isAsyncSupported()Z
	at org.spark_project.jetty.servlet.DefaultServlet.sendData(DefaultServlet.java:909)
	at org.spark_project.jetty.servlet.DefaultServlet.doGet(DefaultServlet.java:526)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:707)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:820)
	at org.spark_project.jetty.servlet.ServletHolder.handle(ServletHolder.java:848)
	at org.spark_project.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:584)
	at org.spark_project.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
	at org.spark_project.jetty.servlet.ServletHandler.doScope(ServletHandler.java:512)
	at org.spark_project.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
	at org.spark_project.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.spark_project.jetty.server.handler.gzip.GzipHandler.handle(GzipHandler.java:493)
	at org.spark_project.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:213)
	at org.spark_project.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
	at org.spark_project.jetty.server.Server.handle(Server.java:534)
	at org.spark_project.jetty.server.HttpChannel.handle(HttpChannel.java:320)
	at org.spark_project.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
	at org.spark_project.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
	at org.spark_project.jetty.io.FillInterest.fillable(FillInterest.java:108)
	at org.spark_project.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
	at org.spark_project.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
	at org.spark_project.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
	at java.lang.Thread.run(Thread.java:745)
2021-12-06 16:31:56,283 [SparkUI-42] WARN [org.spark_project.jetty.server.HttpChannel] - //qb:4040/static/timeline-view.css
java.lang.NoSuchMethodError: javax.servlet.http.HttpServletRequest.isAsyncStarted()Z
	at org.spark_project.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:688)
	at org.spark_project.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
	at org.spark_project.jetty.servlet.ServletHandler.doScope(ServletHandler.java:512)
	at org.spark_project.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
	at org.spark_project.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.spark_project.jetty.server.handler.gzip.GzipHandler.handle(GzipHandler.java:493)
	at org.spark_project.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:213)
	at org.spark_project.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
	at org.spark_project.jetty.server.Server.handle(Server.java:534)
	at org.spark_project.jetty.server.HttpChannel.handle(HttpChannel.java:320)
	at org.spark_project.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
	at org.spark_project.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
	at org.spark_project.jetty.io.FillInterest.fillable(FillInterest.java:108)
	at org.spark_project.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
	at org.spark_project.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
	at org.spark_project.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
	at java.lang.Thread.run(Thread.java:745)
2021-12-06 16:31:56,287 [SparkUI-42] INFO [org.spark_project.jetty.servlet.DefaultServlet] - content=ResourceHttpContent@72bb63af{r=jar:file:/C:/Users/ACER/.m2/repository/org/apache/spark/spark-core_2.11/2.3.0/spark-core_2.11-2.3.0.jar!/org/apache/spark/ui/static/table.js,gz=false}
2021-12-06 16:31:56,287 [SparkUI-42] WARN [org.spark_project.jetty.servlet.ServletHandler] - Error for /static/table.js
java.lang.NoSuchMethodError: javax.servlet.http.HttpServletRequest.isAsyncSupported()Z
	at org.spark_project.jetty.servlet.DefaultServlet.sendData(DefaultServlet.java:909)
	at org.spark_project.jetty.servlet.DefaultServlet.doGet(DefaultServlet.java:526)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:707)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:820)
	at org.spark_project.jetty.servlet.ServletHolder.handle(ServletHolder.java:848)
	at org.spark_project.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:584)
	at org.spark_project.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
	at org.spark_project.jetty.servlet.ServletHandler.doScope(ServletHandler.java:512)
	at org.spark_project.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
	at org.spark_project.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.spark_project.jetty.server.handler.gzip.GzipHandler.handle(GzipHandler.java:493)
	at org.spark_project.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:213)
	at org.spark_project.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
	at org.spark_project.jetty.server.Server.handle(Server.java:534)
	at org.spark_project.jetty.server.HttpChannel.handle(HttpChannel.java:320)
	at org.spark_project.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
	at org.spark_project.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
	at org.spark_project.jetty.io.FillInterest.fillable(FillInterest.java:108)
	at org.spark_project.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
	at org.spark_project.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
	at org.spark_project.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
	at java.lang.Thread.run(Thread.java:745)
2021-12-06 16:31:56,288 [SparkUI-42] WARN [org.spark_project.jetty.server.HttpChannel] - //qb:4040/static/table.js
java.lang.NoSuchMethodError: javax.servlet.http.HttpServletRequest.isAsyncStarted()Z
	at org.spark_project.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:688)
	at org.spark_project.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
	at org.spark_project.jetty.servlet.ServletHandler.doScope(ServletHandler.java:512)
	at org.spark_project.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
	at org.spark_project.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.spark_project.jetty.server.handler.gzip.GzipHandler.handle(GzipHandler.java:493)
	at org.spark_project.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:213)
	at org.spark_project.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
	at org.spark_project.jetty.server.Server.handle(Server.java:534)
	at org.spark_project.jetty.server.HttpChannel.handle(HttpChannel.java:320)
	at org.spark_project.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
	at org.spark_project.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
	at org.spark_project.jetty.io.FillInterest.fillable(FillInterest.java:108)
	at org.spark_project.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
	at org.spark_project.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
	at org.spark_project.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
	at java.lang.Thread.run(Thread.java:745)
2021-12-06 16:31:56,290 [SparkUI-37] INFO [org.spark_project.jetty.servlet.DefaultServlet] - content=ResourceHttpContent@50647f61{r=jar:file:/C:/Users/ACER/.m2/repository/org/apache/spark/spark-core_2.11/2.3.0/spark-core_2.11-2.3.0.jar!/org/apache/spark/ui/static/additional-metrics.js,gz=false}
2021-12-06 16:31:56,291 [SparkUI-37] WARN [org.spark_project.jetty.servlet.ServletHandler] - Error for /static/additional-metrics.js
java.lang.NoSuchMethodError: javax.servlet.http.HttpServletRequest.isAsyncSupported()Z
	at org.spark_project.jetty.servlet.DefaultServlet.sendData(DefaultServlet.java:909)
	at org.spark_project.jetty.servlet.DefaultServlet.doGet(DefaultServlet.java:526)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:707)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:820)
	at org.spark_project.jetty.servlet.ServletHolder.handle(ServletHolder.java:848)
	at org.spark_project.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:584)
	at org.spark_project.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
	at org.spark_project.jetty.servlet.ServletHandler.doScope(ServletHandler.java:512)
	at org.spark_project.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
	at org.spark_project.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.spark_project.jetty.server.handler.gzip.GzipHandler.handle(GzipHandler.java:493)
	at org.spark_project.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:213)
	at org.spark_project.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
	at org.spark_project.jetty.server.Server.handle(Server.java:534)
	at org.spark_project.jetty.server.HttpChannel.handle(HttpChannel.java:320)
	at org.spark_project.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
	at org.spark_project.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
	at org.spark_project.jetty.io.FillInterest.fillable(FillInterest.java:108)
	at org.spark_project.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
	at org.spark_project.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
	at org.spark_project.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
	at java.lang.Thread.run(Thread.java:745)
2021-12-06 16:31:56,291 [SparkUI-37] WARN [org.spark_project.jetty.server.HttpChannel] - //qb:4040/static/additional-metrics.js
java.lang.NoSuchMethodError: javax.servlet.http.HttpServletRequest.isAsyncStarted()Z
	at org.spark_project.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:688)
	at org.spark_project.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
	at org.spark_project.jetty.servlet.ServletHandler.doScope(ServletHandler.java:512)
	at org.spark_project.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
	at org.spark_project.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.spark_project.jetty.server.handler.gzip.GzipHandler.handle(GzipHandler.java:493)
	at org.spark_project.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:213)
	at org.spark_project.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
	at org.spark_project.jetty.server.Server.handle(Server.java:534)
	at org.spark_project.jetty.server.HttpChannel.handle(HttpChannel.java:320)
	at org.spark_project.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
	at org.spark_project.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
	at org.spark_project.jetty.io.FillInterest.fillable(FillInterest.java:108)
	at org.spark_project.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
	at org.spark_project.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
	at org.spark_project.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
	at java.lang.Thread.run(Thread.java:745)
2021-12-06 16:31:56,291 [SparkUI-103] INFO [org.spark_project.jetty.servlet.DefaultServlet] - content=ResourceHttpContent@590f1cbf{r=jar:file:/C:/Users/ACER/.m2/repository/org/apache/spark/spark-core_2.11/2.3.0/spark-core_2.11-2.3.0.jar!/org/apache/spark/ui/static/timeline-view.js,gz=false}
2021-12-06 16:31:56,291 [SparkUI-103] WARN [org.spark_project.jetty.servlet.ServletHandler] - Error for /static/timeline-view.js
java.lang.NoSuchMethodError: javax.servlet.http.HttpServletRequest.isAsyncSupported()Z
	at org.spark_project.jetty.servlet.DefaultServlet.sendData(DefaultServlet.java:909)
	at org.spark_project.jetty.servlet.DefaultServlet.doGet(DefaultServlet.java:526)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:707)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:820)
	at org.spark_project.jetty.servlet.ServletHolder.handle(ServletHolder.java:848)
	at org.spark_project.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:584)
	at org.spark_project.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
	at org.spark_project.jetty.servlet.ServletHandler.doScope(ServletHandler.java:512)
	at org.spark_project.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
	at org.spark_project.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.spark_project.jetty.server.handler.gzip.GzipHandler.handle(GzipHandler.java:493)
	at org.spark_project.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:213)
	at org.spark_project.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
	at org.spark_project.jetty.server.Server.handle(Server.java:534)
	at org.spark_project.jetty.server.HttpChannel.handle(HttpChannel.java:320)
	at org.spark_project.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
	at org.spark_project.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
	at org.spark_project.jetty.io.FillInterest.fillable(FillInterest.java:108)
	at org.spark_project.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
	at org.spark_project.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
	at org.spark_project.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
	at java.lang.Thread.run(Thread.java:745)
2021-12-06 16:31:56,291 [SparkUI-103] WARN [org.spark_project.jetty.server.HttpChannel] - //qb:4040/static/timeline-view.js
java.lang.NoSuchMethodError: javax.servlet.http.HttpServletRequest.isAsyncStarted()Z
	at org.spark_project.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:688)
	at org.spark_project.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
	at org.spark_project.jetty.servlet.ServletHandler.doScope(ServletHandler.java:512)
	at org.spark_project.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
	at org.spark_project.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.spark_project.jetty.server.handler.gzip.GzipHandler.handle(GzipHandler.java:493)
	at org.spark_project.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:213)
	at org.spark_project.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
	at org.spark_project.jetty.server.Server.handle(Server.java:534)
	at org.spark_project.jetty.server.HttpChannel.handle(HttpChannel.java:320)
	at org.spark_project.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
	at org.spark_project.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
	at org.spark_project.jetty.io.FillInterest.fillable(FillInterest.java:108)
	at org.spark_project.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
	at org.spark_project.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
	at org.spark_project.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
	at java.lang.Thread.run(Thread.java:745)
2021-12-06 16:31:56,292 [SparkUI-39] INFO [org.spark_project.jetty.servlet.DefaultServlet] - content=ResourceHttpContent@510c9ac0{r=jar:file:/C:/Users/ACER/.m2/repository/org/apache/spark/spark-core_2.11/2.3.0/spark-core_2.11-2.3.0.jar!/org/apache/spark/ui/static/webui.js,gz=false}
2021-12-06 16:31:56,292 [SparkUI-39] WARN [org.spark_project.jetty.servlet.ServletHandler] - Error for /static/webui.js
java.lang.NoSuchMethodError: javax.servlet.http.HttpServletRequest.isAsyncSupported()Z
	at org.spark_project.jetty.servlet.DefaultServlet.sendData(DefaultServlet.java:909)
	at org.spark_project.jetty.servlet.DefaultServlet.doGet(DefaultServlet.java:526)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:707)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:820)
	at org.spark_project.jetty.servlet.ServletHolder.handle(ServletHolder.java:848)
	at org.spark_project.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:584)
	at org.spark_project.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
	at org.spark_project.jetty.servlet.ServletHandler.doScope(ServletHandler.java:512)
	at org.spark_project.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
	at org.spark_project.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.spark_project.jetty.server.handler.gzip.GzipHandler.handle(GzipHandler.java:493)
	at org.spark_project.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:213)
	at org.spark_project.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
	at org.spark_project.jetty.server.Server.handle(Server.java:534)
	at org.spark_project.jetty.server.HttpChannel.handle(HttpChannel.java:320)
	at org.spark_project.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
	at org.spark_project.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
	at org.spark_project.jetty.io.FillInterest.fillable(FillInterest.java:108)
	at org.spark_project.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
	at org.spark_project.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
	at org.spark_project.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
	at java.lang.Thread.run(Thread.java:745)
2021-12-06 16:31:56,292 [SparkUI-39] WARN [org.spark_project.jetty.server.HttpChannel] - //qb:4040/static/webui.js
java.lang.NoSuchMethodError: javax.servlet.http.HttpServletRequest.isAsyncStarted()Z
	at org.spark_project.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:688)
	at org.spark_project.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
	at org.spark_project.jetty.servlet.ServletHandler.doScope(ServletHandler.java:512)
	at org.spark_project.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
	at org.spark_project.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.spark_project.jetty.server.handler.gzip.GzipHandler.handle(GzipHandler.java:493)
	at org.spark_project.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:213)
	at org.spark_project.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
	at org.spark_project.jetty.server.Server.handle(Server.java:534)
	at org.spark_project.jetty.server.HttpChannel.handle(HttpChannel.java:320)
	at org.spark_project.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
	at org.spark_project.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
	at org.spark_project.jetty.io.FillInterest.fillable(FillInterest.java:108)
	at org.spark_project.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
	at org.spark_project.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
	at org.spark_project.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
	at java.lang.Thread.run(Thread.java:745)
2021-12-06 16:31:56,293 [SparkUI-102] INFO [org.spark_project.jetty.servlet.DefaultServlet] - content=ResourceHttpContent@1cad70cf{r=jar:file:/C:/Users/ACER/.m2/repository/org/apache/spark/spark-core_2.11/2.3.0/spark-core_2.11-2.3.0.jar!/org/apache/spark/ui/static/log-view.js,gz=false}
2021-12-06 16:31:56,293 [SparkUI-102] WARN [org.spark_project.jetty.servlet.ServletHandler] - Error for /static/log-view.js
java.lang.NoSuchMethodError: javax.servlet.http.HttpServletRequest.isAsyncSupported()Z
	at org.spark_project.jetty.servlet.DefaultServlet.sendData(DefaultServlet.java:909)
	at org.spark_project.jetty.servlet.DefaultServlet.doGet(DefaultServlet.java:526)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:707)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:820)
	at org.spark_project.jetty.servlet.ServletHolder.handle(ServletHolder.java:848)
	at org.spark_project.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:584)
	at org.spark_project.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
	at org.spark_project.jetty.servlet.ServletHandler.doScope(ServletHandler.java:512)
	at org.spark_project.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
	at org.spark_project.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.spark_project.jetty.server.handler.gzip.GzipHandler.handle(GzipHandler.java:493)
	at org.spark_project.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:213)
	at org.spark_project.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
	at org.spark_project.jetty.server.Server.handle(Server.java:534)
	at org.spark_project.jetty.server.HttpChannel.handle(HttpChannel.java:320)
	at org.spark_project.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
	at org.spark_project.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
	at org.spark_project.jetty.io.FillInterest.fillable(FillInterest.java:108)
	at org.spark_project.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
	at org.spark_project.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
	at org.spark_project.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
	at java.lang.Thread.run(Thread.java:745)
2021-12-06 16:31:56,293 [SparkUI-102] WARN [org.spark_project.jetty.server.HttpChannel] - //qb:4040/static/log-view.js
java.lang.NoSuchMethodError: javax.servlet.http.HttpServletRequest.isAsyncStarted()Z
	at org.spark_project.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:688)
	at org.spark_project.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
	at org.spark_project.jetty.servlet.ServletHandler.doScope(ServletHandler.java:512)
	at org.spark_project.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
	at org.spark_project.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.spark_project.jetty.server.handler.gzip.GzipHandler.handle(GzipHandler.java:493)
	at org.spark_project.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:213)
	at org.spark_project.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
	at org.spark_project.jetty.server.Server.handle(Server.java:534)
	at org.spark_project.jetty.server.HttpChannel.handle(HttpChannel.java:320)
	at org.spark_project.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
	at org.spark_project.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
	at org.spark_project.jetty.io.FillInterest.fillable(FillInterest.java:108)
	at org.spark_project.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
	at org.spark_project.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
	at org.spark_project.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
	at java.lang.Thread.run(Thread.java:745)
2021-12-06 16:31:56,345 [SparkUI-39] INFO [org.spark_project.jetty.servlet.DefaultServlet] - content=ResourceHttpContent@761760f1{r=jar:file:/C:/Users/ACER/.m2/repository/org/apache/spark/spark-core_2.11/2.3.0/spark-core_2.11-2.3.0.jar!/org/apache/spark/ui/static/spark-logo-77x50px-hd.png,gz=false}
2021-12-06 16:31:56,345 [SparkUI-39] WARN [org.spark_project.jetty.servlet.ServletHandler] - Error for /static/spark-logo-77x50px-hd.png
java.lang.NoSuchMethodError: javax.servlet.http.HttpServletRequest.isAsyncSupported()Z
	at org.spark_project.jetty.servlet.DefaultServlet.sendData(DefaultServlet.java:909)
	at org.spark_project.jetty.servlet.DefaultServlet.doGet(DefaultServlet.java:526)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:707)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:820)
	at org.spark_project.jetty.servlet.ServletHolder.handle(ServletHolder.java:848)
	at org.spark_project.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:584)
	at org.spark_project.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
	at org.spark_project.jetty.servlet.ServletHandler.doScope(ServletHandler.java:512)
	at org.spark_project.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
	at org.spark_project.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.spark_project.jetty.server.handler.gzip.GzipHandler.handle(GzipHandler.java:448)
	at org.spark_project.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:213)
	at org.spark_project.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
	at org.spark_project.jetty.server.Server.handle(Server.java:534)
	at org.spark_project.jetty.server.HttpChannel.handle(HttpChannel.java:320)
	at org.spark_project.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
	at org.spark_project.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
	at org.spark_project.jetty.io.FillInterest.fillable(FillInterest.java:108)
	at org.spark_project.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
	at org.spark_project.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
	at org.spark_project.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
	at java.lang.Thread.run(Thread.java:745)
2021-12-06 16:31:56,345 [SparkUI-39] WARN [org.spark_project.jetty.server.HttpChannel] - //qb:4040/static/spark-logo-77x50px-hd.png
java.lang.NoSuchMethodError: javax.servlet.http.HttpServletRequest.isAsyncStarted()Z
	at org.spark_project.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:688)
	at org.spark_project.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
	at org.spark_project.jetty.servlet.ServletHandler.doScope(ServletHandler.java:512)
	at org.spark_project.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
	at org.spark_project.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.spark_project.jetty.server.handler.gzip.GzipHandler.handle(GzipHandler.java:448)
	at org.spark_project.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:213)
	at org.spark_project.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
	at org.spark_project.jetty.server.Server.handle(Server.java:534)
	at org.spark_project.jetty.server.HttpChannel.handle(HttpChannel.java:320)
	at org.spark_project.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
	at org.spark_project.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
	at org.spark_project.jetty.io.FillInterest.fillable(FillInterest.java:108)
	at org.spark_project.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
	at org.spark_project.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
	at org.spark_project.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
	at java.lang.Thread.run(Thread.java:745)
2021-12-06 16:32:08,743 [SparkUI-108] INFO [org.spark_project.jetty.servlet.DefaultServlet] - content=ResourceHttpContent@7a0a1ee4{r=jar:file:/C:/Users/ACER/.m2/repository/org/apache/spark/spark-core_2.11/2.3.0/spark-core_2.11-2.3.0.jar!/org/apache/spark/ui/static/vis.min.css,gz=false}
2021-12-06 16:32:08,743 [SparkUI-42] INFO [org.spark_project.jetty.servlet.DefaultServlet] - content=ResourceHttpContent@233748ed{r=jar:file:/C:/Users/ACER/.m2/repository/org/apache/spark/spark-core_2.11/2.3.0/spark-core_2.11-2.3.0.jar!/org/apache/spark/ui/static/bootstrap.min.css,gz=false}
2021-12-06 16:32:08,743 [SparkUI-108] WARN [org.spark_project.jetty.servlet.ServletHandler] - Error for /static/vis.min.css
java.lang.NoSuchMethodError: javax.servlet.http.HttpServletRequest.isAsyncSupported()Z
	at org.spark_project.jetty.servlet.DefaultServlet.sendData(DefaultServlet.java:909)
	at org.spark_project.jetty.servlet.DefaultServlet.doGet(DefaultServlet.java:526)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:707)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:820)
	at org.spark_project.jetty.servlet.ServletHolder.handle(ServletHolder.java:848)
	at org.spark_project.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:584)
	at org.spark_project.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
	at org.spark_project.jetty.servlet.ServletHandler.doScope(ServletHandler.java:512)
	at org.spark_project.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
	at org.spark_project.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.spark_project.jetty.server.handler.gzip.GzipHandler.handle(GzipHandler.java:493)
	at org.spark_project.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:213)
	at org.spark_project.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
	at org.spark_project.jetty.server.Server.handle(Server.java:534)
	at org.spark_project.jetty.server.HttpChannel.handle(HttpChannel.java:320)
	at org.spark_project.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
	at org.spark_project.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
	at org.spark_project.jetty.io.FillInterest.fillable(FillInterest.java:108)
	at org.spark_project.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
	at org.spark_project.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
	at org.spark_project.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
	at java.lang.Thread.run(Thread.java:745)
2021-12-06 16:32:08,743 [SparkUI-42] WARN [org.spark_project.jetty.servlet.ServletHandler] - Error for /static/bootstrap.min.css
java.lang.NoSuchMethodError: javax.servlet.http.HttpServletRequest.isAsyncSupported()Z
	at org.spark_project.jetty.servlet.DefaultServlet.sendData(DefaultServlet.java:909)
	at org.spark_project.jetty.servlet.DefaultServlet.doGet(DefaultServlet.java:526)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:707)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:820)
	at org.spark_project.jetty.servlet.ServletHolder.handle(ServletHolder.java:848)
	at org.spark_project.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:584)
	at org.spark_project.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
	at org.spark_project.jetty.servlet.ServletHandler.doScope(ServletHandler.java:512)
	at org.spark_project.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
	at org.spark_project.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.spark_project.jetty.server.handler.gzip.GzipHandler.handle(GzipHandler.java:493)
	at org.spark_project.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:213)
	at org.spark_project.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
	at org.spark_project.jetty.server.Server.handle(Server.java:534)
	at org.spark_project.jetty.server.HttpChannel.handle(HttpChannel.java:320)
	at org.spark_project.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
	at org.spark_project.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
	at org.spark_project.jetty.io.FillInterest.fillable(FillInterest.java:108)
	at org.spark_project.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
	at org.spark_project.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
	at org.spark_project.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
	at java.lang.Thread.run(Thread.java:745)
2021-12-06 16:32:08,744 [SparkUI-108] WARN [org.spark_project.jetty.server.HttpChannel] - //qb:4040/static/vis.min.css
java.lang.NoSuchMethodError: javax.servlet.http.HttpServletRequest.isAsyncStarted()Z
	at org.spark_project.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:688)
	at org.spark_project.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
	at org.spark_project.jetty.servlet.ServletHandler.doScope(ServletHandler.java:512)
	at org.spark_project.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
	at org.spark_project.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.spark_project.jetty.server.handler.gzip.GzipHandler.handle(GzipHandler.java:493)
	at org.spark_project.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:213)
	at org.spark_project.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
	at org.spark_project.jetty.server.Server.handle(Server.java:534)
	at org.spark_project.jetty.server.HttpChannel.handle(HttpChannel.java:320)
	at org.spark_project.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
	at org.spark_project.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
	at org.spark_project.jetty.io.FillInterest.fillable(FillInterest.java:108)
	at org.spark_project.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
	at org.spark_project.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
	at org.spark_project.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
	at java.lang.Thread.run(Thread.java:745)
2021-12-06 16:32:08,744 [SparkUI-42] WARN [org.spark_project.jetty.server.HttpChannel] - //qb:4040/static/bootstrap.min.css
java.lang.NoSuchMethodError: javax.servlet.http.HttpServletRequest.isAsyncStarted()Z
	at org.spark_project.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:688)
	at org.spark_project.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
	at org.spark_project.jetty.servlet.ServletHandler.doScope(ServletHandler.java:512)
	at org.spark_project.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
	at org.spark_project.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.spark_project.jetty.server.handler.gzip.GzipHandler.handle(GzipHandler.java:493)
	at org.spark_project.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:213)
	at org.spark_project.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
	at org.spark_project.jetty.server.Server.handle(Server.java:534)
	at org.spark_project.jetty.server.HttpChannel.handle(HttpChannel.java:320)
	at org.spark_project.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
	at org.spark_project.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
	at org.spark_project.jetty.io.FillInterest.fillable(FillInterest.java:108)
	at org.spark_project.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
	at org.spark_project.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
	at org.spark_project.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
	at java.lang.Thread.run(Thread.java:745)
2021-12-06 16:32:08,745 [SparkUI-106] INFO [org.spark_project.jetty.servlet.DefaultServlet] - content=ResourceHttpContent@29729ddf{r=jar:file:/C:/Users/ACER/.m2/repository/org/apache/spark/spark-core_2.11/2.3.0/spark-core_2.11-2.3.0.jar!/org/apache/spark/ui/static/webui.css,gz=false}
2021-12-06 16:32:08,745 [SparkUI-106] WARN [org.spark_project.jetty.servlet.ServletHandler] - Error for /static/webui.css
java.lang.NoSuchMethodError: javax.servlet.http.HttpServletRequest.isAsyncSupported()Z
	at org.spark_project.jetty.servlet.DefaultServlet.sendData(DefaultServlet.java:909)
	at org.spark_project.jetty.servlet.DefaultServlet.doGet(DefaultServlet.java:526)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:707)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:820)
	at org.spark_project.jetty.servlet.ServletHolder.handle(ServletHolder.java:848)
	at org.spark_project.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:584)
	at org.spark_project.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
	at org.spark_project.jetty.servlet.ServletHandler.doScope(ServletHandler.java:512)
	at org.spark_project.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
	at org.spark_project.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.spark_project.jetty.server.handler.gzip.GzipHandler.handle(GzipHandler.java:493)
	at org.spark_project.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:213)
	at org.spark_project.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
	at org.spark_project.jetty.server.Server.handle(Server.java:534)
	at org.spark_project.jetty.server.HttpChannel.handle(HttpChannel.java:320)
	at org.spark_project.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
	at org.spark_project.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
	at org.spark_project.jetty.io.FillInterest.fillable(FillInterest.java:108)
	at org.spark_project.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
	at org.spark_project.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
	at org.spark_project.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
	at java.lang.Thread.run(Thread.java:745)
2021-12-06 16:32:08,746 [SparkUI-106] WARN [org.spark_project.jetty.server.HttpChannel] - //qb:4040/static/webui.css
java.lang.NoSuchMethodError: javax.servlet.http.HttpServletRequest.isAsyncStarted()Z
	at org.spark_project.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:688)
	at org.spark_project.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
	at org.spark_project.jetty.servlet.ServletHandler.doScope(ServletHandler.java:512)
	at org.spark_project.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
	at org.spark_project.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.spark_project.jetty.server.handler.gzip.GzipHandler.handle(GzipHandler.java:493)
	at org.spark_project.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:213)
	at org.spark_project.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
	at org.spark_project.jetty.server.Server.handle(Server.java:534)
	at org.spark_project.jetty.server.HttpChannel.handle(HttpChannel.java:320)
	at org.spark_project.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
	at org.spark_project.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
	at org.spark_project.jetty.io.FillInterest.fillable(FillInterest.java:108)
	at org.spark_project.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
	at org.spark_project.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
	at org.spark_project.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
	at java.lang.Thread.run(Thread.java:745)
2021-12-06 16:32:08,746 [SparkUI-38] INFO [org.spark_project.jetty.servlet.DefaultServlet] - content=ResourceHttpContent@432d7c14{r=jar:file:/C:/Users/ACER/.m2/repository/org/apache/spark/spark-core_2.11/2.3.0/spark-core_2.11-2.3.0.jar!/org/apache/spark/ui/static/timeline-view.css,gz=false}
2021-12-06 16:32:08,746 [SparkUI-38] WARN [org.spark_project.jetty.servlet.ServletHandler] - Error for /static/timeline-view.css
java.lang.NoSuchMethodError: javax.servlet.http.HttpServletRequest.isAsyncSupported()Z
	at org.spark_project.jetty.servlet.DefaultServlet.sendData(DefaultServlet.java:909)
	at org.spark_project.jetty.servlet.DefaultServlet.doGet(DefaultServlet.java:526)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:707)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:820)
	at org.spark_project.jetty.servlet.ServletHolder.handle(ServletHolder.java:848)
	at org.spark_project.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:584)
	at org.spark_project.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
	at org.spark_project.jetty.servlet.ServletHandler.doScope(ServletHandler.java:512)
	at org.spark_project.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
	at org.spark_project.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.spark_project.jetty.server.handler.gzip.GzipHandler.handle(GzipHandler.java:493)
	at org.spark_project.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:213)
	at org.spark_project.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
	at org.spark_project.jetty.server.Server.handle(Server.java:534)
	at org.spark_project.jetty.server.HttpChannel.handle(HttpChannel.java:320)
	at org.spark_project.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
	at org.spark_project.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
	at org.spark_project.jetty.io.FillInterest.fillable(FillInterest.java:108)
	at org.spark_project.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
	at org.spark_project.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
	at org.spark_project.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
	at java.lang.Thread.run(Thread.java:745)
2021-12-06 16:32:08,746 [SparkUI-38] WARN [org.spark_project.jetty.server.HttpChannel] - //qb:4040/static/timeline-view.css
java.lang.NoSuchMethodError: javax.servlet.http.HttpServletRequest.isAsyncStarted()Z
	at org.spark_project.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:688)
	at org.spark_project.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
	at org.spark_project.jetty.servlet.ServletHandler.doScope(ServletHandler.java:512)
	at org.spark_project.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
	at org.spark_project.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.spark_project.jetty.server.handler.gzip.GzipHandler.handle(GzipHandler.java:493)
	at org.spark_project.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:213)
	at org.spark_project.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
	at org.spark_project.jetty.server.Server.handle(Server.java:534)
	at org.spark_project.jetty.server.HttpChannel.handle(HttpChannel.java:320)
	at org.spark_project.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
	at org.spark_project.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
	at org.spark_project.jetty.io.FillInterest.fillable(FillInterest.java:108)
	at org.spark_project.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
	at org.spark_project.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
	at org.spark_project.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
	at java.lang.Thread.run(Thread.java:745)
2021-12-06 16:32:08,747 [SparkUI-40] INFO [org.spark_project.jetty.servlet.DefaultServlet] - content=ResourceHttpContent@7eee2056{r=jar:file:/C:/Users/ACER/.m2/repository/org/apache/spark/spark-core_2.11/2.3.0/spark-core_2.11-2.3.0.jar!/org/apache/spark/ui/static/bootstrap.min.css,gz=false}
2021-12-06 16:32:08,747 [SparkUI-40] WARN [org.spark_project.jetty.servlet.ServletHandler] - Error for /static/bootstrap.min.css
java.lang.NoSuchMethodError: javax.servlet.http.HttpServletRequest.isAsyncSupported()Z
	at org.spark_project.jetty.servlet.DefaultServlet.sendData(DefaultServlet.java:909)
	at org.spark_project.jetty.servlet.DefaultServlet.doGet(DefaultServlet.java:526)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:707)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:820)
	at org.spark_project.jetty.servlet.ServletHolder.handle(ServletHolder.java:848)
	at org.spark_project.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:584)
	at org.spark_project.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
	at org.spark_project.jetty.servlet.ServletHandler.doScope(ServletHandler.java:512)
	at org.spark_project.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
	at org.spark_project.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.spark_project.jetty.server.handler.gzip.GzipHandler.handle(GzipHandler.java:493)
	at org.spark_project.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:213)
	at org.spark_project.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
	at org.spark_project.jetty.server.Server.handle(Server.java:534)
	at org.spark_project.jetty.server.HttpChannel.handle(HttpChannel.java:320)
	at org.spark_project.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
	at org.spark_project.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
	at org.spark_project.jetty.io.FillInterest.fillable(FillInterest.java:108)
	at org.spark_project.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
	at org.spark_project.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
	at org.spark_project.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
	at java.lang.Thread.run(Thread.java:745)
2021-12-06 16:32:08,748 [SparkUI-40] WARN [org.spark_project.jetty.server.HttpChannel] - //qb:4040/static/bootstrap.min.css
java.lang.NoSuchMethodError: javax.servlet.http.HttpServletRequest.isAsyncStarted()Z
	at org.spark_project.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:688)
	at org.spark_project.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
	at org.spark_project.jetty.servlet.ServletHandler.doScope(ServletHandler.java:512)
	at org.spark_project.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
	at org.spark_project.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.spark_project.jetty.server.handler.gzip.GzipHandler.handle(GzipHandler.java:493)
	at org.spark_project.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:213)
	at org.spark_project.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
	at org.spark_project.jetty.server.Server.handle(Server.java:534)
	at org.spark_project.jetty.server.HttpChannel.handle(HttpChannel.java:320)
	at org.spark_project.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
	at org.spark_project.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
	at org.spark_project.jetty.io.FillInterest.fillable(FillInterest.java:108)
	at org.spark_project.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
	at org.spark_project.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
	at org.spark_project.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
	at java.lang.Thread.run(Thread.java:745)
2021-12-06 16:32:08,752 [SparkUI-107] INFO [org.spark_project.jetty.servlet.DefaultServlet] - content=ResourceHttpContent@1e02144a{r=jar:file:/C:/Users/ACER/.m2/repository/org/apache/spark/spark-core_2.11/2.3.0/spark-core_2.11-2.3.0.jar!/org/apache/spark/ui/static/vis.min.css,gz=false}
2021-12-06 16:32:08,752 [SparkUI-107] WARN [org.spark_project.jetty.servlet.ServletHandler] - Error for /static/vis.min.css
java.lang.NoSuchMethodError: javax.servlet.http.HttpServletRequest.isAsyncSupported()Z
	at org.spark_project.jetty.servlet.DefaultServlet.sendData(DefaultServlet.java:909)
	at org.spark_project.jetty.servlet.DefaultServlet.doGet(DefaultServlet.java:526)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:707)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:820)
	at org.spark_project.jetty.servlet.ServletHolder.handle(ServletHolder.java:848)
	at org.spark_project.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:584)
	at org.spark_project.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
	at org.spark_project.jetty.servlet.ServletHandler.doScope(ServletHandler.java:512)
	at org.spark_project.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
	at org.spark_project.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.spark_project.jetty.server.handler.gzip.GzipHandler.handle(GzipHandler.java:493)
	at org.spark_project.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:213)
	at org.spark_project.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
	at org.spark_project.jetty.server.Server.handle(Server.java:534)
	at org.spark_project.jetty.server.HttpChannel.handle(HttpChannel.java:320)
	at org.spark_project.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
	at org.spark_project.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
	at org.spark_project.jetty.io.FillInterest.fillable(FillInterest.java:108)
	at org.spark_project.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
	at org.spark_project.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
	at org.spark_project.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
	at java.lang.Thread.run(Thread.java:745)
2021-12-06 16:32:08,752 [SparkUI-107] WARN [org.spark_project.jetty.server.HttpChannel] - //qb:4040/static/vis.min.css
java.lang.NoSuchMethodError: javax.servlet.http.HttpServletRequest.isAsyncStarted()Z
	at org.spark_project.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:688)
	at org.spark_project.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
	at org.spark_project.jetty.servlet.ServletHandler.doScope(ServletHandler.java:512)
	at org.spark_project.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
	at org.spark_project.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.spark_project.jetty.server.handler.gzip.GzipHandler.handle(GzipHandler.java:493)
	at org.spark_project.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:213)
	at org.spark_project.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
	at org.spark_project.jetty.server.Server.handle(Server.java:534)
	at org.spark_project.jetty.server.HttpChannel.handle(HttpChannel.java:320)
	at org.spark_project.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
	at org.spark_project.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
	at org.spark_project.jetty.io.FillInterest.fillable(FillInterest.java:108)
	at org.spark_project.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
	at org.spark_project.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
	at org.spark_project.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
	at java.lang.Thread.run(Thread.java:745)
2021-12-06 16:32:08,764 [SparkUI-103] INFO [org.spark_project.jetty.servlet.DefaultServlet] - content=ResourceHttpContent@7c43288b{r=jar:file:/C:/Users/ACER/.m2/repository/org/apache/spark/spark-core_2.11/2.3.0/spark-core_2.11-2.3.0.jar!/org/apache/spark/ui/static/sorttable.js,gz=false}
2021-12-06 16:32:08,764 [SparkUI-103] WARN [org.spark_project.jetty.servlet.ServletHandler] - Error for /static/sorttable.js
java.lang.NoSuchMethodError: javax.servlet.http.HttpServletRequest.isAsyncSupported()Z
	at org.spark_project.jetty.servlet.DefaultServlet.sendData(DefaultServlet.java:909)
	at org.spark_project.jetty.servlet.DefaultServlet.doGet(DefaultServlet.java:526)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:707)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:820)
	at org.spark_project.jetty.servlet.ServletHolder.handle(ServletHolder.java:848)
	at org.spark_project.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:584)
	at org.spark_project.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
	at org.spark_project.jetty.servlet.ServletHandler.doScope(ServletHandler.java:512)
	at org.spark_project.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
	at org.spark_project.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.spark_project.jetty.server.handler.gzip.GzipHandler.handle(GzipHandler.java:493)
	at org.spark_project.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:213)
	at org.spark_project.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
	at org.spark_project.jetty.server.Server.handle(Server.java:534)
	at org.spark_project.jetty.server.HttpChannel.handle(HttpChannel.java:320)
	at org.spark_project.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
	at org.spark_project.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
	at org.spark_project.jetty.io.FillInterest.fillable(FillInterest.java:108)
	at org.spark_project.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
	at org.spark_project.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
	at org.spark_project.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
	at java.lang.Thread.run(Thread.java:745)
2021-12-06 16:32:08,764 [SparkUI-102] INFO [org.spark_project.jetty.servlet.DefaultServlet] - content=ResourceHttpContent@2220947a{r=jar:file:/C:/Users/ACER/.m2/repository/org/apache/spark/spark-core_2.11/2.3.0/spark-core_2.11-2.3.0.jar!/org/apache/spark/ui/static/vis.min.js,gz=false}
2021-12-06 16:32:08,765 [SparkUI-102] WARN [org.spark_project.jetty.servlet.ServletHandler] - Error for /static/vis.min.js
java.lang.NoSuchMethodError: javax.servlet.http.HttpServletRequest.isAsyncSupported()Z
	at org.spark_project.jetty.servlet.DefaultServlet.sendData(DefaultServlet.java:909)
	at org.spark_project.jetty.servlet.DefaultServlet.doGet(DefaultServlet.java:526)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:707)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:820)
	at org.spark_project.jetty.servlet.ServletHolder.handle(ServletHolder.java:848)
	at org.spark_project.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:584)
	at org.spark_project.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
	at org.spark_project.jetty.servlet.ServletHandler.doScope(ServletHandler.java:512)
	at org.spark_project.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
	at org.spark_project.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.spark_project.jetty.server.handler.gzip.GzipHandler.handle(GzipHandler.java:493)
	at org.spark_project.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:213)
	at org.spark_project.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
	at org.spark_project.jetty.server.Server.handle(Server.java:534)
	at org.spark_project.jetty.server.HttpChannel.handle(HttpChannel.java:320)
	at org.spark_project.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
	at org.spark_project.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
	at org.spark_project.jetty.io.FillInterest.fillable(FillInterest.java:108)
	at org.spark_project.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
	at org.spark_project.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
	at org.spark_project.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
	at java.lang.Thread.run(Thread.java:745)
2021-12-06 16:32:08,770 [SparkUI-102] WARN [org.spark_project.jetty.server.HttpChannel] - //qb:4040/static/vis.min.js
java.lang.NoSuchMethodError: javax.servlet.http.HttpServletRequest.isAsyncStarted()Z
	at org.spark_project.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:688)
	at org.spark_project.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
	at org.spark_project.jetty.servlet.ServletHandler.doScope(ServletHandler.java:512)
	at org.spark_project.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
	at org.spark_project.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.spark_project.jetty.server.handler.gzip.GzipHandler.handle(GzipHandler.java:493)
	at org.spark_project.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:213)
	at org.spark_project.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
	at org.spark_project.jetty.server.Server.handle(Server.java:534)
	at org.spark_project.jetty.server.HttpChannel.handle(HttpChannel.java:320)
	at org.spark_project.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
	at org.spark_project.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
	at org.spark_project.jetty.io.FillInterest.fillable(FillInterest.java:108)
	at org.spark_project.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
	at org.spark_project.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
	at org.spark_project.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
	at java.lang.Thread.run(Thread.java:745)
2021-12-06 16:32:08,770 [SparkUI-104] INFO [org.spark_project.jetty.servlet.DefaultServlet] - content=ResourceHttpContent@55214bc9{r=jar:file:/C:/Users/ACER/.m2/repository/org/apache/spark/spark-core_2.11/2.3.0/spark-core_2.11-2.3.0.jar!/org/apache/spark/ui/static/jquery-1.11.1.min.js,gz=false}
2021-12-06 16:32:08,770 [SparkUI-103] WARN [org.spark_project.jetty.server.HttpChannel] - //qb:4040/static/sorttable.js
java.lang.NoSuchMethodError: javax.servlet.http.HttpServletRequest.isAsyncStarted()Z
	at org.spark_project.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:688)
	at org.spark_project.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
	at org.spark_project.jetty.servlet.ServletHandler.doScope(ServletHandler.java:512)
	at org.spark_project.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
	at org.spark_project.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.spark_project.jetty.server.handler.gzip.GzipHandler.handle(GzipHandler.java:493)
	at org.spark_project.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:213)
	at org.spark_project.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
	at org.spark_project.jetty.server.Server.handle(Server.java:534)
	at org.spark_project.jetty.server.HttpChannel.handle(HttpChannel.java:320)
	at org.spark_project.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
	at org.spark_project.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
	at org.spark_project.jetty.io.FillInterest.fillable(FillInterest.java:108)
	at org.spark_project.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
	at org.spark_project.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
	at org.spark_project.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
	at java.lang.Thread.run(Thread.java:745)
2021-12-06 16:32:08,770 [SparkUI-104] WARN [org.spark_project.jetty.servlet.ServletHandler] - Error for /static/jquery-1.11.1.min.js
java.lang.NoSuchMethodError: javax.servlet.http.HttpServletRequest.isAsyncSupported()Z
	at org.spark_project.jetty.servlet.DefaultServlet.sendData(DefaultServlet.java:909)
	at org.spark_project.jetty.servlet.DefaultServlet.doGet(DefaultServlet.java:526)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:707)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:820)
	at org.spark_project.jetty.servlet.ServletHolder.handle(ServletHolder.java:848)
	at org.spark_project.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:584)
	at org.spark_project.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
	at org.spark_project.jetty.servlet.ServletHandler.doScope(ServletHandler.java:512)
	at org.spark_project.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
	at org.spark_project.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.spark_project.jetty.server.handler.gzip.GzipHandler.handle(GzipHandler.java:493)
	at org.spark_project.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:213)
	at org.spark_project.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
	at org.spark_project.jetty.server.Server.handle(Server.java:534)
	at org.spark_project.jetty.server.HttpChannel.handle(HttpChannel.java:320)
	at org.spark_project.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
	at org.spark_project.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
	at org.spark_project.jetty.io.FillInterest.fillable(FillInterest.java:108)
	at org.spark_project.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
	at org.spark_project.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
	at org.spark_project.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
	at java.lang.Thread.run(Thread.java:745)
2021-12-06 16:32:08,770 [SparkUI-104] WARN [org.spark_project.jetty.server.HttpChannel] - //qb:4040/static/jquery-1.11.1.min.js
java.lang.NoSuchMethodError: javax.servlet.http.HttpServletRequest.isAsyncStarted()Z
	at org.spark_project.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:688)
	at org.spark_project.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
	at org.spark_project.jetty.servlet.ServletHandler.doScope(ServletHandler.java:512)
	at org.spark_project.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
	at org.spark_project.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.spark_project.jetty.server.handler.gzip.GzipHandler.handle(GzipHandler.java:493)
	at org.spark_project.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:213)
	at org.spark_project.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
	at org.spark_project.jetty.server.Server.handle(Server.java:534)
	at org.spark_project.jetty.server.HttpChannel.handle(HttpChannel.java:320)
	at org.spark_project.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
	at org.spark_project.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
	at org.spark_project.jetty.io.FillInterest.fillable(FillInterest.java:108)
	at org.spark_project.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
	at org.spark_project.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
	at org.spark_project.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
	at java.lang.Thread.run(Thread.java:745)
2021-12-06 16:32:08,771 [SparkUI-43] INFO [org.spark_project.jetty.servlet.DefaultServlet] - content=ResourceHttpContent@71a2cbf3{r=jar:file:/C:/Users/ACER/.m2/repository/org/apache/spark/spark-core_2.11/2.3.0/spark-core_2.11-2.3.0.jar!/org/apache/spark/ui/static/bootstrap-tooltip.js,gz=false}
2021-12-06 16:32:08,771 [SparkUI-43] WARN [org.spark_project.jetty.servlet.ServletHandler] - Error for /static/bootstrap-tooltip.js
java.lang.NoSuchMethodError: javax.servlet.http.HttpServletRequest.isAsyncSupported()Z
	at org.spark_project.jetty.servlet.DefaultServlet.sendData(DefaultServlet.java:909)
	at org.spark_project.jetty.servlet.DefaultServlet.doGet(DefaultServlet.java:526)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:707)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:820)
	at org.spark_project.jetty.servlet.ServletHolder.handle(ServletHolder.java:848)
	at org.spark_project.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:584)
	at org.spark_project.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
	at org.spark_project.jetty.servlet.ServletHandler.doScope(ServletHandler.java:512)
	at org.spark_project.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
	at org.spark_project.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.spark_project.jetty.server.handler.gzip.GzipHandler.handle(GzipHandler.java:493)
	at org.spark_project.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:213)
	at org.spark_project.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
	at org.spark_project.jetty.server.Server.handle(Server.java:534)
	at org.spark_project.jetty.server.HttpChannel.handle(HttpChannel.java:320)
	at org.spark_project.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
	at org.spark_project.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
	at org.spark_project.jetty.io.FillInterest.fillable(FillInterest.java:108)
	at org.spark_project.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
	at org.spark_project.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
	at org.spark_project.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
	at java.lang.Thread.run(Thread.java:745)
2021-12-06 16:32:08,771 [SparkUI-43] WARN [org.spark_project.jetty.server.HttpChannel] - //qb:4040/static/bootstrap-tooltip.js
java.lang.NoSuchMethodError: javax.servlet.http.HttpServletRequest.isAsyncStarted()Z
	at org.spark_project.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:688)
	at org.spark_project.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
	at org.spark_project.jetty.servlet.ServletHandler.doScope(ServletHandler.java:512)
	at org.spark_project.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
	at org.spark_project.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.spark_project.jetty.server.handler.gzip.GzipHandler.handle(GzipHandler.java:493)
	at org.spark_project.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:213)
	at org.spark_project.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
	at org.spark_project.jetty.server.Server.handle(Server.java:534)
	at org.spark_project.jetty.server.HttpChannel.handle(HttpChannel.java:320)
	at org.spark_project.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
	at org.spark_project.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
	at org.spark_project.jetty.io.FillInterest.fillable(FillInterest.java:108)
	at org.spark_project.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
	at org.spark_project.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
	at org.spark_project.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
	at java.lang.Thread.run(Thread.java:745)
2021-12-06 16:32:08,772 [SparkUI-103] INFO [org.spark_project.jetty.servlet.DefaultServlet] - content=ResourceHttpContent@140f83e9{r=jar:file:/C:/Users/ACER/.m2/repository/org/apache/spark/spark-core_2.11/2.3.0/spark-core_2.11-2.3.0.jar!/org/apache/spark/ui/static/initialize-tooltips.js,gz=false}
2021-12-06 16:32:08,772 [SparkUI-104] INFO [org.spark_project.jetty.servlet.DefaultServlet] - content=ResourceHttpContent@62f974eb{r=jar:file:/C:/Users/ACER/.m2/repository/org/apache/spark/spark-core_2.11/2.3.0/spark-core_2.11-2.3.0.jar!/org/apache/spark/ui/static/table.js,gz=false}
2021-12-06 16:32:08,773 [SparkUI-103] WARN [org.spark_project.jetty.servlet.ServletHandler] - Error for /static/initialize-tooltips.js
java.lang.NoSuchMethodError: javax.servlet.http.HttpServletRequest.isAsyncSupported()Z
	at org.spark_project.jetty.servlet.DefaultServlet.sendData(DefaultServlet.java:909)
	at org.spark_project.jetty.servlet.DefaultServlet.doGet(DefaultServlet.java:526)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:707)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:820)
	at org.spark_project.jetty.servlet.ServletHolder.handle(ServletHolder.java:848)
	at org.spark_project.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:584)
	at org.spark_project.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
	at org.spark_project.jetty.servlet.ServletHandler.doScope(ServletHandler.java:512)
	at org.spark_project.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
	at org.spark_project.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.spark_project.jetty.server.handler.gzip.GzipHandler.handle(GzipHandler.java:493)
	at org.spark_project.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:213)
	at org.spark_project.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
	at org.spark_project.jetty.server.Server.handle(Server.java:534)
	at org.spark_project.jetty.server.HttpChannel.handle(HttpChannel.java:320)
	at org.spark_project.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
	at org.spark_project.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
	at org.spark_project.jetty.io.FillInterest.fillable(FillInterest.java:108)
	at org.spark_project.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
	at org.spark_project.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
	at org.spark_project.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
	at java.lang.Thread.run(Thread.java:745)
2021-12-06 16:32:08,773 [SparkUI-104] WARN [org.spark_project.jetty.servlet.ServletHandler] - Error for /static/table.js
java.lang.NoSuchMethodError: javax.servlet.http.HttpServletRequest.isAsyncSupported()Z
	at org.spark_project.jetty.servlet.DefaultServlet.sendData(DefaultServlet.java:909)
	at org.spark_project.jetty.servlet.DefaultServlet.doGet(DefaultServlet.java:526)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:707)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:820)
	at org.spark_project.jetty.servlet.ServletHolder.handle(ServletHolder.java:848)
	at org.spark_project.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:584)
	at org.spark_project.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
	at org.spark_project.jetty.servlet.ServletHandler.doScope(ServletHandler.java:512)
	at org.spark_project.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
	at org.spark_project.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.spark_project.jetty.server.handler.gzip.GzipHandler.handle(GzipHandler.java:493)
	at org.spark_project.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:213)
	at org.spark_project.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
	at org.spark_project.jetty.server.Server.handle(Server.java:534)
	at org.spark_project.jetty.server.HttpChannel.handle(HttpChannel.java:320)
	at org.spark_project.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
	at org.spark_project.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
	at org.spark_project.jetty.io.FillInterest.fillable(FillInterest.java:108)
	at org.spark_project.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
	at org.spark_project.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
	at org.spark_project.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
	at java.lang.Thread.run(Thread.java:745)
2021-12-06 16:32:08,773 [SparkUI-104] WARN [org.spark_project.jetty.server.HttpChannel] - //qb:4040/static/table.js
java.lang.NoSuchMethodError: javax.servlet.http.HttpServletRequest.isAsyncStarted()Z
	at org.spark_project.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:688)
	at org.spark_project.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
	at org.spark_project.jetty.servlet.ServletHandler.doScope(ServletHandler.java:512)
	at org.spark_project.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
	at org.spark_project.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.spark_project.jetty.server.handler.gzip.GzipHandler.handle(GzipHandler.java:493)
	at org.spark_project.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:213)
	at org.spark_project.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
	at org.spark_project.jetty.server.Server.handle(Server.java:534)
	at org.spark_project.jetty.server.HttpChannel.handle(HttpChannel.java:320)
	at org.spark_project.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
	at org.spark_project.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
	at org.spark_project.jetty.io.FillInterest.fillable(FillInterest.java:108)
	at org.spark_project.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
	at org.spark_project.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
	at org.spark_project.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
	at java.lang.Thread.run(Thread.java:745)
2021-12-06 16:32:08,773 [SparkUI-103] WARN [org.spark_project.jetty.server.HttpChannel] - //qb:4040/static/initialize-tooltips.js
java.lang.NoSuchMethodError: javax.servlet.http.HttpServletRequest.isAsyncStarted()Z
	at org.spark_project.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:688)
	at org.spark_project.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
	at org.spark_project.jetty.servlet.ServletHandler.doScope(ServletHandler.java:512)
	at org.spark_project.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
	at org.spark_project.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.spark_project.jetty.server.handler.gzip.GzipHandler.handle(GzipHandler.java:493)
	at org.spark_project.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:213)
	at org.spark_project.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
	at org.spark_project.jetty.server.Server.handle(Server.java:534)
	at org.spark_project.jetty.server.HttpChannel.handle(HttpChannel.java:320)
	at org.spark_project.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
	at org.spark_project.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
	at org.spark_project.jetty.io.FillInterest.fillable(FillInterest.java:108)
	at org.spark_project.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
	at org.spark_project.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
	at org.spark_project.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
	at java.lang.Thread.run(Thread.java:745)
2021-12-06 16:32:08,774 [SparkUI-43] INFO [org.spark_project.jetty.servlet.DefaultServlet] - content=ResourceHttpContent@340d8b8a{r=jar:file:/C:/Users/ACER/.m2/repository/org/apache/spark/spark-core_2.11/2.3.0/spark-core_2.11-2.3.0.jar!/org/apache/spark/ui/static/additional-metrics.js,gz=false}
2021-12-06 16:32:08,774 [SparkUI-43] WARN [org.spark_project.jetty.servlet.ServletHandler] - Error for /static/additional-metrics.js
java.lang.NoSuchMethodError: javax.servlet.http.HttpServletRequest.isAsyncSupported()Z
	at org.spark_project.jetty.servlet.DefaultServlet.sendData(DefaultServlet.java:909)
	at org.spark_project.jetty.servlet.DefaultServlet.doGet(DefaultServlet.java:526)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:707)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:820)
	at org.spark_project.jetty.servlet.ServletHolder.handle(ServletHolder.java:848)
	at org.spark_project.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:584)
	at org.spark_project.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
	at org.spark_project.jetty.servlet.ServletHandler.doScope(ServletHandler.java:512)
	at org.spark_project.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
	at org.spark_project.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.spark_project.jetty.server.handler.gzip.GzipHandler.handle(GzipHandler.java:493)
	at org.spark_project.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:213)
	at org.spark_project.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
	at org.spark_project.jetty.server.Server.handle(Server.java:534)
	at org.spark_project.jetty.server.HttpChannel.handle(HttpChannel.java:320)
	at org.spark_project.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
	at org.spark_project.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
	at org.spark_project.jetty.io.FillInterest.fillable(FillInterest.java:108)
	at org.spark_project.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
	at org.spark_project.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
	at org.spark_project.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
	at java.lang.Thread.run(Thread.java:745)
2021-12-06 16:32:08,774 [SparkUI-43] WARN [org.spark_project.jetty.server.HttpChannel] - //qb:4040/static/additional-metrics.js
java.lang.NoSuchMethodError: javax.servlet.http.HttpServletRequest.isAsyncStarted()Z
	at org.spark_project.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:688)
	at org.spark_project.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
	at org.spark_project.jetty.servlet.ServletHandler.doScope(ServletHandler.java:512)
	at org.spark_project.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
	at org.spark_project.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.spark_project.jetty.server.handler.gzip.GzipHandler.handle(GzipHandler.java:493)
	at org.spark_project.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:213)
	at org.spark_project.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
	at org.spark_project.jetty.server.Server.handle(Server.java:534)
	at org.spark_project.jetty.server.HttpChannel.handle(HttpChannel.java:320)
	at org.spark_project.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
	at org.spark_project.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
	at org.spark_project.jetty.io.FillInterest.fillable(FillInterest.java:108)
	at org.spark_project.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
	at org.spark_project.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
	at org.spark_project.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
	at java.lang.Thread.run(Thread.java:745)
2021-12-06 16:32:08,780 [SparkUI-102] INFO [org.spark_project.jetty.servlet.DefaultServlet] - content=ResourceHttpContent@f928ddf{r=jar:file:/C:/Users/ACER/.m2/repository/org/apache/spark/spark-core_2.11/2.3.0/spark-core_2.11-2.3.0.jar!/org/apache/spark/ui/static/timeline-view.js,gz=false}
2021-12-06 16:32:08,780 [SparkUI-102] WARN [org.spark_project.jetty.servlet.ServletHandler] - Error for /static/timeline-view.js
java.lang.NoSuchMethodError: javax.servlet.http.HttpServletRequest.isAsyncSupported()Z
	at org.spark_project.jetty.servlet.DefaultServlet.sendData(DefaultServlet.java:909)
	at org.spark_project.jetty.servlet.DefaultServlet.doGet(DefaultServlet.java:526)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:707)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:820)
	at org.spark_project.jetty.servlet.ServletHolder.handle(ServletHolder.java:848)
	at org.spark_project.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:584)
	at org.spark_project.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
	at org.spark_project.jetty.servlet.ServletHandler.doScope(ServletHandler.java:512)
	at org.spark_project.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
	at org.spark_project.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.spark_project.jetty.server.handler.gzip.GzipHandler.handle(GzipHandler.java:493)
	at org.spark_project.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:213)
	at org.spark_project.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
	at org.spark_project.jetty.server.Server.handle(Server.java:534)
	at org.spark_project.jetty.server.HttpChannel.handle(HttpChannel.java:320)
	at org.spark_project.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
	at org.spark_project.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
	at org.spark_project.jetty.io.FillInterest.fillable(FillInterest.java:108)
	at org.spark_project.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
	at org.spark_project.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
	at org.spark_project.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
	at java.lang.Thread.run(Thread.java:745)
2021-12-06 16:32:08,780 [SparkUI-102] WARN [org.spark_project.jetty.server.HttpChannel] - //qb:4040/static/timeline-view.js
java.lang.NoSuchMethodError: javax.servlet.http.HttpServletRequest.isAsyncStarted()Z
	at org.spark_project.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:688)
	at org.spark_project.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
	at org.spark_project.jetty.servlet.ServletHandler.doScope(ServletHandler.java:512)
	at org.spark_project.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
	at org.spark_project.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.spark_project.jetty.server.handler.gzip.GzipHandler.handle(GzipHandler.java:493)
	at org.spark_project.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:213)
	at org.spark_project.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
	at org.spark_project.jetty.server.Server.handle(Server.java:534)
	at org.spark_project.jetty.server.HttpChannel.handle(HttpChannel.java:320)
	at org.spark_project.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
	at org.spark_project.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
	at org.spark_project.jetty.io.FillInterest.fillable(FillInterest.java:108)
	at org.spark_project.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
	at org.spark_project.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
	at org.spark_project.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
	at java.lang.Thread.run(Thread.java:745)
2021-12-06 16:32:08,789 [SparkUI-103] INFO [org.spark_project.jetty.servlet.DefaultServlet] - content=ResourceHttpContent@61d9af34{r=jar:file:/C:/Users/ACER/.m2/repository/org/apache/spark/spark-core_2.11/2.3.0/spark-core_2.11-2.3.0.jar!/org/apache/spark/ui/static/log-view.js,gz=false}
2021-12-06 16:32:08,789 [SparkUI-104] INFO [org.spark_project.jetty.servlet.DefaultServlet] - content=ResourceHttpContent@709fc2d0{r=jar:file:/C:/Users/ACER/.m2/repository/org/apache/spark/spark-core_2.11/2.3.0/spark-core_2.11-2.3.0.jar!/org/apache/spark/ui/static/webui.js,gz=false}
2021-12-06 16:32:08,789 [SparkUI-103] WARN [org.spark_project.jetty.servlet.ServletHandler] - Error for /static/log-view.js
java.lang.NoSuchMethodError: javax.servlet.http.HttpServletRequest.isAsyncSupported()Z
	at org.spark_project.jetty.servlet.DefaultServlet.sendData(DefaultServlet.java:909)
	at org.spark_project.jetty.servlet.DefaultServlet.doGet(DefaultServlet.java:526)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:707)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:820)
	at org.spark_project.jetty.servlet.ServletHolder.handle(ServletHolder.java:848)
	at org.spark_project.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:584)
	at org.spark_project.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
	at org.spark_project.jetty.servlet.ServletHandler.doScope(ServletHandler.java:512)
	at org.spark_project.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
	at org.spark_project.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.spark_project.jetty.server.handler.gzip.GzipHandler.handle(GzipHandler.java:493)
	at org.spark_project.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:213)
	at org.spark_project.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
	at org.spark_project.jetty.server.Server.handle(Server.java:534)
	at org.spark_project.jetty.server.HttpChannel.handle(HttpChannel.java:320)
	at org.spark_project.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
	at org.spark_project.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
	at org.spark_project.jetty.io.FillInterest.fillable(FillInterest.java:108)
	at org.spark_project.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
	at org.spark_project.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
	at org.spark_project.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
	at java.lang.Thread.run(Thread.java:745)
2021-12-06 16:32:08,789 [SparkUI-104] WARN [org.spark_project.jetty.servlet.ServletHandler] - Error for /static/webui.js
java.lang.NoSuchMethodError: javax.servlet.http.HttpServletRequest.isAsyncSupported()Z
	at org.spark_project.jetty.servlet.DefaultServlet.sendData(DefaultServlet.java:909)
	at org.spark_project.jetty.servlet.DefaultServlet.doGet(DefaultServlet.java:526)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:707)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:820)
	at org.spark_project.jetty.servlet.ServletHolder.handle(ServletHolder.java:848)
	at org.spark_project.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:584)
	at org.spark_project.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
	at org.spark_project.jetty.servlet.ServletHandler.doScope(ServletHandler.java:512)
	at org.spark_project.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
	at org.spark_project.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.spark_project.jetty.server.handler.gzip.GzipHandler.handle(GzipHandler.java:493)
	at org.spark_project.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:213)
	at org.spark_project.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
	at org.spark_project.jetty.server.Server.handle(Server.java:534)
	at org.spark_project.jetty.server.HttpChannel.handle(HttpChannel.java:320)
	at org.spark_project.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
	at org.spark_project.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
	at org.spark_project.jetty.io.FillInterest.fillable(FillInterest.java:108)
	at org.spark_project.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
	at org.spark_project.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
	at org.spark_project.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
	at java.lang.Thread.run(Thread.java:745)
2021-12-06 16:32:08,789 [SparkUI-104] WARN [org.spark_project.jetty.server.HttpChannel] - //qb:4040/static/webui.js
java.lang.NoSuchMethodError: javax.servlet.http.HttpServletRequest.isAsyncStarted()Z
	at org.spark_project.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:688)
	at org.spark_project.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
	at org.spark_project.jetty.servlet.ServletHandler.doScope(ServletHandler.java:512)
	at org.spark_project.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
	at org.spark_project.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.spark_project.jetty.server.handler.gzip.GzipHandler.handle(GzipHandler.java:493)
	at org.spark_project.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:213)
	at org.spark_project.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
	at org.spark_project.jetty.server.Server.handle(Server.java:534)
	at org.spark_project.jetty.server.HttpChannel.handle(HttpChannel.java:320)
	at org.spark_project.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
	at org.spark_project.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
	at org.spark_project.jetty.io.FillInterest.fillable(FillInterest.java:108)
	at org.spark_project.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
	at org.spark_project.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
	at org.spark_project.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
	at java.lang.Thread.run(Thread.java:745)
2021-12-06 16:32:08,789 [SparkUI-103] WARN [org.spark_project.jetty.server.HttpChannel] - //qb:4040/static/log-view.js
java.lang.NoSuchMethodError: javax.servlet.http.HttpServletRequest.isAsyncStarted()Z
	at org.spark_project.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:688)
	at org.spark_project.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
	at org.spark_project.jetty.servlet.ServletHandler.doScope(ServletHandler.java:512)
	at org.spark_project.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
	at org.spark_project.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.spark_project.jetty.server.handler.gzip.GzipHandler.handle(GzipHandler.java:493)
	at org.spark_project.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:213)
	at org.spark_project.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
	at org.spark_project.jetty.server.Server.handle(Server.java:534)
	at org.spark_project.jetty.server.HttpChannel.handle(HttpChannel.java:320)
	at org.spark_project.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
	at org.spark_project.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
	at org.spark_project.jetty.io.FillInterest.fillable(FillInterest.java:108)
	at org.spark_project.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
	at org.spark_project.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
	at org.spark_project.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
	at java.lang.Thread.run(Thread.java:745)
2021-12-06 16:32:08,807 [SparkUI-103] INFO [org.spark_project.jetty.servlet.DefaultServlet] - content=ResourceHttpContent@1278881d{r=jar:file:/C:/Users/ACER/.m2/repository/org/apache/spark/spark-core_2.11/2.3.0/spark-core_2.11-2.3.0.jar!/org/apache/spark/ui/static/spark-logo-77x50px-hd.png,gz=false}
2021-12-06 16:32:08,808 [SparkUI-103] WARN [org.spark_project.jetty.servlet.ServletHandler] - Error for /static/spark-logo-77x50px-hd.png
java.lang.NoSuchMethodError: javax.servlet.http.HttpServletRequest.isAsyncSupported()Z
	at org.spark_project.jetty.servlet.DefaultServlet.sendData(DefaultServlet.java:909)
	at org.spark_project.jetty.servlet.DefaultServlet.doGet(DefaultServlet.java:526)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:707)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:820)
	at org.spark_project.jetty.servlet.ServletHolder.handle(ServletHolder.java:848)
	at org.spark_project.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:584)
	at org.spark_project.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
	at org.spark_project.jetty.servlet.ServletHandler.doScope(ServletHandler.java:512)
	at org.spark_project.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
	at org.spark_project.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.spark_project.jetty.server.handler.gzip.GzipHandler.handle(GzipHandler.java:448)
	at org.spark_project.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:213)
	at org.spark_project.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
	at org.spark_project.jetty.server.Server.handle(Server.java:534)
	at org.spark_project.jetty.server.HttpChannel.handle(HttpChannel.java:320)
	at org.spark_project.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
	at org.spark_project.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
	at org.spark_project.jetty.io.FillInterest.fillable(FillInterest.java:108)
	at org.spark_project.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
	at org.spark_project.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
	at org.spark_project.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
	at java.lang.Thread.run(Thread.java:745)
2021-12-06 16:32:08,808 [SparkUI-103] WARN [org.spark_project.jetty.server.HttpChannel] - //qb:4040/static/spark-logo-77x50px-hd.png
java.lang.NoSuchMethodError: javax.servlet.http.HttpServletRequest.isAsyncStarted()Z
	at org.spark_project.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:688)
	at org.spark_project.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
	at org.spark_project.jetty.servlet.ServletHandler.doScope(ServletHandler.java:512)
	at org.spark_project.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
	at org.spark_project.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.spark_project.jetty.server.handler.gzip.GzipHandler.handle(GzipHandler.java:448)
	at org.spark_project.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:213)
	at org.spark_project.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
	at org.spark_project.jetty.server.Server.handle(Server.java:534)
	at org.spark_project.jetty.server.HttpChannel.handle(HttpChannel.java:320)
	at org.spark_project.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
	at org.spark_project.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
	at org.spark_project.jetty.io.FillInterest.fillable(FillInterest.java:108)
	at org.spark_project.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
	at org.spark_project.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
	at org.spark_project.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
	at java.lang.Thread.run(Thread.java:745)
2021-12-06 16:32:09,056 [SparkUI-39] WARN [org.spark_project.jetty.http.HttpParser] - bad HTTP parsed: 400 Unknown Version for HttpChannelOverHttp@74e6ca4d{r=0,c=false,a=IDLE,uri=null}
org.spark_project.jetty.http.BadMessageException: 400: Unknown Version
	at org.spark_project.jetty.http.HttpParser.parseLine(HttpParser.java:835)
	at org.spark_project.jetty.http.HttpParser.parseNext(HttpParser.java:1328)
	at org.spark_project.jetty.server.HttpConnection.parseRequestBuffer(HttpConnection.java:351)
	at org.spark_project.jetty.server.HttpConnection.onFillable(HttpConnection.java:234)
	at org.spark_project.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
	at org.spark_project.jetty.io.FillInterest.fillable(FillInterest.java:108)
	at org.spark_project.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
	at org.spark_project.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
	at org.spark_project.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
	at java.lang.Thread.run(Thread.java:745)
2021-12-06 16:32:21,533 [SparkUI-40] INFO [org.spark_project.jetty.servlet.DefaultServlet] - content=ResourceHttpContent@c2136f4{r=jar:file:/C:/Users/ACER/.m2/repository/org/apache/spark/spark-core_2.11/2.3.0/spark-core_2.11-2.3.0.jar!/org/apache/spark/ui/static/bootstrap.min.css,gz=false}
2021-12-06 16:32:21,533 [SparkUI-40] WARN [org.spark_project.jetty.servlet.ServletHandler] - Error for /static/bootstrap.min.css
java.lang.NoSuchMethodError: javax.servlet.http.HttpServletRequest.isAsyncSupported()Z
	at org.spark_project.jetty.servlet.DefaultServlet.sendData(DefaultServlet.java:909)
	at org.spark_project.jetty.servlet.DefaultServlet.doGet(DefaultServlet.java:526)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:707)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:820)
	at org.spark_project.jetty.servlet.ServletHolder.handle(ServletHolder.java:848)
	at org.spark_project.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:584)
	at org.spark_project.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
	at org.spark_project.jetty.servlet.ServletHandler.doScope(ServletHandler.java:512)
	at org.spark_project.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
	at org.spark_project.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.spark_project.jetty.server.handler.gzip.GzipHandler.handle(GzipHandler.java:493)
	at org.spark_project.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:213)
	at org.spark_project.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
	at org.spark_project.jetty.server.Server.handle(Server.java:534)
	at org.spark_project.jetty.server.HttpChannel.handle(HttpChannel.java:320)
	at org.spark_project.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
	at org.spark_project.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
	at org.spark_project.jetty.io.FillInterest.fillable(FillInterest.java:108)
	at org.spark_project.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
	at org.spark_project.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
	at org.spark_project.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
	at java.lang.Thread.run(Thread.java:745)
2021-12-06 16:32:21,533 [SparkUI-40] WARN [org.spark_project.jetty.server.HttpChannel] - //qb:4040/static/bootstrap.min.css
java.lang.NoSuchMethodError: javax.servlet.http.HttpServletRequest.isAsyncStarted()Z
	at org.spark_project.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:688)
	at org.spark_project.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
	at org.spark_project.jetty.servlet.ServletHandler.doScope(ServletHandler.java:512)
	at org.spark_project.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
	at org.spark_project.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.spark_project.jetty.server.handler.gzip.GzipHandler.handle(GzipHandler.java:493)
	at org.spark_project.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:213)
	at org.spark_project.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
	at org.spark_project.jetty.server.Server.handle(Server.java:534)
	at org.spark_project.jetty.server.HttpChannel.handle(HttpChannel.java:320)
	at org.spark_project.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
	at org.spark_project.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
	at org.spark_project.jetty.io.FillInterest.fillable(FillInterest.java:108)
	at org.spark_project.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
	at org.spark_project.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
	at org.spark_project.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
	at java.lang.Thread.run(Thread.java:745)
2021-12-06 16:32:21,534 [SparkUI-108] INFO [org.spark_project.jetty.servlet.DefaultServlet] - content=ResourceHttpContent@31e9d4a8{r=jar:file:/C:/Users/ACER/.m2/repository/org/apache/spark/spark-core_2.11/2.3.0/spark-core_2.11-2.3.0.jar!/org/apache/spark/ui/static/vis.min.css,gz=false}
2021-12-06 16:32:21,534 [SparkUI-108] WARN [org.spark_project.jetty.servlet.ServletHandler] - Error for /static/vis.min.css
java.lang.NoSuchMethodError: javax.servlet.http.HttpServletRequest.isAsyncSupported()Z
	at org.spark_project.jetty.servlet.DefaultServlet.sendData(DefaultServlet.java:909)
	at org.spark_project.jetty.servlet.DefaultServlet.doGet(DefaultServlet.java:526)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:707)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:820)
	at org.spark_project.jetty.servlet.ServletHolder.handle(ServletHolder.java:848)
	at org.spark_project.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:584)
	at org.spark_project.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
	at org.spark_project.jetty.servlet.ServletHandler.doScope(ServletHandler.java:512)
	at org.spark_project.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
	at org.spark_project.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.spark_project.jetty.server.handler.gzip.GzipHandler.handle(GzipHandler.java:493)
	at org.spark_project.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:213)
	at org.spark_project.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
	at org.spark_project.jetty.server.Server.handle(Server.java:534)
	at org.spark_project.jetty.server.HttpChannel.handle(HttpChannel.java:320)
	at org.spark_project.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
	at org.spark_project.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
	at org.spark_project.jetty.io.FillInterest.fillable(FillInterest.java:108)
	at org.spark_project.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
	at org.spark_project.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
	at org.spark_project.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
	at java.lang.Thread.run(Thread.java:745)
2021-12-06 16:32:21,534 [SparkUI-108] WARN [org.spark_project.jetty.server.HttpChannel] - //qb:4040/static/vis.min.css
java.lang.NoSuchMethodError: javax.servlet.http.HttpServletRequest.isAsyncStarted()Z
	at org.spark_project.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:688)
	at org.spark_project.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
	at org.spark_project.jetty.servlet.ServletHandler.doScope(ServletHandler.java:512)
	at org.spark_project.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
	at org.spark_project.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.spark_project.jetty.server.handler.gzip.GzipHandler.handle(GzipHandler.java:493)
	at org.spark_project.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:213)
	at org.spark_project.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
	at org.spark_project.jetty.server.Server.handle(Server.java:534)
	at org.spark_project.jetty.server.HttpChannel.handle(HttpChannel.java:320)
	at org.spark_project.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
	at org.spark_project.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
	at org.spark_project.jetty.io.FillInterest.fillable(FillInterest.java:108)
	at org.spark_project.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
	at org.spark_project.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
	at org.spark_project.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
	at java.lang.Thread.run(Thread.java:745)
2021-12-06 16:32:21,537 [SparkUI-38] INFO [org.spark_project.jetty.servlet.DefaultServlet] - content=ResourceHttpContent@1c96026{r=jar:file:/C:/Users/ACER/.m2/repository/org/apache/spark/spark-core_2.11/2.3.0/spark-core_2.11-2.3.0.jar!/org/apache/spark/ui/static/timeline-view.css,gz=false}
2021-12-06 16:32:21,537 [SparkUI-104] INFO [org.spark_project.jetty.servlet.DefaultServlet] - content=ResourceHttpContent@2fe3ec92{r=jar:file:/C:/Users/ACER/.m2/repository/org/apache/spark/spark-core_2.11/2.3.0/spark-core_2.11-2.3.0.jar!/org/apache/spark/ui/static/webui.css,gz=false}
2021-12-06 16:32:21,537 [SparkUI-37] INFO [org.spark_project.jetty.servlet.DefaultServlet] - content=ResourceHttpContent@15adae51{r=jar:file:/C:/Users/ACER/.m2/repository/org/apache/spark/spark-core_2.11/2.3.0/spark-core_2.11-2.3.0.jar!/org/apache/spark/ui/static/bootstrap.min.css,gz=false}
2021-12-06 16:32:21,538 [SparkUI-38] WARN [org.spark_project.jetty.servlet.ServletHandler] - Error for /static/timeline-view.css
java.lang.NoSuchMethodError: javax.servlet.http.HttpServletRequest.isAsyncSupported()Z
	at org.spark_project.jetty.servlet.DefaultServlet.sendData(DefaultServlet.java:909)
	at org.spark_project.jetty.servlet.DefaultServlet.doGet(DefaultServlet.java:526)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:707)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:820)
	at org.spark_project.jetty.servlet.ServletHolder.handle(ServletHolder.java:848)
	at org.spark_project.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:584)
	at org.spark_project.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
	at org.spark_project.jetty.servlet.ServletHandler.doScope(ServletHandler.java:512)
	at org.spark_project.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
	at org.spark_project.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.spark_project.jetty.server.handler.gzip.GzipHandler.handle(GzipHandler.java:493)
	at org.spark_project.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:213)
	at org.spark_project.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
	at org.spark_project.jetty.server.Server.handle(Server.java:534)
	at org.spark_project.jetty.server.HttpChannel.handle(HttpChannel.java:320)
	at org.spark_project.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
	at org.spark_project.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
	at org.spark_project.jetty.io.FillInterest.fillable(FillInterest.java:108)
	at org.spark_project.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
	at org.spark_project.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
	at org.spark_project.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
	at java.lang.Thread.run(Thread.java:745)
2021-12-06 16:32:21,538 [SparkUI-37] WARN [org.spark_project.jetty.servlet.ServletHandler] - Error for /static/bootstrap.min.css
java.lang.NoSuchMethodError: javax.servlet.http.HttpServletRequest.isAsyncSupported()Z
	at org.spark_project.jetty.servlet.DefaultServlet.sendData(DefaultServlet.java:909)
	at org.spark_project.jetty.servlet.DefaultServlet.doGet(DefaultServlet.java:526)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:707)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:820)
	at org.spark_project.jetty.servlet.ServletHolder.handle(ServletHolder.java:848)
	at org.spark_project.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:584)
	at org.spark_project.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
	at org.spark_project.jetty.servlet.ServletHandler.doScope(ServletHandler.java:512)
	at org.spark_project.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
	at org.spark_project.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.spark_project.jetty.server.handler.gzip.GzipHandler.handle(GzipHandler.java:493)
	at org.spark_project.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:213)
	at org.spark_project.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
	at org.spark_project.jetty.server.Server.handle(Server.java:534)
	at org.spark_project.jetty.server.HttpChannel.handle(HttpChannel.java:320)
	at org.spark_project.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
	at org.spark_project.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
	at org.spark_project.jetty.io.FillInterest.fillable(FillInterest.java:108)
	at org.spark_project.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
	at org.spark_project.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
	at org.spark_project.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
	at java.lang.Thread.run(Thread.java:745)
2021-12-06 16:32:21,538 [SparkUI-103] INFO [org.spark_project.jetty.servlet.DefaultServlet] - content=ResourceHttpContent@399268df{r=jar:file:/C:/Users/ACER/.m2/repository/org/apache/spark/spark-core_2.11/2.3.0/spark-core_2.11-2.3.0.jar!/org/apache/spark/ui/static/vis.min.css,gz=false}
2021-12-06 16:32:21,538 [SparkUI-104] WARN [org.spark_project.jetty.servlet.ServletHandler] - Error for /static/webui.css
java.lang.NoSuchMethodError: javax.servlet.http.HttpServletRequest.isAsyncSupported()Z
	at org.spark_project.jetty.servlet.DefaultServlet.sendData(DefaultServlet.java:909)
	at org.spark_project.jetty.servlet.DefaultServlet.doGet(DefaultServlet.java:526)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:707)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:820)
	at org.spark_project.jetty.servlet.ServletHolder.handle(ServletHolder.java:848)
	at org.spark_project.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:584)
	at org.spark_project.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
	at org.spark_project.jetty.servlet.ServletHandler.doScope(ServletHandler.java:512)
	at org.spark_project.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
	at org.spark_project.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.spark_project.jetty.server.handler.gzip.GzipHandler.handle(GzipHandler.java:493)
	at org.spark_project.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:213)
	at org.spark_project.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
	at org.spark_project.jetty.server.Server.handle(Server.java:534)
	at org.spark_project.jetty.server.HttpChannel.handle(HttpChannel.java:320)
	at org.spark_project.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
	at org.spark_project.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
	at org.spark_project.jetty.io.FillInterest.fillable(FillInterest.java:108)
	at org.spark_project.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
	at org.spark_project.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
	at org.spark_project.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
	at java.lang.Thread.run(Thread.java:745)
2021-12-06 16:32:21,538 [SparkUI-103] WARN [org.spark_project.jetty.servlet.ServletHandler] - Error for /static/vis.min.css
java.lang.NoSuchMethodError: javax.servlet.http.HttpServletRequest.isAsyncSupported()Z
	at org.spark_project.jetty.servlet.DefaultServlet.sendData(DefaultServlet.java:909)
	at org.spark_project.jetty.servlet.DefaultServlet.doGet(DefaultServlet.java:526)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:707)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:820)
	at org.spark_project.jetty.servlet.ServletHolder.handle(ServletHolder.java:848)
	at org.spark_project.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:584)
	at org.spark_project.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
	at org.spark_project.jetty.servlet.ServletHandler.doScope(ServletHandler.java:512)
	at org.spark_project.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
	at org.spark_project.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.spark_project.jetty.server.handler.gzip.GzipHandler.handle(GzipHandler.java:493)
	at org.spark_project.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:213)
	at org.spark_project.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
	at org.spark_project.jetty.server.Server.handle(Server.java:534)
	at org.spark_project.jetty.server.HttpChannel.handle(HttpChannel.java:320)
	at org.spark_project.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
	at org.spark_project.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
	at org.spark_project.jetty.io.FillInterest.fillable(FillInterest.java:108)
	at org.spark_project.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
	at org.spark_project.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
	at org.spark_project.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
	at java.lang.Thread.run(Thread.java:745)
2021-12-06 16:32:21,538 [SparkUI-104] WARN [org.spark_project.jetty.server.HttpChannel] - //qb:4040/static/webui.css
java.lang.NoSuchMethodError: javax.servlet.http.HttpServletRequest.isAsyncStarted()Z
	at org.spark_project.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:688)
	at org.spark_project.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
	at org.spark_project.jetty.servlet.ServletHandler.doScope(ServletHandler.java:512)
	at org.spark_project.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
	at org.spark_project.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.spark_project.jetty.server.handler.gzip.GzipHandler.handle(GzipHandler.java:493)
	at org.spark_project.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:213)
	at org.spark_project.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
	at org.spark_project.jetty.server.Server.handle(Server.java:534)
	at org.spark_project.jetty.server.HttpChannel.handle(HttpChannel.java:320)
	at org.spark_project.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
	at org.spark_project.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
	at org.spark_project.jetty.io.FillInterest.fillable(FillInterest.java:108)
	at org.spark_project.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
	at org.spark_project.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
	at org.spark_project.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
	at java.lang.Thread.run(Thread.java:745)
2021-12-06 16:32:21,538 [SparkUI-108] INFO [org.spark_project.jetty.servlet.DefaultServlet] - content=ResourceHttpContent@13b16efe{r=jar:file:/C:/Users/ACER/.m2/repository/org/apache/spark/spark-core_2.11/2.3.0/spark-core_2.11-2.3.0.jar!/org/apache/spark/ui/static/sorttable.js,gz=false}
2021-12-06 16:32:21,538 [SparkUI-103] WARN [org.spark_project.jetty.server.HttpChannel] - //qb:4040/static/vis.min.css
java.lang.NoSuchMethodError: javax.servlet.http.HttpServletRequest.isAsyncStarted()Z
	at org.spark_project.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:688)
	at org.spark_project.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
	at org.spark_project.jetty.servlet.ServletHandler.doScope(ServletHandler.java:512)
	at org.spark_project.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
	at org.spark_project.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.spark_project.jetty.server.handler.gzip.GzipHandler.handle(GzipHandler.java:493)
	at org.spark_project.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:213)
	at org.spark_project.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
	at org.spark_project.jetty.server.Server.handle(Server.java:534)
	at org.spark_project.jetty.server.HttpChannel.handle(HttpChannel.java:320)
	at org.spark_project.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
	at org.spark_project.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
	at org.spark_project.jetty.io.FillInterest.fillable(FillInterest.java:108)
	at org.spark_project.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
	at org.spark_project.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
	at org.spark_project.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
	at java.lang.Thread.run(Thread.java:745)
2021-12-06 16:32:21,538 [SparkUI-37] WARN [org.spark_project.jetty.server.HttpChannel] - //qb:4040/static/bootstrap.min.css
java.lang.NoSuchMethodError: javax.servlet.http.HttpServletRequest.isAsyncStarted()Z
	at org.spark_project.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:688)
	at org.spark_project.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
	at org.spark_project.jetty.servlet.ServletHandler.doScope(ServletHandler.java:512)
	at org.spark_project.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
	at org.spark_project.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.spark_project.jetty.server.handler.gzip.GzipHandler.handle(GzipHandler.java:493)
	at org.spark_project.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:213)
	at org.spark_project.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
	at org.spark_project.jetty.server.Server.handle(Server.java:534)
	at org.spark_project.jetty.server.HttpChannel.handle(HttpChannel.java:320)
	at org.spark_project.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
	at org.spark_project.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
	at org.spark_project.jetty.io.FillInterest.fillable(FillInterest.java:108)
	at org.spark_project.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
	at org.spark_project.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
	at org.spark_project.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
	at java.lang.Thread.run(Thread.java:745)
2021-12-06 16:32:21,538 [SparkUI-38] WARN [org.spark_project.jetty.server.HttpChannel] - //qb:4040/static/timeline-view.css
java.lang.NoSuchMethodError: javax.servlet.http.HttpServletRequest.isAsyncStarted()Z
	at org.spark_project.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:688)
	at org.spark_project.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
	at org.spark_project.jetty.servlet.ServletHandler.doScope(ServletHandler.java:512)
	at org.spark_project.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
	at org.spark_project.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.spark_project.jetty.server.handler.gzip.GzipHandler.handle(GzipHandler.java:493)
	at org.spark_project.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:213)
	at org.spark_project.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
	at org.spark_project.jetty.server.Server.handle(Server.java:534)
	at org.spark_project.jetty.server.HttpChannel.handle(HttpChannel.java:320)
	at org.spark_project.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
	at org.spark_project.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
	at org.spark_project.jetty.io.FillInterest.fillable(FillInterest.java:108)
	at org.spark_project.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
	at org.spark_project.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
	at org.spark_project.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
	at java.lang.Thread.run(Thread.java:745)
2021-12-06 16:32:21,538 [SparkUI-108] WARN [org.spark_project.jetty.servlet.ServletHandler] - Error for /static/sorttable.js
java.lang.NoSuchMethodError: javax.servlet.http.HttpServletRequest.isAsyncSupported()Z
	at org.spark_project.jetty.servlet.DefaultServlet.sendData(DefaultServlet.java:909)
	at org.spark_project.jetty.servlet.DefaultServlet.doGet(DefaultServlet.java:526)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:707)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:820)
	at org.spark_project.jetty.servlet.ServletHolder.handle(ServletHolder.java:848)
	at org.spark_project.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:584)
	at org.spark_project.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
	at org.spark_project.jetty.servlet.ServletHandler.doScope(ServletHandler.java:512)
	at org.spark_project.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
	at org.spark_project.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.spark_project.jetty.server.handler.gzip.GzipHandler.handle(GzipHandler.java:493)
	at org.spark_project.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:213)
	at org.spark_project.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
	at org.spark_project.jetty.server.Server.handle(Server.java:534)
	at org.spark_project.jetty.server.HttpChannel.handle(HttpChannel.java:320)
	at org.spark_project.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
	at org.spark_project.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
	at org.spark_project.jetty.io.FillInterest.fillable(FillInterest.java:108)
	at org.spark_project.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
	at org.spark_project.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
	at org.spark_project.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
	at java.lang.Thread.run(Thread.java:745)
2021-12-06 16:32:21,539 [SparkUI-108] WARN [org.spark_project.jetty.server.HttpChannel] - //qb:4040/static/sorttable.js
java.lang.NoSuchMethodError: javax.servlet.http.HttpServletRequest.isAsyncStarted()Z
	at org.spark_project.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:688)
	at org.spark_project.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
	at org.spark_project.jetty.servlet.ServletHandler.doScope(ServletHandler.java:512)
	at org.spark_project.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
	at org.spark_project.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.spark_project.jetty.server.handler.gzip.GzipHandler.handle(GzipHandler.java:493)
	at org.spark_project.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:213)
	at org.spark_project.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
	at org.spark_project.jetty.server.Server.handle(Server.java:534)
	at org.spark_project.jetty.server.HttpChannel.handle(HttpChannel.java:320)
	at org.spark_project.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
	at org.spark_project.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
	at org.spark_project.jetty.io.FillInterest.fillable(FillInterest.java:108)
	at org.spark_project.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
	at org.spark_project.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
	at org.spark_project.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
	at java.lang.Thread.run(Thread.java:745)
2021-12-06 16:32:21,539 [SparkUI-40] INFO [org.spark_project.jetty.servlet.DefaultServlet] - content=ResourceHttpContent@5fba008c{r=jar:file:/C:/Users/ACER/.m2/repository/org/apache/spark/spark-core_2.11/2.3.0/spark-core_2.11-2.3.0.jar!/org/apache/spark/ui/static/jquery-1.11.1.min.js,gz=false}
2021-12-06 16:32:21,539 [SparkUI-40] WARN [org.spark_project.jetty.servlet.ServletHandler] - Error for /static/jquery-1.11.1.min.js
java.lang.NoSuchMethodError: javax.servlet.http.HttpServletRequest.isAsyncSupported()Z
	at org.spark_project.jetty.servlet.DefaultServlet.sendData(DefaultServlet.java:909)
	at org.spark_project.jetty.servlet.DefaultServlet.doGet(DefaultServlet.java:526)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:707)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:820)
	at org.spark_project.jetty.servlet.ServletHolder.handle(ServletHolder.java:848)
	at org.spark_project.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:584)
	at org.spark_project.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
	at org.spark_project.jetty.servlet.ServletHandler.doScope(ServletHandler.java:512)
	at org.spark_project.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
	at org.spark_project.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.spark_project.jetty.server.handler.gzip.GzipHandler.handle(GzipHandler.java:493)
	at org.spark_project.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:213)
	at org.spark_project.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
	at org.spark_project.jetty.server.Server.handle(Server.java:534)
	at org.spark_project.jetty.server.HttpChannel.handle(HttpChannel.java:320)
	at org.spark_project.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
	at org.spark_project.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
	at org.spark_project.jetty.io.FillInterest.fillable(FillInterest.java:108)
	at org.spark_project.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
	at org.spark_project.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
	at org.spark_project.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
	at java.lang.Thread.run(Thread.java:745)
2021-12-06 16:32:21,539 [SparkUI-40] WARN [org.spark_project.jetty.server.HttpChannel] - //qb:4040/static/jquery-1.11.1.min.js
java.lang.NoSuchMethodError: javax.servlet.http.HttpServletRequest.isAsyncStarted()Z
	at org.spark_project.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:688)
	at org.spark_project.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
	at org.spark_project.jetty.servlet.ServletHandler.doScope(ServletHandler.java:512)
	at org.spark_project.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
	at org.spark_project.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.spark_project.jetty.server.handler.gzip.GzipHandler.handle(GzipHandler.java:493)
	at org.spark_project.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:213)
	at org.spark_project.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
	at org.spark_project.jetty.server.Server.handle(Server.java:534)
	at org.spark_project.jetty.server.HttpChannel.handle(HttpChannel.java:320)
	at org.spark_project.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
	at org.spark_project.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
	at org.spark_project.jetty.io.FillInterest.fillable(FillInterest.java:108)
	at org.spark_project.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
	at org.spark_project.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
	at org.spark_project.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
	at java.lang.Thread.run(Thread.java:745)
2021-12-06 16:32:21,543 [SparkUI-102] INFO [org.spark_project.jetty.servlet.DefaultServlet] - content=ResourceHttpContent@21010206{r=jar:file:/C:/Users/ACER/.m2/repository/org/apache/spark/spark-core_2.11/2.3.0/spark-core_2.11-2.3.0.jar!/org/apache/spark/ui/static/initialize-tooltips.js,gz=false}
2021-12-06 16:32:21,543 [SparkUI-108] INFO [org.spark_project.jetty.servlet.DefaultServlet] - content=ResourceHttpContent@62beb2e8{r=jar:file:/C:/Users/ACER/.m2/repository/org/apache/spark/spark-core_2.11/2.3.0/spark-core_2.11-2.3.0.jar!/org/apache/spark/ui/static/bootstrap-tooltip.js,gz=false}
2021-12-06 16:32:21,543 [SparkUI-102] WARN [org.spark_project.jetty.servlet.ServletHandler] - Error for /static/initialize-tooltips.js
java.lang.NoSuchMethodError: javax.servlet.http.HttpServletRequest.isAsyncSupported()Z
	at org.spark_project.jetty.servlet.DefaultServlet.sendData(DefaultServlet.java:909)
	at org.spark_project.jetty.servlet.DefaultServlet.doGet(DefaultServlet.java:526)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:707)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:820)
	at org.spark_project.jetty.servlet.ServletHolder.handle(ServletHolder.java:848)
	at org.spark_project.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:584)
	at org.spark_project.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
	at org.spark_project.jetty.servlet.ServletHandler.doScope(ServletHandler.java:512)
	at org.spark_project.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
	at org.spark_project.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.spark_project.jetty.server.handler.gzip.GzipHandler.handle(GzipHandler.java:493)
	at org.spark_project.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:213)
	at org.spark_project.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
	at org.spark_project.jetty.server.Server.handle(Server.java:534)
	at org.spark_project.jetty.server.HttpChannel.handle(HttpChannel.java:320)
	at org.spark_project.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
	at org.spark_project.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
	at org.spark_project.jetty.io.FillInterest.fillable(FillInterest.java:108)
	at org.spark_project.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
	at org.spark_project.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
	at org.spark_project.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
	at java.lang.Thread.run(Thread.java:745)
2021-12-06 16:32:21,543 [SparkUI-108] WARN [org.spark_project.jetty.servlet.ServletHandler] - Error for /static/bootstrap-tooltip.js
java.lang.NoSuchMethodError: javax.servlet.http.HttpServletRequest.isAsyncSupported()Z
	at org.spark_project.jetty.servlet.DefaultServlet.sendData(DefaultServlet.java:909)
	at org.spark_project.jetty.servlet.DefaultServlet.doGet(DefaultServlet.java:526)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:707)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:820)
	at org.spark_project.jetty.servlet.ServletHolder.handle(ServletHolder.java:848)
	at org.spark_project.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:584)
	at org.spark_project.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
	at org.spark_project.jetty.servlet.ServletHandler.doScope(ServletHandler.java:512)
	at org.spark_project.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
	at org.spark_project.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.spark_project.jetty.server.handler.gzip.GzipHandler.handle(GzipHandler.java:493)
	at org.spark_project.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:213)
	at org.spark_project.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
	at org.spark_project.jetty.server.Server.handle(Server.java:534)
	at org.spark_project.jetty.server.HttpChannel.handle(HttpChannel.java:320)
	at org.spark_project.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
	at org.spark_project.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
	at org.spark_project.jetty.io.FillInterest.fillable(FillInterest.java:108)
	at org.spark_project.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
	at org.spark_project.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
	at org.spark_project.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
	at java.lang.Thread.run(Thread.java:745)
2021-12-06 16:32:21,543 [SparkUI-107] INFO [org.spark_project.jetty.servlet.DefaultServlet] - content=ResourceHttpContent@5f7c6bfb{r=jar:file:/C:/Users/ACER/.m2/repository/org/apache/spark/spark-core_2.11/2.3.0/spark-core_2.11-2.3.0.jar!/org/apache/spark/ui/static/vis.min.js,gz=false}
2021-12-06 16:32:21,544 [SparkUI-107] WARN [org.spark_project.jetty.servlet.ServletHandler] - Error for /static/vis.min.js
java.lang.NoSuchMethodError: javax.servlet.http.HttpServletRequest.isAsyncSupported()Z
	at org.spark_project.jetty.servlet.DefaultServlet.sendData(DefaultServlet.java:909)
	at org.spark_project.jetty.servlet.DefaultServlet.doGet(DefaultServlet.java:526)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:707)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:820)
	at org.spark_project.jetty.servlet.ServletHolder.handle(ServletHolder.java:848)
	at org.spark_project.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:584)
	at org.spark_project.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
	at org.spark_project.jetty.servlet.ServletHandler.doScope(ServletHandler.java:512)
	at org.spark_project.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
	at org.spark_project.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.spark_project.jetty.server.handler.gzip.GzipHandler.handle(GzipHandler.java:493)
	at org.spark_project.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:213)
	at org.spark_project.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
	at org.spark_project.jetty.server.Server.handle(Server.java:534)
	at org.spark_project.jetty.server.HttpChannel.handle(HttpChannel.java:320)
	at org.spark_project.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
	at org.spark_project.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
	at org.spark_project.jetty.io.FillInterest.fillable(FillInterest.java:108)
	at org.spark_project.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
	at org.spark_project.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
	at org.spark_project.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
	at java.lang.Thread.run(Thread.java:745)
2021-12-06 16:32:21,544 [SparkUI-37] INFO [org.spark_project.jetty.servlet.DefaultServlet] - content=ResourceHttpContent@3cde8140{r=jar:file:/C:/Users/ACER/.m2/repository/org/apache/spark/spark-core_2.11/2.3.0/spark-core_2.11-2.3.0.jar!/org/apache/spark/ui/static/table.js,gz=false}
2021-12-06 16:32:21,544 [SparkUI-108] WARN [org.spark_project.jetty.server.HttpChannel] - //qb:4040/static/bootstrap-tooltip.js
java.lang.NoSuchMethodError: javax.servlet.http.HttpServletRequest.isAsyncStarted()Z
	at org.spark_project.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:688)
	at org.spark_project.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
	at org.spark_project.jetty.servlet.ServletHandler.doScope(ServletHandler.java:512)
	at org.spark_project.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
	at org.spark_project.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.spark_project.jetty.server.handler.gzip.GzipHandler.handle(GzipHandler.java:493)
	at org.spark_project.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:213)
	at org.spark_project.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
	at org.spark_project.jetty.server.Server.handle(Server.java:534)
	at org.spark_project.jetty.server.HttpChannel.handle(HttpChannel.java:320)
	at org.spark_project.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
	at org.spark_project.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
	at org.spark_project.jetty.io.FillInterest.fillable(FillInterest.java:108)
	at org.spark_project.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
	at org.spark_project.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
	at org.spark_project.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
	at java.lang.Thread.run(Thread.java:745)
2021-12-06 16:32:21,544 [SparkUI-102] WARN [org.spark_project.jetty.server.HttpChannel] - //qb:4040/static/initialize-tooltips.js
java.lang.NoSuchMethodError: javax.servlet.http.HttpServletRequest.isAsyncStarted()Z
	at org.spark_project.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:688)
	at org.spark_project.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
	at org.spark_project.jetty.servlet.ServletHandler.doScope(ServletHandler.java:512)
	at org.spark_project.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
	at org.spark_project.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.spark_project.jetty.server.handler.gzip.GzipHandler.handle(GzipHandler.java:493)
	at org.spark_project.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:213)
	at org.spark_project.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
	at org.spark_project.jetty.server.Server.handle(Server.java:534)
	at org.spark_project.jetty.server.HttpChannel.handle(HttpChannel.java:320)
	at org.spark_project.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
	at org.spark_project.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
	at org.spark_project.jetty.io.FillInterest.fillable(FillInterest.java:108)
	at org.spark_project.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
	at org.spark_project.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
	at org.spark_project.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
	at java.lang.Thread.run(Thread.java:745)
2021-12-06 16:32:21,544 [SparkUI-37] WARN [org.spark_project.jetty.servlet.ServletHandler] - Error for /static/table.js
java.lang.NoSuchMethodError: javax.servlet.http.HttpServletRequest.isAsyncSupported()Z
	at org.spark_project.jetty.servlet.DefaultServlet.sendData(DefaultServlet.java:909)
	at org.spark_project.jetty.servlet.DefaultServlet.doGet(DefaultServlet.java:526)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:707)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:820)
	at org.spark_project.jetty.servlet.ServletHolder.handle(ServletHolder.java:848)
	at org.spark_project.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:584)
	at org.spark_project.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
	at org.spark_project.jetty.servlet.ServletHandler.doScope(ServletHandler.java:512)
	at org.spark_project.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
	at org.spark_project.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.spark_project.jetty.server.handler.gzip.GzipHandler.handle(GzipHandler.java:493)
	at org.spark_project.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:213)
	at org.spark_project.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
	at org.spark_project.jetty.server.Server.handle(Server.java:534)
	at org.spark_project.jetty.server.HttpChannel.handle(HttpChannel.java:320)
	at org.spark_project.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
	at org.spark_project.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
	at org.spark_project.jetty.io.FillInterest.fillable(FillInterest.java:108)
	at org.spark_project.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
	at org.spark_project.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
	at org.spark_project.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
	at java.lang.Thread.run(Thread.java:745)
2021-12-06 16:32:21,544 [SparkUI-37] WARN [org.spark_project.jetty.server.HttpChannel] - //qb:4040/static/table.js
java.lang.NoSuchMethodError: javax.servlet.http.HttpServletRequest.isAsyncStarted()Z
	at org.spark_project.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:688)
	at org.spark_project.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
	at org.spark_project.jetty.servlet.ServletHandler.doScope(ServletHandler.java:512)
	at org.spark_project.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
	at org.spark_project.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.spark_project.jetty.server.handler.gzip.GzipHandler.handle(GzipHandler.java:493)
	at org.spark_project.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:213)
	at org.spark_project.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
	at org.spark_project.jetty.server.Server.handle(Server.java:534)
	at org.spark_project.jetty.server.HttpChannel.handle(HttpChannel.java:320)
	at org.spark_project.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
	at org.spark_project.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
	at org.spark_project.jetty.io.FillInterest.fillable(FillInterest.java:108)
	at org.spark_project.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
	at org.spark_project.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
	at org.spark_project.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
	at java.lang.Thread.run(Thread.java:745)
2021-12-06 16:32:21,544 [SparkUI-103] INFO [org.spark_project.jetty.servlet.DefaultServlet] - content=ResourceHttpContent@252f21c5{r=jar:file:/C:/Users/ACER/.m2/repository/org/apache/spark/spark-core_2.11/2.3.0/spark-core_2.11-2.3.0.jar!/org/apache/spark/ui/static/additional-metrics.js,gz=false}
2021-12-06 16:32:21,544 [SparkUI-107] WARN [org.spark_project.jetty.server.HttpChannel] - //qb:4040/static/vis.min.js
java.lang.NoSuchMethodError: javax.servlet.http.HttpServletRequest.isAsyncStarted()Z
	at org.spark_project.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:688)
	at org.spark_project.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
	at org.spark_project.jetty.servlet.ServletHandler.doScope(ServletHandler.java:512)
	at org.spark_project.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
	at org.spark_project.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.spark_project.jetty.server.handler.gzip.GzipHandler.handle(GzipHandler.java:493)
	at org.spark_project.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:213)
	at org.spark_project.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
	at org.spark_project.jetty.server.Server.handle(Server.java:534)
	at org.spark_project.jetty.server.HttpChannel.handle(HttpChannel.java:320)
	at org.spark_project.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
	at org.spark_project.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
	at org.spark_project.jetty.io.FillInterest.fillable(FillInterest.java:108)
	at org.spark_project.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
	at org.spark_project.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
	at org.spark_project.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
	at java.lang.Thread.run(Thread.java:745)
2021-12-06 16:32:21,545 [SparkUI-103] WARN [org.spark_project.jetty.servlet.ServletHandler] - Error for /static/additional-metrics.js
java.lang.NoSuchMethodError: javax.servlet.http.HttpServletRequest.isAsyncSupported()Z
	at org.spark_project.jetty.servlet.DefaultServlet.sendData(DefaultServlet.java:909)
	at org.spark_project.jetty.servlet.DefaultServlet.doGet(DefaultServlet.java:526)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:707)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:820)
	at org.spark_project.jetty.servlet.ServletHolder.handle(ServletHolder.java:848)
	at org.spark_project.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:584)
	at org.spark_project.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
	at org.spark_project.jetty.servlet.ServletHandler.doScope(ServletHandler.java:512)
	at org.spark_project.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
	at org.spark_project.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.spark_project.jetty.server.handler.gzip.GzipHandler.handle(GzipHandler.java:493)
	at org.spark_project.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:213)
	at org.spark_project.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
	at org.spark_project.jetty.server.Server.handle(Server.java:534)
	at org.spark_project.jetty.server.HttpChannel.handle(HttpChannel.java:320)
	at org.spark_project.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
	at org.spark_project.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
	at org.spark_project.jetty.io.FillInterest.fillable(FillInterest.java:108)
	at org.spark_project.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
	at org.spark_project.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
	at org.spark_project.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
	at java.lang.Thread.run(Thread.java:745)
2021-12-06 16:32:21,545 [SparkUI-103] WARN [org.spark_project.jetty.server.HttpChannel] - //qb:4040/static/additional-metrics.js
java.lang.NoSuchMethodError: javax.servlet.http.HttpServletRequest.isAsyncStarted()Z
	at org.spark_project.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:688)
	at org.spark_project.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
	at org.spark_project.jetty.servlet.ServletHandler.doScope(ServletHandler.java:512)
	at org.spark_project.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
	at org.spark_project.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.spark_project.jetty.server.handler.gzip.GzipHandler.handle(GzipHandler.java:493)
	at org.spark_project.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:213)
	at org.spark_project.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
	at org.spark_project.jetty.server.Server.handle(Server.java:534)
	at org.spark_project.jetty.server.HttpChannel.handle(HttpChannel.java:320)
	at org.spark_project.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
	at org.spark_project.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
	at org.spark_project.jetty.io.FillInterest.fillable(FillInterest.java:108)
	at org.spark_project.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
	at org.spark_project.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
	at org.spark_project.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
	at java.lang.Thread.run(Thread.java:745)
2021-12-06 16:32:21,546 [SparkUI-104] INFO [org.spark_project.jetty.servlet.DefaultServlet] - content=ResourceHttpContent@258a4ebe{r=jar:file:/C:/Users/ACER/.m2/repository/org/apache/spark/spark-core_2.11/2.3.0/spark-core_2.11-2.3.0.jar!/org/apache/spark/ui/static/timeline-view.js,gz=false}
2021-12-06 16:32:21,546 [SparkUI-104] WARN [org.spark_project.jetty.servlet.ServletHandler] - Error for /static/timeline-view.js
java.lang.NoSuchMethodError: javax.servlet.http.HttpServletRequest.isAsyncSupported()Z
	at org.spark_project.jetty.servlet.DefaultServlet.sendData(DefaultServlet.java:909)
	at org.spark_project.jetty.servlet.DefaultServlet.doGet(DefaultServlet.java:526)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:707)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:820)
	at org.spark_project.jetty.servlet.ServletHolder.handle(ServletHolder.java:848)
	at org.spark_project.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:584)
	at org.spark_project.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
	at org.spark_project.jetty.servlet.ServletHandler.doScope(ServletHandler.java:512)
	at org.spark_project.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
	at org.spark_project.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.spark_project.jetty.server.handler.gzip.GzipHandler.handle(GzipHandler.java:493)
	at org.spark_project.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:213)
	at org.spark_project.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
	at org.spark_project.jetty.server.Server.handle(Server.java:534)
	at org.spark_project.jetty.server.HttpChannel.handle(HttpChannel.java:320)
	at org.spark_project.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
	at org.spark_project.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
	at org.spark_project.jetty.io.FillInterest.fillable(FillInterest.java:108)
	at org.spark_project.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
	at org.spark_project.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
	at org.spark_project.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
	at java.lang.Thread.run(Thread.java:745)
2021-12-06 16:32:21,546 [SparkUI-104] WARN [org.spark_project.jetty.server.HttpChannel] - //qb:4040/static/timeline-view.js
java.lang.NoSuchMethodError: javax.servlet.http.HttpServletRequest.isAsyncStarted()Z
	at org.spark_project.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:688)
	at org.spark_project.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
	at org.spark_project.jetty.servlet.ServletHandler.doScope(ServletHandler.java:512)
	at org.spark_project.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
	at org.spark_project.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.spark_project.jetty.server.handler.gzip.GzipHandler.handle(GzipHandler.java:493)
	at org.spark_project.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:213)
	at org.spark_project.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
	at org.spark_project.jetty.server.Server.handle(Server.java:534)
	at org.spark_project.jetty.server.HttpChannel.handle(HttpChannel.java:320)
	at org.spark_project.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
	at org.spark_project.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
	at org.spark_project.jetty.io.FillInterest.fillable(FillInterest.java:108)
	at org.spark_project.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
	at org.spark_project.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
	at org.spark_project.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
	at java.lang.Thread.run(Thread.java:745)
2021-12-06 16:32:21,548 [SparkUI-43] INFO [org.spark_project.jetty.servlet.DefaultServlet] - content=ResourceHttpContent@7550f0fd{r=jar:file:/C:/Users/ACER/.m2/repository/org/apache/spark/spark-core_2.11/2.3.0/spark-core_2.11-2.3.0.jar!/org/apache/spark/ui/static/log-view.js,gz=false}
2021-12-06 16:32:21,548 [SparkUI-43] WARN [org.spark_project.jetty.servlet.ServletHandler] - Error for /static/log-view.js
java.lang.NoSuchMethodError: javax.servlet.http.HttpServletRequest.isAsyncSupported()Z
	at org.spark_project.jetty.servlet.DefaultServlet.sendData(DefaultServlet.java:909)
	at org.spark_project.jetty.servlet.DefaultServlet.doGet(DefaultServlet.java:526)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:707)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:820)
	at org.spark_project.jetty.servlet.ServletHolder.handle(ServletHolder.java:848)
	at org.spark_project.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:584)
	at org.spark_project.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
	at org.spark_project.jetty.servlet.ServletHandler.doScope(ServletHandler.java:512)
	at org.spark_project.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
	at org.spark_project.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.spark_project.jetty.server.handler.gzip.GzipHandler.handle(GzipHandler.java:493)
	at org.spark_project.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:213)
	at org.spark_project.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
	at org.spark_project.jetty.server.Server.handle(Server.java:534)
	at org.spark_project.jetty.server.HttpChannel.handle(HttpChannel.java:320)
	at org.spark_project.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
	at org.spark_project.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
	at org.spark_project.jetty.io.FillInterest.fillable(FillInterest.java:108)
	at org.spark_project.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
	at org.spark_project.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
	at org.spark_project.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
	at java.lang.Thread.run(Thread.java:745)
2021-12-06 16:32:21,548 [SparkUI-43] WARN [org.spark_project.jetty.server.HttpChannel] - //qb:4040/static/log-view.js
java.lang.NoSuchMethodError: javax.servlet.http.HttpServletRequest.isAsyncStarted()Z
	at org.spark_project.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:688)
	at org.spark_project.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
	at org.spark_project.jetty.servlet.ServletHandler.doScope(ServletHandler.java:512)
	at org.spark_project.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
	at org.spark_project.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.spark_project.jetty.server.handler.gzip.GzipHandler.handle(GzipHandler.java:493)
	at org.spark_project.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:213)
	at org.spark_project.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
	at org.spark_project.jetty.server.Server.handle(Server.java:534)
	at org.spark_project.jetty.server.HttpChannel.handle(HttpChannel.java:320)
	at org.spark_project.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
	at org.spark_project.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
	at org.spark_project.jetty.io.FillInterest.fillable(FillInterest.java:108)
	at org.spark_project.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
	at org.spark_project.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
	at org.spark_project.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
	at java.lang.Thread.run(Thread.java:745)
2021-12-06 16:32:21,562 [SparkUI-105] INFO [org.spark_project.jetty.servlet.DefaultServlet] - content=ResourceHttpContent@235c8be1{r=jar:file:/C:/Users/ACER/.m2/repository/org/apache/spark/spark-core_2.11/2.3.0/spark-core_2.11-2.3.0.jar!/org/apache/spark/ui/static/webui.js,gz=false}
2021-12-06 16:32:21,562 [SparkUI-107] INFO [org.spark_project.jetty.servlet.DefaultServlet] - content=ResourceHttpContent@347704b8{r=jar:file:/C:/Users/ACER/.m2/repository/org/apache/spark/spark-core_2.11/2.3.0/spark-core_2.11-2.3.0.jar!/org/apache/spark/ui/static/spark-dag-viz.css,gz=false}
2021-12-06 16:32:21,562 [SparkUI-103] INFO [org.spark_project.jetty.servlet.DefaultServlet] - content=ResourceHttpContent@62a4c8d7{r=jar:file:/C:/Users/ACER/.m2/repository/org/apache/spark/spark-core_2.11/2.3.0/spark-core_2.11-2.3.0.jar!/org/apache/spark/ui/static/dagre-d3.min.js,gz=false}
2021-12-06 16:32:21,562 [SparkUI-105] WARN [org.spark_project.jetty.servlet.ServletHandler] - Error for /static/webui.js
java.lang.NoSuchMethodError: javax.servlet.http.HttpServletRequest.isAsyncSupported()Z
	at org.spark_project.jetty.servlet.DefaultServlet.sendData(DefaultServlet.java:909)
	at org.spark_project.jetty.servlet.DefaultServlet.doGet(DefaultServlet.java:526)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:707)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:820)
	at org.spark_project.jetty.servlet.ServletHolder.handle(ServletHolder.java:848)
	at org.spark_project.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:584)
	at org.spark_project.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
	at org.spark_project.jetty.servlet.ServletHandler.doScope(ServletHandler.java:512)
	at org.spark_project.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
	at org.spark_project.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.spark_project.jetty.server.handler.gzip.GzipHandler.handle(GzipHandler.java:493)
	at org.spark_project.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:213)
	at org.spark_project.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
	at org.spark_project.jetty.server.Server.handle(Server.java:534)
	at org.spark_project.jetty.server.HttpChannel.handle(HttpChannel.java:320)
	at org.spark_project.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
	at org.spark_project.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
	at org.spark_project.jetty.io.FillInterest.fillable(FillInterest.java:108)
	at org.spark_project.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
	at org.spark_project.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
	at org.spark_project.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
	at java.lang.Thread.run(Thread.java:745)
2021-12-06 16:32:21,562 [SparkUI-103] WARN [org.spark_project.jetty.servlet.ServletHandler] - Error for /static/dagre-d3.min.js
java.lang.NoSuchMethodError: javax.servlet.http.HttpServletRequest.isAsyncSupported()Z
	at org.spark_project.jetty.servlet.DefaultServlet.sendData(DefaultServlet.java:909)
	at org.spark_project.jetty.servlet.DefaultServlet.doGet(DefaultServlet.java:526)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:707)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:820)
	at org.spark_project.jetty.servlet.ServletHolder.handle(ServletHolder.java:848)
	at org.spark_project.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:584)
	at org.spark_project.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
	at org.spark_project.jetty.servlet.ServletHandler.doScope(ServletHandler.java:512)
	at org.spark_project.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
	at org.spark_project.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.spark_project.jetty.server.handler.gzip.GzipHandler.handle(GzipHandler.java:493)
	at org.spark_project.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:213)
	at org.spark_project.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
	at org.spark_project.jetty.server.Server.handle(Server.java:534)
	at org.spark_project.jetty.server.HttpChannel.handle(HttpChannel.java:320)
	at org.spark_project.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
	at org.spark_project.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
	at org.spark_project.jetty.io.FillInterest.fillable(FillInterest.java:108)
	at org.spark_project.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
	at org.spark_project.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
	at org.spark_project.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
	at java.lang.Thread.run(Thread.java:745)
2021-12-06 16:32:21,562 [SparkUI-107] WARN [org.spark_project.jetty.servlet.ServletHandler] - Error for /static/spark-dag-viz.css
java.lang.NoSuchMethodError: javax.servlet.http.HttpServletRequest.isAsyncSupported()Z
	at org.spark_project.jetty.servlet.DefaultServlet.sendData(DefaultServlet.java:909)
	at org.spark_project.jetty.servlet.DefaultServlet.doGet(DefaultServlet.java:526)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:707)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:820)
	at org.spark_project.jetty.servlet.ServletHolder.handle(ServletHolder.java:848)
	at org.spark_project.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:584)
	at org.spark_project.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
	at org.spark_project.jetty.servlet.ServletHandler.doScope(ServletHandler.java:512)
	at org.spark_project.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
	at org.spark_project.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.spark_project.jetty.server.handler.gzip.GzipHandler.handle(GzipHandler.java:493)
	at org.spark_project.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:213)
	at org.spark_project.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
	at org.spark_project.jetty.server.Server.handle(Server.java:534)
	at org.spark_project.jetty.server.HttpChannel.handle(HttpChannel.java:320)
	at org.spark_project.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
	at org.spark_project.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
	at org.spark_project.jetty.io.FillInterest.fillable(FillInterest.java:108)
	at org.spark_project.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
	at org.spark_project.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
	at org.spark_project.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
	at java.lang.Thread.run(Thread.java:745)
2021-12-06 16:32:21,563 [SparkUI-39] INFO [org.spark_project.jetty.servlet.DefaultServlet] - content=ResourceHttpContent@6f48d195{r=jar:file:/C:/Users/ACER/.m2/repository/org/apache/spark/spark-core_2.11/2.3.0/spark-core_2.11-2.3.0.jar!/org/apache/spark/ui/static/d3.min.js,gz=false}
2021-12-06 16:32:21,563 [SparkUI-107] WARN [org.spark_project.jetty.server.HttpChannel] - //qb:4040/static/spark-dag-viz.css
java.lang.NoSuchMethodError: javax.servlet.http.HttpServletRequest.isAsyncStarted()Z
	at org.spark_project.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:688)
	at org.spark_project.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
	at org.spark_project.jetty.servlet.ServletHandler.doScope(ServletHandler.java:512)
	at org.spark_project.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
	at org.spark_project.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.spark_project.jetty.server.handler.gzip.GzipHandler.handle(GzipHandler.java:493)
	at org.spark_project.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:213)
	at org.spark_project.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
	at org.spark_project.jetty.server.Server.handle(Server.java:534)
	at org.spark_project.jetty.server.HttpChannel.handle(HttpChannel.java:320)
	at org.spark_project.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
	at org.spark_project.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
	at org.spark_project.jetty.io.FillInterest.fillable(FillInterest.java:108)
	at org.spark_project.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
	at org.spark_project.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
	at org.spark_project.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
	at java.lang.Thread.run(Thread.java:745)
2021-12-06 16:32:21,563 [SparkUI-103] WARN [org.spark_project.jetty.server.HttpChannel] - //qb:4040/static/dagre-d3.min.js
java.lang.NoSuchMethodError: javax.servlet.http.HttpServletRequest.isAsyncStarted()Z
	at org.spark_project.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:688)
	at org.spark_project.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
	at org.spark_project.jetty.servlet.ServletHandler.doScope(ServletHandler.java:512)
	at org.spark_project.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
	at org.spark_project.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.spark_project.jetty.server.handler.gzip.GzipHandler.handle(GzipHandler.java:493)
	at org.spark_project.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:213)
	at org.spark_project.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
	at org.spark_project.jetty.server.Server.handle(Server.java:534)
	at org.spark_project.jetty.server.HttpChannel.handle(HttpChannel.java:320)
	at org.spark_project.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
	at org.spark_project.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
	at org.spark_project.jetty.io.FillInterest.fillable(FillInterest.java:108)
	at org.spark_project.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
	at org.spark_project.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
	at org.spark_project.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
	at java.lang.Thread.run(Thread.java:745)
2021-12-06 16:32:21,563 [SparkUI-105] WARN [org.spark_project.jetty.server.HttpChannel] - //qb:4040/static/webui.js
java.lang.NoSuchMethodError: javax.servlet.http.HttpServletRequest.isAsyncStarted()Z
	at org.spark_project.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:688)
	at org.spark_project.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
	at org.spark_project.jetty.servlet.ServletHandler.doScope(ServletHandler.java:512)
	at org.spark_project.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
	at org.spark_project.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.spark_project.jetty.server.handler.gzip.GzipHandler.handle(GzipHandler.java:493)
	at org.spark_project.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:213)
	at org.spark_project.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
	at org.spark_project.jetty.server.Server.handle(Server.java:534)
	at org.spark_project.jetty.server.HttpChannel.handle(HttpChannel.java:320)
	at org.spark_project.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
	at org.spark_project.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
	at org.spark_project.jetty.io.FillInterest.fillable(FillInterest.java:108)
	at org.spark_project.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
	at org.spark_project.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
	at org.spark_project.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
	at java.lang.Thread.run(Thread.java:745)
2021-12-06 16:32:21,563 [SparkUI-39] WARN [org.spark_project.jetty.servlet.ServletHandler] - Error for /static/d3.min.js
java.lang.NoSuchMethodError: javax.servlet.http.HttpServletRequest.isAsyncSupported()Z
	at org.spark_project.jetty.servlet.DefaultServlet.sendData(DefaultServlet.java:909)
	at org.spark_project.jetty.servlet.DefaultServlet.doGet(DefaultServlet.java:526)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:707)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:820)
	at org.spark_project.jetty.servlet.ServletHolder.handle(ServletHolder.java:848)
	at org.spark_project.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:584)
	at org.spark_project.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
	at org.spark_project.jetty.servlet.ServletHandler.doScope(ServletHandler.java:512)
	at org.spark_project.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
	at org.spark_project.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.spark_project.jetty.server.handler.gzip.GzipHandler.handle(GzipHandler.java:493)
	at org.spark_project.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:213)
	at org.spark_project.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
	at org.spark_project.jetty.server.Server.handle(Server.java:534)
	at org.spark_project.jetty.server.HttpChannel.handle(HttpChannel.java:320)
	at org.spark_project.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
	at org.spark_project.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
	at org.spark_project.jetty.io.FillInterest.fillable(FillInterest.java:108)
	at org.spark_project.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
	at org.spark_project.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
	at org.spark_project.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
	at java.lang.Thread.run(Thread.java:745)
2021-12-06 16:32:21,563 [SparkUI-39] WARN [org.spark_project.jetty.server.HttpChannel] - //qb:4040/static/d3.min.js
java.lang.NoSuchMethodError: javax.servlet.http.HttpServletRequest.isAsyncStarted()Z
	at org.spark_project.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:688)
	at org.spark_project.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
	at org.spark_project.jetty.servlet.ServletHandler.doScope(ServletHandler.java:512)
	at org.spark_project.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
	at org.spark_project.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.spark_project.jetty.server.handler.gzip.GzipHandler.handle(GzipHandler.java:493)
	at org.spark_project.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:213)
	at org.spark_project.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
	at org.spark_project.jetty.server.Server.handle(Server.java:534)
	at org.spark_project.jetty.server.HttpChannel.handle(HttpChannel.java:320)
	at org.spark_project.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
	at org.spark_project.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
	at org.spark_project.jetty.io.FillInterest.fillable(FillInterest.java:108)
	at org.spark_project.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
	at org.spark_project.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
	at org.spark_project.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
	at java.lang.Thread.run(Thread.java:745)
2021-12-06 16:32:21,564 [SparkUI-38] INFO [org.spark_project.jetty.servlet.DefaultServlet] - content=ResourceHttpContent@37e826e6{r=jar:file:/C:/Users/ACER/.m2/repository/org/apache/spark/spark-core_2.11/2.3.0/spark-core_2.11-2.3.0.jar!/org/apache/spark/ui/static/graphlib-dot.min.js,gz=false}
2021-12-06 16:32:21,564 [SparkUI-38] WARN [org.spark_project.jetty.servlet.ServletHandler] - Error for /static/graphlib-dot.min.js
java.lang.NoSuchMethodError: javax.servlet.http.HttpServletRequest.isAsyncSupported()Z
	at org.spark_project.jetty.servlet.DefaultServlet.sendData(DefaultServlet.java:909)
	at org.spark_project.jetty.servlet.DefaultServlet.doGet(DefaultServlet.java:526)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:707)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:820)
	at org.spark_project.jetty.servlet.ServletHolder.handle(ServletHolder.java:848)
	at org.spark_project.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:584)
	at org.spark_project.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
	at org.spark_project.jetty.servlet.ServletHandler.doScope(ServletHandler.java:512)
	at org.spark_project.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
	at org.spark_project.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.spark_project.jetty.server.handler.gzip.GzipHandler.handle(GzipHandler.java:493)
	at org.spark_project.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:213)
	at org.spark_project.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
	at org.spark_project.jetty.server.Server.handle(Server.java:534)
	at org.spark_project.jetty.server.HttpChannel.handle(HttpChannel.java:320)
	at org.spark_project.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
	at org.spark_project.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
	at org.spark_project.jetty.io.FillInterest.fillable(FillInterest.java:108)
	at org.spark_project.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
	at org.spark_project.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
	at org.spark_project.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
	at java.lang.Thread.run(Thread.java:745)
2021-12-06 16:32:21,564 [SparkUI-38] WARN [org.spark_project.jetty.server.HttpChannel] - //qb:4040/static/graphlib-dot.min.js
java.lang.NoSuchMethodError: javax.servlet.http.HttpServletRequest.isAsyncStarted()Z
	at org.spark_project.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:688)
	at org.spark_project.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
	at org.spark_project.jetty.servlet.ServletHandler.doScope(ServletHandler.java:512)
	at org.spark_project.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
	at org.spark_project.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.spark_project.jetty.server.handler.gzip.GzipHandler.handle(GzipHandler.java:493)
	at org.spark_project.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:213)
	at org.spark_project.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
	at org.spark_project.jetty.server.Server.handle(Server.java:534)
	at org.spark_project.jetty.server.HttpChannel.handle(HttpChannel.java:320)
	at org.spark_project.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
	at org.spark_project.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
	at org.spark_project.jetty.io.FillInterest.fillable(FillInterest.java:108)
	at org.spark_project.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
	at org.spark_project.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
	at org.spark_project.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
	at java.lang.Thread.run(Thread.java:745)
2021-12-06 16:32:21,565 [SparkUI-106] INFO [org.spark_project.jetty.servlet.DefaultServlet] - content=ResourceHttpContent@4e5e963c{r=jar:file:/C:/Users/ACER/.m2/repository/org/apache/spark/spark-core_2.11/2.3.0/spark-core_2.11-2.3.0.jar!/org/apache/spark/ui/static/spark-dag-viz.js,gz=false}
2021-12-06 16:32:21,565 [SparkUI-106] WARN [org.spark_project.jetty.servlet.ServletHandler] - Error for /static/spark-dag-viz.js
java.lang.NoSuchMethodError: javax.servlet.http.HttpServletRequest.isAsyncSupported()Z
	at org.spark_project.jetty.servlet.DefaultServlet.sendData(DefaultServlet.java:909)
	at org.spark_project.jetty.servlet.DefaultServlet.doGet(DefaultServlet.java:526)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:707)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:820)
	at org.spark_project.jetty.servlet.ServletHolder.handle(ServletHolder.java:848)
	at org.spark_project.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:584)
	at org.spark_project.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
	at org.spark_project.jetty.servlet.ServletHandler.doScope(ServletHandler.java:512)
	at org.spark_project.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
	at org.spark_project.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.spark_project.jetty.server.handler.gzip.GzipHandler.handle(GzipHandler.java:493)
	at org.spark_project.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:213)
	at org.spark_project.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
	at org.spark_project.jetty.server.Server.handle(Server.java:534)
	at org.spark_project.jetty.server.HttpChannel.handle(HttpChannel.java:320)
	at org.spark_project.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
	at org.spark_project.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
	at org.spark_project.jetty.io.FillInterest.fillable(FillInterest.java:108)
	at org.spark_project.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
	at org.spark_project.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
	at org.spark_project.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
	at java.lang.Thread.run(Thread.java:745)
2021-12-06 16:32:21,565 [SparkUI-106] WARN [org.spark_project.jetty.server.HttpChannel] - //qb:4040/static/spark-dag-viz.js
java.lang.NoSuchMethodError: javax.servlet.http.HttpServletRequest.isAsyncStarted()Z
	at org.spark_project.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:688)
	at org.spark_project.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
	at org.spark_project.jetty.servlet.ServletHandler.doScope(ServletHandler.java:512)
	at org.spark_project.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
	at org.spark_project.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.spark_project.jetty.server.handler.gzip.GzipHandler.handle(GzipHandler.java:493)
	at org.spark_project.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:213)
	at org.spark_project.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
	at org.spark_project.jetty.server.Server.handle(Server.java:534)
	at org.spark_project.jetty.server.HttpChannel.handle(HttpChannel.java:320)
	at org.spark_project.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
	at org.spark_project.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
	at org.spark_project.jetty.io.FillInterest.fillable(FillInterest.java:108)
	at org.spark_project.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
	at org.spark_project.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
	at org.spark_project.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
	at java.lang.Thread.run(Thread.java:745)
2021-12-06 16:32:21,586 [SparkUI-102] INFO [org.spark_project.jetty.servlet.DefaultServlet] - content=ResourceHttpContent@815917e{r=jar:file:/C:/Users/ACER/.m2/repository/org/apache/spark/spark-core_2.11/2.3.0/spark-core_2.11-2.3.0.jar!/org/apache/spark/ui/static/spark-logo-77x50px-hd.png,gz=false}
2021-12-06 16:32:21,586 [SparkUI-102] WARN [org.spark_project.jetty.servlet.ServletHandler] - Error for /static/spark-logo-77x50px-hd.png
java.lang.NoSuchMethodError: javax.servlet.http.HttpServletRequest.isAsyncSupported()Z
	at org.spark_project.jetty.servlet.DefaultServlet.sendData(DefaultServlet.java:909)
	at org.spark_project.jetty.servlet.DefaultServlet.doGet(DefaultServlet.java:526)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:707)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:820)
	at org.spark_project.jetty.servlet.ServletHolder.handle(ServletHolder.java:848)
	at org.spark_project.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:584)
	at org.spark_project.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
	at org.spark_project.jetty.servlet.ServletHandler.doScope(ServletHandler.java:512)
	at org.spark_project.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
	at org.spark_project.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.spark_project.jetty.server.handler.gzip.GzipHandler.handle(GzipHandler.java:448)
	at org.spark_project.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:213)
	at org.spark_project.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
	at org.spark_project.jetty.server.Server.handle(Server.java:534)
	at org.spark_project.jetty.server.HttpChannel.handle(HttpChannel.java:320)
	at org.spark_project.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
	at org.spark_project.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
	at org.spark_project.jetty.io.FillInterest.fillable(FillInterest.java:108)
	at org.spark_project.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
	at org.spark_project.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
	at org.spark_project.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
	at java.lang.Thread.run(Thread.java:745)
2021-12-06 16:32:21,587 [SparkUI-102] WARN [org.spark_project.jetty.server.HttpChannel] - //qb:4040/static/spark-logo-77x50px-hd.png
java.lang.NoSuchMethodError: javax.servlet.http.HttpServletRequest.isAsyncStarted()Z
	at org.spark_project.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:688)
	at org.spark_project.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
	at org.spark_project.jetty.servlet.ServletHandler.doScope(ServletHandler.java:512)
	at org.spark_project.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
	at org.spark_project.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.spark_project.jetty.server.handler.gzip.GzipHandler.handle(GzipHandler.java:448)
	at org.spark_project.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:213)
	at org.spark_project.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
	at org.spark_project.jetty.server.Server.handle(Server.java:534)
	at org.spark_project.jetty.server.HttpChannel.handle(HttpChannel.java:320)
	at org.spark_project.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
	at org.spark_project.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
	at org.spark_project.jetty.io.FillInterest.fillable(FillInterest.java:108)
	at org.spark_project.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
	at org.spark_project.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
	at org.spark_project.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
	at java.lang.Thread.run(Thread.java:745)
2021-12-06 17:11:36,886 [SparkUI-43] INFO [org.spark_project.jetty.servlet.DefaultServlet] - content=ResourceHttpContent@5b5e4311{r=jar:file:/C:/Users/ACER/.m2/repository/org/apache/spark/spark-core_2.11/2.3.0/spark-core_2.11-2.3.0.jar!/org/apache/spark/ui/static/bootstrap.min.css,gz=false}
2021-12-06 17:11:36,886 [SparkUI-43] WARN [org.spark_project.jetty.servlet.ServletHandler] - Error for /static/bootstrap.min.css
java.lang.NoSuchMethodError: javax.servlet.http.HttpServletRequest.isAsyncSupported()Z
	at org.spark_project.jetty.servlet.DefaultServlet.sendData(DefaultServlet.java:909)
	at org.spark_project.jetty.servlet.DefaultServlet.doGet(DefaultServlet.java:526)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:707)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:820)
	at org.spark_project.jetty.servlet.ServletHolder.handle(ServletHolder.java:848)
	at org.spark_project.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:584)
	at org.spark_project.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
	at org.spark_project.jetty.servlet.ServletHandler.doScope(ServletHandler.java:512)
	at org.spark_project.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
	at org.spark_project.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.spark_project.jetty.server.handler.gzip.GzipHandler.handle(GzipHandler.java:493)
	at org.spark_project.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:213)
	at org.spark_project.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
	at org.spark_project.jetty.server.Server.handle(Server.java:534)
	at org.spark_project.jetty.server.HttpChannel.handle(HttpChannel.java:320)
	at org.spark_project.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
	at org.spark_project.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
	at org.spark_project.jetty.io.FillInterest.fillable(FillInterest.java:108)
	at org.spark_project.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
	at org.spark_project.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
	at org.spark_project.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
	at java.lang.Thread.run(Thread.java:745)
2021-12-06 17:11:36,886 [SparkUI-43] WARN [org.spark_project.jetty.server.HttpChannel] - //qb:4040/static/bootstrap.min.css
java.lang.NoSuchMethodError: javax.servlet.http.HttpServletRequest.isAsyncStarted()Z
	at org.spark_project.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:688)
	at org.spark_project.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
	at org.spark_project.jetty.servlet.ServletHandler.doScope(ServletHandler.java:512)
	at org.spark_project.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
	at org.spark_project.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.spark_project.jetty.server.handler.gzip.GzipHandler.handle(GzipHandler.java:493)
	at org.spark_project.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:213)
	at org.spark_project.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
	at org.spark_project.jetty.server.Server.handle(Server.java:534)
	at org.spark_project.jetty.server.HttpChannel.handle(HttpChannel.java:320)
	at org.spark_project.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
	at org.spark_project.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
	at org.spark_project.jetty.io.FillInterest.fillable(FillInterest.java:108)
	at org.spark_project.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
	at org.spark_project.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
	at org.spark_project.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
	at java.lang.Thread.run(Thread.java:745)
2021-12-06 17:11:36,887 [SparkUI-104] INFO [org.spark_project.jetty.servlet.DefaultServlet] - content=ResourceHttpContent@3d016932{r=jar:file:/C:/Users/ACER/.m2/repository/org/apache/spark/spark-core_2.11/2.3.0/spark-core_2.11-2.3.0.jar!/org/apache/spark/ui/static/webui.css,gz=false}
2021-12-06 17:11:36,887 [SparkUI-104] WARN [org.spark_project.jetty.servlet.ServletHandler] - Error for /static/webui.css
java.lang.NoSuchMethodError: javax.servlet.http.HttpServletRequest.isAsyncSupported()Z
	at org.spark_project.jetty.servlet.DefaultServlet.sendData(DefaultServlet.java:909)
	at org.spark_project.jetty.servlet.DefaultServlet.doGet(DefaultServlet.java:526)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:707)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:820)
	at org.spark_project.jetty.servlet.ServletHolder.handle(ServletHolder.java:848)
	at org.spark_project.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:584)
	at org.spark_project.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
	at org.spark_project.jetty.servlet.ServletHandler.doScope(ServletHandler.java:512)
	at org.spark_project.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
	at org.spark_project.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.spark_project.jetty.server.handler.gzip.GzipHandler.handle(GzipHandler.java:493)
	at org.spark_project.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:213)
	at org.spark_project.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
	at org.spark_project.jetty.server.Server.handle(Server.java:534)
	at org.spark_project.jetty.server.HttpChannel.handle(HttpChannel.java:320)
	at org.spark_project.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
	at org.spark_project.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
	at org.spark_project.jetty.io.FillInterest.fillable(FillInterest.java:108)
	at org.spark_project.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
	at org.spark_project.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
	at org.spark_project.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
	at java.lang.Thread.run(Thread.java:745)
2021-12-06 17:11:36,888 [SparkUI-104] WARN [org.spark_project.jetty.server.HttpChannel] - //qb:4040/static/webui.css
java.lang.NoSuchMethodError: javax.servlet.http.HttpServletRequest.isAsyncStarted()Z
	at org.spark_project.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:688)
	at org.spark_project.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
	at org.spark_project.jetty.servlet.ServletHandler.doScope(ServletHandler.java:512)
	at org.spark_project.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
	at org.spark_project.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.spark_project.jetty.server.handler.gzip.GzipHandler.handle(GzipHandler.java:493)
	at org.spark_project.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:213)
	at org.spark_project.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
	at org.spark_project.jetty.server.Server.handle(Server.java:534)
	at org.spark_project.jetty.server.HttpChannel.handle(HttpChannel.java:320)
	at org.spark_project.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
	at org.spark_project.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
	at org.spark_project.jetty.io.FillInterest.fillable(FillInterest.java:108)
	at org.spark_project.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
	at org.spark_project.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
	at org.spark_project.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
	at java.lang.Thread.run(Thread.java:745)
2021-12-06 17:11:36,888 [SparkUI-39] INFO [org.spark_project.jetty.servlet.DefaultServlet] - content=ResourceHttpContent@39190107{r=jar:file:/C:/Users/ACER/.m2/repository/org/apache/spark/spark-core_2.11/2.3.0/spark-core_2.11-2.3.0.jar!/org/apache/spark/ui/static/timeline-view.css,gz=false}
2021-12-06 17:11:36,888 [SparkUI-39] WARN [org.spark_project.jetty.servlet.ServletHandler] - Error for /static/timeline-view.css
java.lang.NoSuchMethodError: javax.servlet.http.HttpServletRequest.isAsyncSupported()Z
	at org.spark_project.jetty.servlet.DefaultServlet.sendData(DefaultServlet.java:909)
	at org.spark_project.jetty.servlet.DefaultServlet.doGet(DefaultServlet.java:526)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:707)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:820)
	at org.spark_project.jetty.servlet.ServletHolder.handle(ServletHolder.java:848)
	at org.spark_project.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:584)
	at org.spark_project.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
	at org.spark_project.jetty.servlet.ServletHandler.doScope(ServletHandler.java:512)
	at org.spark_project.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
	at org.spark_project.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.spark_project.jetty.server.handler.gzip.GzipHandler.handle(GzipHandler.java:493)
	at org.spark_project.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:213)
	at org.spark_project.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
	at org.spark_project.jetty.server.Server.handle(Server.java:534)
	at org.spark_project.jetty.server.HttpChannel.handle(HttpChannel.java:320)
	at org.spark_project.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
	at org.spark_project.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
	at org.spark_project.jetty.io.FillInterest.fillable(FillInterest.java:108)
	at org.spark_project.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
	at org.spark_project.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
	at org.spark_project.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
	at java.lang.Thread.run(Thread.java:745)
2021-12-06 17:11:36,888 [SparkUI-39] WARN [org.spark_project.jetty.server.HttpChannel] - //qb:4040/static/timeline-view.css
java.lang.NoSuchMethodError: javax.servlet.http.HttpServletRequest.isAsyncStarted()Z
	at org.spark_project.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:688)
	at org.spark_project.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
	at org.spark_project.jetty.servlet.ServletHandler.doScope(ServletHandler.java:512)
	at org.spark_project.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
	at org.spark_project.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.spark_project.jetty.server.handler.gzip.GzipHandler.handle(GzipHandler.java:493)
	at org.spark_project.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:213)
	at org.spark_project.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
	at org.spark_project.jetty.server.Server.handle(Server.java:534)
	at org.spark_project.jetty.server.HttpChannel.handle(HttpChannel.java:320)
	at org.spark_project.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
	at org.spark_project.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
	at org.spark_project.jetty.io.FillInterest.fillable(FillInterest.java:108)
	at org.spark_project.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
	at org.spark_project.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
	at org.spark_project.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
	at java.lang.Thread.run(Thread.java:745)
2021-12-06 17:11:36,889 [SparkUI-107] INFO [org.spark_project.jetty.servlet.DefaultServlet] - content=ResourceHttpContent@3aa34fe2{r=jar:file:/C:/Users/ACER/.m2/repository/org/apache/spark/spark-core_2.11/2.3.0/spark-core_2.11-2.3.0.jar!/org/apache/spark/ui/static/vis.min.css,gz=false}
2021-12-06 17:11:36,889 [SparkUI-107] WARN [org.spark_project.jetty.servlet.ServletHandler] - Error for /static/vis.min.css
java.lang.NoSuchMethodError: javax.servlet.http.HttpServletRequest.isAsyncSupported()Z
	at org.spark_project.jetty.servlet.DefaultServlet.sendData(DefaultServlet.java:909)
	at org.spark_project.jetty.servlet.DefaultServlet.doGet(DefaultServlet.java:526)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:707)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:820)
	at org.spark_project.jetty.servlet.ServletHolder.handle(ServletHolder.java:848)
	at org.spark_project.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:584)
	at org.spark_project.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
	at org.spark_project.jetty.servlet.ServletHandler.doScope(ServletHandler.java:512)
	at org.spark_project.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
	at org.spark_project.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.spark_project.jetty.server.handler.gzip.GzipHandler.handle(GzipHandler.java:493)
	at org.spark_project.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:213)
	at org.spark_project.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
	at org.spark_project.jetty.server.Server.handle(Server.java:534)
	at org.spark_project.jetty.server.HttpChannel.handle(HttpChannel.java:320)
	at org.spark_project.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
	at org.spark_project.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
	at org.spark_project.jetty.io.FillInterest.fillable(FillInterest.java:108)
	at org.spark_project.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
	at org.spark_project.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
	at org.spark_project.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
	at java.lang.Thread.run(Thread.java:745)
2021-12-06 17:11:36,889 [SparkUI-107] WARN [org.spark_project.jetty.server.HttpChannel] - //qb:4040/static/vis.min.css
java.lang.NoSuchMethodError: javax.servlet.http.HttpServletRequest.isAsyncStarted()Z
	at org.spark_project.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:688)
	at org.spark_project.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
	at org.spark_project.jetty.servlet.ServletHandler.doScope(ServletHandler.java:512)
	at org.spark_project.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
	at org.spark_project.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.spark_project.jetty.server.handler.gzip.GzipHandler.handle(GzipHandler.java:493)
	at org.spark_project.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:213)
	at org.spark_project.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
	at org.spark_project.jetty.server.Server.handle(Server.java:534)
	at org.spark_project.jetty.server.HttpChannel.handle(HttpChannel.java:320)
	at org.spark_project.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
	at org.spark_project.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
	at org.spark_project.jetty.io.FillInterest.fillable(FillInterest.java:108)
	at org.spark_project.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
	at org.spark_project.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
	at org.spark_project.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
	at java.lang.Thread.run(Thread.java:745)
2021-12-06 17:11:36,891 [SparkUI-39] INFO [org.spark_project.jetty.servlet.DefaultServlet] - content=ResourceHttpContent@ecc133{r=jar:file:/C:/Users/ACER/.m2/repository/org/apache/spark/spark-core_2.11/2.3.0/spark-core_2.11-2.3.0.jar!/org/apache/spark/ui/static/bootstrap.min.css,gz=false}
2021-12-06 17:11:36,891 [SparkUI-39] WARN [org.spark_project.jetty.servlet.ServletHandler] - Error for /static/bootstrap.min.css
java.lang.NoSuchMethodError: javax.servlet.http.HttpServletRequest.isAsyncSupported()Z
	at org.spark_project.jetty.servlet.DefaultServlet.sendData(DefaultServlet.java:909)
	at org.spark_project.jetty.servlet.DefaultServlet.doGet(DefaultServlet.java:526)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:707)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:820)
	at org.spark_project.jetty.servlet.ServletHolder.handle(ServletHolder.java:848)
	at org.spark_project.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:584)
	at org.spark_project.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
	at org.spark_project.jetty.servlet.ServletHandler.doScope(ServletHandler.java:512)
	at org.spark_project.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
	at org.spark_project.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.spark_project.jetty.server.handler.gzip.GzipHandler.handle(GzipHandler.java:493)
	at org.spark_project.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:213)
	at org.spark_project.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
	at org.spark_project.jetty.server.Server.handle(Server.java:534)
	at org.spark_project.jetty.server.HttpChannel.handle(HttpChannel.java:320)
	at org.spark_project.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
	at org.spark_project.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
	at org.spark_project.jetty.io.FillInterest.fillable(FillInterest.java:108)
	at org.spark_project.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
	at org.spark_project.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
	at org.spark_project.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
	at java.lang.Thread.run(Thread.java:745)
2021-12-06 17:11:36,891 [SparkUI-39] WARN [org.spark_project.jetty.server.HttpChannel] - //qb:4040/static/bootstrap.min.css
java.lang.NoSuchMethodError: javax.servlet.http.HttpServletRequest.isAsyncStarted()Z
	at org.spark_project.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:688)
	at org.spark_project.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
	at org.spark_project.jetty.servlet.ServletHandler.doScope(ServletHandler.java:512)
	at org.spark_project.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
	at org.spark_project.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.spark_project.jetty.server.handler.gzip.GzipHandler.handle(GzipHandler.java:493)
	at org.spark_project.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:213)
	at org.spark_project.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
	at org.spark_project.jetty.server.Server.handle(Server.java:534)
	at org.spark_project.jetty.server.HttpChannel.handle(HttpChannel.java:320)
	at org.spark_project.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
	at org.spark_project.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
	at org.spark_project.jetty.io.FillInterest.fillable(FillInterest.java:108)
	at org.spark_project.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
	at org.spark_project.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
	at org.spark_project.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
	at java.lang.Thread.run(Thread.java:745)
2021-12-06 17:11:36,892 [SparkUI-106] INFO [org.spark_project.jetty.servlet.DefaultServlet] - content=ResourceHttpContent@4f574f62{r=jar:file:/C:/Users/ACER/.m2/repository/org/apache/spark/spark-core_2.11/2.3.0/spark-core_2.11-2.3.0.jar!/org/apache/spark/ui/static/spark-dag-viz.css,gz=false}
2021-12-06 17:11:36,892 [SparkUI-106] WARN [org.spark_project.jetty.servlet.ServletHandler] - Error for /static/spark-dag-viz.css
java.lang.NoSuchMethodError: javax.servlet.http.HttpServletRequest.isAsyncSupported()Z
	at org.spark_project.jetty.servlet.DefaultServlet.sendData(DefaultServlet.java:909)
	at org.spark_project.jetty.servlet.DefaultServlet.doGet(DefaultServlet.java:526)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:707)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:820)
	at org.spark_project.jetty.servlet.ServletHolder.handle(ServletHolder.java:848)
	at org.spark_project.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:584)
	at org.spark_project.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
	at org.spark_project.jetty.servlet.ServletHandler.doScope(ServletHandler.java:512)
	at org.spark_project.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
	at org.spark_project.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.spark_project.jetty.server.handler.gzip.GzipHandler.handle(GzipHandler.java:493)
	at org.spark_project.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:213)
	at org.spark_project.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
	at org.spark_project.jetty.server.Server.handle(Server.java:534)
	at org.spark_project.jetty.server.HttpChannel.handle(HttpChannel.java:320)
	at org.spark_project.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
	at org.spark_project.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
	at org.spark_project.jetty.io.FillInterest.fillable(FillInterest.java:108)
	at org.spark_project.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
	at org.spark_project.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
	at org.spark_project.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
	at java.lang.Thread.run(Thread.java:745)
2021-12-06 17:11:36,892 [SparkUI-106] WARN [org.spark_project.jetty.server.HttpChannel] - //qb:4040/static/spark-dag-viz.css
java.lang.NoSuchMethodError: javax.servlet.http.HttpServletRequest.isAsyncStarted()Z
	at org.spark_project.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:688)
	at org.spark_project.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
	at org.spark_project.jetty.servlet.ServletHandler.doScope(ServletHandler.java:512)
	at org.spark_project.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
	at org.spark_project.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.spark_project.jetty.server.handler.gzip.GzipHandler.handle(GzipHandler.java:493)
	at org.spark_project.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:213)
	at org.spark_project.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
	at org.spark_project.jetty.server.Server.handle(Server.java:534)
	at org.spark_project.jetty.server.HttpChannel.handle(HttpChannel.java:320)
	at org.spark_project.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
	at org.spark_project.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
	at org.spark_project.jetty.io.FillInterest.fillable(FillInterest.java:108)
	at org.spark_project.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
	at org.spark_project.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
	at org.spark_project.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
	at java.lang.Thread.run(Thread.java:745)
2021-12-06 17:11:36,892 [SparkUI-38] INFO [org.spark_project.jetty.servlet.DefaultServlet] - content=ResourceHttpContent@58fd077b{r=jar:file:/C:/Users/ACER/.m2/repository/org/apache/spark/spark-core_2.11/2.3.0/spark-core_2.11-2.3.0.jar!/org/apache/spark/ui/static/vis.min.css,gz=false}
2021-12-06 17:11:36,893 [SparkUI-38] WARN [org.spark_project.jetty.servlet.ServletHandler] - Error for /static/vis.min.css
java.lang.NoSuchMethodError: javax.servlet.http.HttpServletRequest.isAsyncSupported()Z
	at org.spark_project.jetty.servlet.DefaultServlet.sendData(DefaultServlet.java:909)
	at org.spark_project.jetty.servlet.DefaultServlet.doGet(DefaultServlet.java:526)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:707)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:820)
	at org.spark_project.jetty.servlet.ServletHolder.handle(ServletHolder.java:848)
	at org.spark_project.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:584)
	at org.spark_project.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
	at org.spark_project.jetty.servlet.ServletHandler.doScope(ServletHandler.java:512)
	at org.spark_project.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
	at org.spark_project.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.spark_project.jetty.server.handler.gzip.GzipHandler.handle(GzipHandler.java:493)
	at org.spark_project.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:213)
	at org.spark_project.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
	at org.spark_project.jetty.server.Server.handle(Server.java:534)
	at org.spark_project.jetty.server.HttpChannel.handle(HttpChannel.java:320)
	at org.spark_project.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
	at org.spark_project.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
	at org.spark_project.jetty.io.FillInterest.fillable(FillInterest.java:108)
	at org.spark_project.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
	at org.spark_project.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
	at org.spark_project.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
	at java.lang.Thread.run(Thread.java:745)
2021-12-06 17:11:36,893 [SparkUI-38] WARN [org.spark_project.jetty.server.HttpChannel] - //qb:4040/static/vis.min.css
java.lang.NoSuchMethodError: javax.servlet.http.HttpServletRequest.isAsyncStarted()Z
	at org.spark_project.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:688)
	at org.spark_project.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
	at org.spark_project.jetty.servlet.ServletHandler.doScope(ServletHandler.java:512)
	at org.spark_project.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
	at org.spark_project.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.spark_project.jetty.server.handler.gzip.GzipHandler.handle(GzipHandler.java:493)
	at org.spark_project.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:213)
	at org.spark_project.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
	at org.spark_project.jetty.server.Server.handle(Server.java:534)
	at org.spark_project.jetty.server.HttpChannel.handle(HttpChannel.java:320)
	at org.spark_project.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
	at org.spark_project.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
	at org.spark_project.jetty.io.FillInterest.fillable(FillInterest.java:108)
	at org.spark_project.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
	at org.spark_project.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
	at org.spark_project.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
	at java.lang.Thread.run(Thread.java:745)
2021-12-06 17:11:36,972 [SparkUI-38] INFO [org.spark_project.jetty.servlet.DefaultServlet] - content=ResourceHttpContent@6f81398b{r=jar:file:/C:/Users/ACER/.m2/repository/org/apache/spark/spark-core_2.11/2.3.0/spark-core_2.11-2.3.0.jar!/org/apache/spark/ui/static/sorttable.js,gz=false}
2021-12-06 17:11:36,972 [SparkUI-43] INFO [org.spark_project.jetty.servlet.DefaultServlet] - content=ResourceHttpContent@297ec99b{r=jar:file:/C:/Users/ACER/.m2/repository/org/apache/spark/spark-core_2.11/2.3.0/spark-core_2.11-2.3.0.jar!/org/apache/spark/ui/static/jquery-1.11.1.min.js,gz=false}
2021-12-06 17:11:36,972 [SparkUI-38] WARN [org.spark_project.jetty.servlet.ServletHandler] - Error for /static/sorttable.js
java.lang.NoSuchMethodError: javax.servlet.http.HttpServletRequest.isAsyncSupported()Z
	at org.spark_project.jetty.servlet.DefaultServlet.sendData(DefaultServlet.java:909)
	at org.spark_project.jetty.servlet.DefaultServlet.doGet(DefaultServlet.java:526)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:707)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:820)
	at org.spark_project.jetty.servlet.ServletHolder.handle(ServletHolder.java:848)
	at org.spark_project.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:584)
	at org.spark_project.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
	at org.spark_project.jetty.servlet.ServletHandler.doScope(ServletHandler.java:512)
	at org.spark_project.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
	at org.spark_project.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.spark_project.jetty.server.handler.gzip.GzipHandler.handle(GzipHandler.java:493)
	at org.spark_project.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:213)
	at org.spark_project.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
	at org.spark_project.jetty.server.Server.handle(Server.java:534)
	at org.spark_project.jetty.server.HttpChannel.handle(HttpChannel.java:320)
	at org.spark_project.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
	at org.spark_project.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
	at org.spark_project.jetty.io.FillInterest.fillable(FillInterest.java:108)
	at org.spark_project.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
	at org.spark_project.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
	at org.spark_project.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
	at java.lang.Thread.run(Thread.java:745)
2021-12-06 17:11:36,972 [SparkUI-43] WARN [org.spark_project.jetty.servlet.ServletHandler] - Error for /static/jquery-1.11.1.min.js
java.lang.NoSuchMethodError: javax.servlet.http.HttpServletRequest.isAsyncSupported()Z
	at org.spark_project.jetty.servlet.DefaultServlet.sendData(DefaultServlet.java:909)
	at org.spark_project.jetty.servlet.DefaultServlet.doGet(DefaultServlet.java:526)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:707)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:820)
	at org.spark_project.jetty.servlet.ServletHolder.handle(ServletHolder.java:848)
	at org.spark_project.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:584)
	at org.spark_project.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
	at org.spark_project.jetty.servlet.ServletHandler.doScope(ServletHandler.java:512)
	at org.spark_project.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
	at org.spark_project.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.spark_project.jetty.server.handler.gzip.GzipHandler.handle(GzipHandler.java:493)
	at org.spark_project.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:213)
	at org.spark_project.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
	at org.spark_project.jetty.server.Server.handle(Server.java:534)
	at org.spark_project.jetty.server.HttpChannel.handle(HttpChannel.java:320)
	at org.spark_project.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
	at org.spark_project.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
	at org.spark_project.jetty.io.FillInterest.fillable(FillInterest.java:108)
	at org.spark_project.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
	at org.spark_project.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
	at org.spark_project.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
	at java.lang.Thread.run(Thread.java:745)
2021-12-06 17:11:36,972 [SparkUI-43] WARN [org.spark_project.jetty.server.HttpChannel] - //qb:4040/static/jquery-1.11.1.min.js
java.lang.NoSuchMethodError: javax.servlet.http.HttpServletRequest.isAsyncStarted()Z
	at org.spark_project.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:688)
	at org.spark_project.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
	at org.spark_project.jetty.servlet.ServletHandler.doScope(ServletHandler.java:512)
	at org.spark_project.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
	at org.spark_project.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.spark_project.jetty.server.handler.gzip.GzipHandler.handle(GzipHandler.java:493)
	at org.spark_project.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:213)
	at org.spark_project.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
	at org.spark_project.jetty.server.Server.handle(Server.java:534)
	at org.spark_project.jetty.server.HttpChannel.handle(HttpChannel.java:320)
	at org.spark_project.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
	at org.spark_project.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
	at org.spark_project.jetty.io.FillInterest.fillable(FillInterest.java:108)
	at org.spark_project.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
	at org.spark_project.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
	at org.spark_project.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
	at java.lang.Thread.run(Thread.java:745)
2021-12-06 17:11:36,972 [SparkUI-111] INFO [org.spark_project.jetty.servlet.DefaultServlet] - content=ResourceHttpContent@73019766{r=jar:file:/C:/Users/ACER/.m2/repository/org/apache/spark/spark-core_2.11/2.3.0/spark-core_2.11-2.3.0.jar!/org/apache/spark/ui/static/bootstrap-tooltip.js,gz=false}
2021-12-06 17:11:36,972 [SparkUI-112] INFO [org.spark_project.jetty.servlet.DefaultServlet] - content=ResourceHttpContent@3d939956{r=jar:file:/C:/Users/ACER/.m2/repository/org/apache/spark/spark-core_2.11/2.3.0/spark-core_2.11-2.3.0.jar!/org/apache/spark/ui/static/vis.min.js,gz=false}
2021-12-06 17:11:36,972 [SparkUI-110] INFO [org.spark_project.jetty.servlet.DefaultServlet] - content=ResourceHttpContent@11793e45{r=jar:file:/C:/Users/ACER/.m2/repository/org/apache/spark/spark-core_2.11/2.3.0/spark-core_2.11-2.3.0.jar!/org/apache/spark/ui/static/initialize-tooltips.js,gz=false}
2021-12-06 17:11:36,972 [SparkUI-38] WARN [org.spark_project.jetty.server.HttpChannel] - //qb:4040/static/sorttable.js
java.lang.NoSuchMethodError: javax.servlet.http.HttpServletRequest.isAsyncStarted()Z
	at org.spark_project.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:688)
	at org.spark_project.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
	at org.spark_project.jetty.servlet.ServletHandler.doScope(ServletHandler.java:512)
	at org.spark_project.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
	at org.spark_project.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.spark_project.jetty.server.handler.gzip.GzipHandler.handle(GzipHandler.java:493)
	at org.spark_project.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:213)
	at org.spark_project.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
	at org.spark_project.jetty.server.Server.handle(Server.java:534)
	at org.spark_project.jetty.server.HttpChannel.handle(HttpChannel.java:320)
	at org.spark_project.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
	at org.spark_project.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
	at org.spark_project.jetty.io.FillInterest.fillable(FillInterest.java:108)
	at org.spark_project.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
	at org.spark_project.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
	at org.spark_project.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
	at java.lang.Thread.run(Thread.java:745)
2021-12-06 17:11:36,972 [SparkUI-110] WARN [org.spark_project.jetty.servlet.ServletHandler] - Error for /static/initialize-tooltips.js
java.lang.NoSuchMethodError: javax.servlet.http.HttpServletRequest.isAsyncSupported()Z
	at org.spark_project.jetty.servlet.DefaultServlet.sendData(DefaultServlet.java:909)
	at org.spark_project.jetty.servlet.DefaultServlet.doGet(DefaultServlet.java:526)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:707)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:820)
	at org.spark_project.jetty.servlet.ServletHolder.handle(ServletHolder.java:848)
	at org.spark_project.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:584)
	at org.spark_project.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
	at org.spark_project.jetty.servlet.ServletHandler.doScope(ServletHandler.java:512)
	at org.spark_project.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
	at org.spark_project.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.spark_project.jetty.server.handler.gzip.GzipHandler.handle(GzipHandler.java:493)
	at org.spark_project.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:213)
	at org.spark_project.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
	at org.spark_project.jetty.server.Server.handle(Server.java:534)
	at org.spark_project.jetty.server.HttpChannel.handle(HttpChannel.java:320)
	at org.spark_project.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
	at org.spark_project.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
	at org.spark_project.jetty.io.FillInterest.fillable(FillInterest.java:108)
	at org.spark_project.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
	at org.spark_project.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
	at org.spark_project.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
	at java.lang.Thread.run(Thread.java:745)
2021-12-06 17:11:36,972 [SparkUI-112] WARN [org.spark_project.jetty.servlet.ServletHandler] - Error for /static/vis.min.js
java.lang.NoSuchMethodError: javax.servlet.http.HttpServletRequest.isAsyncSupported()Z
	at org.spark_project.jetty.servlet.DefaultServlet.sendData(DefaultServlet.java:909)
	at org.spark_project.jetty.servlet.DefaultServlet.doGet(DefaultServlet.java:526)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:707)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:820)
	at org.spark_project.jetty.servlet.ServletHolder.handle(ServletHolder.java:848)
	at org.spark_project.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:584)
	at org.spark_project.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
	at org.spark_project.jetty.servlet.ServletHandler.doScope(ServletHandler.java:512)
	at org.spark_project.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
	at org.spark_project.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.spark_project.jetty.server.handler.gzip.GzipHandler.handle(GzipHandler.java:493)
	at org.spark_project.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:213)
	at org.spark_project.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
	at org.spark_project.jetty.server.Server.handle(Server.java:534)
	at org.spark_project.jetty.server.HttpChannel.handle(HttpChannel.java:320)
	at org.spark_project.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
	at org.spark_project.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
	at org.spark_project.jetty.io.FillInterest.fillable(FillInterest.java:108)
	at org.spark_project.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
	at org.spark_project.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
	at org.spark_project.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
	at java.lang.Thread.run(Thread.java:745)
2021-12-06 17:11:36,972 [SparkUI-111] WARN [org.spark_project.jetty.servlet.ServletHandler] - Error for /static/bootstrap-tooltip.js
java.lang.NoSuchMethodError: javax.servlet.http.HttpServletRequest.isAsyncSupported()Z
	at org.spark_project.jetty.servlet.DefaultServlet.sendData(DefaultServlet.java:909)
	at org.spark_project.jetty.servlet.DefaultServlet.doGet(DefaultServlet.java:526)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:707)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:820)
	at org.spark_project.jetty.servlet.ServletHolder.handle(ServletHolder.java:848)
	at org.spark_project.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:584)
	at org.spark_project.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
	at org.spark_project.jetty.servlet.ServletHandler.doScope(ServletHandler.java:512)
	at org.spark_project.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
	at org.spark_project.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.spark_project.jetty.server.handler.gzip.GzipHandler.handle(GzipHandler.java:493)
	at org.spark_project.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:213)
	at org.spark_project.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
	at org.spark_project.jetty.server.Server.handle(Server.java:534)
	at org.spark_project.jetty.server.HttpChannel.handle(HttpChannel.java:320)
	at org.spark_project.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
	at org.spark_project.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
	at org.spark_project.jetty.io.FillInterest.fillable(FillInterest.java:108)
	at org.spark_project.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
	at org.spark_project.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
	at org.spark_project.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
	at java.lang.Thread.run(Thread.java:745)
2021-12-06 17:11:36,973 [SparkUI-111] WARN [org.spark_project.jetty.server.HttpChannel] - //qb:4040/static/bootstrap-tooltip.js
java.lang.NoSuchMethodError: javax.servlet.http.HttpServletRequest.isAsyncStarted()Z
	at org.spark_project.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:688)
	at org.spark_project.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
	at org.spark_project.jetty.servlet.ServletHandler.doScope(ServletHandler.java:512)
	at org.spark_project.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
	at org.spark_project.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.spark_project.jetty.server.handler.gzip.GzipHandler.handle(GzipHandler.java:493)
	at org.spark_project.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:213)
	at org.spark_project.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
	at org.spark_project.jetty.server.Server.handle(Server.java:534)
	at org.spark_project.jetty.server.HttpChannel.handle(HttpChannel.java:320)
	at org.spark_project.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
	at org.spark_project.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
	at org.spark_project.jetty.io.FillInterest.fillable(FillInterest.java:108)
	at org.spark_project.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
	at org.spark_project.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
	at org.spark_project.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
	at java.lang.Thread.run(Thread.java:745)
2021-12-06 17:11:36,973 [SparkUI-110] WARN [org.spark_project.jetty.server.HttpChannel] - //qb:4040/static/initialize-tooltips.js
java.lang.NoSuchMethodError: javax.servlet.http.HttpServletRequest.isAsyncStarted()Z
	at org.spark_project.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:688)
	at org.spark_project.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
	at org.spark_project.jetty.servlet.ServletHandler.doScope(ServletHandler.java:512)
	at org.spark_project.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
	at org.spark_project.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.spark_project.jetty.server.handler.gzip.GzipHandler.handle(GzipHandler.java:493)
	at org.spark_project.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:213)
	at org.spark_project.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
	at org.spark_project.jetty.server.Server.handle(Server.java:534)
	at org.spark_project.jetty.server.HttpChannel.handle(HttpChannel.java:320)
	at org.spark_project.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
	at org.spark_project.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
	at org.spark_project.jetty.io.FillInterest.fillable(FillInterest.java:108)
	at org.spark_project.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
	at org.spark_project.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
	at org.spark_project.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
	at java.lang.Thread.run(Thread.java:745)
2021-12-06 17:11:36,973 [SparkUI-112] WARN [org.spark_project.jetty.server.HttpChannel] - //qb:4040/static/vis.min.js
java.lang.NoSuchMethodError: javax.servlet.http.HttpServletRequest.isAsyncStarted()Z
	at org.spark_project.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:688)
	at org.spark_project.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
	at org.spark_project.jetty.servlet.ServletHandler.doScope(ServletHandler.java:512)
	at org.spark_project.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
	at org.spark_project.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.spark_project.jetty.server.handler.gzip.GzipHandler.handle(GzipHandler.java:493)
	at org.spark_project.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:213)
	at org.spark_project.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
	at org.spark_project.jetty.server.Server.handle(Server.java:534)
	at org.spark_project.jetty.server.HttpChannel.handle(HttpChannel.java:320)
	at org.spark_project.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
	at org.spark_project.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
	at org.spark_project.jetty.io.FillInterest.fillable(FillInterest.java:108)
	at org.spark_project.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
	at org.spark_project.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
	at org.spark_project.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
	at java.lang.Thread.run(Thread.java:745)
2021-12-06 17:11:36,975 [SparkUI-107] INFO [org.spark_project.jetty.servlet.DefaultServlet] - content=ResourceHttpContent@31eae8b2{r=jar:file:/C:/Users/ACER/.m2/repository/org/apache/spark/spark-core_2.11/2.3.0/spark-core_2.11-2.3.0.jar!/org/apache/spark/ui/static/table.js,gz=false}
2021-12-06 17:11:36,975 [SparkUI-107] WARN [org.spark_project.jetty.servlet.ServletHandler] - Error for /static/table.js
java.lang.NoSuchMethodError: javax.servlet.http.HttpServletRequest.isAsyncSupported()Z
	at org.spark_project.jetty.servlet.DefaultServlet.sendData(DefaultServlet.java:909)
	at org.spark_project.jetty.servlet.DefaultServlet.doGet(DefaultServlet.java:526)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:707)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:820)
	at org.spark_project.jetty.servlet.ServletHolder.handle(ServletHolder.java:848)
	at org.spark_project.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:584)
	at org.spark_project.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
	at org.spark_project.jetty.servlet.ServletHandler.doScope(ServletHandler.java:512)
	at org.spark_project.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
	at org.spark_project.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.spark_project.jetty.server.handler.gzip.GzipHandler.handle(GzipHandler.java:493)
	at org.spark_project.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:213)
	at org.spark_project.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
	at org.spark_project.jetty.server.Server.handle(Server.java:534)
	at org.spark_project.jetty.server.HttpChannel.handle(HttpChannel.java:320)
	at org.spark_project.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
	at org.spark_project.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
	at org.spark_project.jetty.io.FillInterest.fillable(FillInterest.java:108)
	at org.spark_project.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
	at org.spark_project.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
	at org.spark_project.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
	at java.lang.Thread.run(Thread.java:745)
2021-12-06 17:11:36,975 [SparkUI-107] WARN [org.spark_project.jetty.server.HttpChannel] - //qb:4040/static/table.js
java.lang.NoSuchMethodError: javax.servlet.http.HttpServletRequest.isAsyncStarted()Z
	at org.spark_project.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:688)
	at org.spark_project.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
	at org.spark_project.jetty.servlet.ServletHandler.doScope(ServletHandler.java:512)
	at org.spark_project.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
	at org.spark_project.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.spark_project.jetty.server.handler.gzip.GzipHandler.handle(GzipHandler.java:493)
	at org.spark_project.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:213)
	at org.spark_project.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
	at org.spark_project.jetty.server.Server.handle(Server.java:534)
	at org.spark_project.jetty.server.HttpChannel.handle(HttpChannel.java:320)
	at org.spark_project.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
	at org.spark_project.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
	at org.spark_project.jetty.io.FillInterest.fillable(FillInterest.java:108)
	at org.spark_project.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
	at org.spark_project.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
	at org.spark_project.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
	at java.lang.Thread.run(Thread.java:745)
2021-12-06 17:11:36,984 [SparkUI-108] INFO [org.spark_project.jetty.servlet.DefaultServlet] - content=ResourceHttpContent@32bbdcc9{r=jar:file:/C:/Users/ACER/.m2/repository/org/apache/spark/spark-core_2.11/2.3.0/spark-core_2.11-2.3.0.jar!/org/apache/spark/ui/static/log-view.js,gz=false}
2021-12-06 17:11:36,984 [SparkUI-43] INFO [org.spark_project.jetty.servlet.DefaultServlet] - content=ResourceHttpContent@617d3f4d{r=jar:file:/C:/Users/ACER/.m2/repository/org/apache/spark/spark-core_2.11/2.3.0/spark-core_2.11-2.3.0.jar!/org/apache/spark/ui/static/webui.js,gz=false}
2021-12-06 17:11:36,984 [SparkUI-108] WARN [org.spark_project.jetty.servlet.ServletHandler] - Error for /static/log-view.js
java.lang.NoSuchMethodError: javax.servlet.http.HttpServletRequest.isAsyncSupported()Z
	at org.spark_project.jetty.servlet.DefaultServlet.sendData(DefaultServlet.java:909)
	at org.spark_project.jetty.servlet.DefaultServlet.doGet(DefaultServlet.java:526)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:707)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:820)
	at org.spark_project.jetty.servlet.ServletHolder.handle(ServletHolder.java:848)
	at org.spark_project.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:584)
	at org.spark_project.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
	at org.spark_project.jetty.servlet.ServletHandler.doScope(ServletHandler.java:512)
	at org.spark_project.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
	at org.spark_project.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.spark_project.jetty.server.handler.gzip.GzipHandler.handle(GzipHandler.java:493)
	at org.spark_project.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:213)
	at org.spark_project.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
	at org.spark_project.jetty.server.Server.handle(Server.java:534)
	at org.spark_project.jetty.server.HttpChannel.handle(HttpChannel.java:320)
	at org.spark_project.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
	at org.spark_project.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
	at org.spark_project.jetty.io.FillInterest.fillable(FillInterest.java:108)
	at org.spark_project.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
	at org.spark_project.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
	at org.spark_project.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
	at java.lang.Thread.run(Thread.java:745)
2021-12-06 17:11:36,984 [SparkUI-43] WARN [org.spark_project.jetty.servlet.ServletHandler] - Error for /static/webui.js
java.lang.NoSuchMethodError: javax.servlet.http.HttpServletRequest.isAsyncSupported()Z
	at org.spark_project.jetty.servlet.DefaultServlet.sendData(DefaultServlet.java:909)
	at org.spark_project.jetty.servlet.DefaultServlet.doGet(DefaultServlet.java:526)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:707)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:820)
	at org.spark_project.jetty.servlet.ServletHolder.handle(ServletHolder.java:848)
	at org.spark_project.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:584)
	at org.spark_project.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
	at org.spark_project.jetty.servlet.ServletHandler.doScope(ServletHandler.java:512)
	at org.spark_project.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
	at org.spark_project.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.spark_project.jetty.server.handler.gzip.GzipHandler.handle(GzipHandler.java:493)
	at org.spark_project.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:213)
	at org.spark_project.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
	at org.spark_project.jetty.server.Server.handle(Server.java:534)
	at org.spark_project.jetty.server.HttpChannel.handle(HttpChannel.java:320)
	at org.spark_project.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
	at org.spark_project.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
	at org.spark_project.jetty.io.FillInterest.fillable(FillInterest.java:108)
	at org.spark_project.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
	at org.spark_project.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
	at org.spark_project.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
	at java.lang.Thread.run(Thread.java:745)
2021-12-06 17:11:36,984 [SparkUI-108] WARN [org.spark_project.jetty.server.HttpChannel] - //qb:4040/static/log-view.js
java.lang.NoSuchMethodError: javax.servlet.http.HttpServletRequest.isAsyncStarted()Z
	at org.spark_project.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:688)
	at org.spark_project.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
	at org.spark_project.jetty.servlet.ServletHandler.doScope(ServletHandler.java:512)
	at org.spark_project.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
	at org.spark_project.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.spark_project.jetty.server.handler.gzip.GzipHandler.handle(GzipHandler.java:493)
	at org.spark_project.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:213)
	at org.spark_project.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
	at org.spark_project.jetty.server.Server.handle(Server.java:534)
	at org.spark_project.jetty.server.HttpChannel.handle(HttpChannel.java:320)
	at org.spark_project.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
	at org.spark_project.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
	at org.spark_project.jetty.io.FillInterest.fillable(FillInterest.java:108)
	at org.spark_project.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
	at org.spark_project.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
	at org.spark_project.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
	at java.lang.Thread.run(Thread.java:745)
2021-12-06 17:11:36,984 [SparkUI-43] WARN [org.spark_project.jetty.server.HttpChannel] - //qb:4040/static/webui.js
java.lang.NoSuchMethodError: javax.servlet.http.HttpServletRequest.isAsyncStarted()Z
	at org.spark_project.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:688)
	at org.spark_project.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
	at org.spark_project.jetty.servlet.ServletHandler.doScope(ServletHandler.java:512)
	at org.spark_project.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
	at org.spark_project.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.spark_project.jetty.server.handler.gzip.GzipHandler.handle(GzipHandler.java:493)
	at org.spark_project.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:213)
	at org.spark_project.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
	at org.spark_project.jetty.server.Server.handle(Server.java:534)
	at org.spark_project.jetty.server.HttpChannel.handle(HttpChannel.java:320)
	at org.spark_project.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
	at org.spark_project.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
	at org.spark_project.jetty.io.FillInterest.fillable(FillInterest.java:108)
	at org.spark_project.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
	at org.spark_project.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
	at org.spark_project.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
	at java.lang.Thread.run(Thread.java:745)
2021-12-06 17:11:36,988 [SparkUI-112] INFO [org.spark_project.jetty.servlet.DefaultServlet] - content=ResourceHttpContent@73891d6c{r=jar:file:/C:/Users/ACER/.m2/repository/org/apache/spark/spark-core_2.11/2.3.0/spark-core_2.11-2.3.0.jar!/org/apache/spark/ui/static/dagre-d3.min.js,gz=false}
2021-12-06 17:11:36,988 [SparkUI-112] WARN [org.spark_project.jetty.servlet.ServletHandler] - Error for /static/dagre-d3.min.js
java.lang.NoSuchMethodError: javax.servlet.http.HttpServletRequest.isAsyncSupported()Z
	at org.spark_project.jetty.servlet.DefaultServlet.sendData(DefaultServlet.java:909)
	at org.spark_project.jetty.servlet.DefaultServlet.doGet(DefaultServlet.java:526)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:707)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:820)
	at org.spark_project.jetty.servlet.ServletHolder.handle(ServletHolder.java:848)
	at org.spark_project.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:584)
	at org.spark_project.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
	at org.spark_project.jetty.servlet.ServletHandler.doScope(ServletHandler.java:512)
	at org.spark_project.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
	at org.spark_project.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.spark_project.jetty.server.handler.gzip.GzipHandler.handle(GzipHandler.java:493)
	at org.spark_project.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:213)
	at org.spark_project.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
	at org.spark_project.jetty.server.Server.handle(Server.java:534)
	at org.spark_project.jetty.server.HttpChannel.handle(HttpChannel.java:320)
	at org.spark_project.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
	at org.spark_project.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
	at org.spark_project.jetty.io.FillInterest.fillable(FillInterest.java:108)
	at org.spark_project.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
	at org.spark_project.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
	at org.spark_project.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
	at java.lang.Thread.run(Thread.java:745)
2021-12-06 17:11:36,989 [SparkUI-112] WARN [org.spark_project.jetty.server.HttpChannel] - //qb:4040/static/dagre-d3.min.js
java.lang.NoSuchMethodError: javax.servlet.http.HttpServletRequest.isAsyncStarted()Z
	at org.spark_project.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:688)
	at org.spark_project.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
	at org.spark_project.jetty.servlet.ServletHandler.doScope(ServletHandler.java:512)
	at org.spark_project.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
	at org.spark_project.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.spark_project.jetty.server.handler.gzip.GzipHandler.handle(GzipHandler.java:493)
	at org.spark_project.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:213)
	at org.spark_project.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
	at org.spark_project.jetty.server.Server.handle(Server.java:534)
	at org.spark_project.jetty.server.HttpChannel.handle(HttpChannel.java:320)
	at org.spark_project.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
	at org.spark_project.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
	at org.spark_project.jetty.io.FillInterest.fillable(FillInterest.java:108)
	at org.spark_project.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
	at org.spark_project.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
	at org.spark_project.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
	at java.lang.Thread.run(Thread.java:745)
2021-12-06 17:11:36,989 [SparkUI-39] INFO [org.spark_project.jetty.servlet.DefaultServlet] - content=ResourceHttpContent@4c8e7fb7{r=jar:file:/C:/Users/ACER/.m2/repository/org/apache/spark/spark-core_2.11/2.3.0/spark-core_2.11-2.3.0.jar!/org/apache/spark/ui/static/additional-metrics.js,gz=false}
2021-12-06 17:11:36,989 [SparkUI-39] WARN [org.spark_project.jetty.servlet.ServletHandler] - Error for /static/additional-metrics.js
java.lang.NoSuchMethodError: javax.servlet.http.HttpServletRequest.isAsyncSupported()Z
	at org.spark_project.jetty.servlet.DefaultServlet.sendData(DefaultServlet.java:909)
	at org.spark_project.jetty.servlet.DefaultServlet.doGet(DefaultServlet.java:526)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:707)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:820)
	at org.spark_project.jetty.servlet.ServletHolder.handle(ServletHolder.java:848)
	at org.spark_project.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:584)
	at org.spark_project.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
	at org.spark_project.jetty.servlet.ServletHandler.doScope(ServletHandler.java:512)
	at org.spark_project.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
	at org.spark_project.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.spark_project.jetty.server.handler.gzip.GzipHandler.handle(GzipHandler.java:493)
	at org.spark_project.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:213)
	at org.spark_project.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
	at org.spark_project.jetty.server.Server.handle(Server.java:534)
	at org.spark_project.jetty.server.HttpChannel.handle(HttpChannel.java:320)
	at org.spark_project.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
	at org.spark_project.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
	at org.spark_project.jetty.io.FillInterest.fillable(FillInterest.java:108)
	at org.spark_project.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
	at org.spark_project.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
	at org.spark_project.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
	at java.lang.Thread.run(Thread.java:745)
2021-12-06 17:11:36,989 [SparkUI-39] WARN [org.spark_project.jetty.server.HttpChannel] - //qb:4040/static/additional-metrics.js
java.lang.NoSuchMethodError: javax.servlet.http.HttpServletRequest.isAsyncStarted()Z
	at org.spark_project.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:688)
	at org.spark_project.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
	at org.spark_project.jetty.servlet.ServletHandler.doScope(ServletHandler.java:512)
	at org.spark_project.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
	at org.spark_project.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.spark_project.jetty.server.handler.gzip.GzipHandler.handle(GzipHandler.java:493)
	at org.spark_project.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:213)
	at org.spark_project.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
	at org.spark_project.jetty.server.Server.handle(Server.java:534)
	at org.spark_project.jetty.server.HttpChannel.handle(HttpChannel.java:320)
	at org.spark_project.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
	at org.spark_project.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
	at org.spark_project.jetty.io.FillInterest.fillable(FillInterest.java:108)
	at org.spark_project.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
	at org.spark_project.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
	at org.spark_project.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
	at java.lang.Thread.run(Thread.java:745)
2021-12-06 17:11:36,991 [SparkUI-111] INFO [org.spark_project.jetty.servlet.DefaultServlet] - content=ResourceHttpContent@31a0cd57{r=jar:file:/C:/Users/ACER/.m2/repository/org/apache/spark/spark-core_2.11/2.3.0/spark-core_2.11-2.3.0.jar!/org/apache/spark/ui/static/spark-dag-viz.js,gz=false}
2021-12-06 17:11:36,991 [SparkUI-111] WARN [org.spark_project.jetty.servlet.ServletHandler] - Error for /static/spark-dag-viz.js
java.lang.NoSuchMethodError: javax.servlet.http.HttpServletRequest.isAsyncSupported()Z
	at org.spark_project.jetty.servlet.DefaultServlet.sendData(DefaultServlet.java:909)
	at org.spark_project.jetty.servlet.DefaultServlet.doGet(DefaultServlet.java:526)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:707)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:820)
	at org.spark_project.jetty.servlet.ServletHolder.handle(ServletHolder.java:848)
	at org.spark_project.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:584)
	at org.spark_project.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
	at org.spark_project.jetty.servlet.ServletHandler.doScope(ServletHandler.java:512)
	at org.spark_project.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
	at org.spark_project.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.spark_project.jetty.server.handler.gzip.GzipHandler.handle(GzipHandler.java:493)
	at org.spark_project.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:213)
	at org.spark_project.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
	at org.spark_project.jetty.server.Server.handle(Server.java:534)
	at org.spark_project.jetty.server.HttpChannel.handle(HttpChannel.java:320)
	at org.spark_project.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
	at org.spark_project.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
	at org.spark_project.jetty.io.FillInterest.fillable(FillInterest.java:108)
	at org.spark_project.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
	at org.spark_project.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
	at org.spark_project.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
	at java.lang.Thread.run(Thread.java:745)
2021-12-06 17:11:36,992 [SparkUI-111] WARN [org.spark_project.jetty.server.HttpChannel] - //qb:4040/static/spark-dag-viz.js
java.lang.NoSuchMethodError: javax.servlet.http.HttpServletRequest.isAsyncStarted()Z
	at org.spark_project.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:688)
	at org.spark_project.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
	at org.spark_project.jetty.servlet.ServletHandler.doScope(ServletHandler.java:512)
	at org.spark_project.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
	at org.spark_project.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.spark_project.jetty.server.handler.gzip.GzipHandler.handle(GzipHandler.java:493)
	at org.spark_project.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:213)
	at org.spark_project.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
	at org.spark_project.jetty.server.Server.handle(Server.java:534)
	at org.spark_project.jetty.server.HttpChannel.handle(HttpChannel.java:320)
	at org.spark_project.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
	at org.spark_project.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
	at org.spark_project.jetty.io.FillInterest.fillable(FillInterest.java:108)
	at org.spark_project.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
	at org.spark_project.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
	at org.spark_project.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
	at java.lang.Thread.run(Thread.java:745)
2021-12-06 17:11:36,992 [SparkUI-106] INFO [org.spark_project.jetty.servlet.DefaultServlet] - content=ResourceHttpContent@52ea5473{r=jar:file:/C:/Users/ACER/.m2/repository/org/apache/spark/spark-core_2.11/2.3.0/spark-core_2.11-2.3.0.jar!/org/apache/spark/ui/static/timeline-view.js,gz=false}
2021-12-06 17:11:36,992 [SparkUI-106] WARN [org.spark_project.jetty.servlet.ServletHandler] - Error for /static/timeline-view.js
java.lang.NoSuchMethodError: javax.servlet.http.HttpServletRequest.isAsyncSupported()Z
	at org.spark_project.jetty.servlet.DefaultServlet.sendData(DefaultServlet.java:909)
	at org.spark_project.jetty.servlet.DefaultServlet.doGet(DefaultServlet.java:526)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:707)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:820)
	at org.spark_project.jetty.servlet.ServletHolder.handle(ServletHolder.java:848)
	at org.spark_project.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:584)
	at org.spark_project.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
	at org.spark_project.jetty.servlet.ServletHandler.doScope(ServletHandler.java:512)
	at org.spark_project.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
	at org.spark_project.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.spark_project.jetty.server.handler.gzip.GzipHandler.handle(GzipHandler.java:493)
	at org.spark_project.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:213)
	at org.spark_project.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
	at org.spark_project.jetty.server.Server.handle(Server.java:534)
	at org.spark_project.jetty.server.HttpChannel.handle(HttpChannel.java:320)
	at org.spark_project.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
	at org.spark_project.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
	at org.spark_project.jetty.io.FillInterest.fillable(FillInterest.java:108)
	at org.spark_project.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
	at org.spark_project.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
	at org.spark_project.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
	at java.lang.Thread.run(Thread.java:745)
2021-12-06 17:11:36,993 [SparkUI-106] WARN [org.spark_project.jetty.server.HttpChannel] - //qb:4040/static/timeline-view.js
java.lang.NoSuchMethodError: javax.servlet.http.HttpServletRequest.isAsyncStarted()Z
	at org.spark_project.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:688)
	at org.spark_project.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
	at org.spark_project.jetty.servlet.ServletHandler.doScope(ServletHandler.java:512)
	at org.spark_project.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
	at org.spark_project.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.spark_project.jetty.server.handler.gzip.GzipHandler.handle(GzipHandler.java:493)
	at org.spark_project.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:213)
	at org.spark_project.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
	at org.spark_project.jetty.server.Server.handle(Server.java:534)
	at org.spark_project.jetty.server.HttpChannel.handle(HttpChannel.java:320)
	at org.spark_project.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
	at org.spark_project.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
	at org.spark_project.jetty.io.FillInterest.fillable(FillInterest.java:108)
	at org.spark_project.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
	at org.spark_project.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
	at org.spark_project.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
	at java.lang.Thread.run(Thread.java:745)
2021-12-06 17:11:36,992 [SparkUI-107] INFO [org.spark_project.jetty.servlet.DefaultServlet] - content=ResourceHttpContent@10154d39{r=jar:file:/C:/Users/ACER/.m2/repository/org/apache/spark/spark-core_2.11/2.3.0/spark-core_2.11-2.3.0.jar!/org/apache/spark/ui/static/d3.min.js,gz=false}
2021-12-06 17:11:36,993 [SparkUI-107] WARN [org.spark_project.jetty.servlet.ServletHandler] - Error for /static/d3.min.js
java.lang.NoSuchMethodError: javax.servlet.http.HttpServletRequest.isAsyncSupported()Z
	at org.spark_project.jetty.servlet.DefaultServlet.sendData(DefaultServlet.java:909)
	at org.spark_project.jetty.servlet.DefaultServlet.doGet(DefaultServlet.java:526)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:707)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:820)
	at org.spark_project.jetty.servlet.ServletHolder.handle(ServletHolder.java:848)
	at org.spark_project.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:584)
	at org.spark_project.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
	at org.spark_project.jetty.servlet.ServletHandler.doScope(ServletHandler.java:512)
	at org.spark_project.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
	at org.spark_project.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.spark_project.jetty.server.handler.gzip.GzipHandler.handle(GzipHandler.java:493)
	at org.spark_project.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:213)
	at org.spark_project.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
	at org.spark_project.jetty.server.Server.handle(Server.java:534)
	at org.spark_project.jetty.server.HttpChannel.handle(HttpChannel.java:320)
	at org.spark_project.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
	at org.spark_project.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
	at org.spark_project.jetty.io.FillInterest.fillable(FillInterest.java:108)
	at org.spark_project.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
	at org.spark_project.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
	at org.spark_project.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
	at java.lang.Thread.run(Thread.java:745)
2021-12-06 17:11:36,995 [SparkUI-108] INFO [org.spark_project.jetty.servlet.DefaultServlet] - content=ResourceHttpContent@19f35fb8{r=jar:file:/C:/Users/ACER/.m2/repository/org/apache/spark/spark-core_2.11/2.3.0/spark-core_2.11-2.3.0.jar!/org/apache/spark/ui/static/graphlib-dot.min.js,gz=false}
2021-12-06 17:11:36,995 [SparkUI-108] WARN [org.spark_project.jetty.servlet.ServletHandler] - Error for /static/graphlib-dot.min.js
java.lang.NoSuchMethodError: javax.servlet.http.HttpServletRequest.isAsyncSupported()Z
	at org.spark_project.jetty.servlet.DefaultServlet.sendData(DefaultServlet.java:909)
	at org.spark_project.jetty.servlet.DefaultServlet.doGet(DefaultServlet.java:526)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:707)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:820)
	at org.spark_project.jetty.servlet.ServletHolder.handle(ServletHolder.java:848)
	at org.spark_project.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:584)
	at org.spark_project.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
	at org.spark_project.jetty.servlet.ServletHandler.doScope(ServletHandler.java:512)
	at org.spark_project.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
	at org.spark_project.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.spark_project.jetty.server.handler.gzip.GzipHandler.handle(GzipHandler.java:493)
	at org.spark_project.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:213)
	at org.spark_project.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
	at org.spark_project.jetty.server.Server.handle(Server.java:534)
	at org.spark_project.jetty.server.HttpChannel.handle(HttpChannel.java:320)
	at org.spark_project.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
	at org.spark_project.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
	at org.spark_project.jetty.io.FillInterest.fillable(FillInterest.java:108)
	at org.spark_project.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
	at org.spark_project.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
	at org.spark_project.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
	at java.lang.Thread.run(Thread.java:745)
2021-12-06 17:11:36,995 [SparkUI-108] WARN [org.spark_project.jetty.server.HttpChannel] - //qb:4040/static/graphlib-dot.min.js
java.lang.NoSuchMethodError: javax.servlet.http.HttpServletRequest.isAsyncStarted()Z
	at org.spark_project.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:688)
	at org.spark_project.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
	at org.spark_project.jetty.servlet.ServletHandler.doScope(ServletHandler.java:512)
	at org.spark_project.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
	at org.spark_project.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.spark_project.jetty.server.handler.gzip.GzipHandler.handle(GzipHandler.java:493)
	at org.spark_project.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:213)
	at org.spark_project.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
	at org.spark_project.jetty.server.Server.handle(Server.java:534)
	at org.spark_project.jetty.server.HttpChannel.handle(HttpChannel.java:320)
	at org.spark_project.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
	at org.spark_project.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
	at org.spark_project.jetty.io.FillInterest.fillable(FillInterest.java:108)
	at org.spark_project.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
	at org.spark_project.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
	at org.spark_project.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
	at java.lang.Thread.run(Thread.java:745)
2021-12-06 17:11:36,995 [SparkUI-107] WARN [org.spark_project.jetty.server.HttpChannel] - //qb:4040/static/d3.min.js
java.lang.NoSuchMethodError: javax.servlet.http.HttpServletRequest.isAsyncStarted()Z
	at org.spark_project.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:688)
	at org.spark_project.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
	at org.spark_project.jetty.servlet.ServletHandler.doScope(ServletHandler.java:512)
	at org.spark_project.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
	at org.spark_project.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.spark_project.jetty.server.handler.gzip.GzipHandler.handle(GzipHandler.java:493)
	at org.spark_project.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:213)
	at org.spark_project.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
	at org.spark_project.jetty.server.Server.handle(Server.java:534)
	at org.spark_project.jetty.server.HttpChannel.handle(HttpChannel.java:320)
	at org.spark_project.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
	at org.spark_project.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
	at org.spark_project.jetty.io.FillInterest.fillable(FillInterest.java:108)
	at org.spark_project.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
	at org.spark_project.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
	at org.spark_project.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
	at java.lang.Thread.run(Thread.java:745)
2021-12-06 17:11:37,056 [SparkUI-107] INFO [org.spark_project.jetty.servlet.DefaultServlet] - content=ResourceHttpContent@d56ee37{r=jar:file:/C:/Users/ACER/.m2/repository/org/apache/spark/spark-core_2.11/2.3.0/spark-core_2.11-2.3.0.jar!/org/apache/spark/ui/static/spark-logo-77x50px-hd.png,gz=false}
2021-12-06 17:11:37,056 [SparkUI-107] WARN [org.spark_project.jetty.servlet.ServletHandler] - Error for /static/spark-logo-77x50px-hd.png
java.lang.NoSuchMethodError: javax.servlet.http.HttpServletRequest.isAsyncSupported()Z
	at org.spark_project.jetty.servlet.DefaultServlet.sendData(DefaultServlet.java:909)
	at org.spark_project.jetty.servlet.DefaultServlet.doGet(DefaultServlet.java:526)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:707)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:820)
	at org.spark_project.jetty.servlet.ServletHolder.handle(ServletHolder.java:848)
	at org.spark_project.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:584)
	at org.spark_project.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
	at org.spark_project.jetty.servlet.ServletHandler.doScope(ServletHandler.java:512)
	at org.spark_project.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
	at org.spark_project.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.spark_project.jetty.server.handler.gzip.GzipHandler.handle(GzipHandler.java:448)
	at org.spark_project.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:213)
	at org.spark_project.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
	at org.spark_project.jetty.server.Server.handle(Server.java:534)
	at org.spark_project.jetty.server.HttpChannel.handle(HttpChannel.java:320)
	at org.spark_project.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
	at org.spark_project.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
	at org.spark_project.jetty.io.FillInterest.fillable(FillInterest.java:108)
	at org.spark_project.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
	at org.spark_project.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
	at org.spark_project.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
	at java.lang.Thread.run(Thread.java:745)
2021-12-06 17:11:37,057 [SparkUI-107] WARN [org.spark_project.jetty.server.HttpChannel] - //qb:4040/static/spark-logo-77x50px-hd.png
java.lang.NoSuchMethodError: javax.servlet.http.HttpServletRequest.isAsyncStarted()Z
	at org.spark_project.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:688)
	at org.spark_project.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
	at org.spark_project.jetty.servlet.ServletHandler.doScope(ServletHandler.java:512)
	at org.spark_project.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
	at org.spark_project.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.spark_project.jetty.server.handler.gzip.GzipHandler.handle(GzipHandler.java:448)
	at org.spark_project.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:213)
	at org.spark_project.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
	at org.spark_project.jetty.server.Server.handle(Server.java:534)
	at org.spark_project.jetty.server.HttpChannel.handle(HttpChannel.java:320)
	at org.spark_project.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
	at org.spark_project.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
	at org.spark_project.jetty.io.FillInterest.fillable(FillInterest.java:108)
	at org.spark_project.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
	at org.spark_project.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
	at org.spark_project.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
	at java.lang.Thread.run(Thread.java:745)
2021-12-06 17:11:40,119 [SparkUI-110] INFO [org.spark_project.jetty.servlet.DefaultServlet] - content=ResourceHttpContent@26e5b0d3{r=jar:file:/C:/Users/ACER/.m2/repository/org/apache/spark/spark-core_2.11/2.3.0/spark-core_2.11-2.3.0.jar!/org/apache/spark/ui/static/bootstrap.min.css,gz=false}
2021-12-06 17:11:40,119 [SparkUI-110] WARN [org.spark_project.jetty.servlet.ServletHandler] - Error for /static/bootstrap.min.css
java.lang.NoSuchMethodError: javax.servlet.http.HttpServletRequest.isAsyncSupported()Z
	at org.spark_project.jetty.servlet.DefaultServlet.sendData(DefaultServlet.java:909)
	at org.spark_project.jetty.servlet.DefaultServlet.doGet(DefaultServlet.java:526)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:707)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:820)
	at org.spark_project.jetty.servlet.ServletHolder.handle(ServletHolder.java:848)
	at org.spark_project.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:584)
	at org.spark_project.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
	at org.spark_project.jetty.servlet.ServletHandler.doScope(ServletHandler.java:512)
	at org.spark_project.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
	at org.spark_project.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.spark_project.jetty.server.handler.gzip.GzipHandler.handle(GzipHandler.java:493)
	at org.spark_project.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:213)
	at org.spark_project.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
	at org.spark_project.jetty.server.Server.handle(Server.java:534)
	at org.spark_project.jetty.server.HttpChannel.handle(HttpChannel.java:320)
	at org.spark_project.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
	at org.spark_project.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
	at org.spark_project.jetty.io.FillInterest.fillable(FillInterest.java:108)
	at org.spark_project.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
	at org.spark_project.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
	at org.spark_project.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
	at java.lang.Thread.run(Thread.java:745)
2021-12-06 17:11:40,119 [SparkUI-110] WARN [org.spark_project.jetty.server.HttpChannel] - //qb:4040/static/bootstrap.min.css
java.lang.NoSuchMethodError: javax.servlet.http.HttpServletRequest.isAsyncStarted()Z
	at org.spark_project.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:688)
	at org.spark_project.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
	at org.spark_project.jetty.servlet.ServletHandler.doScope(ServletHandler.java:512)
	at org.spark_project.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
	at org.spark_project.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.spark_project.jetty.server.handler.gzip.GzipHandler.handle(GzipHandler.java:493)
	at org.spark_project.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:213)
	at org.spark_project.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
	at org.spark_project.jetty.server.Server.handle(Server.java:534)
	at org.spark_project.jetty.server.HttpChannel.handle(HttpChannel.java:320)
	at org.spark_project.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
	at org.spark_project.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
	at org.spark_project.jetty.io.FillInterest.fillable(FillInterest.java:108)
	at org.spark_project.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
	at org.spark_project.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
	at org.spark_project.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
	at java.lang.Thread.run(Thread.java:745)
2021-12-06 17:11:40,120 [SparkUI-115] INFO [org.spark_project.jetty.servlet.DefaultServlet] - content=ResourceHttpContent@6b5c5653{r=jar:file:/C:/Users/ACER/.m2/repository/org/apache/spark/spark-core_2.11/2.3.0/spark-core_2.11-2.3.0.jar!/org/apache/spark/ui/static/vis.min.css,gz=false}
2021-12-06 17:11:40,120 [SparkUI-115] WARN [org.spark_project.jetty.servlet.ServletHandler] - Error for /static/vis.min.css
java.lang.NoSuchMethodError: javax.servlet.http.HttpServletRequest.isAsyncSupported()Z
	at org.spark_project.jetty.servlet.DefaultServlet.sendData(DefaultServlet.java:909)
	at org.spark_project.jetty.servlet.DefaultServlet.doGet(DefaultServlet.java:526)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:707)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:820)
	at org.spark_project.jetty.servlet.ServletHolder.handle(ServletHolder.java:848)
	at org.spark_project.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:584)
	at org.spark_project.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
	at org.spark_project.jetty.servlet.ServletHandler.doScope(ServletHandler.java:512)
	at org.spark_project.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
	at org.spark_project.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.spark_project.jetty.server.handler.gzip.GzipHandler.handle(GzipHandler.java:493)
	at org.spark_project.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:213)
	at org.spark_project.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
	at org.spark_project.jetty.server.Server.handle(Server.java:534)
	at org.spark_project.jetty.server.HttpChannel.handle(HttpChannel.java:320)
	at org.spark_project.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
	at org.spark_project.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
	at org.spark_project.jetty.io.FillInterest.fillable(FillInterest.java:108)
	at org.spark_project.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
	at org.spark_project.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
	at org.spark_project.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
	at java.lang.Thread.run(Thread.java:745)
2021-12-06 17:11:40,120 [SparkUI-115] WARN [org.spark_project.jetty.server.HttpChannel] - //qb:4040/static/vis.min.css
java.lang.NoSuchMethodError: javax.servlet.http.HttpServletRequest.isAsyncStarted()Z
	at org.spark_project.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:688)
	at org.spark_project.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
	at org.spark_project.jetty.servlet.ServletHandler.doScope(ServletHandler.java:512)
	at org.spark_project.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
	at org.spark_project.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.spark_project.jetty.server.handler.gzip.GzipHandler.handle(GzipHandler.java:493)
	at org.spark_project.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:213)
	at org.spark_project.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
	at org.spark_project.jetty.server.Server.handle(Server.java:534)
	at org.spark_project.jetty.server.HttpChannel.handle(HttpChannel.java:320)
	at org.spark_project.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
	at org.spark_project.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
	at org.spark_project.jetty.io.FillInterest.fillable(FillInterest.java:108)
	at org.spark_project.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
	at org.spark_project.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
	at org.spark_project.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
	at java.lang.Thread.run(Thread.java:745)
2021-12-06 17:11:40,121 [SparkUI-111] INFO [org.spark_project.jetty.servlet.DefaultServlet] - content=ResourceHttpContent@2da8090{r=jar:file:/C:/Users/ACER/.m2/repository/org/apache/spark/spark-core_2.11/2.3.0/spark-core_2.11-2.3.0.jar!/org/apache/spark/ui/static/timeline-view.css,gz=false}
2021-12-06 17:11:40,121 [SparkUI-38] INFO [org.spark_project.jetty.servlet.DefaultServlet] - content=ResourceHttpContent@14491077{r=jar:file:/C:/Users/ACER/.m2/repository/org/apache/spark/spark-core_2.11/2.3.0/spark-core_2.11-2.3.0.jar!/org/apache/spark/ui/static/webui.css,gz=false}
2021-12-06 17:11:40,121 [SparkUI-111] WARN [org.spark_project.jetty.servlet.ServletHandler] - Error for /static/timeline-view.css
java.lang.NoSuchMethodError: javax.servlet.http.HttpServletRequest.isAsyncSupported()Z
	at org.spark_project.jetty.servlet.DefaultServlet.sendData(DefaultServlet.java:909)
	at org.spark_project.jetty.servlet.DefaultServlet.doGet(DefaultServlet.java:526)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:707)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:820)
	at org.spark_project.jetty.servlet.ServletHolder.handle(ServletHolder.java:848)
	at org.spark_project.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:584)
	at org.spark_project.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
	at org.spark_project.jetty.servlet.ServletHandler.doScope(ServletHandler.java:512)
	at org.spark_project.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
	at org.spark_project.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.spark_project.jetty.server.handler.gzip.GzipHandler.handle(GzipHandler.java:493)
	at org.spark_project.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:213)
	at org.spark_project.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
	at org.spark_project.jetty.server.Server.handle(Server.java:534)
	at org.spark_project.jetty.server.HttpChannel.handle(HttpChannel.java:320)
	at org.spark_project.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
	at org.spark_project.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
	at org.spark_project.jetty.io.FillInterest.fillable(FillInterest.java:108)
	at org.spark_project.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
	at org.spark_project.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
	at org.spark_project.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
	at java.lang.Thread.run(Thread.java:745)
2021-12-06 17:11:40,121 [SparkUI-38] WARN [org.spark_project.jetty.servlet.ServletHandler] - Error for /static/webui.css
java.lang.NoSuchMethodError: javax.servlet.http.HttpServletRequest.isAsyncSupported()Z
	at org.spark_project.jetty.servlet.DefaultServlet.sendData(DefaultServlet.java:909)
	at org.spark_project.jetty.servlet.DefaultServlet.doGet(DefaultServlet.java:526)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:707)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:820)
	at org.spark_project.jetty.servlet.ServletHolder.handle(ServletHolder.java:848)
	at org.spark_project.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:584)
	at org.spark_project.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
	at org.spark_project.jetty.servlet.ServletHandler.doScope(ServletHandler.java:512)
	at org.spark_project.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
	at org.spark_project.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.spark_project.jetty.server.handler.gzip.GzipHandler.handle(GzipHandler.java:493)
	at org.spark_project.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:213)
	at org.spark_project.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
	at org.spark_project.jetty.server.Server.handle(Server.java:534)
	at org.spark_project.jetty.server.HttpChannel.handle(HttpChannel.java:320)
	at org.spark_project.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
	at org.spark_project.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
	at org.spark_project.jetty.io.FillInterest.fillable(FillInterest.java:108)
	at org.spark_project.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
	at org.spark_project.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
	at org.spark_project.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
	at java.lang.Thread.run(Thread.java:745)
2021-12-06 17:11:40,121 [SparkUI-111] WARN [org.spark_project.jetty.server.HttpChannel] - //qb:4040/static/timeline-view.css
java.lang.NoSuchMethodError: javax.servlet.http.HttpServletRequest.isAsyncStarted()Z
	at org.spark_project.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:688)
	at org.spark_project.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
	at org.spark_project.jetty.servlet.ServletHandler.doScope(ServletHandler.java:512)
	at org.spark_project.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
	at org.spark_project.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.spark_project.jetty.server.handler.gzip.GzipHandler.handle(GzipHandler.java:493)
	at org.spark_project.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:213)
	at org.spark_project.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
	at org.spark_project.jetty.server.Server.handle(Server.java:534)
	at org.spark_project.jetty.server.HttpChannel.handle(HttpChannel.java:320)
	at org.spark_project.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
	at org.spark_project.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
	at org.spark_project.jetty.io.FillInterest.fillable(FillInterest.java:108)
	at org.spark_project.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
	at org.spark_project.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
	at org.spark_project.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
	at java.lang.Thread.run(Thread.java:745)
2021-12-06 17:11:40,121 [SparkUI-38] WARN [org.spark_project.jetty.server.HttpChannel] - //qb:4040/static/webui.css
java.lang.NoSuchMethodError: javax.servlet.http.HttpServletRequest.isAsyncStarted()Z
	at org.spark_project.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:688)
	at org.spark_project.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
	at org.spark_project.jetty.servlet.ServletHandler.doScope(ServletHandler.java:512)
	at org.spark_project.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
	at org.spark_project.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.spark_project.jetty.server.handler.gzip.GzipHandler.handle(GzipHandler.java:493)
	at org.spark_project.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:213)
	at org.spark_project.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
	at org.spark_project.jetty.server.Server.handle(Server.java:534)
	at org.spark_project.jetty.server.HttpChannel.handle(HttpChannel.java:320)
	at org.spark_project.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
	at org.spark_project.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
	at org.spark_project.jetty.io.FillInterest.fillable(FillInterest.java:108)
	at org.spark_project.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
	at org.spark_project.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
	at org.spark_project.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
	at java.lang.Thread.run(Thread.java:745)
2021-12-06 17:11:40,122 [SparkUI-110] INFO [org.spark_project.jetty.servlet.DefaultServlet] - content=ResourceHttpContent@647cd51d{r=jar:file:/C:/Users/ACER/.m2/repository/org/apache/spark/spark-core_2.11/2.3.0/spark-core_2.11-2.3.0.jar!/org/apache/spark/ui/static/spark-dag-viz.css,gz=false}
2021-12-06 17:11:40,122 [SparkUI-110] WARN [org.spark_project.jetty.servlet.ServletHandler] - Error for /static/spark-dag-viz.css
java.lang.NoSuchMethodError: javax.servlet.http.HttpServletRequest.isAsyncSupported()Z
	at org.spark_project.jetty.servlet.DefaultServlet.sendData(DefaultServlet.java:909)
	at org.spark_project.jetty.servlet.DefaultServlet.doGet(DefaultServlet.java:526)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:707)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:820)
	at org.spark_project.jetty.servlet.ServletHolder.handle(ServletHolder.java:848)
	at org.spark_project.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:584)
	at org.spark_project.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
	at org.spark_project.jetty.servlet.ServletHandler.doScope(ServletHandler.java:512)
	at org.spark_project.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
	at org.spark_project.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.spark_project.jetty.server.handler.gzip.GzipHandler.handle(GzipHandler.java:493)
	at org.spark_project.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:213)
	at org.spark_project.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
	at org.spark_project.jetty.server.Server.handle(Server.java:534)
	at org.spark_project.jetty.server.HttpChannel.handle(HttpChannel.java:320)
	at org.spark_project.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
	at org.spark_project.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
	at org.spark_project.jetty.io.FillInterest.fillable(FillInterest.java:108)
	at org.spark_project.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
	at org.spark_project.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
	at org.spark_project.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
	at java.lang.Thread.run(Thread.java:745)
2021-12-06 17:11:40,122 [SparkUI-110] WARN [org.spark_project.jetty.server.HttpChannel] - //qb:4040/static/spark-dag-viz.css
java.lang.NoSuchMethodError: javax.servlet.http.HttpServletRequest.isAsyncStarted()Z
	at org.spark_project.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:688)
	at org.spark_project.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
	at org.spark_project.jetty.servlet.ServletHandler.doScope(ServletHandler.java:512)
	at org.spark_project.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
	at org.spark_project.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.spark_project.jetty.server.handler.gzip.GzipHandler.handle(GzipHandler.java:493)
	at org.spark_project.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:213)
	at org.spark_project.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
	at org.spark_project.jetty.server.Server.handle(Server.java:534)
	at org.spark_project.jetty.server.HttpChannel.handle(HttpChannel.java:320)
	at org.spark_project.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
	at org.spark_project.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
	at org.spark_project.jetty.io.FillInterest.fillable(FillInterest.java:108)
	at org.spark_project.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
	at org.spark_project.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
	at org.spark_project.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
	at java.lang.Thread.run(Thread.java:745)
2021-12-06 17:11:40,123 [SparkUI-115] INFO [org.spark_project.jetty.servlet.DefaultServlet] - content=ResourceHttpContent@2159cb02{r=jar:file:/C:/Users/ACER/.m2/repository/org/apache/spark/spark-core_2.11/2.3.0/spark-core_2.11-2.3.0.jar!/org/apache/spark/ui/static/bootstrap.min.css,gz=false}
2021-12-06 17:11:40,123 [SparkUI-115] WARN [org.spark_project.jetty.servlet.ServletHandler] - Error for /static/bootstrap.min.css
java.lang.NoSuchMethodError: javax.servlet.http.HttpServletRequest.isAsyncSupported()Z
	at org.spark_project.jetty.servlet.DefaultServlet.sendData(DefaultServlet.java:909)
	at org.spark_project.jetty.servlet.DefaultServlet.doGet(DefaultServlet.java:526)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:707)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:820)
	at org.spark_project.jetty.servlet.ServletHolder.handle(ServletHolder.java:848)
	at org.spark_project.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:584)
	at org.spark_project.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
	at org.spark_project.jetty.servlet.ServletHandler.doScope(ServletHandler.java:512)
	at org.spark_project.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
	at org.spark_project.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.spark_project.jetty.server.handler.gzip.GzipHandler.handle(GzipHandler.java:493)
	at org.spark_project.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:213)
	at org.spark_project.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
	at org.spark_project.jetty.server.Server.handle(Server.java:534)
	at org.spark_project.jetty.server.HttpChannel.handle(HttpChannel.java:320)
	at org.spark_project.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
	at org.spark_project.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
	at org.spark_project.jetty.io.FillInterest.fillable(FillInterest.java:108)
	at org.spark_project.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
	at org.spark_project.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
	at org.spark_project.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
	at java.lang.Thread.run(Thread.java:745)
2021-12-06 17:11:40,123 [SparkUI-115] WARN [org.spark_project.jetty.server.HttpChannel] - //qb:4040/static/bootstrap.min.css
java.lang.NoSuchMethodError: javax.servlet.http.HttpServletRequest.isAsyncStarted()Z
	at org.spark_project.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:688)
	at org.spark_project.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
	at org.spark_project.jetty.servlet.ServletHandler.doScope(ServletHandler.java:512)
	at org.spark_project.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
	at org.spark_project.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.spark_project.jetty.server.handler.gzip.GzipHandler.handle(GzipHandler.java:493)
	at org.spark_project.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:213)
	at org.spark_project.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
	at org.spark_project.jetty.server.Server.handle(Server.java:534)
	at org.spark_project.jetty.server.HttpChannel.handle(HttpChannel.java:320)
	at org.spark_project.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
	at org.spark_project.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
	at org.spark_project.jetty.io.FillInterest.fillable(FillInterest.java:108)
	at org.spark_project.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
	at org.spark_project.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
	at org.spark_project.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
	at java.lang.Thread.run(Thread.java:745)
2021-12-06 17:11:40,125 [SparkUI-112] INFO [org.spark_project.jetty.servlet.DefaultServlet] - content=ResourceHttpContent@229637c8{r=jar:file:/C:/Users/ACER/.m2/repository/org/apache/spark/spark-core_2.11/2.3.0/spark-core_2.11-2.3.0.jar!/org/apache/spark/ui/static/vis.min.css,gz=false}
2021-12-06 17:11:40,125 [SparkUI-112] WARN [org.spark_project.jetty.servlet.ServletHandler] - Error for /static/vis.min.css
java.lang.NoSuchMethodError: javax.servlet.http.HttpServletRequest.isAsyncSupported()Z
	at org.spark_project.jetty.servlet.DefaultServlet.sendData(DefaultServlet.java:909)
	at org.spark_project.jetty.servlet.DefaultServlet.doGet(DefaultServlet.java:526)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:707)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:820)
	at org.spark_project.jetty.servlet.ServletHolder.handle(ServletHolder.java:848)
	at org.spark_project.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:584)
	at org.spark_project.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
	at org.spark_project.jetty.servlet.ServletHandler.doScope(ServletHandler.java:512)
	at org.spark_project.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
	at org.spark_project.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.spark_project.jetty.server.handler.gzip.GzipHandler.handle(GzipHandler.java:493)
	at org.spark_project.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:213)
	at org.spark_project.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
	at org.spark_project.jetty.server.Server.handle(Server.java:534)
	at org.spark_project.jetty.server.HttpChannel.handle(HttpChannel.java:320)
	at org.spark_project.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
	at org.spark_project.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
	at org.spark_project.jetty.io.FillInterest.fillable(FillInterest.java:108)
	at org.spark_project.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
	at org.spark_project.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
	at org.spark_project.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
	at java.lang.Thread.run(Thread.java:745)
2021-12-06 17:11:40,125 [SparkUI-112] WARN [org.spark_project.jetty.server.HttpChannel] - //qb:4040/static/vis.min.css
java.lang.NoSuchMethodError: javax.servlet.http.HttpServletRequest.isAsyncStarted()Z
	at org.spark_project.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:688)
	at org.spark_project.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
	at org.spark_project.jetty.servlet.ServletHandler.doScope(ServletHandler.java:512)
	at org.spark_project.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
	at org.spark_project.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.spark_project.jetty.server.handler.gzip.GzipHandler.handle(GzipHandler.java:493)
	at org.spark_project.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:213)
	at org.spark_project.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
	at org.spark_project.jetty.server.Server.handle(Server.java:534)
	at org.spark_project.jetty.server.HttpChannel.handle(HttpChannel.java:320)
	at org.spark_project.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
	at org.spark_project.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
	at org.spark_project.jetty.io.FillInterest.fillable(FillInterest.java:108)
	at org.spark_project.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
	at org.spark_project.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
	at org.spark_project.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
	at java.lang.Thread.run(Thread.java:745)
2021-12-06 17:11:40,152 [SparkUI-114] INFO [org.spark_project.jetty.servlet.DefaultServlet] - content=ResourceHttpContent@4cadaa3e{r=jar:file:/C:/Users/ACER/.m2/repository/org/apache/spark/spark-core_2.11/2.3.0/spark-core_2.11-2.3.0.jar!/org/apache/spark/ui/static/bootstrap-tooltip.js,gz=false}
2021-12-06 17:11:40,152 [SparkUI-43] INFO [org.spark_project.jetty.servlet.DefaultServlet] - content=ResourceHttpContent@3fb1b8f3{r=jar:file:/C:/Users/ACER/.m2/repository/org/apache/spark/spark-core_2.11/2.3.0/spark-core_2.11-2.3.0.jar!/org/apache/spark/ui/static/sorttable.js,gz=false}
2021-12-06 17:11:40,152 [SparkUI-114] WARN [org.spark_project.jetty.servlet.ServletHandler] - Error for /static/bootstrap-tooltip.js
java.lang.NoSuchMethodError: javax.servlet.http.HttpServletRequest.isAsyncSupported()Z
	at org.spark_project.jetty.servlet.DefaultServlet.sendData(DefaultServlet.java:909)
	at org.spark_project.jetty.servlet.DefaultServlet.doGet(DefaultServlet.java:526)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:707)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:820)
	at org.spark_project.jetty.servlet.ServletHolder.handle(ServletHolder.java:848)
	at org.spark_project.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:584)
	at org.spark_project.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
	at org.spark_project.jetty.servlet.ServletHandler.doScope(ServletHandler.java:512)
	at org.spark_project.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
	at org.spark_project.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.spark_project.jetty.server.handler.gzip.GzipHandler.handle(GzipHandler.java:493)
	at org.spark_project.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:213)
	at org.spark_project.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
	at org.spark_project.jetty.server.Server.handle(Server.java:534)
	at org.spark_project.jetty.server.HttpChannel.handle(HttpChannel.java:320)
	at org.spark_project.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
	at org.spark_project.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
	at org.spark_project.jetty.io.FillInterest.fillable(FillInterest.java:108)
	at org.spark_project.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
	at org.spark_project.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
	at org.spark_project.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
	at java.lang.Thread.run(Thread.java:745)
2021-12-06 17:11:40,152 [SparkUI-110] INFO [org.spark_project.jetty.servlet.DefaultServlet] - content=ResourceHttpContent@7fa8f3c8{r=jar:file:/C:/Users/ACER/.m2/repository/org/apache/spark/spark-core_2.11/2.3.0/spark-core_2.11-2.3.0.jar!/org/apache/spark/ui/static/vis.min.js,gz=false}
2021-12-06 17:11:40,152 [SparkUI-43] WARN [org.spark_project.jetty.servlet.ServletHandler] - Error for /static/sorttable.js
java.lang.NoSuchMethodError: javax.servlet.http.HttpServletRequest.isAsyncSupported()Z
	at org.spark_project.jetty.servlet.DefaultServlet.sendData(DefaultServlet.java:909)
	at org.spark_project.jetty.servlet.DefaultServlet.doGet(DefaultServlet.java:526)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:707)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:820)
	at org.spark_project.jetty.servlet.ServletHolder.handle(ServletHolder.java:848)
	at org.spark_project.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:584)
	at org.spark_project.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
	at org.spark_project.jetty.servlet.ServletHandler.doScope(ServletHandler.java:512)
	at org.spark_project.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
	at org.spark_project.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.spark_project.jetty.server.handler.gzip.GzipHandler.handle(GzipHandler.java:493)
	at org.spark_project.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:213)
	at org.spark_project.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
	at org.spark_project.jetty.server.Server.handle(Server.java:534)
	at org.spark_project.jetty.server.HttpChannel.handle(HttpChannel.java:320)
	at org.spark_project.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
	at org.spark_project.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
	at org.spark_project.jetty.io.FillInterest.fillable(FillInterest.java:108)
	at org.spark_project.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
	at org.spark_project.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
	at org.spark_project.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
	at java.lang.Thread.run(Thread.java:745)
2021-12-06 17:11:40,152 [SparkUI-114] WARN [org.spark_project.jetty.server.HttpChannel] - //qb:4040/static/bootstrap-tooltip.js
java.lang.NoSuchMethodError: javax.servlet.http.HttpServletRequest.isAsyncStarted()Z
	at org.spark_project.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:688)
	at org.spark_project.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
	at org.spark_project.jetty.servlet.ServletHandler.doScope(ServletHandler.java:512)
	at org.spark_project.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
	at org.spark_project.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.spark_project.jetty.server.handler.gzip.GzipHandler.handle(GzipHandler.java:493)
	at org.spark_project.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:213)
	at org.spark_project.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
	at org.spark_project.jetty.server.Server.handle(Server.java:534)
	at org.spark_project.jetty.server.HttpChannel.handle(HttpChannel.java:320)
	at org.spark_project.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
	at org.spark_project.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
	at org.spark_project.jetty.io.FillInterest.fillable(FillInterest.java:108)
	at org.spark_project.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
	at org.spark_project.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
	at org.spark_project.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
	at java.lang.Thread.run(Thread.java:745)
2021-12-06 17:11:40,152 [SparkUI-110] WARN [org.spark_project.jetty.servlet.ServletHandler] - Error for /static/vis.min.js
java.lang.NoSuchMethodError: javax.servlet.http.HttpServletRequest.isAsyncSupported()Z
	at org.spark_project.jetty.servlet.DefaultServlet.sendData(DefaultServlet.java:909)
	at org.spark_project.jetty.servlet.DefaultServlet.doGet(DefaultServlet.java:526)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:707)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:820)
	at org.spark_project.jetty.servlet.ServletHolder.handle(ServletHolder.java:848)
	at org.spark_project.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:584)
	at org.spark_project.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
	at org.spark_project.jetty.servlet.ServletHandler.doScope(ServletHandler.java:512)
	at org.spark_project.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
	at org.spark_project.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.spark_project.jetty.server.handler.gzip.GzipHandler.handle(GzipHandler.java:493)
	at org.spark_project.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:213)
	at org.spark_project.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
	at org.spark_project.jetty.server.Server.handle(Server.java:534)
	at org.spark_project.jetty.server.HttpChannel.handle(HttpChannel.java:320)
	at org.spark_project.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
	at org.spark_project.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
	at org.spark_project.jetty.io.FillInterest.fillable(FillInterest.java:108)
	at org.spark_project.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
	at org.spark_project.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
	at org.spark_project.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
	at java.lang.Thread.run(Thread.java:745)
2021-12-06 17:11:40,153 [SparkUI-43] WARN [org.spark_project.jetty.server.HttpChannel] - //qb:4040/static/sorttable.js
java.lang.NoSuchMethodError: javax.servlet.http.HttpServletRequest.isAsyncStarted()Z
	at org.spark_project.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:688)
	at org.spark_project.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
	at org.spark_project.jetty.servlet.ServletHandler.doScope(ServletHandler.java:512)
	at org.spark_project.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
	at org.spark_project.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.spark_project.jetty.server.handler.gzip.GzipHandler.handle(GzipHandler.java:493)
	at org.spark_project.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:213)
	at org.spark_project.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
	at org.spark_project.jetty.server.Server.handle(Server.java:534)
	at org.spark_project.jetty.server.HttpChannel.handle(HttpChannel.java:320)
	at org.spark_project.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
	at org.spark_project.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
	at org.spark_project.jetty.io.FillInterest.fillable(FillInterest.java:108)
	at org.spark_project.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
	at org.spark_project.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
	at org.spark_project.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
	at java.lang.Thread.run(Thread.java:745)
2021-12-06 17:11:40,153 [SparkUI-107] INFO [org.spark_project.jetty.servlet.DefaultServlet] - content=ResourceHttpContent@4add9248{r=jar:file:/C:/Users/ACER/.m2/repository/org/apache/spark/spark-core_2.11/2.3.0/spark-core_2.11-2.3.0.jar!/org/apache/spark/ui/static/initialize-tooltips.js,gz=false}
2021-12-06 17:11:40,153 [SparkUI-107] WARN [org.spark_project.jetty.servlet.ServletHandler] - Error for /static/initialize-tooltips.js
java.lang.NoSuchMethodError: javax.servlet.http.HttpServletRequest.isAsyncSupported()Z
	at org.spark_project.jetty.servlet.DefaultServlet.sendData(DefaultServlet.java:909)
	at org.spark_project.jetty.servlet.DefaultServlet.doGet(DefaultServlet.java:526)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:707)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:820)
	at org.spark_project.jetty.servlet.ServletHolder.handle(ServletHolder.java:848)
	at org.spark_project.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:584)
	at org.spark_project.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
	at org.spark_project.jetty.servlet.ServletHandler.doScope(ServletHandler.java:512)
	at org.spark_project.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
	at org.spark_project.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.spark_project.jetty.server.handler.gzip.GzipHandler.handle(GzipHandler.java:493)
	at org.spark_project.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:213)
	at org.spark_project.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
	at org.spark_project.jetty.server.Server.handle(Server.java:534)
	at org.spark_project.jetty.server.HttpChannel.handle(HttpChannel.java:320)
	at org.spark_project.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
	at org.spark_project.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
	at org.spark_project.jetty.io.FillInterest.fillable(FillInterest.java:108)
	at org.spark_project.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
	at org.spark_project.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
	at org.spark_project.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
	at java.lang.Thread.run(Thread.java:745)
2021-12-06 17:11:40,154 [SparkUI-107] WARN [org.spark_project.jetty.server.HttpChannel] - //qb:4040/static/initialize-tooltips.js
java.lang.NoSuchMethodError: javax.servlet.http.HttpServletRequest.isAsyncStarted()Z
	at org.spark_project.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:688)
	at org.spark_project.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
	at org.spark_project.jetty.servlet.ServletHandler.doScope(ServletHandler.java:512)
	at org.spark_project.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
	at org.spark_project.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.spark_project.jetty.server.handler.gzip.GzipHandler.handle(GzipHandler.java:493)
	at org.spark_project.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:213)
	at org.spark_project.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
	at org.spark_project.jetty.server.Server.handle(Server.java:534)
	at org.spark_project.jetty.server.HttpChannel.handle(HttpChannel.java:320)
	at org.spark_project.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
	at org.spark_project.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
	at org.spark_project.jetty.io.FillInterest.fillable(FillInterest.java:108)
	at org.spark_project.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
	at org.spark_project.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
	at org.spark_project.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
	at java.lang.Thread.run(Thread.java:745)
2021-12-06 17:11:40,153 [SparkUI-110] WARN [org.spark_project.jetty.server.HttpChannel] - //qb:4040/static/vis.min.js
java.lang.NoSuchMethodError: javax.servlet.http.HttpServletRequest.isAsyncStarted()Z
	at org.spark_project.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:688)
	at org.spark_project.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
	at org.spark_project.jetty.servlet.ServletHandler.doScope(ServletHandler.java:512)
	at org.spark_project.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
	at org.spark_project.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.spark_project.jetty.server.handler.gzip.GzipHandler.handle(GzipHandler.java:493)
	at org.spark_project.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:213)
	at org.spark_project.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
	at org.spark_project.jetty.server.Server.handle(Server.java:534)
	at org.spark_project.jetty.server.HttpChannel.handle(HttpChannel.java:320)
	at org.spark_project.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
	at org.spark_project.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
	at org.spark_project.jetty.io.FillInterest.fillable(FillInterest.java:108)
	at org.spark_project.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
	at org.spark_project.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
	at org.spark_project.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
	at java.lang.Thread.run(Thread.java:745)
2021-12-06 17:11:40,157 [SparkUI-113] INFO [org.spark_project.jetty.servlet.DefaultServlet] - content=ResourceHttpContent@d6a5717{r=jar:file:/C:/Users/ACER/.m2/repository/org/apache/spark/spark-core_2.11/2.3.0/spark-core_2.11-2.3.0.jar!/org/apache/spark/ui/static/jquery-1.11.1.min.js,gz=false}
2021-12-06 17:11:40,157 [SparkUI-114] INFO [org.spark_project.jetty.servlet.DefaultServlet] - content=ResourceHttpContent@2d9b3ba5{r=jar:file:/C:/Users/ACER/.m2/repository/org/apache/spark/spark-core_2.11/2.3.0/spark-core_2.11-2.3.0.jar!/org/apache/spark/ui/static/log-view.js,gz=false}
2021-12-06 17:11:40,157 [SparkUI-39] INFO [org.spark_project.jetty.servlet.DefaultServlet] - content=ResourceHttpContent@59ea126{r=jar:file:/C:/Users/ACER/.m2/repository/org/apache/spark/spark-core_2.11/2.3.0/spark-core_2.11-2.3.0.jar!/org/apache/spark/ui/static/additional-metrics.js,gz=false}
2021-12-06 17:11:40,157 [SparkUI-108] INFO [org.spark_project.jetty.servlet.DefaultServlet] - content=ResourceHttpContent@7b2a5fa7{r=jar:file:/C:/Users/ACER/.m2/repository/org/apache/spark/spark-core_2.11/2.3.0/spark-core_2.11-2.3.0.jar!/org/apache/spark/ui/static/timeline-view.js,gz=false}
2021-12-06 17:11:40,157 [SparkUI-114] WARN [org.spark_project.jetty.servlet.ServletHandler] - Error for /static/log-view.js
java.lang.NoSuchMethodError: javax.servlet.http.HttpServletRequest.isAsyncSupported()Z
	at org.spark_project.jetty.servlet.DefaultServlet.sendData(DefaultServlet.java:909)
	at org.spark_project.jetty.servlet.DefaultServlet.doGet(DefaultServlet.java:526)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:707)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:820)
	at org.spark_project.jetty.servlet.ServletHolder.handle(ServletHolder.java:848)
	at org.spark_project.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:584)
	at org.spark_project.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
	at org.spark_project.jetty.servlet.ServletHandler.doScope(ServletHandler.java:512)
	at org.spark_project.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
	at org.spark_project.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.spark_project.jetty.server.handler.gzip.GzipHandler.handle(GzipHandler.java:493)
	at org.spark_project.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:213)
	at org.spark_project.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
	at org.spark_project.jetty.server.Server.handle(Server.java:534)
	at org.spark_project.jetty.server.HttpChannel.handle(HttpChannel.java:320)
	at org.spark_project.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
	at org.spark_project.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
	at org.spark_project.jetty.io.FillInterest.fillable(FillInterest.java:108)
	at org.spark_project.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
	at org.spark_project.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
	at org.spark_project.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
	at java.lang.Thread.run(Thread.java:745)
2021-12-06 17:11:40,158 [SparkUI-114] WARN [org.spark_project.jetty.server.HttpChannel] - //qb:4040/static/log-view.js
java.lang.NoSuchMethodError: javax.servlet.http.HttpServletRequest.isAsyncStarted()Z
	at org.spark_project.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:688)
	at org.spark_project.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
	at org.spark_project.jetty.servlet.ServletHandler.doScope(ServletHandler.java:512)
	at org.spark_project.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
	at org.spark_project.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.spark_project.jetty.server.handler.gzip.GzipHandler.handle(GzipHandler.java:493)
	at org.spark_project.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:213)
	at org.spark_project.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
	at org.spark_project.jetty.server.Server.handle(Server.java:534)
	at org.spark_project.jetty.server.HttpChannel.handle(HttpChannel.java:320)
	at org.spark_project.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
	at org.spark_project.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
	at org.spark_project.jetty.io.FillInterest.fillable(FillInterest.java:108)
	at org.spark_project.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
	at org.spark_project.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
	at org.spark_project.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
	at java.lang.Thread.run(Thread.java:745)
2021-12-06 17:11:40,157 [SparkUI-113] WARN [org.spark_project.jetty.servlet.ServletHandler] - Error for /static/jquery-1.11.1.min.js
java.lang.NoSuchMethodError: javax.servlet.http.HttpServletRequest.isAsyncSupported()Z
	at org.spark_project.jetty.servlet.DefaultServlet.sendData(DefaultServlet.java:909)
	at org.spark_project.jetty.servlet.DefaultServlet.doGet(DefaultServlet.java:526)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:707)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:820)
	at org.spark_project.jetty.servlet.ServletHolder.handle(ServletHolder.java:848)
	at org.spark_project.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:584)
	at org.spark_project.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
	at org.spark_project.jetty.servlet.ServletHandler.doScope(ServletHandler.java:512)
	at org.spark_project.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
	at org.spark_project.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.spark_project.jetty.server.handler.gzip.GzipHandler.handle(GzipHandler.java:493)
	at org.spark_project.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:213)
	at org.spark_project.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
	at org.spark_project.jetty.server.Server.handle(Server.java:534)
	at org.spark_project.jetty.server.HttpChannel.handle(HttpChannel.java:320)
	at org.spark_project.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
	at org.spark_project.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
	at org.spark_project.jetty.io.FillInterest.fillable(FillInterest.java:108)
	at org.spark_project.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
	at org.spark_project.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
	at org.spark_project.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
	at java.lang.Thread.run(Thread.java:745)
2021-12-06 17:11:40,157 [SparkUI-108] WARN [org.spark_project.jetty.servlet.ServletHandler] - Error for /static/timeline-view.js
java.lang.NoSuchMethodError: javax.servlet.http.HttpServletRequest.isAsyncSupported()Z
	at org.spark_project.jetty.servlet.DefaultServlet.sendData(DefaultServlet.java:909)
	at org.spark_project.jetty.servlet.DefaultServlet.doGet(DefaultServlet.java:526)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:707)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:820)
	at org.spark_project.jetty.servlet.ServletHolder.handle(ServletHolder.java:848)
	at org.spark_project.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:584)
	at org.spark_project.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
	at org.spark_project.jetty.servlet.ServletHandler.doScope(ServletHandler.java:512)
	at org.spark_project.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
	at org.spark_project.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.spark_project.jetty.server.handler.gzip.GzipHandler.handle(GzipHandler.java:493)
	at org.spark_project.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:213)
	at org.spark_project.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
	at org.spark_project.jetty.server.Server.handle(Server.java:534)
	at org.spark_project.jetty.server.HttpChannel.handle(HttpChannel.java:320)
	at org.spark_project.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
	at org.spark_project.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
	at org.spark_project.jetty.io.FillInterest.fillable(FillInterest.java:108)
	at org.spark_project.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
	at org.spark_project.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
	at org.spark_project.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
	at java.lang.Thread.run(Thread.java:745)
2021-12-06 17:11:40,157 [SparkUI-39] WARN [org.spark_project.jetty.servlet.ServletHandler] - Error for /static/additional-metrics.js
java.lang.NoSuchMethodError: javax.servlet.http.HttpServletRequest.isAsyncSupported()Z
	at org.spark_project.jetty.servlet.DefaultServlet.sendData(DefaultServlet.java:909)
	at org.spark_project.jetty.servlet.DefaultServlet.doGet(DefaultServlet.java:526)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:707)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:820)
	at org.spark_project.jetty.servlet.ServletHolder.handle(ServletHolder.java:848)
	at org.spark_project.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:584)
	at org.spark_project.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
	at org.spark_project.jetty.servlet.ServletHandler.doScope(ServletHandler.java:512)
	at org.spark_project.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
	at org.spark_project.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.spark_project.jetty.server.handler.gzip.GzipHandler.handle(GzipHandler.java:493)
	at org.spark_project.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:213)
	at org.spark_project.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
	at org.spark_project.jetty.server.Server.handle(Server.java:534)
	at org.spark_project.jetty.server.HttpChannel.handle(HttpChannel.java:320)
	at org.spark_project.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
	at org.spark_project.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
	at org.spark_project.jetty.io.FillInterest.fillable(FillInterest.java:108)
	at org.spark_project.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
	at org.spark_project.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
	at org.spark_project.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
	at java.lang.Thread.run(Thread.java:745)
2021-12-06 17:11:40,161 [SparkUI-39] WARN [org.spark_project.jetty.server.HttpChannel] - //qb:4040/static/additional-metrics.js
java.lang.NoSuchMethodError: javax.servlet.http.HttpServletRequest.isAsyncStarted()Z
	at org.spark_project.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:688)
	at org.spark_project.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
	at org.spark_project.jetty.servlet.ServletHandler.doScope(ServletHandler.java:512)
	at org.spark_project.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
	at org.spark_project.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.spark_project.jetty.server.handler.gzip.GzipHandler.handle(GzipHandler.java:493)
	at org.spark_project.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:213)
	at org.spark_project.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
	at org.spark_project.jetty.server.Server.handle(Server.java:534)
	at org.spark_project.jetty.server.HttpChannel.handle(HttpChannel.java:320)
	at org.spark_project.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
	at org.spark_project.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
	at org.spark_project.jetty.io.FillInterest.fillable(FillInterest.java:108)
	at org.spark_project.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
	at org.spark_project.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
	at org.spark_project.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
	at java.lang.Thread.run(Thread.java:745)
2021-12-06 17:11:40,161 [SparkUI-113] WARN [org.spark_project.jetty.server.HttpChannel] - //qb:4040/static/jquery-1.11.1.min.js
java.lang.NoSuchMethodError: javax.servlet.http.HttpServletRequest.isAsyncStarted()Z
	at org.spark_project.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:688)
	at org.spark_project.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
	at org.spark_project.jetty.servlet.ServletHandler.doScope(ServletHandler.java:512)
	at org.spark_project.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
	at org.spark_project.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.spark_project.jetty.server.handler.gzip.GzipHandler.handle(GzipHandler.java:493)
	at org.spark_project.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:213)
	at org.spark_project.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
	at org.spark_project.jetty.server.Server.handle(Server.java:534)
	at org.spark_project.jetty.server.HttpChannel.handle(HttpChannel.java:320)
	at org.spark_project.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
	at org.spark_project.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
	at org.spark_project.jetty.io.FillInterest.fillable(FillInterest.java:108)
	at org.spark_project.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
	at org.spark_project.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
	at org.spark_project.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
	at java.lang.Thread.run(Thread.java:745)
2021-12-06 17:11:40,161 [SparkUI-108] WARN [org.spark_project.jetty.server.HttpChannel] - //qb:4040/static/timeline-view.js
java.lang.NoSuchMethodError: javax.servlet.http.HttpServletRequest.isAsyncStarted()Z
	at org.spark_project.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:688)
	at org.spark_project.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
	at org.spark_project.jetty.servlet.ServletHandler.doScope(ServletHandler.java:512)
	at org.spark_project.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
	at org.spark_project.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.spark_project.jetty.server.handler.gzip.GzipHandler.handle(GzipHandler.java:493)
	at org.spark_project.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:213)
	at org.spark_project.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
	at org.spark_project.jetty.server.Server.handle(Server.java:534)
	at org.spark_project.jetty.server.HttpChannel.handle(HttpChannel.java:320)
	at org.spark_project.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
	at org.spark_project.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
	at org.spark_project.jetty.io.FillInterest.fillable(FillInterest.java:108)
	at org.spark_project.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
	at org.spark_project.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
	at org.spark_project.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
	at java.lang.Thread.run(Thread.java:745)
2021-12-06 17:11:40,163 [SparkUI-107] INFO [org.spark_project.jetty.servlet.DefaultServlet] - content=ResourceHttpContent@1f2d4519{r=jar:file:/C:/Users/ACER/.m2/repository/org/apache/spark/spark-core_2.11/2.3.0/spark-core_2.11-2.3.0.jar!/org/apache/spark/ui/static/d3.min.js,gz=false}
2021-12-06 17:11:40,163 [SparkUI-112] INFO [org.spark_project.jetty.servlet.DefaultServlet] - content=ResourceHttpContent@331890a2{r=jar:file:/C:/Users/ACER/.m2/repository/org/apache/spark/spark-core_2.11/2.3.0/spark-core_2.11-2.3.0.jar!/org/apache/spark/ui/static/table.js,gz=false}
2021-12-06 17:11:40,163 [SparkUI-112] WARN [org.spark_project.jetty.servlet.ServletHandler] - Error for /static/table.js
java.lang.NoSuchMethodError: javax.servlet.http.HttpServletRequest.isAsyncSupported()Z
	at org.spark_project.jetty.servlet.DefaultServlet.sendData(DefaultServlet.java:909)
	at org.spark_project.jetty.servlet.DefaultServlet.doGet(DefaultServlet.java:526)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:707)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:820)
	at org.spark_project.jetty.servlet.ServletHolder.handle(ServletHolder.java:848)
	at org.spark_project.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:584)
	at org.spark_project.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
	at org.spark_project.jetty.servlet.ServletHandler.doScope(ServletHandler.java:512)
	at org.spark_project.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
	at org.spark_project.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.spark_project.jetty.server.handler.gzip.GzipHandler.handle(GzipHandler.java:493)
	at org.spark_project.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:213)
	at org.spark_project.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
	at org.spark_project.jetty.server.Server.handle(Server.java:534)
	at org.spark_project.jetty.server.HttpChannel.handle(HttpChannel.java:320)
	at org.spark_project.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
	at org.spark_project.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
	at org.spark_project.jetty.io.FillInterest.fillable(FillInterest.java:108)
	at org.spark_project.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
	at org.spark_project.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
	at org.spark_project.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
	at java.lang.Thread.run(Thread.java:745)
2021-12-06 17:11:40,164 [SparkUI-112] WARN [org.spark_project.jetty.server.HttpChannel] - //qb:4040/static/table.js
java.lang.NoSuchMethodError: javax.servlet.http.HttpServletRequest.isAsyncStarted()Z
	at org.spark_project.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:688)
	at org.spark_project.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
	at org.spark_project.jetty.servlet.ServletHandler.doScope(ServletHandler.java:512)
	at org.spark_project.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
	at org.spark_project.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.spark_project.jetty.server.handler.gzip.GzipHandler.handle(GzipHandler.java:493)
	at org.spark_project.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:213)
	at org.spark_project.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
	at org.spark_project.jetty.server.Server.handle(Server.java:534)
	at org.spark_project.jetty.server.HttpChannel.handle(HttpChannel.java:320)
	at org.spark_project.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
	at org.spark_project.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
	at org.spark_project.jetty.io.FillInterest.fillable(FillInterest.java:108)
	at org.spark_project.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
	at org.spark_project.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
	at org.spark_project.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
	at java.lang.Thread.run(Thread.java:745)
2021-12-06 17:11:40,165 [SparkUI-38] INFO [org.spark_project.jetty.servlet.DefaultServlet] - content=ResourceHttpContent@76602fd0{r=jar:file:/C:/Users/ACER/.m2/repository/org/apache/spark/spark-core_2.11/2.3.0/spark-core_2.11-2.3.0.jar!/org/apache/spark/ui/static/webui.js,gz=false}
2021-12-06 17:11:40,165 [SparkUI-38] WARN [org.spark_project.jetty.servlet.ServletHandler] - Error for /static/webui.js
java.lang.NoSuchMethodError: javax.servlet.http.HttpServletRequest.isAsyncSupported()Z
	at org.spark_project.jetty.servlet.DefaultServlet.sendData(DefaultServlet.java:909)
	at org.spark_project.jetty.servlet.DefaultServlet.doGet(DefaultServlet.java:526)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:707)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:820)
	at org.spark_project.jetty.servlet.ServletHolder.handle(ServletHolder.java:848)
	at org.spark_project.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:584)
	at org.spark_project.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
	at org.spark_project.jetty.servlet.ServletHandler.doScope(ServletHandler.java:512)
	at org.spark_project.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
	at org.spark_project.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.spark_project.jetty.server.handler.gzip.GzipHandler.handle(GzipHandler.java:493)
	at org.spark_project.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:213)
	at org.spark_project.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
	at org.spark_project.jetty.server.Server.handle(Server.java:534)
	at org.spark_project.jetty.server.HttpChannel.handle(HttpChannel.java:320)
	at org.spark_project.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
	at org.spark_project.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
	at org.spark_project.jetty.io.FillInterest.fillable(FillInterest.java:108)
	at org.spark_project.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
	at org.spark_project.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
	at org.spark_project.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
	at java.lang.Thread.run(Thread.java:745)
2021-12-06 17:11:40,166 [SparkUI-38] WARN [org.spark_project.jetty.server.HttpChannel] - //qb:4040/static/webui.js
java.lang.NoSuchMethodError: javax.servlet.http.HttpServletRequest.isAsyncStarted()Z
	at org.spark_project.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:688)
	at org.spark_project.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
	at org.spark_project.jetty.servlet.ServletHandler.doScope(ServletHandler.java:512)
	at org.spark_project.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
	at org.spark_project.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.spark_project.jetty.server.handler.gzip.GzipHandler.handle(GzipHandler.java:493)
	at org.spark_project.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:213)
	at org.spark_project.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
	at org.spark_project.jetty.server.Server.handle(Server.java:534)
	at org.spark_project.jetty.server.HttpChannel.handle(HttpChannel.java:320)
	at org.spark_project.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
	at org.spark_project.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
	at org.spark_project.jetty.io.FillInterest.fillable(FillInterest.java:108)
	at org.spark_project.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
	at org.spark_project.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
	at org.spark_project.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
	at java.lang.Thread.run(Thread.java:745)
2021-12-06 17:11:40,164 [SparkUI-107] WARN [org.spark_project.jetty.servlet.ServletHandler] - Error for /static/d3.min.js
java.lang.NoSuchMethodError: javax.servlet.http.HttpServletRequest.isAsyncSupported()Z
	at org.spark_project.jetty.servlet.DefaultServlet.sendData(DefaultServlet.java:909)
	at org.spark_project.jetty.servlet.DefaultServlet.doGet(DefaultServlet.java:526)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:707)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:820)
	at org.spark_project.jetty.servlet.ServletHolder.handle(ServletHolder.java:848)
	at org.spark_project.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:584)
	at org.spark_project.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
	at org.spark_project.jetty.servlet.ServletHandler.doScope(ServletHandler.java:512)
	at org.spark_project.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
	at org.spark_project.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.spark_project.jetty.server.handler.gzip.GzipHandler.handle(GzipHandler.java:493)
	at org.spark_project.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:213)
	at org.spark_project.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
	at org.spark_project.jetty.server.Server.handle(Server.java:534)
	at org.spark_project.jetty.server.HttpChannel.handle(HttpChannel.java:320)
	at org.spark_project.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
	at org.spark_project.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
	at org.spark_project.jetty.io.FillInterest.fillable(FillInterest.java:108)
	at org.spark_project.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
	at org.spark_project.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
	at org.spark_project.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
	at java.lang.Thread.run(Thread.java:745)
2021-12-06 17:11:40,167 [SparkUI-107] WARN [org.spark_project.jetty.server.HttpChannel] - //qb:4040/static/d3.min.js
java.lang.NoSuchMethodError: javax.servlet.http.HttpServletRequest.isAsyncStarted()Z
	at org.spark_project.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:688)
	at org.spark_project.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
	at org.spark_project.jetty.servlet.ServletHandler.doScope(ServletHandler.java:512)
	at org.spark_project.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
	at org.spark_project.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.spark_project.jetty.server.handler.gzip.GzipHandler.handle(GzipHandler.java:493)
	at org.spark_project.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:213)
	at org.spark_project.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
	at org.spark_project.jetty.server.Server.handle(Server.java:534)
	at org.spark_project.jetty.server.HttpChannel.handle(HttpChannel.java:320)
	at org.spark_project.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
	at org.spark_project.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
	at org.spark_project.jetty.io.FillInterest.fillable(FillInterest.java:108)
	at org.spark_project.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
	at org.spark_project.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
	at org.spark_project.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
	at java.lang.Thread.run(Thread.java:745)
2021-12-06 17:11:40,168 [SparkUI-108] INFO [org.spark_project.jetty.servlet.DefaultServlet] - content=ResourceHttpContent@1561c5b0{r=jar:file:/C:/Users/ACER/.m2/repository/org/apache/spark/spark-core_2.11/2.3.0/spark-core_2.11-2.3.0.jar!/org/apache/spark/ui/static/dagre-d3.min.js,gz=false}
2021-12-06 17:11:40,168 [SparkUI-108] WARN [org.spark_project.jetty.servlet.ServletHandler] - Error for /static/dagre-d3.min.js
java.lang.NoSuchMethodError: javax.servlet.http.HttpServletRequest.isAsyncSupported()Z
	at org.spark_project.jetty.servlet.DefaultServlet.sendData(DefaultServlet.java:909)
	at org.spark_project.jetty.servlet.DefaultServlet.doGet(DefaultServlet.java:526)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:707)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:820)
	at org.spark_project.jetty.servlet.ServletHolder.handle(ServletHolder.java:848)
	at org.spark_project.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:584)
	at org.spark_project.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
	at org.spark_project.jetty.servlet.ServletHandler.doScope(ServletHandler.java:512)
	at org.spark_project.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
	at org.spark_project.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.spark_project.jetty.server.handler.gzip.GzipHandler.handle(GzipHandler.java:493)
	at org.spark_project.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:213)
	at org.spark_project.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
	at org.spark_project.jetty.server.Server.handle(Server.java:534)
	at org.spark_project.jetty.server.HttpChannel.handle(HttpChannel.java:320)
	at org.spark_project.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
	at org.spark_project.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
	at org.spark_project.jetty.io.FillInterest.fillable(FillInterest.java:108)
	at org.spark_project.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
	at org.spark_project.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
	at org.spark_project.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
	at java.lang.Thread.run(Thread.java:745)
2021-12-06 17:11:40,168 [SparkUI-108] WARN [org.spark_project.jetty.server.HttpChannel] - //qb:4040/static/dagre-d3.min.js
java.lang.NoSuchMethodError: javax.servlet.http.HttpServletRequest.isAsyncStarted()Z
	at org.spark_project.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:688)
	at org.spark_project.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
	at org.spark_project.jetty.servlet.ServletHandler.doScope(ServletHandler.java:512)
	at org.spark_project.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
	at org.spark_project.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.spark_project.jetty.server.handler.gzip.GzipHandler.handle(GzipHandler.java:493)
	at org.spark_project.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:213)
	at org.spark_project.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
	at org.spark_project.jetty.server.Server.handle(Server.java:534)
	at org.spark_project.jetty.server.HttpChannel.handle(HttpChannel.java:320)
	at org.spark_project.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
	at org.spark_project.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
	at org.spark_project.jetty.io.FillInterest.fillable(FillInterest.java:108)
	at org.spark_project.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
	at org.spark_project.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
	at org.spark_project.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
	at java.lang.Thread.run(Thread.java:745)
2021-12-06 17:11:40,168 [SparkUI-43] INFO [org.spark_project.jetty.servlet.DefaultServlet] - content=ResourceHttpContent@1db6c3c0{r=jar:file:/C:/Users/ACER/.m2/repository/org/apache/spark/spark-core_2.11/2.3.0/spark-core_2.11-2.3.0.jar!/org/apache/spark/ui/static/graphlib-dot.min.js,gz=false}
2021-12-06 17:11:40,169 [SparkUI-43] WARN [org.spark_project.jetty.servlet.ServletHandler] - Error for /static/graphlib-dot.min.js
java.lang.NoSuchMethodError: javax.servlet.http.HttpServletRequest.isAsyncSupported()Z
	at org.spark_project.jetty.servlet.DefaultServlet.sendData(DefaultServlet.java:909)
	at org.spark_project.jetty.servlet.DefaultServlet.doGet(DefaultServlet.java:526)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:707)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:820)
	at org.spark_project.jetty.servlet.ServletHolder.handle(ServletHolder.java:848)
	at org.spark_project.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:584)
	at org.spark_project.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
	at org.spark_project.jetty.servlet.ServletHandler.doScope(ServletHandler.java:512)
	at org.spark_project.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
	at org.spark_project.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.spark_project.jetty.server.handler.gzip.GzipHandler.handle(GzipHandler.java:493)
	at org.spark_project.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:213)
	at org.spark_project.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
	at org.spark_project.jetty.server.Server.handle(Server.java:534)
	at org.spark_project.jetty.server.HttpChannel.handle(HttpChannel.java:320)
	at org.spark_project.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
	at org.spark_project.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
	at org.spark_project.jetty.io.FillInterest.fillable(FillInterest.java:108)
	at org.spark_project.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
	at org.spark_project.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
	at org.spark_project.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
	at java.lang.Thread.run(Thread.java:745)
2021-12-06 17:11:40,169 [SparkUI-43] WARN [org.spark_project.jetty.server.HttpChannel] - //qb:4040/static/graphlib-dot.min.js
java.lang.NoSuchMethodError: javax.servlet.http.HttpServletRequest.isAsyncStarted()Z
	at org.spark_project.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:688)
	at org.spark_project.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
	at org.spark_project.jetty.servlet.ServletHandler.doScope(ServletHandler.java:512)
	at org.spark_project.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
	at org.spark_project.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.spark_project.jetty.server.handler.gzip.GzipHandler.handle(GzipHandler.java:493)
	at org.spark_project.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:213)
	at org.spark_project.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
	at org.spark_project.jetty.server.Server.handle(Server.java:534)
	at org.spark_project.jetty.server.HttpChannel.handle(HttpChannel.java:320)
	at org.spark_project.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
	at org.spark_project.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
	at org.spark_project.jetty.io.FillInterest.fillable(FillInterest.java:108)
	at org.spark_project.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
	at org.spark_project.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
	at org.spark_project.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
	at java.lang.Thread.run(Thread.java:745)
2021-12-06 17:11:40,169 [SparkUI-111] INFO [org.spark_project.jetty.servlet.DefaultServlet] - content=ResourceHttpContent@635e8150{r=jar:file:/C:/Users/ACER/.m2/repository/org/apache/spark/spark-core_2.11/2.3.0/spark-core_2.11-2.3.0.jar!/org/apache/spark/ui/static/spark-dag-viz.js,gz=false}
2021-12-06 17:11:40,169 [SparkUI-111] WARN [org.spark_project.jetty.servlet.ServletHandler] - Error for /static/spark-dag-viz.js
java.lang.NoSuchMethodError: javax.servlet.http.HttpServletRequest.isAsyncSupported()Z
	at org.spark_project.jetty.servlet.DefaultServlet.sendData(DefaultServlet.java:909)
	at org.spark_project.jetty.servlet.DefaultServlet.doGet(DefaultServlet.java:526)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:707)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:820)
	at org.spark_project.jetty.servlet.ServletHolder.handle(ServletHolder.java:848)
	at org.spark_project.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:584)
	at org.spark_project.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
	at org.spark_project.jetty.servlet.ServletHandler.doScope(ServletHandler.java:512)
	at org.spark_project.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
	at org.spark_project.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.spark_project.jetty.server.handler.gzip.GzipHandler.handle(GzipHandler.java:493)
	at org.spark_project.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:213)
	at org.spark_project.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
	at org.spark_project.jetty.server.Server.handle(Server.java:534)
	at org.spark_project.jetty.server.HttpChannel.handle(HttpChannel.java:320)
	at org.spark_project.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
	at org.spark_project.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
	at org.spark_project.jetty.io.FillInterest.fillable(FillInterest.java:108)
	at org.spark_project.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
	at org.spark_project.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
	at org.spark_project.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
	at java.lang.Thread.run(Thread.java:745)
2021-12-06 17:11:40,169 [SparkUI-111] WARN [org.spark_project.jetty.server.HttpChannel] - //qb:4040/static/spark-dag-viz.js
java.lang.NoSuchMethodError: javax.servlet.http.HttpServletRequest.isAsyncStarted()Z
	at org.spark_project.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:688)
	at org.spark_project.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
	at org.spark_project.jetty.servlet.ServletHandler.doScope(ServletHandler.java:512)
	at org.spark_project.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
	at org.spark_project.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.spark_project.jetty.server.handler.gzip.GzipHandler.handle(GzipHandler.java:493)
	at org.spark_project.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:213)
	at org.spark_project.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
	at org.spark_project.jetty.server.Server.handle(Server.java:534)
	at org.spark_project.jetty.server.HttpChannel.handle(HttpChannel.java:320)
	at org.spark_project.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
	at org.spark_project.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
	at org.spark_project.jetty.io.FillInterest.fillable(FillInterest.java:108)
	at org.spark_project.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
	at org.spark_project.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
	at org.spark_project.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
	at java.lang.Thread.run(Thread.java:745)
2021-12-06 17:11:40,196 [SparkUI-112] INFO [org.spark_project.jetty.servlet.DefaultServlet] - content=ResourceHttpContent@2d5e5f3b{r=jar:file:/C:/Users/ACER/.m2/repository/org/apache/spark/spark-core_2.11/2.3.0/spark-core_2.11-2.3.0.jar!/org/apache/spark/ui/static/spark-logo-77x50px-hd.png,gz=false}
2021-12-06 17:11:40,196 [SparkUI-112] WARN [org.spark_project.jetty.servlet.ServletHandler] - Error for /static/spark-logo-77x50px-hd.png
java.lang.NoSuchMethodError: javax.servlet.http.HttpServletRequest.isAsyncSupported()Z
	at org.spark_project.jetty.servlet.DefaultServlet.sendData(DefaultServlet.java:909)
	at org.spark_project.jetty.servlet.DefaultServlet.doGet(DefaultServlet.java:526)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:707)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:820)
	at org.spark_project.jetty.servlet.ServletHolder.handle(ServletHolder.java:848)
	at org.spark_project.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:584)
	at org.spark_project.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
	at org.spark_project.jetty.servlet.ServletHandler.doScope(ServletHandler.java:512)
	at org.spark_project.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
	at org.spark_project.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.spark_project.jetty.server.handler.gzip.GzipHandler.handle(GzipHandler.java:448)
	at org.spark_project.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:213)
	at org.spark_project.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
	at org.spark_project.jetty.server.Server.handle(Server.java:534)
	at org.spark_project.jetty.server.HttpChannel.handle(HttpChannel.java:320)
	at org.spark_project.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
	at org.spark_project.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
	at org.spark_project.jetty.io.FillInterest.fillable(FillInterest.java:108)
	at org.spark_project.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
	at org.spark_project.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
	at org.spark_project.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
	at java.lang.Thread.run(Thread.java:745)
2021-12-06 17:11:40,196 [SparkUI-112] WARN [org.spark_project.jetty.server.HttpChannel] - //qb:4040/static/spark-logo-77x50px-hd.png
java.lang.NoSuchMethodError: javax.servlet.http.HttpServletRequest.isAsyncStarted()Z
	at org.spark_project.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:688)
	at org.spark_project.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
	at org.spark_project.jetty.servlet.ServletHandler.doScope(ServletHandler.java:512)
	at org.spark_project.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
	at org.spark_project.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.spark_project.jetty.server.handler.gzip.GzipHandler.handle(GzipHandler.java:448)
	at org.spark_project.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:213)
	at org.spark_project.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
	at org.spark_project.jetty.server.Server.handle(Server.java:534)
	at org.spark_project.jetty.server.HttpChannel.handle(HttpChannel.java:320)
	at org.spark_project.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
	at org.spark_project.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
	at org.spark_project.jetty.io.FillInterest.fillable(FillInterest.java:108)
	at org.spark_project.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
	at org.spark_project.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
	at org.spark_project.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
	at java.lang.Thread.run(Thread.java:745)
2021-12-06 17:11:44,126 [SparkUI-111] INFO [org.spark_project.jetty.servlet.DefaultServlet] - content=ResourceHttpContent@46c01bee{r=jar:file:/C:/Users/ACER/.m2/repository/org/apache/spark/spark-core_2.11/2.3.0/spark-core_2.11-2.3.0.jar!/org/apache/spark/ui/static/bootstrap.min.css,gz=false}
2021-12-06 17:11:44,126 [SparkUI-111] WARN [org.spark_project.jetty.servlet.ServletHandler] - Error for /static/bootstrap.min.css
java.lang.NoSuchMethodError: javax.servlet.http.HttpServletRequest.isAsyncSupported()Z
	at org.spark_project.jetty.servlet.DefaultServlet.sendData(DefaultServlet.java:909)
	at org.spark_project.jetty.servlet.DefaultServlet.doGet(DefaultServlet.java:526)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:707)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:820)
	at org.spark_project.jetty.servlet.ServletHolder.handle(ServletHolder.java:848)
	at org.spark_project.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:584)
	at org.spark_project.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
	at org.spark_project.jetty.servlet.ServletHandler.doScope(ServletHandler.java:512)
	at org.spark_project.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
	at org.spark_project.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.spark_project.jetty.server.handler.gzip.GzipHandler.handle(GzipHandler.java:493)
	at org.spark_project.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:213)
	at org.spark_project.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
	at org.spark_project.jetty.server.Server.handle(Server.java:534)
	at org.spark_project.jetty.server.HttpChannel.handle(HttpChannel.java:320)
	at org.spark_project.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
	at org.spark_project.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
	at org.spark_project.jetty.io.FillInterest.fillable(FillInterest.java:108)
	at org.spark_project.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
	at org.spark_project.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
	at org.spark_project.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
	at java.lang.Thread.run(Thread.java:745)
2021-12-06 17:11:44,126 [SparkUI-111] WARN [org.spark_project.jetty.server.HttpChannel] - //qb:4040/static/bootstrap.min.css
java.lang.NoSuchMethodError: javax.servlet.http.HttpServletRequest.isAsyncStarted()Z
	at org.spark_project.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:688)
	at org.spark_project.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
	at org.spark_project.jetty.servlet.ServletHandler.doScope(ServletHandler.java:512)
	at org.spark_project.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
	at org.spark_project.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.spark_project.jetty.server.handler.gzip.GzipHandler.handle(GzipHandler.java:493)
	at org.spark_project.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:213)
	at org.spark_project.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
	at org.spark_project.jetty.server.Server.handle(Server.java:534)
	at org.spark_project.jetty.server.HttpChannel.handle(HttpChannel.java:320)
	at org.spark_project.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
	at org.spark_project.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
	at org.spark_project.jetty.io.FillInterest.fillable(FillInterest.java:108)
	at org.spark_project.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
	at org.spark_project.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
	at org.spark_project.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
	at java.lang.Thread.run(Thread.java:745)
2021-12-06 17:11:44,128 [SparkUI-107] INFO [org.spark_project.jetty.servlet.DefaultServlet] - content=ResourceHttpContent@53b6914a{r=jar:file:/C:/Users/ACER/.m2/repository/org/apache/spark/spark-core_2.11/2.3.0/spark-core_2.11-2.3.0.jar!/org/apache/spark/ui/static/vis.min.css,gz=false}
2021-12-06 17:11:44,128 [SparkUI-107] WARN [org.spark_project.jetty.servlet.ServletHandler] - Error for /static/vis.min.css
java.lang.NoSuchMethodError: javax.servlet.http.HttpServletRequest.isAsyncSupported()Z
	at org.spark_project.jetty.servlet.DefaultServlet.sendData(DefaultServlet.java:909)
	at org.spark_project.jetty.servlet.DefaultServlet.doGet(DefaultServlet.java:526)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:707)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:820)
	at org.spark_project.jetty.servlet.ServletHolder.handle(ServletHolder.java:848)
	at org.spark_project.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:584)
	at org.spark_project.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
	at org.spark_project.jetty.servlet.ServletHandler.doScope(ServletHandler.java:512)
	at org.spark_project.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
	at org.spark_project.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.spark_project.jetty.server.handler.gzip.GzipHandler.handle(GzipHandler.java:493)
	at org.spark_project.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:213)
	at org.spark_project.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
	at org.spark_project.jetty.server.Server.handle(Server.java:534)
	at org.spark_project.jetty.server.HttpChannel.handle(HttpChannel.java:320)
	at org.spark_project.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
	at org.spark_project.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
	at org.spark_project.jetty.io.FillInterest.fillable(FillInterest.java:108)
	at org.spark_project.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
	at org.spark_project.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
	at org.spark_project.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
	at java.lang.Thread.run(Thread.java:745)
2021-12-06 17:11:44,128 [SparkUI-107] WARN [org.spark_project.jetty.server.HttpChannel] - //qb:4040/static/vis.min.css
java.lang.NoSuchMethodError: javax.servlet.http.HttpServletRequest.isAsyncStarted()Z
	at org.spark_project.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:688)
	at org.spark_project.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
	at org.spark_project.jetty.servlet.ServletHandler.doScope(ServletHandler.java:512)
	at org.spark_project.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
	at org.spark_project.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.spark_project.jetty.server.handler.gzip.GzipHandler.handle(GzipHandler.java:493)
	at org.spark_project.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:213)
	at org.spark_project.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
	at org.spark_project.jetty.server.Server.handle(Server.java:534)
	at org.spark_project.jetty.server.HttpChannel.handle(HttpChannel.java:320)
	at org.spark_project.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
	at org.spark_project.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
	at org.spark_project.jetty.io.FillInterest.fillable(FillInterest.java:108)
	at org.spark_project.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
	at org.spark_project.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
	at org.spark_project.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
	at java.lang.Thread.run(Thread.java:745)
2021-12-06 17:11:44,129 [SparkUI-112] INFO [org.spark_project.jetty.servlet.DefaultServlet] - content=ResourceHttpContent@68337fc5{r=jar:file:/C:/Users/ACER/.m2/repository/org/apache/spark/spark-core_2.11/2.3.0/spark-core_2.11-2.3.0.jar!/org/apache/spark/ui/static/webui.css,gz=false}
2021-12-06 17:11:44,129 [SparkUI-112] WARN [org.spark_project.jetty.servlet.ServletHandler] - Error for /static/webui.css
java.lang.NoSuchMethodError: javax.servlet.http.HttpServletRequest.isAsyncSupported()Z
	at org.spark_project.jetty.servlet.DefaultServlet.sendData(DefaultServlet.java:909)
	at org.spark_project.jetty.servlet.DefaultServlet.doGet(DefaultServlet.java:526)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:707)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:820)
	at org.spark_project.jetty.servlet.ServletHolder.handle(ServletHolder.java:848)
	at org.spark_project.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:584)
	at org.spark_project.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
	at org.spark_project.jetty.servlet.ServletHandler.doScope(ServletHandler.java:512)
	at org.spark_project.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
	at org.spark_project.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.spark_project.jetty.server.handler.gzip.GzipHandler.handle(GzipHandler.java:493)
	at org.spark_project.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:213)
	at org.spark_project.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
	at org.spark_project.jetty.server.Server.handle(Server.java:534)
	at org.spark_project.jetty.server.HttpChannel.handle(HttpChannel.java:320)
	at org.spark_project.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
	at org.spark_project.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
	at org.spark_project.jetty.io.FillInterest.fillable(FillInterest.java:108)
	at org.spark_project.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
	at org.spark_project.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
	at org.spark_project.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
	at java.lang.Thread.run(Thread.java:745)
2021-12-06 17:11:44,129 [SparkUI-112] WARN [org.spark_project.jetty.server.HttpChannel] - //qb:4040/static/webui.css
java.lang.NoSuchMethodError: javax.servlet.http.HttpServletRequest.isAsyncStarted()Z
	at org.spark_project.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:688)
	at org.spark_project.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
	at org.spark_project.jetty.servlet.ServletHandler.doScope(ServletHandler.java:512)
	at org.spark_project.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
	at org.spark_project.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.spark_project.jetty.server.handler.gzip.GzipHandler.handle(GzipHandler.java:493)
	at org.spark_project.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:213)
	at org.spark_project.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
	at org.spark_project.jetty.server.Server.handle(Server.java:534)
	at org.spark_project.jetty.server.HttpChannel.handle(HttpChannel.java:320)
	at org.spark_project.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
	at org.spark_project.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
	at org.spark_project.jetty.io.FillInterest.fillable(FillInterest.java:108)
	at org.spark_project.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
	at org.spark_project.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
	at org.spark_project.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
	at java.lang.Thread.run(Thread.java:745)
2021-12-06 17:11:44,130 [SparkUI-38] INFO [org.spark_project.jetty.servlet.DefaultServlet] - content=ResourceHttpContent@6035dcf{r=jar:file:/C:/Users/ACER/.m2/repository/org/apache/spark/spark-core_2.11/2.3.0/spark-core_2.11-2.3.0.jar!/org/apache/spark/ui/static/timeline-view.css,gz=false}
2021-12-06 17:11:44,130 [SparkUI-38] WARN [org.spark_project.jetty.servlet.ServletHandler] - Error for /static/timeline-view.css
java.lang.NoSuchMethodError: javax.servlet.http.HttpServletRequest.isAsyncSupported()Z
	at org.spark_project.jetty.servlet.DefaultServlet.sendData(DefaultServlet.java:909)
	at org.spark_project.jetty.servlet.DefaultServlet.doGet(DefaultServlet.java:526)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:707)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:820)
	at org.spark_project.jetty.servlet.ServletHolder.handle(ServletHolder.java:848)
	at org.spark_project.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:584)
	at org.spark_project.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
	at org.spark_project.jetty.servlet.ServletHandler.doScope(ServletHandler.java:512)
	at org.spark_project.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
	at org.spark_project.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.spark_project.jetty.server.handler.gzip.GzipHandler.handle(GzipHandler.java:493)
	at org.spark_project.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:213)
	at org.spark_project.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
	at org.spark_project.jetty.server.Server.handle(Server.java:534)
	at org.spark_project.jetty.server.HttpChannel.handle(HttpChannel.java:320)
	at org.spark_project.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
	at org.spark_project.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
	at org.spark_project.jetty.io.FillInterest.fillable(FillInterest.java:108)
	at org.spark_project.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
	at org.spark_project.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
	at org.spark_project.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
	at java.lang.Thread.run(Thread.java:745)
2021-12-06 17:11:44,130 [SparkUI-38] WARN [org.spark_project.jetty.server.HttpChannel] - //qb:4040/static/timeline-view.css
java.lang.NoSuchMethodError: javax.servlet.http.HttpServletRequest.isAsyncStarted()Z
	at org.spark_project.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:688)
	at org.spark_project.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
	at org.spark_project.jetty.servlet.ServletHandler.doScope(ServletHandler.java:512)
	at org.spark_project.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
	at org.spark_project.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.spark_project.jetty.server.handler.gzip.GzipHandler.handle(GzipHandler.java:493)
	at org.spark_project.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:213)
	at org.spark_project.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
	at org.spark_project.jetty.server.Server.handle(Server.java:534)
	at org.spark_project.jetty.server.HttpChannel.handle(HttpChannel.java:320)
	at org.spark_project.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
	at org.spark_project.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
	at org.spark_project.jetty.io.FillInterest.fillable(FillInterest.java:108)
	at org.spark_project.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
	at org.spark_project.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
	at org.spark_project.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
	at java.lang.Thread.run(Thread.java:745)
2021-12-06 17:11:44,131 [SparkUI-114] INFO [org.spark_project.jetty.servlet.DefaultServlet] - content=ResourceHttpContent@41fcfb2c{r=jar:file:/C:/Users/ACER/.m2/repository/org/apache/spark/spark-core_2.11/2.3.0/spark-core_2.11-2.3.0.jar!/org/apache/spark/ui/static/bootstrap.min.css,gz=false}
2021-12-06 17:11:44,131 [SparkUI-114] WARN [org.spark_project.jetty.servlet.ServletHandler] - Error for /static/bootstrap.min.css
java.lang.NoSuchMethodError: javax.servlet.http.HttpServletRequest.isAsyncSupported()Z
	at org.spark_project.jetty.servlet.DefaultServlet.sendData(DefaultServlet.java:909)
	at org.spark_project.jetty.servlet.DefaultServlet.doGet(DefaultServlet.java:526)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:707)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:820)
	at org.spark_project.jetty.servlet.ServletHolder.handle(ServletHolder.java:848)
	at org.spark_project.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:584)
	at org.spark_project.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
	at org.spark_project.jetty.servlet.ServletHandler.doScope(ServletHandler.java:512)
	at org.spark_project.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
	at org.spark_project.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.spark_project.jetty.server.handler.gzip.GzipHandler.handle(GzipHandler.java:493)
	at org.spark_project.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:213)
	at org.spark_project.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
	at org.spark_project.jetty.server.Server.handle(Server.java:534)
	at org.spark_project.jetty.server.HttpChannel.handle(HttpChannel.java:320)
	at org.spark_project.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
	at org.spark_project.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
	at org.spark_project.jetty.io.FillInterest.fillable(FillInterest.java:108)
	at org.spark_project.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
	at org.spark_project.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
	at org.spark_project.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
	at java.lang.Thread.run(Thread.java:745)
2021-12-06 17:11:44,131 [SparkUI-114] WARN [org.spark_project.jetty.server.HttpChannel] - //qb:4040/static/bootstrap.min.css
java.lang.NoSuchMethodError: javax.servlet.http.HttpServletRequest.isAsyncStarted()Z
	at org.spark_project.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:688)
	at org.spark_project.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
	at org.spark_project.jetty.servlet.ServletHandler.doScope(ServletHandler.java:512)
	at org.spark_project.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
	at org.spark_project.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.spark_project.jetty.server.handler.gzip.GzipHandler.handle(GzipHandler.java:493)
	at org.spark_project.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:213)
	at org.spark_project.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
	at org.spark_project.jetty.server.Server.handle(Server.java:534)
	at org.spark_project.jetty.server.HttpChannel.handle(HttpChannel.java:320)
	at org.spark_project.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
	at org.spark_project.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
	at org.spark_project.jetty.io.FillInterest.fillable(FillInterest.java:108)
	at org.spark_project.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
	at org.spark_project.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
	at org.spark_project.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
	at java.lang.Thread.run(Thread.java:745)
2021-12-06 17:11:44,137 [SparkUI-113] INFO [org.spark_project.jetty.servlet.DefaultServlet] - content=ResourceHttpContent@3ab7ba4d{r=jar:file:/C:/Users/ACER/.m2/repository/org/apache/spark/spark-core_2.11/2.3.0/spark-core_2.11-2.3.0.jar!/org/apache/spark/ui/static/vis.min.css,gz=false}
2021-12-06 17:11:44,137 [SparkUI-113] WARN [org.spark_project.jetty.servlet.ServletHandler] - Error for /static/vis.min.css
java.lang.NoSuchMethodError: javax.servlet.http.HttpServletRequest.isAsyncSupported()Z
	at org.spark_project.jetty.servlet.DefaultServlet.sendData(DefaultServlet.java:909)
	at org.spark_project.jetty.servlet.DefaultServlet.doGet(DefaultServlet.java:526)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:707)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:820)
	at org.spark_project.jetty.servlet.ServletHolder.handle(ServletHolder.java:848)
	at org.spark_project.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:584)
	at org.spark_project.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
	at org.spark_project.jetty.servlet.ServletHandler.doScope(ServletHandler.java:512)
	at org.spark_project.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
	at org.spark_project.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.spark_project.jetty.server.handler.gzip.GzipHandler.handle(GzipHandler.java:493)
	at org.spark_project.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:213)
	at org.spark_project.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
	at org.spark_project.jetty.server.Server.handle(Server.java:534)
	at org.spark_project.jetty.server.HttpChannel.handle(HttpChannel.java:320)
	at org.spark_project.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
	at org.spark_project.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
	at org.spark_project.jetty.io.FillInterest.fillable(FillInterest.java:108)
	at org.spark_project.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
	at org.spark_project.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
	at org.spark_project.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
	at java.lang.Thread.run(Thread.java:745)
2021-12-06 17:11:44,137 [SparkUI-113] WARN [org.spark_project.jetty.server.HttpChannel] - //qb:4040/static/vis.min.css
java.lang.NoSuchMethodError: javax.servlet.http.HttpServletRequest.isAsyncStarted()Z
	at org.spark_project.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:688)
	at org.spark_project.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
	at org.spark_project.jetty.servlet.ServletHandler.doScope(ServletHandler.java:512)
	at org.spark_project.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
	at org.spark_project.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.spark_project.jetty.server.handler.gzip.GzipHandler.handle(GzipHandler.java:493)
	at org.spark_project.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:213)
	at org.spark_project.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
	at org.spark_project.jetty.server.Server.handle(Server.java:534)
	at org.spark_project.jetty.server.HttpChannel.handle(HttpChannel.java:320)
	at org.spark_project.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
	at org.spark_project.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
	at org.spark_project.jetty.io.FillInterest.fillable(FillInterest.java:108)
	at org.spark_project.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
	at org.spark_project.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
	at org.spark_project.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
	at java.lang.Thread.run(Thread.java:745)
2021-12-06 17:11:44,147 [SparkUI-114] INFO [org.spark_project.jetty.servlet.DefaultServlet] - content=ResourceHttpContent@4ca5c670{r=jar:file:/C:/Users/ACER/.m2/repository/org/apache/spark/spark-core_2.11/2.3.0/spark-core_2.11-2.3.0.jar!/org/apache/spark/ui/static/sorttable.js,gz=false}
2021-12-06 17:11:44,147 [SparkUI-114] WARN [org.spark_project.jetty.servlet.ServletHandler] - Error for /static/sorttable.js
java.lang.NoSuchMethodError: javax.servlet.http.HttpServletRequest.isAsyncSupported()Z
	at org.spark_project.jetty.servlet.DefaultServlet.sendData(DefaultServlet.java:909)
	at org.spark_project.jetty.servlet.DefaultServlet.doGet(DefaultServlet.java:526)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:707)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:820)
	at org.spark_project.jetty.servlet.ServletHolder.handle(ServletHolder.java:848)
	at org.spark_project.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:584)
	at org.spark_project.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
	at org.spark_project.jetty.servlet.ServletHandler.doScope(ServletHandler.java:512)
	at org.spark_project.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
	at org.spark_project.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.spark_project.jetty.server.handler.gzip.GzipHandler.handle(GzipHandler.java:493)
	at org.spark_project.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:213)
	at org.spark_project.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
	at org.spark_project.jetty.server.Server.handle(Server.java:534)
	at org.spark_project.jetty.server.HttpChannel.handle(HttpChannel.java:320)
	at org.spark_project.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
	at org.spark_project.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
	at org.spark_project.jetty.io.FillInterest.fillable(FillInterest.java:108)
	at org.spark_project.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
	at org.spark_project.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
	at org.spark_project.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
	at java.lang.Thread.run(Thread.java:745)
2021-12-06 17:11:44,147 [SparkUI-114] WARN [org.spark_project.jetty.server.HttpChannel] - //qb:4040/static/sorttable.js
java.lang.NoSuchMethodError: javax.servlet.http.HttpServletRequest.isAsyncStarted()Z
	at org.spark_project.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:688)
	at org.spark_project.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
	at org.spark_project.jetty.servlet.ServletHandler.doScope(ServletHandler.java:512)
	at org.spark_project.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
	at org.spark_project.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.spark_project.jetty.server.handler.gzip.GzipHandler.handle(GzipHandler.java:493)
	at org.spark_project.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:213)
	at org.spark_project.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
	at org.spark_project.jetty.server.Server.handle(Server.java:534)
	at org.spark_project.jetty.server.HttpChannel.handle(HttpChannel.java:320)
	at org.spark_project.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
	at org.spark_project.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
	at org.spark_project.jetty.io.FillInterest.fillable(FillInterest.java:108)
	at org.spark_project.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
	at org.spark_project.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
	at org.spark_project.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
	at java.lang.Thread.run(Thread.java:745)
2021-12-06 17:11:44,148 [SparkUI-111] INFO [org.spark_project.jetty.servlet.DefaultServlet] - content=ResourceHttpContent@630b22e4{r=jar:file:/C:/Users/ACER/.m2/repository/org/apache/spark/spark-core_2.11/2.3.0/spark-core_2.11-2.3.0.jar!/org/apache/spark/ui/static/bootstrap-tooltip.js,gz=false}
2021-12-06 17:11:44,148 [SparkUI-111] WARN [org.spark_project.jetty.servlet.ServletHandler] - Error for /static/bootstrap-tooltip.js
java.lang.NoSuchMethodError: javax.servlet.http.HttpServletRequest.isAsyncSupported()Z
	at org.spark_project.jetty.servlet.DefaultServlet.sendData(DefaultServlet.java:909)
	at org.spark_project.jetty.servlet.DefaultServlet.doGet(DefaultServlet.java:526)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:707)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:820)
	at org.spark_project.jetty.servlet.ServletHolder.handle(ServletHolder.java:848)
	at org.spark_project.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:584)
	at org.spark_project.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
	at org.spark_project.jetty.servlet.ServletHandler.doScope(ServletHandler.java:512)
	at org.spark_project.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
	at org.spark_project.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.spark_project.jetty.server.handler.gzip.GzipHandler.handle(GzipHandler.java:493)
	at org.spark_project.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:213)
	at org.spark_project.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
	at org.spark_project.jetty.server.Server.handle(Server.java:534)
	at org.spark_project.jetty.server.HttpChannel.handle(HttpChannel.java:320)
	at org.spark_project.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
	at org.spark_project.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
	at org.spark_project.jetty.io.FillInterest.fillable(FillInterest.java:108)
	at org.spark_project.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
	at org.spark_project.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
	at org.spark_project.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
	at java.lang.Thread.run(Thread.java:745)
2021-12-06 17:11:44,148 [SparkUI-107] INFO [org.spark_project.jetty.servlet.DefaultServlet] - content=ResourceHttpContent@1cecf048{r=jar:file:/C:/Users/ACER/.m2/repository/org/apache/spark/spark-core_2.11/2.3.0/spark-core_2.11-2.3.0.jar!/org/apache/spark/ui/static/jquery-1.11.1.min.js,gz=false}
2021-12-06 17:11:44,148 [SparkUI-111] WARN [org.spark_project.jetty.server.HttpChannel] - //qb:4040/static/bootstrap-tooltip.js
java.lang.NoSuchMethodError: javax.servlet.http.HttpServletRequest.isAsyncStarted()Z
	at org.spark_project.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:688)
	at org.spark_project.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
	at org.spark_project.jetty.servlet.ServletHandler.doScope(ServletHandler.java:512)
	at org.spark_project.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
	at org.spark_project.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.spark_project.jetty.server.handler.gzip.GzipHandler.handle(GzipHandler.java:493)
	at org.spark_project.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:213)
	at org.spark_project.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
	at org.spark_project.jetty.server.Server.handle(Server.java:534)
	at org.spark_project.jetty.server.HttpChannel.handle(HttpChannel.java:320)
	at org.spark_project.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
	at org.spark_project.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
	at org.spark_project.jetty.io.FillInterest.fillable(FillInterest.java:108)
	at org.spark_project.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
	at org.spark_project.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
	at org.spark_project.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
	at java.lang.Thread.run(Thread.java:745)
2021-12-06 17:11:44,148 [SparkUI-112] INFO [org.spark_project.jetty.servlet.DefaultServlet] - content=ResourceHttpContent@757973b{r=jar:file:/C:/Users/ACER/.m2/repository/org/apache/spark/spark-core_2.11/2.3.0/spark-core_2.11-2.3.0.jar!/org/apache/spark/ui/static/vis.min.js,gz=false}
2021-12-06 17:11:44,148 [SparkUI-112] WARN [org.spark_project.jetty.servlet.ServletHandler] - Error for /static/vis.min.js
java.lang.NoSuchMethodError: javax.servlet.http.HttpServletRequest.isAsyncSupported()Z
	at org.spark_project.jetty.servlet.DefaultServlet.sendData(DefaultServlet.java:909)
	at org.spark_project.jetty.servlet.DefaultServlet.doGet(DefaultServlet.java:526)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:707)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:820)
	at org.spark_project.jetty.servlet.ServletHolder.handle(ServletHolder.java:848)
	at org.spark_project.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:584)
	at org.spark_project.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
	at org.spark_project.jetty.servlet.ServletHandler.doScope(ServletHandler.java:512)
	at org.spark_project.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
	at org.spark_project.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.spark_project.jetty.server.handler.gzip.GzipHandler.handle(GzipHandler.java:493)
	at org.spark_project.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:213)
	at org.spark_project.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
	at org.spark_project.jetty.server.Server.handle(Server.java:534)
	at org.spark_project.jetty.server.HttpChannel.handle(HttpChannel.java:320)
	at org.spark_project.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
	at org.spark_project.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
	at org.spark_project.jetty.io.FillInterest.fillable(FillInterest.java:108)
	at org.spark_project.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
	at org.spark_project.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
	at org.spark_project.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
	at java.lang.Thread.run(Thread.java:745)
2021-12-06 17:11:44,148 [SparkUI-112] WARN [org.spark_project.jetty.server.HttpChannel] - //qb:4040/static/vis.min.js
java.lang.NoSuchMethodError: javax.servlet.http.HttpServletRequest.isAsyncStarted()Z
	at org.spark_project.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:688)
	at org.spark_project.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
	at org.spark_project.jetty.servlet.ServletHandler.doScope(ServletHandler.java:512)
	at org.spark_project.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
	at org.spark_project.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.spark_project.jetty.server.handler.gzip.GzipHandler.handle(GzipHandler.java:493)
	at org.spark_project.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:213)
	at org.spark_project.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
	at org.spark_project.jetty.server.Server.handle(Server.java:534)
	at org.spark_project.jetty.server.HttpChannel.handle(HttpChannel.java:320)
	at org.spark_project.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
	at org.spark_project.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
	at org.spark_project.jetty.io.FillInterest.fillable(FillInterest.java:108)
	at org.spark_project.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
	at org.spark_project.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
	at org.spark_project.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
	at java.lang.Thread.run(Thread.java:745)
2021-12-06 17:11:44,148 [SparkUI-107] WARN [org.spark_project.jetty.servlet.ServletHandler] - Error for /static/jquery-1.11.1.min.js
java.lang.NoSuchMethodError: javax.servlet.http.HttpServletRequest.isAsyncSupported()Z
	at org.spark_project.jetty.servlet.DefaultServlet.sendData(DefaultServlet.java:909)
	at org.spark_project.jetty.servlet.DefaultServlet.doGet(DefaultServlet.java:526)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:707)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:820)
	at org.spark_project.jetty.servlet.ServletHolder.handle(ServletHolder.java:848)
	at org.spark_project.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:584)
	at org.spark_project.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
	at org.spark_project.jetty.servlet.ServletHandler.doScope(ServletHandler.java:512)
	at org.spark_project.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
	at org.spark_project.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.spark_project.jetty.server.handler.gzip.GzipHandler.handle(GzipHandler.java:493)
	at org.spark_project.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:213)
	at org.spark_project.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
	at org.spark_project.jetty.server.Server.handle(Server.java:534)
	at org.spark_project.jetty.server.HttpChannel.handle(HttpChannel.java:320)
	at org.spark_project.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
	at org.spark_project.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
	at org.spark_project.jetty.io.FillInterest.fillable(FillInterest.java:108)
	at org.spark_project.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
	at org.spark_project.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
	at org.spark_project.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
	at java.lang.Thread.run(Thread.java:745)
2021-12-06 17:11:44,149 [SparkUI-107] WARN [org.spark_project.jetty.server.HttpChannel] - //qb:4040/static/jquery-1.11.1.min.js
java.lang.NoSuchMethodError: javax.servlet.http.HttpServletRequest.isAsyncStarted()Z
	at org.spark_project.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:688)
	at org.spark_project.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
	at org.spark_project.jetty.servlet.ServletHandler.doScope(ServletHandler.java:512)
	at org.spark_project.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
	at org.spark_project.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.spark_project.jetty.server.handler.gzip.GzipHandler.handle(GzipHandler.java:493)
	at org.spark_project.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:213)
	at org.spark_project.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
	at org.spark_project.jetty.server.Server.handle(Server.java:534)
	at org.spark_project.jetty.server.HttpChannel.handle(HttpChannel.java:320)
	at org.spark_project.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
	at org.spark_project.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
	at org.spark_project.jetty.io.FillInterest.fillable(FillInterest.java:108)
	at org.spark_project.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
	at org.spark_project.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
	at org.spark_project.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
	at java.lang.Thread.run(Thread.java:745)
2021-12-06 17:11:44,150 [SparkUI-106] INFO [org.spark_project.jetty.servlet.DefaultServlet] - content=ResourceHttpContent@6531917b{r=jar:file:/C:/Users/ACER/.m2/repository/org/apache/spark/spark-core_2.11/2.3.0/spark-core_2.11-2.3.0.jar!/org/apache/spark/ui/static/initialize-tooltips.js,gz=false}
2021-12-06 17:11:44,150 [SparkUI-106] WARN [org.spark_project.jetty.servlet.ServletHandler] - Error for /static/initialize-tooltips.js
java.lang.NoSuchMethodError: javax.servlet.http.HttpServletRequest.isAsyncSupported()Z
	at org.spark_project.jetty.servlet.DefaultServlet.sendData(DefaultServlet.java:909)
	at org.spark_project.jetty.servlet.DefaultServlet.doGet(DefaultServlet.java:526)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:707)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:820)
	at org.spark_project.jetty.servlet.ServletHolder.handle(ServletHolder.java:848)
	at org.spark_project.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:584)
	at org.spark_project.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
	at org.spark_project.jetty.servlet.ServletHandler.doScope(ServletHandler.java:512)
	at org.spark_project.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
	at org.spark_project.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.spark_project.jetty.server.handler.gzip.GzipHandler.handle(GzipHandler.java:493)
	at org.spark_project.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:213)
	at org.spark_project.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
	at org.spark_project.jetty.server.Server.handle(Server.java:534)
	at org.spark_project.jetty.server.HttpChannel.handle(HttpChannel.java:320)
	at org.spark_project.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
	at org.spark_project.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
	at org.spark_project.jetty.io.FillInterest.fillable(FillInterest.java:108)
	at org.spark_project.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
	at org.spark_project.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
	at org.spark_project.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
	at java.lang.Thread.run(Thread.java:745)
2021-12-06 17:11:44,150 [SparkUI-106] WARN [org.spark_project.jetty.server.HttpChannel] - //qb:4040/static/initialize-tooltips.js
java.lang.NoSuchMethodError: javax.servlet.http.HttpServletRequest.isAsyncStarted()Z
	at org.spark_project.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:688)
	at org.spark_project.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
	at org.spark_project.jetty.servlet.ServletHandler.doScope(ServletHandler.java:512)
	at org.spark_project.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
	at org.spark_project.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.spark_project.jetty.server.handler.gzip.GzipHandler.handle(GzipHandler.java:493)
	at org.spark_project.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:213)
	at org.spark_project.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
	at org.spark_project.jetty.server.Server.handle(Server.java:534)
	at org.spark_project.jetty.server.HttpChannel.handle(HttpChannel.java:320)
	at org.spark_project.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
	at org.spark_project.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
	at org.spark_project.jetty.io.FillInterest.fillable(FillInterest.java:108)
	at org.spark_project.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
	at org.spark_project.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
	at org.spark_project.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
	at java.lang.Thread.run(Thread.java:745)
2021-12-06 17:11:44,150 [SparkUI-108] INFO [org.spark_project.jetty.servlet.DefaultServlet] - content=ResourceHttpContent@7354baae{r=jar:file:/C:/Users/ACER/.m2/repository/org/apache/spark/spark-core_2.11/2.3.0/spark-core_2.11-2.3.0.jar!/org/apache/spark/ui/static/additional-metrics.js,gz=false}
2021-12-06 17:11:44,150 [SparkUI-108] WARN [org.spark_project.jetty.servlet.ServletHandler] - Error for /static/additional-metrics.js
java.lang.NoSuchMethodError: javax.servlet.http.HttpServletRequest.isAsyncSupported()Z
	at org.spark_project.jetty.servlet.DefaultServlet.sendData(DefaultServlet.java:909)
	at org.spark_project.jetty.servlet.DefaultServlet.doGet(DefaultServlet.java:526)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:707)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:820)
	at org.spark_project.jetty.servlet.ServletHolder.handle(ServletHolder.java:848)
	at org.spark_project.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:584)
	at org.spark_project.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
	at org.spark_project.jetty.servlet.ServletHandler.doScope(ServletHandler.java:512)
	at org.spark_project.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
	at org.spark_project.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.spark_project.jetty.server.handler.gzip.GzipHandler.handle(GzipHandler.java:493)
	at org.spark_project.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:213)
	at org.spark_project.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
	at org.spark_project.jetty.server.Server.handle(Server.java:534)
	at org.spark_project.jetty.server.HttpChannel.handle(HttpChannel.java:320)
	at org.spark_project.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
	at org.spark_project.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
	at org.spark_project.jetty.io.FillInterest.fillable(FillInterest.java:108)
	at org.spark_project.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
	at org.spark_project.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
	at org.spark_project.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
	at java.lang.Thread.run(Thread.java:745)
2021-12-06 17:11:44,150 [SparkUI-108] WARN [org.spark_project.jetty.server.HttpChannel] - //qb:4040/static/additional-metrics.js
java.lang.NoSuchMethodError: javax.servlet.http.HttpServletRequest.isAsyncStarted()Z
	at org.spark_project.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:688)
	at org.spark_project.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
	at org.spark_project.jetty.servlet.ServletHandler.doScope(ServletHandler.java:512)
	at org.spark_project.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
	at org.spark_project.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.spark_project.jetty.server.handler.gzip.GzipHandler.handle(GzipHandler.java:493)
	at org.spark_project.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:213)
	at org.spark_project.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
	at org.spark_project.jetty.server.Server.handle(Server.java:534)
	at org.spark_project.jetty.server.HttpChannel.handle(HttpChannel.java:320)
	at org.spark_project.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
	at org.spark_project.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
	at org.spark_project.jetty.io.FillInterest.fillable(FillInterest.java:108)
	at org.spark_project.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
	at org.spark_project.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
	at org.spark_project.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
	at java.lang.Thread.run(Thread.java:745)
2021-12-06 17:11:44,154 [SparkUI-114] INFO [org.spark_project.jetty.servlet.DefaultServlet] - content=ResourceHttpContent@4ba9a1d8{r=jar:file:/C:/Users/ACER/.m2/repository/org/apache/spark/spark-core_2.11/2.3.0/spark-core_2.11-2.3.0.jar!/org/apache/spark/ui/static/webui.js,gz=false}
2021-12-06 17:11:44,154 [SparkUI-111] INFO [org.spark_project.jetty.servlet.DefaultServlet] - content=ResourceHttpContent@347033ec{r=jar:file:/C:/Users/ACER/.m2/repository/org/apache/spark/spark-core_2.11/2.3.0/spark-core_2.11-2.3.0.jar!/org/apache/spark/ui/static/log-view.js,gz=false}
2021-12-06 17:11:44,154 [SparkUI-114] WARN [org.spark_project.jetty.servlet.ServletHandler] - Error for /static/webui.js
java.lang.NoSuchMethodError: javax.servlet.http.HttpServletRequest.isAsyncSupported()Z
	at org.spark_project.jetty.servlet.DefaultServlet.sendData(DefaultServlet.java:909)
	at org.spark_project.jetty.servlet.DefaultServlet.doGet(DefaultServlet.java:526)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:707)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:820)
	at org.spark_project.jetty.servlet.ServletHolder.handle(ServletHolder.java:848)
	at org.spark_project.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:584)
	at org.spark_project.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
	at org.spark_project.jetty.servlet.ServletHandler.doScope(ServletHandler.java:512)
	at org.spark_project.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
	at org.spark_project.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.spark_project.jetty.server.handler.gzip.GzipHandler.handle(GzipHandler.java:493)
	at org.spark_project.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:213)
	at org.spark_project.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
	at org.spark_project.jetty.server.Server.handle(Server.java:534)
	at org.spark_project.jetty.server.HttpChannel.handle(HttpChannel.java:320)
	at org.spark_project.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
	at org.spark_project.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
	at org.spark_project.jetty.io.FillInterest.fillable(FillInterest.java:108)
	at org.spark_project.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
	at org.spark_project.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
	at org.spark_project.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
	at java.lang.Thread.run(Thread.java:745)
2021-12-06 17:11:44,154 [SparkUI-38] INFO [org.spark_project.jetty.servlet.DefaultServlet] - content=ResourceHttpContent@1fd4da38{r=jar:file:/C:/Users/ACER/.m2/repository/org/apache/spark/spark-core_2.11/2.3.0/spark-core_2.11-2.3.0.jar!/org/apache/spark/ui/static/timeline-view.js,gz=false}
2021-12-06 17:11:44,155 [SparkUI-114] WARN [org.spark_project.jetty.server.HttpChannel] - //qb:4040/static/webui.js
java.lang.NoSuchMethodError: javax.servlet.http.HttpServletRequest.isAsyncStarted()Z
	at org.spark_project.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:688)
	at org.spark_project.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
	at org.spark_project.jetty.servlet.ServletHandler.doScope(ServletHandler.java:512)
	at org.spark_project.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
	at org.spark_project.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.spark_project.jetty.server.handler.gzip.GzipHandler.handle(GzipHandler.java:493)
	at org.spark_project.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:213)
	at org.spark_project.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
	at org.spark_project.jetty.server.Server.handle(Server.java:534)
	at org.spark_project.jetty.server.HttpChannel.handle(HttpChannel.java:320)
	at org.spark_project.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
	at org.spark_project.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
	at org.spark_project.jetty.io.FillInterest.fillable(FillInterest.java:108)
	at org.spark_project.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
	at org.spark_project.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
	at org.spark_project.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
	at java.lang.Thread.run(Thread.java:745)
2021-12-06 17:11:44,155 [SparkUI-111] WARN [org.spark_project.jetty.servlet.ServletHandler] - Error for /static/log-view.js
java.lang.NoSuchMethodError: javax.servlet.http.HttpServletRequest.isAsyncSupported()Z
	at org.spark_project.jetty.servlet.DefaultServlet.sendData(DefaultServlet.java:909)
	at org.spark_project.jetty.servlet.DefaultServlet.doGet(DefaultServlet.java:526)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:707)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:820)
	at org.spark_project.jetty.servlet.ServletHolder.handle(ServletHolder.java:848)
	at org.spark_project.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:584)
	at org.spark_project.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
	at org.spark_project.jetty.servlet.ServletHandler.doScope(ServletHandler.java:512)
	at org.spark_project.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
	at org.spark_project.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.spark_project.jetty.server.handler.gzip.GzipHandler.handle(GzipHandler.java:493)
	at org.spark_project.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:213)
	at org.spark_project.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
	at org.spark_project.jetty.server.Server.handle(Server.java:534)
	at org.spark_project.jetty.server.HttpChannel.handle(HttpChannel.java:320)
	at org.spark_project.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
	at org.spark_project.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
	at org.spark_project.jetty.io.FillInterest.fillable(FillInterest.java:108)
	at org.spark_project.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
	at org.spark_project.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
	at org.spark_project.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
	at java.lang.Thread.run(Thread.java:745)
2021-12-06 17:11:44,155 [SparkUI-38] WARN [org.spark_project.jetty.servlet.ServletHandler] - Error for /static/timeline-view.js
java.lang.NoSuchMethodError: javax.servlet.http.HttpServletRequest.isAsyncSupported()Z
	at org.spark_project.jetty.servlet.DefaultServlet.sendData(DefaultServlet.java:909)
	at org.spark_project.jetty.servlet.DefaultServlet.doGet(DefaultServlet.java:526)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:707)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:820)
	at org.spark_project.jetty.servlet.ServletHolder.handle(ServletHolder.java:848)
	at org.spark_project.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:584)
	at org.spark_project.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
	at org.spark_project.jetty.servlet.ServletHandler.doScope(ServletHandler.java:512)
	at org.spark_project.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
	at org.spark_project.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.spark_project.jetty.server.handler.gzip.GzipHandler.handle(GzipHandler.java:493)
	at org.spark_project.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:213)
	at org.spark_project.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
	at org.spark_project.jetty.server.Server.handle(Server.java:534)
	at org.spark_project.jetty.server.HttpChannel.handle(HttpChannel.java:320)
	at org.spark_project.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
	at org.spark_project.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
	at org.spark_project.jetty.io.FillInterest.fillable(FillInterest.java:108)
	at org.spark_project.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
	at org.spark_project.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
	at org.spark_project.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
	at java.lang.Thread.run(Thread.java:745)
2021-12-06 17:11:44,155 [SparkUI-111] WARN [org.spark_project.jetty.server.HttpChannel] - //qb:4040/static/log-view.js
java.lang.NoSuchMethodError: javax.servlet.http.HttpServletRequest.isAsyncStarted()Z
	at org.spark_project.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:688)
	at org.spark_project.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
	at org.spark_project.jetty.servlet.ServletHandler.doScope(ServletHandler.java:512)
	at org.spark_project.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
	at org.spark_project.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.spark_project.jetty.server.handler.gzip.GzipHandler.handle(GzipHandler.java:493)
	at org.spark_project.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:213)
	at org.spark_project.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
	at org.spark_project.jetty.server.Server.handle(Server.java:534)
	at org.spark_project.jetty.server.HttpChannel.handle(HttpChannel.java:320)
	at org.spark_project.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
	at org.spark_project.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
	at org.spark_project.jetty.io.FillInterest.fillable(FillInterest.java:108)
	at org.spark_project.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
	at org.spark_project.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
	at org.spark_project.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
	at java.lang.Thread.run(Thread.java:745)
2021-12-06 17:11:44,155 [SparkUI-38] WARN [org.spark_project.jetty.server.HttpChannel] - //qb:4040/static/timeline-view.js
java.lang.NoSuchMethodError: javax.servlet.http.HttpServletRequest.isAsyncStarted()Z
	at org.spark_project.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:688)
	at org.spark_project.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
	at org.spark_project.jetty.servlet.ServletHandler.doScope(ServletHandler.java:512)
	at org.spark_project.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
	at org.spark_project.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.spark_project.jetty.server.handler.gzip.GzipHandler.handle(GzipHandler.java:493)
	at org.spark_project.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:213)
	at org.spark_project.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
	at org.spark_project.jetty.server.Server.handle(Server.java:534)
	at org.spark_project.jetty.server.HttpChannel.handle(HttpChannel.java:320)
	at org.spark_project.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
	at org.spark_project.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
	at org.spark_project.jetty.io.FillInterest.fillable(FillInterest.java:108)
	at org.spark_project.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
	at org.spark_project.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
	at org.spark_project.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
	at java.lang.Thread.run(Thread.java:745)
2021-12-06 17:11:44,156 [SparkUI-107] INFO [org.spark_project.jetty.servlet.DefaultServlet] - content=ResourceHttpContent@4330d43d{r=jar:file:/C:/Users/ACER/.m2/repository/org/apache/spark/spark-core_2.11/2.3.0/spark-core_2.11-2.3.0.jar!/org/apache/spark/ui/static/table.js,gz=false}
2021-12-06 17:11:44,156 [SparkUI-107] WARN [org.spark_project.jetty.servlet.ServletHandler] - Error for /static/table.js
java.lang.NoSuchMethodError: javax.servlet.http.HttpServletRequest.isAsyncSupported()Z
	at org.spark_project.jetty.servlet.DefaultServlet.sendData(DefaultServlet.java:909)
	at org.spark_project.jetty.servlet.DefaultServlet.doGet(DefaultServlet.java:526)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:707)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:820)
	at org.spark_project.jetty.servlet.ServletHolder.handle(ServletHolder.java:848)
	at org.spark_project.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:584)
	at org.spark_project.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
	at org.spark_project.jetty.servlet.ServletHandler.doScope(ServletHandler.java:512)
	at org.spark_project.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
	at org.spark_project.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.spark_project.jetty.server.handler.gzip.GzipHandler.handle(GzipHandler.java:493)
	at org.spark_project.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:213)
	at org.spark_project.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
	at org.spark_project.jetty.server.Server.handle(Server.java:534)
	at org.spark_project.jetty.server.HttpChannel.handle(HttpChannel.java:320)
	at org.spark_project.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
	at org.spark_project.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
	at org.spark_project.jetty.io.FillInterest.fillable(FillInterest.java:108)
	at org.spark_project.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
	at org.spark_project.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
	at org.spark_project.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
	at java.lang.Thread.run(Thread.java:745)
2021-12-06 17:11:44,156 [SparkUI-107] WARN [org.spark_project.jetty.server.HttpChannel] - //qb:4040/static/table.js
java.lang.NoSuchMethodError: javax.servlet.http.HttpServletRequest.isAsyncStarted()Z
	at org.spark_project.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:688)
	at org.spark_project.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
	at org.spark_project.jetty.servlet.ServletHandler.doScope(ServletHandler.java:512)
	at org.spark_project.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
	at org.spark_project.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.spark_project.jetty.server.handler.gzip.GzipHandler.handle(GzipHandler.java:493)
	at org.spark_project.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:213)
	at org.spark_project.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
	at org.spark_project.jetty.server.Server.handle(Server.java:534)
	at org.spark_project.jetty.server.HttpChannel.handle(HttpChannel.java:320)
	at org.spark_project.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
	at org.spark_project.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
	at org.spark_project.jetty.io.FillInterest.fillable(FillInterest.java:108)
	at org.spark_project.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
	at org.spark_project.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
	at org.spark_project.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
	at java.lang.Thread.run(Thread.java:745)
2021-12-06 17:11:44,184 [SparkUI-106] INFO [org.spark_project.jetty.servlet.DefaultServlet] - content=ResourceHttpContent@1f8dab0a{r=jar:file:/C:/Users/ACER/.m2/repository/org/apache/spark/spark-core_2.11/2.3.0/spark-core_2.11-2.3.0.jar!/org/apache/spark/ui/static/spark-logo-77x50px-hd.png,gz=false}
2021-12-06 17:11:44,184 [SparkUI-106] WARN [org.spark_project.jetty.servlet.ServletHandler] - Error for /static/spark-logo-77x50px-hd.png
java.lang.NoSuchMethodError: javax.servlet.http.HttpServletRequest.isAsyncSupported()Z
	at org.spark_project.jetty.servlet.DefaultServlet.sendData(DefaultServlet.java:909)
	at org.spark_project.jetty.servlet.DefaultServlet.doGet(DefaultServlet.java:526)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:707)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:820)
	at org.spark_project.jetty.servlet.ServletHolder.handle(ServletHolder.java:848)
	at org.spark_project.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:584)
	at org.spark_project.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
	at org.spark_project.jetty.servlet.ServletHandler.doScope(ServletHandler.java:512)
	at org.spark_project.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
	at org.spark_project.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.spark_project.jetty.server.handler.gzip.GzipHandler.handle(GzipHandler.java:448)
	at org.spark_project.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:213)
	at org.spark_project.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
	at org.spark_project.jetty.server.Server.handle(Server.java:534)
	at org.spark_project.jetty.server.HttpChannel.handle(HttpChannel.java:320)
	at org.spark_project.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
	at org.spark_project.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
	at org.spark_project.jetty.io.FillInterest.fillable(FillInterest.java:108)
	at org.spark_project.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
	at org.spark_project.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
	at org.spark_project.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
	at java.lang.Thread.run(Thread.java:745)
2021-12-06 17:11:44,185 [SparkUI-106] WARN [org.spark_project.jetty.server.HttpChannel] - //qb:4040/static/spark-logo-77x50px-hd.png
java.lang.NoSuchMethodError: javax.servlet.http.HttpServletRequest.isAsyncStarted()Z
	at org.spark_project.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:688)
	at org.spark_project.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
	at org.spark_project.jetty.servlet.ServletHandler.doScope(ServletHandler.java:512)
	at org.spark_project.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
	at org.spark_project.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.spark_project.jetty.server.handler.gzip.GzipHandler.handle(GzipHandler.java:448)
	at org.spark_project.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:213)
	at org.spark_project.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
	at org.spark_project.jetty.server.Server.handle(Server.java:534)
	at org.spark_project.jetty.server.HttpChannel.handle(HttpChannel.java:320)
	at org.spark_project.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
	at org.spark_project.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
	at org.spark_project.jetty.io.FillInterest.fillable(FillInterest.java:108)
	at org.spark_project.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
	at org.spark_project.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
	at org.spark_project.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
	at java.lang.Thread.run(Thread.java:745)
2021-12-06 17:12:45,543 [SparkUI-110] INFO [org.spark_project.jetty.servlet.DefaultServlet] - content=ResourceHttpContent@53a40252{r=jar:file:/C:/Users/ACER/.m2/repository/org/apache/spark/spark-core_2.11/2.3.0/spark-core_2.11-2.3.0.jar!/org/apache/spark/ui/static/bootstrap.min.css,gz=false}
2021-12-06 17:12:45,543 [SparkUI-38] INFO [org.spark_project.jetty.servlet.DefaultServlet] - content=ResourceHttpContent@404000a2{r=jar:file:/C:/Users/ACER/.m2/repository/org/apache/spark/spark-core_2.11/2.3.0/spark-core_2.11-2.3.0.jar!/org/apache/spark/ui/static/vis.min.css,gz=false}
2021-12-06 17:12:45,543 [SparkUI-38] WARN [org.spark_project.jetty.servlet.ServletHandler] - Error for /static/vis.min.css
java.lang.NoSuchMethodError: javax.servlet.http.HttpServletRequest.isAsyncSupported()Z
	at org.spark_project.jetty.servlet.DefaultServlet.sendData(DefaultServlet.java:909)
	at org.spark_project.jetty.servlet.DefaultServlet.doGet(DefaultServlet.java:526)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:707)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:820)
	at org.spark_project.jetty.servlet.ServletHolder.handle(ServletHolder.java:848)
	at org.spark_project.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:584)
	at org.spark_project.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
	at org.spark_project.jetty.servlet.ServletHandler.doScope(ServletHandler.java:512)
	at org.spark_project.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
	at org.spark_project.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.spark_project.jetty.server.handler.gzip.GzipHandler.handle(GzipHandler.java:493)
	at org.spark_project.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:213)
	at org.spark_project.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
	at org.spark_project.jetty.server.Server.handle(Server.java:534)
	at org.spark_project.jetty.server.HttpChannel.handle(HttpChannel.java:320)
	at org.spark_project.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
	at org.spark_project.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
	at org.spark_project.jetty.io.FillInterest.fillable(FillInterest.java:108)
	at org.spark_project.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
	at org.spark_project.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
	at org.spark_project.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
	at java.lang.Thread.run(Thread.java:745)
2021-12-06 17:12:45,543 [SparkUI-110] WARN [org.spark_project.jetty.servlet.ServletHandler] - Error for /static/bootstrap.min.css
java.lang.NoSuchMethodError: javax.servlet.http.HttpServletRequest.isAsyncSupported()Z
	at org.spark_project.jetty.servlet.DefaultServlet.sendData(DefaultServlet.java:909)
	at org.spark_project.jetty.servlet.DefaultServlet.doGet(DefaultServlet.java:526)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:707)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:820)
	at org.spark_project.jetty.servlet.ServletHolder.handle(ServletHolder.java:848)
	at org.spark_project.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:584)
	at org.spark_project.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
	at org.spark_project.jetty.servlet.ServletHandler.doScope(ServletHandler.java:512)
	at org.spark_project.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
	at org.spark_project.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.spark_project.jetty.server.handler.gzip.GzipHandler.handle(GzipHandler.java:493)
	at org.spark_project.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:213)
	at org.spark_project.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
	at org.spark_project.jetty.server.Server.handle(Server.java:534)
	at org.spark_project.jetty.server.HttpChannel.handle(HttpChannel.java:320)
	at org.spark_project.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
	at org.spark_project.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
	at org.spark_project.jetty.io.FillInterest.fillable(FillInterest.java:108)
	at org.spark_project.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
	at org.spark_project.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
	at org.spark_project.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
	at java.lang.Thread.run(Thread.java:745)
2021-12-06 17:12:45,544 [SparkUI-110] WARN [org.spark_project.jetty.server.HttpChannel] - //qb:4040/static/bootstrap.min.css
java.lang.NoSuchMethodError: javax.servlet.http.HttpServletRequest.isAsyncStarted()Z
	at org.spark_project.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:688)
	at org.spark_project.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
	at org.spark_project.jetty.servlet.ServletHandler.doScope(ServletHandler.java:512)
	at org.spark_project.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
	at org.spark_project.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.spark_project.jetty.server.handler.gzip.GzipHandler.handle(GzipHandler.java:493)
	at org.spark_project.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:213)
	at org.spark_project.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
	at org.spark_project.jetty.server.Server.handle(Server.java:534)
	at org.spark_project.jetty.server.HttpChannel.handle(HttpChannel.java:320)
	at org.spark_project.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
	at org.spark_project.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
	at org.spark_project.jetty.io.FillInterest.fillable(FillInterest.java:108)
	at org.spark_project.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
	at org.spark_project.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
	at org.spark_project.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
	at java.lang.Thread.run(Thread.java:745)
2021-12-06 17:12:45,544 [SparkUI-38] WARN [org.spark_project.jetty.server.HttpChannel] - //qb:4040/static/vis.min.css
java.lang.NoSuchMethodError: javax.servlet.http.HttpServletRequest.isAsyncStarted()Z
	at org.spark_project.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:688)
	at org.spark_project.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
	at org.spark_project.jetty.servlet.ServletHandler.doScope(ServletHandler.java:512)
	at org.spark_project.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
	at org.spark_project.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.spark_project.jetty.server.handler.gzip.GzipHandler.handle(GzipHandler.java:493)
	at org.spark_project.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:213)
	at org.spark_project.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
	at org.spark_project.jetty.server.Server.handle(Server.java:534)
	at org.spark_project.jetty.server.HttpChannel.handle(HttpChannel.java:320)
	at org.spark_project.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
	at org.spark_project.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
	at org.spark_project.jetty.io.FillInterest.fillable(FillInterest.java:108)
	at org.spark_project.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
	at org.spark_project.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
	at org.spark_project.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
	at java.lang.Thread.run(Thread.java:745)
2021-12-06 17:12:45,548 [SparkUI-113] INFO [org.spark_project.jetty.servlet.DefaultServlet] - content=ResourceHttpContent@26b43026{r=jar:file:/C:/Users/ACER/.m2/repository/org/apache/spark/spark-core_2.11/2.3.0/spark-core_2.11-2.3.0.jar!/org/apache/spark/ui/static/webui.css,gz=false}
2021-12-06 17:12:45,548 [SparkUI-113] WARN [org.spark_project.jetty.servlet.ServletHandler] - Error for /static/webui.css
java.lang.NoSuchMethodError: javax.servlet.http.HttpServletRequest.isAsyncSupported()Z
	at org.spark_project.jetty.servlet.DefaultServlet.sendData(DefaultServlet.java:909)
	at org.spark_project.jetty.servlet.DefaultServlet.doGet(DefaultServlet.java:526)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:707)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:820)
	at org.spark_project.jetty.servlet.ServletHolder.handle(ServletHolder.java:848)
	at org.spark_project.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:584)
	at org.spark_project.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
	at org.spark_project.jetty.servlet.ServletHandler.doScope(ServletHandler.java:512)
	at org.spark_project.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
	at org.spark_project.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.spark_project.jetty.server.handler.gzip.GzipHandler.handle(GzipHandler.java:493)
	at org.spark_project.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:213)
	at org.spark_project.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
	at org.spark_project.jetty.server.Server.handle(Server.java:534)
	at org.spark_project.jetty.server.HttpChannel.handle(HttpChannel.java:320)
	at org.spark_project.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
	at org.spark_project.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
	at org.spark_project.jetty.io.FillInterest.fillable(FillInterest.java:108)
	at org.spark_project.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
	at org.spark_project.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
	at org.spark_project.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
	at java.lang.Thread.run(Thread.java:745)
2021-12-06 17:12:45,549 [SparkUI-113] WARN [org.spark_project.jetty.server.HttpChannel] - //qb:4040/static/webui.css
java.lang.NoSuchMethodError: javax.servlet.http.HttpServletRequest.isAsyncStarted()Z
	at org.spark_project.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:688)
	at org.spark_project.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
	at org.spark_project.jetty.servlet.ServletHandler.doScope(ServletHandler.java:512)
	at org.spark_project.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
	at org.spark_project.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.spark_project.jetty.server.handler.gzip.GzipHandler.handle(GzipHandler.java:493)
	at org.spark_project.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:213)
	at org.spark_project.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
	at org.spark_project.jetty.server.Server.handle(Server.java:534)
	at org.spark_project.jetty.server.HttpChannel.handle(HttpChannel.java:320)
	at org.spark_project.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
	at org.spark_project.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
	at org.spark_project.jetty.io.FillInterest.fillable(FillInterest.java:108)
	at org.spark_project.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
	at org.spark_project.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
	at org.spark_project.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
	at java.lang.Thread.run(Thread.java:745)
2021-12-06 17:12:45,550 [SparkUI-114] INFO [org.spark_project.jetty.servlet.DefaultServlet] - content=ResourceHttpContent@1c3c23e6{r=jar:file:/C:/Users/ACER/.m2/repository/org/apache/spark/spark-core_2.11/2.3.0/spark-core_2.11-2.3.0.jar!/org/apache/spark/ui/static/timeline-view.css,gz=false}
2021-12-06 17:12:45,550 [SparkUI-114] WARN [org.spark_project.jetty.servlet.ServletHandler] - Error for /static/timeline-view.css
java.lang.NoSuchMethodError: javax.servlet.http.HttpServletRequest.isAsyncSupported()Z
	at org.spark_project.jetty.servlet.DefaultServlet.sendData(DefaultServlet.java:909)
	at org.spark_project.jetty.servlet.DefaultServlet.doGet(DefaultServlet.java:526)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:707)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:820)
	at org.spark_project.jetty.servlet.ServletHolder.handle(ServletHolder.java:848)
	at org.spark_project.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:584)
	at org.spark_project.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
	at org.spark_project.jetty.servlet.ServletHandler.doScope(ServletHandler.java:512)
	at org.spark_project.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
	at org.spark_project.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.spark_project.jetty.server.handler.gzip.GzipHandler.handle(GzipHandler.java:493)
	at org.spark_project.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:213)
	at org.spark_project.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
	at org.spark_project.jetty.server.Server.handle(Server.java:534)
	at org.spark_project.jetty.server.HttpChannel.handle(HttpChannel.java:320)
	at org.spark_project.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
	at org.spark_project.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
	at org.spark_project.jetty.io.FillInterest.fillable(FillInterest.java:108)
	at org.spark_project.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
	at org.spark_project.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
	at org.spark_project.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
	at java.lang.Thread.run(Thread.java:745)
2021-12-06 17:12:45,550 [SparkUI-114] WARN [org.spark_project.jetty.server.HttpChannel] - //qb:4040/static/timeline-view.css
java.lang.NoSuchMethodError: javax.servlet.http.HttpServletRequest.isAsyncStarted()Z
	at org.spark_project.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:688)
	at org.spark_project.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
	at org.spark_project.jetty.servlet.ServletHandler.doScope(ServletHandler.java:512)
	at org.spark_project.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
	at org.spark_project.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.spark_project.jetty.server.handler.gzip.GzipHandler.handle(GzipHandler.java:493)
	at org.spark_project.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:213)
	at org.spark_project.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
	at org.spark_project.jetty.server.Server.handle(Server.java:534)
	at org.spark_project.jetty.server.HttpChannel.handle(HttpChannel.java:320)
	at org.spark_project.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
	at org.spark_project.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
	at org.spark_project.jetty.io.FillInterest.fillable(FillInterest.java:108)
	at org.spark_project.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
	at org.spark_project.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
	at org.spark_project.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
	at java.lang.Thread.run(Thread.java:745)
2021-12-06 17:12:45,551 [SparkUI-39] INFO [org.spark_project.jetty.servlet.DefaultServlet] - content=ResourceHttpContent@654420c7{r=jar:file:/C:/Users/ACER/.m2/repository/org/apache/spark/spark-core_2.11/2.3.0/spark-core_2.11-2.3.0.jar!/org/apache/spark/ui/static/vis.min.css,gz=false}
2021-12-06 17:12:45,551 [SparkUI-39] WARN [org.spark_project.jetty.servlet.ServletHandler] - Error for /static/vis.min.css
java.lang.NoSuchMethodError: javax.servlet.http.HttpServletRequest.isAsyncSupported()Z
	at org.spark_project.jetty.servlet.DefaultServlet.sendData(DefaultServlet.java:909)
	at org.spark_project.jetty.servlet.DefaultServlet.doGet(DefaultServlet.java:526)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:707)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:820)
	at org.spark_project.jetty.servlet.ServletHolder.handle(ServletHolder.java:848)
	at org.spark_project.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:584)
	at org.spark_project.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
	at org.spark_project.jetty.servlet.ServletHandler.doScope(ServletHandler.java:512)
	at org.spark_project.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
	at org.spark_project.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.spark_project.jetty.server.handler.gzip.GzipHandler.handle(GzipHandler.java:493)
	at org.spark_project.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:213)
	at org.spark_project.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
	at org.spark_project.jetty.server.Server.handle(Server.java:534)
	at org.spark_project.jetty.server.HttpChannel.handle(HttpChannel.java:320)
	at org.spark_project.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
	at org.spark_project.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
	at org.spark_project.jetty.io.FillInterest.fillable(FillInterest.java:108)
	at org.spark_project.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
	at org.spark_project.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
	at org.spark_project.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
	at java.lang.Thread.run(Thread.java:745)
2021-12-06 17:12:45,551 [SparkUI-106] INFO [org.spark_project.jetty.servlet.DefaultServlet] - content=ResourceHttpContent@54c3e958{r=jar:file:/C:/Users/ACER/.m2/repository/org/apache/spark/spark-core_2.11/2.3.0/spark-core_2.11-2.3.0.jar!/org/apache/spark/ui/static/bootstrap.min.css,gz=false}
2021-12-06 17:12:45,551 [SparkUI-106] WARN [org.spark_project.jetty.servlet.ServletHandler] - Error for /static/bootstrap.min.css
java.lang.NoSuchMethodError: javax.servlet.http.HttpServletRequest.isAsyncSupported()Z
	at org.spark_project.jetty.servlet.DefaultServlet.sendData(DefaultServlet.java:909)
	at org.spark_project.jetty.servlet.DefaultServlet.doGet(DefaultServlet.java:526)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:707)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:820)
	at org.spark_project.jetty.servlet.ServletHolder.handle(ServletHolder.java:848)
	at org.spark_project.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:584)
	at org.spark_project.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
	at org.spark_project.jetty.servlet.ServletHandler.doScope(ServletHandler.java:512)
	at org.spark_project.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
	at org.spark_project.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.spark_project.jetty.server.handler.gzip.GzipHandler.handle(GzipHandler.java:493)
	at org.spark_project.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:213)
	at org.spark_project.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
	at org.spark_project.jetty.server.Server.handle(Server.java:534)
	at org.spark_project.jetty.server.HttpChannel.handle(HttpChannel.java:320)
	at org.spark_project.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
	at org.spark_project.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
	at org.spark_project.jetty.io.FillInterest.fillable(FillInterest.java:108)
	at org.spark_project.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
	at org.spark_project.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
	at org.spark_project.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
	at java.lang.Thread.run(Thread.java:745)
2021-12-06 17:12:45,551 [SparkUI-39] WARN [org.spark_project.jetty.server.HttpChannel] - //qb:4040/static/vis.min.css
java.lang.NoSuchMethodError: javax.servlet.http.HttpServletRequest.isAsyncStarted()Z
	at org.spark_project.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:688)
	at org.spark_project.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
	at org.spark_project.jetty.servlet.ServletHandler.doScope(ServletHandler.java:512)
	at org.spark_project.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
	at org.spark_project.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.spark_project.jetty.server.handler.gzip.GzipHandler.handle(GzipHandler.java:493)
	at org.spark_project.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:213)
	at org.spark_project.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
	at org.spark_project.jetty.server.Server.handle(Server.java:534)
	at org.spark_project.jetty.server.HttpChannel.handle(HttpChannel.java:320)
	at org.spark_project.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
	at org.spark_project.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
	at org.spark_project.jetty.io.FillInterest.fillable(FillInterest.java:108)
	at org.spark_project.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
	at org.spark_project.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
	at org.spark_project.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
	at java.lang.Thread.run(Thread.java:745)
2021-12-06 17:12:45,551 [SparkUI-106] WARN [org.spark_project.jetty.server.HttpChannel] - //qb:4040/static/bootstrap.min.css
java.lang.NoSuchMethodError: javax.servlet.http.HttpServletRequest.isAsyncStarted()Z
	at org.spark_project.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:688)
	at org.spark_project.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
	at org.spark_project.jetty.servlet.ServletHandler.doScope(ServletHandler.java:512)
	at org.spark_project.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
	at org.spark_project.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.spark_project.jetty.server.handler.gzip.GzipHandler.handle(GzipHandler.java:493)
	at org.spark_project.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:213)
	at org.spark_project.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
	at org.spark_project.jetty.server.Server.handle(Server.java:534)
	at org.spark_project.jetty.server.HttpChannel.handle(HttpChannel.java:320)
	at org.spark_project.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
	at org.spark_project.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
	at org.spark_project.jetty.io.FillInterest.fillable(FillInterest.java:108)
	at org.spark_project.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
	at org.spark_project.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
	at org.spark_project.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
	at java.lang.Thread.run(Thread.java:745)
2021-12-06 17:12:45,593 [SparkUI-39] INFO [org.spark_project.jetty.servlet.DefaultServlet] - content=ResourceHttpContent@36e660c5{r=jar:file:/C:/Users/ACER/.m2/repository/org/apache/spark/spark-core_2.11/2.3.0/spark-core_2.11-2.3.0.jar!/org/apache/spark/ui/static/jquery-1.11.1.min.js,gz=false}
2021-12-06 17:12:45,593 [SparkUI-43] INFO [org.spark_project.jetty.servlet.DefaultServlet] - content=ResourceHttpContent@2264c11c{r=jar:file:/C:/Users/ACER/.m2/repository/org/apache/spark/spark-core_2.11/2.3.0/spark-core_2.11-2.3.0.jar!/org/apache/spark/ui/static/sorttable.js,gz=false}
2021-12-06 17:12:45,593 [SparkUI-38] INFO [org.spark_project.jetty.servlet.DefaultServlet] - content=ResourceHttpContent@7a3a1f7f{r=jar:file:/C:/Users/ACER/.m2/repository/org/apache/spark/spark-core_2.11/2.3.0/spark-core_2.11-2.3.0.jar!/org/apache/spark/ui/static/vis.min.js,gz=false}
2021-12-06 17:12:45,593 [SparkUI-43] WARN [org.spark_project.jetty.servlet.ServletHandler] - Error for /static/sorttable.js
java.lang.NoSuchMethodError: javax.servlet.http.HttpServletRequest.isAsyncSupported()Z
	at org.spark_project.jetty.servlet.DefaultServlet.sendData(DefaultServlet.java:909)
	at org.spark_project.jetty.servlet.DefaultServlet.doGet(DefaultServlet.java:526)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:707)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:820)
	at org.spark_project.jetty.servlet.ServletHolder.handle(ServletHolder.java:848)
	at org.spark_project.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:584)
	at org.spark_project.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
	at org.spark_project.jetty.servlet.ServletHandler.doScope(ServletHandler.java:512)
	at org.spark_project.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
	at org.spark_project.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.spark_project.jetty.server.handler.gzip.GzipHandler.handle(GzipHandler.java:493)
	at org.spark_project.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:213)
	at org.spark_project.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
	at org.spark_project.jetty.server.Server.handle(Server.java:534)
	at org.spark_project.jetty.server.HttpChannel.handle(HttpChannel.java:320)
	at org.spark_project.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
	at org.spark_project.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
	at org.spark_project.jetty.io.FillInterest.fillable(FillInterest.java:108)
	at org.spark_project.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
	at org.spark_project.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
	at org.spark_project.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
	at java.lang.Thread.run(Thread.java:745)
2021-12-06 17:12:45,593 [SparkUI-39] WARN [org.spark_project.jetty.servlet.ServletHandler] - Error for /static/jquery-1.11.1.min.js
java.lang.NoSuchMethodError: javax.servlet.http.HttpServletRequest.isAsyncSupported()Z
	at org.spark_project.jetty.servlet.DefaultServlet.sendData(DefaultServlet.java:909)
	at org.spark_project.jetty.servlet.DefaultServlet.doGet(DefaultServlet.java:526)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:707)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:820)
	at org.spark_project.jetty.servlet.ServletHolder.handle(ServletHolder.java:848)
	at org.spark_project.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:584)
	at org.spark_project.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
	at org.spark_project.jetty.servlet.ServletHandler.doScope(ServletHandler.java:512)
	at org.spark_project.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
	at org.spark_project.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.spark_project.jetty.server.handler.gzip.GzipHandler.handle(GzipHandler.java:493)
	at org.spark_project.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:213)
	at org.spark_project.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
	at org.spark_project.jetty.server.Server.handle(Server.java:534)
	at org.spark_project.jetty.server.HttpChannel.handle(HttpChannel.java:320)
	at org.spark_project.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
	at org.spark_project.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
	at org.spark_project.jetty.io.FillInterest.fillable(FillInterest.java:108)
	at org.spark_project.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
	at org.spark_project.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
	at org.spark_project.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
	at java.lang.Thread.run(Thread.java:745)
2021-12-06 17:12:45,593 [SparkUI-38] WARN [org.spark_project.jetty.servlet.ServletHandler] - Error for /static/vis.min.js
java.lang.NoSuchMethodError: javax.servlet.http.HttpServletRequest.isAsyncSupported()Z
	at org.spark_project.jetty.servlet.DefaultServlet.sendData(DefaultServlet.java:909)
	at org.spark_project.jetty.servlet.DefaultServlet.doGet(DefaultServlet.java:526)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:707)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:820)
	at org.spark_project.jetty.servlet.ServletHolder.handle(ServletHolder.java:848)
	at org.spark_project.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:584)
	at org.spark_project.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
	at org.spark_project.jetty.servlet.ServletHandler.doScope(ServletHandler.java:512)
	at org.spark_project.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
	at org.spark_project.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.spark_project.jetty.server.handler.gzip.GzipHandler.handle(GzipHandler.java:493)
	at org.spark_project.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:213)
	at org.spark_project.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
	at org.spark_project.jetty.server.Server.handle(Server.java:534)
	at org.spark_project.jetty.server.HttpChannel.handle(HttpChannel.java:320)
	at org.spark_project.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
	at org.spark_project.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
	at org.spark_project.jetty.io.FillInterest.fillable(FillInterest.java:108)
	at org.spark_project.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
	at org.spark_project.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
	at org.spark_project.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
	at java.lang.Thread.run(Thread.java:745)
2021-12-06 17:12:45,594 [SparkUI-43] WARN [org.spark_project.jetty.server.HttpChannel] - //qb:4040/static/sorttable.js
java.lang.NoSuchMethodError: javax.servlet.http.HttpServletRequest.isAsyncStarted()Z
	at org.spark_project.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:688)
	at org.spark_project.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
	at org.spark_project.jetty.servlet.ServletHandler.doScope(ServletHandler.java:512)
	at org.spark_project.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
	at org.spark_project.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.spark_project.jetty.server.handler.gzip.GzipHandler.handle(GzipHandler.java:493)
	at org.spark_project.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:213)
	at org.spark_project.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
	at org.spark_project.jetty.server.Server.handle(Server.java:534)
	at org.spark_project.jetty.server.HttpChannel.handle(HttpChannel.java:320)
	at org.spark_project.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
	at org.spark_project.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
	at org.spark_project.jetty.io.FillInterest.fillable(FillInterest.java:108)
	at org.spark_project.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
	at org.spark_project.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
	at org.spark_project.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
	at java.lang.Thread.run(Thread.java:745)
2021-12-06 17:12:45,594 [SparkUI-38] WARN [org.spark_project.jetty.server.HttpChannel] - //qb:4040/static/vis.min.js
java.lang.NoSuchMethodError: javax.servlet.http.HttpServletRequest.isAsyncStarted()Z
	at org.spark_project.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:688)
	at org.spark_project.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
	at org.spark_project.jetty.servlet.ServletHandler.doScope(ServletHandler.java:512)
	at org.spark_project.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
	at org.spark_project.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.spark_project.jetty.server.handler.gzip.GzipHandler.handle(GzipHandler.java:493)
	at org.spark_project.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:213)
	at org.spark_project.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
	at org.spark_project.jetty.server.Server.handle(Server.java:534)
	at org.spark_project.jetty.server.HttpChannel.handle(HttpChannel.java:320)
	at org.spark_project.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
	at org.spark_project.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
	at org.spark_project.jetty.io.FillInterest.fillable(FillInterest.java:108)
	at org.spark_project.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
	at org.spark_project.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
	at org.spark_project.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
	at java.lang.Thread.run(Thread.java:745)
2021-12-06 17:12:45,594 [SparkUI-116] INFO [org.spark_project.jetty.servlet.DefaultServlet] - content=ResourceHttpContent@678ef361{r=jar:file:/C:/Users/ACER/.m2/repository/org/apache/spark/spark-core_2.11/2.3.0/spark-core_2.11-2.3.0.jar!/org/apache/spark/ui/static/table.js,gz=false}
2021-12-06 17:12:45,594 [SparkUI-39] WARN [org.spark_project.jetty.server.HttpChannel] - //qb:4040/static/jquery-1.11.1.min.js
java.lang.NoSuchMethodError: javax.servlet.http.HttpServletRequest.isAsyncStarted()Z
	at org.spark_project.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:688)
	at org.spark_project.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
	at org.spark_project.jetty.servlet.ServletHandler.doScope(ServletHandler.java:512)
	at org.spark_project.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
	at org.spark_project.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.spark_project.jetty.server.handler.gzip.GzipHandler.handle(GzipHandler.java:493)
	at org.spark_project.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:213)
	at org.spark_project.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
	at org.spark_project.jetty.server.Server.handle(Server.java:534)
	at org.spark_project.jetty.server.HttpChannel.handle(HttpChannel.java:320)
	at org.spark_project.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
	at org.spark_project.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
	at org.spark_project.jetty.io.FillInterest.fillable(FillInterest.java:108)
	at org.spark_project.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
	at org.spark_project.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
	at org.spark_project.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
	at java.lang.Thread.run(Thread.java:745)
2021-12-06 17:12:45,594 [SparkUI-116] WARN [org.spark_project.jetty.servlet.ServletHandler] - Error for /static/table.js
java.lang.NoSuchMethodError: javax.servlet.http.HttpServletRequest.isAsyncSupported()Z
	at org.spark_project.jetty.servlet.DefaultServlet.sendData(DefaultServlet.java:909)
	at org.spark_project.jetty.servlet.DefaultServlet.doGet(DefaultServlet.java:526)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:707)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:820)
	at org.spark_project.jetty.servlet.ServletHolder.handle(ServletHolder.java:848)
	at org.spark_project.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:584)
	at org.spark_project.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
	at org.spark_project.jetty.servlet.ServletHandler.doScope(ServletHandler.java:512)
	at org.spark_project.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
	at org.spark_project.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.spark_project.jetty.server.handler.gzip.GzipHandler.handle(GzipHandler.java:493)
	at org.spark_project.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:213)
	at org.spark_project.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
	at org.spark_project.jetty.server.Server.handle(Server.java:534)
	at org.spark_project.jetty.server.HttpChannel.handle(HttpChannel.java:320)
	at org.spark_project.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
	at org.spark_project.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
	at org.spark_project.jetty.io.FillInterest.fillable(FillInterest.java:108)
	at org.spark_project.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
	at org.spark_project.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
	at org.spark_project.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
	at java.lang.Thread.run(Thread.java:745)
2021-12-06 17:12:45,595 [SparkUI-116] WARN [org.spark_project.jetty.server.HttpChannel] - //qb:4040/static/table.js
java.lang.NoSuchMethodError: javax.servlet.http.HttpServletRequest.isAsyncStarted()Z
	at org.spark_project.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:688)
	at org.spark_project.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
	at org.spark_project.jetty.servlet.ServletHandler.doScope(ServletHandler.java:512)
	at org.spark_project.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
	at org.spark_project.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.spark_project.jetty.server.handler.gzip.GzipHandler.handle(GzipHandler.java:493)
	at org.spark_project.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:213)
	at org.spark_project.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
	at org.spark_project.jetty.server.Server.handle(Server.java:534)
	at org.spark_project.jetty.server.HttpChannel.handle(HttpChannel.java:320)
	at org.spark_project.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
	at org.spark_project.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
	at org.spark_project.jetty.io.FillInterest.fillable(FillInterest.java:108)
	at org.spark_project.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
	at org.spark_project.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
	at org.spark_project.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
	at java.lang.Thread.run(Thread.java:745)
2021-12-06 17:12:45,596 [SparkUI-107] INFO [org.spark_project.jetty.servlet.DefaultServlet] - content=ResourceHttpContent@368baf01{r=jar:file:/C:/Users/ACER/.m2/repository/org/apache/spark/spark-core_2.11/2.3.0/spark-core_2.11-2.3.0.jar!/org/apache/spark/ui/static/initialize-tooltips.js,gz=false}
2021-12-06 17:12:45,596 [SparkUI-107] WARN [org.spark_project.jetty.servlet.ServletHandler] - Error for /static/initialize-tooltips.js
java.lang.NoSuchMethodError: javax.servlet.http.HttpServletRequest.isAsyncSupported()Z
	at org.spark_project.jetty.servlet.DefaultServlet.sendData(DefaultServlet.java:909)
	at org.spark_project.jetty.servlet.DefaultServlet.doGet(DefaultServlet.java:526)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:707)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:820)
	at org.spark_project.jetty.servlet.ServletHolder.handle(ServletHolder.java:848)
	at org.spark_project.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:584)
	at org.spark_project.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
	at org.spark_project.jetty.servlet.ServletHandler.doScope(ServletHandler.java:512)
	at org.spark_project.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
	at org.spark_project.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.spark_project.jetty.server.handler.gzip.GzipHandler.handle(GzipHandler.java:493)
	at org.spark_project.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:213)
	at org.spark_project.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
	at org.spark_project.jetty.server.Server.handle(Server.java:534)
	at org.spark_project.jetty.server.HttpChannel.handle(HttpChannel.java:320)
	at org.spark_project.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
	at org.spark_project.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
	at org.spark_project.jetty.io.FillInterest.fillable(FillInterest.java:108)
	at org.spark_project.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
	at org.spark_project.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
	at org.spark_project.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
	at java.lang.Thread.run(Thread.java:745)
2021-12-06 17:12:45,597 [SparkUI-107] WARN [org.spark_project.jetty.server.HttpChannel] - //qb:4040/static/initialize-tooltips.js
java.lang.NoSuchMethodError: javax.servlet.http.HttpServletRequest.isAsyncStarted()Z
	at org.spark_project.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:688)
	at org.spark_project.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
	at org.spark_project.jetty.servlet.ServletHandler.doScope(ServletHandler.java:512)
	at org.spark_project.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
	at org.spark_project.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.spark_project.jetty.server.handler.gzip.GzipHandler.handle(GzipHandler.java:493)
	at org.spark_project.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:213)
	at org.spark_project.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
	at org.spark_project.jetty.server.Server.handle(Server.java:534)
	at org.spark_project.jetty.server.HttpChannel.handle(HttpChannel.java:320)
	at org.spark_project.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
	at org.spark_project.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
	at org.spark_project.jetty.io.FillInterest.fillable(FillInterest.java:108)
	at org.spark_project.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
	at org.spark_project.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
	at org.spark_project.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
	at java.lang.Thread.run(Thread.java:745)
2021-12-06 17:12:45,597 [SparkUI-113] INFO [org.spark_project.jetty.servlet.DefaultServlet] - content=ResourceHttpContent@21c1381d{r=jar:file:/C:/Users/ACER/.m2/repository/org/apache/spark/spark-core_2.11/2.3.0/spark-core_2.11-2.3.0.jar!/org/apache/spark/ui/static/bootstrap-tooltip.js,gz=false}
2021-12-06 17:12:45,597 [SparkUI-113] WARN [org.spark_project.jetty.servlet.ServletHandler] - Error for /static/bootstrap-tooltip.js
java.lang.NoSuchMethodError: javax.servlet.http.HttpServletRequest.isAsyncSupported()Z
	at org.spark_project.jetty.servlet.DefaultServlet.sendData(DefaultServlet.java:909)
	at org.spark_project.jetty.servlet.DefaultServlet.doGet(DefaultServlet.java:526)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:707)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:820)
	at org.spark_project.jetty.servlet.ServletHolder.handle(ServletHolder.java:848)
	at org.spark_project.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:584)
	at org.spark_project.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
	at org.spark_project.jetty.servlet.ServletHandler.doScope(ServletHandler.java:512)
	at org.spark_project.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
	at org.spark_project.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.spark_project.jetty.server.handler.gzip.GzipHandler.handle(GzipHandler.java:493)
	at org.spark_project.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:213)
	at org.spark_project.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
	at org.spark_project.jetty.server.Server.handle(Server.java:534)
	at org.spark_project.jetty.server.HttpChannel.handle(HttpChannel.java:320)
	at org.spark_project.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
	at org.spark_project.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
	at org.spark_project.jetty.io.FillInterest.fillable(FillInterest.java:108)
	at org.spark_project.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
	at org.spark_project.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
	at org.spark_project.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
	at java.lang.Thread.run(Thread.java:745)
2021-12-06 17:12:45,598 [SparkUI-113] WARN [org.spark_project.jetty.server.HttpChannel] - //qb:4040/static/bootstrap-tooltip.js
java.lang.NoSuchMethodError: javax.servlet.http.HttpServletRequest.isAsyncStarted()Z
	at org.spark_project.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:688)
	at org.spark_project.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
	at org.spark_project.jetty.servlet.ServletHandler.doScope(ServletHandler.java:512)
	at org.spark_project.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
	at org.spark_project.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.spark_project.jetty.server.handler.gzip.GzipHandler.handle(GzipHandler.java:493)
	at org.spark_project.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:213)
	at org.spark_project.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
	at org.spark_project.jetty.server.Server.handle(Server.java:534)
	at org.spark_project.jetty.server.HttpChannel.handle(HttpChannel.java:320)
	at org.spark_project.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
	at org.spark_project.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
	at org.spark_project.jetty.io.FillInterest.fillable(FillInterest.java:108)
	at org.spark_project.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
	at org.spark_project.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
	at org.spark_project.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
	at java.lang.Thread.run(Thread.java:745)
2021-12-06 17:12:45,600 [SparkUI-39] INFO [org.spark_project.jetty.servlet.DefaultServlet] - content=ResourceHttpContent@286ba703{r=jar:file:/C:/Users/ACER/.m2/repository/org/apache/spark/spark-core_2.11/2.3.0/spark-core_2.11-2.3.0.jar!/org/apache/spark/ui/static/webui.js,gz=false}
2021-12-06 17:12:45,601 [SparkUI-39] WARN [org.spark_project.jetty.servlet.ServletHandler] - Error for /static/webui.js
java.lang.NoSuchMethodError: javax.servlet.http.HttpServletRequest.isAsyncSupported()Z
	at org.spark_project.jetty.servlet.DefaultServlet.sendData(DefaultServlet.java:909)
	at org.spark_project.jetty.servlet.DefaultServlet.doGet(DefaultServlet.java:526)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:707)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:820)
	at org.spark_project.jetty.servlet.ServletHolder.handle(ServletHolder.java:848)
	at org.spark_project.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:584)
	at org.spark_project.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
	at org.spark_project.jetty.servlet.ServletHandler.doScope(ServletHandler.java:512)
	at org.spark_project.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
	at org.spark_project.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.spark_project.jetty.server.handler.gzip.GzipHandler.handle(GzipHandler.java:493)
	at org.spark_project.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:213)
	at org.spark_project.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
	at org.spark_project.jetty.server.Server.handle(Server.java:534)
	at org.spark_project.jetty.server.HttpChannel.handle(HttpChannel.java:320)
	at org.spark_project.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
	at org.spark_project.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
	at org.spark_project.jetty.io.FillInterest.fillable(FillInterest.java:108)
	at org.spark_project.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
	at org.spark_project.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
	at org.spark_project.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
	at java.lang.Thread.run(Thread.java:745)
2021-12-06 17:12:45,601 [SparkUI-39] WARN [org.spark_project.jetty.server.HttpChannel] - //qb:4040/static/webui.js
java.lang.NoSuchMethodError: javax.servlet.http.HttpServletRequest.isAsyncStarted()Z
	at org.spark_project.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:688)
	at org.spark_project.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
	at org.spark_project.jetty.servlet.ServletHandler.doScope(ServletHandler.java:512)
	at org.spark_project.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
	at org.spark_project.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.spark_project.jetty.server.handler.gzip.GzipHandler.handle(GzipHandler.java:493)
	at org.spark_project.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:213)
	at org.spark_project.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
	at org.spark_project.jetty.server.Server.handle(Server.java:534)
	at org.spark_project.jetty.server.HttpChannel.handle(HttpChannel.java:320)
	at org.spark_project.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
	at org.spark_project.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
	at org.spark_project.jetty.io.FillInterest.fillable(FillInterest.java:108)
	at org.spark_project.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
	at org.spark_project.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
	at org.spark_project.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
	at java.lang.Thread.run(Thread.java:745)
2021-12-06 17:12:45,601 [SparkUI-106] INFO [org.spark_project.jetty.servlet.DefaultServlet] - content=ResourceHttpContent@3c85d887{r=jar:file:/C:/Users/ACER/.m2/repository/org/apache/spark/spark-core_2.11/2.3.0/spark-core_2.11-2.3.0.jar!/org/apache/spark/ui/static/additional-metrics.js,gz=false}
2021-12-06 17:12:45,601 [SparkUI-106] WARN [org.spark_project.jetty.servlet.ServletHandler] - Error for /static/additional-metrics.js
java.lang.NoSuchMethodError: javax.servlet.http.HttpServletRequest.isAsyncSupported()Z
	at org.spark_project.jetty.servlet.DefaultServlet.sendData(DefaultServlet.java:909)
	at org.spark_project.jetty.servlet.DefaultServlet.doGet(DefaultServlet.java:526)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:707)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:820)
	at org.spark_project.jetty.servlet.ServletHolder.handle(ServletHolder.java:848)
	at org.spark_project.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:584)
	at org.spark_project.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
	at org.spark_project.jetty.servlet.ServletHandler.doScope(ServletHandler.java:512)
	at org.spark_project.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
	at org.spark_project.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.spark_project.jetty.server.handler.gzip.GzipHandler.handle(GzipHandler.java:493)
	at org.spark_project.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:213)
	at org.spark_project.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
	at org.spark_project.jetty.server.Server.handle(Server.java:534)
	at org.spark_project.jetty.server.HttpChannel.handle(HttpChannel.java:320)
	at org.spark_project.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
	at org.spark_project.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
	at org.spark_project.jetty.io.FillInterest.fillable(FillInterest.java:108)
	at org.spark_project.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
	at org.spark_project.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
	at org.spark_project.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
	at java.lang.Thread.run(Thread.java:745)
2021-12-06 17:12:45,602 [SparkUI-106] WARN [org.spark_project.jetty.server.HttpChannel] - //qb:4040/static/additional-metrics.js
java.lang.NoSuchMethodError: javax.servlet.http.HttpServletRequest.isAsyncStarted()Z
	at org.spark_project.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:688)
	at org.spark_project.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
	at org.spark_project.jetty.servlet.ServletHandler.doScope(ServletHandler.java:512)
	at org.spark_project.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
	at org.spark_project.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.spark_project.jetty.server.handler.gzip.GzipHandler.handle(GzipHandler.java:493)
	at org.spark_project.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:213)
	at org.spark_project.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
	at org.spark_project.jetty.server.Server.handle(Server.java:534)
	at org.spark_project.jetty.server.HttpChannel.handle(HttpChannel.java:320)
	at org.spark_project.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
	at org.spark_project.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
	at org.spark_project.jetty.io.FillInterest.fillable(FillInterest.java:108)
	at org.spark_project.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
	at org.spark_project.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
	at org.spark_project.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
	at java.lang.Thread.run(Thread.java:745)
2021-12-06 17:12:45,602 [SparkUI-108] INFO [org.spark_project.jetty.servlet.DefaultServlet] - content=ResourceHttpContent@6a22dfff{r=jar:file:/C:/Users/ACER/.m2/repository/org/apache/spark/spark-core_2.11/2.3.0/spark-core_2.11-2.3.0.jar!/org/apache/spark/ui/static/log-view.js,gz=false}
2021-12-06 17:12:45,602 [SparkUI-108] WARN [org.spark_project.jetty.servlet.ServletHandler] - Error for /static/log-view.js
java.lang.NoSuchMethodError: javax.servlet.http.HttpServletRequest.isAsyncSupported()Z
	at org.spark_project.jetty.servlet.DefaultServlet.sendData(DefaultServlet.java:909)
	at org.spark_project.jetty.servlet.DefaultServlet.doGet(DefaultServlet.java:526)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:707)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:820)
	at org.spark_project.jetty.servlet.ServletHolder.handle(ServletHolder.java:848)
	at org.spark_project.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:584)
	at org.spark_project.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
	at org.spark_project.jetty.servlet.ServletHandler.doScope(ServletHandler.java:512)
	at org.spark_project.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
	at org.spark_project.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.spark_project.jetty.server.handler.gzip.GzipHandler.handle(GzipHandler.java:493)
	at org.spark_project.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:213)
	at org.spark_project.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
	at org.spark_project.jetty.server.Server.handle(Server.java:534)
	at org.spark_project.jetty.server.HttpChannel.handle(HttpChannel.java:320)
	at org.spark_project.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
	at org.spark_project.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
	at org.spark_project.jetty.io.FillInterest.fillable(FillInterest.java:108)
	at org.spark_project.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
	at org.spark_project.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
	at org.spark_project.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
	at java.lang.Thread.run(Thread.java:745)
2021-12-06 17:12:45,603 [SparkUI-108] WARN [org.spark_project.jetty.server.HttpChannel] - //qb:4040/static/log-view.js
java.lang.NoSuchMethodError: javax.servlet.http.HttpServletRequest.isAsyncStarted()Z
	at org.spark_project.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:688)
	at org.spark_project.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
	at org.spark_project.jetty.servlet.ServletHandler.doScope(ServletHandler.java:512)
	at org.spark_project.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
	at org.spark_project.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.spark_project.jetty.server.handler.gzip.GzipHandler.handle(GzipHandler.java:493)
	at org.spark_project.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:213)
	at org.spark_project.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
	at org.spark_project.jetty.server.Server.handle(Server.java:534)
	at org.spark_project.jetty.server.HttpChannel.handle(HttpChannel.java:320)
	at org.spark_project.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
	at org.spark_project.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
	at org.spark_project.jetty.io.FillInterest.fillable(FillInterest.java:108)
	at org.spark_project.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
	at org.spark_project.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
	at org.spark_project.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
	at java.lang.Thread.run(Thread.java:745)
2021-12-06 17:12:45,603 [SparkUI-107] INFO [org.spark_project.jetty.servlet.DefaultServlet] - content=ResourceHttpContent@133d9684{r=jar:file:/C:/Users/ACER/.m2/repository/org/apache/spark/spark-core_2.11/2.3.0/spark-core_2.11-2.3.0.jar!/org/apache/spark/ui/static/timeline-view.js,gz=false}
2021-12-06 17:12:45,603 [SparkUI-107] WARN [org.spark_project.jetty.servlet.ServletHandler] - Error for /static/timeline-view.js
java.lang.NoSuchMethodError: javax.servlet.http.HttpServletRequest.isAsyncSupported()Z
	at org.spark_project.jetty.servlet.DefaultServlet.sendData(DefaultServlet.java:909)
	at org.spark_project.jetty.servlet.DefaultServlet.doGet(DefaultServlet.java:526)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:707)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:820)
	at org.spark_project.jetty.servlet.ServletHolder.handle(ServletHolder.java:848)
	at org.spark_project.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:584)
	at org.spark_project.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
	at org.spark_project.jetty.servlet.ServletHandler.doScope(ServletHandler.java:512)
	at org.spark_project.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
	at org.spark_project.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.spark_project.jetty.server.handler.gzip.GzipHandler.handle(GzipHandler.java:493)
	at org.spark_project.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:213)
	at org.spark_project.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
	at org.spark_project.jetty.server.Server.handle(Server.java:534)
	at org.spark_project.jetty.server.HttpChannel.handle(HttpChannel.java:320)
	at org.spark_project.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
	at org.spark_project.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
	at org.spark_project.jetty.io.FillInterest.fillable(FillInterest.java:108)
	at org.spark_project.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
	at org.spark_project.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
	at org.spark_project.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
	at java.lang.Thread.run(Thread.java:745)
2021-12-06 17:12:45,603 [SparkUI-107] WARN [org.spark_project.jetty.server.HttpChannel] - //qb:4040/static/timeline-view.js
java.lang.NoSuchMethodError: javax.servlet.http.HttpServletRequest.isAsyncStarted()Z
	at org.spark_project.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:688)
	at org.spark_project.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
	at org.spark_project.jetty.servlet.ServletHandler.doScope(ServletHandler.java:512)
	at org.spark_project.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
	at org.spark_project.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.spark_project.jetty.server.handler.gzip.GzipHandler.handle(GzipHandler.java:493)
	at org.spark_project.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:213)
	at org.spark_project.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
	at org.spark_project.jetty.server.Server.handle(Server.java:534)
	at org.spark_project.jetty.server.HttpChannel.handle(HttpChannel.java:320)
	at org.spark_project.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
	at org.spark_project.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
	at org.spark_project.jetty.io.FillInterest.fillable(FillInterest.java:108)
	at org.spark_project.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
	at org.spark_project.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
	at org.spark_project.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
	at java.lang.Thread.run(Thread.java:745)
2021-12-06 17:12:45,637 [SparkUI-113] INFO [org.spark_project.jetty.servlet.DefaultServlet] - content=ResourceHttpContent@50c8f9f5{r=jar:file:/C:/Users/ACER/.m2/repository/org/apache/spark/spark-core_2.11/2.3.0/spark-core_2.11-2.3.0.jar!/org/apache/spark/ui/static/spark-logo-77x50px-hd.png,gz=false}
2021-12-06 17:12:45,637 [SparkUI-113] WARN [org.spark_project.jetty.servlet.ServletHandler] - Error for /static/spark-logo-77x50px-hd.png
java.lang.NoSuchMethodError: javax.servlet.http.HttpServletRequest.isAsyncSupported()Z
	at org.spark_project.jetty.servlet.DefaultServlet.sendData(DefaultServlet.java:909)
	at org.spark_project.jetty.servlet.DefaultServlet.doGet(DefaultServlet.java:526)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:707)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:820)
	at org.spark_project.jetty.servlet.ServletHolder.handle(ServletHolder.java:848)
	at org.spark_project.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:584)
	at org.spark_project.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
	at org.spark_project.jetty.servlet.ServletHandler.doScope(ServletHandler.java:512)
	at org.spark_project.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
	at org.spark_project.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.spark_project.jetty.server.handler.gzip.GzipHandler.handle(GzipHandler.java:448)
	at org.spark_project.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:213)
	at org.spark_project.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
	at org.spark_project.jetty.server.Server.handle(Server.java:534)
	at org.spark_project.jetty.server.HttpChannel.handle(HttpChannel.java:320)
	at org.spark_project.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
	at org.spark_project.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
	at org.spark_project.jetty.io.FillInterest.fillable(FillInterest.java:108)
	at org.spark_project.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
	at org.spark_project.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
	at org.spark_project.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
	at java.lang.Thread.run(Thread.java:745)
2021-12-06 17:12:45,638 [SparkUI-113] WARN [org.spark_project.jetty.server.HttpChannel] - //qb:4040/static/spark-logo-77x50px-hd.png
java.lang.NoSuchMethodError: javax.servlet.http.HttpServletRequest.isAsyncStarted()Z
	at org.spark_project.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:688)
	at org.spark_project.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
	at org.spark_project.jetty.servlet.ServletHandler.doScope(ServletHandler.java:512)
	at org.spark_project.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
	at org.spark_project.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.spark_project.jetty.server.handler.gzip.GzipHandler.handle(GzipHandler.java:448)
	at org.spark_project.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:213)
	at org.spark_project.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
	at org.spark_project.jetty.server.Server.handle(Server.java:534)
	at org.spark_project.jetty.server.HttpChannel.handle(HttpChannel.java:320)
	at org.spark_project.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
	at org.spark_project.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
	at org.spark_project.jetty.io.FillInterest.fillable(FillInterest.java:108)
	at org.spark_project.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
	at org.spark_project.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
	at org.spark_project.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
	at java.lang.Thread.run(Thread.java:745)
