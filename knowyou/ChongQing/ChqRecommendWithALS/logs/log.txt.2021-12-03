2021-12-03 16:30:46,200 [main] INFO [org.apache.spark.SparkContext] - Running Spark version 2.3.0
2021-12-03 16:30:46,580 [main] INFO [org.apache.spark.SparkContext] - Submitted application: PaidPromotion
2021-12-03 16:30:46,650 [main] INFO [org.apache.spark.SecurityManager] - Changing view acls to: ACER,root
2021-12-03 16:30:46,651 [main] INFO [org.apache.spark.SecurityManager] - Changing modify acls to: ACER,root
2021-12-03 16:30:46,651 [main] INFO [org.apache.spark.SecurityManager] - Changing view acls groups to: 
2021-12-03 16:30:46,652 [main] INFO [org.apache.spark.SecurityManager] - Changing modify acls groups to: 
2021-12-03 16:30:46,652 [main] INFO [org.apache.spark.SecurityManager] - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(ACER, root); groups with view permissions: Set(); users  with modify permissions: Set(ACER, root); groups with modify permissions: Set()
2021-12-03 16:30:47,264 [main] INFO [org.apache.spark.util.Utils] - Successfully started service 'sparkDriver' on port 64157.
2021-12-03 16:30:47,288 [main] INFO [org.apache.spark.SparkEnv] - Registering MapOutputTracker
2021-12-03 16:30:47,308 [main] INFO [org.apache.spark.SparkEnv] - Registering BlockManagerMaster
2021-12-03 16:30:47,311 [main] INFO [org.apache.spark.storage.BlockManagerMasterEndpoint] - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2021-12-03 16:30:47,311 [main] INFO [org.apache.spark.storage.BlockManagerMasterEndpoint] - BlockManagerMasterEndpoint up
2021-12-03 16:30:47,322 [main] INFO [org.apache.spark.storage.DiskBlockManager] - Created local directory at C:\Users\ACER\AppData\Local\Temp\blockmgr-3dd1c0f7-5d94-4971-a1b0-efb279a188f6
2021-12-03 16:30:47,340 [main] INFO [org.apache.spark.storage.memory.MemoryStore] - MemoryStore started with capacity 1990.8 MB
2021-12-03 16:30:47,352 [main] INFO [org.apache.spark.SparkEnv] - Registering OutputCommitCoordinator
2021-12-03 16:30:47,418 [main] INFO [org.spark_project.jetty.util.log] - Logging initialized @2176ms
2021-12-03 16:30:47,472 [main] INFO [org.spark_project.jetty.server.Server] - jetty-9.3.z-SNAPSHOT
2021-12-03 16:30:47,485 [main] INFO [org.spark_project.jetty.server.Server] - Started @2244ms
2021-12-03 16:30:47,512 [main] INFO [org.spark_project.jetty.server.AbstractConnector] - Started ServerConnector@5b800468{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2021-12-03 16:30:47,512 [main] INFO [org.apache.spark.util.Utils] - Successfully started service 'SparkUI' on port 4040.
2021-12-03 16:30:47,534 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@1568159{/jobs,null,AVAILABLE,@Spark}
2021-12-03 16:30:47,535 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@63cd604c{/jobs/json,null,AVAILABLE,@Spark}
2021-12-03 16:30:47,536 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@3954d008{/jobs/job,null,AVAILABLE,@Spark}
2021-12-03 16:30:47,537 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@6d8792db{/jobs/job/json,null,AVAILABLE,@Spark}
2021-12-03 16:30:47,538 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@3a1d593e{/stages,null,AVAILABLE,@Spark}
2021-12-03 16:30:47,539 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@285d851a{/stages/json,null,AVAILABLE,@Spark}
2021-12-03 16:30:47,540 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@7876d598{/stages/stage,null,AVAILABLE,@Spark}
2021-12-03 16:30:47,542 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@4985cbcb{/stages/stage/json,null,AVAILABLE,@Spark}
2021-12-03 16:30:47,542 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@54361a9{/stages/pool,null,AVAILABLE,@Spark}
2021-12-03 16:30:47,543 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@293bb8a5{/stages/pool/json,null,AVAILABLE,@Spark}
2021-12-03 16:30:47,544 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@290b1b2e{/storage,null,AVAILABLE,@Spark}
2021-12-03 16:30:47,545 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@5db4c359{/storage/json,null,AVAILABLE,@Spark}
2021-12-03 16:30:47,546 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@6fefce9e{/storage/rdd,null,AVAILABLE,@Spark}
2021-12-03 16:30:47,547 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@8a589a2{/storage/rdd/json,null,AVAILABLE,@Spark}
2021-12-03 16:30:47,548 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@5cc69cfe{/environment,null,AVAILABLE,@Spark}
2021-12-03 16:30:47,549 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@11dee337{/environment/json,null,AVAILABLE,@Spark}
2021-12-03 16:30:47,550 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@74bdc168{/executors,null,AVAILABLE,@Spark}
2021-12-03 16:30:47,551 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@7bb3a9fe{/executors/json,null,AVAILABLE,@Spark}
2021-12-03 16:30:47,552 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@f19c9d2{/executors/threadDump,null,AVAILABLE,@Spark}
2021-12-03 16:30:47,553 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@a77614d{/executors/threadDump/json,null,AVAILABLE,@Spark}
2021-12-03 16:30:47,560 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@523424b5{/static,null,AVAILABLE,@Spark}
2021-12-03 16:30:47,561 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@12cd9150{/,null,AVAILABLE,@Spark}
2021-12-03 16:30:47,563 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@32fe9d0a{/api,null,AVAILABLE,@Spark}
2021-12-03 16:30:47,564 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@59fc684e{/jobs/job/kill,null,AVAILABLE,@Spark}
2021-12-03 16:30:47,564 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@355e34c7{/stages/stage/kill,null,AVAILABLE,@Spark}
2021-12-03 16:30:47,566 [main] INFO [org.apache.spark.ui.SparkUI] - Bound SparkUI to 0.0.0.0, and started at http://qb:4040
2021-12-03 16:30:47,647 [main] INFO [org.apache.spark.executor.Executor] - Starting executor ID driver on host localhost
2021-12-03 16:30:47,692 [main] INFO [org.apache.spark.util.Utils] - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 64198.
2021-12-03 16:30:47,693 [main] INFO [org.apache.spark.network.netty.NettyBlockTransferService] - Server created on qb:64198
2021-12-03 16:30:47,695 [main] INFO [org.apache.spark.storage.BlockManager] - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2021-12-03 16:30:47,696 [main] INFO [org.apache.spark.storage.BlockManagerMaster] - Registering BlockManager BlockManagerId(driver, qb, 64198, None)
2021-12-03 16:30:47,699 [dispatcher-event-loop-10] INFO [org.apache.spark.storage.BlockManagerMasterEndpoint] - Registering block manager qb:64198 with 1990.8 MB RAM, BlockManagerId(driver, qb, 64198, None)
2021-12-03 16:30:47,701 [main] INFO [org.apache.spark.storage.BlockManagerMaster] - Registered BlockManager BlockManagerId(driver, qb, 64198, None)
2021-12-03 16:30:47,702 [main] INFO [org.apache.spark.storage.BlockManager] - Initialized BlockManager: BlockManagerId(driver, qb, 64198, None)
2021-12-03 16:30:47,842 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@6fe46b62{/metrics/json,null,AVAILABLE,@Spark}
2021-12-03 16:30:48,335 [main] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_0 stored as values in memory (estimated size 284.2 KB, free 1990.5 MB)
2021-12-03 16:30:48,563 [main] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_0_piece0 stored as bytes in memory (estimated size 24.5 KB, free 1990.5 MB)
2021-12-03 16:30:48,565 [dispatcher-event-loop-0] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_0_piece0 in memory on qb:64198 (size: 24.5 KB, free: 1990.8 MB)
2021-12-03 16:30:48,568 [main] INFO [org.apache.spark.SparkContext] - Created broadcast 0 from textFile at PaidPromotionAdjustParameter.scala:59
2021-12-03 16:30:50,962 [Thread-1] INFO [org.apache.spark.SparkContext] - Invoking stop() from shutdown hook
2021-12-03 16:30:50,967 [Thread-1] INFO [org.spark_project.jetty.server.AbstractConnector] - Stopped Spark@5b800468{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2021-12-03 16:30:50,968 [Thread-1] INFO [org.apache.spark.ui.SparkUI] - Stopped Spark web UI at http://qb:4040
2021-12-03 16:30:50,975 [dispatcher-event-loop-3] INFO [org.apache.spark.MapOutputTrackerMasterEndpoint] - MapOutputTrackerMasterEndpoint stopped!
2021-12-03 16:30:50,982 [Thread-1] INFO [org.apache.spark.storage.memory.MemoryStore] - MemoryStore cleared
2021-12-03 16:30:50,982 [Thread-1] INFO [org.apache.spark.storage.BlockManager] - BlockManager stopped
2021-12-03 16:30:50,987 [Thread-1] INFO [org.apache.spark.storage.BlockManagerMaster] - BlockManagerMaster stopped
2021-12-03 16:30:50,990 [dispatcher-event-loop-8] INFO [org.apache.spark.scheduler.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint] - OutputCommitCoordinator stopped!
2021-12-03 16:30:50,992 [Thread-1] INFO [org.apache.spark.SparkContext] - Successfully stopped SparkContext
2021-12-03 16:30:50,992 [Thread-1] INFO [org.apache.spark.util.ShutdownHookManager] - Shutdown hook called
2021-12-03 16:30:50,993 [Thread-1] INFO [org.apache.spark.util.ShutdownHookManager] - Deleting directory C:\Users\ACER\AppData\Local\Temp\spark-57783d00-e255-4ab6-9df4-b4eba716d756
2021-12-03 16:33:15,676 [main] INFO [org.apache.spark.SparkContext] - Running Spark version 2.3.0
2021-12-03 16:33:15,943 [main] INFO [org.apache.spark.SparkContext] - Submitted application: PaidPromotion
2021-12-03 16:33:15,989 [main] INFO [org.apache.spark.SecurityManager] - Changing view acls to: ACER,root
2021-12-03 16:33:15,989 [main] INFO [org.apache.spark.SecurityManager] - Changing modify acls to: ACER,root
2021-12-03 16:33:15,989 [main] INFO [org.apache.spark.SecurityManager] - Changing view acls groups to: 
2021-12-03 16:33:15,990 [main] INFO [org.apache.spark.SecurityManager] - Changing modify acls groups to: 
2021-12-03 16:33:15,990 [main] INFO [org.apache.spark.SecurityManager] - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(ACER, root); groups with view permissions: Set(); users  with modify permissions: Set(ACER, root); groups with modify permissions: Set()
2021-12-03 16:33:16,557 [main] INFO [org.apache.spark.util.Utils] - Successfully started service 'sparkDriver' on port 64341.
2021-12-03 16:33:16,573 [main] INFO [org.apache.spark.SparkEnv] - Registering MapOutputTracker
2021-12-03 16:33:16,587 [main] INFO [org.apache.spark.SparkEnv] - Registering BlockManagerMaster
2021-12-03 16:33:16,590 [main] INFO [org.apache.spark.storage.BlockManagerMasterEndpoint] - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2021-12-03 16:33:16,590 [main] INFO [org.apache.spark.storage.BlockManagerMasterEndpoint] - BlockManagerMasterEndpoint up
2021-12-03 16:33:16,597 [main] INFO [org.apache.spark.storage.DiskBlockManager] - Created local directory at C:\Users\ACER\AppData\Local\Temp\blockmgr-4b42c0e0-b15c-41f1-aa79-5210656e5cc2
2021-12-03 16:33:16,612 [main] INFO [org.apache.spark.storage.memory.MemoryStore] - MemoryStore started with capacity 1990.8 MB
2021-12-03 16:33:16,622 [main] INFO [org.apache.spark.SparkEnv] - Registering OutputCommitCoordinator
2021-12-03 16:33:16,675 [main] INFO [org.spark_project.jetty.util.log] - Logging initialized @1827ms
2021-12-03 16:33:16,721 [main] INFO [org.spark_project.jetty.server.Server] - jetty-9.3.z-SNAPSHOT
2021-12-03 16:33:16,732 [main] INFO [org.spark_project.jetty.server.Server] - Started @1884ms
2021-12-03 16:33:16,755 [main] INFO [org.spark_project.jetty.server.AbstractConnector] - Started ServerConnector@5f7f2382{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2021-12-03 16:33:16,755 [main] INFO [org.apache.spark.util.Utils] - Successfully started service 'SparkUI' on port 4040.
2021-12-03 16:33:16,778 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@3af17be2{/jobs,null,AVAILABLE,@Spark}
2021-12-03 16:33:16,779 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@6a1d204a{/jobs/json,null,AVAILABLE,@Spark}
2021-12-03 16:33:16,780 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@72ccd81a{/jobs/job,null,AVAILABLE,@Spark}
2021-12-03 16:33:16,781 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@5d25e6bb{/jobs/job/json,null,AVAILABLE,@Spark}
2021-12-03 16:33:16,782 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@7859e786{/stages,null,AVAILABLE,@Spark}
2021-12-03 16:33:16,784 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@5118388b{/stages/json,null,AVAILABLE,@Spark}
2021-12-03 16:33:16,785 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@71104a4{/stages/stage,null,AVAILABLE,@Spark}
2021-12-03 16:33:16,788 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@332a7fce{/stages/stage/json,null,AVAILABLE,@Spark}
2021-12-03 16:33:16,789 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@37ebc9d8{/stages/pool,null,AVAILABLE,@Spark}
2021-12-03 16:33:16,790 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@6e9319f{/stages/pool/json,null,AVAILABLE,@Spark}
2021-12-03 16:33:16,792 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@2c177f9e{/storage,null,AVAILABLE,@Spark}
2021-12-03 16:33:16,793 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@f9b7332{/storage/json,null,AVAILABLE,@Spark}
2021-12-03 16:33:16,795 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@192f2f27{/storage/rdd,null,AVAILABLE,@Spark}
2021-12-03 16:33:16,796 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@b672aa8{/storage/rdd/json,null,AVAILABLE,@Spark}
2021-12-03 16:33:16,798 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@7997b197{/environment,null,AVAILABLE,@Spark}
2021-12-03 16:33:16,800 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@11acdc30{/environment/json,null,AVAILABLE,@Spark}
2021-12-03 16:33:16,802 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@611f8234{/executors,null,AVAILABLE,@Spark}
2021-12-03 16:33:16,803 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@62923ee6{/executors/json,null,AVAILABLE,@Spark}
2021-12-03 16:33:16,805 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@4b6166aa{/executors/threadDump,null,AVAILABLE,@Spark}
2021-12-03 16:33:16,807 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@a1217f9{/executors/threadDump/json,null,AVAILABLE,@Spark}
2021-12-03 16:33:16,815 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@791cbf87{/static,null,AVAILABLE,@Spark}
2021-12-03 16:33:16,817 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@cf65451{/,null,AVAILABLE,@Spark}
2021-12-03 16:33:16,819 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@46074492{/api,null,AVAILABLE,@Spark}
2021-12-03 16:33:16,820 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@5ae76500{/jobs/job/kill,null,AVAILABLE,@Spark}
2021-12-03 16:33:16,821 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@24f360b2{/stages/stage/kill,null,AVAILABLE,@Spark}
2021-12-03 16:33:16,823 [main] INFO [org.apache.spark.ui.SparkUI] - Bound SparkUI to 0.0.0.0, and started at http://qb:4040
2021-12-03 16:33:16,912 [main] INFO [org.apache.spark.executor.Executor] - Starting executor ID driver on host localhost
2021-12-03 16:33:16,960 [main] INFO [org.apache.spark.util.Utils] - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 64385.
2021-12-03 16:33:16,960 [main] INFO [org.apache.spark.network.netty.NettyBlockTransferService] - Server created on qb:64385
2021-12-03 16:33:16,961 [main] INFO [org.apache.spark.storage.BlockManager] - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2021-12-03 16:33:16,963 [main] INFO [org.apache.spark.storage.BlockManagerMaster] - Registering BlockManager BlockManagerId(driver, qb, 64385, None)
2021-12-03 16:33:16,965 [dispatcher-event-loop-10] INFO [org.apache.spark.storage.BlockManagerMasterEndpoint] - Registering block manager qb:64385 with 1990.8 MB RAM, BlockManagerId(driver, qb, 64385, None)
2021-12-03 16:33:16,967 [main] INFO [org.apache.spark.storage.BlockManagerMaster] - Registered BlockManager BlockManagerId(driver, qb, 64385, None)
2021-12-03 16:33:16,967 [main] INFO [org.apache.spark.storage.BlockManager] - Initialized BlockManager: BlockManagerId(driver, qb, 64385, None)
2021-12-03 16:33:17,114 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@7c9b78e3{/metrics/json,null,AVAILABLE,@Spark}
2021-12-03 16:33:17,592 [main] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_0 stored as values in memory (estimated size 312.7 KB, free 1990.5 MB)
2021-12-03 16:33:17,792 [main] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_0_piece0 stored as bytes in memory (estimated size 27.3 KB, free 1990.5 MB)
2021-12-03 16:33:17,795 [dispatcher-event-loop-0] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_0_piece0 in memory on qb:64385 (size: 27.3 KB, free: 1990.8 MB)
2021-12-03 16:33:17,798 [main] INFO [org.apache.spark.SparkContext] - Created broadcast 0 from textFile at PaidPromotionAdjustParameter.scala:59
2021-12-03 16:33:18,253 [main] WARN [org.apache.hadoop.hdfs.shortcircuit.DomainSocketFactory] - The short-circuit local reads feature cannot be used because UNIX Domain sockets are not available on Windows.
2021-12-03 16:33:18,326 [Thread-1] INFO [org.apache.spark.SparkContext] - Invoking stop() from shutdown hook
2021-12-03 16:33:18,331 [Thread-1] INFO [org.spark_project.jetty.server.AbstractConnector] - Stopped Spark@5f7f2382{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2021-12-03 16:33:18,332 [Thread-1] INFO [org.apache.spark.ui.SparkUI] - Stopped Spark web UI at http://qb:4040
2021-12-03 16:33:18,339 [dispatcher-event-loop-3] INFO [org.apache.spark.MapOutputTrackerMasterEndpoint] - MapOutputTrackerMasterEndpoint stopped!
2021-12-03 16:33:18,348 [Thread-1] INFO [org.apache.spark.storage.memory.MemoryStore] - MemoryStore cleared
2021-12-03 16:33:18,348 [Thread-1] INFO [org.apache.spark.storage.BlockManager] - BlockManager stopped
2021-12-03 16:33:18,352 [Thread-1] INFO [org.apache.spark.storage.BlockManagerMaster] - BlockManagerMaster stopped
2021-12-03 16:33:18,355 [dispatcher-event-loop-8] INFO [org.apache.spark.scheduler.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint] - OutputCommitCoordinator stopped!
2021-12-03 16:33:18,358 [Thread-1] INFO [org.apache.spark.SparkContext] - Successfully stopped SparkContext
2021-12-03 16:33:18,358 [Thread-1] INFO [org.apache.spark.util.ShutdownHookManager] - Shutdown hook called
2021-12-03 16:33:18,359 [Thread-1] INFO [org.apache.spark.util.ShutdownHookManager] - Deleting directory C:\Users\ACER\AppData\Local\Temp\spark-171ab95e-1f82-4f1d-9ac4-a28b1233f617
2021-12-03 16:41:52,953 [main] INFO [org.apache.spark.SparkContext] - Running Spark version 2.3.0
2021-12-03 16:41:53,236 [main] INFO [org.apache.spark.SparkContext] - Submitted application: PaidPromotion
2021-12-03 16:41:53,286 [main] INFO [org.apache.spark.SecurityManager] - Changing view acls to: ACER,root
2021-12-03 16:41:53,287 [main] INFO [org.apache.spark.SecurityManager] - Changing modify acls to: ACER,root
2021-12-03 16:41:53,287 [main] INFO [org.apache.spark.SecurityManager] - Changing view acls groups to: 
2021-12-03 16:41:53,287 [main] INFO [org.apache.spark.SecurityManager] - Changing modify acls groups to: 
2021-12-03 16:41:53,288 [main] INFO [org.apache.spark.SecurityManager] - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(ACER, root); groups with view permissions: Set(); users  with modify permissions: Set(ACER, root); groups with modify permissions: Set()
2021-12-03 16:41:53,862 [main] INFO [org.apache.spark.util.Utils] - Successfully started service 'sparkDriver' on port 53266.
2021-12-03 16:41:53,879 [main] INFO [org.apache.spark.SparkEnv] - Registering MapOutputTracker
2021-12-03 16:41:53,893 [main] INFO [org.apache.spark.SparkEnv] - Registering BlockManagerMaster
2021-12-03 16:41:53,895 [main] INFO [org.apache.spark.storage.BlockManagerMasterEndpoint] - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2021-12-03 16:41:53,895 [main] INFO [org.apache.spark.storage.BlockManagerMasterEndpoint] - BlockManagerMasterEndpoint up
2021-12-03 16:41:53,902 [main] INFO [org.apache.spark.storage.DiskBlockManager] - Created local directory at C:\Users\ACER\AppData\Local\Temp\blockmgr-79b55249-aad7-46cd-9c0f-568fe7f4deaa
2021-12-03 16:41:53,916 [main] INFO [org.apache.spark.storage.memory.MemoryStore] - MemoryStore started with capacity 1990.8 MB
2021-12-03 16:41:53,925 [main] INFO [org.apache.spark.SparkEnv] - Registering OutputCommitCoordinator
2021-12-03 16:41:53,976 [main] INFO [org.spark_project.jetty.util.log] - Logging initialized @1847ms
2021-12-03 16:41:54,019 [main] INFO [org.spark_project.jetty.server.Server] - jetty-9.3.z-SNAPSHOT
2021-12-03 16:41:54,031 [main] INFO [org.spark_project.jetty.server.Server] - Started @1903ms
2021-12-03 16:41:54,054 [main] INFO [org.spark_project.jetty.server.AbstractConnector] - Started ServerConnector@5b800468{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2021-12-03 16:41:54,054 [main] INFO [org.apache.spark.util.Utils] - Successfully started service 'SparkUI' on port 4040.
2021-12-03 16:41:54,073 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@1568159{/jobs,null,AVAILABLE,@Spark}
2021-12-03 16:41:54,074 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@63cd604c{/jobs/json,null,AVAILABLE,@Spark}
2021-12-03 16:41:54,075 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@3954d008{/jobs/job,null,AVAILABLE,@Spark}
2021-12-03 16:41:54,077 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@6d8792db{/jobs/job/json,null,AVAILABLE,@Spark}
2021-12-03 16:41:54,077 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@3a1d593e{/stages,null,AVAILABLE,@Spark}
2021-12-03 16:41:54,078 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@285d851a{/stages/json,null,AVAILABLE,@Spark}
2021-12-03 16:41:54,079 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@7876d598{/stages/stage,null,AVAILABLE,@Spark}
2021-12-03 16:41:54,080 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@4985cbcb{/stages/stage/json,null,AVAILABLE,@Spark}
2021-12-03 16:41:54,082 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@54361a9{/stages/pool,null,AVAILABLE,@Spark}
2021-12-03 16:41:54,083 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@293bb8a5{/stages/pool/json,null,AVAILABLE,@Spark}
2021-12-03 16:41:54,083 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@290b1b2e{/storage,null,AVAILABLE,@Spark}
2021-12-03 16:41:54,084 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@5db4c359{/storage/json,null,AVAILABLE,@Spark}
2021-12-03 16:41:54,086 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@6fefce9e{/storage/rdd,null,AVAILABLE,@Spark}
2021-12-03 16:41:54,088 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@8a589a2{/storage/rdd/json,null,AVAILABLE,@Spark}
2021-12-03 16:41:54,089 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@5cc69cfe{/environment,null,AVAILABLE,@Spark}
2021-12-03 16:41:54,090 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@11dee337{/environment/json,null,AVAILABLE,@Spark}
2021-12-03 16:41:54,091 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@74bdc168{/executors,null,AVAILABLE,@Spark}
2021-12-03 16:41:54,092 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@7bb3a9fe{/executors/json,null,AVAILABLE,@Spark}
2021-12-03 16:41:54,093 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@f19c9d2{/executors/threadDump,null,AVAILABLE,@Spark}
2021-12-03 16:41:54,094 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@a77614d{/executors/threadDump/json,null,AVAILABLE,@Spark}
2021-12-03 16:41:54,100 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@523424b5{/static,null,AVAILABLE,@Spark}
2021-12-03 16:41:54,102 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@12cd9150{/,null,AVAILABLE,@Spark}
2021-12-03 16:41:54,103 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@32fe9d0a{/api,null,AVAILABLE,@Spark}
2021-12-03 16:41:54,104 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@59fc684e{/jobs/job/kill,null,AVAILABLE,@Spark}
2021-12-03 16:41:54,105 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@355e34c7{/stages/stage/kill,null,AVAILABLE,@Spark}
2021-12-03 16:41:54,107 [main] INFO [org.apache.spark.ui.SparkUI] - Bound SparkUI to 0.0.0.0, and started at http://qb:4040
2021-12-03 16:41:54,184 [main] INFO [org.apache.spark.executor.Executor] - Starting executor ID driver on host localhost
2021-12-03 16:41:54,225 [main] INFO [org.apache.spark.util.Utils] - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 53307.
2021-12-03 16:41:54,227 [main] INFO [org.apache.spark.network.netty.NettyBlockTransferService] - Server created on qb:53307
2021-12-03 16:41:54,228 [main] INFO [org.apache.spark.storage.BlockManager] - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2021-12-03 16:41:54,229 [main] INFO [org.apache.spark.storage.BlockManagerMaster] - Registering BlockManager BlockManagerId(driver, qb, 53307, None)
2021-12-03 16:41:54,231 [dispatcher-event-loop-10] INFO [org.apache.spark.storage.BlockManagerMasterEndpoint] - Registering block manager qb:53307 with 1990.8 MB RAM, BlockManagerId(driver, qb, 53307, None)
2021-12-03 16:41:54,232 [main] INFO [org.apache.spark.storage.BlockManagerMaster] - Registered BlockManager BlockManagerId(driver, qb, 53307, None)
2021-12-03 16:41:54,232 [main] INFO [org.apache.spark.storage.BlockManager] - Initialized BlockManager: BlockManagerId(driver, qb, 53307, None)
2021-12-03 16:41:54,350 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@6fe46b62{/metrics/json,null,AVAILABLE,@Spark}
2021-12-03 16:41:54,760 [main] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_0 stored as values in memory (estimated size 312.7 KB, free 1990.5 MB)
2021-12-03 16:41:54,939 [main] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_0_piece0 stored as bytes in memory (estimated size 27.3 KB, free 1990.5 MB)
2021-12-03 16:41:54,941 [dispatcher-event-loop-0] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_0_piece0 in memory on qb:53307 (size: 27.3 KB, free: 1990.8 MB)
2021-12-03 16:41:54,943 [main] INFO [org.apache.spark.SparkContext] - Created broadcast 0 from textFile at PaidPromotionAdjustParameter.scala:59
2021-12-03 16:41:55,251 [main] WARN [org.apache.hadoop.hdfs.shortcircuit.DomainSocketFactory] - The short-circuit local reads feature cannot be used because UNIX Domain sockets are not available on Windows.
2021-12-03 16:42:15,292 [main] INFO [org.apache.hadoop.ipc.Client] - Retrying connect to server: hdp1/172.16.1.222:8020. Already tried 0 time(s); maxRetries=45
2021-12-03 16:42:35,295 [main] INFO [org.apache.hadoop.ipc.Client] - Retrying connect to server: hdp1/172.16.1.222:8020. Already tried 1 time(s); maxRetries=45
2021-12-03 17:52:22,849 [main] INFO [org.apache.spark.SparkContext] - Running Spark version 2.3.0
2021-12-03 17:52:23,117 [main] INFO [org.apache.spark.SparkContext] - Submitted application: PaidPromotion
2021-12-03 17:52:23,161 [main] INFO [org.apache.spark.SecurityManager] - Changing view acls to: ACER,root
2021-12-03 17:52:23,161 [main] INFO [org.apache.spark.SecurityManager] - Changing modify acls to: ACER,root
2021-12-03 17:52:23,161 [main] INFO [org.apache.spark.SecurityManager] - Changing view acls groups to: 
2021-12-03 17:52:23,162 [main] INFO [org.apache.spark.SecurityManager] - Changing modify acls groups to: 
2021-12-03 17:52:23,162 [main] INFO [org.apache.spark.SecurityManager] - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(ACER, root); groups with view permissions: Set(); users  with modify permissions: Set(ACER, root); groups with modify permissions: Set()
2021-12-03 17:52:23,716 [main] INFO [org.apache.spark.util.Utils] - Successfully started service 'sparkDriver' on port 51817.
2021-12-03 17:52:23,732 [main] INFO [org.apache.spark.SparkEnv] - Registering MapOutputTracker
2021-12-03 17:52:23,746 [main] INFO [org.apache.spark.SparkEnv] - Registering BlockManagerMaster
2021-12-03 17:52:23,749 [main] INFO [org.apache.spark.storage.BlockManagerMasterEndpoint] - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2021-12-03 17:52:23,749 [main] INFO [org.apache.spark.storage.BlockManagerMasterEndpoint] - BlockManagerMasterEndpoint up
2021-12-03 17:52:23,756 [main] INFO [org.apache.spark.storage.DiskBlockManager] - Created local directory at C:\Users\ACER\AppData\Local\Temp\blockmgr-65430998-6f34-44c7-b622-96f11bc85450
2021-12-03 17:52:23,770 [main] INFO [org.apache.spark.storage.memory.MemoryStore] - MemoryStore started with capacity 1990.8 MB
2021-12-03 17:52:23,779 [main] INFO [org.apache.spark.SparkEnv] - Registering OutputCommitCoordinator
2021-12-03 17:52:23,831 [main] INFO [org.spark_project.jetty.util.log] - Logging initialized @1811ms
2021-12-03 17:52:23,876 [main] INFO [org.spark_project.jetty.server.Server] - jetty-9.3.z-SNAPSHOT
2021-12-03 17:52:23,886 [main] INFO [org.spark_project.jetty.server.Server] - Started @1867ms
2021-12-03 17:52:23,910 [main] INFO [org.spark_project.jetty.server.AbstractConnector] - Started ServerConnector@5b800468{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2021-12-03 17:52:23,911 [main] INFO [org.apache.spark.util.Utils] - Successfully started service 'SparkUI' on port 4040.
2021-12-03 17:52:23,935 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@1568159{/jobs,null,AVAILABLE,@Spark}
2021-12-03 17:52:23,937 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@63cd604c{/jobs/json,null,AVAILABLE,@Spark}
2021-12-03 17:52:23,938 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@3954d008{/jobs/job,null,AVAILABLE,@Spark}
2021-12-03 17:52:23,940 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@6d8792db{/jobs/job/json,null,AVAILABLE,@Spark}
2021-12-03 17:52:23,941 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@3a1d593e{/stages,null,AVAILABLE,@Spark}
2021-12-03 17:52:23,943 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@285d851a{/stages/json,null,AVAILABLE,@Spark}
2021-12-03 17:52:23,943 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@7876d598{/stages/stage,null,AVAILABLE,@Spark}
2021-12-03 17:52:23,945 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@4985cbcb{/stages/stage/json,null,AVAILABLE,@Spark}
2021-12-03 17:52:23,946 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@54361a9{/stages/pool,null,AVAILABLE,@Spark}
2021-12-03 17:52:23,947 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@293bb8a5{/stages/pool/json,null,AVAILABLE,@Spark}
2021-12-03 17:52:23,948 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@290b1b2e{/storage,null,AVAILABLE,@Spark}
2021-12-03 17:52:23,950 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@5db4c359{/storage/json,null,AVAILABLE,@Spark}
2021-12-03 17:52:23,951 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@6fefce9e{/storage/rdd,null,AVAILABLE,@Spark}
2021-12-03 17:52:23,952 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@8a589a2{/storage/rdd/json,null,AVAILABLE,@Spark}
2021-12-03 17:52:23,953 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@5cc69cfe{/environment,null,AVAILABLE,@Spark}
2021-12-03 17:52:23,954 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@11dee337{/environment/json,null,AVAILABLE,@Spark}
2021-12-03 17:52:23,955 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@74bdc168{/executors,null,AVAILABLE,@Spark}
2021-12-03 17:52:23,956 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@7bb3a9fe{/executors/json,null,AVAILABLE,@Spark}
2021-12-03 17:52:23,957 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@f19c9d2{/executors/threadDump,null,AVAILABLE,@Spark}
2021-12-03 17:52:23,958 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@a77614d{/executors/threadDump/json,null,AVAILABLE,@Spark}
2021-12-03 17:52:23,964 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@523424b5{/static,null,AVAILABLE,@Spark}
2021-12-03 17:52:23,965 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@12cd9150{/,null,AVAILABLE,@Spark}
2021-12-03 17:52:23,967 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@32fe9d0a{/api,null,AVAILABLE,@Spark}
2021-12-03 17:52:23,968 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@59fc684e{/jobs/job/kill,null,AVAILABLE,@Spark}
2021-12-03 17:52:23,970 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@355e34c7{/stages/stage/kill,null,AVAILABLE,@Spark}
2021-12-03 17:52:23,972 [main] INFO [org.apache.spark.ui.SparkUI] - Bound SparkUI to 0.0.0.0, and started at http://qb:4040
2021-12-03 17:52:24,049 [main] INFO [org.apache.spark.executor.Executor] - Starting executor ID driver on host localhost
2021-12-03 17:52:24,091 [main] INFO [org.apache.spark.util.Utils] - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 51862.
2021-12-03 17:52:24,092 [main] INFO [org.apache.spark.network.netty.NettyBlockTransferService] - Server created on qb:51862
2021-12-03 17:52:24,093 [main] INFO [org.apache.spark.storage.BlockManager] - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2021-12-03 17:52:24,094 [main] INFO [org.apache.spark.storage.BlockManagerMaster] - Registering BlockManager BlockManagerId(driver, qb, 51862, None)
2021-12-03 17:52:24,096 [dispatcher-event-loop-7] INFO [org.apache.spark.storage.BlockManagerMasterEndpoint] - Registering block manager qb:51862 with 1990.8 MB RAM, BlockManagerId(driver, qb, 51862, None)
2021-12-03 17:52:24,098 [main] INFO [org.apache.spark.storage.BlockManagerMaster] - Registered BlockManager BlockManagerId(driver, qb, 51862, None)
2021-12-03 17:52:24,098 [main] INFO [org.apache.spark.storage.BlockManager] - Initialized BlockManager: BlockManagerId(driver, qb, 51862, None)
2021-12-03 17:52:24,228 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@6fe46b62{/metrics/json,null,AVAILABLE,@Spark}
2021-12-03 17:52:24,706 [main] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_0 stored as values in memory (estimated size 312.7 KB, free 1990.5 MB)
2021-12-03 17:52:24,946 [main] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_0_piece0 stored as bytes in memory (estimated size 27.3 KB, free 1990.5 MB)
2021-12-03 17:52:24,948 [dispatcher-event-loop-0] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_0_piece0 in memory on qb:51862 (size: 27.3 KB, free: 1990.8 MB)
2021-12-03 17:52:24,953 [main] INFO [org.apache.spark.SparkContext] - Created broadcast 0 from textFile at PaidPromotionAdjustParameter.scala:57
2021-12-03 17:52:25,279 [main] WARN [org.apache.hadoop.hdfs.shortcircuit.DomainSocketFactory] - The short-circuit local reads feature cannot be used because UNIX Domain sockets are not available on Windows.
2021-12-03 17:52:25,338 [Thread-1] INFO [org.apache.spark.SparkContext] - Invoking stop() from shutdown hook
2021-12-03 17:52:25,344 [Thread-1] INFO [org.spark_project.jetty.server.AbstractConnector] - Stopped Spark@5b800468{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2021-12-03 17:52:25,345 [Thread-1] INFO [org.apache.spark.ui.SparkUI] - Stopped Spark web UI at http://qb:4040
2021-12-03 17:52:25,352 [dispatcher-event-loop-2] INFO [org.apache.spark.MapOutputTrackerMasterEndpoint] - MapOutputTrackerMasterEndpoint stopped!
2021-12-03 17:52:25,359 [Thread-1] INFO [org.apache.spark.storage.memory.MemoryStore] - MemoryStore cleared
2021-12-03 17:52:25,360 [Thread-1] INFO [org.apache.spark.storage.BlockManager] - BlockManager stopped
2021-12-03 17:52:25,363 [Thread-1] INFO [org.apache.spark.storage.BlockManagerMaster] - BlockManagerMaster stopped
2021-12-03 17:52:25,365 [dispatcher-event-loop-8] INFO [org.apache.spark.scheduler.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint] - OutputCommitCoordinator stopped!
2021-12-03 17:52:25,368 [Thread-1] INFO [org.apache.spark.SparkContext] - Successfully stopped SparkContext
2021-12-03 17:52:25,368 [Thread-1] INFO [org.apache.spark.util.ShutdownHookManager] - Shutdown hook called
2021-12-03 17:52:25,369 [Thread-1] INFO [org.apache.spark.util.ShutdownHookManager] - Deleting directory C:\Users\ACER\AppData\Local\Temp\spark-dbcf91f9-bf76-47b7-a89b-30ba1f493a7d
2021-12-03 19:08:27,768 [main] INFO [org.apache.spark.SparkContext] - Running Spark version 2.3.0
2021-12-03 19:08:28,040 [main] INFO [org.apache.spark.SparkContext] - Submitted application: PaidPromotion
2021-12-03 19:08:28,085 [main] INFO [org.apache.spark.SecurityManager] - Changing view acls to: ACER,root
2021-12-03 19:08:28,085 [main] INFO [org.apache.spark.SecurityManager] - Changing modify acls to: ACER,root
2021-12-03 19:08:28,086 [main] INFO [org.apache.spark.SecurityManager] - Changing view acls groups to: 
2021-12-03 19:08:28,086 [main] INFO [org.apache.spark.SecurityManager] - Changing modify acls groups to: 
2021-12-03 19:08:28,086 [main] INFO [org.apache.spark.SecurityManager] - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(ACER, root); groups with view permissions: Set(); users  with modify permissions: Set(ACER, root); groups with modify permissions: Set()
2021-12-03 19:08:28,649 [main] INFO [org.apache.spark.util.Utils] - Successfully started service 'sparkDriver' on port 50870.
2021-12-03 19:08:28,665 [main] INFO [org.apache.spark.SparkEnv] - Registering MapOutputTracker
2021-12-03 19:08:28,680 [main] INFO [org.apache.spark.SparkEnv] - Registering BlockManagerMaster
2021-12-03 19:08:28,682 [main] INFO [org.apache.spark.storage.BlockManagerMasterEndpoint] - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2021-12-03 19:08:28,682 [main] INFO [org.apache.spark.storage.BlockManagerMasterEndpoint] - BlockManagerMasterEndpoint up
2021-12-03 19:08:28,690 [main] INFO [org.apache.spark.storage.DiskBlockManager] - Created local directory at C:\Users\ACER\AppData\Local\Temp\blockmgr-c9ae76f1-dc72-41c9-813f-1d570bb540d7
2021-12-03 19:08:28,704 [main] INFO [org.apache.spark.storage.memory.MemoryStore] - MemoryStore started with capacity 1990.8 MB
2021-12-03 19:08:28,714 [main] INFO [org.apache.spark.SparkEnv] - Registering OutputCommitCoordinator
2021-12-03 19:08:28,768 [main] INFO [org.spark_project.jetty.util.log] - Logging initialized @1856ms
2021-12-03 19:08:28,816 [main] INFO [org.spark_project.jetty.server.Server] - jetty-9.3.z-SNAPSHOT
2021-12-03 19:08:28,829 [main] INFO [org.spark_project.jetty.server.Server] - Started @1916ms
2021-12-03 19:08:28,857 [main] INFO [org.spark_project.jetty.server.AbstractConnector] - Started ServerConnector@5f7f2382{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2021-12-03 19:08:28,857 [main] INFO [org.apache.spark.util.Utils] - Successfully started service 'SparkUI' on port 4040.
2021-12-03 19:08:28,878 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@3af17be2{/jobs,null,AVAILABLE,@Spark}
2021-12-03 19:08:28,879 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@6a1d204a{/jobs/json,null,AVAILABLE,@Spark}
2021-12-03 19:08:28,880 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@72ccd81a{/jobs/job,null,AVAILABLE,@Spark}
2021-12-03 19:08:28,882 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@5d25e6bb{/jobs/job/json,null,AVAILABLE,@Spark}
2021-12-03 19:08:28,884 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@7859e786{/stages,null,AVAILABLE,@Spark}
2021-12-03 19:08:28,884 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@5118388b{/stages/json,null,AVAILABLE,@Spark}
2021-12-03 19:08:28,886 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@71104a4{/stages/stage,null,AVAILABLE,@Spark}
2021-12-03 19:08:28,888 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@332a7fce{/stages/stage/json,null,AVAILABLE,@Spark}
2021-12-03 19:08:28,889 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@37ebc9d8{/stages/pool,null,AVAILABLE,@Spark}
2021-12-03 19:08:28,891 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@6e9319f{/stages/pool/json,null,AVAILABLE,@Spark}
2021-12-03 19:08:28,892 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@2c177f9e{/storage,null,AVAILABLE,@Spark}
2021-12-03 19:08:28,893 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@f9b7332{/storage/json,null,AVAILABLE,@Spark}
2021-12-03 19:08:28,894 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@192f2f27{/storage/rdd,null,AVAILABLE,@Spark}
2021-12-03 19:08:28,896 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@b672aa8{/storage/rdd/json,null,AVAILABLE,@Spark}
2021-12-03 19:08:28,897 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@7997b197{/environment,null,AVAILABLE,@Spark}
2021-12-03 19:08:28,898 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@11acdc30{/environment/json,null,AVAILABLE,@Spark}
2021-12-03 19:08:28,899 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@611f8234{/executors,null,AVAILABLE,@Spark}
2021-12-03 19:08:28,900 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@62923ee6{/executors/json,null,AVAILABLE,@Spark}
2021-12-03 19:08:28,902 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@4b6166aa{/executors/threadDump,null,AVAILABLE,@Spark}
2021-12-03 19:08:28,903 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@a1217f9{/executors/threadDump/json,null,AVAILABLE,@Spark}
2021-12-03 19:08:28,908 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@791cbf87{/static,null,AVAILABLE,@Spark}
2021-12-03 19:08:28,909 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@cf65451{/,null,AVAILABLE,@Spark}
2021-12-03 19:08:28,911 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@46074492{/api,null,AVAILABLE,@Spark}
2021-12-03 19:08:28,913 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@5ae76500{/jobs/job/kill,null,AVAILABLE,@Spark}
2021-12-03 19:08:28,914 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@24f360b2{/stages/stage/kill,null,AVAILABLE,@Spark}
2021-12-03 19:08:28,917 [main] INFO [org.apache.spark.ui.SparkUI] - Bound SparkUI to 0.0.0.0, and started at http://qb:4040
2021-12-03 19:08:29,005 [main] INFO [org.apache.spark.executor.Executor] - Starting executor ID driver on host localhost
2021-12-03 19:08:29,049 [main] INFO [org.apache.spark.util.Utils] - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 50913.
2021-12-03 19:08:29,049 [main] INFO [org.apache.spark.network.netty.NettyBlockTransferService] - Server created on qb:50913
2021-12-03 19:08:29,050 [main] INFO [org.apache.spark.storage.BlockManager] - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2021-12-03 19:08:29,052 [main] INFO [org.apache.spark.storage.BlockManagerMaster] - Registering BlockManager BlockManagerId(driver, qb, 50913, None)
2021-12-03 19:08:29,054 [dispatcher-event-loop-10] INFO [org.apache.spark.storage.BlockManagerMasterEndpoint] - Registering block manager qb:50913 with 1990.8 MB RAM, BlockManagerId(driver, qb, 50913, None)
2021-12-03 19:08:29,056 [main] INFO [org.apache.spark.storage.BlockManagerMaster] - Registered BlockManager BlockManagerId(driver, qb, 50913, None)
2021-12-03 19:08:29,056 [main] INFO [org.apache.spark.storage.BlockManager] - Initialized BlockManager: BlockManagerId(driver, qb, 50913, None)
2021-12-03 19:08:29,193 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@7c9b78e3{/metrics/json,null,AVAILABLE,@Spark}
2021-12-03 19:08:29,658 [main] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_0 stored as values in memory (estimated size 312.7 KB, free 1990.5 MB)
2021-12-03 19:08:29,886 [main] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_0_piece0 stored as bytes in memory (estimated size 27.3 KB, free 1990.5 MB)
2021-12-03 19:08:29,888 [dispatcher-event-loop-0] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_0_piece0 in memory on qb:50913 (size: 27.3 KB, free: 1990.8 MB)
2021-12-03 19:08:29,893 [main] INFO [org.apache.spark.SparkContext] - Created broadcast 0 from textFile at PaidPromotionAdjustParameter.scala:57
2021-12-03 19:08:30,254 [main] WARN [org.apache.hadoop.hdfs.shortcircuit.DomainSocketFactory] - The short-circuit local reads feature cannot be used because UNIX Domain sockets are not available on Windows.
2021-12-03 19:08:30,330 [main] INFO [org.apache.hadoop.mapred.FileInputFormat] - Total input paths to process : 1
2021-12-03 19:08:30,394 [main] INFO [org.apache.hadoop.net.NetworkTopology] - Adding a new node: /default-rack/192.168.1.33:50010
2021-12-03 19:08:30,394 [main] INFO [org.apache.hadoop.net.NetworkTopology] - Adding a new node: /default-rack/172.16.1.222:50010
2021-12-03 19:08:30,394 [main] INFO [org.apache.hadoop.net.NetworkTopology] - Adding a new node: /default-rack/192.168.1.34:50010
2021-12-03 19:08:30,397 [main] INFO [PaidPromotion$] - 收视分区数22
2021-12-03 19:08:30,397 [main] INFO [PaidPromotion$] - 收视数据示例==================================================
2021-12-03 19:08:30,424 [main] INFO [org.apache.spark.SparkContext] - Starting job: take at PaidPromotionAdjustParameter.scala:61
2021-12-03 19:08:30,436 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 0 (take at PaidPromotionAdjustParameter.scala:61) with 1 output partitions
2021-12-03 19:08:30,436 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 0 (take at PaidPromotionAdjustParameter.scala:61)
2021-12-03 19:08:30,436 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List()
2021-12-03 19:08:30,438 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2021-12-03 19:08:30,444 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 0 (/sk/chongqing/data/behavior_data.bcp MapPartitionsRDD[1] at textFile at PaidPromotionAdjustParameter.scala:57), which has no missing parents
2021-12-03 19:08:30,459 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_1 stored as values in memory (estimated size 3.3 KB, free 1990.5 MB)
2021-12-03 19:08:30,464 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_1_piece0 stored as bytes in memory (estimated size 1975.0 B, free 1990.5 MB)
2021-12-03 19:08:30,465 [dispatcher-event-loop-1] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_1_piece0 in memory on qb:50913 (size: 1975.0 B, free: 1990.8 MB)
2021-12-03 19:08:30,465 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 1 from broadcast at DAGScheduler.scala:1039
2021-12-03 19:08:30,477 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 0 (/sk/chongqing/data/behavior_data.bcp MapPartitionsRDD[1] at textFile at PaidPromotionAdjustParameter.scala:57) (first 15 tasks are for partitions Vector(0))
2021-12-03 19:08:30,478 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 0.0 with 1 tasks
2021-12-03 19:08:30,514 [dispatcher-event-loop-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 0.0 (TID 0, localhost, executor driver, partition 0, ANY, 7899 bytes)
2021-12-03 19:08:30,522 [Executor task launch worker for task 0] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 0.0 (TID 0)
2021-12-03 19:08:30,564 [Executor task launch worker for task 0] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:0+134217728
2021-12-03 19:08:30,746 [Executor task launch worker for task 0] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 0.0 (TID 0). 1129 bytes result sent to driver
2021-12-03 19:08:30,755 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 0.0 (TID 0) in 250 ms on localhost (executor driver) (1/1)
2021-12-03 19:08:30,756 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 0.0, whose tasks have all completed, from pool 
2021-12-03 19:08:30,760 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 0 (take at PaidPromotionAdjustParameter.scala:61) finished in 0.301 s
2021-12-03 19:08:30,765 [main] INFO [org.apache.spark.scheduler.DAGScheduler] - Job 0 finished: take at PaidPromotionAdjustParameter.scala:61, took 0.340831 s
2021-12-03 19:08:30,786 [main] INFO [org.apache.spark.SparkContext] - Starting job: count at PaidPromotionAdjustParameter.scala:70
2021-12-03 19:08:30,795 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 3 (map at PaidPromotionAdjustParameter.scala:69)
2021-12-03 19:08:30,796 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 1 (count at PaidPromotionAdjustParameter.scala:70) with 22 output partitions
2021-12-03 19:08:30,796 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 2 (count at PaidPromotionAdjustParameter.scala:70)
2021-12-03 19:08:30,796 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 1)
2021-12-03 19:08:30,797 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List(ShuffleMapStage 1)
2021-12-03 19:08:30,797 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ShuffleMapStage 1 (MapPartitionsRDD[3] at map at PaidPromotionAdjustParameter.scala:69), which has no missing parents
2021-12-03 19:08:30,807 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_2 stored as values in memory (estimated size 4.7 KB, free 1990.5 MB)
2021-12-03 19:08:30,811 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_2_piece0 stored as bytes in memory (estimated size 2.7 KB, free 1990.5 MB)
2021-12-03 19:08:30,811 [dispatcher-event-loop-5] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_2_piece0 in memory on qb:50913 (size: 2.7 KB, free: 1990.8 MB)
2021-12-03 19:08:30,812 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 2 from broadcast at DAGScheduler.scala:1039
2021-12-03 19:08:30,814 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 22 missing tasks from ShuffleMapStage 1 (MapPartitionsRDD[3] at map at PaidPromotionAdjustParameter.scala:69) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14))
2021-12-03 19:08:30,814 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 1.0 with 22 tasks
2021-12-03 19:08:30,815 [dispatcher-event-loop-6] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 1.0 (TID 1, localhost, executor driver, partition 0, ANY, 7888 bytes)
2021-12-03 19:08:30,816 [dispatcher-event-loop-6] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 1.0 (TID 2, localhost, executor driver, partition 1, ANY, 7888 bytes)
2021-12-03 19:08:30,816 [dispatcher-event-loop-6] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 2.0 in stage 1.0 (TID 3, localhost, executor driver, partition 2, ANY, 7888 bytes)
2021-12-03 19:08:30,816 [dispatcher-event-loop-6] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 3.0 in stage 1.0 (TID 4, localhost, executor driver, partition 3, ANY, 7888 bytes)
2021-12-03 19:08:30,816 [dispatcher-event-loop-6] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 4.0 in stage 1.0 (TID 5, localhost, executor driver, partition 4, ANY, 7888 bytes)
2021-12-03 19:08:30,817 [dispatcher-event-loop-6] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 5.0 in stage 1.0 (TID 6, localhost, executor driver, partition 5, ANY, 7888 bytes)
2021-12-03 19:08:30,817 [dispatcher-event-loop-6] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 6.0 in stage 1.0 (TID 7, localhost, executor driver, partition 6, ANY, 7888 bytes)
2021-12-03 19:08:30,817 [dispatcher-event-loop-6] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 7.0 in stage 1.0 (TID 8, localhost, executor driver, partition 7, ANY, 7888 bytes)
2021-12-03 19:08:30,817 [dispatcher-event-loop-6] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 8.0 in stage 1.0 (TID 9, localhost, executor driver, partition 8, ANY, 7888 bytes)
2021-12-03 19:08:30,818 [dispatcher-event-loop-6] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 9.0 in stage 1.0 (TID 10, localhost, executor driver, partition 9, ANY, 7888 bytes)
2021-12-03 19:08:30,818 [dispatcher-event-loop-6] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 10.0 in stage 1.0 (TID 11, localhost, executor driver, partition 10, ANY, 7888 bytes)
2021-12-03 19:08:30,818 [dispatcher-event-loop-6] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 11.0 in stage 1.0 (TID 12, localhost, executor driver, partition 11, ANY, 7888 bytes)
2021-12-03 19:08:30,818 [Executor task launch worker for task 1] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 1.0 (TID 1)
2021-12-03 19:08:30,819 [Executor task launch worker for task 2] INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 1.0 (TID 2)
2021-12-03 19:08:30,819 [Executor task launch worker for task 3] INFO [org.apache.spark.executor.Executor] - Running task 2.0 in stage 1.0 (TID 3)
2021-12-03 19:08:30,819 [Executor task launch worker for task 4] INFO [org.apache.spark.executor.Executor] - Running task 3.0 in stage 1.0 (TID 4)
2021-12-03 19:08:30,819 [Executor task launch worker for task 5] INFO [org.apache.spark.executor.Executor] - Running task 4.0 in stage 1.0 (TID 5)
2021-12-03 19:08:30,819 [Executor task launch worker for task 6] INFO [org.apache.spark.executor.Executor] - Running task 5.0 in stage 1.0 (TID 6)
2021-12-03 19:08:30,819 [Executor task launch worker for task 7] INFO [org.apache.spark.executor.Executor] - Running task 6.0 in stage 1.0 (TID 7)
2021-12-03 19:08:30,819 [Executor task launch worker for task 8] INFO [org.apache.spark.executor.Executor] - Running task 7.0 in stage 1.0 (TID 8)
2021-12-03 19:08:30,819 [Executor task launch worker for task 9] INFO [org.apache.spark.executor.Executor] - Running task 8.0 in stage 1.0 (TID 9)
2021-12-03 19:08:30,819 [Executor task launch worker for task 10] INFO [org.apache.spark.executor.Executor] - Running task 9.0 in stage 1.0 (TID 10)
2021-12-03 19:08:30,820 [Executor task launch worker for task 11] INFO [org.apache.spark.executor.Executor] - Running task 10.0 in stage 1.0 (TID 11)
2021-12-03 19:08:30,821 [Executor task launch worker for task 12] INFO [org.apache.spark.executor.Executor] - Running task 11.0 in stage 1.0 (TID 12)
2021-12-03 19:08:30,825 [Executor task launch worker for task 7] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:805306368+134217728
2021-12-03 19:08:30,825 [Executor task launch worker for task 1] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:0+134217728
2021-12-03 19:08:30,825 [Executor task launch worker for task 4] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:402653184+134217728
2021-12-03 19:08:30,825 [Executor task launch worker for task 3] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:268435456+134217728
2021-12-03 19:08:30,825 [Executor task launch worker for task 9] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:1073741824+134217728
2021-12-03 19:08:30,825 [Executor task launch worker for task 5] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:536870912+134217728
2021-12-03 19:08:30,825 [Executor task launch worker for task 12] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:1476395008+134217728
2021-12-03 19:08:30,825 [Executor task launch worker for task 2] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:134217728+134217728
2021-12-03 19:08:30,826 [Executor task launch worker for task 10] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:1207959552+134217728
2021-12-03 19:08:30,825 [Executor task launch worker for task 11] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:1342177280+134217728
2021-12-03 19:08:30,827 [Executor task launch worker for task 8] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:939524096+134217728
2021-12-03 19:08:30,828 [Executor task launch worker for task 6] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:671088640+134217728
2021-12-03 19:08:31,137 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 5
2021-12-03 19:08:31,181 [dispatcher-event-loop-10] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_1_piece0 on qb:50913 in memory (size: 1975.0 B, free: 1990.8 MB)
2021-12-03 19:08:31,184 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 9
2021-12-03 19:08:31,185 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 15
2021-12-03 19:08:31,185 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 12
2021-12-03 19:08:31,185 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 13
2021-12-03 19:08:31,185 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 14
2021-12-03 19:08:31,185 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 6
2021-12-03 19:08:31,185 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 10
2021-12-03 19:08:31,185 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 2
2021-12-03 19:08:31,185 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 17
2021-12-03 19:08:31,185 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 7
2021-12-03 19:08:31,185 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 23
2021-12-03 19:08:31,185 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 20
2021-12-03 19:08:31,185 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 8
2021-12-03 19:08:31,185 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 19
2021-12-03 19:08:31,185 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 16
2021-12-03 19:08:31,185 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 3
2021-12-03 19:08:31,185 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 24
2021-12-03 19:08:31,185 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 4
2021-12-03 19:08:31,186 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1
2021-12-03 19:08:31,186 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 18
2021-12-03 19:08:31,186 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 21
2021-12-03 19:08:31,186 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 0
2021-12-03 19:08:31,186 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 11
2021-12-03 19:08:31,186 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 22
2021-12-03 19:10:27,419 [Executor task launch worker for task 9] INFO [org.apache.spark.executor.Executor] - Finished task 8.0 in stage 1.0 (TID 9). 1052 bytes result sent to driver
2021-12-03 19:10:27,421 [dispatcher-event-loop-10] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 12.0 in stage 1.0 (TID 13, localhost, executor driver, partition 12, ANY, 7888 bytes)
2021-12-03 19:10:27,421 [Executor task launch worker for task 13] INFO [org.apache.spark.executor.Executor] - Running task 12.0 in stage 1.0 (TID 13)
2021-12-03 19:10:27,423 [Executor task launch worker for task 13] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:1610612736+134217728
2021-12-03 19:10:27,441 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 8.0 in stage 1.0 (TID 9) in 116624 ms on localhost (executor driver) (1/22)
2021-12-03 19:10:33,998 [Executor task launch worker for task 3] INFO [org.apache.spark.executor.Executor] - Finished task 2.0 in stage 1.0 (TID 3). 1052 bytes result sent to driver
2021-12-03 19:10:33,998 [dispatcher-event-loop-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 13.0 in stage 1.0 (TID 14, localhost, executor driver, partition 13, ANY, 7888 bytes)
2021-12-03 19:10:33,998 [Executor task launch worker for task 14] INFO [org.apache.spark.executor.Executor] - Running task 13.0 in stage 1.0 (TID 14)
2021-12-03 19:10:34,000 [Executor task launch worker for task 14] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:1744830464+134217728
2021-12-03 19:10:34,000 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 2.0 in stage 1.0 (TID 3) in 123184 ms on localhost (executor driver) (2/22)
2021-12-03 19:10:34,934 [Executor task launch worker for task 5] INFO [org.apache.spark.executor.Executor] - Finished task 4.0 in stage 1.0 (TID 5). 1052 bytes result sent to driver
2021-12-03 19:10:34,935 [dispatcher-event-loop-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 14.0 in stage 1.0 (TID 15, localhost, executor driver, partition 14, ANY, 7888 bytes)
2021-12-03 19:10:34,935 [Executor task launch worker for task 15] INFO [org.apache.spark.executor.Executor] - Running task 14.0 in stage 1.0 (TID 15)
2021-12-03 19:10:34,937 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 4.0 in stage 1.0 (TID 5) in 124121 ms on localhost (executor driver) (3/22)
2021-12-03 19:10:34,938 [Executor task launch worker for task 15] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:1879048192+134217728
2021-12-03 19:10:47,995 [Executor task launch worker for task 11] INFO [org.apache.spark.executor.Executor] - Finished task 10.0 in stage 1.0 (TID 11). 1095 bytes result sent to driver
2021-12-03 19:10:47,995 [dispatcher-event-loop-9] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 15.0 in stage 1.0 (TID 16, localhost, executor driver, partition 15, ANY, 7888 bytes)
2021-12-03 19:10:47,995 [Executor task launch worker for task 16] INFO [org.apache.spark.executor.Executor] - Running task 15.0 in stage 1.0 (TID 16)
2021-12-03 19:10:47,996 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 10.0 in stage 1.0 (TID 11) in 137177 ms on localhost (executor driver) (4/22)
2021-12-03 19:10:47,997 [Executor task launch worker for task 16] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:2013265920+134217728
2021-12-03 19:10:56,990 [Executor task launch worker for task 7] INFO [org.apache.spark.executor.Executor] - Finished task 6.0 in stage 1.0 (TID 7). 1052 bytes result sent to driver
2021-12-03 19:10:56,990 [dispatcher-event-loop-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 16.0 in stage 1.0 (TID 17, localhost, executor driver, partition 16, ANY, 7888 bytes)
2021-12-03 19:10:56,990 [Executor task launch worker for task 17] INFO [org.apache.spark.executor.Executor] - Running task 16.0 in stage 1.0 (TID 17)
2021-12-03 19:10:56,990 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 6.0 in stage 1.0 (TID 7) in 146173 ms on localhost (executor driver) (5/22)
2021-12-03 19:10:56,991 [Executor task launch worker for task 17] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:2147483648+134217728
2021-12-03 19:10:57,106 [Executor task launch worker for task 10] INFO [org.apache.spark.executor.Executor] - Finished task 9.0 in stage 1.0 (TID 10). 1052 bytes result sent to driver
2021-12-03 19:10:57,107 [dispatcher-event-loop-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 17.0 in stage 1.0 (TID 18, localhost, executor driver, partition 17, ANY, 7888 bytes)
2021-12-03 19:10:57,107 [Executor task launch worker for task 18] INFO [org.apache.spark.executor.Executor] - Running task 17.0 in stage 1.0 (TID 18)
2021-12-03 19:10:57,107 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 9.0 in stage 1.0 (TID 10) in 146290 ms on localhost (executor driver) (6/22)
2021-12-03 19:10:57,108 [Executor task launch worker for task 18] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:2281701376+134217728
2021-12-03 19:10:57,859 [Executor task launch worker for task 2] INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 1.0 (TID 2). 1052 bytes result sent to driver
2021-12-03 19:10:57,859 [dispatcher-event-loop-6] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 18.0 in stage 1.0 (TID 19, localhost, executor driver, partition 18, ANY, 7888 bytes)
2021-12-03 19:10:57,859 [Executor task launch worker for task 19] INFO [org.apache.spark.executor.Executor] - Running task 18.0 in stage 1.0 (TID 19)
2021-12-03 19:10:57,859 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 1.0 (TID 2) in 147044 ms on localhost (executor driver) (7/22)
2021-12-03 19:10:57,860 [Executor task launch worker for task 19] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:2415919104+134217728
2021-12-03 19:10:58,364 [Executor task launch worker for task 6] INFO [org.apache.spark.executor.Executor] - Finished task 5.0 in stage 1.0 (TID 6). 1052 bytes result sent to driver
2021-12-03 19:10:58,365 [dispatcher-event-loop-7] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 19.0 in stage 1.0 (TID 20, localhost, executor driver, partition 19, ANY, 7888 bytes)
2021-12-03 19:10:58,365 [Executor task launch worker for task 20] INFO [org.apache.spark.executor.Executor] - Running task 19.0 in stage 1.0 (TID 20)
2021-12-03 19:10:58,365 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 5.0 in stage 1.0 (TID 6) in 147549 ms on localhost (executor driver) (8/22)
2021-12-03 19:10:58,366 [Executor task launch worker for task 20] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:2550136832+134217728
2021-12-03 19:11:01,390 [Executor task launch worker for task 8] INFO [org.apache.spark.executor.Executor] - Finished task 7.0 in stage 1.0 (TID 8). 1052 bytes result sent to driver
2021-12-03 19:11:01,390 [dispatcher-event-loop-9] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 20.0 in stage 1.0 (TID 21, localhost, executor driver, partition 20, ANY, 7888 bytes)
2021-12-03 19:11:01,390 [Executor task launch worker for task 21] INFO [org.apache.spark.executor.Executor] - Running task 20.0 in stage 1.0 (TID 21)
2021-12-03 19:11:01,390 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 7.0 in stage 1.0 (TID 8) in 150573 ms on localhost (executor driver) (9/22)
2021-12-03 19:11:01,391 [Executor task launch worker for task 21] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:2684354560+134217728
2021-12-03 19:11:06,638 [Executor task launch worker for task 1] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 1.0 (TID 1). 1052 bytes result sent to driver
2021-12-03 19:11:06,638 [dispatcher-event-loop-11] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 21.0 in stage 1.0 (TID 22, localhost, executor driver, partition 21, ANY, 7888 bytes)
2021-12-03 19:11:06,639 [Executor task launch worker for task 22] INFO [org.apache.spark.executor.Executor] - Running task 21.0 in stage 1.0 (TID 22)
2021-12-03 19:11:06,639 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 1.0 (TID 1) in 155824 ms on localhost (executor driver) (10/22)
2021-12-03 19:11:06,639 [Executor task launch worker for task 22] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:2818572288+147216171
2021-12-03 19:11:15,423 [Executor task launch worker for task 4] INFO [org.apache.spark.executor.Executor] - Finished task 3.0 in stage 1.0 (TID 4). 1052 bytes result sent to driver
2021-12-03 19:11:15,424 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 3.0 in stage 1.0 (TID 4) in 164608 ms on localhost (executor driver) (11/22)
2021-12-03 19:11:26,480 [Executor task launch worker for task 12] INFO [org.apache.spark.executor.Executor] - Finished task 11.0 in stage 1.0 (TID 12). 1052 bytes result sent to driver
2021-12-03 19:11:26,480 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 11.0 in stage 1.0 (TID 12) in 175662 ms on localhost (executor driver) (12/22)
2021-12-03 19:11:54,874 [Executor task launch worker for task 15] INFO [org.apache.spark.executor.Executor] - Finished task 14.0 in stage 1.0 (TID 15). 1052 bytes result sent to driver
2021-12-03 19:11:54,874 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 14.0 in stage 1.0 (TID 15) in 79939 ms on localhost (executor driver) (13/22)
2021-12-03 19:12:04,463 [Executor task launch worker for task 13] INFO [org.apache.spark.executor.Executor] - Finished task 12.0 in stage 1.0 (TID 13). 1095 bytes result sent to driver
2021-12-03 19:12:04,463 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 12.0 in stage 1.0 (TID 13) in 97043 ms on localhost (executor driver) (14/22)
2021-12-03 19:12:37,852 [Executor task launch worker for task 20] INFO [org.apache.spark.executor.Executor] - Finished task 19.0 in stage 1.0 (TID 20). 1052 bytes result sent to driver
2021-12-03 19:12:37,853 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 19.0 in stage 1.0 (TID 20) in 99489 ms on localhost (executor driver) (15/22)
2021-12-03 19:12:38,778 [Executor task launch worker for task 16] INFO [org.apache.spark.executor.Executor] - Finished task 15.0 in stage 1.0 (TID 16). 1052 bytes result sent to driver
2021-12-03 19:12:38,779 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 15.0 in stage 1.0 (TID 16) in 110784 ms on localhost (executor driver) (16/22)
2021-12-03 19:12:40,552 [Executor task launch worker for task 19] INFO [org.apache.spark.executor.Executor] - Finished task 18.0 in stage 1.0 (TID 19). 1009 bytes result sent to driver
2021-12-03 19:12:40,552 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 18.0 in stage 1.0 (TID 19) in 102693 ms on localhost (executor driver) (17/22)
2021-12-03 19:12:42,775 [Executor task launch worker for task 17] INFO [org.apache.spark.executor.Executor] - Finished task 16.0 in stage 1.0 (TID 17). 1052 bytes result sent to driver
2021-12-03 19:12:42,776 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 16.0 in stage 1.0 (TID 17) in 105786 ms on localhost (executor driver) (18/22)
2021-12-03 19:12:47,687 [Executor task launch worker for task 22] INFO [org.apache.spark.executor.Executor] - Finished task 21.0 in stage 1.0 (TID 22). 1009 bytes result sent to driver
2021-12-03 19:12:47,687 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 21.0 in stage 1.0 (TID 22) in 101049 ms on localhost (executor driver) (19/22)
2021-12-03 19:12:47,800 [Executor task launch worker for task 14] INFO [org.apache.spark.executor.Executor] - Finished task 13.0 in stage 1.0 (TID 14). 1052 bytes result sent to driver
2021-12-03 19:12:47,800 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 13.0 in stage 1.0 (TID 14) in 133802 ms on localhost (executor driver) (20/22)
2021-12-03 19:12:48,022 [Executor task launch worker for task 21] INFO [org.apache.spark.executor.Executor] - Finished task 20.0 in stage 1.0 (TID 21). 1009 bytes result sent to driver
2021-12-03 19:12:48,022 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 20.0 in stage 1.0 (TID 21) in 106632 ms on localhost (executor driver) (21/22)
2021-12-03 19:12:48,583 [Executor task launch worker for task 18] INFO [org.apache.spark.executor.Executor] - Finished task 17.0 in stage 1.0 (TID 18). 1009 bytes result sent to driver
2021-12-03 19:12:48,584 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 17.0 in stage 1.0 (TID 18) in 111477 ms on localhost (executor driver) (22/22)
2021-12-03 19:12:48,584 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 1.0, whose tasks have all completed, from pool 
2021-12-03 19:12:48,584 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ShuffleMapStage 1 (map at PaidPromotionAdjustParameter.scala:69) finished in 257.784 s
2021-12-03 19:12:48,585 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - looking for newly runnable stages
2021-12-03 19:12:48,585 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - running: Set()
2021-12-03 19:12:48,585 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - waiting: Set(ResultStage 2)
2021-12-03 19:12:48,586 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - failed: Set()
2021-12-03 19:12:48,588 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 2 (ShuffledRDD[4] at reduceByKey at PaidPromotionAdjustParameter.scala:69), which has no missing parents
2021-12-03 19:12:48,593 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_3 stored as values in memory (estimated size 3.0 KB, free 1990.5 MB)
2021-12-03 19:12:48,595 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_3_piece0 stored as bytes in memory (estimated size 1906.0 B, free 1990.5 MB)
2021-12-03 19:12:48,595 [dispatcher-event-loop-1] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_3_piece0 in memory on qb:50913 (size: 1906.0 B, free: 1990.8 MB)
2021-12-03 19:12:48,596 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 3 from broadcast at DAGScheduler.scala:1039
2021-12-03 19:12:48,596 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 22 missing tasks from ResultStage 2 (ShuffledRDD[4] at reduceByKey at PaidPromotionAdjustParameter.scala:69) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14))
2021-12-03 19:12:48,596 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 2.0 with 22 tasks
2021-12-03 19:12:48,597 [dispatcher-event-loop-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 2.0 (TID 23, localhost, executor driver, partition 0, ANY, 7649 bytes)
2021-12-03 19:12:48,597 [dispatcher-event-loop-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 2.0 (TID 24, localhost, executor driver, partition 1, ANY, 7649 bytes)
2021-12-03 19:12:48,597 [dispatcher-event-loop-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 2.0 in stage 2.0 (TID 25, localhost, executor driver, partition 2, ANY, 7649 bytes)
2021-12-03 19:12:48,598 [dispatcher-event-loop-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 3.0 in stage 2.0 (TID 26, localhost, executor driver, partition 3, ANY, 7649 bytes)
2021-12-03 19:12:48,598 [dispatcher-event-loop-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 4.0 in stage 2.0 (TID 27, localhost, executor driver, partition 4, ANY, 7649 bytes)
2021-12-03 19:12:48,598 [dispatcher-event-loop-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 5.0 in stage 2.0 (TID 28, localhost, executor driver, partition 5, ANY, 7649 bytes)
2021-12-03 19:12:48,598 [dispatcher-event-loop-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 6.0 in stage 2.0 (TID 29, localhost, executor driver, partition 6, ANY, 7649 bytes)
2021-12-03 19:12:48,598 [dispatcher-event-loop-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 7.0 in stage 2.0 (TID 30, localhost, executor driver, partition 7, ANY, 7649 bytes)
2021-12-03 19:12:48,598 [dispatcher-event-loop-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 8.0 in stage 2.0 (TID 31, localhost, executor driver, partition 8, ANY, 7649 bytes)
2021-12-03 19:12:48,598 [dispatcher-event-loop-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 9.0 in stage 2.0 (TID 32, localhost, executor driver, partition 9, ANY, 7649 bytes)
2021-12-03 19:12:48,599 [dispatcher-event-loop-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 10.0 in stage 2.0 (TID 33, localhost, executor driver, partition 10, ANY, 7649 bytes)
2021-12-03 19:12:48,599 [dispatcher-event-loop-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 11.0 in stage 2.0 (TID 34, localhost, executor driver, partition 11, ANY, 7649 bytes)
2021-12-03 19:12:48,599 [Executor task launch worker for task 24] INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 2.0 (TID 24)
2021-12-03 19:12:48,599 [Executor task launch worker for task 25] INFO [org.apache.spark.executor.Executor] - Running task 2.0 in stage 2.0 (TID 25)
2021-12-03 19:12:48,599 [Executor task launch worker for task 31] INFO [org.apache.spark.executor.Executor] - Running task 8.0 in stage 2.0 (TID 31)
2021-12-03 19:12:48,599 [Executor task launch worker for task 29] INFO [org.apache.spark.executor.Executor] - Running task 6.0 in stage 2.0 (TID 29)
2021-12-03 19:12:48,599 [Executor task launch worker for task 23] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 2.0 (TID 23)
2021-12-03 19:12:48,599 [Executor task launch worker for task 28] INFO [org.apache.spark.executor.Executor] - Running task 5.0 in stage 2.0 (TID 28)
2021-12-03 19:12:48,599 [Executor task launch worker for task 26] INFO [org.apache.spark.executor.Executor] - Running task 3.0 in stage 2.0 (TID 26)
2021-12-03 19:12:48,599 [Executor task launch worker for task 27] INFO [org.apache.spark.executor.Executor] - Running task 4.0 in stage 2.0 (TID 27)
2021-12-03 19:12:48,599 [Executor task launch worker for task 30] INFO [org.apache.spark.executor.Executor] - Running task 7.0 in stage 2.0 (TID 30)
2021-12-03 19:12:48,599 [Executor task launch worker for task 32] INFO [org.apache.spark.executor.Executor] - Running task 9.0 in stage 2.0 (TID 32)
2021-12-03 19:12:48,600 [Executor task launch worker for task 33] INFO [org.apache.spark.executor.Executor] - Running task 10.0 in stage 2.0 (TID 33)
2021-12-03 19:12:48,600 [Executor task launch worker for task 34] INFO [org.apache.spark.executor.Executor] - Running task 11.0 in stage 2.0 (TID 34)
2021-12-03 19:12:48,612 [Executor task launch worker for task 29] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 19:12:48,612 [Executor task launch worker for task 33] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 19:12:48,612 [Executor task launch worker for task 26] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 19:12:48,612 [Executor task launch worker for task 23] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 19:12:48,612 [Executor task launch worker for task 34] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 19:12:48,612 [Executor task launch worker for task 30] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 19:12:48,612 [Executor task launch worker for task 31] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 19:12:48,612 [Executor task launch worker for task 28] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 19:12:48,612 [Executor task launch worker for task 24] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 19:12:48,612 [Executor task launch worker for task 32] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 19:12:48,612 [Executor task launch worker for task 27] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 19:12:48,612 [Executor task launch worker for task 25] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 19:12:48,614 [Executor task launch worker for task 34] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 6 ms
2021-12-03 19:12:48,614 [Executor task launch worker for task 24] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 6 ms
2021-12-03 19:12:48,614 [Executor task launch worker for task 23] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 6 ms
2021-12-03 19:12:48,614 [Executor task launch worker for task 31] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 6 ms
2021-12-03 19:12:48,614 [Executor task launch worker for task 25] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 6 ms
2021-12-03 19:12:48,614 [Executor task launch worker for task 33] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 6 ms
2021-12-03 19:12:48,614 [Executor task launch worker for task 30] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 6 ms
2021-12-03 19:12:48,614 [Executor task launch worker for task 32] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 6 ms
2021-12-03 19:12:48,614 [Executor task launch worker for task 26] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 6 ms
2021-12-03 19:12:48,614 [Executor task launch worker for task 29] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 6 ms
2021-12-03 19:12:48,614 [Executor task launch worker for task 28] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 6 ms
2021-12-03 19:12:48,614 [Executor task launch worker for task 27] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 6 ms
2021-12-03 19:12:49,031 [Executor task launch worker for task 29] INFO [org.apache.spark.executor.Executor] - Finished task 6.0 in stage 2.0 (TID 29). 1141 bytes result sent to driver
2021-12-03 19:12:49,033 [dispatcher-event-loop-4] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 12.0 in stage 2.0 (TID 35, localhost, executor driver, partition 12, ANY, 7649 bytes)
2021-12-03 19:12:49,033 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 6.0 in stage 2.0 (TID 29) in 435 ms on localhost (executor driver) (1/22)
2021-12-03 19:12:49,033 [Executor task launch worker for task 35] INFO [org.apache.spark.executor.Executor] - Running task 12.0 in stage 2.0 (TID 35)
2021-12-03 19:12:49,034 [Executor task launch worker for task 31] INFO [org.apache.spark.executor.Executor] - Finished task 8.0 in stage 2.0 (TID 31). 1098 bytes result sent to driver
2021-12-03 19:12:49,034 [Executor task launch worker for task 35] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 19:12:49,034 [Executor task launch worker for task 35] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 19:12:49,038 [dispatcher-event-loop-6] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 13.0 in stage 2.0 (TID 36, localhost, executor driver, partition 13, ANY, 7649 bytes)
2021-12-03 19:12:49,038 [Executor task launch worker for task 36] INFO [org.apache.spark.executor.Executor] - Running task 13.0 in stage 2.0 (TID 36)
2021-12-03 19:12:49,038 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 8.0 in stage 2.0 (TID 31) in 440 ms on localhost (executor driver) (2/22)
2021-12-03 19:12:49,039 [Executor task launch worker for task 36] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 19:12:49,039 [Executor task launch worker for task 36] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 19:12:49,039 [Executor task launch worker for task 26] INFO [org.apache.spark.executor.Executor] - Finished task 3.0 in stage 2.0 (TID 26). 1098 bytes result sent to driver
2021-12-03 19:12:49,040 [dispatcher-event-loop-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 14.0 in stage 2.0 (TID 37, localhost, executor driver, partition 14, ANY, 7649 bytes)
2021-12-03 19:12:49,041 [Executor task launch worker for task 37] INFO [org.apache.spark.executor.Executor] - Running task 14.0 in stage 2.0 (TID 37)
2021-12-03 19:12:49,041 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 3.0 in stage 2.0 (TID 26) in 444 ms on localhost (executor driver) (3/22)
2021-12-03 19:12:49,042 [Executor task launch worker for task 37] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 19:12:49,042 [Executor task launch worker for task 37] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 19:12:49,043 [Executor task launch worker for task 24] INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 2.0 (TID 24). 1098 bytes result sent to driver
2021-12-03 19:12:49,044 [Executor task launch worker for task 32] INFO [org.apache.spark.executor.Executor] - Finished task 9.0 in stage 2.0 (TID 32). 1098 bytes result sent to driver
2021-12-03 19:12:49,044 [Executor task launch worker for task 25] INFO [org.apache.spark.executor.Executor] - Finished task 2.0 in stage 2.0 (TID 25). 1098 bytes result sent to driver
2021-12-03 19:12:49,045 [dispatcher-event-loop-10] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 15.0 in stage 2.0 (TID 38, localhost, executor driver, partition 15, ANY, 7649 bytes)
2021-12-03 19:12:49,045 [Executor task launch worker for task 38] INFO [org.apache.spark.executor.Executor] - Running task 15.0 in stage 2.0 (TID 38)
2021-12-03 19:12:49,045 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 2.0 (TID 24) in 448 ms on localhost (executor driver) (4/22)
2021-12-03 19:12:49,046 [Executor task launch worker for task 34] INFO [org.apache.spark.executor.Executor] - Finished task 11.0 in stage 2.0 (TID 34). 1098 bytes result sent to driver
2021-12-03 19:12:49,046 [dispatcher-event-loop-10] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 16.0 in stage 2.0 (TID 39, localhost, executor driver, partition 16, ANY, 7649 bytes)
2021-12-03 19:12:49,046 [dispatcher-event-loop-10] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 17.0 in stage 2.0 (TID 40, localhost, executor driver, partition 17, ANY, 7649 bytes)
2021-12-03 19:12:49,046 [Executor task launch worker for task 23] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 2.0 (TID 23). 1098 bytes result sent to driver
2021-12-03 19:12:49,046 [Executor task launch worker for task 38] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 19:12:49,046 [Executor task launch worker for task 38] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 19:12:49,046 [Executor task launch worker for task 39] INFO [org.apache.spark.executor.Executor] - Running task 16.0 in stage 2.0 (TID 39)
2021-12-03 19:12:49,046 [Executor task launch worker for task 28] INFO [org.apache.spark.executor.Executor] - Finished task 5.0 in stage 2.0 (TID 28). 1098 bytes result sent to driver
2021-12-03 19:12:49,047 [Executor task launch worker for task 30] INFO [org.apache.spark.executor.Executor] - Finished task 7.0 in stage 2.0 (TID 30). 1098 bytes result sent to driver
2021-12-03 19:12:49,046 [Executor task launch worker for task 40] INFO [org.apache.spark.executor.Executor] - Running task 17.0 in stage 2.0 (TID 40)
2021-12-03 19:12:49,047 [Executor task launch worker for task 33] INFO [org.apache.spark.executor.Executor] - Finished task 10.0 in stage 2.0 (TID 33). 1098 bytes result sent to driver
2021-12-03 19:12:49,047 [Executor task launch worker for task 27] INFO [org.apache.spark.executor.Executor] - Finished task 4.0 in stage 2.0 (TID 27). 1098 bytes result sent to driver
2021-12-03 19:12:49,047 [dispatcher-event-loop-10] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 18.0 in stage 2.0 (TID 41, localhost, executor driver, partition 18, ANY, 7649 bytes)
2021-12-03 19:12:49,048 [Executor task launch worker for task 41] INFO [org.apache.spark.executor.Executor] - Running task 18.0 in stage 2.0 (TID 41)
2021-12-03 19:12:49,048 [dispatcher-event-loop-10] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 19.0 in stage 2.0 (TID 42, localhost, executor driver, partition 19, ANY, 7649 bytes)
2021-12-03 19:12:49,048 [Executor task launch worker for task 42] INFO [org.apache.spark.executor.Executor] - Running task 19.0 in stage 2.0 (TID 42)
2021-12-03 19:12:49,048 [dispatcher-event-loop-10] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 20.0 in stage 2.0 (TID 43, localhost, executor driver, partition 20, ANY, 7649 bytes)
2021-12-03 19:12:49,048 [dispatcher-event-loop-10] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 21.0 in stage 2.0 (TID 44, localhost, executor driver, partition 21, ANY, 7649 bytes)
2021-12-03 19:12:49,048 [Executor task launch worker for task 40] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 19:12:49,048 [Executor task launch worker for task 40] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 19:12:49,049 [Executor task launch worker for task 41] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 19:12:49,049 [Executor task launch worker for task 41] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 1 ms
2021-12-03 19:12:49,049 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 2.0 in stage 2.0 (TID 25) in 452 ms on localhost (executor driver) (5/22)
2021-12-03 19:12:49,049 [Executor task launch worker for task 42] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 19:12:49,049 [Executor task launch worker for task 42] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 19:12:49,048 [Executor task launch worker for task 43] INFO [org.apache.spark.executor.Executor] - Running task 20.0 in stage 2.0 (TID 43)
2021-12-03 19:12:49,049 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 5.0 in stage 2.0 (TID 28) in 451 ms on localhost (executor driver) (6/22)
2021-12-03 19:12:49,049 [Executor task launch worker for task 44] INFO [org.apache.spark.executor.Executor] - Running task 21.0 in stage 2.0 (TID 44)
2021-12-03 19:12:49,049 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 2.0 (TID 23) in 452 ms on localhost (executor driver) (7/22)
2021-12-03 19:12:49,049 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 11.0 in stage 2.0 (TID 34) in 450 ms on localhost (executor driver) (8/22)
2021-12-03 19:12:49,050 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 4.0 in stage 2.0 (TID 27) in 452 ms on localhost (executor driver) (9/22)
2021-12-03 19:12:49,048 [Executor task launch worker for task 39] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 19:12:49,050 [Executor task launch worker for task 39] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 2 ms
2021-12-03 19:12:49,050 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 10.0 in stage 2.0 (TID 33) in 452 ms on localhost (executor driver) (10/22)
2021-12-03 19:12:49,050 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 7.0 in stage 2.0 (TID 30) in 452 ms on localhost (executor driver) (11/22)
2021-12-03 19:12:49,050 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 9.0 in stage 2.0 (TID 32) in 452 ms on localhost (executor driver) (12/22)
2021-12-03 19:12:49,050 [Executor task launch worker for task 43] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 19:12:49,050 [Executor task launch worker for task 43] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 19:12:49,051 [Executor task launch worker for task 44] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 19:12:49,051 [Executor task launch worker for task 44] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 1 ms
2021-12-03 19:12:49,132 [Executor task launch worker for task 36] INFO [org.apache.spark.executor.Executor] - Finished task 13.0 in stage 2.0 (TID 36). 1055 bytes result sent to driver
2021-12-03 19:12:49,132 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 13.0 in stage 2.0 (TID 36) in 95 ms on localhost (executor driver) (13/22)
2021-12-03 19:12:49,136 [Executor task launch worker for task 35] INFO [org.apache.spark.executor.Executor] - Finished task 12.0 in stage 2.0 (TID 35). 1012 bytes result sent to driver
2021-12-03 19:12:49,136 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 12.0 in stage 2.0 (TID 35) in 104 ms on localhost (executor driver) (14/22)
2021-12-03 19:12:49,141 [Executor task launch worker for task 41] INFO [org.apache.spark.executor.Executor] - Finished task 18.0 in stage 2.0 (TID 41). 1055 bytes result sent to driver
2021-12-03 19:12:49,141 [Executor task launch worker for task 37] INFO [org.apache.spark.executor.Executor] - Finished task 14.0 in stage 2.0 (TID 37). 1055 bytes result sent to driver
2021-12-03 19:12:49,141 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 18.0 in stage 2.0 (TID 41) in 94 ms on localhost (executor driver) (15/22)
2021-12-03 19:12:49,141 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 14.0 in stage 2.0 (TID 37) in 101 ms on localhost (executor driver) (16/22)
2021-12-03 19:12:49,142 [Executor task launch worker for task 40] INFO [org.apache.spark.executor.Executor] - Finished task 17.0 in stage 2.0 (TID 40). 1055 bytes result sent to driver
2021-12-03 19:12:49,142 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 17.0 in stage 2.0 (TID 40) in 96 ms on localhost (executor driver) (17/22)
2021-12-03 19:12:49,145 [Executor task launch worker for task 43] INFO [org.apache.spark.executor.Executor] - Finished task 20.0 in stage 2.0 (TID 43). 1055 bytes result sent to driver
2021-12-03 19:12:49,145 [Executor task launch worker for task 42] INFO [org.apache.spark.executor.Executor] - Finished task 19.0 in stage 2.0 (TID 42). 1098 bytes result sent to driver
2021-12-03 19:12:49,146 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 20.0 in stage 2.0 (TID 43) in 98 ms on localhost (executor driver) (18/22)
2021-12-03 19:12:49,146 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 19.0 in stage 2.0 (TID 42) in 98 ms on localhost (executor driver) (19/22)
2021-12-03 19:12:49,148 [Executor task launch worker for task 39] INFO [org.apache.spark.executor.Executor] - Finished task 16.0 in stage 2.0 (TID 39). 1055 bytes result sent to driver
2021-12-03 19:12:49,149 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 16.0 in stage 2.0 (TID 39) in 104 ms on localhost (executor driver) (20/22)
2021-12-03 19:12:49,149 [Executor task launch worker for task 38] INFO [org.apache.spark.executor.Executor] - Finished task 15.0 in stage 2.0 (TID 38). 1012 bytes result sent to driver
2021-12-03 19:12:49,150 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 15.0 in stage 2.0 (TID 38) in 106 ms on localhost (executor driver) (21/22)
2021-12-03 19:12:49,153 [Executor task launch worker for task 44] INFO [org.apache.spark.executor.Executor] - Finished task 21.0 in stage 2.0 (TID 44). 1012 bytes result sent to driver
2021-12-03 19:12:49,153 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 21.0 in stage 2.0 (TID 44) in 105 ms on localhost (executor driver) (22/22)
2021-12-03 19:12:49,153 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 2.0, whose tasks have all completed, from pool 
2021-12-03 19:12:49,153 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 2 (count at PaidPromotionAdjustParameter.scala:70) finished in 0.562 s
2021-12-03 19:12:49,154 [main] INFO [org.apache.spark.scheduler.DAGScheduler] - Job 1 finished: count at PaidPromotionAdjustParameter.scala:70, took 258.367445 s
2021-12-03 19:12:49,172 [main] INFO [org.apache.spark.SparkContext] - Starting job: sortByKey at PaidPromotionAdjustParameter.scala:74
2021-12-03 19:12:49,173 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 2 (sortByKey at PaidPromotionAdjustParameter.scala:74) with 22 output partitions
2021-12-03 19:12:49,173 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 4 (sortByKey at PaidPromotionAdjustParameter.scala:74)
2021-12-03 19:12:49,173 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 3)
2021-12-03 19:12:49,173 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2021-12-03 19:12:49,173 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 4 (MapPartitionsRDD[7] at sortByKey at PaidPromotionAdjustParameter.scala:74), which has no missing parents
2021-12-03 19:12:49,176 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_4 stored as values in memory (estimated size 4.1 KB, free 1990.5 MB)
2021-12-03 19:12:49,177 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_4_piece0 stored as bytes in memory (estimated size 2.4 KB, free 1990.4 MB)
2021-12-03 19:12:49,178 [dispatcher-event-loop-10] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_4_piece0 in memory on qb:50913 (size: 2.4 KB, free: 1990.8 MB)
2021-12-03 19:12:49,178 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 4 from broadcast at DAGScheduler.scala:1039
2021-12-03 19:12:49,178 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 22 missing tasks from ResultStage 4 (MapPartitionsRDD[7] at sortByKey at PaidPromotionAdjustParameter.scala:74) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14))
2021-12-03 19:12:49,178 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 4.0 with 22 tasks
2021-12-03 19:12:49,179 [dispatcher-event-loop-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 4.0 (TID 45, localhost, executor driver, partition 0, ANY, 7649 bytes)
2021-12-03 19:12:49,179 [dispatcher-event-loop-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 4.0 (TID 46, localhost, executor driver, partition 1, ANY, 7649 bytes)
2021-12-03 19:12:49,179 [dispatcher-event-loop-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 2.0 in stage 4.0 (TID 47, localhost, executor driver, partition 2, ANY, 7649 bytes)
2021-12-03 19:12:49,179 [dispatcher-event-loop-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 3.0 in stage 4.0 (TID 48, localhost, executor driver, partition 3, ANY, 7649 bytes)
2021-12-03 19:12:49,179 [dispatcher-event-loop-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 4.0 in stage 4.0 (TID 49, localhost, executor driver, partition 4, ANY, 7649 bytes)
2021-12-03 19:12:49,179 [dispatcher-event-loop-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 5.0 in stage 4.0 (TID 50, localhost, executor driver, partition 5, ANY, 7649 bytes)
2021-12-03 19:12:49,179 [dispatcher-event-loop-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 6.0 in stage 4.0 (TID 51, localhost, executor driver, partition 6, ANY, 7649 bytes)
2021-12-03 19:12:49,180 [dispatcher-event-loop-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 7.0 in stage 4.0 (TID 52, localhost, executor driver, partition 7, ANY, 7649 bytes)
2021-12-03 19:12:49,180 [dispatcher-event-loop-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 8.0 in stage 4.0 (TID 53, localhost, executor driver, partition 8, ANY, 7649 bytes)
2021-12-03 19:12:49,180 [dispatcher-event-loop-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 9.0 in stage 4.0 (TID 54, localhost, executor driver, partition 9, ANY, 7649 bytes)
2021-12-03 19:12:49,180 [dispatcher-event-loop-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 10.0 in stage 4.0 (TID 55, localhost, executor driver, partition 10, ANY, 7649 bytes)
2021-12-03 19:12:49,180 [dispatcher-event-loop-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 11.0 in stage 4.0 (TID 56, localhost, executor driver, partition 11, ANY, 7649 bytes)
2021-12-03 19:12:49,180 [Executor task launch worker for task 45] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 4.0 (TID 45)
2021-12-03 19:12:49,180 [Executor task launch worker for task 47] INFO [org.apache.spark.executor.Executor] - Running task 2.0 in stage 4.0 (TID 47)
2021-12-03 19:12:49,180 [Executor task launch worker for task 51] INFO [org.apache.spark.executor.Executor] - Running task 6.0 in stage 4.0 (TID 51)
2021-12-03 19:12:49,180 [Executor task launch worker for task 53] INFO [org.apache.spark.executor.Executor] - Running task 8.0 in stage 4.0 (TID 53)
2021-12-03 19:12:49,180 [Executor task launch worker for task 52] INFO [org.apache.spark.executor.Executor] - Running task 7.0 in stage 4.0 (TID 52)
2021-12-03 19:12:49,180 [Executor task launch worker for task 50] INFO [org.apache.spark.executor.Executor] - Running task 5.0 in stage 4.0 (TID 50)
2021-12-03 19:12:49,180 [Executor task launch worker for task 49] INFO [org.apache.spark.executor.Executor] - Running task 4.0 in stage 4.0 (TID 49)
2021-12-03 19:12:49,180 [Executor task launch worker for task 48] INFO [org.apache.spark.executor.Executor] - Running task 3.0 in stage 4.0 (TID 48)
2021-12-03 19:12:49,180 [Executor task launch worker for task 46] INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 4.0 (TID 46)
2021-12-03 19:12:49,180 [Executor task launch worker for task 54] INFO [org.apache.spark.executor.Executor] - Running task 9.0 in stage 4.0 (TID 54)
2021-12-03 19:12:49,180 [Executor task launch worker for task 55] INFO [org.apache.spark.executor.Executor] - Running task 10.0 in stage 4.0 (TID 55)
2021-12-03 19:12:49,180 [Executor task launch worker for task 56] INFO [org.apache.spark.executor.Executor] - Running task 11.0 in stage 4.0 (TID 56)
2021-12-03 19:12:49,182 [Executor task launch worker for task 48] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 19:12:49,182 [Executor task launch worker for task 48] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 1 ms
2021-12-03 19:12:49,182 [Executor task launch worker for task 46] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 19:12:49,182 [Executor task launch worker for task 46] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 19:12:49,182 [Executor task launch worker for task 55] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 19:12:49,182 [Executor task launch worker for task 45] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 19:12:49,182 [Executor task launch worker for task 55] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 19:12:49,182 [Executor task launch worker for task 45] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 19:12:49,182 [Executor task launch worker for task 54] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 19:12:49,182 [Executor task launch worker for task 54] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 19:12:49,182 [Executor task launch worker for task 50] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 19:12:49,182 [Executor task launch worker for task 50] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 19:12:49,182 [Executor task launch worker for task 52] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 19:12:49,182 [Executor task launch worker for task 52] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 19:12:49,182 [Executor task launch worker for task 47] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 19:12:49,182 [Executor task launch worker for task 47] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 19:12:49,182 [Executor task launch worker for task 56] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 19:12:49,182 [Executor task launch worker for task 56] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 19:12:49,182 [Executor task launch worker for task 49] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 19:12:49,182 [Executor task launch worker for task 49] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 19:12:49,182 [Executor task launch worker for task 51] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 19:12:49,182 [Executor task launch worker for task 51] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 19:12:49,182 [Executor task launch worker for task 53] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 19:12:49,182 [Executor task launch worker for task 53] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 19:12:49,262 [dispatcher-event-loop-6] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_3_piece0 on qb:50913 in memory (size: 1906.0 B, free: 1990.8 MB)
2021-12-03 19:12:49,311 [Executor task launch worker for task 54] INFO [org.apache.spark.executor.Executor] - Finished task 9.0 in stage 4.0 (TID 54). 1192 bytes result sent to driver
2021-12-03 19:12:49,312 [dispatcher-event-loop-5] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 12.0 in stage 4.0 (TID 57, localhost, executor driver, partition 12, ANY, 7649 bytes)
2021-12-03 19:12:49,312 [Executor task launch worker for task 57] INFO [org.apache.spark.executor.Executor] - Running task 12.0 in stage 4.0 (TID 57)
2021-12-03 19:12:49,312 [Executor task launch worker for task 51] INFO [org.apache.spark.executor.Executor] - Finished task 6.0 in stage 4.0 (TID 51). 1138 bytes result sent to driver
2021-12-03 19:12:49,312 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 9.0 in stage 4.0 (TID 54) in 132 ms on localhost (executor driver) (1/22)
2021-12-03 19:12:49,312 [dispatcher-event-loop-7] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 13.0 in stage 4.0 (TID 58, localhost, executor driver, partition 13, ANY, 7649 bytes)
2021-12-03 19:12:49,312 [Executor task launch worker for task 58] INFO [org.apache.spark.executor.Executor] - Running task 13.0 in stage 4.0 (TID 58)
2021-12-03 19:12:49,312 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 6.0 in stage 4.0 (TID 51) in 133 ms on localhost (executor driver) (2/22)
2021-12-03 19:12:49,313 [Executor task launch worker for task 57] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 19:12:49,313 [Executor task launch worker for task 57] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 19:12:49,313 [Executor task launch worker for task 58] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 19:12:49,313 [Executor task launch worker for task 58] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 19:12:49,313 [Executor task launch worker for task 55] INFO [org.apache.spark.executor.Executor] - Finished task 10.0 in stage 4.0 (TID 55). 1187 bytes result sent to driver
2021-12-03 19:12:49,314 [dispatcher-event-loop-11] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 14.0 in stage 4.0 (TID 59, localhost, executor driver, partition 14, ANY, 7649 bytes)
2021-12-03 19:12:49,314 [Executor task launch worker for task 59] INFO [org.apache.spark.executor.Executor] - Running task 14.0 in stage 4.0 (TID 59)
2021-12-03 19:12:49,314 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 10.0 in stage 4.0 (TID 55) in 134 ms on localhost (executor driver) (3/22)
2021-12-03 19:12:49,315 [Executor task launch worker for task 59] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 19:12:49,315 [Executor task launch worker for task 59] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 19:12:49,315 [Executor task launch worker for task 45] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 4.0 (TID 45). 1188 bytes result sent to driver
2021-12-03 19:12:49,317 [dispatcher-event-loop-9] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 15.0 in stage 4.0 (TID 60, localhost, executor driver, partition 15, ANY, 7649 bytes)
2021-12-03 19:12:49,317 [Executor task launch worker for task 60] INFO [org.apache.spark.executor.Executor] - Running task 15.0 in stage 4.0 (TID 60)
2021-12-03 19:12:49,317 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 4.0 (TID 45) in 138 ms on localhost (executor driver) (4/22)
2021-12-03 19:12:49,318 [Executor task launch worker for task 60] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 19:12:49,318 [Executor task launch worker for task 60] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 19:12:49,323 [Executor task launch worker for task 50] INFO [org.apache.spark.executor.Executor] - Finished task 5.0 in stage 4.0 (TID 50). 1232 bytes result sent to driver
2021-12-03 19:12:49,323 [dispatcher-event-loop-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 16.0 in stage 4.0 (TID 61, localhost, executor driver, partition 16, ANY, 7649 bytes)
2021-12-03 19:12:49,324 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 5.0 in stage 4.0 (TID 50) in 145 ms on localhost (executor driver) (5/22)
2021-12-03 19:12:49,324 [Executor task launch worker for task 61] INFO [org.apache.spark.executor.Executor] - Running task 16.0 in stage 4.0 (TID 61)
2021-12-03 19:12:49,324 [Executor task launch worker for task 49] INFO [org.apache.spark.executor.Executor] - Finished task 4.0 in stage 4.0 (TID 49). 1187 bytes result sent to driver
2021-12-03 19:12:49,325 [Executor task launch worker for task 46] INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 4.0 (TID 46). 1140 bytes result sent to driver
2021-12-03 19:12:49,325 [Executor task launch worker for task 47] INFO [org.apache.spark.executor.Executor] - Finished task 2.0 in stage 4.0 (TID 47). 1146 bytes result sent to driver
2021-12-03 19:12:49,326 [dispatcher-event-loop-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 17.0 in stage 4.0 (TID 62, localhost, executor driver, partition 17, ANY, 7649 bytes)
2021-12-03 19:12:49,326 [Executor task launch worker for task 61] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 19:12:49,326 [Executor task launch worker for task 61] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 1 ms
2021-12-03 19:12:49,327 [Executor task launch worker for task 62] INFO [org.apache.spark.executor.Executor] - Running task 17.0 in stage 4.0 (TID 62)
2021-12-03 19:12:49,327 [dispatcher-event-loop-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 18.0 in stage 4.0 (TID 63, localhost, executor driver, partition 18, ANY, 7649 bytes)
2021-12-03 19:12:49,327 [Executor task launch worker for task 63] INFO [org.apache.spark.executor.Executor] - Running task 18.0 in stage 4.0 (TID 63)
2021-12-03 19:12:49,327 [dispatcher-event-loop-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 19.0 in stage 4.0 (TID 64, localhost, executor driver, partition 19, ANY, 7649 bytes)
2021-12-03 19:12:49,327 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 4.0 (TID 46) in 148 ms on localhost (executor driver) (6/22)
2021-12-03 19:12:49,328 [Executor task launch worker for task 64] INFO [org.apache.spark.executor.Executor] - Running task 19.0 in stage 4.0 (TID 64)
2021-12-03 19:12:49,328 [Executor task launch worker for task 62] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 19:12:49,328 [Executor task launch worker for task 62] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 19:12:49,328 [Executor task launch worker for task 63] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 19:12:49,328 [Executor task launch worker for task 63] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 19:12:49,328 [Executor task launch worker for task 48] INFO [org.apache.spark.executor.Executor] - Finished task 3.0 in stage 4.0 (TID 48). 1141 bytes result sent to driver
2021-12-03 19:12:49,328 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 4.0 in stage 4.0 (TID 49) in 149 ms on localhost (executor driver) (7/22)
2021-12-03 19:12:49,328 [Executor task launch worker for task 56] INFO [org.apache.spark.executor.Executor] - Finished task 11.0 in stage 4.0 (TID 56). 1185 bytes result sent to driver
2021-12-03 19:12:49,329 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 2.0 in stage 4.0 (TID 47) in 150 ms on localhost (executor driver) (8/22)
2021-12-03 19:12:49,329 [Executor task launch worker for task 53] INFO [org.apache.spark.executor.Executor] - Finished task 8.0 in stage 4.0 (TID 53). 1144 bytes result sent to driver
2021-12-03 19:12:49,329 [Executor task launch worker for task 64] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 19:12:49,329 [Executor task launch worker for task 64] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 1 ms
2021-12-03 19:12:49,330 [dispatcher-event-loop-5] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 20.0 in stage 4.0 (TID 65, localhost, executor driver, partition 20, ANY, 7649 bytes)
2021-12-03 19:12:49,330 [Executor task launch worker for task 65] INFO [org.apache.spark.executor.Executor] - Running task 20.0 in stage 4.0 (TID 65)
2021-12-03 19:12:49,330 [dispatcher-event-loop-5] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 21.0 in stage 4.0 (TID 66, localhost, executor driver, partition 21, ANY, 7649 bytes)
2021-12-03 19:12:49,330 [Executor task launch worker for task 52] INFO [org.apache.spark.executor.Executor] - Finished task 7.0 in stage 4.0 (TID 52). 1143 bytes result sent to driver
2021-12-03 19:12:49,331 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 3.0 in stage 4.0 (TID 48) in 152 ms on localhost (executor driver) (9/22)
2021-12-03 19:12:49,331 [Executor task launch worker for task 66] INFO [org.apache.spark.executor.Executor] - Running task 21.0 in stage 4.0 (TID 66)
2021-12-03 19:12:49,331 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 11.0 in stage 4.0 (TID 56) in 151 ms on localhost (executor driver) (10/22)
2021-12-03 19:12:49,331 [Executor task launch worker for task 65] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 19:12:49,331 [Executor task launch worker for task 65] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 19:12:49,331 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 8.0 in stage 4.0 (TID 53) in 151 ms on localhost (executor driver) (11/22)
2021-12-03 19:12:49,332 [Executor task launch worker for task 66] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 19:12:49,332 [Executor task launch worker for task 66] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 19:12:49,332 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 7.0 in stage 4.0 (TID 52) in 153 ms on localhost (executor driver) (12/22)
2021-12-03 19:12:49,405 [Executor task launch worker for task 57] INFO [org.apache.spark.executor.Executor] - Finished task 12.0 in stage 4.0 (TID 57). 1142 bytes result sent to driver
2021-12-03 19:12:49,406 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 12.0 in stage 4.0 (TID 57) in 94 ms on localhost (executor driver) (13/22)
2021-12-03 19:12:49,409 [Executor task launch worker for task 59] INFO [org.apache.spark.executor.Executor] - Finished task 14.0 in stage 4.0 (TID 59). 1185 bytes result sent to driver
2021-12-03 19:12:49,409 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 14.0 in stage 4.0 (TID 59) in 95 ms on localhost (executor driver) (14/22)
2021-12-03 19:12:49,411 [Executor task launch worker for task 58] INFO [org.apache.spark.executor.Executor] - Finished task 13.0 in stage 4.0 (TID 58). 1141 bytes result sent to driver
2021-12-03 19:12:49,411 [Executor task launch worker for task 60] INFO [org.apache.spark.executor.Executor] - Finished task 15.0 in stage 4.0 (TID 60). 1094 bytes result sent to driver
2021-12-03 19:12:49,411 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 13.0 in stage 4.0 (TID 58) in 99 ms on localhost (executor driver) (15/22)
2021-12-03 19:12:49,411 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 15.0 in stage 4.0 (TID 60) in 95 ms on localhost (executor driver) (16/22)
2021-12-03 19:12:49,419 [Executor task launch worker for task 63] INFO [org.apache.spark.executor.Executor] - Finished task 18.0 in stage 4.0 (TID 63). 1137 bytes result sent to driver
2021-12-03 19:12:49,420 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 18.0 in stage 4.0 (TID 63) in 93 ms on localhost (executor driver) (17/22)
2021-12-03 19:12:49,420 [Executor task launch worker for task 61] INFO [org.apache.spark.executor.Executor] - Finished task 16.0 in stage 4.0 (TID 61). 1143 bytes result sent to driver
2021-12-03 19:12:49,420 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 16.0 in stage 4.0 (TID 61) in 97 ms on localhost (executor driver) (18/22)
2021-12-03 19:12:49,423 [Executor task launch worker for task 66] INFO [org.apache.spark.executor.Executor] - Finished task 21.0 in stage 4.0 (TID 66). 1144 bytes result sent to driver
2021-12-03 19:12:49,424 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 21.0 in stage 4.0 (TID 66) in 94 ms on localhost (executor driver) (19/22)
2021-12-03 19:12:49,424 [Executor task launch worker for task 62] INFO [org.apache.spark.executor.Executor] - Finished task 17.0 in stage 4.0 (TID 62). 1099 bytes result sent to driver
2021-12-03 19:12:49,425 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 17.0 in stage 4.0 (TID 62) in 99 ms on localhost (executor driver) (20/22)
2021-12-03 19:12:49,427 [Executor task launch worker for task 65] INFO [org.apache.spark.executor.Executor] - Finished task 20.0 in stage 4.0 (TID 65). 1146 bytes result sent to driver
2021-12-03 19:12:49,427 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 20.0 in stage 4.0 (TID 65) in 98 ms on localhost (executor driver) (21/22)
2021-12-03 19:12:49,432 [Executor task launch worker for task 64] INFO [org.apache.spark.executor.Executor] - Finished task 19.0 in stage 4.0 (TID 64). 1103 bytes result sent to driver
2021-12-03 19:12:49,432 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 19.0 in stage 4.0 (TID 64) in 105 ms on localhost (executor driver) (22/22)
2021-12-03 19:12:49,432 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 4.0, whose tasks have all completed, from pool 
2021-12-03 19:12:49,432 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 4 (sortByKey at PaidPromotionAdjustParameter.scala:74) finished in 0.257 s
2021-12-03 19:12:49,432 [main] INFO [org.apache.spark.scheduler.DAGScheduler] - Job 2 finished: sortByKey at PaidPromotionAdjustParameter.scala:74, took 0.260362 s
2021-12-03 19:12:49,447 [main] INFO [org.apache.spark.SparkContext] - Starting job: zipWithIndex at PaidPromotionAdjustParameter.scala:75
2021-12-03 19:12:49,448 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 5 (map at PaidPromotionAdjustParameter.scala:73)
2021-12-03 19:12:49,448 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 3 (zipWithIndex at PaidPromotionAdjustParameter.scala:75) with 21 output partitions
2021-12-03 19:12:49,448 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 7 (zipWithIndex at PaidPromotionAdjustParameter.scala:75)
2021-12-03 19:12:49,448 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 6)
2021-12-03 19:12:49,448 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List(ShuffleMapStage 6)
2021-12-03 19:12:49,448 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ShuffleMapStage 6 (MapPartitionsRDD[5] at map at PaidPromotionAdjustParameter.scala:73), which has no missing parents
2021-12-03 19:12:49,456 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_5 stored as values in memory (estimated size 4.1 KB, free 1990.5 MB)
2021-12-03 19:12:49,459 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_5_piece0 stored as bytes in memory (estimated size 2.4 KB, free 1990.4 MB)
2021-12-03 19:12:49,459 [dispatcher-event-loop-1] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_5_piece0 in memory on qb:50913 (size: 2.4 KB, free: 1990.8 MB)
2021-12-03 19:12:49,459 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 5 from broadcast at DAGScheduler.scala:1039
2021-12-03 19:12:49,460 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 22 missing tasks from ShuffleMapStage 6 (MapPartitionsRDD[5] at map at PaidPromotionAdjustParameter.scala:73) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14))
2021-12-03 19:12:49,460 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 6.0 with 22 tasks
2021-12-03 19:12:49,460 [dispatcher-event-loop-4] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 6.0 (TID 67, localhost, executor driver, partition 0, ANY, 7638 bytes)
2021-12-03 19:12:49,460 [dispatcher-event-loop-4] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 6.0 (TID 68, localhost, executor driver, partition 1, ANY, 7638 bytes)
2021-12-03 19:12:49,460 [dispatcher-event-loop-4] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 2.0 in stage 6.0 (TID 69, localhost, executor driver, partition 2, ANY, 7638 bytes)
2021-12-03 19:12:49,460 [dispatcher-event-loop-4] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 3.0 in stage 6.0 (TID 70, localhost, executor driver, partition 3, ANY, 7638 bytes)
2021-12-03 19:12:49,461 [dispatcher-event-loop-4] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 4.0 in stage 6.0 (TID 71, localhost, executor driver, partition 4, ANY, 7638 bytes)
2021-12-03 19:12:49,461 [dispatcher-event-loop-4] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 5.0 in stage 6.0 (TID 72, localhost, executor driver, partition 5, ANY, 7638 bytes)
2021-12-03 19:12:49,461 [dispatcher-event-loop-4] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 6.0 in stage 6.0 (TID 73, localhost, executor driver, partition 6, ANY, 7638 bytes)
2021-12-03 19:12:49,461 [dispatcher-event-loop-4] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 7.0 in stage 6.0 (TID 74, localhost, executor driver, partition 7, ANY, 7638 bytes)
2021-12-03 19:12:49,461 [dispatcher-event-loop-4] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 8.0 in stage 6.0 (TID 75, localhost, executor driver, partition 8, ANY, 7638 bytes)
2021-12-03 19:12:49,461 [dispatcher-event-loop-4] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 9.0 in stage 6.0 (TID 76, localhost, executor driver, partition 9, ANY, 7638 bytes)
2021-12-03 19:12:49,461 [dispatcher-event-loop-4] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 10.0 in stage 6.0 (TID 77, localhost, executor driver, partition 10, ANY, 7638 bytes)
2021-12-03 19:12:49,461 [dispatcher-event-loop-4] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 11.0 in stage 6.0 (TID 78, localhost, executor driver, partition 11, ANY, 7638 bytes)
2021-12-03 19:12:49,461 [Executor task launch worker for task 68] INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 6.0 (TID 68)
2021-12-03 19:12:49,461 [Executor task launch worker for task 69] INFO [org.apache.spark.executor.Executor] - Running task 2.0 in stage 6.0 (TID 69)
2021-12-03 19:12:49,461 [Executor task launch worker for task 75] INFO [org.apache.spark.executor.Executor] - Running task 8.0 in stage 6.0 (TID 75)
2021-12-03 19:12:49,461 [Executor task launch worker for task 67] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 6.0 (TID 67)
2021-12-03 19:12:49,461 [Executor task launch worker for task 72] INFO [org.apache.spark.executor.Executor] - Running task 5.0 in stage 6.0 (TID 72)
2021-12-03 19:12:49,461 [Executor task launch worker for task 70] INFO [org.apache.spark.executor.Executor] - Running task 3.0 in stage 6.0 (TID 70)
2021-12-03 19:12:49,461 [Executor task launch worker for task 71] INFO [org.apache.spark.executor.Executor] - Running task 4.0 in stage 6.0 (TID 71)
2021-12-03 19:12:49,461 [Executor task launch worker for task 73] INFO [org.apache.spark.executor.Executor] - Running task 6.0 in stage 6.0 (TID 73)
2021-12-03 19:12:49,461 [Executor task launch worker for task 78] INFO [org.apache.spark.executor.Executor] - Running task 11.0 in stage 6.0 (TID 78)
2021-12-03 19:12:49,461 [Executor task launch worker for task 74] INFO [org.apache.spark.executor.Executor] - Running task 7.0 in stage 6.0 (TID 74)
2021-12-03 19:12:49,461 [Executor task launch worker for task 77] INFO [org.apache.spark.executor.Executor] - Running task 10.0 in stage 6.0 (TID 77)
2021-12-03 19:12:49,461 [Executor task launch worker for task 76] INFO [org.apache.spark.executor.Executor] - Running task 9.0 in stage 6.0 (TID 76)
2021-12-03 19:12:49,470 [Executor task launch worker for task 76] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 19:12:49,470 [Executor task launch worker for task 78] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 19:12:49,470 [Executor task launch worker for task 76] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 19:12:49,470 [Executor task launch worker for task 78] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 19:12:49,470 [Executor task launch worker for task 71] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 19:12:49,470 [Executor task launch worker for task 71] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 19:12:49,470 [Executor task launch worker for task 74] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 19:12:49,470 [Executor task launch worker for task 72] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 19:12:49,470 [Executor task launch worker for task 72] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 19:12:49,470 [Executor task launch worker for task 75] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 19:12:49,470 [Executor task launch worker for task 75] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 19:12:49,470 [Executor task launch worker for task 73] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 19:12:49,470 [Executor task launch worker for task 68] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 19:12:49,470 [Executor task launch worker for task 77] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 19:12:49,470 [Executor task launch worker for task 74] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 19:12:49,470 [Executor task launch worker for task 77] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 19:12:49,470 [Executor task launch worker for task 70] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 19:12:49,470 [Executor task launch worker for task 68] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 19:12:49,470 [Executor task launch worker for task 73] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 19:12:49,470 [Executor task launch worker for task 67] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 19:12:49,470 [Executor task launch worker for task 69] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 19:12:49,470 [Executor task launch worker for task 67] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 19:12:49,470 [Executor task launch worker for task 70] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 19:12:49,470 [Executor task launch worker for task 69] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 19:12:50,057 [Executor task launch worker for task 75] INFO [org.apache.spark.executor.Executor] - Finished task 8.0 in stage 6.0 (TID 75). 1267 bytes result sent to driver
2021-12-03 19:12:50,057 [dispatcher-event-loop-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 12.0 in stage 6.0 (TID 79, localhost, executor driver, partition 12, ANY, 7638 bytes)
2021-12-03 19:12:50,057 [Executor task launch worker for task 79] INFO [org.apache.spark.executor.Executor] - Running task 12.0 in stage 6.0 (TID 79)
2021-12-03 19:12:50,058 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 8.0 in stage 6.0 (TID 75) in 597 ms on localhost (executor driver) (1/22)
2021-12-03 19:12:50,064 [Executor task launch worker for task 79] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 19:12:50,064 [Executor task launch worker for task 79] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 19:12:50,065 [Executor task launch worker for task 76] INFO [org.apache.spark.executor.Executor] - Finished task 9.0 in stage 6.0 (TID 76). 1267 bytes result sent to driver
2021-12-03 19:12:50,065 [Executor task launch worker for task 72] INFO [org.apache.spark.executor.Executor] - Finished task 5.0 in stage 6.0 (TID 72). 1267 bytes result sent to driver
2021-12-03 19:12:50,066 [dispatcher-event-loop-7] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 13.0 in stage 6.0 (TID 80, localhost, executor driver, partition 13, ANY, 7638 bytes)
2021-12-03 19:12:50,066 [dispatcher-event-loop-7] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 14.0 in stage 6.0 (TID 81, localhost, executor driver, partition 14, ANY, 7638 bytes)
2021-12-03 19:12:50,066 [Executor task launch worker for task 81] INFO [org.apache.spark.executor.Executor] - Running task 14.0 in stage 6.0 (TID 81)
2021-12-03 19:12:50,066 [Executor task launch worker for task 80] INFO [org.apache.spark.executor.Executor] - Running task 13.0 in stage 6.0 (TID 80)
2021-12-03 19:12:50,066 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 5.0 in stage 6.0 (TID 72) in 605 ms on localhost (executor driver) (2/22)
2021-12-03 19:12:50,067 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 9.0 in stage 6.0 (TID 76) in 606 ms on localhost (executor driver) (3/22)
2021-12-03 19:12:50,069 [Executor task launch worker for task 81] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 19:12:50,069 [Executor task launch worker for task 81] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 19:12:50,069 [Executor task launch worker for task 80] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 19:12:50,070 [Executor task launch worker for task 80] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 1 ms
2021-12-03 19:12:50,100 [Executor task launch worker for task 67] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 6.0 (TID 67). 1267 bytes result sent to driver
2021-12-03 19:12:50,101 [dispatcher-event-loop-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 15.0 in stage 6.0 (TID 82, localhost, executor driver, partition 15, ANY, 7638 bytes)
2021-12-03 19:12:50,101 [Executor task launch worker for task 82] INFO [org.apache.spark.executor.Executor] - Running task 15.0 in stage 6.0 (TID 82)
2021-12-03 19:12:50,103 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 6.0 (TID 67) in 643 ms on localhost (executor driver) (4/22)
2021-12-03 19:12:50,105 [Executor task launch worker for task 82] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 19:12:50,105 [Executor task launch worker for task 82] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 19:12:50,134 [Executor task launch worker for task 77] INFO [org.apache.spark.executor.Executor] - Finished task 10.0 in stage 6.0 (TID 77). 1267 bytes result sent to driver
2021-12-03 19:12:50,135 [dispatcher-event-loop-10] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 16.0 in stage 6.0 (TID 83, localhost, executor driver, partition 16, ANY, 7638 bytes)
2021-12-03 19:12:50,135 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 10.0 in stage 6.0 (TID 77) in 674 ms on localhost (executor driver) (5/22)
2021-12-03 19:12:50,135 [Executor task launch worker for task 83] INFO [org.apache.spark.executor.Executor] - Running task 16.0 in stage 6.0 (TID 83)
2021-12-03 19:12:50,140 [Executor task launch worker for task 83] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 19:12:50,140 [Executor task launch worker for task 83] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 19:12:50,146 [Executor task launch worker for task 78] INFO [org.apache.spark.executor.Executor] - Finished task 11.0 in stage 6.0 (TID 78). 1267 bytes result sent to driver
2021-12-03 19:12:50,146 [dispatcher-event-loop-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 17.0 in stage 6.0 (TID 84, localhost, executor driver, partition 17, ANY, 7638 bytes)
2021-12-03 19:12:50,147 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 11.0 in stage 6.0 (TID 78) in 686 ms on localhost (executor driver) (6/22)
2021-12-03 19:12:50,147 [Executor task launch worker for task 84] INFO [org.apache.spark.executor.Executor] - Running task 17.0 in stage 6.0 (TID 84)
2021-12-03 19:12:50,150 [Executor task launch worker for task 84] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 19:12:50,150 [Executor task launch worker for task 84] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 19:12:50,153 [Executor task launch worker for task 71] INFO [org.apache.spark.executor.Executor] - Finished task 4.0 in stage 6.0 (TID 71). 1267 bytes result sent to driver
2021-12-03 19:12:50,153 [dispatcher-event-loop-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 18.0 in stage 6.0 (TID 85, localhost, executor driver, partition 18, ANY, 7638 bytes)
2021-12-03 19:12:50,154 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 4.0 in stage 6.0 (TID 71) in 694 ms on localhost (executor driver) (7/22)
2021-12-03 19:12:50,155 [Executor task launch worker for task 68] INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 6.0 (TID 68). 1267 bytes result sent to driver
2021-12-03 19:12:50,156 [dispatcher-event-loop-6] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 19.0 in stage 6.0 (TID 86, localhost, executor driver, partition 19, ANY, 7638 bytes)
2021-12-03 19:12:50,156 [Executor task launch worker for task 86] INFO [org.apache.spark.executor.Executor] - Running task 19.0 in stage 6.0 (TID 86)
2021-12-03 19:12:50,157 [Executor task launch worker for task 85] INFO [org.apache.spark.executor.Executor] - Running task 18.0 in stage 6.0 (TID 85)
2021-12-03 19:12:50,157 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 6.0 (TID 68) in 697 ms on localhost (executor driver) (8/22)
2021-12-03 19:12:50,158 [Executor task launch worker for task 73] INFO [org.apache.spark.executor.Executor] - Finished task 6.0 in stage 6.0 (TID 73). 1267 bytes result sent to driver
2021-12-03 19:12:50,159 [dispatcher-event-loop-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 20.0 in stage 6.0 (TID 87, localhost, executor driver, partition 20, ANY, 7638 bytes)
2021-12-03 19:12:50,159 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 6.0 in stage 6.0 (TID 73) in 698 ms on localhost (executor driver) (9/22)
2021-12-03 19:12:50,160 [Executor task launch worker for task 86] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 19:12:50,160 [Executor task launch worker for task 87] INFO [org.apache.spark.executor.Executor] - Running task 20.0 in stage 6.0 (TID 87)
2021-12-03 19:12:50,160 [Executor task launch worker for task 86] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 19:12:50,160 [Executor task launch worker for task 74] INFO [org.apache.spark.executor.Executor] - Finished task 7.0 in stage 6.0 (TID 74). 1267 bytes result sent to driver
2021-12-03 19:12:50,160 [Executor task launch worker for task 69] INFO [org.apache.spark.executor.Executor] - Finished task 2.0 in stage 6.0 (TID 69). 1267 bytes result sent to driver
2021-12-03 19:12:50,160 [dispatcher-event-loop-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 21.0 in stage 6.0 (TID 88, localhost, executor driver, partition 21, ANY, 7638 bytes)
2021-12-03 19:12:50,161 [Executor task launch worker for task 85] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 19:12:50,161 [Executor task launch worker for task 85] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 19:12:50,161 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 7.0 in stage 6.0 (TID 74) in 700 ms on localhost (executor driver) (10/22)
2021-12-03 19:12:50,161 [Executor task launch worker for task 88] INFO [org.apache.spark.executor.Executor] - Running task 21.0 in stage 6.0 (TID 88)
2021-12-03 19:12:50,161 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 2.0 in stage 6.0 (TID 69) in 701 ms on localhost (executor driver) (11/22)
2021-12-03 19:12:50,163 [Executor task launch worker for task 87] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 19:12:50,163 [Executor task launch worker for task 87] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 19:12:50,165 [Executor task launch worker for task 88] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 19:12:50,165 [Executor task launch worker for task 88] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 19:12:50,168 [Executor task launch worker for task 70] INFO [org.apache.spark.executor.Executor] - Finished task 3.0 in stage 6.0 (TID 70). 1267 bytes result sent to driver
2021-12-03 19:12:50,177 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 3.0 in stage 6.0 (TID 70) in 716 ms on localhost (executor driver) (12/22)
2021-12-03 19:12:50,453 [Executor task launch worker for task 79] INFO [org.apache.spark.executor.Executor] - Finished task 12.0 in stage 6.0 (TID 79). 1224 bytes result sent to driver
2021-12-03 19:12:50,453 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 12.0 in stage 6.0 (TID 79) in 396 ms on localhost (executor driver) (13/22)
2021-12-03 19:12:50,454 [Executor task launch worker for task 80] INFO [org.apache.spark.executor.Executor] - Finished task 13.0 in stage 6.0 (TID 80). 1224 bytes result sent to driver
2021-12-03 19:12:50,454 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 13.0 in stage 6.0 (TID 80) in 389 ms on localhost (executor driver) (14/22)
2021-12-03 19:12:50,492 [Executor task launch worker for task 81] INFO [org.apache.spark.executor.Executor] - Finished task 14.0 in stage 6.0 (TID 81). 1224 bytes result sent to driver
2021-12-03 19:12:50,493 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 14.0 in stage 6.0 (TID 81) in 427 ms on localhost (executor driver) (15/22)
2021-12-03 19:12:50,552 [Executor task launch worker for task 83] INFO [org.apache.spark.executor.Executor] - Finished task 16.0 in stage 6.0 (TID 83). 1224 bytes result sent to driver
2021-12-03 19:12:50,552 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 16.0 in stage 6.0 (TID 83) in 417 ms on localhost (executor driver) (16/22)
2021-12-03 19:12:50,564 [Executor task launch worker for task 84] INFO [org.apache.spark.executor.Executor] - Finished task 17.0 in stage 6.0 (TID 84). 1224 bytes result sent to driver
2021-12-03 19:12:50,564 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 17.0 in stage 6.0 (TID 84) in 418 ms on localhost (executor driver) (17/22)
2021-12-03 19:12:50,566 [Executor task launch worker for task 82] INFO [org.apache.spark.executor.Executor] - Finished task 15.0 in stage 6.0 (TID 82). 1224 bytes result sent to driver
2021-12-03 19:12:50,566 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 15.0 in stage 6.0 (TID 82) in 465 ms on localhost (executor driver) (18/22)
2021-12-03 19:12:50,581 [Executor task launch worker for task 86] INFO [org.apache.spark.executor.Executor] - Finished task 19.0 in stage 6.0 (TID 86). 1267 bytes result sent to driver
2021-12-03 19:12:50,582 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 19.0 in stage 6.0 (TID 86) in 427 ms on localhost (executor driver) (19/22)
2021-12-03 19:12:50,583 [Executor task launch worker for task 87] INFO [org.apache.spark.executor.Executor] - Finished task 20.0 in stage 6.0 (TID 87). 1224 bytes result sent to driver
2021-12-03 19:12:50,584 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 20.0 in stage 6.0 (TID 87) in 425 ms on localhost (executor driver) (20/22)
2021-12-03 19:12:50,595 [Executor task launch worker for task 85] INFO [org.apache.spark.executor.Executor] - Finished task 18.0 in stage 6.0 (TID 85). 1224 bytes result sent to driver
2021-12-03 19:12:50,595 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 18.0 in stage 6.0 (TID 85) in 442 ms on localhost (executor driver) (21/22)
2021-12-03 19:12:50,595 [Executor task launch worker for task 88] INFO [org.apache.spark.executor.Executor] - Finished task 21.0 in stage 6.0 (TID 88). 1224 bytes result sent to driver
2021-12-03 19:12:50,596 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 21.0 in stage 6.0 (TID 88) in 436 ms on localhost (executor driver) (22/22)
2021-12-03 19:12:50,596 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 6.0, whose tasks have all completed, from pool 
2021-12-03 19:12:50,596 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ShuffleMapStage 6 (map at PaidPromotionAdjustParameter.scala:73) finished in 1.146 s
2021-12-03 19:12:50,596 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - looking for newly runnable stages
2021-12-03 19:12:50,596 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - running: Set()
2021-12-03 19:12:50,596 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - waiting: Set(ResultStage 7)
2021-12-03 19:12:50,596 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - failed: Set()
2021-12-03 19:12:50,596 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 7 (ShuffledRDD[8] at sortByKey at PaidPromotionAdjustParameter.scala:74), which has no missing parents
2021-12-03 19:12:50,599 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_6 stored as values in memory (estimated size 3.4 KB, free 1990.4 MB)
2021-12-03 19:12:50,601 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_6_piece0 stored as bytes in memory (estimated size 2.0 KB, free 1990.4 MB)
2021-12-03 19:12:50,601 [dispatcher-event-loop-10] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_6_piece0 in memory on qb:50913 (size: 2.0 KB, free: 1990.8 MB)
2021-12-03 19:12:50,601 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 6 from broadcast at DAGScheduler.scala:1039
2021-12-03 19:12:50,601 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 21 missing tasks from ResultStage 7 (ShuffledRDD[8] at sortByKey at PaidPromotionAdjustParameter.scala:74) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14))
2021-12-03 19:12:50,601 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 7.0 with 21 tasks
2021-12-03 19:12:50,602 [dispatcher-event-loop-5] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 7.0 (TID 89, localhost, executor driver, partition 0, ANY, 7649 bytes)
2021-12-03 19:12:50,602 [dispatcher-event-loop-5] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 7.0 (TID 90, localhost, executor driver, partition 1, ANY, 7649 bytes)
2021-12-03 19:12:50,602 [dispatcher-event-loop-5] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 2.0 in stage 7.0 (TID 91, localhost, executor driver, partition 2, ANY, 7649 bytes)
2021-12-03 19:12:50,602 [dispatcher-event-loop-5] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 3.0 in stage 7.0 (TID 92, localhost, executor driver, partition 3, ANY, 7649 bytes)
2021-12-03 19:12:50,602 [dispatcher-event-loop-5] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 4.0 in stage 7.0 (TID 93, localhost, executor driver, partition 4, ANY, 7649 bytes)
2021-12-03 19:12:50,602 [dispatcher-event-loop-5] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 5.0 in stage 7.0 (TID 94, localhost, executor driver, partition 5, ANY, 7649 bytes)
2021-12-03 19:12:50,602 [dispatcher-event-loop-5] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 6.0 in stage 7.0 (TID 95, localhost, executor driver, partition 6, ANY, 7649 bytes)
2021-12-03 19:12:50,603 [dispatcher-event-loop-5] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 7.0 in stage 7.0 (TID 96, localhost, executor driver, partition 7, ANY, 7649 bytes)
2021-12-03 19:12:50,603 [dispatcher-event-loop-5] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 8.0 in stage 7.0 (TID 97, localhost, executor driver, partition 8, ANY, 7649 bytes)
2021-12-03 19:12:50,603 [dispatcher-event-loop-5] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 9.0 in stage 7.0 (TID 98, localhost, executor driver, partition 9, ANY, 7649 bytes)
2021-12-03 19:12:50,603 [dispatcher-event-loop-5] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 10.0 in stage 7.0 (TID 99, localhost, executor driver, partition 10, ANY, 7649 bytes)
2021-12-03 19:12:50,603 [dispatcher-event-loop-5] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 11.0 in stage 7.0 (TID 100, localhost, executor driver, partition 11, ANY, 7649 bytes)
2021-12-03 19:12:50,603 [Executor task launch worker for task 89] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 7.0 (TID 89)
2021-12-03 19:12:50,603 [Executor task launch worker for task 95] INFO [org.apache.spark.executor.Executor] - Running task 6.0 in stage 7.0 (TID 95)
2021-12-03 19:12:50,603 [Executor task launch worker for task 96] INFO [org.apache.spark.executor.Executor] - Running task 7.0 in stage 7.0 (TID 96)
2021-12-03 19:12:50,603 [Executor task launch worker for task 91] INFO [org.apache.spark.executor.Executor] - Running task 2.0 in stage 7.0 (TID 91)
2021-12-03 19:12:50,603 [Executor task launch worker for task 93] INFO [org.apache.spark.executor.Executor] - Running task 4.0 in stage 7.0 (TID 93)
2021-12-03 19:12:50,603 [Executor task launch worker for task 90] INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 7.0 (TID 90)
2021-12-03 19:12:50,603 [Executor task launch worker for task 92] INFO [org.apache.spark.executor.Executor] - Running task 3.0 in stage 7.0 (TID 92)
2021-12-03 19:12:50,603 [Executor task launch worker for task 94] INFO [org.apache.spark.executor.Executor] - Running task 5.0 in stage 7.0 (TID 94)
2021-12-03 19:12:50,603 [Executor task launch worker for task 99] INFO [org.apache.spark.executor.Executor] - Running task 10.0 in stage 7.0 (TID 99)
2021-12-03 19:12:50,603 [Executor task launch worker for task 98] INFO [org.apache.spark.executor.Executor] - Running task 9.0 in stage 7.0 (TID 98)
2021-12-03 19:12:50,603 [Executor task launch worker for task 100] INFO [org.apache.spark.executor.Executor] - Running task 11.0 in stage 7.0 (TID 100)
2021-12-03 19:12:50,603 [Executor task launch worker for task 97] INFO [org.apache.spark.executor.Executor] - Running task 8.0 in stage 7.0 (TID 97)
2021-12-03 19:12:50,606 [Executor task launch worker for task 99] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 19:12:50,607 [Executor task launch worker for task 98] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 19:12:50,607 [Executor task launch worker for task 99] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 1 ms
2021-12-03 19:12:50,607 [Executor task launch worker for task 98] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 1 ms
2021-12-03 19:12:50,607 [Executor task launch worker for task 97] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 19:12:50,607 [Executor task launch worker for task 97] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 19:12:50,607 [Executor task launch worker for task 90] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 19:12:50,607 [Executor task launch worker for task 90] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 19:12:50,607 [Executor task launch worker for task 92] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 19:12:50,607 [Executor task launch worker for task 92] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 19:12:50,608 [Executor task launch worker for task 95] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 19:12:50,608 [Executor task launch worker for task 95] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 19:12:50,608 [Executor task launch worker for task 100] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 19:12:50,608 [Executor task launch worker for task 100] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 19:12:50,608 [Executor task launch worker for task 94] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 19:12:50,608 [Executor task launch worker for task 94] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 19:12:50,609 [Executor task launch worker for task 91] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 19:12:50,609 [Executor task launch worker for task 91] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 19:12:50,609 [Executor task launch worker for task 89] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 19:12:50,609 [Executor task launch worker for task 89] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 19:12:50,609 [Executor task launch worker for task 93] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 19:12:50,609 [Executor task launch worker for task 93] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 19:12:50,610 [Executor task launch worker for task 96] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 19:12:50,610 [Executor task launch worker for task 96] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 19:12:50,913 [Executor task launch worker for task 99] INFO [org.apache.spark.executor.Executor] - Finished task 10.0 in stage 7.0 (TID 99). 1098 bytes result sent to driver
2021-12-03 19:12:50,914 [dispatcher-event-loop-4] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 12.0 in stage 7.0 (TID 101, localhost, executor driver, partition 12, ANY, 7649 bytes)
2021-12-03 19:12:50,914 [Executor task launch worker for task 98] INFO [org.apache.spark.executor.Executor] - Finished task 9.0 in stage 7.0 (TID 98). 1098 bytes result sent to driver
2021-12-03 19:12:50,914 [Executor task launch worker for task 101] INFO [org.apache.spark.executor.Executor] - Running task 12.0 in stage 7.0 (TID 101)
2021-12-03 19:12:50,914 [dispatcher-event-loop-4] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 13.0 in stage 7.0 (TID 102, localhost, executor driver, partition 13, ANY, 7649 bytes)
2021-12-03 19:12:50,914 [Executor task launch worker for task 102] INFO [org.apache.spark.executor.Executor] - Running task 13.0 in stage 7.0 (TID 102)
2021-12-03 19:12:50,915 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 9.0 in stage 7.0 (TID 98) in 312 ms on localhost (executor driver) (1/21)
2021-12-03 19:12:50,916 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 10.0 in stage 7.0 (TID 99) in 313 ms on localhost (executor driver) (2/21)
2021-12-03 19:12:50,916 [Executor task launch worker for task 101] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 19:12:50,916 [Executor task launch worker for task 101] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 19:12:50,917 [Executor task launch worker for task 102] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 19:12:50,917 [Executor task launch worker for task 102] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 19:12:50,926 [Executor task launch worker for task 95] INFO [org.apache.spark.executor.Executor] - Finished task 6.0 in stage 7.0 (TID 95). 1098 bytes result sent to driver
2021-12-03 19:12:50,926 [Executor task launch worker for task 100] INFO [org.apache.spark.executor.Executor] - Finished task 11.0 in stage 7.0 (TID 100). 1098 bytes result sent to driver
2021-12-03 19:12:50,927 [dispatcher-event-loop-8] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 14.0 in stage 7.0 (TID 103, localhost, executor driver, partition 14, ANY, 7649 bytes)
2021-12-03 19:12:50,927 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 11.0 in stage 7.0 (TID 100) in 324 ms on localhost (executor driver) (3/21)
2021-12-03 19:12:50,927 [Executor task launch worker for task 103] INFO [org.apache.spark.executor.Executor] - Running task 14.0 in stage 7.0 (TID 103)
2021-12-03 19:12:50,927 [dispatcher-event-loop-8] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 15.0 in stage 7.0 (TID 104, localhost, executor driver, partition 15, ANY, 7649 bytes)
2021-12-03 19:12:50,927 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 6.0 in stage 7.0 (TID 95) in 325 ms on localhost (executor driver) (4/21)
2021-12-03 19:12:50,927 [Executor task launch worker for task 104] INFO [org.apache.spark.executor.Executor] - Running task 15.0 in stage 7.0 (TID 104)
2021-12-03 19:12:50,928 [Executor task launch worker for task 97] INFO [org.apache.spark.executor.Executor] - Finished task 8.0 in stage 7.0 (TID 97). 1098 bytes result sent to driver
2021-12-03 19:12:50,928 [Executor task launch worker for task 94] INFO [org.apache.spark.executor.Executor] - Finished task 5.0 in stage 7.0 (TID 94). 1098 bytes result sent to driver
2021-12-03 19:12:50,929 [dispatcher-event-loop-11] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 16.0 in stage 7.0 (TID 105, localhost, executor driver, partition 16, ANY, 7649 bytes)
2021-12-03 19:12:50,929 [dispatcher-event-loop-11] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 17.0 in stage 7.0 (TID 106, localhost, executor driver, partition 17, ANY, 7649 bytes)
2021-12-03 19:12:50,929 [Executor task launch worker for task 106] INFO [org.apache.spark.executor.Executor] - Running task 17.0 in stage 7.0 (TID 106)
2021-12-03 19:12:50,930 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 5.0 in stage 7.0 (TID 94) in 328 ms on localhost (executor driver) (5/21)
2021-12-03 19:12:50,930 [Executor task launch worker for task 105] INFO [org.apache.spark.executor.Executor] - Running task 16.0 in stage 7.0 (TID 105)
2021-12-03 19:12:50,930 [Executor task launch worker for task 104] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 19:12:50,930 [Executor task launch worker for task 104] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 19:12:50,932 [Executor task launch worker for task 96] INFO [org.apache.spark.executor.Executor] - Finished task 7.0 in stage 7.0 (TID 96). 1098 bytes result sent to driver
2021-12-03 19:12:50,932 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 8.0 in stage 7.0 (TID 97) in 329 ms on localhost (executor driver) (6/21)
2021-12-03 19:12:50,932 [dispatcher-event-loop-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 18.0 in stage 7.0 (TID 107, localhost, executor driver, partition 18, ANY, 7649 bytes)
2021-12-03 19:12:50,932 [Executor task launch worker for task 107] INFO [org.apache.spark.executor.Executor] - Running task 18.0 in stage 7.0 (TID 107)
2021-12-03 19:12:50,932 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 7.0 in stage 7.0 (TID 96) in 330 ms on localhost (executor driver) (7/21)
2021-12-03 19:12:50,933 [Executor task launch worker for task 103] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 19:12:50,933 [Executor task launch worker for task 103] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 19:12:50,933 [Executor task launch worker for task 106] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 19:12:50,933 [Executor task launch worker for task 106] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 19:12:50,933 [Executor task launch worker for task 105] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 19:12:50,934 [Executor task launch worker for task 105] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 1 ms
2021-12-03 19:12:50,935 [Executor task launch worker for task 107] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 19:12:50,935 [Executor task launch worker for task 107] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 19:12:50,946 [Executor task launch worker for task 92] INFO [org.apache.spark.executor.Executor] - Finished task 3.0 in stage 7.0 (TID 92). 1098 bytes result sent to driver
2021-12-03 19:12:50,946 [dispatcher-event-loop-4] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 19.0 in stage 7.0 (TID 108, localhost, executor driver, partition 19, ANY, 7649 bytes)
2021-12-03 19:12:50,947 [Executor task launch worker for task 108] INFO [org.apache.spark.executor.Executor] - Running task 19.0 in stage 7.0 (TID 108)
2021-12-03 19:12:50,949 [Executor task launch worker for task 108] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 19:12:50,949 [Executor task launch worker for task 108] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 19:12:50,950 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 3.0 in stage 7.0 (TID 92) in 348 ms on localhost (executor driver) (8/21)
2021-12-03 19:12:50,955 [Executor task launch worker for task 89] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 7.0 (TID 89). 1098 bytes result sent to driver
2021-12-03 19:12:50,955 [dispatcher-event-loop-7] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 20.0 in stage 7.0 (TID 109, localhost, executor driver, partition 20, ANY, 7649 bytes)
2021-12-03 19:12:50,955 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 7.0 (TID 89) in 353 ms on localhost (executor driver) (9/21)
2021-12-03 19:12:50,955 [Executor task launch worker for task 109] INFO [org.apache.spark.executor.Executor] - Running task 20.0 in stage 7.0 (TID 109)
2021-12-03 19:12:50,958 [Executor task launch worker for task 90] INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 7.0 (TID 90). 1141 bytes result sent to driver
2021-12-03 19:12:50,958 [Executor task launch worker for task 93] INFO [org.apache.spark.executor.Executor] - Finished task 4.0 in stage 7.0 (TID 93). 1098 bytes result sent to driver
2021-12-03 19:12:50,958 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 7.0 (TID 90) in 356 ms on localhost (executor driver) (10/21)
2021-12-03 19:12:50,958 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 4.0 in stage 7.0 (TID 93) in 356 ms on localhost (executor driver) (11/21)
2021-12-03 19:12:50,959 [Executor task launch worker for task 109] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 19:12:50,959 [Executor task launch worker for task 109] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 19:12:50,968 [Executor task launch worker for task 91] INFO [org.apache.spark.executor.Executor] - Finished task 2.0 in stage 7.0 (TID 91). 1098 bytes result sent to driver
2021-12-03 19:12:50,969 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 2.0 in stage 7.0 (TID 91) in 367 ms on localhost (executor driver) (12/21)
2021-12-03 19:12:51,000 [Executor task launch worker for task 102] INFO [org.apache.spark.executor.Executor] - Finished task 13.0 in stage 7.0 (TID 102). 1055 bytes result sent to driver
2021-12-03 19:12:51,000 [Executor task launch worker for task 103] INFO [org.apache.spark.executor.Executor] - Finished task 14.0 in stage 7.0 (TID 103). 1055 bytes result sent to driver
2021-12-03 19:12:51,000 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 13.0 in stage 7.0 (TID 102) in 86 ms on localhost (executor driver) (13/21)
2021-12-03 19:12:51,000 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 14.0 in stage 7.0 (TID 103) in 73 ms on localhost (executor driver) (14/21)
2021-12-03 19:12:51,002 [Executor task launch worker for task 105] INFO [org.apache.spark.executor.Executor] - Finished task 16.0 in stage 7.0 (TID 105). 1055 bytes result sent to driver
2021-12-03 19:12:51,003 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 16.0 in stage 7.0 (TID 105) in 74 ms on localhost (executor driver) (15/21)
2021-12-03 19:12:51,006 [Executor task launch worker for task 101] INFO [org.apache.spark.executor.Executor] - Finished task 12.0 in stage 7.0 (TID 101). 1055 bytes result sent to driver
2021-12-03 19:12:51,006 [Executor task launch worker for task 107] INFO [org.apache.spark.executor.Executor] - Finished task 18.0 in stage 7.0 (TID 107). 1055 bytes result sent to driver
2021-12-03 19:12:51,007 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 12.0 in stage 7.0 (TID 101) in 94 ms on localhost (executor driver) (16/21)
2021-12-03 19:12:51,007 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 18.0 in stage 7.0 (TID 107) in 75 ms on localhost (executor driver) (17/21)
2021-12-03 19:12:51,011 [Executor task launch worker for task 104] INFO [org.apache.spark.executor.Executor] - Finished task 15.0 in stage 7.0 (TID 104). 1055 bytes result sent to driver
2021-12-03 19:12:51,011 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 15.0 in stage 7.0 (TID 104) in 84 ms on localhost (executor driver) (18/21)
2021-12-03 19:12:51,021 [Executor task launch worker for task 108] INFO [org.apache.spark.executor.Executor] - Finished task 19.0 in stage 7.0 (TID 108). 1055 bytes result sent to driver
2021-12-03 19:12:51,021 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 19.0 in stage 7.0 (TID 108) in 75 ms on localhost (executor driver) (19/21)
2021-12-03 19:12:51,023 [Executor task launch worker for task 106] INFO [org.apache.spark.executor.Executor] - Finished task 17.0 in stage 7.0 (TID 106). 1055 bytes result sent to driver
2021-12-03 19:12:51,023 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 17.0 in stage 7.0 (TID 106) in 94 ms on localhost (executor driver) (20/21)
2021-12-03 19:12:51,025 [Executor task launch worker for task 109] INFO [org.apache.spark.executor.Executor] - Finished task 20.0 in stage 7.0 (TID 109). 1098 bytes result sent to driver
2021-12-03 19:12:51,025 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 20.0 in stage 7.0 (TID 109) in 70 ms on localhost (executor driver) (21/21)
2021-12-03 19:12:51,025 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 7.0, whose tasks have all completed, from pool 
2021-12-03 19:12:51,025 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 7 (zipWithIndex at PaidPromotionAdjustParameter.scala:75) finished in 0.427 s
2021-12-03 19:12:51,026 [main] INFO [org.apache.spark.scheduler.DAGScheduler] - Job 3 finished: zipWithIndex at PaidPromotionAdjustParameter.scala:75, took 1.578088 s
2021-12-03 19:12:51,049 [main] INFO [org.apache.spark.SparkContext] - Starting job: takeSample at PaidPromotionAdjustParameter.scala:78
2021-12-03 19:12:51,049 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 4 (takeSample at PaidPromotionAdjustParameter.scala:78) with 22 output partitions
2021-12-03 19:12:51,050 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 10 (takeSample at PaidPromotionAdjustParameter.scala:78)
2021-12-03 19:12:51,050 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 9)
2021-12-03 19:12:51,050 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2021-12-03 19:12:51,050 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 10 (MapPartitionsRDD[11] at map at PaidPromotionAdjustParameter.scala:77), which has no missing parents
2021-12-03 19:12:51,053 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_7 stored as values in memory (estimated size 4.2 KB, free 1990.4 MB)
2021-12-03 19:12:51,055 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_7_piece0 stored as bytes in memory (estimated size 2.4 KB, free 1990.4 MB)
2021-12-03 19:12:51,055 [dispatcher-event-loop-8] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_7_piece0 in memory on qb:50913 (size: 2.4 KB, free: 1990.8 MB)
2021-12-03 19:12:51,055 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 7 from broadcast at DAGScheduler.scala:1039
2021-12-03 19:12:51,055 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 22 missing tasks from ResultStage 10 (MapPartitionsRDD[11] at map at PaidPromotionAdjustParameter.scala:77) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14))
2021-12-03 19:12:51,055 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 10.0 with 22 tasks
2021-12-03 19:12:51,056 [dispatcher-event-loop-9] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 10.0 (TID 110, localhost, executor driver, partition 0, ANY, 7759 bytes)
2021-12-03 19:12:51,056 [dispatcher-event-loop-9] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 10.0 (TID 111, localhost, executor driver, partition 1, ANY, 7759 bytes)
2021-12-03 19:12:51,056 [dispatcher-event-loop-9] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 2.0 in stage 10.0 (TID 112, localhost, executor driver, partition 2, ANY, 7759 bytes)
2021-12-03 19:12:51,057 [dispatcher-event-loop-9] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 3.0 in stage 10.0 (TID 113, localhost, executor driver, partition 3, ANY, 7759 bytes)
2021-12-03 19:12:51,057 [dispatcher-event-loop-9] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 4.0 in stage 10.0 (TID 114, localhost, executor driver, partition 4, ANY, 7759 bytes)
2021-12-03 19:12:51,057 [dispatcher-event-loop-9] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 5.0 in stage 10.0 (TID 115, localhost, executor driver, partition 5, ANY, 7759 bytes)
2021-12-03 19:12:51,057 [dispatcher-event-loop-9] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 6.0 in stage 10.0 (TID 116, localhost, executor driver, partition 6, ANY, 7759 bytes)
2021-12-03 19:12:51,057 [dispatcher-event-loop-9] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 7.0 in stage 10.0 (TID 117, localhost, executor driver, partition 7, ANY, 7759 bytes)
2021-12-03 19:12:51,057 [dispatcher-event-loop-9] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 8.0 in stage 10.0 (TID 118, localhost, executor driver, partition 8, ANY, 7759 bytes)
2021-12-03 19:12:51,057 [dispatcher-event-loop-9] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 9.0 in stage 10.0 (TID 119, localhost, executor driver, partition 9, ANY, 7759 bytes)
2021-12-03 19:12:51,057 [dispatcher-event-loop-9] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 10.0 in stage 10.0 (TID 120, localhost, executor driver, partition 10, ANY, 7759 bytes)
2021-12-03 19:12:51,057 [dispatcher-event-loop-9] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 11.0 in stage 10.0 (TID 121, localhost, executor driver, partition 11, ANY, 7759 bytes)
2021-12-03 19:12:51,057 [Executor task launch worker for task 111] INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 10.0 (TID 111)
2021-12-03 19:12:51,057 [Executor task launch worker for task 115] INFO [org.apache.spark.executor.Executor] - Running task 5.0 in stage 10.0 (TID 115)
2021-12-03 19:12:51,057 [Executor task launch worker for task 120] INFO [org.apache.spark.executor.Executor] - Running task 10.0 in stage 10.0 (TID 120)
2021-12-03 19:12:51,057 [Executor task launch worker for task 112] INFO [org.apache.spark.executor.Executor] - Running task 2.0 in stage 10.0 (TID 112)
2021-12-03 19:12:51,057 [Executor task launch worker for task 117] INFO [org.apache.spark.executor.Executor] - Running task 7.0 in stage 10.0 (TID 117)
2021-12-03 19:12:51,057 [Executor task launch worker for task 114] INFO [org.apache.spark.executor.Executor] - Running task 4.0 in stage 10.0 (TID 114)
2021-12-03 19:12:51,057 [Executor task launch worker for task 113] INFO [org.apache.spark.executor.Executor] - Running task 3.0 in stage 10.0 (TID 113)
2021-12-03 19:12:51,057 [Executor task launch worker for task 110] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 10.0 (TID 110)
2021-12-03 19:12:51,057 [Executor task launch worker for task 116] INFO [org.apache.spark.executor.Executor] - Running task 6.0 in stage 10.0 (TID 116)
2021-12-03 19:12:51,057 [Executor task launch worker for task 118] INFO [org.apache.spark.executor.Executor] - Running task 8.0 in stage 10.0 (TID 118)
2021-12-03 19:12:51,057 [Executor task launch worker for task 119] INFO [org.apache.spark.executor.Executor] - Running task 9.0 in stage 10.0 (TID 119)
2021-12-03 19:12:51,057 [Executor task launch worker for task 121] INFO [org.apache.spark.executor.Executor] - Running task 11.0 in stage 10.0 (TID 121)
2021-12-03 19:12:51,060 [Executor task launch worker for task 120] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 19:12:51,060 [Executor task launch worker for task 120] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 19:12:51,060 [Executor task launch worker for task 119] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 19:12:51,060 [Executor task launch worker for task 119] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 19:12:51,061 [Executor task launch worker for task 116] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 19:12:51,061 [Executor task launch worker for task 116] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 19:12:51,061 [Executor task launch worker for task 111] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 19:12:51,061 [Executor task launch worker for task 111] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 19:12:51,061 [Executor task launch worker for task 121] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 19:12:51,061 [Executor task launch worker for task 121] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 19:12:51,062 [Executor task launch worker for task 117] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 19:12:51,062 [Executor task launch worker for task 117] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 19:12:51,062 [Executor task launch worker for task 113] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 19:12:51,062 [Executor task launch worker for task 113] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 19:12:51,062 [Executor task launch worker for task 115] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 19:12:51,062 [Executor task launch worker for task 115] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 19:12:51,063 [Executor task launch worker for task 112] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 19:12:51,063 [Executor task launch worker for task 112] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 19:12:51,063 [Executor task launch worker for task 118] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 19:12:51,063 [Executor task launch worker for task 118] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 19:12:51,063 [Executor task launch worker for task 110] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 19:12:51,063 [Executor task launch worker for task 110] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 19:12:51,064 [Executor task launch worker for task 114] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 19:12:51,064 [Executor task launch worker for task 114] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 19:12:51,176 [Executor task launch worker for task 115] INFO [org.apache.spark.executor.Executor] - Finished task 5.0 in stage 10.0 (TID 115). 1053 bytes result sent to driver
2021-12-03 19:12:51,178 [dispatcher-event-loop-11] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 12.0 in stage 10.0 (TID 122, localhost, executor driver, partition 12, ANY, 7759 bytes)
2021-12-03 19:12:51,178 [Executor task launch worker for task 122] INFO [org.apache.spark.executor.Executor] - Running task 12.0 in stage 10.0 (TID 122)
2021-12-03 19:12:51,178 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 5.0 in stage 10.0 (TID 115) in 121 ms on localhost (executor driver) (1/22)
2021-12-03 19:12:51,181 [Executor task launch worker for task 122] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 19:12:51,181 [Executor task launch worker for task 122] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 19:12:51,186 [Executor task launch worker for task 114] INFO [org.apache.spark.executor.Executor] - Finished task 4.0 in stage 10.0 (TID 114). 1053 bytes result sent to driver
2021-12-03 19:12:51,187 [dispatcher-event-loop-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 13.0 in stage 10.0 (TID 123, localhost, executor driver, partition 13, ANY, 7759 bytes)
2021-12-03 19:12:51,187 [Executor task launch worker for task 123] INFO [org.apache.spark.executor.Executor] - Running task 13.0 in stage 10.0 (TID 123)
2021-12-03 19:12:51,187 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 4.0 in stage 10.0 (TID 114) in 130 ms on localhost (executor driver) (2/22)
2021-12-03 19:12:51,189 [Executor task launch worker for task 120] INFO [org.apache.spark.executor.Executor] - Finished task 10.0 in stage 10.0 (TID 120). 1053 bytes result sent to driver
2021-12-03 19:12:51,189 [Executor task launch worker for task 113] INFO [org.apache.spark.executor.Executor] - Finished task 3.0 in stage 10.0 (TID 113). 1053 bytes result sent to driver
2021-12-03 19:12:51,189 [dispatcher-event-loop-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 14.0 in stage 10.0 (TID 124, localhost, executor driver, partition 14, ANY, 7759 bytes)
2021-12-03 19:12:51,189 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 10.0 in stage 10.0 (TID 120) in 132 ms on localhost (executor driver) (3/22)
2021-12-03 19:12:51,189 [Executor task launch worker for task 124] INFO [org.apache.spark.executor.Executor] - Running task 14.0 in stage 10.0 (TID 124)
2021-12-03 19:12:51,190 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 3.0 in stage 10.0 (TID 113) in 133 ms on localhost (executor driver) (4/22)
2021-12-03 19:12:51,190 [Executor task launch worker for task 123] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 19:12:51,190 [Executor task launch worker for task 123] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 19:12:51,191 [dispatcher-event-loop-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 15.0 in stage 10.0 (TID 125, localhost, executor driver, partition 15, ANY, 7759 bytes)
2021-12-03 19:12:51,191 [Executor task launch worker for task 125] INFO [org.apache.spark.executor.Executor] - Running task 15.0 in stage 10.0 (TID 125)
2021-12-03 19:12:51,193 [Executor task launch worker for task 124] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 19:12:51,193 [Executor task launch worker for task 124] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 1 ms
2021-12-03 19:12:51,193 [Executor task launch worker for task 111] INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 10.0 (TID 111). 1053 bytes result sent to driver
2021-12-03 19:12:51,194 [dispatcher-event-loop-7] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 16.0 in stage 10.0 (TID 126, localhost, executor driver, partition 16, ANY, 7759 bytes)
2021-12-03 19:12:51,194 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 10.0 (TID 111) in 138 ms on localhost (executor driver) (5/22)
2021-12-03 19:12:51,194 [Executor task launch worker for task 126] INFO [org.apache.spark.executor.Executor] - Running task 16.0 in stage 10.0 (TID 126)
2021-12-03 19:12:51,195 [Executor task launch worker for task 125] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 19:12:51,195 [Executor task launch worker for task 125] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 19:12:51,230 [Executor task launch worker for task 126] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 19:12:51,230 [Executor task launch worker for task 126] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 19:12:51,232 [Executor task launch worker for task 119] INFO [org.apache.spark.executor.Executor] - Finished task 9.0 in stage 10.0 (TID 119). 1096 bytes result sent to driver
2021-12-03 19:12:51,232 [dispatcher-event-loop-8] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 17.0 in stage 10.0 (TID 127, localhost, executor driver, partition 17, ANY, 7759 bytes)
2021-12-03 19:12:51,233 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 9.0 in stage 10.0 (TID 119) in 176 ms on localhost (executor driver) (6/22)
2021-12-03 19:12:51,236 [Executor task launch worker for task 127] INFO [org.apache.spark.executor.Executor] - Running task 17.0 in stage 10.0 (TID 127)
2021-12-03 19:12:51,238 [dispatcher-event-loop-11] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_6_piece0 on qb:50913 in memory (size: 2.0 KB, free: 1990.8 MB)
2021-12-03 19:12:51,240 [Executor task launch worker for task 127] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 19:12:51,240 [Executor task launch worker for task 127] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 1 ms
2021-12-03 19:12:51,246 [Executor task launch worker for task 121] INFO [org.apache.spark.executor.Executor] - Finished task 11.0 in stage 10.0 (TID 121). 1096 bytes result sent to driver
2021-12-03 19:12:51,252 [Executor task launch worker for task 116] INFO [org.apache.spark.executor.Executor] - Finished task 6.0 in stage 10.0 (TID 116). 1139 bytes result sent to driver
2021-12-03 19:12:51,252 [Executor task launch worker for task 118] INFO [org.apache.spark.executor.Executor] - Finished task 8.0 in stage 10.0 (TID 118). 1096 bytes result sent to driver
2021-12-03 19:12:51,254 [dispatcher-event-loop-5] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 18.0 in stage 10.0 (TID 128, localhost, executor driver, partition 18, ANY, 7759 bytes)
2021-12-03 19:12:51,254 [dispatcher-event-loop-5] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 19.0 in stage 10.0 (TID 129, localhost, executor driver, partition 19, ANY, 7759 bytes)
2021-12-03 19:12:51,256 [dispatcher-event-loop-5] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 20.0 in stage 10.0 (TID 130, localhost, executor driver, partition 20, ANY, 7759 bytes)
2021-12-03 19:12:51,258 [Executor task launch worker for task 112] INFO [org.apache.spark.executor.Executor] - Finished task 2.0 in stage 10.0 (TID 112). 1096 bytes result sent to driver
2021-12-03 19:12:51,259 [Executor task launch worker for task 117] INFO [org.apache.spark.executor.Executor] - Finished task 7.0 in stage 10.0 (TID 117). 1096 bytes result sent to driver
2021-12-03 19:12:51,259 [dispatcher-event-loop-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 21.0 in stage 10.0 (TID 131, localhost, executor driver, partition 21, ANY, 7759 bytes)
2021-12-03 19:12:51,259 [Executor task launch worker for task 128] INFO [org.apache.spark.executor.Executor] - Running task 18.0 in stage 10.0 (TID 128)
2021-12-03 19:12:51,259 [Executor task launch worker for task 129] INFO [org.apache.spark.executor.Executor] - Running task 19.0 in stage 10.0 (TID 129)
2021-12-03 19:12:51,260 [Executor task launch worker for task 130] INFO [org.apache.spark.executor.Executor] - Running task 20.0 in stage 10.0 (TID 130)
2021-12-03 19:12:51,265 [Executor task launch worker for task 130] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 19:12:51,265 [Executor task launch worker for task 130] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 19:12:51,266 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 11.0 in stage 10.0 (TID 121) in 209 ms on localhost (executor driver) (7/22)
2021-12-03 19:12:51,267 [Executor task launch worker for task 131] INFO [org.apache.spark.executor.Executor] - Running task 21.0 in stage 10.0 (TID 131)
2021-12-03 19:12:51,269 [Executor task launch worker for task 129] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 19:12:51,269 [Executor task launch worker for task 129] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 19:12:51,272 [Executor task launch worker for task 131] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 19:12:51,272 [Executor task launch worker for task 131] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 19:12:51,272 [Executor task launch worker for task 128] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 19:12:51,272 [Executor task launch worker for task 128] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 19:12:51,267 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 8.0 in stage 10.0 (TID 118) in 210 ms on localhost (executor driver) (8/22)
2021-12-03 19:12:51,275 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 6.0 in stage 10.0 (TID 116) in 218 ms on localhost (executor driver) (9/22)
2021-12-03 19:12:51,276 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 7.0 in stage 10.0 (TID 117) in 219 ms on localhost (executor driver) (10/22)
2021-12-03 19:12:51,276 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 2.0 in stage 10.0 (TID 112) in 220 ms on localhost (executor driver) (11/22)
2021-12-03 19:12:51,304 [Executor task launch worker for task 110] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 10.0 (TID 110). 1096 bytes result sent to driver
2021-12-03 19:12:51,304 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 10.0 (TID 110) in 248 ms on localhost (executor driver) (12/22)
2021-12-03 19:12:51,310 [Executor task launch worker for task 124] INFO [org.apache.spark.executor.Executor] - Finished task 14.0 in stage 10.0 (TID 124). 1139 bytes result sent to driver
2021-12-03 19:12:51,311 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 14.0 in stage 10.0 (TID 124) in 122 ms on localhost (executor driver) (13/22)
2021-12-03 19:12:51,312 [Executor task launch worker for task 123] INFO [org.apache.spark.executor.Executor] - Finished task 13.0 in stage 10.0 (TID 123). 1139 bytes result sent to driver
2021-12-03 19:12:51,314 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 13.0 in stage 10.0 (TID 123) in 128 ms on localhost (executor driver) (14/22)
2021-12-03 19:12:51,317 [Executor task launch worker for task 126] INFO [org.apache.spark.executor.Executor] - Finished task 16.0 in stage 10.0 (TID 126). 1096 bytes result sent to driver
2021-12-03 19:12:51,318 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 16.0 in stage 10.0 (TID 126) in 124 ms on localhost (executor driver) (15/22)
2021-12-03 19:12:51,318 [Executor task launch worker for task 122] INFO [org.apache.spark.executor.Executor] - Finished task 12.0 in stage 10.0 (TID 122). 1096 bytes result sent to driver
2021-12-03 19:12:51,320 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 12.0 in stage 10.0 (TID 122) in 143 ms on localhost (executor driver) (16/22)
2021-12-03 19:12:51,331 [Executor task launch worker for task 125] INFO [org.apache.spark.executor.Executor] - Finished task 15.0 in stage 10.0 (TID 125). 1096 bytes result sent to driver
2021-12-03 19:12:51,332 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 15.0 in stage 10.0 (TID 125) in 141 ms on localhost (executor driver) (17/22)
2021-12-03 19:12:51,353 [Executor task launch worker for task 130] INFO [org.apache.spark.executor.Executor] - Finished task 20.0 in stage 10.0 (TID 130). 1053 bytes result sent to driver
2021-12-03 19:12:51,353 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 20.0 in stage 10.0 (TID 130) in 97 ms on localhost (executor driver) (18/22)
2021-12-03 19:12:51,359 [Executor task launch worker for task 131] INFO [org.apache.spark.executor.Executor] - Finished task 21.0 in stage 10.0 (TID 131). 1096 bytes result sent to driver
2021-12-03 19:12:51,359 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 21.0 in stage 10.0 (TID 131) in 100 ms on localhost (executor driver) (19/22)
2021-12-03 19:12:51,362 [Executor task launch worker for task 128] INFO [org.apache.spark.executor.Executor] - Finished task 18.0 in stage 10.0 (TID 128). 1053 bytes result sent to driver
2021-12-03 19:12:51,362 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 18.0 in stage 10.0 (TID 128) in 108 ms on localhost (executor driver) (20/22)
2021-12-03 19:12:51,366 [Executor task launch worker for task 129] INFO [org.apache.spark.executor.Executor] - Finished task 19.0 in stage 10.0 (TID 129). 1053 bytes result sent to driver
2021-12-03 19:12:51,366 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 19.0 in stage 10.0 (TID 129) in 112 ms on localhost (executor driver) (21/22)
2021-12-03 19:12:51,367 [Executor task launch worker for task 127] INFO [org.apache.spark.executor.Executor] - Finished task 17.0 in stage 10.0 (TID 127). 1096 bytes result sent to driver
2021-12-03 19:12:51,367 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 17.0 in stage 10.0 (TID 127) in 135 ms on localhost (executor driver) (22/22)
2021-12-03 19:12:51,367 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 10.0, whose tasks have all completed, from pool 
2021-12-03 19:12:51,368 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 10 (takeSample at PaidPromotionAdjustParameter.scala:78) finished in 0.316 s
2021-12-03 19:12:51,368 [main] INFO [org.apache.spark.scheduler.DAGScheduler] - Job 4 finished: takeSample at PaidPromotionAdjustParameter.scala:78, took 0.318964 s
2021-12-03 19:12:51,374 [main] INFO [org.apache.spark.SparkContext] - Starting job: takeSample at PaidPromotionAdjustParameter.scala:78
2021-12-03 19:12:51,374 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 5 (takeSample at PaidPromotionAdjustParameter.scala:78) with 22 output partitions
2021-12-03 19:12:51,374 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 13 (takeSample at PaidPromotionAdjustParameter.scala:78)
2021-12-03 19:12:51,374 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 12)
2021-12-03 19:12:51,374 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2021-12-03 19:12:51,375 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 13 (MapPartitionsRDD[11] at map at PaidPromotionAdjustParameter.scala:77), which has no missing parents
2021-12-03 19:12:51,377 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_8 stored as values in memory (estimated size 4.3 KB, free 1990.4 MB)
2021-12-03 19:12:51,378 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_8_piece0 stored as bytes in memory (estimated size 2.5 KB, free 1990.4 MB)
2021-12-03 19:12:51,379 [dispatcher-event-loop-6] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_8_piece0 in memory on qb:50913 (size: 2.5 KB, free: 1990.8 MB)
2021-12-03 19:12:51,379 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 8 from broadcast at DAGScheduler.scala:1039
2021-12-03 19:12:51,379 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 22 missing tasks from ResultStage 13 (MapPartitionsRDD[11] at map at PaidPromotionAdjustParameter.scala:77) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14))
2021-12-03 19:12:51,379 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 13.0 with 22 tasks
2021-12-03 19:12:51,380 [dispatcher-event-loop-11] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 13.0 (TID 132, localhost, executor driver, partition 0, ANY, 7759 bytes)
2021-12-03 19:12:51,380 [dispatcher-event-loop-11] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 13.0 (TID 133, localhost, executor driver, partition 1, ANY, 7759 bytes)
2021-12-03 19:12:51,380 [dispatcher-event-loop-11] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 2.0 in stage 13.0 (TID 134, localhost, executor driver, partition 2, ANY, 7759 bytes)
2021-12-03 19:12:51,380 [dispatcher-event-loop-11] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 3.0 in stage 13.0 (TID 135, localhost, executor driver, partition 3, ANY, 7759 bytes)
2021-12-03 19:12:51,380 [dispatcher-event-loop-11] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 4.0 in stage 13.0 (TID 136, localhost, executor driver, partition 4, ANY, 7759 bytes)
2021-12-03 19:12:51,380 [dispatcher-event-loop-11] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 5.0 in stage 13.0 (TID 137, localhost, executor driver, partition 5, ANY, 7759 bytes)
2021-12-03 19:12:51,380 [dispatcher-event-loop-11] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 6.0 in stage 13.0 (TID 138, localhost, executor driver, partition 6, ANY, 7759 bytes)
2021-12-03 19:12:51,380 [dispatcher-event-loop-11] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 7.0 in stage 13.0 (TID 139, localhost, executor driver, partition 7, ANY, 7759 bytes)
2021-12-03 19:12:51,380 [dispatcher-event-loop-11] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 8.0 in stage 13.0 (TID 140, localhost, executor driver, partition 8, ANY, 7759 bytes)
2021-12-03 19:12:51,380 [dispatcher-event-loop-11] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 9.0 in stage 13.0 (TID 141, localhost, executor driver, partition 9, ANY, 7759 bytes)
2021-12-03 19:12:51,380 [dispatcher-event-loop-11] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 10.0 in stage 13.0 (TID 142, localhost, executor driver, partition 10, ANY, 7759 bytes)
2021-12-03 19:12:51,380 [dispatcher-event-loop-11] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 11.0 in stage 13.0 (TID 143, localhost, executor driver, partition 11, ANY, 7759 bytes)
2021-12-03 19:12:51,380 [Executor task launch worker for task 137] INFO [org.apache.spark.executor.Executor] - Running task 5.0 in stage 13.0 (TID 137)
2021-12-03 19:12:51,380 [Executor task launch worker for task 132] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 13.0 (TID 132)
2021-12-03 19:12:51,380 [Executor task launch worker for task 141] INFO [org.apache.spark.executor.Executor] - Running task 9.0 in stage 13.0 (TID 141)
2021-12-03 19:12:51,380 [Executor task launch worker for task 133] INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 13.0 (TID 133)
2021-12-03 19:12:51,380 [Executor task launch worker for task 140] INFO [org.apache.spark.executor.Executor] - Running task 8.0 in stage 13.0 (TID 140)
2021-12-03 19:12:51,380 [Executor task launch worker for task 139] INFO [org.apache.spark.executor.Executor] - Running task 7.0 in stage 13.0 (TID 139)
2021-12-03 19:12:51,380 [Executor task launch worker for task 135] INFO [org.apache.spark.executor.Executor] - Running task 3.0 in stage 13.0 (TID 135)
2021-12-03 19:12:51,380 [Executor task launch worker for task 138] INFO [org.apache.spark.executor.Executor] - Running task 6.0 in stage 13.0 (TID 138)
2021-12-03 19:12:51,380 [Executor task launch worker for task 134] INFO [org.apache.spark.executor.Executor] - Running task 2.0 in stage 13.0 (TID 134)
2021-12-03 19:12:51,380 [Executor task launch worker for task 136] INFO [org.apache.spark.executor.Executor] - Running task 4.0 in stage 13.0 (TID 136)
2021-12-03 19:12:51,380 [Executor task launch worker for task 143] INFO [org.apache.spark.executor.Executor] - Running task 11.0 in stage 13.0 (TID 143)
2021-12-03 19:12:51,380 [Executor task launch worker for task 142] INFO [org.apache.spark.executor.Executor] - Running task 10.0 in stage 13.0 (TID 142)
2021-12-03 19:12:51,383 [Executor task launch worker for task 134] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 19:12:51,383 [Executor task launch worker for task 134] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 19:12:51,383 [Executor task launch worker for task 143] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 19:12:51,383 [Executor task launch worker for task 143] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 19:12:51,384 [Executor task launch worker for task 140] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 19:12:51,384 [Executor task launch worker for task 140] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 19:12:51,384 [Executor task launch worker for task 138] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 19:12:51,384 [Executor task launch worker for task 138] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 19:12:51,384 [Executor task launch worker for task 136] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 19:12:51,384 [Executor task launch worker for task 136] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 19:12:51,384 [Executor task launch worker for task 142] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 19:12:51,384 [Executor task launch worker for task 142] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 19:12:51,385 [Executor task launch worker for task 133] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 19:12:51,385 [Executor task launch worker for task 133] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 19:12:51,385 [Executor task launch worker for task 137] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 19:12:51,385 [Executor task launch worker for task 137] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 19:12:51,385 [Executor task launch worker for task 135] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 19:12:51,385 [Executor task launch worker for task 135] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 19:12:51,386 [Executor task launch worker for task 139] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 19:12:51,386 [Executor task launch worker for task 139] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 19:12:51,386 [Executor task launch worker for task 141] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 19:12:51,386 [Executor task launch worker for task 141] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 19:12:51,386 [Executor task launch worker for task 132] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 19:12:51,386 [Executor task launch worker for task 132] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 19:12:51,469 [Executor task launch worker for task 143] INFO [org.apache.spark.executor.Executor] - Finished task 11.0 in stage 13.0 (TID 143). 1054 bytes result sent to driver
2021-12-03 19:12:51,470 [dispatcher-event-loop-10] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 12.0 in stage 13.0 (TID 144, localhost, executor driver, partition 12, ANY, 7759 bytes)
2021-12-03 19:12:51,470 [Executor task launch worker for task 144] INFO [org.apache.spark.executor.Executor] - Running task 12.0 in stage 13.0 (TID 144)
2021-12-03 19:12:51,473 [Executor task launch worker for task 144] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 19:12:51,474 [Executor task launch worker for task 144] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 1 ms
2021-12-03 19:12:51,476 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 11.0 in stage 13.0 (TID 143) in 96 ms on localhost (executor driver) (1/22)
2021-12-03 19:12:51,485 [Executor task launch worker for task 141] INFO [org.apache.spark.executor.Executor] - Finished task 9.0 in stage 13.0 (TID 141). 1054 bytes result sent to driver
2021-12-03 19:12:51,485 [dispatcher-event-loop-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 13.0 in stage 13.0 (TID 145, localhost, executor driver, partition 13, ANY, 7759 bytes)
2021-12-03 19:12:51,485 [Executor task launch worker for task 137] INFO [org.apache.spark.executor.Executor] - Finished task 5.0 in stage 13.0 (TID 137). 1054 bytes result sent to driver
2021-12-03 19:12:51,485 [Executor task launch worker for task 145] INFO [org.apache.spark.executor.Executor] - Running task 13.0 in stage 13.0 (TID 145)
2021-12-03 19:12:51,485 [Executor task launch worker for task 136] INFO [org.apache.spark.executor.Executor] - Finished task 4.0 in stage 13.0 (TID 136). 1054 bytes result sent to driver
2021-12-03 19:12:51,486 [dispatcher-event-loop-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 14.0 in stage 13.0 (TID 146, localhost, executor driver, partition 14, ANY, 7759 bytes)
2021-12-03 19:12:51,486 [dispatcher-event-loop-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 15.0 in stage 13.0 (TID 147, localhost, executor driver, partition 15, ANY, 7759 bytes)
2021-12-03 19:12:51,486 [Executor task launch worker for task 146] INFO [org.apache.spark.executor.Executor] - Running task 14.0 in stage 13.0 (TID 146)
2021-12-03 19:12:51,486 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 4.0 in stage 13.0 (TID 136) in 106 ms on localhost (executor driver) (2/22)
2021-12-03 19:12:51,486 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 5.0 in stage 13.0 (TID 137) in 106 ms on localhost (executor driver) (3/22)
2021-12-03 19:12:51,486 [Executor task launch worker for task 147] INFO [org.apache.spark.executor.Executor] - Running task 15.0 in stage 13.0 (TID 147)
2021-12-03 19:12:51,487 [Executor task launch worker for task 138] INFO [org.apache.spark.executor.Executor] - Finished task 6.0 in stage 13.0 (TID 138). 1054 bytes result sent to driver
2021-12-03 19:12:51,487 [Executor task launch worker for task 140] INFO [org.apache.spark.executor.Executor] - Finished task 8.0 in stage 13.0 (TID 140). 1054 bytes result sent to driver
2021-12-03 19:12:51,488 [dispatcher-event-loop-8] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 16.0 in stage 13.0 (TID 148, localhost, executor driver, partition 16, ANY, 7759 bytes)
2021-12-03 19:12:51,488 [Executor task launch worker for task 148] INFO [org.apache.spark.executor.Executor] - Running task 16.0 in stage 13.0 (TID 148)
2021-12-03 19:12:51,488 [dispatcher-event-loop-8] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 17.0 in stage 13.0 (TID 149, localhost, executor driver, partition 17, ANY, 7759 bytes)
2021-12-03 19:12:51,488 [Executor task launch worker for task 149] INFO [org.apache.spark.executor.Executor] - Running task 17.0 in stage 13.0 (TID 149)
2021-12-03 19:12:51,488 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 6.0 in stage 13.0 (TID 138) in 108 ms on localhost (executor driver) (4/22)
2021-12-03 19:12:51,488 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 9.0 in stage 13.0 (TID 141) in 108 ms on localhost (executor driver) (5/22)
2021-12-03 19:12:51,489 [Executor task launch worker for task 145] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 19:12:51,489 [Executor task launch worker for task 145] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 19:12:51,489 [Executor task launch worker for task 147] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 19:12:51,490 [Executor task launch worker for task 147] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 1 ms
2021-12-03 19:12:51,490 [Executor task launch worker for task 146] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 19:12:51,490 [Executor task launch worker for task 146] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 1 ms
2021-12-03 19:12:51,490 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 8.0 in stage 13.0 (TID 140) in 110 ms on localhost (executor driver) (6/22)
2021-12-03 19:12:51,490 [Executor task launch worker for task 148] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 19:12:51,490 [Executor task launch worker for task 148] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 19:12:51,491 [Executor task launch worker for task 149] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 19:12:51,491 [Executor task launch worker for task 149] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 1 ms
2021-12-03 19:12:51,504 [Executor task launch worker for task 139] INFO [org.apache.spark.executor.Executor] - Finished task 7.0 in stage 13.0 (TID 139). 1054 bytes result sent to driver
2021-12-03 19:12:51,508 [Executor task launch worker for task 135] INFO [org.apache.spark.executor.Executor] - Finished task 3.0 in stage 13.0 (TID 135). 1054 bytes result sent to driver
2021-12-03 19:12:51,515 [Executor task launch worker for task 142] INFO [org.apache.spark.executor.Executor] - Finished task 10.0 in stage 13.0 (TID 142). 1054 bytes result sent to driver
2021-12-03 19:12:51,515 [dispatcher-event-loop-10] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 18.0 in stage 13.0 (TID 150, localhost, executor driver, partition 18, ANY, 7759 bytes)
2021-12-03 19:12:51,515 [Executor task launch worker for task 150] INFO [org.apache.spark.executor.Executor] - Running task 18.0 in stage 13.0 (TID 150)
2021-12-03 19:12:51,515 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 7.0 in stage 13.0 (TID 139) in 135 ms on localhost (executor driver) (7/22)
2021-12-03 19:12:51,516 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 3.0 in stage 13.0 (TID 135) in 136 ms on localhost (executor driver) (8/22)
2021-12-03 19:12:51,516 [dispatcher-event-loop-10] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 19.0 in stage 13.0 (TID 151, localhost, executor driver, partition 19, ANY, 7759 bytes)
2021-12-03 19:12:51,516 [dispatcher-event-loop-10] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 20.0 in stage 13.0 (TID 152, localhost, executor driver, partition 20, ANY, 7759 bytes)
2021-12-03 19:12:51,516 [Executor task launch worker for task 152] INFO [org.apache.spark.executor.Executor] - Running task 20.0 in stage 13.0 (TID 152)
2021-12-03 19:12:51,518 [Executor task launch worker for task 151] INFO [org.apache.spark.executor.Executor] - Running task 19.0 in stage 13.0 (TID 151)
2021-12-03 19:12:51,542 [Executor task launch worker for task 152] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 19:12:51,542 [Executor task launch worker for task 152] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 19:12:51,542 [Executor task launch worker for task 150] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 19:12:51,564 [Executor task launch worker for task 150] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 22 ms
2021-12-03 19:12:51,565 [Executor task launch worker for task 151] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 19:12:51,565 [Executor task launch worker for task 151] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 19:12:51,562 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 10.0 in stage 13.0 (TID 142) in 182 ms on localhost (executor driver) (9/22)
2021-12-03 19:12:51,565 [Executor task launch worker for task 132] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 13.0 (TID 132). 1097 bytes result sent to driver
2021-12-03 19:12:51,565 [Executor task launch worker for task 134] INFO [org.apache.spark.executor.Executor] - Finished task 2.0 in stage 13.0 (TID 134). 1130 bytes result sent to driver
2021-12-03 19:12:51,566 [dispatcher-event-loop-9] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_7_piece0 on qb:50913 in memory (size: 2.4 KB, free: 1990.8 MB)
2021-12-03 19:12:51,567 [dispatcher-event-loop-8] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 21.0 in stage 13.0 (TID 153, localhost, executor driver, partition 21, ANY, 7759 bytes)
2021-12-03 19:12:51,567 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 13.0 (TID 132) in 188 ms on localhost (executor driver) (10/22)
2021-12-03 19:12:51,567 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 2.0 in stage 13.0 (TID 134) in 187 ms on localhost (executor driver) (11/22)
2021-12-03 19:12:51,567 [Executor task launch worker for task 153] INFO [org.apache.spark.executor.Executor] - Running task 21.0 in stage 13.0 (TID 153)
2021-12-03 19:12:51,569 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 172
2021-12-03 19:12:51,569 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 164
2021-12-03 19:12:51,569 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 170
2021-12-03 19:12:51,569 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 152
2021-12-03 19:12:51,569 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 160
2021-12-03 19:12:51,569 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 173
2021-12-03 19:12:51,569 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 150
2021-12-03 19:12:51,569 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 162
2021-12-03 19:12:51,569 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 167
2021-12-03 19:12:51,569 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 157
2021-12-03 19:12:51,569 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 154
2021-12-03 19:12:51,569 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 174
2021-12-03 19:12:51,569 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 159
2021-12-03 19:12:51,569 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 155
2021-12-03 19:12:51,569 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 158
2021-12-03 19:12:51,569 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 165
2021-12-03 19:12:51,569 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 163
2021-12-03 19:12:51,570 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 156
2021-12-03 19:12:51,570 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 153
2021-12-03 19:12:51,570 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 166
2021-12-03 19:12:51,570 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 168
2021-12-03 19:12:51,570 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 171
2021-12-03 19:12:51,570 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 161
2021-12-03 19:12:51,570 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 169
2021-12-03 19:12:51,570 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 151
2021-12-03 19:12:51,572 [Executor task launch worker for task 153] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 19:12:51,572 [Executor task launch worker for task 153] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 19:12:51,581 [Executor task launch worker for task 133] INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 13.0 (TID 133). 1097 bytes result sent to driver
2021-12-03 19:12:51,582 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 13.0 (TID 133) in 202 ms on localhost (executor driver) (12/22)
2021-12-03 19:12:51,601 [Executor task launch worker for task 148] INFO [org.apache.spark.executor.Executor] - Finished task 16.0 in stage 13.0 (TID 148). 1097 bytes result sent to driver
2021-12-03 19:12:51,602 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 16.0 in stage 13.0 (TID 148) in 115 ms on localhost (executor driver) (13/22)
2021-12-03 19:12:51,614 [Executor task launch worker for task 147] INFO [org.apache.spark.executor.Executor] - Finished task 15.0 in stage 13.0 (TID 147). 1097 bytes result sent to driver
2021-12-03 19:12:51,615 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 15.0 in stage 13.0 (TID 147) in 129 ms on localhost (executor driver) (14/22)
2021-12-03 19:12:51,617 [Executor task launch worker for task 144] INFO [org.apache.spark.executor.Executor] - Finished task 12.0 in stage 13.0 (TID 144). 1140 bytes result sent to driver
2021-12-03 19:12:51,617 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 12.0 in stage 13.0 (TID 144) in 147 ms on localhost (executor driver) (15/22)
2021-12-03 19:12:51,617 [Executor task launch worker for task 146] INFO [org.apache.spark.executor.Executor] - Finished task 14.0 in stage 13.0 (TID 146). 1140 bytes result sent to driver
2021-12-03 19:12:51,618 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 14.0 in stage 13.0 (TID 146) in 132 ms on localhost (executor driver) (16/22)
2021-12-03 19:12:51,626 [Executor task launch worker for task 145] INFO [org.apache.spark.executor.Executor] - Finished task 13.0 in stage 13.0 (TID 145). 1140 bytes result sent to driver
2021-12-03 19:12:51,626 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 13.0 in stage 13.0 (TID 145) in 141 ms on localhost (executor driver) (17/22)
2021-12-03 19:12:51,638 [Executor task launch worker for task 152] INFO [org.apache.spark.executor.Executor] - Finished task 20.0 in stage 13.0 (TID 152). 1097 bytes result sent to driver
2021-12-03 19:12:51,638 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 20.0 in stage 13.0 (TID 152) in 122 ms on localhost (executor driver) (18/22)
2021-12-03 19:12:51,645 [Executor task launch worker for task 149] INFO [org.apache.spark.executor.Executor] - Finished task 17.0 in stage 13.0 (TID 149). 1097 bytes result sent to driver
2021-12-03 19:12:51,646 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 17.0 in stage 13.0 (TID 149) in 158 ms on localhost (executor driver) (19/22)
2021-12-03 19:12:51,647 [Executor task launch worker for task 151] INFO [org.apache.spark.executor.Executor] - Finished task 19.0 in stage 13.0 (TID 151). 1140 bytes result sent to driver
2021-12-03 19:12:51,647 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 19.0 in stage 13.0 (TID 151) in 131 ms on localhost (executor driver) (20/22)
2021-12-03 19:12:51,648 [Executor task launch worker for task 150] INFO [org.apache.spark.executor.Executor] - Finished task 18.0 in stage 13.0 (TID 150). 1097 bytes result sent to driver
2021-12-03 19:12:51,648 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 18.0 in stage 13.0 (TID 150) in 133 ms on localhost (executor driver) (21/22)
2021-12-03 19:12:51,662 [Executor task launch worker for task 153] INFO [org.apache.spark.executor.Executor] - Finished task 21.0 in stage 13.0 (TID 153). 1054 bytes result sent to driver
2021-12-03 19:12:51,662 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 21.0 in stage 13.0 (TID 153) in 96 ms on localhost (executor driver) (22/22)
2021-12-03 19:12:51,662 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 13.0, whose tasks have all completed, from pool 
2021-12-03 19:12:51,662 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 13 (takeSample at PaidPromotionAdjustParameter.scala:78) finished in 0.286 s
2021-12-03 19:12:51,662 [main] INFO [org.apache.spark.scheduler.DAGScheduler] - Job 5 finished: takeSample at PaidPromotionAdjustParameter.scala:78, took 0.288594 s
2021-12-03 19:12:51,681 [main] INFO [org.apache.hadoop.conf.Configuration.deprecation] - mapred.output.dir is deprecated. Instead, use mapreduce.output.fileoutputformat.outputdir
2021-12-03 19:12:51,683 [main] INFO [org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter] - File Output Committer Algorithm version is 1
2021-12-03 19:12:51,742 [main] INFO [org.apache.spark.SparkContext] - Starting job: runJob at SparkHadoopWriter.scala:78
2021-12-03 19:12:51,742 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 6 (runJob at SparkHadoopWriter.scala:78) with 22 output partitions
2021-12-03 19:12:51,742 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 14 (runJob at SparkHadoopWriter.scala:78)
2021-12-03 19:12:51,742 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List()
2021-12-03 19:12:51,742 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2021-12-03 19:12:51,743 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 14 (MapPartitionsRDD[14] at saveAsTextFile at PaidPromotionAdjustParameter.scala:82), which has no missing parents
2021-12-03 19:12:51,754 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_9 stored as values in memory (estimated size 79.9 KB, free 1990.4 MB)
2021-12-03 19:12:51,755 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_9_piece0 stored as bytes in memory (estimated size 30.5 KB, free 1990.3 MB)
2021-12-03 19:12:51,755 [dispatcher-event-loop-6] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_9_piece0 in memory on qb:50913 (size: 30.5 KB, free: 1990.7 MB)
2021-12-03 19:12:51,756 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 9 from broadcast at DAGScheduler.scala:1039
2021-12-03 19:12:51,756 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 22 missing tasks from ResultStage 14 (MapPartitionsRDD[14] at saveAsTextFile at PaidPromotionAdjustParameter.scala:82) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14))
2021-12-03 19:12:51,756 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 14.0 with 22 tasks
2021-12-03 19:12:51,756 [dispatcher-event-loop-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 14.0 (TID 154, localhost, executor driver, partition 0, ANY, 7899 bytes)
2021-12-03 19:12:51,757 [dispatcher-event-loop-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 14.0 (TID 155, localhost, executor driver, partition 1, ANY, 7899 bytes)
2021-12-03 19:12:51,757 [dispatcher-event-loop-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 2.0 in stage 14.0 (TID 156, localhost, executor driver, partition 2, ANY, 7899 bytes)
2021-12-03 19:12:51,757 [dispatcher-event-loop-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 3.0 in stage 14.0 (TID 157, localhost, executor driver, partition 3, ANY, 7899 bytes)
2021-12-03 19:12:51,757 [dispatcher-event-loop-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 4.0 in stage 14.0 (TID 158, localhost, executor driver, partition 4, ANY, 7899 bytes)
2021-12-03 19:12:51,757 [dispatcher-event-loop-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 5.0 in stage 14.0 (TID 159, localhost, executor driver, partition 5, ANY, 7899 bytes)
2021-12-03 19:12:51,757 [dispatcher-event-loop-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 6.0 in stage 14.0 (TID 160, localhost, executor driver, partition 6, ANY, 7899 bytes)
2021-12-03 19:12:51,757 [dispatcher-event-loop-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 7.0 in stage 14.0 (TID 161, localhost, executor driver, partition 7, ANY, 7899 bytes)
2021-12-03 19:12:51,757 [dispatcher-event-loop-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 8.0 in stage 14.0 (TID 162, localhost, executor driver, partition 8, ANY, 7899 bytes)
2021-12-03 19:12:51,757 [dispatcher-event-loop-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 9.0 in stage 14.0 (TID 163, localhost, executor driver, partition 9, ANY, 7899 bytes)
2021-12-03 19:12:51,757 [dispatcher-event-loop-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 10.0 in stage 14.0 (TID 164, localhost, executor driver, partition 10, ANY, 7899 bytes)
2021-12-03 19:12:51,757 [dispatcher-event-loop-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 11.0 in stage 14.0 (TID 165, localhost, executor driver, partition 11, ANY, 7899 bytes)
2021-12-03 19:12:51,757 [Executor task launch worker for task 154] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 14.0 (TID 154)
2021-12-03 19:12:51,758 [Executor task launch worker for task 159] INFO [org.apache.spark.executor.Executor] - Running task 5.0 in stage 14.0 (TID 159)
2021-12-03 19:12:51,758 [Executor task launch worker for task 165] INFO [org.apache.spark.executor.Executor] - Running task 11.0 in stage 14.0 (TID 165)
2021-12-03 19:12:51,758 [Executor task launch worker for task 162] INFO [org.apache.spark.executor.Executor] - Running task 8.0 in stage 14.0 (TID 162)
2021-12-03 19:12:51,758 [Executor task launch worker for task 163] INFO [org.apache.spark.executor.Executor] - Running task 9.0 in stage 14.0 (TID 163)
2021-12-03 19:12:51,758 [Executor task launch worker for task 164] INFO [org.apache.spark.executor.Executor] - Running task 10.0 in stage 14.0 (TID 164)
2021-12-03 19:12:51,758 [Executor task launch worker for task 161] INFO [org.apache.spark.executor.Executor] - Running task 7.0 in stage 14.0 (TID 161)
2021-12-03 19:12:51,758 [Executor task launch worker for task 156] INFO [org.apache.spark.executor.Executor] - Running task 2.0 in stage 14.0 (TID 156)
2021-12-03 19:12:51,758 [Executor task launch worker for task 160] INFO [org.apache.spark.executor.Executor] - Running task 6.0 in stage 14.0 (TID 160)
2021-12-03 19:12:51,758 [Executor task launch worker for task 157] INFO [org.apache.spark.executor.Executor] - Running task 3.0 in stage 14.0 (TID 157)
2021-12-03 19:12:51,758 [Executor task launch worker for task 158] INFO [org.apache.spark.executor.Executor] - Running task 4.0 in stage 14.0 (TID 158)
2021-12-03 19:12:51,757 [Executor task launch worker for task 155] INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 14.0 (TID 155)
2021-12-03 19:12:51,780 [Executor task launch worker for task 160] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:805306368+134217728
2021-12-03 19:12:51,780 [Executor task launch worker for task 157] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:402653184+134217728
2021-12-03 19:12:51,780 [Executor task launch worker for task 161] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:939524096+134217728
2021-12-03 19:12:51,781 [Executor task launch worker for task 162] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:1073741824+134217728
2021-12-03 19:12:51,782 [Executor task launch worker for task 159] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:671088640+134217728
2021-12-03 19:12:51,782 [Executor task launch worker for task 158] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:536870912+134217728
2021-12-03 19:12:51,782 [Executor task launch worker for task 156] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:268435456+134217728
2021-12-03 19:12:51,783 [Executor task launch worker for task 164] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:1342177280+134217728
2021-12-03 19:12:51,783 [Executor task launch worker for task 155] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:134217728+134217728
2021-12-03 19:12:51,784 [Executor task launch worker for task 163] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:1207959552+134217728
2021-12-03 19:12:51,784 [Executor task launch worker for task 165] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:1476395008+134217728
2021-12-03 19:12:51,784 [Executor task launch worker for task 154] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:0+134217728
2021-12-03 19:12:51,801 [Executor task launch worker for task 154] INFO [org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter] - File Output Committer Algorithm version is 1
2021-12-03 19:12:51,845 [Executor task launch worker for task 158] INFO [org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter] - File Output Committer Algorithm version is 1
2021-12-03 19:12:51,869 [Executor task launch worker for task 162] INFO [org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter] - File Output Committer Algorithm version is 1
2021-12-03 19:12:51,874 [Executor task launch worker for task 155] INFO [org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter] - File Output Committer Algorithm version is 1
2021-12-03 19:12:51,881 [Executor task launch worker for task 157] INFO [org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter] - File Output Committer Algorithm version is 1
2021-12-03 19:12:51,927 [Executor task launch worker for task 165] INFO [org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter] - File Output Committer Algorithm version is 1
2021-12-03 19:12:51,954 [Executor task launch worker for task 159] INFO [org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter] - File Output Committer Algorithm version is 1
2021-12-03 19:12:52,147 [Executor task launch worker for task 160] INFO [org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter] - File Output Committer Algorithm version is 1
2021-12-03 19:12:52,217 [Executor task launch worker for task 163] INFO [org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter] - File Output Committer Algorithm version is 1
2021-12-03 19:12:52,219 [Executor task launch worker for task 156] INFO [org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter] - File Output Committer Algorithm version is 1
2021-12-03 19:12:52,232 [Executor task launch worker for task 164] INFO [org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter] - File Output Committer Algorithm version is 1
2021-12-03 19:12:52,285 [Executor task launch worker for task 161] INFO [org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter] - File Output Committer Algorithm version is 1
2021-12-03 19:12:54,253 [dispatcher-event-loop-4] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_8_piece0 on qb:50913 in memory (size: 2.5 KB, free: 1990.7 MB)
2021-12-03 19:14:43,236 [Executor task launch worker for task 158] INFO [org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter] - Saved output of task 'attempt_20211203191251_0014_m_000004_0' to hdfs://hdp1:8020/sk/chongqing/sample_data/filter-sample-device-video-data.bcp/_temporary/0/task_20211203191251_0014_m_000004
2021-12-03 19:14:43,236 [Executor task launch worker for task 158] INFO [org.apache.spark.mapred.SparkHadoopMapRedUtil] - attempt_20211203191251_0014_m_000004_0: Committed
2021-12-03 19:14:43,239 [Executor task launch worker for task 158] INFO [org.apache.spark.executor.Executor] - Finished task 4.0 in stage 14.0 (TID 158). 912 bytes result sent to driver
2021-12-03 19:14:43,239 [dispatcher-event-loop-7] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 12.0 in stage 14.0 (TID 166, localhost, executor driver, partition 12, ANY, 7899 bytes)
2021-12-03 19:14:43,239 [Executor task launch worker for task 166] INFO [org.apache.spark.executor.Executor] - Running task 12.0 in stage 14.0 (TID 166)
2021-12-03 19:14:43,241 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 4.0 in stage 14.0 (TID 158) in 111484 ms on localhost (executor driver) (1/22)
2021-12-03 19:14:43,244 [Executor task launch worker for task 166] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:1610612736+134217728
2021-12-03 19:14:43,841 [Executor task launch worker for task 166] INFO [org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter] - File Output Committer Algorithm version is 1
2021-12-03 19:14:56,122 [Executor task launch worker for task 159] INFO [org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter] - Saved output of task 'attempt_20211203191251_0014_m_000005_0' to hdfs://hdp1:8020/sk/chongqing/sample_data/filter-sample-device-video-data.bcp/_temporary/0/task_20211203191251_0014_m_000005
2021-12-03 19:14:56,122 [Executor task launch worker for task 159] INFO [org.apache.spark.mapred.SparkHadoopMapRedUtil] - attempt_20211203191251_0014_m_000005_0: Committed
2021-12-03 19:14:56,124 [Executor task launch worker for task 159] INFO [org.apache.spark.executor.Executor] - Finished task 5.0 in stage 14.0 (TID 159). 869 bytes result sent to driver
2021-12-03 19:14:56,124 [dispatcher-event-loop-8] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 13.0 in stage 14.0 (TID 167, localhost, executor driver, partition 13, ANY, 7899 bytes)
2021-12-03 19:14:56,124 [Executor task launch worker for task 167] INFO [org.apache.spark.executor.Executor] - Running task 13.0 in stage 14.0 (TID 167)
2021-12-03 19:14:56,125 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 5.0 in stage 14.0 (TID 159) in 124368 ms on localhost (executor driver) (2/22)
2021-12-03 19:14:56,127 [Executor task launch worker for task 167] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:1744830464+134217728
2021-12-03 19:14:56,754 [Executor task launch worker for task 167] INFO [org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter] - File Output Committer Algorithm version is 1
2021-12-03 19:14:57,488 [Executor task launch worker for task 162] INFO [org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter] - Saved output of task 'attempt_20211203191251_0014_m_000008_0' to hdfs://hdp1:8020/sk/chongqing/sample_data/filter-sample-device-video-data.bcp/_temporary/0/task_20211203191251_0014_m_000008
2021-12-03 19:14:57,488 [Executor task launch worker for task 162] INFO [org.apache.spark.mapred.SparkHadoopMapRedUtil] - attempt_20211203191251_0014_m_000008_0: Committed
2021-12-03 19:14:57,489 [Executor task launch worker for task 162] INFO [org.apache.spark.executor.Executor] - Finished task 8.0 in stage 14.0 (TID 162). 912 bytes result sent to driver
2021-12-03 19:14:57,490 [dispatcher-event-loop-4] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 14.0 in stage 14.0 (TID 168, localhost, executor driver, partition 14, ANY, 7899 bytes)
2021-12-03 19:14:57,490 [Executor task launch worker for task 168] INFO [org.apache.spark.executor.Executor] - Running task 14.0 in stage 14.0 (TID 168)
2021-12-03 19:14:57,490 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 8.0 in stage 14.0 (TID 162) in 125733 ms on localhost (executor driver) (3/22)
2021-12-03 19:14:57,493 [Executor task launch worker for task 168] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:1879048192+134217728
2021-12-03 19:14:58,123 [Executor task launch worker for task 168] INFO [org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter] - File Output Committer Algorithm version is 1
2021-12-03 19:15:01,826 [Executor task launch worker for task 157] INFO [org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter] - Saved output of task 'attempt_20211203191251_0014_m_000003_0' to hdfs://hdp1:8020/sk/chongqing/sample_data/filter-sample-device-video-data.bcp/_temporary/0/task_20211203191251_0014_m_000003
2021-12-03 19:15:01,826 [Executor task launch worker for task 157] INFO [org.apache.spark.mapred.SparkHadoopMapRedUtil] - attempt_20211203191251_0014_m_000003_0: Committed
2021-12-03 19:15:01,827 [Executor task launch worker for task 157] INFO [org.apache.spark.executor.Executor] - Finished task 3.0 in stage 14.0 (TID 157). 912 bytes result sent to driver
2021-12-03 19:15:01,827 [dispatcher-event-loop-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 15.0 in stage 14.0 (TID 169, localhost, executor driver, partition 15, ANY, 7899 bytes)
2021-12-03 19:15:01,827 [Executor task launch worker for task 169] INFO [org.apache.spark.executor.Executor] - Running task 15.0 in stage 14.0 (TID 169)
2021-12-03 19:15:01,829 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 3.0 in stage 14.0 (TID 157) in 130072 ms on localhost (executor driver) (4/22)
2021-12-03 19:15:01,832 [Executor task launch worker for task 169] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:2013265920+134217728
2021-12-03 19:15:02,512 [Executor task launch worker for task 169] INFO [org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter] - File Output Committer Algorithm version is 1
2021-12-03 19:15:05,635 [Executor task launch worker for task 165] INFO [org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter] - Saved output of task 'attempt_20211203191251_0014_m_000011_0' to hdfs://hdp1:8020/sk/chongqing/sample_data/filter-sample-device-video-data.bcp/_temporary/0/task_20211203191251_0014_m_000011
2021-12-03 19:15:05,635 [Executor task launch worker for task 165] INFO [org.apache.spark.mapred.SparkHadoopMapRedUtil] - attempt_20211203191251_0014_m_000011_0: Committed
2021-12-03 19:15:05,636 [Executor task launch worker for task 165] INFO [org.apache.spark.executor.Executor] - Finished task 11.0 in stage 14.0 (TID 165). 912 bytes result sent to driver
2021-12-03 19:15:05,636 [dispatcher-event-loop-9] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 16.0 in stage 14.0 (TID 170, localhost, executor driver, partition 16, ANY, 7899 bytes)
2021-12-03 19:15:05,636 [Executor task launch worker for task 170] INFO [org.apache.spark.executor.Executor] - Running task 16.0 in stage 14.0 (TID 170)
2021-12-03 19:15:05,636 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 11.0 in stage 14.0 (TID 165) in 133879 ms on localhost (executor driver) (5/22)
2021-12-03 19:15:05,639 [Executor task launch worker for task 170] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:2147483648+134217728
2021-12-03 19:15:06,727 [Executor task launch worker for task 170] INFO [org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter] - File Output Committer Algorithm version is 1
2021-12-03 19:15:15,276 [Executor task launch worker for task 155] INFO [org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter] - Saved output of task 'attempt_20211203191251_0014_m_000001_0' to hdfs://hdp1:8020/sk/chongqing/sample_data/filter-sample-device-video-data.bcp/_temporary/0/task_20211203191251_0014_m_000001
2021-12-03 19:15:15,276 [Executor task launch worker for task 155] INFO [org.apache.spark.mapred.SparkHadoopMapRedUtil] - attempt_20211203191251_0014_m_000001_0: Committed
2021-12-03 19:15:15,277 [Executor task launch worker for task 155] INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 14.0 (TID 155). 912 bytes result sent to driver
2021-12-03 19:15:15,277 [dispatcher-event-loop-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 17.0 in stage 14.0 (TID 171, localhost, executor driver, partition 17, ANY, 7899 bytes)
2021-12-03 19:15:15,277 [Executor task launch worker for task 171] INFO [org.apache.spark.executor.Executor] - Running task 17.0 in stage 14.0 (TID 171)
2021-12-03 19:15:15,277 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 14.0 (TID 155) in 143520 ms on localhost (executor driver) (6/22)
2021-12-03 19:15:15,280 [Executor task launch worker for task 171] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:2281701376+134217728
2021-12-03 19:15:16,007 [Executor task launch worker for task 171] INFO [org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter] - File Output Committer Algorithm version is 1
2021-12-03 19:15:22,350 [Executor task launch worker for task 164] INFO [org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter] - Saved output of task 'attempt_20211203191251_0014_m_000010_0' to hdfs://hdp1:8020/sk/chongqing/sample_data/filter-sample-device-video-data.bcp/_temporary/0/task_20211203191251_0014_m_000010
2021-12-03 19:15:22,350 [Executor task launch worker for task 164] INFO [org.apache.spark.mapred.SparkHadoopMapRedUtil] - attempt_20211203191251_0014_m_000010_0: Committed
2021-12-03 19:15:22,351 [Executor task launch worker for task 164] INFO [org.apache.spark.executor.Executor] - Finished task 10.0 in stage 14.0 (TID 164). 912 bytes result sent to driver
2021-12-03 19:15:22,351 [dispatcher-event-loop-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 18.0 in stage 14.0 (TID 172, localhost, executor driver, partition 18, ANY, 7899 bytes)
2021-12-03 19:15:22,352 [Executor task launch worker for task 172] INFO [org.apache.spark.executor.Executor] - Running task 18.0 in stage 14.0 (TID 172)
2021-12-03 19:15:22,352 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 10.0 in stage 14.0 (TID 164) in 150595 ms on localhost (executor driver) (7/22)
2021-12-03 19:15:22,355 [Executor task launch worker for task 172] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:2415919104+134217728
2021-12-03 19:15:22,965 [Executor task launch worker for task 172] INFO [org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter] - File Output Committer Algorithm version is 1
2021-12-03 19:15:30,373 [Executor task launch worker for task 161] INFO [org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter] - Saved output of task 'attempt_20211203191251_0014_m_000007_0' to hdfs://hdp1:8020/sk/chongqing/sample_data/filter-sample-device-video-data.bcp/_temporary/0/task_20211203191251_0014_m_000007
2021-12-03 19:15:30,373 [Executor task launch worker for task 161] INFO [org.apache.spark.mapred.SparkHadoopMapRedUtil] - attempt_20211203191251_0014_m_000007_0: Committed
2021-12-03 19:15:30,374 [Executor task launch worker for task 161] INFO [org.apache.spark.executor.Executor] - Finished task 7.0 in stage 14.0 (TID 161). 912 bytes result sent to driver
2021-12-03 19:15:30,374 [dispatcher-event-loop-5] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 19.0 in stage 14.0 (TID 173, localhost, executor driver, partition 19, ANY, 7899 bytes)
2021-12-03 19:15:30,374 [Executor task launch worker for task 173] INFO [org.apache.spark.executor.Executor] - Running task 19.0 in stage 14.0 (TID 173)
2021-12-03 19:15:30,374 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 7.0 in stage 14.0 (TID 161) in 158617 ms on localhost (executor driver) (8/22)
2021-12-03 19:15:30,377 [Executor task launch worker for task 173] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:2550136832+134217728
2021-12-03 19:15:30,749 [Executor task launch worker for task 173] INFO [org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter] - File Output Committer Algorithm version is 1
2021-12-03 19:15:32,146 [Executor task launch worker for task 160] INFO [org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter] - Saved output of task 'attempt_20211203191251_0014_m_000006_0' to hdfs://hdp1:8020/sk/chongqing/sample_data/filter-sample-device-video-data.bcp/_temporary/0/task_20211203191251_0014_m_000006
2021-12-03 19:15:32,146 [Executor task launch worker for task 160] INFO [org.apache.spark.mapred.SparkHadoopMapRedUtil] - attempt_20211203191251_0014_m_000006_0: Committed
2021-12-03 19:15:32,147 [Executor task launch worker for task 160] INFO [org.apache.spark.executor.Executor] - Finished task 6.0 in stage 14.0 (TID 160). 869 bytes result sent to driver
2021-12-03 19:15:32,147 [dispatcher-event-loop-10] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 20.0 in stage 14.0 (TID 174, localhost, executor driver, partition 20, ANY, 7899 bytes)
2021-12-03 19:15:32,147 [Executor task launch worker for task 174] INFO [org.apache.spark.executor.Executor] - Running task 20.0 in stage 14.0 (TID 174)
2021-12-03 19:15:32,148 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 6.0 in stage 14.0 (TID 160) in 160390 ms on localhost (executor driver) (9/22)
2021-12-03 19:15:32,150 [Executor task launch worker for task 174] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:2684354560+134217728
2021-12-03 19:15:32,512 [Executor task launch worker for task 163] INFO [org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter] - Saved output of task 'attempt_20211203191251_0014_m_000009_0' to hdfs://hdp1:8020/sk/chongqing/sample_data/filter-sample-device-video-data.bcp/_temporary/0/task_20211203191251_0014_m_000009
2021-12-03 19:15:32,512 [Executor task launch worker for task 163] INFO [org.apache.spark.mapred.SparkHadoopMapRedUtil] - attempt_20211203191251_0014_m_000009_0: Committed
2021-12-03 19:15:32,513 [Executor task launch worker for task 163] INFO [org.apache.spark.executor.Executor] - Finished task 9.0 in stage 14.0 (TID 163). 912 bytes result sent to driver
2021-12-03 19:15:32,513 [dispatcher-event-loop-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 21.0 in stage 14.0 (TID 175, localhost, executor driver, partition 21, ANY, 7899 bytes)
2021-12-03 19:15:32,513 [Executor task launch worker for task 175] INFO [org.apache.spark.executor.Executor] - Running task 21.0 in stage 14.0 (TID 175)
2021-12-03 19:15:32,514 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 9.0 in stage 14.0 (TID 163) in 160756 ms on localhost (executor driver) (10/22)
2021-12-03 19:15:32,516 [Executor task launch worker for task 175] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:2818572288+147216171
2021-12-03 19:15:32,961 [Executor task launch worker for task 175] INFO [org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter] - File Output Committer Algorithm version is 1
2021-12-03 19:15:33,195 [Executor task launch worker for task 174] INFO [org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter] - File Output Committer Algorithm version is 1
2021-12-03 19:15:47,095 [Executor task launch worker for task 154] INFO [org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter] - Saved output of task 'attempt_20211203191251_0014_m_000000_0' to hdfs://hdp1:8020/sk/chongqing/sample_data/filter-sample-device-video-data.bcp/_temporary/0/task_20211203191251_0014_m_000000
2021-12-03 19:15:47,095 [Executor task launch worker for task 154] INFO [org.apache.spark.mapred.SparkHadoopMapRedUtil] - attempt_20211203191251_0014_m_000000_0: Committed
2021-12-03 19:15:47,096 [Executor task launch worker for task 154] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 14.0 (TID 154). 912 bytes result sent to driver
2021-12-03 19:15:47,096 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 14.0 (TID 154) in 175340 ms on localhost (executor driver) (11/22)
2021-12-03 19:15:48,188 [Executor task launch worker for task 156] INFO [org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter] - Saved output of task 'attempt_20211203191251_0014_m_000002_0' to hdfs://hdp1:8020/sk/chongqing/sample_data/filter-sample-device-video-data.bcp/_temporary/0/task_20211203191251_0014_m_000002
2021-12-03 19:15:48,188 [Executor task launch worker for task 156] INFO [org.apache.spark.mapred.SparkHadoopMapRedUtil] - attempt_20211203191251_0014_m_000002_0: Committed
2021-12-03 19:15:48,189 [Executor task launch worker for task 156] INFO [org.apache.spark.executor.Executor] - Finished task 2.0 in stage 14.0 (TID 156). 912 bytes result sent to driver
2021-12-03 19:15:48,190 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 2.0 in stage 14.0 (TID 156) in 176433 ms on localhost (executor driver) (12/22)
2021-12-03 19:16:31,838 [Executor task launch worker for task 166] INFO [org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter] - Saved output of task 'attempt_20211203191251_0014_m_000012_0' to hdfs://hdp1:8020/sk/chongqing/sample_data/filter-sample-device-video-data.bcp/_temporary/0/task_20211203191251_0014_m_000012
2021-12-03 19:16:31,838 [Executor task launch worker for task 166] INFO [org.apache.spark.mapred.SparkHadoopMapRedUtil] - attempt_20211203191251_0014_m_000012_0: Committed
2021-12-03 19:16:31,839 [Executor task launch worker for task 166] INFO [org.apache.spark.executor.Executor] - Finished task 12.0 in stage 14.0 (TID 166). 955 bytes result sent to driver
2021-12-03 19:16:31,839 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 12.0 in stage 14.0 (TID 166) in 108600 ms on localhost (executor driver) (13/22)
2021-12-03 19:16:36,497 [Executor task launch worker for task 167] INFO [org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter] - Saved output of task 'attempt_20211203191251_0014_m_000013_0' to hdfs://hdp1:8020/sk/chongqing/sample_data/filter-sample-device-video-data.bcp/_temporary/0/task_20211203191251_0014_m_000013
2021-12-03 19:16:36,497 [Executor task launch worker for task 167] INFO [org.apache.spark.mapred.SparkHadoopMapRedUtil] - attempt_20211203191251_0014_m_000013_0: Committed
2021-12-03 19:16:36,498 [Executor task launch worker for task 167] INFO [org.apache.spark.executor.Executor] - Finished task 13.0 in stage 14.0 (TID 167). 912 bytes result sent to driver
2021-12-03 19:16:36,499 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 13.0 in stage 14.0 (TID 167) in 100375 ms on localhost (executor driver) (14/22)
2021-12-03 19:16:42,223 [Executor task launch worker for task 169] INFO [org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter] - Saved output of task 'attempt_20211203191251_0014_m_000015_0' to hdfs://hdp1:8020/sk/chongqing/sample_data/filter-sample-device-video-data.bcp/_temporary/0/task_20211203191251_0014_m_000015
2021-12-03 19:16:42,223 [Executor task launch worker for task 169] INFO [org.apache.spark.mapred.SparkHadoopMapRedUtil] - attempt_20211203191251_0014_m_000015_0: Committed
2021-12-03 19:16:42,224 [Executor task launch worker for task 169] INFO [org.apache.spark.executor.Executor] - Finished task 15.0 in stage 14.0 (TID 169). 912 bytes result sent to driver
2021-12-03 19:16:42,225 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 15.0 in stage 14.0 (TID 169) in 100398 ms on localhost (executor driver) (15/22)
2021-12-03 19:16:47,134 [Executor task launch worker for task 171] INFO [org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter] - Saved output of task 'attempt_20211203191251_0014_m_000017_0' to hdfs://hdp1:8020/sk/chongqing/sample_data/filter-sample-device-video-data.bcp/_temporary/0/task_20211203191251_0014_m_000017
2021-12-03 19:16:47,135 [Executor task launch worker for task 171] INFO [org.apache.spark.mapred.SparkHadoopMapRedUtil] - attempt_20211203191251_0014_m_000017_0: Committed
2021-12-03 19:16:47,135 [Executor task launch worker for task 171] INFO [org.apache.spark.executor.Executor] - Finished task 17.0 in stage 14.0 (TID 171). 869 bytes result sent to driver
2021-12-03 19:16:47,136 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 17.0 in stage 14.0 (TID 171) in 91859 ms on localhost (executor driver) (16/22)
2021-12-03 19:16:58,049 [Executor task launch worker for task 175] INFO [org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter] - Saved output of task 'attempt_20211203191251_0014_m_000021_0' to hdfs://hdp1:8020/sk/chongqing/sample_data/filter-sample-device-video-data.bcp/_temporary/0/task_20211203191251_0014_m_000021
2021-12-03 19:16:58,049 [Executor task launch worker for task 175] INFO [org.apache.spark.mapred.SparkHadoopMapRedUtil] - attempt_20211203191251_0014_m_000021_0: Committed
2021-12-03 19:16:58,050 [Executor task launch worker for task 175] INFO [org.apache.spark.executor.Executor] - Finished task 21.0 in stage 14.0 (TID 175). 869 bytes result sent to driver
2021-12-03 19:16:58,050 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 21.0 in stage 14.0 (TID 175) in 85537 ms on localhost (executor driver) (17/22)
2021-12-03 19:17:07,761 [Executor task launch worker for task 173] INFO [org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter] - Saved output of task 'attempt_20211203191251_0014_m_000019_0' to hdfs://hdp1:8020/sk/chongqing/sample_data/filter-sample-device-video-data.bcp/_temporary/0/task_20211203191251_0014_m_000019
2021-12-03 19:17:07,761 [Executor task launch worker for task 173] INFO [org.apache.spark.mapred.SparkHadoopMapRedUtil] - attempt_20211203191251_0014_m_000019_0: Committed
2021-12-03 19:17:07,762 [Executor task launch worker for task 173] INFO [org.apache.spark.executor.Executor] - Finished task 19.0 in stage 14.0 (TID 173). 912 bytes result sent to driver
2021-12-03 19:17:07,762 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 19.0 in stage 14.0 (TID 173) in 97388 ms on localhost (executor driver) (18/22)
2021-12-03 19:17:07,795 [Executor task launch worker for task 168] INFO [org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter] - Saved output of task 'attempt_20211203191251_0014_m_000014_0' to hdfs://hdp1:8020/sk/chongqing/sample_data/filter-sample-device-video-data.bcp/_temporary/0/task_20211203191251_0014_m_000014
2021-12-03 19:17:07,795 [Executor task launch worker for task 168] INFO [org.apache.spark.mapred.SparkHadoopMapRedUtil] - attempt_20211203191251_0014_m_000014_0: Committed
2021-12-03 19:17:07,796 [Executor task launch worker for task 168] INFO [org.apache.spark.executor.Executor] - Finished task 14.0 in stage 14.0 (TID 168). 869 bytes result sent to driver
2021-12-03 19:17:07,796 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 14.0 in stage 14.0 (TID 168) in 130307 ms on localhost (executor driver) (19/22)
2021-12-03 19:17:11,654 [Executor task launch worker for task 172] INFO [org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter] - Saved output of task 'attempt_20211203191251_0014_m_000018_0' to hdfs://hdp1:8020/sk/chongqing/sample_data/filter-sample-device-video-data.bcp/_temporary/0/task_20211203191251_0014_m_000018
2021-12-03 19:17:11,654 [Executor task launch worker for task 172] INFO [org.apache.spark.mapred.SparkHadoopMapRedUtil] - attempt_20211203191251_0014_m_000018_0: Committed
2021-12-03 19:17:11,655 [Executor task launch worker for task 172] INFO [org.apache.spark.executor.Executor] - Finished task 18.0 in stage 14.0 (TID 172). 869 bytes result sent to driver
2021-12-03 19:17:11,656 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 18.0 in stage 14.0 (TID 172) in 109305 ms on localhost (executor driver) (20/22)
2021-12-03 19:17:12,037 [Executor task launch worker for task 170] INFO [org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter] - Saved output of task 'attempt_20211203191251_0014_m_000016_0' to hdfs://hdp1:8020/sk/chongqing/sample_data/filter-sample-device-video-data.bcp/_temporary/0/task_20211203191251_0014_m_000016
2021-12-03 19:17:12,038 [Executor task launch worker for task 170] INFO [org.apache.spark.mapred.SparkHadoopMapRedUtil] - attempt_20211203191251_0014_m_000016_0: Committed
2021-12-03 19:17:12,038 [Executor task launch worker for task 170] INFO [org.apache.spark.executor.Executor] - Finished task 16.0 in stage 14.0 (TID 170). 869 bytes result sent to driver
2021-12-03 19:17:12,039 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 16.0 in stage 14.0 (TID 170) in 126403 ms on localhost (executor driver) (21/22)
2021-12-03 19:17:12,392 [Executor task launch worker for task 174] INFO [org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter] - Saved output of task 'attempt_20211203191251_0014_m_000020_0' to hdfs://hdp1:8020/sk/chongqing/sample_data/filter-sample-device-video-data.bcp/_temporary/0/task_20211203191251_0014_m_000020
2021-12-03 19:17:12,392 [Executor task launch worker for task 174] INFO [org.apache.spark.mapred.SparkHadoopMapRedUtil] - attempt_20211203191251_0014_m_000020_0: Committed
2021-12-03 19:17:12,393 [Executor task launch worker for task 174] INFO [org.apache.spark.executor.Executor] - Finished task 20.0 in stage 14.0 (TID 174). 869 bytes result sent to driver
2021-12-03 19:17:12,393 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 20.0 in stage 14.0 (TID 174) in 100246 ms on localhost (executor driver) (22/22)
2021-12-03 19:17:12,393 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 14.0, whose tasks have all completed, from pool 
2021-12-03 19:17:12,393 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 14 (runJob at SparkHadoopWriter.scala:78) finished in 260.650 s
2021-12-03 19:17:12,394 [main] INFO [org.apache.spark.scheduler.DAGScheduler] - Job 6 finished: runJob at SparkHadoopWriter.scala:78, took 260.651989 s
2021-12-03 19:17:15,213 [main] INFO [org.apache.spark.internal.io.SparkHadoopWriter] - Job job_20211203191251_0014 committed.
2021-12-03 19:17:15,218 [main] INFO [org.spark_project.jetty.server.AbstractConnector] - Stopped Spark@5f7f2382{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2021-12-03 19:17:15,220 [main] INFO [org.apache.spark.ui.SparkUI] - Stopped Spark web UI at http://qb:4040
2021-12-03 19:17:15,227 [dispatcher-event-loop-11] INFO [org.apache.spark.MapOutputTrackerMasterEndpoint] - MapOutputTrackerMasterEndpoint stopped!
2021-12-03 19:17:15,312 [main] INFO [org.apache.spark.storage.memory.MemoryStore] - MemoryStore cleared
2021-12-03 19:17:15,313 [main] INFO [org.apache.spark.storage.BlockManager] - BlockManager stopped
2021-12-03 19:17:15,313 [main] INFO [org.apache.spark.storage.BlockManagerMaster] - BlockManagerMaster stopped
2021-12-03 19:17:15,315 [dispatcher-event-loop-5] INFO [org.apache.spark.scheduler.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint] - OutputCommitCoordinator stopped!
2021-12-03 19:17:15,317 [main] INFO [org.apache.spark.SparkContext] - Successfully stopped SparkContext
2021-12-03 19:17:15,319 [Thread-1] INFO [org.apache.spark.util.ShutdownHookManager] - Shutdown hook called
2021-12-03 19:17:15,319 [Thread-1] INFO [org.apache.spark.util.ShutdownHookManager] - Deleting directory C:\Users\ACER\AppData\Local\Temp\spark-eb52432c-a8e3-4eba-95fa-b93b2020aea2
2021-12-03 19:24:56,044 [main] INFO [org.apache.spark.SparkContext] - Running Spark version 2.3.0
2021-12-03 19:24:56,308 [main] INFO [org.apache.spark.SparkContext] - Submitted application: PaidPromotion
2021-12-03 19:24:56,353 [main] INFO [org.apache.spark.SecurityManager] - Changing view acls to: ACER,root
2021-12-03 19:24:56,354 [main] INFO [org.apache.spark.SecurityManager] - Changing modify acls to: ACER,root
2021-12-03 19:24:56,354 [main] INFO [org.apache.spark.SecurityManager] - Changing view acls groups to: 
2021-12-03 19:24:56,354 [main] INFO [org.apache.spark.SecurityManager] - Changing modify acls groups to: 
2021-12-03 19:24:56,355 [main] INFO [org.apache.spark.SecurityManager] - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(ACER, root); groups with view permissions: Set(); users  with modify permissions: Set(ACER, root); groups with modify permissions: Set()
2021-12-03 19:24:56,920 [main] INFO [org.apache.spark.util.Utils] - Successfully started service 'sparkDriver' on port 62212.
2021-12-03 19:24:56,939 [main] INFO [org.apache.spark.SparkEnv] - Registering MapOutputTracker
2021-12-03 19:24:56,956 [main] INFO [org.apache.spark.SparkEnv] - Registering BlockManagerMaster
2021-12-03 19:24:56,959 [main] INFO [org.apache.spark.storage.BlockManagerMasterEndpoint] - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2021-12-03 19:24:56,959 [main] INFO [org.apache.spark.storage.BlockManagerMasterEndpoint] - BlockManagerMasterEndpoint up
2021-12-03 19:24:56,967 [main] INFO [org.apache.spark.storage.DiskBlockManager] - Created local directory at C:\Users\ACER\AppData\Local\Temp\blockmgr-7b3a2829-742a-4864-9f06-e260a2d57bf9
2021-12-03 19:24:56,981 [main] INFO [org.apache.spark.storage.memory.MemoryStore] - MemoryStore started with capacity 1990.8 MB
2021-12-03 19:24:56,990 [main] INFO [org.apache.spark.SparkEnv] - Registering OutputCommitCoordinator
2021-12-03 19:24:57,045 [main] INFO [org.spark_project.jetty.util.log] - Logging initialized @1830ms
2021-12-03 19:24:57,094 [main] INFO [org.spark_project.jetty.server.Server] - jetty-9.3.z-SNAPSHOT
2021-12-03 19:24:57,105 [main] INFO [org.spark_project.jetty.server.Server] - Started @1890ms
2021-12-03 19:24:57,130 [main] INFO [org.spark_project.jetty.server.AbstractConnector] - Started ServerConnector@5b800468{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2021-12-03 19:24:57,130 [main] INFO [org.apache.spark.util.Utils] - Successfully started service 'SparkUI' on port 4040.
2021-12-03 19:24:57,151 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@1568159{/jobs,null,AVAILABLE,@Spark}
2021-12-03 19:24:57,152 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@63cd604c{/jobs/json,null,AVAILABLE,@Spark}
2021-12-03 19:24:57,154 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@3954d008{/jobs/job,null,AVAILABLE,@Spark}
2021-12-03 19:24:57,155 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@6d8792db{/jobs/job/json,null,AVAILABLE,@Spark}
2021-12-03 19:24:57,156 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@3a1d593e{/stages,null,AVAILABLE,@Spark}
2021-12-03 19:24:57,157 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@285d851a{/stages/json,null,AVAILABLE,@Spark}
2021-12-03 19:24:57,158 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@7876d598{/stages/stage,null,AVAILABLE,@Spark}
2021-12-03 19:24:57,160 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@4985cbcb{/stages/stage/json,null,AVAILABLE,@Spark}
2021-12-03 19:24:57,160 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@54361a9{/stages/pool,null,AVAILABLE,@Spark}
2021-12-03 19:24:57,161 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@293bb8a5{/stages/pool/json,null,AVAILABLE,@Spark}
2021-12-03 19:24:57,163 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@290b1b2e{/storage,null,AVAILABLE,@Spark}
2021-12-03 19:24:57,165 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@5db4c359{/storage/json,null,AVAILABLE,@Spark}
2021-12-03 19:24:57,166 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@6fefce9e{/storage/rdd,null,AVAILABLE,@Spark}
2021-12-03 19:24:57,167 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@8a589a2{/storage/rdd/json,null,AVAILABLE,@Spark}
2021-12-03 19:24:57,168 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@5cc69cfe{/environment,null,AVAILABLE,@Spark}
2021-12-03 19:24:57,169 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@11dee337{/environment/json,null,AVAILABLE,@Spark}
2021-12-03 19:24:57,170 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@74bdc168{/executors,null,AVAILABLE,@Spark}
2021-12-03 19:24:57,171 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@7bb3a9fe{/executors/json,null,AVAILABLE,@Spark}
2021-12-03 19:24:57,172 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@f19c9d2{/executors/threadDump,null,AVAILABLE,@Spark}
2021-12-03 19:24:57,173 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@a77614d{/executors/threadDump/json,null,AVAILABLE,@Spark}
2021-12-03 19:24:57,179 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@523424b5{/static,null,AVAILABLE,@Spark}
2021-12-03 19:24:57,181 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@12cd9150{/,null,AVAILABLE,@Spark}
2021-12-03 19:24:57,183 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@32fe9d0a{/api,null,AVAILABLE,@Spark}
2021-12-03 19:24:57,185 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@59fc684e{/jobs/job/kill,null,AVAILABLE,@Spark}
2021-12-03 19:24:57,186 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@355e34c7{/stages/stage/kill,null,AVAILABLE,@Spark}
2021-12-03 19:24:57,188 [main] INFO [org.apache.spark.ui.SparkUI] - Bound SparkUI to 0.0.0.0, and started at http://qb:4040
2021-12-03 19:24:57,266 [main] INFO [org.apache.spark.executor.Executor] - Starting executor ID driver on host localhost
2021-12-03 19:24:57,314 [main] INFO [org.apache.spark.util.Utils] - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 62255.
2021-12-03 19:24:57,314 [main] INFO [org.apache.spark.network.netty.NettyBlockTransferService] - Server created on qb:62255
2021-12-03 19:24:57,316 [main] INFO [org.apache.spark.storage.BlockManager] - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2021-12-03 19:24:57,317 [main] INFO [org.apache.spark.storage.BlockManagerMaster] - Registering BlockManager BlockManagerId(driver, qb, 62255, None)
2021-12-03 19:24:57,319 [dispatcher-event-loop-10] INFO [org.apache.spark.storage.BlockManagerMasterEndpoint] - Registering block manager qb:62255 with 1990.8 MB RAM, BlockManagerId(driver, qb, 62255, None)
2021-12-03 19:24:57,320 [main] INFO [org.apache.spark.storage.BlockManagerMaster] - Registered BlockManager BlockManagerId(driver, qb, 62255, None)
2021-12-03 19:24:57,321 [main] INFO [org.apache.spark.storage.BlockManager] - Initialized BlockManager: BlockManagerId(driver, qb, 62255, None)
2021-12-03 19:24:57,452 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@6fe46b62{/metrics/json,null,AVAILABLE,@Spark}
2021-12-03 19:24:57,903 [main] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_0 stored as values in memory (estimated size 312.7 KB, free 1990.5 MB)
2021-12-03 19:24:58,126 [main] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_0_piece0 stored as bytes in memory (estimated size 27.3 KB, free 1990.5 MB)
2021-12-03 19:24:58,129 [dispatcher-event-loop-0] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_0_piece0 in memory on qb:62255 (size: 27.3 KB, free: 1990.8 MB)
2021-12-03 19:24:58,132 [main] INFO [org.apache.spark.SparkContext] - Created broadcast 0 from textFile at PaidPromotionAdjustParameter.scala:57
2021-12-03 19:24:58,529 [main] WARN [org.apache.hadoop.hdfs.shortcircuit.DomainSocketFactory] - The short-circuit local reads feature cannot be used because UNIX Domain sockets are not available on Windows.
2021-12-03 19:24:58,611 [main] INFO [org.apache.hadoop.mapred.FileInputFormat] - Total input paths to process : 1
2021-12-03 19:24:58,647 [main] INFO [org.apache.hadoop.net.NetworkTopology] - Adding a new node: /default-rack/192.168.1.33:50010
2021-12-03 19:24:58,648 [main] INFO [org.apache.hadoop.net.NetworkTopology] - Adding a new node: /default-rack/172.16.1.222:50010
2021-12-03 19:24:58,648 [main] INFO [org.apache.hadoop.net.NetworkTopology] - Adding a new node: /default-rack/192.168.1.34:50010
2021-12-03 19:24:58,654 [main] INFO [org.apache.spark.SparkContext] - Starting job: count at PaidPromotionAdjustParameter.scala:59
2021-12-03 19:24:58,664 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 0 (count at PaidPromotionAdjustParameter.scala:59) with 22 output partitions
2021-12-03 19:24:58,664 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 0 (count at PaidPromotionAdjustParameter.scala:59)
2021-12-03 19:24:58,665 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List()
2021-12-03 19:24:58,666 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2021-12-03 19:24:58,673 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 0 (/sk/chongqing/data/behavior_data.bcp MapPartitionsRDD[1] at textFile at PaidPromotionAdjustParameter.scala:57), which has no missing parents
2021-12-03 19:24:58,709 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_1 stored as values in memory (estimated size 3.1 KB, free 1990.5 MB)
2021-12-03 19:24:58,715 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_1_piece0 stored as bytes in memory (estimated size 1903.0 B, free 1990.5 MB)
2021-12-03 19:24:58,716 [dispatcher-event-loop-1] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_1_piece0 in memory on qb:62255 (size: 1903.0 B, free: 1990.8 MB)
2021-12-03 19:24:58,716 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 1 from broadcast at DAGScheduler.scala:1039
2021-12-03 19:24:58,728 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 22 missing tasks from ResultStage 0 (/sk/chongqing/data/behavior_data.bcp MapPartitionsRDD[1] at textFile at PaidPromotionAdjustParameter.scala:57) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14))
2021-12-03 19:24:58,728 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 0.0 with 22 tasks
2021-12-03 19:24:58,762 [dispatcher-event-loop-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 0.0 (TID 0, localhost, executor driver, partition 0, ANY, 7899 bytes)
2021-12-03 19:24:58,763 [dispatcher-event-loop-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 0.0 (TID 1, localhost, executor driver, partition 1, ANY, 7899 bytes)
2021-12-03 19:24:58,763 [dispatcher-event-loop-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 2.0 in stage 0.0 (TID 2, localhost, executor driver, partition 2, ANY, 7899 bytes)
2021-12-03 19:24:58,764 [dispatcher-event-loop-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 3.0 in stage 0.0 (TID 3, localhost, executor driver, partition 3, ANY, 7899 bytes)
2021-12-03 19:24:58,764 [dispatcher-event-loop-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 4.0 in stage 0.0 (TID 4, localhost, executor driver, partition 4, ANY, 7899 bytes)
2021-12-03 19:24:58,764 [dispatcher-event-loop-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 5.0 in stage 0.0 (TID 5, localhost, executor driver, partition 5, ANY, 7899 bytes)
2021-12-03 19:24:58,765 [dispatcher-event-loop-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 6.0 in stage 0.0 (TID 6, localhost, executor driver, partition 6, ANY, 7899 bytes)
2021-12-03 19:24:58,765 [dispatcher-event-loop-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 7.0 in stage 0.0 (TID 7, localhost, executor driver, partition 7, ANY, 7899 bytes)
2021-12-03 19:24:58,765 [dispatcher-event-loop-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 8.0 in stage 0.0 (TID 8, localhost, executor driver, partition 8, ANY, 7899 bytes)
2021-12-03 19:24:58,765 [dispatcher-event-loop-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 9.0 in stage 0.0 (TID 9, localhost, executor driver, partition 9, ANY, 7899 bytes)
2021-12-03 19:24:58,766 [dispatcher-event-loop-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 10.0 in stage 0.0 (TID 10, localhost, executor driver, partition 10, ANY, 7899 bytes)
2021-12-03 19:24:58,766 [dispatcher-event-loop-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 11.0 in stage 0.0 (TID 11, localhost, executor driver, partition 11, ANY, 7899 bytes)
2021-12-03 19:24:58,771 [Executor task launch worker for task 10] INFO [org.apache.spark.executor.Executor] - Running task 10.0 in stage 0.0 (TID 10)
2021-12-03 19:24:58,771 [Executor task launch worker for task 1] INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 0.0 (TID 1)
2021-12-03 19:24:58,771 [Executor task launch worker for task 5] INFO [org.apache.spark.executor.Executor] - Running task 5.0 in stage 0.0 (TID 5)
2021-12-03 19:24:58,771 [Executor task launch worker for task 9] INFO [org.apache.spark.executor.Executor] - Running task 9.0 in stage 0.0 (TID 9)
2021-12-03 19:24:58,771 [Executor task launch worker for task 4] INFO [org.apache.spark.executor.Executor] - Running task 4.0 in stage 0.0 (TID 4)
2021-12-03 19:24:58,771 [Executor task launch worker for task 0] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 0.0 (TID 0)
2021-12-03 19:24:58,771 [Executor task launch worker for task 3] INFO [org.apache.spark.executor.Executor] - Running task 3.0 in stage 0.0 (TID 3)
2021-12-03 19:24:58,771 [Executor task launch worker for task 2] INFO [org.apache.spark.executor.Executor] - Running task 2.0 in stage 0.0 (TID 2)
2021-12-03 19:24:58,771 [Executor task launch worker for task 6] INFO [org.apache.spark.executor.Executor] - Running task 6.0 in stage 0.0 (TID 6)
2021-12-03 19:24:58,771 [Executor task launch worker for task 11] INFO [org.apache.spark.executor.Executor] - Running task 11.0 in stage 0.0 (TID 11)
2021-12-03 19:24:58,771 [Executor task launch worker for task 7] INFO [org.apache.spark.executor.Executor] - Running task 7.0 in stage 0.0 (TID 7)
2021-12-03 19:24:58,771 [Executor task launch worker for task 8] INFO [org.apache.spark.executor.Executor] - Running task 8.0 in stage 0.0 (TID 8)
2021-12-03 19:24:58,814 [Executor task launch worker for task 2] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:268435456+134217728
2021-12-03 19:24:58,814 [Executor task launch worker for task 0] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:0+134217728
2021-12-03 19:24:58,814 [Executor task launch worker for task 10] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:1342177280+134217728
2021-12-03 19:24:58,814 [Executor task launch worker for task 11] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:1476395008+134217728
2021-12-03 19:24:58,814 [Executor task launch worker for task 3] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:402653184+134217728
2021-12-03 19:24:58,814 [Executor task launch worker for task 9] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:1207959552+134217728
2021-12-03 19:24:58,814 [Executor task launch worker for task 1] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:134217728+134217728
2021-12-03 19:24:58,814 [Executor task launch worker for task 7] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:939524096+134217728
2021-12-03 19:24:58,814 [Executor task launch worker for task 8] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:1073741824+134217728
2021-12-03 19:24:58,814 [Executor task launch worker for task 6] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:805306368+134217728
2021-12-03 19:24:58,814 [Executor task launch worker for task 4] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:536870912+134217728
2021-12-03 19:24:58,814 [Executor task launch worker for task 5] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:671088640+134217728
2021-12-03 19:27:03,558 [Executor task launch worker for task 7] INFO [org.apache.spark.executor.Executor] - Finished task 7.0 in stage 0.0 (TID 7). 755 bytes result sent to driver
2021-12-03 19:27:03,560 [dispatcher-event-loop-6] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 12.0 in stage 0.0 (TID 12, localhost, executor driver, partition 12, ANY, 7899 bytes)
2021-12-03 19:27:03,560 [Executor task launch worker for task 12] INFO [org.apache.spark.executor.Executor] - Running task 12.0 in stage 0.0 (TID 12)
2021-12-03 19:27:03,561 [Executor task launch worker for task 12] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:1610612736+134217728
2021-12-03 19:27:03,567 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 7.0 in stage 0.0 (TID 7) in 124801 ms on localhost (executor driver) (1/22)
2021-12-03 19:27:04,727 [Executor task launch worker for task 8] INFO [org.apache.spark.executor.Executor] - Finished task 8.0 in stage 0.0 (TID 8). 755 bytes result sent to driver
2021-12-03 19:27:04,728 [dispatcher-event-loop-4] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 13.0 in stage 0.0 (TID 13, localhost, executor driver, partition 13, ANY, 7899 bytes)
2021-12-03 19:27:04,728 [Executor task launch worker for task 13] INFO [org.apache.spark.executor.Executor] - Running task 13.0 in stage 0.0 (TID 13)
2021-12-03 19:27:04,730 [Executor task launch worker for task 13] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:1744830464+134217728
2021-12-03 19:27:04,732 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 8.0 in stage 0.0 (TID 8) in 125966 ms on localhost (executor driver) (2/22)
2021-12-03 19:27:17,850 [Executor task launch worker for task 1] INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 0.0 (TID 1). 755 bytes result sent to driver
2021-12-03 19:27:17,851 [dispatcher-event-loop-5] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 14.0 in stage 0.0 (TID 14, localhost, executor driver, partition 14, ANY, 7899 bytes)
2021-12-03 19:27:17,851 [Executor task launch worker for task 14] INFO [org.apache.spark.executor.Executor] - Running task 14.0 in stage 0.0 (TID 14)
2021-12-03 19:27:17,852 [Executor task launch worker for task 14] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:1879048192+134217728
2021-12-03 19:27:17,853 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 0.0 (TID 1) in 139090 ms on localhost (executor driver) (3/22)
2021-12-03 19:27:22,301 [Executor task launch worker for task 11] INFO [org.apache.spark.executor.Executor] - Finished task 11.0 in stage 0.0 (TID 11). 755 bytes result sent to driver
2021-12-03 19:27:22,302 [dispatcher-event-loop-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 15.0 in stage 0.0 (TID 15, localhost, executor driver, partition 15, ANY, 7899 bytes)
2021-12-03 19:27:22,302 [Executor task launch worker for task 15] INFO [org.apache.spark.executor.Executor] - Running task 15.0 in stage 0.0 (TID 15)
2021-12-03 19:27:22,303 [Executor task launch worker for task 15] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:2013265920+134217728
2021-12-03 19:27:22,304 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 11.0 in stage 0.0 (TID 11) in 143538 ms on localhost (executor driver) (4/22)
2021-12-03 19:27:23,368 [Executor task launch worker for task 10] INFO [org.apache.spark.executor.Executor] - Finished task 10.0 in stage 0.0 (TID 10). 755 bytes result sent to driver
2021-12-03 19:27:23,368 [dispatcher-event-loop-6] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 16.0 in stage 0.0 (TID 16, localhost, executor driver, partition 16, ANY, 7899 bytes)
2021-12-03 19:27:23,369 [Executor task launch worker for task 16] INFO [org.apache.spark.executor.Executor] - Running task 16.0 in stage 0.0 (TID 16)
2021-12-03 19:27:23,369 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 10.0 in stage 0.0 (TID 10) in 144604 ms on localhost (executor driver) (5/22)
2021-12-03 19:27:23,370 [Executor task launch worker for task 16] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:2147483648+134217728
2021-12-03 19:27:25,685 [Executor task launch worker for task 5] INFO [org.apache.spark.executor.Executor] - Finished task 5.0 in stage 0.0 (TID 5). 755 bytes result sent to driver
2021-12-03 19:27:25,685 [dispatcher-event-loop-4] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 17.0 in stage 0.0 (TID 17, localhost, executor driver, partition 17, ANY, 7899 bytes)
2021-12-03 19:27:25,686 [Executor task launch worker for task 17] INFO [org.apache.spark.executor.Executor] - Running task 17.0 in stage 0.0 (TID 17)
2021-12-03 19:27:25,686 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 5.0 in stage 0.0 (TID 5) in 146922 ms on localhost (executor driver) (6/22)
2021-12-03 19:27:25,686 [Executor task launch worker for task 17] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:2281701376+134217728
2021-12-03 19:27:31,934 [Executor task launch worker for task 6] INFO [org.apache.spark.executor.Executor] - Finished task 6.0 in stage 0.0 (TID 6). 798 bytes result sent to driver
2021-12-03 19:27:31,934 [dispatcher-event-loop-11] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 18.0 in stage 0.0 (TID 18, localhost, executor driver, partition 18, ANY, 7899 bytes)
2021-12-03 19:27:31,934 [Executor task launch worker for task 18] INFO [org.apache.spark.executor.Executor] - Running task 18.0 in stage 0.0 (TID 18)
2021-12-03 19:27:31,934 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 6.0 in stage 0.0 (TID 6) in 153170 ms on localhost (executor driver) (7/22)
2021-12-03 19:27:31,935 [Executor task launch worker for task 18] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:2415919104+134217728
2021-12-03 19:27:34,018 [Executor task launch worker for task 2] INFO [org.apache.spark.executor.Executor] - Finished task 2.0 in stage 0.0 (TID 2). 755 bytes result sent to driver
2021-12-03 19:27:34,018 [dispatcher-event-loop-5] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 19.0 in stage 0.0 (TID 19, localhost, executor driver, partition 19, ANY, 7899 bytes)
2021-12-03 19:27:34,018 [Executor task launch worker for task 19] INFO [org.apache.spark.executor.Executor] - Running task 19.0 in stage 0.0 (TID 19)
2021-12-03 19:27:34,018 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 2.0 in stage 0.0 (TID 2) in 155255 ms on localhost (executor driver) (8/22)
2021-12-03 19:27:34,019 [Executor task launch worker for task 19] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:2550136832+134217728
2021-12-03 19:27:41,822 [Executor task launch worker for task 9] INFO [org.apache.spark.executor.Executor] - Finished task 9.0 in stage 0.0 (TID 9). 755 bytes result sent to driver
2021-12-03 19:27:41,823 [dispatcher-event-loop-6] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 20.0 in stage 0.0 (TID 20, localhost, executor driver, partition 20, ANY, 7899 bytes)
2021-12-03 19:27:41,823 [Executor task launch worker for task 20] INFO [org.apache.spark.executor.Executor] - Running task 20.0 in stage 0.0 (TID 20)
2021-12-03 19:27:41,823 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 9.0 in stage 0.0 (TID 9) in 163058 ms on localhost (executor driver) (9/22)
2021-12-03 19:27:41,823 [Executor task launch worker for task 20] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:2684354560+134217728
2021-12-03 19:27:43,007 [Executor task launch worker for task 4] INFO [org.apache.spark.executor.Executor] - Finished task 4.0 in stage 0.0 (TID 4). 755 bytes result sent to driver
2021-12-03 19:27:43,007 [dispatcher-event-loop-4] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 21.0 in stage 0.0 (TID 21, localhost, executor driver, partition 21, ANY, 7899 bytes)
2021-12-03 19:27:43,008 [Executor task launch worker for task 21] INFO [org.apache.spark.executor.Executor] - Running task 21.0 in stage 0.0 (TID 21)
2021-12-03 19:27:43,008 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 4.0 in stage 0.0 (TID 4) in 164244 ms on localhost (executor driver) (10/22)
2021-12-03 19:27:43,009 [Executor task launch worker for task 21] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:2818572288+147216171
2021-12-03 19:27:48,013 [Executor task launch worker for task 3] INFO [org.apache.spark.executor.Executor] - Finished task 3.0 in stage 0.0 (TID 3). 755 bytes result sent to driver
2021-12-03 19:27:48,015 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 3.0 in stage 0.0 (TID 3) in 169251 ms on localhost (executor driver) (11/22)
2021-12-03 19:27:49,280 [Executor task launch worker for task 0] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 0.0 (TID 0). 755 bytes result sent to driver
2021-12-03 19:27:49,281 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 0.0 (TID 0) in 170528 ms on localhost (executor driver) (12/22)
2021-12-03 19:29:06,441 [Executor task launch worker for task 15] INFO [org.apache.spark.executor.Executor] - Finished task 15.0 in stage 0.0 (TID 15). 755 bytes result sent to driver
2021-12-03 19:29:06,442 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 15.0 in stage 0.0 (TID 15) in 104141 ms on localhost (executor driver) (13/22)
2021-12-03 19:29:13,935 [Executor task launch worker for task 13] INFO [org.apache.spark.executor.Executor] - Finished task 13.0 in stage 0.0 (TID 13). 755 bytes result sent to driver
2021-12-03 19:29:13,935 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 13.0 in stage 0.0 (TID 13) in 129207 ms on localhost (executor driver) (14/22)
2021-12-03 19:29:15,865 [Executor task launch worker for task 12] INFO [org.apache.spark.executor.Executor] - Finished task 12.0 in stage 0.0 (TID 12). 712 bytes result sent to driver
2021-12-03 19:29:15,866 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 12.0 in stage 0.0 (TID 12) in 132307 ms on localhost (executor driver) (15/22)
2021-12-03 19:29:22,700 [Executor task launch worker for task 14] INFO [org.apache.spark.executor.Executor] - Finished task 14.0 in stage 0.0 (TID 14). 755 bytes result sent to driver
2021-12-03 19:29:22,700 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 14.0 in stage 0.0 (TID 14) in 124849 ms on localhost (executor driver) (16/22)
2021-12-03 19:29:22,748 [Executor task launch worker for task 17] INFO [org.apache.spark.executor.Executor] - Finished task 17.0 in stage 0.0 (TID 17). 712 bytes result sent to driver
2021-12-03 19:29:22,748 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 17.0 in stage 0.0 (TID 17) in 117063 ms on localhost (executor driver) (17/22)
2021-12-03 19:29:22,946 [Executor task launch worker for task 18] INFO [org.apache.spark.executor.Executor] - Finished task 18.0 in stage 0.0 (TID 18). 755 bytes result sent to driver
2021-12-03 19:29:22,946 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 18.0 in stage 0.0 (TID 18) in 111012 ms on localhost (executor driver) (18/22)
2021-12-03 19:29:23,591 [Executor task launch worker for task 20] INFO [org.apache.spark.executor.Executor] - Finished task 20.0 in stage 0.0 (TID 20). 712 bytes result sent to driver
2021-12-03 19:29:23,591 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 20.0 in stage 0.0 (TID 20) in 101769 ms on localhost (executor driver) (19/22)
2021-12-03 19:29:23,842 [Executor task launch worker for task 16] INFO [org.apache.spark.executor.Executor] - Finished task 16.0 in stage 0.0 (TID 16). 755 bytes result sent to driver
2021-12-03 19:29:23,843 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 16.0 in stage 0.0 (TID 16) in 120475 ms on localhost (executor driver) (20/22)
2021-12-03 19:29:25,938 [Executor task launch worker for task 19] INFO [org.apache.spark.executor.Executor] - Finished task 19.0 in stage 0.0 (TID 19). 755 bytes result sent to driver
2021-12-03 19:29:25,939 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 19.0 in stage 0.0 (TID 19) in 111921 ms on localhost (executor driver) (21/22)
2021-12-03 19:29:28,603 [Executor task launch worker for task 21] INFO [org.apache.spark.executor.Executor] - Finished task 21.0 in stage 0.0 (TID 21). 755 bytes result sent to driver
2021-12-03 19:29:28,603 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 21.0 in stage 0.0 (TID 21) in 105596 ms on localhost (executor driver) (22/22)
2021-12-03 19:29:28,604 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 0.0, whose tasks have all completed, from pool 
2021-12-03 19:29:28,604 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 0 (count at PaidPromotionAdjustParameter.scala:59) finished in 269.915 s
2021-12-03 19:29:28,608 [main] INFO [org.apache.spark.scheduler.DAGScheduler] - Job 0 finished: count at PaidPromotionAdjustParameter.scala:59, took 269.953734 s
2021-12-03 19:29:28,609 [main] INFO [PaidPromotion$] - 收视总数68489201
2021-12-03 19:29:28,629 [main] INFO [org.apache.spark.SparkContext] - Starting job: count at PaidPromotionAdjustParameter.scala:68
2021-12-03 19:29:28,635 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 3 (map at PaidPromotionAdjustParameter.scala:67)
2021-12-03 19:29:28,636 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 1 (count at PaidPromotionAdjustParameter.scala:68) with 22 output partitions
2021-12-03 19:29:28,636 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 2 (count at PaidPromotionAdjustParameter.scala:68)
2021-12-03 19:29:28,636 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 1)
2021-12-03 19:29:28,636 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List(ShuffleMapStage 1)
2021-12-03 19:29:28,637 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ShuffleMapStage 1 (MapPartitionsRDD[3] at map at PaidPromotionAdjustParameter.scala:67), which has no missing parents
2021-12-03 19:29:28,646 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_2 stored as values in memory (estimated size 4.7 KB, free 1990.5 MB)
2021-12-03 19:29:28,648 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_2_piece0 stored as bytes in memory (estimated size 2.7 KB, free 1990.5 MB)
2021-12-03 19:29:28,649 [dispatcher-event-loop-9] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_2_piece0 in memory on qb:62255 (size: 2.7 KB, free: 1990.8 MB)
2021-12-03 19:29:28,649 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 2 from broadcast at DAGScheduler.scala:1039
2021-12-03 19:29:28,651 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 22 missing tasks from ShuffleMapStage 1 (MapPartitionsRDD[3] at map at PaidPromotionAdjustParameter.scala:67) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14))
2021-12-03 19:29:28,651 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 1.0 with 22 tasks
2021-12-03 19:29:28,652 [dispatcher-event-loop-10] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 1.0 (TID 22, localhost, executor driver, partition 0, ANY, 7888 bytes)
2021-12-03 19:29:28,652 [dispatcher-event-loop-10] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 1.0 (TID 23, localhost, executor driver, partition 1, ANY, 7888 bytes)
2021-12-03 19:29:28,653 [dispatcher-event-loop-10] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 2.0 in stage 1.0 (TID 24, localhost, executor driver, partition 2, ANY, 7888 bytes)
2021-12-03 19:29:28,653 [dispatcher-event-loop-10] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 3.0 in stage 1.0 (TID 25, localhost, executor driver, partition 3, ANY, 7888 bytes)
2021-12-03 19:29:28,653 [dispatcher-event-loop-10] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 4.0 in stage 1.0 (TID 26, localhost, executor driver, partition 4, ANY, 7888 bytes)
2021-12-03 19:29:28,653 [dispatcher-event-loop-10] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 5.0 in stage 1.0 (TID 27, localhost, executor driver, partition 5, ANY, 7888 bytes)
2021-12-03 19:29:28,653 [dispatcher-event-loop-10] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 6.0 in stage 1.0 (TID 28, localhost, executor driver, partition 6, ANY, 7888 bytes)
2021-12-03 19:29:28,653 [dispatcher-event-loop-10] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 7.0 in stage 1.0 (TID 29, localhost, executor driver, partition 7, ANY, 7888 bytes)
2021-12-03 19:29:28,654 [dispatcher-event-loop-10] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 8.0 in stage 1.0 (TID 30, localhost, executor driver, partition 8, ANY, 7888 bytes)
2021-12-03 19:29:28,654 [dispatcher-event-loop-10] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 9.0 in stage 1.0 (TID 31, localhost, executor driver, partition 9, ANY, 7888 bytes)
2021-12-03 19:29:28,654 [dispatcher-event-loop-10] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 10.0 in stage 1.0 (TID 32, localhost, executor driver, partition 10, ANY, 7888 bytes)
2021-12-03 19:29:28,654 [dispatcher-event-loop-10] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 11.0 in stage 1.0 (TID 33, localhost, executor driver, partition 11, ANY, 7888 bytes)
2021-12-03 19:29:28,654 [Executor task launch worker for task 22] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 1.0 (TID 22)
2021-12-03 19:29:28,654 [Executor task launch worker for task 25] INFO [org.apache.spark.executor.Executor] - Running task 3.0 in stage 1.0 (TID 25)
2021-12-03 19:29:28,654 [Executor task launch worker for task 30] INFO [org.apache.spark.executor.Executor] - Running task 8.0 in stage 1.0 (TID 30)
2021-12-03 19:29:28,654 [Executor task launch worker for task 31] INFO [org.apache.spark.executor.Executor] - Running task 9.0 in stage 1.0 (TID 31)
2021-12-03 19:29:28,654 [Executor task launch worker for task 29] INFO [org.apache.spark.executor.Executor] - Running task 7.0 in stage 1.0 (TID 29)
2021-12-03 19:29:28,654 [Executor task launch worker for task 28] INFO [org.apache.spark.executor.Executor] - Running task 6.0 in stage 1.0 (TID 28)
2021-12-03 19:29:28,654 [Executor task launch worker for task 26] INFO [org.apache.spark.executor.Executor] - Running task 4.0 in stage 1.0 (TID 26)
2021-12-03 19:29:28,654 [Executor task launch worker for task 24] INFO [org.apache.spark.executor.Executor] - Running task 2.0 in stage 1.0 (TID 24)
2021-12-03 19:29:28,654 [Executor task launch worker for task 27] INFO [org.apache.spark.executor.Executor] - Running task 5.0 in stage 1.0 (TID 27)
2021-12-03 19:29:28,654 [Executor task launch worker for task 23] INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 1.0 (TID 23)
2021-12-03 19:29:28,655 [Executor task launch worker for task 33] INFO [org.apache.spark.executor.Executor] - Running task 11.0 in stage 1.0 (TID 33)
2021-12-03 19:29:28,655 [Executor task launch worker for task 32] INFO [org.apache.spark.executor.Executor] - Running task 10.0 in stage 1.0 (TID 32)
2021-12-03 19:29:28,660 [Executor task launch worker for task 29] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:939524096+134217728
2021-12-03 19:29:28,660 [Executor task launch worker for task 33] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:1476395008+134217728
2021-12-03 19:29:28,660 [Executor task launch worker for task 26] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:536870912+134217728
2021-12-03 19:29:28,660 [Executor task launch worker for task 32] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:1342177280+134217728
2021-12-03 19:29:28,660 [Executor task launch worker for task 27] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:671088640+134217728
2021-12-03 19:29:28,660 [Executor task launch worker for task 30] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:1073741824+134217728
2021-12-03 19:29:28,660 [Executor task launch worker for task 24] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:268435456+134217728
2021-12-03 19:29:28,660 [Executor task launch worker for task 31] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:1207959552+134217728
2021-12-03 19:29:28,660 [Executor task launch worker for task 25] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:402653184+134217728
2021-12-03 19:29:28,660 [Executor task launch worker for task 28] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:805306368+134217728
2021-12-03 19:29:28,660 [Executor task launch worker for task 22] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:0+134217728
2021-12-03 19:29:28,660 [Executor task launch worker for task 23] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:134217728+134217728
2021-12-03 19:31:20,135 [Executor task launch worker for task 23] INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 1.0 (TID 23). 1052 bytes result sent to driver
2021-12-03 19:31:20,136 [dispatcher-event-loop-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 12.0 in stage 1.0 (TID 34, localhost, executor driver, partition 12, ANY, 7888 bytes)
2021-12-03 19:31:20,136 [Executor task launch worker for task 34] INFO [org.apache.spark.executor.Executor] - Running task 12.0 in stage 1.0 (TID 34)
2021-12-03 19:31:20,137 [Executor task launch worker for task 34] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:1610612736+134217728
2021-12-03 19:31:20,148 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 1.0 (TID 23) in 111496 ms on localhost (executor driver) (1/22)
2021-12-03 19:31:27,281 [Executor task launch worker for task 22] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 1.0 (TID 22). 1052 bytes result sent to driver
2021-12-03 19:31:27,282 [dispatcher-event-loop-10] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 13.0 in stage 1.0 (TID 35, localhost, executor driver, partition 13, ANY, 7888 bytes)
2021-12-03 19:31:27,282 [Executor task launch worker for task 35] INFO [org.apache.spark.executor.Executor] - Running task 13.0 in stage 1.0 (TID 35)
2021-12-03 19:31:27,282 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 1.0 (TID 22) in 118630 ms on localhost (executor driver) (2/22)
2021-12-03 19:31:27,283 [Executor task launch worker for task 35] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:1744830464+134217728
2021-12-03 19:31:27,728 [Executor task launch worker for task 28] INFO [org.apache.spark.executor.Executor] - Finished task 6.0 in stage 1.0 (TID 28). 1052 bytes result sent to driver
2021-12-03 19:31:27,730 [dispatcher-event-loop-8] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 14.0 in stage 1.0 (TID 36, localhost, executor driver, partition 14, ANY, 7888 bytes)
2021-12-03 19:31:27,730 [Executor task launch worker for task 36] INFO [org.apache.spark.executor.Executor] - Running task 14.0 in stage 1.0 (TID 36)
2021-12-03 19:31:27,731 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 6.0 in stage 1.0 (TID 28) in 119078 ms on localhost (executor driver) (3/22)
2021-12-03 19:31:27,732 [Executor task launch worker for task 36] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:1879048192+134217728
2021-12-03 19:31:40,929 [Executor task launch worker for task 30] INFO [org.apache.spark.executor.Executor] - Finished task 8.0 in stage 1.0 (TID 30). 1052 bytes result sent to driver
2021-12-03 19:31:40,929 [dispatcher-event-loop-9] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 15.0 in stage 1.0 (TID 37, localhost, executor driver, partition 15, ANY, 7888 bytes)
2021-12-03 19:31:40,929 [Executor task launch worker for task 37] INFO [org.apache.spark.executor.Executor] - Running task 15.0 in stage 1.0 (TID 37)
2021-12-03 19:31:40,929 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 8.0 in stage 1.0 (TID 30) in 132276 ms on localhost (executor driver) (4/22)
2021-12-03 19:31:40,930 [Executor task launch worker for task 37] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:2013265920+134217728
2021-12-03 19:31:45,940 [Executor task launch worker for task 25] INFO [org.apache.spark.executor.Executor] - Finished task 3.0 in stage 1.0 (TID 25). 1052 bytes result sent to driver
2021-12-03 19:31:45,940 [dispatcher-event-loop-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 16.0 in stage 1.0 (TID 38, localhost, executor driver, partition 16, ANY, 7888 bytes)
2021-12-03 19:31:45,940 [Executor task launch worker for task 38] INFO [org.apache.spark.executor.Executor] - Running task 16.0 in stage 1.0 (TID 38)
2021-12-03 19:31:45,940 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 3.0 in stage 1.0 (TID 25) in 137287 ms on localhost (executor driver) (5/22)
2021-12-03 19:31:45,941 [Executor task launch worker for task 38] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:2147483648+134217728
2021-12-03 19:31:49,483 [Executor task launch worker for task 32] INFO [org.apache.spark.executor.Executor] - Finished task 10.0 in stage 1.0 (TID 32). 1052 bytes result sent to driver
2021-12-03 19:31:49,484 [dispatcher-event-loop-10] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 17.0 in stage 1.0 (TID 39, localhost, executor driver, partition 17, ANY, 7888 bytes)
2021-12-03 19:31:49,484 [Executor task launch worker for task 39] INFO [org.apache.spark.executor.Executor] - Running task 17.0 in stage 1.0 (TID 39)
2021-12-03 19:31:49,484 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 10.0 in stage 1.0 (TID 32) in 140830 ms on localhost (executor driver) (6/22)
2021-12-03 19:31:49,485 [Executor task launch worker for task 39] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:2281701376+134217728
2021-12-03 19:31:56,903 [Executor task launch worker for task 29] INFO [org.apache.spark.executor.Executor] - Finished task 7.0 in stage 1.0 (TID 29). 1052 bytes result sent to driver
2021-12-03 19:31:56,903 [dispatcher-event-loop-4] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 18.0 in stage 1.0 (TID 40, localhost, executor driver, partition 18, ANY, 7888 bytes)
2021-12-03 19:31:56,903 [Executor task launch worker for task 40] INFO [org.apache.spark.executor.Executor] - Running task 18.0 in stage 1.0 (TID 40)
2021-12-03 19:31:56,903 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 7.0 in stage 1.0 (TID 29) in 148250 ms on localhost (executor driver) (7/22)
2021-12-03 19:31:56,904 [Executor task launch worker for task 40] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:2415919104+134217728
2021-12-03 19:32:02,949 [Executor task launch worker for task 24] INFO [org.apache.spark.executor.Executor] - Finished task 2.0 in stage 1.0 (TID 24). 1052 bytes result sent to driver
2021-12-03 19:32:02,950 [dispatcher-event-loop-11] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 19.0 in stage 1.0 (TID 41, localhost, executor driver, partition 19, ANY, 7888 bytes)
2021-12-03 19:32:02,950 [Executor task launch worker for task 41] INFO [org.apache.spark.executor.Executor] - Running task 19.0 in stage 1.0 (TID 41)
2021-12-03 19:32:02,950 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 2.0 in stage 1.0 (TID 24) in 154298 ms on localhost (executor driver) (8/22)
2021-12-03 19:32:02,951 [Executor task launch worker for task 41] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:2550136832+134217728
2021-12-03 19:32:05,731 [Executor task launch worker for task 26] INFO [org.apache.spark.executor.Executor] - Finished task 4.0 in stage 1.0 (TID 26). 1052 bytes result sent to driver
2021-12-03 19:32:05,731 [dispatcher-event-loop-5] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 20.0 in stage 1.0 (TID 42, localhost, executor driver, partition 20, ANY, 7888 bytes)
2021-12-03 19:32:05,731 [Executor task launch worker for task 42] INFO [org.apache.spark.executor.Executor] - Running task 20.0 in stage 1.0 (TID 42)
2021-12-03 19:32:05,731 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 4.0 in stage 1.0 (TID 26) in 157078 ms on localhost (executor driver) (9/22)
2021-12-03 19:32:05,732 [Executor task launch worker for task 42] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:2684354560+134217728
2021-12-03 19:32:08,435 [Executor task launch worker for task 33] INFO [org.apache.spark.executor.Executor] - Finished task 11.0 in stage 1.0 (TID 33). 1052 bytes result sent to driver
2021-12-03 19:32:08,436 [dispatcher-event-loop-7] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 21.0 in stage 1.0 (TID 43, localhost, executor driver, partition 21, ANY, 7888 bytes)
2021-12-03 19:32:08,436 [Executor task launch worker for task 43] INFO [org.apache.spark.executor.Executor] - Running task 21.0 in stage 1.0 (TID 43)
2021-12-03 19:32:08,436 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 11.0 in stage 1.0 (TID 33) in 159782 ms on localhost (executor driver) (10/22)
2021-12-03 19:32:08,437 [Executor task launch worker for task 43] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:2818572288+147216171
2021-12-03 19:32:08,650 [Executor task launch worker for task 27] INFO [org.apache.spark.executor.Executor] - Finished task 5.0 in stage 1.0 (TID 27). 1052 bytes result sent to driver
2021-12-03 19:32:08,650 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 5.0 in stage 1.0 (TID 27) in 159997 ms on localhost (executor driver) (11/22)
2021-12-03 19:32:11,278 [Executor task launch worker for task 31] INFO [org.apache.spark.executor.Executor] - Finished task 9.0 in stage 1.0 (TID 31). 1052 bytes result sent to driver
2021-12-03 19:32:11,278 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 9.0 in stage 1.0 (TID 31) in 162624 ms on localhost (executor driver) (12/22)
2021-12-03 19:32:15,197 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 10
2021-12-03 19:32:15,197 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 12
2021-12-03 19:32:15,197 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 18
2021-12-03 19:32:15,197 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 14
2021-12-03 19:32:15,197 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 0
2021-12-03 19:32:15,197 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 5
2021-12-03 19:32:15,197 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 2
2021-12-03 19:32:15,197 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 20
2021-12-03 19:32:15,197 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 13
2021-12-03 19:32:15,197 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 9
2021-12-03 19:32:15,197 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 3
2021-12-03 19:32:15,197 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 8
2021-12-03 19:32:15,197 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 15
2021-12-03 19:32:15,198 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 4
2021-12-03 19:32:15,198 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 17
2021-12-03 19:32:15,198 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 7
2021-12-03 19:32:15,198 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1
2021-12-03 19:32:15,207 [dispatcher-event-loop-11] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_1_piece0 on qb:62255 in memory (size: 1903.0 B, free: 1990.8 MB)
2021-12-03 19:32:15,209 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 16
2021-12-03 19:32:15,209 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 6
2021-12-03 19:32:15,209 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 19
2021-12-03 19:32:15,209 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 21
2021-12-03 19:32:15,209 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 22
2021-12-03 19:32:15,209 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 23
2021-12-03 19:32:15,209 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 24
2021-12-03 19:32:15,209 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 11
2021-12-03 19:32:55,689 [Executor task launch worker for task 42] INFO [org.apache.spark.executor.Executor] - Finished task 20.0 in stage 1.0 (TID 42). 1009 bytes result sent to driver
2021-12-03 19:32:55,689 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 20.0 in stage 1.0 (TID 42) in 49958 ms on localhost (executor driver) (13/22)
2021-12-03 19:33:09,880 [Executor task launch worker for task 36] INFO [org.apache.spark.executor.Executor] - Finished task 14.0 in stage 1.0 (TID 36). 1052 bytes result sent to driver
2021-12-03 19:33:09,880 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 14.0 in stage 1.0 (TID 36) in 102150 ms on localhost (executor driver) (14/22)
2021-12-03 19:33:27,320 [Executor task launch worker for task 41] INFO [org.apache.spark.executor.Executor] - Finished task 19.0 in stage 1.0 (TID 41). 1052 bytes result sent to driver
2021-12-03 19:33:27,321 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 19.0 in stage 1.0 (TID 41) in 84371 ms on localhost (executor driver) (15/22)
2021-12-03 19:33:36,322 [Executor task launch worker for task 34] INFO [org.apache.spark.executor.Executor] - Finished task 12.0 in stage 1.0 (TID 34). 1052 bytes result sent to driver
2021-12-03 19:33:36,322 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 12.0 in stage 1.0 (TID 34) in 136187 ms on localhost (executor driver) (16/22)
2021-12-03 19:33:36,790 [Executor task launch worker for task 40] INFO [org.apache.spark.executor.Executor] - Finished task 18.0 in stage 1.0 (TID 40). 1052 bytes result sent to driver
2021-12-03 19:33:36,790 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 18.0 in stage 1.0 (TID 40) in 99887 ms on localhost (executor driver) (17/22)
2021-12-03 19:33:41,760 [Executor task launch worker for task 37] INFO [org.apache.spark.executor.Executor] - Finished task 15.0 in stage 1.0 (TID 37). 1052 bytes result sent to driver
2021-12-03 19:33:41,760 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 15.0 in stage 1.0 (TID 37) in 120831 ms on localhost (executor driver) (18/22)
2021-12-03 19:33:42,541 [Executor task launch worker for task 35] INFO [org.apache.spark.executor.Executor] - Finished task 13.0 in stage 1.0 (TID 35). 1095 bytes result sent to driver
2021-12-03 19:33:42,542 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 13.0 in stage 1.0 (TID 35) in 135260 ms on localhost (executor driver) (19/22)
2021-12-03 19:33:47,653 [Executor task launch worker for task 39] INFO [org.apache.spark.executor.Executor] - Finished task 17.0 in stage 1.0 (TID 39). 1052 bytes result sent to driver
2021-12-03 19:33:47,653 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 17.0 in stage 1.0 (TID 39) in 118169 ms on localhost (executor driver) (20/22)
2021-12-03 19:33:51,229 [Executor task launch worker for task 38] INFO [org.apache.spark.executor.Executor] - Finished task 16.0 in stage 1.0 (TID 38). 1009 bytes result sent to driver
2021-12-03 19:33:51,229 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 16.0 in stage 1.0 (TID 38) in 125289 ms on localhost (executor driver) (21/22)
2021-12-03 19:33:55,270 [Executor task launch worker for task 43] INFO [org.apache.spark.executor.Executor] - Finished task 21.0 in stage 1.0 (TID 43). 1052 bytes result sent to driver
2021-12-03 19:33:55,270 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 21.0 in stage 1.0 (TID 43) in 106834 ms on localhost (executor driver) (22/22)
2021-12-03 19:33:55,270 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 1.0, whose tasks have all completed, from pool 
2021-12-03 19:33:55,270 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ShuffleMapStage 1 (map at PaidPromotionAdjustParameter.scala:67) finished in 266.630 s
2021-12-03 19:33:55,271 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - looking for newly runnable stages
2021-12-03 19:33:55,271 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - running: Set()
2021-12-03 19:33:55,272 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - waiting: Set(ResultStage 2)
2021-12-03 19:33:55,272 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - failed: Set()
2021-12-03 19:33:55,275 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 2 (ShuffledRDD[4] at reduceByKey at PaidPromotionAdjustParameter.scala:67), which has no missing parents
2021-12-03 19:33:55,281 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_3 stored as values in memory (estimated size 3.0 KB, free 1990.5 MB)
2021-12-03 19:33:55,283 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_3_piece0 stored as bytes in memory (estimated size 1906.0 B, free 1990.5 MB)
2021-12-03 19:33:55,283 [dispatcher-event-loop-6] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_3_piece0 in memory on qb:62255 (size: 1906.0 B, free: 1990.8 MB)
2021-12-03 19:33:55,284 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 3 from broadcast at DAGScheduler.scala:1039
2021-12-03 19:33:55,284 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 22 missing tasks from ResultStage 2 (ShuffledRDD[4] at reduceByKey at PaidPromotionAdjustParameter.scala:67) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14))
2021-12-03 19:33:55,284 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 2.0 with 22 tasks
2021-12-03 19:33:55,285 [dispatcher-event-loop-4] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 2.0 (TID 44, localhost, executor driver, partition 0, ANY, 7649 bytes)
2021-12-03 19:33:55,286 [dispatcher-event-loop-4] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 2.0 (TID 45, localhost, executor driver, partition 1, ANY, 7649 bytes)
2021-12-03 19:33:55,286 [dispatcher-event-loop-4] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 2.0 in stage 2.0 (TID 46, localhost, executor driver, partition 2, ANY, 7649 bytes)
2021-12-03 19:33:55,286 [dispatcher-event-loop-4] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 3.0 in stage 2.0 (TID 47, localhost, executor driver, partition 3, ANY, 7649 bytes)
2021-12-03 19:33:55,286 [dispatcher-event-loop-4] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 4.0 in stage 2.0 (TID 48, localhost, executor driver, partition 4, ANY, 7649 bytes)
2021-12-03 19:33:55,286 [dispatcher-event-loop-4] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 5.0 in stage 2.0 (TID 49, localhost, executor driver, partition 5, ANY, 7649 bytes)
2021-12-03 19:33:55,286 [dispatcher-event-loop-4] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 6.0 in stage 2.0 (TID 50, localhost, executor driver, partition 6, ANY, 7649 bytes)
2021-12-03 19:33:55,286 [dispatcher-event-loop-4] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 7.0 in stage 2.0 (TID 51, localhost, executor driver, partition 7, ANY, 7649 bytes)
2021-12-03 19:33:55,286 [dispatcher-event-loop-4] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 8.0 in stage 2.0 (TID 52, localhost, executor driver, partition 8, ANY, 7649 bytes)
2021-12-03 19:33:55,286 [dispatcher-event-loop-4] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 9.0 in stage 2.0 (TID 53, localhost, executor driver, partition 9, ANY, 7649 bytes)
2021-12-03 19:33:55,287 [dispatcher-event-loop-4] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 10.0 in stage 2.0 (TID 54, localhost, executor driver, partition 10, ANY, 7649 bytes)
2021-12-03 19:33:55,287 [dispatcher-event-loop-4] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 11.0 in stage 2.0 (TID 55, localhost, executor driver, partition 11, ANY, 7649 bytes)
2021-12-03 19:33:55,287 [Executor task launch worker for task 44] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 2.0 (TID 44)
2021-12-03 19:33:55,287 [Executor task launch worker for task 47] INFO [org.apache.spark.executor.Executor] - Running task 3.0 in stage 2.0 (TID 47)
2021-12-03 19:33:55,287 [Executor task launch worker for task 50] INFO [org.apache.spark.executor.Executor] - Running task 6.0 in stage 2.0 (TID 50)
2021-12-03 19:33:55,287 [Executor task launch worker for task 51] INFO [org.apache.spark.executor.Executor] - Running task 7.0 in stage 2.0 (TID 51)
2021-12-03 19:33:55,287 [Executor task launch worker for task 48] INFO [org.apache.spark.executor.Executor] - Running task 4.0 in stage 2.0 (TID 48)
2021-12-03 19:33:55,287 [Executor task launch worker for task 49] INFO [org.apache.spark.executor.Executor] - Running task 5.0 in stage 2.0 (TID 49)
2021-12-03 19:33:55,287 [Executor task launch worker for task 46] INFO [org.apache.spark.executor.Executor] - Running task 2.0 in stage 2.0 (TID 46)
2021-12-03 19:33:55,287 [Executor task launch worker for task 45] INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 2.0 (TID 45)
2021-12-03 19:33:55,287 [Executor task launch worker for task 53] INFO [org.apache.spark.executor.Executor] - Running task 9.0 in stage 2.0 (TID 53)
2021-12-03 19:33:55,287 [Executor task launch worker for task 52] INFO [org.apache.spark.executor.Executor] - Running task 8.0 in stage 2.0 (TID 52)
2021-12-03 19:33:55,288 [Executor task launch worker for task 55] INFO [org.apache.spark.executor.Executor] - Running task 11.0 in stage 2.0 (TID 55)
2021-12-03 19:33:55,288 [Executor task launch worker for task 54] INFO [org.apache.spark.executor.Executor] - Running task 10.0 in stage 2.0 (TID 54)
2021-12-03 19:33:55,305 [Executor task launch worker for task 47] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 19:33:55,305 [Executor task launch worker for task 46] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 19:33:55,305 [Executor task launch worker for task 44] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 19:33:55,305 [Executor task launch worker for task 45] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 19:33:55,305 [Executor task launch worker for task 51] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 19:33:55,305 [Executor task launch worker for task 54] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 19:33:55,305 [Executor task launch worker for task 52] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 19:33:55,305 [Executor task launch worker for task 50] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 19:33:55,305 [Executor task launch worker for task 55] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 19:33:55,305 [Executor task launch worker for task 48] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 19:33:55,305 [Executor task launch worker for task 53] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 19:33:55,305 [Executor task launch worker for task 49] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 19:33:55,307 [Executor task launch worker for task 55] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 9 ms
2021-12-03 19:33:55,307 [Executor task launch worker for task 46] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 9 ms
2021-12-03 19:33:55,307 [Executor task launch worker for task 44] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 8 ms
2021-12-03 19:33:55,307 [Executor task launch worker for task 48] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 8 ms
2021-12-03 19:33:55,307 [Executor task launch worker for task 52] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 9 ms
2021-12-03 19:33:55,307 [Executor task launch worker for task 47] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 9 ms
2021-12-03 19:33:55,307 [Executor task launch worker for task 50] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 9 ms
2021-12-03 19:33:55,307 [Executor task launch worker for task 53] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 9 ms
2021-12-03 19:33:55,307 [Executor task launch worker for task 51] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 8 ms
2021-12-03 19:33:55,307 [Executor task launch worker for task 45] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 9 ms
2021-12-03 19:33:55,307 [Executor task launch worker for task 54] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 9 ms
2021-12-03 19:33:55,307 [Executor task launch worker for task 49] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 8 ms
2021-12-03 19:33:55,697 [Executor task launch worker for task 52] INFO [org.apache.spark.executor.Executor] - Finished task 8.0 in stage 2.0 (TID 52). 1098 bytes result sent to driver
2021-12-03 19:33:55,697 [Executor task launch worker for task 49] INFO [org.apache.spark.executor.Executor] - Finished task 5.0 in stage 2.0 (TID 49). 1098 bytes result sent to driver
2021-12-03 19:33:55,697 [Executor task launch worker for task 45] INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 2.0 (TID 45). 1098 bytes result sent to driver
2021-12-03 19:33:55,698 [dispatcher-event-loop-9] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 12.0 in stage 2.0 (TID 56, localhost, executor driver, partition 12, ANY, 7649 bytes)
2021-12-03 19:33:55,698 [Executor task launch worker for task 53] INFO [org.apache.spark.executor.Executor] - Finished task 9.0 in stage 2.0 (TID 53). 1098 bytes result sent to driver
2021-12-03 19:33:55,698 [dispatcher-event-loop-9] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 13.0 in stage 2.0 (TID 57, localhost, executor driver, partition 13, ANY, 7649 bytes)
2021-12-03 19:33:55,698 [dispatcher-event-loop-9] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 14.0 in stage 2.0 (TID 58, localhost, executor driver, partition 14, ANY, 7649 bytes)
2021-12-03 19:33:55,698 [dispatcher-event-loop-9] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 15.0 in stage 2.0 (TID 59, localhost, executor driver, partition 15, ANY, 7649 bytes)
2021-12-03 19:33:55,699 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 8.0 in stage 2.0 (TID 52) in 412 ms on localhost (executor driver) (1/22)
2021-12-03 19:33:55,699 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 5.0 in stage 2.0 (TID 49) in 413 ms on localhost (executor driver) (2/22)
2021-12-03 19:33:55,699 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 2.0 (TID 45) in 413 ms on localhost (executor driver) (3/22)
2021-12-03 19:33:55,699 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 9.0 in stage 2.0 (TID 53) in 413 ms on localhost (executor driver) (4/22)
2021-12-03 19:33:55,699 [Executor task launch worker for task 59] INFO [org.apache.spark.executor.Executor] - Running task 15.0 in stage 2.0 (TID 59)
2021-12-03 19:33:55,699 [Executor task launch worker for task 58] INFO [org.apache.spark.executor.Executor] - Running task 14.0 in stage 2.0 (TID 58)
2021-12-03 19:33:55,700 [Executor task launch worker for task 59] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 19:33:55,700 [Executor task launch worker for task 56] INFO [org.apache.spark.executor.Executor] - Running task 12.0 in stage 2.0 (TID 56)
2021-12-03 19:33:55,700 [Executor task launch worker for task 57] INFO [org.apache.spark.executor.Executor] - Running task 13.0 in stage 2.0 (TID 57)
2021-12-03 19:33:55,701 [Executor task launch worker for task 55] INFO [org.apache.spark.executor.Executor] - Finished task 11.0 in stage 2.0 (TID 55). 1055 bytes result sent to driver
2021-12-03 19:33:55,701 [Executor task launch worker for task 58] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 19:33:55,701 [Executor task launch worker for task 58] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 1 ms
2021-12-03 19:33:55,701 [Executor task launch worker for task 59] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 19:33:55,701 [Executor task launch worker for task 46] INFO [org.apache.spark.executor.Executor] - Finished task 2.0 in stage 2.0 (TID 46). 1098 bytes result sent to driver
2021-12-03 19:33:55,701 [Executor task launch worker for task 56] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 19:33:55,701 [Executor task launch worker for task 56] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 19:33:55,701 [dispatcher-event-loop-4] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 16.0 in stage 2.0 (TID 60, localhost, executor driver, partition 16, ANY, 7649 bytes)
2021-12-03 19:33:55,702 [Executor task launch worker for task 57] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 19:33:55,702 [Executor task launch worker for task 57] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 1 ms
2021-12-03 19:33:55,702 [Executor task launch worker for task 60] INFO [org.apache.spark.executor.Executor] - Running task 16.0 in stage 2.0 (TID 60)
2021-12-03 19:33:55,702 [Executor task launch worker for task 50] INFO [org.apache.spark.executor.Executor] - Finished task 6.0 in stage 2.0 (TID 50). 1098 bytes result sent to driver
2021-12-03 19:33:55,702 [Executor task launch worker for task 47] INFO [org.apache.spark.executor.Executor] - Finished task 3.0 in stage 2.0 (TID 47). 1098 bytes result sent to driver
2021-12-03 19:33:55,702 [dispatcher-event-loop-4] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 17.0 in stage 2.0 (TID 61, localhost, executor driver, partition 17, ANY, 7649 bytes)
2021-12-03 19:33:55,702 [dispatcher-event-loop-4] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 18.0 in stage 2.0 (TID 62, localhost, executor driver, partition 18, ANY, 7649 bytes)
2021-12-03 19:33:55,702 [Executor task launch worker for task 60] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 19:33:55,702 [Executor task launch worker for task 60] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 19:33:55,702 [Executor task launch worker for task 61] INFO [org.apache.spark.executor.Executor] - Running task 17.0 in stage 2.0 (TID 61)
2021-12-03 19:33:55,703 [dispatcher-event-loop-4] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 19.0 in stage 2.0 (TID 63, localhost, executor driver, partition 19, ANY, 7649 bytes)
2021-12-03 19:33:55,703 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 3.0 in stage 2.0 (TID 47) in 417 ms on localhost (executor driver) (5/22)
2021-12-03 19:33:55,703 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 11.0 in stage 2.0 (TID 55) in 416 ms on localhost (executor driver) (6/22)
2021-12-03 19:33:55,703 [Executor task launch worker for task 62] INFO [org.apache.spark.executor.Executor] - Running task 18.0 in stage 2.0 (TID 62)
2021-12-03 19:33:55,703 [Executor task launch worker for task 63] INFO [org.apache.spark.executor.Executor] - Running task 19.0 in stage 2.0 (TID 63)
2021-12-03 19:33:55,703 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 6.0 in stage 2.0 (TID 50) in 417 ms on localhost (executor driver) (7/22)
2021-12-03 19:33:55,703 [Executor task launch worker for task 61] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 19:33:55,703 [Executor task launch worker for task 61] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 19:33:55,703 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 2.0 in stage 2.0 (TID 46) in 417 ms on localhost (executor driver) (8/22)
2021-12-03 19:33:55,705 [Executor task launch worker for task 63] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 19:33:55,705 [Executor task launch worker for task 63] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 19:33:55,705 [Executor task launch worker for task 62] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 19:33:55,707 [Executor task launch worker for task 62] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 2 ms
2021-12-03 19:33:55,707 [Executor task launch worker for task 54] INFO [org.apache.spark.executor.Executor] - Finished task 10.0 in stage 2.0 (TID 54). 1055 bytes result sent to driver
2021-12-03 19:33:55,707 [Executor task launch worker for task 44] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 2.0 (TID 44). 1055 bytes result sent to driver
2021-12-03 19:33:55,707 [Executor task launch worker for task 51] INFO [org.apache.spark.executor.Executor] - Finished task 7.0 in stage 2.0 (TID 51). 1098 bytes result sent to driver
2021-12-03 19:33:55,708 [Executor task launch worker for task 48] INFO [org.apache.spark.executor.Executor] - Finished task 4.0 in stage 2.0 (TID 48). 1098 bytes result sent to driver
2021-12-03 19:33:55,708 [dispatcher-event-loop-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 20.0 in stage 2.0 (TID 64, localhost, executor driver, partition 20, ANY, 7649 bytes)
2021-12-03 19:33:55,708 [Executor task launch worker for task 64] INFO [org.apache.spark.executor.Executor] - Running task 20.0 in stage 2.0 (TID 64)
2021-12-03 19:33:55,708 [dispatcher-event-loop-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 21.0 in stage 2.0 (TID 65, localhost, executor driver, partition 21, ANY, 7649 bytes)
2021-12-03 19:33:55,709 [Executor task launch worker for task 65] INFO [org.apache.spark.executor.Executor] - Running task 21.0 in stage 2.0 (TID 65)
2021-12-03 19:33:55,709 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 7.0 in stage 2.0 (TID 51) in 423 ms on localhost (executor driver) (9/22)
2021-12-03 19:33:55,709 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 4.0 in stage 2.0 (TID 48) in 423 ms on localhost (executor driver) (10/22)
2021-12-03 19:33:55,709 [Executor task launch worker for task 64] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 19:33:55,709 [Executor task launch worker for task 65] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 19:33:55,709 [Executor task launch worker for task 65] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 19:33:55,710 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 10.0 in stage 2.0 (TID 54) in 424 ms on localhost (executor driver) (11/22)
2021-12-03 19:33:55,709 [Executor task launch worker for task 64] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 19:33:55,710 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 2.0 (TID 44) in 426 ms on localhost (executor driver) (12/22)
2021-12-03 19:33:55,807 [Executor task launch worker for task 60] INFO [org.apache.spark.executor.Executor] - Finished task 16.0 in stage 2.0 (TID 60). 1012 bytes result sent to driver
2021-12-03 19:33:55,810 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 16.0 in stage 2.0 (TID 60) in 109 ms on localhost (executor driver) (13/22)
2021-12-03 19:33:55,821 [Executor task launch worker for task 57] INFO [org.apache.spark.executor.Executor] - Finished task 13.0 in stage 2.0 (TID 57). 1055 bytes result sent to driver
2021-12-03 19:33:55,822 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 13.0 in stage 2.0 (TID 57) in 123 ms on localhost (executor driver) (14/22)
2021-12-03 19:33:55,827 [Executor task launch worker for task 58] INFO [org.apache.spark.executor.Executor] - Finished task 14.0 in stage 2.0 (TID 58). 1055 bytes result sent to driver
2021-12-03 19:33:55,829 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 14.0 in stage 2.0 (TID 58) in 131 ms on localhost (executor driver) (15/22)
2021-12-03 19:33:55,830 [Executor task launch worker for task 61] INFO [org.apache.spark.executor.Executor] - Finished task 17.0 in stage 2.0 (TID 61). 1012 bytes result sent to driver
2021-12-03 19:33:55,830 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 17.0 in stage 2.0 (TID 61) in 128 ms on localhost (executor driver) (16/22)
2021-12-03 19:33:55,832 [Executor task launch worker for task 65] INFO [org.apache.spark.executor.Executor] - Finished task 21.0 in stage 2.0 (TID 65). 1012 bytes result sent to driver
2021-12-03 19:33:55,833 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 21.0 in stage 2.0 (TID 65) in 125 ms on localhost (executor driver) (17/22)
2021-12-03 19:33:55,835 [Executor task launch worker for task 59] INFO [org.apache.spark.executor.Executor] - Finished task 15.0 in stage 2.0 (TID 59). 1012 bytes result sent to driver
2021-12-03 19:33:55,835 [Executor task launch worker for task 64] INFO [org.apache.spark.executor.Executor] - Finished task 20.0 in stage 2.0 (TID 64). 1055 bytes result sent to driver
2021-12-03 19:33:55,836 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 15.0 in stage 2.0 (TID 59) in 138 ms on localhost (executor driver) (18/22)
2021-12-03 19:33:55,836 [Executor task launch worker for task 56] INFO [org.apache.spark.executor.Executor] - Finished task 12.0 in stage 2.0 (TID 56). 1055 bytes result sent to driver
2021-12-03 19:33:55,836 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 20.0 in stage 2.0 (TID 64) in 128 ms on localhost (executor driver) (19/22)
2021-12-03 19:33:55,836 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 12.0 in stage 2.0 (TID 56) in 139 ms on localhost (executor driver) (20/22)
2021-12-03 19:33:55,837 [Executor task launch worker for task 63] INFO [org.apache.spark.executor.Executor] - Finished task 19.0 in stage 2.0 (TID 63). 1012 bytes result sent to driver
2021-12-03 19:33:55,837 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 19.0 in stage 2.0 (TID 63) in 135 ms on localhost (executor driver) (21/22)
2021-12-03 19:33:55,845 [Executor task launch worker for task 62] INFO [org.apache.spark.executor.Executor] - Finished task 18.0 in stage 2.0 (TID 62). 1098 bytes result sent to driver
2021-12-03 19:33:55,846 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 18.0 in stage 2.0 (TID 62) in 144 ms on localhost (executor driver) (22/22)
2021-12-03 19:33:55,846 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 2.0, whose tasks have all completed, from pool 
2021-12-03 19:33:55,846 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 2 (count at PaidPromotionAdjustParameter.scala:68) finished in 0.567 s
2021-12-03 19:33:55,846 [main] INFO [org.apache.spark.scheduler.DAGScheduler] - Job 1 finished: count at PaidPromotionAdjustParameter.scala:68, took 267.217297 s
2021-12-03 19:33:55,865 [main] INFO [org.apache.spark.SparkContext] - Starting job: sortByKey at PaidPromotionAdjustParameter.scala:72
2021-12-03 19:33:55,866 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 2 (sortByKey at PaidPromotionAdjustParameter.scala:72) with 22 output partitions
2021-12-03 19:33:55,866 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 4 (sortByKey at PaidPromotionAdjustParameter.scala:72)
2021-12-03 19:33:55,866 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 3)
2021-12-03 19:33:55,866 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2021-12-03 19:33:55,866 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 4 (MapPartitionsRDD[7] at sortByKey at PaidPromotionAdjustParameter.scala:72), which has no missing parents
2021-12-03 19:33:55,868 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_4 stored as values in memory (estimated size 4.1 KB, free 1990.5 MB)
2021-12-03 19:33:55,870 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_4_piece0 stored as bytes in memory (estimated size 2.4 KB, free 1990.4 MB)
2021-12-03 19:33:55,870 [dispatcher-event-loop-3] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_4_piece0 in memory on qb:62255 (size: 2.4 KB, free: 1990.8 MB)
2021-12-03 19:33:55,870 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 4 from broadcast at DAGScheduler.scala:1039
2021-12-03 19:33:55,871 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 22 missing tasks from ResultStage 4 (MapPartitionsRDD[7] at sortByKey at PaidPromotionAdjustParameter.scala:72) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14))
2021-12-03 19:33:55,871 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 4.0 with 22 tasks
2021-12-03 19:33:55,871 [dispatcher-event-loop-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 4.0 (TID 66, localhost, executor driver, partition 0, ANY, 7649 bytes)
2021-12-03 19:33:55,871 [dispatcher-event-loop-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 4.0 (TID 67, localhost, executor driver, partition 1, ANY, 7649 bytes)
2021-12-03 19:33:55,871 [dispatcher-event-loop-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 2.0 in stage 4.0 (TID 68, localhost, executor driver, partition 2, ANY, 7649 bytes)
2021-12-03 19:33:55,871 [dispatcher-event-loop-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 3.0 in stage 4.0 (TID 69, localhost, executor driver, partition 3, ANY, 7649 bytes)
2021-12-03 19:33:55,872 [dispatcher-event-loop-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 4.0 in stage 4.0 (TID 70, localhost, executor driver, partition 4, ANY, 7649 bytes)
2021-12-03 19:33:55,872 [dispatcher-event-loop-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 5.0 in stage 4.0 (TID 71, localhost, executor driver, partition 5, ANY, 7649 bytes)
2021-12-03 19:33:55,872 [dispatcher-event-loop-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 6.0 in stage 4.0 (TID 72, localhost, executor driver, partition 6, ANY, 7649 bytes)
2021-12-03 19:33:55,872 [dispatcher-event-loop-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 7.0 in stage 4.0 (TID 73, localhost, executor driver, partition 7, ANY, 7649 bytes)
2021-12-03 19:33:55,872 [dispatcher-event-loop-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 8.0 in stage 4.0 (TID 74, localhost, executor driver, partition 8, ANY, 7649 bytes)
2021-12-03 19:33:55,872 [dispatcher-event-loop-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 9.0 in stage 4.0 (TID 75, localhost, executor driver, partition 9, ANY, 7649 bytes)
2021-12-03 19:33:55,872 [dispatcher-event-loop-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 10.0 in stage 4.0 (TID 76, localhost, executor driver, partition 10, ANY, 7649 bytes)
2021-12-03 19:33:55,872 [dispatcher-event-loop-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 11.0 in stage 4.0 (TID 77, localhost, executor driver, partition 11, ANY, 7649 bytes)
2021-12-03 19:33:55,872 [Executor task launch worker for task 66] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 4.0 (TID 66)
2021-12-03 19:33:55,872 [Executor task launch worker for task 67] INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 4.0 (TID 67)
2021-12-03 19:33:55,872 [Executor task launch worker for task 75] INFO [org.apache.spark.executor.Executor] - Running task 9.0 in stage 4.0 (TID 75)
2021-12-03 19:33:55,872 [Executor task launch worker for task 72] INFO [org.apache.spark.executor.Executor] - Running task 6.0 in stage 4.0 (TID 72)
2021-12-03 19:33:55,872 [Executor task launch worker for task 69] INFO [org.apache.spark.executor.Executor] - Running task 3.0 in stage 4.0 (TID 69)
2021-12-03 19:33:55,872 [Executor task launch worker for task 71] INFO [org.apache.spark.executor.Executor] - Running task 5.0 in stage 4.0 (TID 71)
2021-12-03 19:33:55,872 [Executor task launch worker for task 68] INFO [org.apache.spark.executor.Executor] - Running task 2.0 in stage 4.0 (TID 68)
2021-12-03 19:33:55,872 [Executor task launch worker for task 70] INFO [org.apache.spark.executor.Executor] - Running task 4.0 in stage 4.0 (TID 70)
2021-12-03 19:33:55,872 [Executor task launch worker for task 76] INFO [org.apache.spark.executor.Executor] - Running task 10.0 in stage 4.0 (TID 76)
2021-12-03 19:33:55,872 [Executor task launch worker for task 74] INFO [org.apache.spark.executor.Executor] - Running task 8.0 in stage 4.0 (TID 74)
2021-12-03 19:33:55,872 [Executor task launch worker for task 73] INFO [org.apache.spark.executor.Executor] - Running task 7.0 in stage 4.0 (TID 73)
2021-12-03 19:33:55,872 [Executor task launch worker for task 77] INFO [org.apache.spark.executor.Executor] - Running task 11.0 in stage 4.0 (TID 77)
2021-12-03 19:33:55,873 [Executor task launch worker for task 76] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 19:33:55,874 [Executor task launch worker for task 76] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 1 ms
2021-12-03 19:33:55,874 [Executor task launch worker for task 74] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 19:33:55,874 [Executor task launch worker for task 74] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 19:33:55,874 [Executor task launch worker for task 75] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 19:33:55,874 [Executor task launch worker for task 75] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 19:33:55,874 [Executor task launch worker for task 67] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 19:33:55,874 [Executor task launch worker for task 67] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 19:33:55,874 [Executor task launch worker for task 72] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 19:33:55,874 [Executor task launch worker for task 72] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 19:33:55,874 [Executor task launch worker for task 70] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 19:33:55,874 [Executor task launch worker for task 70] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 19:33:55,874 [Executor task launch worker for task 66] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 19:33:55,874 [Executor task launch worker for task 66] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 19:33:55,874 [Executor task launch worker for task 73] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 19:33:55,874 [Executor task launch worker for task 73] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 19:33:55,875 [Executor task launch worker for task 68] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 19:33:55,875 [Executor task launch worker for task 68] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 1 ms
2021-12-03 19:33:55,875 [Executor task launch worker for task 69] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 19:33:55,875 [Executor task launch worker for task 69] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 19:33:55,875 [Executor task launch worker for task 77] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 19:33:55,875 [Executor task launch worker for task 77] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 19:33:55,875 [Executor task launch worker for task 71] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 19:33:55,875 [Executor task launch worker for task 71] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 19:33:55,991 [Executor task launch worker for task 74] INFO [org.apache.spark.executor.Executor] - Finished task 8.0 in stage 4.0 (TID 74). 1144 bytes result sent to driver
2021-12-03 19:33:55,991 [Executor task launch worker for task 75] INFO [org.apache.spark.executor.Executor] - Finished task 9.0 in stage 4.0 (TID 75). 1149 bytes result sent to driver
2021-12-03 19:33:55,992 [dispatcher-event-loop-9] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 12.0 in stage 4.0 (TID 78, localhost, executor driver, partition 12, ANY, 7649 bytes)
2021-12-03 19:33:55,992 [Executor task launch worker for task 78] INFO [org.apache.spark.executor.Executor] - Running task 12.0 in stage 4.0 (TID 78)
2021-12-03 19:33:55,992 [dispatcher-event-loop-9] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 13.0 in stage 4.0 (TID 79, localhost, executor driver, partition 13, ANY, 7649 bytes)
2021-12-03 19:33:55,992 [Executor task launch worker for task 69] INFO [org.apache.spark.executor.Executor] - Finished task 3.0 in stage 4.0 (TID 69). 1098 bytes result sent to driver
2021-12-03 19:33:55,992 [Executor task launch worker for task 76] INFO [org.apache.spark.executor.Executor] - Finished task 10.0 in stage 4.0 (TID 76). 1144 bytes result sent to driver
2021-12-03 19:33:55,993 [Executor task launch worker for task 72] INFO [org.apache.spark.executor.Executor] - Finished task 6.0 in stage 4.0 (TID 72). 1138 bytes result sent to driver
2021-12-03 19:33:55,993 [dispatcher-event-loop-6] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 14.0 in stage 4.0 (TID 80, localhost, executor driver, partition 14, ANY, 7649 bytes)
2021-12-03 19:33:55,993 [Executor task launch worker for task 79] INFO [org.apache.spark.executor.Executor] - Running task 13.0 in stage 4.0 (TID 79)
2021-12-03 19:33:55,993 [Executor task launch worker for task 80] INFO [org.apache.spark.executor.Executor] - Running task 14.0 in stage 4.0 (TID 80)
2021-12-03 19:33:55,993 [dispatcher-event-loop-6] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 15.0 in stage 4.0 (TID 81, localhost, executor driver, partition 15, ANY, 7649 bytes)
2021-12-03 19:33:55,993 [Executor task launch worker for task 81] INFO [org.apache.spark.executor.Executor] - Running task 15.0 in stage 4.0 (TID 81)
2021-12-03 19:33:55,993 [dispatcher-event-loop-6] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 16.0 in stage 4.0 (TID 82, localhost, executor driver, partition 16, ANY, 7649 bytes)
2021-12-03 19:33:55,993 [Executor task launch worker for task 78] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 19:33:55,993 [Executor task launch worker for task 78] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 19:33:55,993 [Executor task launch worker for task 82] INFO [org.apache.spark.executor.Executor] - Running task 16.0 in stage 4.0 (TID 82)
2021-12-03 19:33:55,994 [Executor task launch worker for task 67] INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 4.0 (TID 67). 1140 bytes result sent to driver
2021-12-03 19:33:55,994 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 8.0 in stage 4.0 (TID 74) in 122 ms on localhost (executor driver) (1/22)
2021-12-03 19:33:55,994 [Executor task launch worker for task 81] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 19:33:55,994 [Executor task launch worker for task 81] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 19:33:55,994 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 3.0 in stage 4.0 (TID 69) in 123 ms on localhost (executor driver) (2/22)
2021-12-03 19:33:55,994 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 6.0 in stage 4.0 (TID 72) in 122 ms on localhost (executor driver) (3/22)
2021-12-03 19:33:55,994 [Executor task launch worker for task 80] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 19:33:55,994 [Executor task launch worker for task 80] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 19:33:55,994 [Executor task launch worker for task 79] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 19:33:55,994 [Executor task launch worker for task 79] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 19:33:55,995 [Executor task launch worker for task 82] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 19:33:55,995 [Executor task launch worker for task 82] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 1 ms
2021-12-03 19:33:55,995 [dispatcher-event-loop-11] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 17.0 in stage 4.0 (TID 83, localhost, executor driver, partition 17, ANY, 7649 bytes)
2021-12-03 19:33:55,995 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 4.0 (TID 67) in 124 ms on localhost (executor driver) (4/22)
2021-12-03 19:33:55,995 [Executor task launch worker for task 83] INFO [org.apache.spark.executor.Executor] - Running task 17.0 in stage 4.0 (TID 83)
2021-12-03 19:33:55,995 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 9.0 in stage 4.0 (TID 75) in 123 ms on localhost (executor driver) (5/22)
2021-12-03 19:33:55,995 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 10.0 in stage 4.0 (TID 76) in 123 ms on localhost (executor driver) (6/22)
2021-12-03 19:33:55,996 [Executor task launch worker for task 83] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 19:33:55,996 [Executor task launch worker for task 83] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 19:33:56,002 [Executor task launch worker for task 71] INFO [org.apache.spark.executor.Executor] - Finished task 5.0 in stage 4.0 (TID 71). 1103 bytes result sent to driver
2021-12-03 19:33:56,003 [dispatcher-event-loop-4] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 18.0 in stage 4.0 (TID 84, localhost, executor driver, partition 18, ANY, 7649 bytes)
2021-12-03 19:33:56,003 [Executor task launch worker for task 84] INFO [org.apache.spark.executor.Executor] - Running task 18.0 in stage 4.0 (TID 84)
2021-12-03 19:33:56,004 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 5.0 in stage 4.0 (TID 71) in 132 ms on localhost (executor driver) (7/22)
2021-12-03 19:33:56,005 [Executor task launch worker for task 84] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 19:33:56,005 [Executor task launch worker for task 84] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 1 ms
2021-12-03 19:33:56,011 [Executor task launch worker for task 66] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 4.0 (TID 66). 1102 bytes result sent to driver
2021-12-03 19:33:56,012 [dispatcher-event-loop-6] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 19.0 in stage 4.0 (TID 85, localhost, executor driver, partition 19, ANY, 7649 bytes)
2021-12-03 19:33:56,012 [Executor task launch worker for task 73] INFO [org.apache.spark.executor.Executor] - Finished task 7.0 in stage 4.0 (TID 73). 1143 bytes result sent to driver
2021-12-03 19:33:56,012 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 4.0 (TID 66) in 141 ms on localhost (executor driver) (8/22)
2021-12-03 19:33:56,013 [Executor task launch worker for task 85] INFO [org.apache.spark.executor.Executor] - Running task 19.0 in stage 4.0 (TID 85)
2021-12-03 19:33:56,014 [Executor task launch worker for task 70] INFO [org.apache.spark.executor.Executor] - Finished task 4.0 in stage 4.0 (TID 70). 1144 bytes result sent to driver
2021-12-03 19:33:56,014 [Executor task launch worker for task 85] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 19:33:56,014 [dispatcher-event-loop-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 20.0 in stage 4.0 (TID 86, localhost, executor driver, partition 20, ANY, 7649 bytes)
2021-12-03 19:33:56,014 [Executor task launch worker for task 85] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 19:33:56,014 [Executor task launch worker for task 86] INFO [org.apache.spark.executor.Executor] - Running task 20.0 in stage 4.0 (TID 86)
2021-12-03 19:33:56,014 [dispatcher-event-loop-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 21.0 in stage 4.0 (TID 87, localhost, executor driver, partition 21, ANY, 7649 bytes)
2021-12-03 19:33:56,014 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 7.0 in stage 4.0 (TID 73) in 142 ms on localhost (executor driver) (9/22)
2021-12-03 19:33:56,014 [Executor task launch worker for task 87] INFO [org.apache.spark.executor.Executor] - Running task 21.0 in stage 4.0 (TID 87)
2021-12-03 19:33:56,014 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 4.0 in stage 4.0 (TID 70) in 143 ms on localhost (executor driver) (10/22)
2021-12-03 19:33:56,015 [Executor task launch worker for task 86] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 19:33:56,015 [Executor task launch worker for task 86] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 19:33:56,015 [Executor task launch worker for task 87] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 19:33:56,015 [Executor task launch worker for task 87] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 19:33:56,016 [Executor task launch worker for task 77] INFO [org.apache.spark.executor.Executor] - Finished task 11.0 in stage 4.0 (TID 77). 1142 bytes result sent to driver
2021-12-03 19:33:56,017 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 11.0 in stage 4.0 (TID 77) in 145 ms on localhost (executor driver) (11/22)
2021-12-03 19:33:56,044 [Executor task launch worker for task 68] INFO [org.apache.spark.executor.Executor] - Finished task 2.0 in stage 4.0 (TID 68). 1146 bytes result sent to driver
2021-12-03 19:33:56,049 [dispatcher-event-loop-4] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_3_piece0 on qb:62255 in memory (size: 1906.0 B, free: 1990.8 MB)
2021-12-03 19:33:56,049 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 2.0 in stage 4.0 (TID 68) in 178 ms on localhost (executor driver) (12/22)
2021-12-03 19:33:56,098 [Executor task launch worker for task 81] INFO [org.apache.spark.executor.Executor] - Finished task 15.0 in stage 4.0 (TID 81). 1137 bytes result sent to driver
2021-12-03 19:33:56,099 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 15.0 in stage 4.0 (TID 81) in 106 ms on localhost (executor driver) (13/22)
2021-12-03 19:33:56,108 [Executor task launch worker for task 80] INFO [org.apache.spark.executor.Executor] - Finished task 14.0 in stage 4.0 (TID 80). 1142 bytes result sent to driver
2021-12-03 19:33:56,109 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 14.0 in stage 4.0 (TID 80) in 117 ms on localhost (executor driver) (14/22)
2021-12-03 19:33:56,109 [Executor task launch worker for task 84] INFO [org.apache.spark.executor.Executor] - Finished task 18.0 in stage 4.0 (TID 84). 1137 bytes result sent to driver
2021-12-03 19:33:56,109 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 18.0 in stage 4.0 (TID 84) in 106 ms on localhost (executor driver) (15/22)
2021-12-03 19:33:56,112 [Executor task launch worker for task 79] INFO [org.apache.spark.executor.Executor] - Finished task 13.0 in stage 4.0 (TID 79). 1184 bytes result sent to driver
2021-12-03 19:33:56,113 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 13.0 in stage 4.0 (TID 79) in 121 ms on localhost (executor driver) (16/22)
2021-12-03 19:33:56,116 [Executor task launch worker for task 83] INFO [org.apache.spark.executor.Executor] - Finished task 17.0 in stage 4.0 (TID 83). 1185 bytes result sent to driver
2021-12-03 19:33:56,116 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 17.0 in stage 4.0 (TID 83) in 121 ms on localhost (executor driver) (17/22)
2021-12-03 19:33:56,116 [Executor task launch worker for task 82] INFO [org.apache.spark.executor.Executor] - Finished task 16.0 in stage 4.0 (TID 82). 1186 bytes result sent to driver
2021-12-03 19:33:56,117 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 16.0 in stage 4.0 (TID 82) in 124 ms on localhost (executor driver) (18/22)
2021-12-03 19:33:56,119 [Executor task launch worker for task 85] INFO [org.apache.spark.executor.Executor] - Finished task 19.0 in stage 4.0 (TID 85). 1146 bytes result sent to driver
2021-12-03 19:33:56,119 [Executor task launch worker for task 78] INFO [org.apache.spark.executor.Executor] - Finished task 12.0 in stage 4.0 (TID 78). 1142 bytes result sent to driver
2021-12-03 19:33:56,120 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 19.0 in stage 4.0 (TID 85) in 108 ms on localhost (executor driver) (19/22)
2021-12-03 19:33:56,120 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 12.0 in stage 4.0 (TID 78) in 128 ms on localhost (executor driver) (20/22)
2021-12-03 19:33:56,121 [Executor task launch worker for task 87] INFO [org.apache.spark.executor.Executor] - Finished task 21.0 in stage 4.0 (TID 87). 1187 bytes result sent to driver
2021-12-03 19:33:56,121 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 21.0 in stage 4.0 (TID 87) in 107 ms on localhost (executor driver) (21/22)
2021-12-03 19:33:56,124 [Executor task launch worker for task 86] INFO [org.apache.spark.executor.Executor] - Finished task 20.0 in stage 4.0 (TID 86). 1146 bytes result sent to driver
2021-12-03 19:33:56,125 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 20.0 in stage 4.0 (TID 86) in 112 ms on localhost (executor driver) (22/22)
2021-12-03 19:33:56,125 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 4.0, whose tasks have all completed, from pool 
2021-12-03 19:33:56,125 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 4 (sortByKey at PaidPromotionAdjustParameter.scala:72) finished in 0.257 s
2021-12-03 19:33:56,125 [main] INFO [org.apache.spark.scheduler.DAGScheduler] - Job 2 finished: sortByKey at PaidPromotionAdjustParameter.scala:72, took 0.260007 s
2021-12-03 19:33:56,138 [main] INFO [org.apache.spark.SparkContext] - Starting job: zipWithIndex at PaidPromotionAdjustParameter.scala:73
2021-12-03 19:33:56,139 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 5 (map at PaidPromotionAdjustParameter.scala:71)
2021-12-03 19:33:56,139 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 3 (zipWithIndex at PaidPromotionAdjustParameter.scala:73) with 21 output partitions
2021-12-03 19:33:56,139 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 7 (zipWithIndex at PaidPromotionAdjustParameter.scala:73)
2021-12-03 19:33:56,139 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 6)
2021-12-03 19:33:56,139 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List(ShuffleMapStage 6)
2021-12-03 19:33:56,139 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ShuffleMapStage 6 (MapPartitionsRDD[5] at map at PaidPromotionAdjustParameter.scala:71), which has no missing parents
2021-12-03 19:33:56,144 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_5 stored as values in memory (estimated size 4.1 KB, free 1990.5 MB)
2021-12-03 19:33:56,146 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_5_piece0 stored as bytes in memory (estimated size 2.4 KB, free 1990.4 MB)
2021-12-03 19:33:56,146 [dispatcher-event-loop-2] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_5_piece0 in memory on qb:62255 (size: 2.4 KB, free: 1990.8 MB)
2021-12-03 19:33:56,147 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 5 from broadcast at DAGScheduler.scala:1039
2021-12-03 19:33:56,147 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 22 missing tasks from ShuffleMapStage 6 (MapPartitionsRDD[5] at map at PaidPromotionAdjustParameter.scala:71) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14))
2021-12-03 19:33:56,147 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 6.0 with 22 tasks
2021-12-03 19:33:56,148 [dispatcher-event-loop-4] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 6.0 (TID 88, localhost, executor driver, partition 0, ANY, 7638 bytes)
2021-12-03 19:33:56,148 [dispatcher-event-loop-4] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 6.0 (TID 89, localhost, executor driver, partition 1, ANY, 7638 bytes)
2021-12-03 19:33:56,148 [dispatcher-event-loop-4] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 2.0 in stage 6.0 (TID 90, localhost, executor driver, partition 2, ANY, 7638 bytes)
2021-12-03 19:33:56,148 [dispatcher-event-loop-4] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 3.0 in stage 6.0 (TID 91, localhost, executor driver, partition 3, ANY, 7638 bytes)
2021-12-03 19:33:56,148 [dispatcher-event-loop-4] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 4.0 in stage 6.0 (TID 92, localhost, executor driver, partition 4, ANY, 7638 bytes)
2021-12-03 19:33:56,148 [dispatcher-event-loop-4] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 5.0 in stage 6.0 (TID 93, localhost, executor driver, partition 5, ANY, 7638 bytes)
2021-12-03 19:33:56,148 [dispatcher-event-loop-4] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 6.0 in stage 6.0 (TID 94, localhost, executor driver, partition 6, ANY, 7638 bytes)
2021-12-03 19:33:56,148 [dispatcher-event-loop-4] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 7.0 in stage 6.0 (TID 95, localhost, executor driver, partition 7, ANY, 7638 bytes)
2021-12-03 19:33:56,148 [dispatcher-event-loop-4] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 8.0 in stage 6.0 (TID 96, localhost, executor driver, partition 8, ANY, 7638 bytes)
2021-12-03 19:33:56,148 [dispatcher-event-loop-4] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 9.0 in stage 6.0 (TID 97, localhost, executor driver, partition 9, ANY, 7638 bytes)
2021-12-03 19:33:56,149 [dispatcher-event-loop-4] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 10.0 in stage 6.0 (TID 98, localhost, executor driver, partition 10, ANY, 7638 bytes)
2021-12-03 19:33:56,149 [dispatcher-event-loop-4] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 11.0 in stage 6.0 (TID 99, localhost, executor driver, partition 11, ANY, 7638 bytes)
2021-12-03 19:33:56,149 [Executor task launch worker for task 89] INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 6.0 (TID 89)
2021-12-03 19:33:56,149 [Executor task launch worker for task 88] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 6.0 (TID 88)
2021-12-03 19:33:56,149 [Executor task launch worker for task 98] INFO [org.apache.spark.executor.Executor] - Running task 10.0 in stage 6.0 (TID 98)
2021-12-03 19:33:56,149 [Executor task launch worker for task 99] INFO [org.apache.spark.executor.Executor] - Running task 11.0 in stage 6.0 (TID 99)
2021-12-03 19:33:56,149 [Executor task launch worker for task 93] INFO [org.apache.spark.executor.Executor] - Running task 5.0 in stage 6.0 (TID 93)
2021-12-03 19:33:56,149 [Executor task launch worker for task 90] INFO [org.apache.spark.executor.Executor] - Running task 2.0 in stage 6.0 (TID 90)
2021-12-03 19:33:56,149 [Executor task launch worker for task 91] INFO [org.apache.spark.executor.Executor] - Running task 3.0 in stage 6.0 (TID 91)
2021-12-03 19:33:56,149 [Executor task launch worker for task 92] INFO [org.apache.spark.executor.Executor] - Running task 4.0 in stage 6.0 (TID 92)
2021-12-03 19:33:56,149 [Executor task launch worker for task 94] INFO [org.apache.spark.executor.Executor] - Running task 6.0 in stage 6.0 (TID 94)
2021-12-03 19:33:56,149 [Executor task launch worker for task 95] INFO [org.apache.spark.executor.Executor] - Running task 7.0 in stage 6.0 (TID 95)
2021-12-03 19:33:56,149 [Executor task launch worker for task 97] INFO [org.apache.spark.executor.Executor] - Running task 9.0 in stage 6.0 (TID 97)
2021-12-03 19:33:56,149 [Executor task launch worker for task 96] INFO [org.apache.spark.executor.Executor] - Running task 8.0 in stage 6.0 (TID 96)
2021-12-03 19:33:56,156 [Executor task launch worker for task 93] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 19:33:56,156 [Executor task launch worker for task 90] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 19:33:56,156 [Executor task launch worker for task 93] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 19:33:56,156 [Executor task launch worker for task 97] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 19:33:56,156 [Executor task launch worker for task 89] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 19:33:56,156 [Executor task launch worker for task 90] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 19:33:56,156 [Executor task launch worker for task 94] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 19:33:56,156 [Executor task launch worker for task 94] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 19:33:56,156 [Executor task launch worker for task 88] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 19:33:56,156 [Executor task launch worker for task 92] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 19:33:56,156 [Executor task launch worker for task 89] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 19:33:56,156 [Executor task launch worker for task 97] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 19:33:56,156 [Executor task launch worker for task 95] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 19:33:56,156 [Executor task launch worker for task 92] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 19:33:56,156 [Executor task launch worker for task 88] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 19:33:56,156 [Executor task launch worker for task 96] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 19:33:56,156 [Executor task launch worker for task 91] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 19:33:56,156 [Executor task launch worker for task 95] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 19:33:56,156 [Executor task launch worker for task 98] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 19:33:56,156 [Executor task launch worker for task 99] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 19:33:56,157 [Executor task launch worker for task 98] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 1 ms
2021-12-03 19:33:56,156 [Executor task launch worker for task 91] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 19:33:56,156 [Executor task launch worker for task 96] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 19:33:56,157 [Executor task launch worker for task 99] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 1 ms
2021-12-03 19:33:56,576 [Executor task launch worker for task 88] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 6.0 (TID 88). 1224 bytes result sent to driver
2021-12-03 19:33:56,576 [dispatcher-event-loop-6] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 12.0 in stage 6.0 (TID 100, localhost, executor driver, partition 12, ANY, 7638 bytes)
2021-12-03 19:33:56,577 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 6.0 (TID 88) in 429 ms on localhost (executor driver) (1/22)
2021-12-03 19:33:56,578 [Executor task launch worker for task 100] INFO [org.apache.spark.executor.Executor] - Running task 12.0 in stage 6.0 (TID 100)
2021-12-03 19:33:56,582 [Executor task launch worker for task 100] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 19:33:56,582 [Executor task launch worker for task 100] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 19:33:56,599 [Executor task launch worker for task 95] INFO [org.apache.spark.executor.Executor] - Finished task 7.0 in stage 6.0 (TID 95). 1224 bytes result sent to driver
2021-12-03 19:33:56,599 [dispatcher-event-loop-9] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 13.0 in stage 6.0 (TID 101, localhost, executor driver, partition 13, ANY, 7638 bytes)
2021-12-03 19:33:56,600 [Executor task launch worker for task 101] INFO [org.apache.spark.executor.Executor] - Running task 13.0 in stage 6.0 (TID 101)
2021-12-03 19:33:56,602 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 7.0 in stage 6.0 (TID 95) in 454 ms on localhost (executor driver) (2/22)
2021-12-03 19:33:56,603 [Executor task launch worker for task 101] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 19:33:56,603 [Executor task launch worker for task 101] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 19:33:56,609 [Executor task launch worker for task 90] INFO [org.apache.spark.executor.Executor] - Finished task 2.0 in stage 6.0 (TID 90). 1224 bytes result sent to driver
2021-12-03 19:33:56,610 [dispatcher-event-loop-7] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 14.0 in stage 6.0 (TID 102, localhost, executor driver, partition 14, ANY, 7638 bytes)
2021-12-03 19:33:56,610 [Executor task launch worker for task 102] INFO [org.apache.spark.executor.Executor] - Running task 14.0 in stage 6.0 (TID 102)
2021-12-03 19:33:56,611 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 2.0 in stage 6.0 (TID 90) in 463 ms on localhost (executor driver) (3/22)
2021-12-03 19:33:56,613 [Executor task launch worker for task 102] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 19:33:56,614 [Executor task launch worker for task 102] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 1 ms
2021-12-03 19:33:56,626 [Executor task launch worker for task 99] INFO [org.apache.spark.executor.Executor] - Finished task 11.0 in stage 6.0 (TID 99). 1224 bytes result sent to driver
2021-12-03 19:33:56,633 [Executor task launch worker for task 97] INFO [org.apache.spark.executor.Executor] - Finished task 9.0 in stage 6.0 (TID 97). 1224 bytes result sent to driver
2021-12-03 19:33:56,633 [dispatcher-event-loop-10] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 15.0 in stage 6.0 (TID 103, localhost, executor driver, partition 15, ANY, 7638 bytes)
2021-12-03 19:33:56,634 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 11.0 in stage 6.0 (TID 99) in 485 ms on localhost (executor driver) (4/22)
2021-12-03 19:33:56,634 [Executor task launch worker for task 93] INFO [org.apache.spark.executor.Executor] - Finished task 5.0 in stage 6.0 (TID 93). 1224 bytes result sent to driver
2021-12-03 19:33:56,634 [Executor task launch worker for task 91] INFO [org.apache.spark.executor.Executor] - Finished task 3.0 in stage 6.0 (TID 91). 1224 bytes result sent to driver
2021-12-03 19:33:56,634 [Executor task launch worker for task 103] INFO [org.apache.spark.executor.Executor] - Running task 15.0 in stage 6.0 (TID 103)
2021-12-03 19:33:56,635 [dispatcher-event-loop-10] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 16.0 in stage 6.0 (TID 104, localhost, executor driver, partition 16, ANY, 7638 bytes)
2021-12-03 19:33:56,635 [Executor task launch worker for task 104] INFO [org.apache.spark.executor.Executor] - Running task 16.0 in stage 6.0 (TID 104)
2021-12-03 19:33:56,635 [dispatcher-event-loop-10] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 17.0 in stage 6.0 (TID 105, localhost, executor driver, partition 17, ANY, 7638 bytes)
2021-12-03 19:33:56,636 [Executor task launch worker for task 98] INFO [org.apache.spark.executor.Executor] - Finished task 10.0 in stage 6.0 (TID 98). 1224 bytes result sent to driver
2021-12-03 19:33:56,636 [dispatcher-event-loop-10] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 18.0 in stage 6.0 (TID 106, localhost, executor driver, partition 18, ANY, 7638 bytes)
2021-12-03 19:33:56,636 [Executor task launch worker for task 105] INFO [org.apache.spark.executor.Executor] - Running task 17.0 in stage 6.0 (TID 105)
2021-12-03 19:33:56,636 [dispatcher-event-loop-10] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 19.0 in stage 6.0 (TID 107, localhost, executor driver, partition 19, ANY, 7638 bytes)
2021-12-03 19:33:56,636 [Executor task launch worker for task 106] INFO [org.apache.spark.executor.Executor] - Running task 18.0 in stage 6.0 (TID 106)
2021-12-03 19:33:56,637 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 9.0 in stage 6.0 (TID 97) in 489 ms on localhost (executor driver) (5/22)
2021-12-03 19:33:56,637 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 10.0 in stage 6.0 (TID 98) in 489 ms on localhost (executor driver) (6/22)
2021-12-03 19:33:56,638 [Executor task launch worker for task 107] INFO [org.apache.spark.executor.Executor] - Running task 19.0 in stage 6.0 (TID 107)
2021-12-03 19:33:56,638 [Executor task launch worker for task 103] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 19:33:56,638 [Executor task launch worker for task 103] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 19:33:56,638 [Executor task launch worker for task 96] INFO [org.apache.spark.executor.Executor] - Finished task 8.0 in stage 6.0 (TID 96). 1224 bytes result sent to driver
2021-12-03 19:33:56,638 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 5.0 in stage 6.0 (TID 93) in 490 ms on localhost (executor driver) (7/22)
2021-12-03 19:33:56,639 [dispatcher-event-loop-6] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 20.0 in stage 6.0 (TID 108, localhost, executor driver, partition 20, ANY, 7638 bytes)
2021-12-03 19:33:56,639 [Executor task launch worker for task 108] INFO [org.apache.spark.executor.Executor] - Running task 20.0 in stage 6.0 (TID 108)
2021-12-03 19:33:56,639 [Executor task launch worker for task 106] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 19:33:56,639 [Executor task launch worker for task 106] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 19:33:56,640 [Executor task launch worker for task 105] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 19:33:56,640 [Executor task launch worker for task 105] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 19:33:56,640 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 8.0 in stage 6.0 (TID 96) in 492 ms on localhost (executor driver) (8/22)
2021-12-03 19:33:56,640 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 3.0 in stage 6.0 (TID 91) in 492 ms on localhost (executor driver) (9/22)
2021-12-03 19:33:56,640 [Executor task launch worker for task 89] INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 6.0 (TID 89). 1224 bytes result sent to driver
2021-12-03 19:33:56,641 [dispatcher-event-loop-5] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 21.0 in stage 6.0 (TID 109, localhost, executor driver, partition 21, ANY, 7638 bytes)
2021-12-03 19:33:56,641 [Executor task launch worker for task 107] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 19:33:56,641 [Executor task launch worker for task 107] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 19:33:56,641 [Executor task launch worker for task 109] INFO [org.apache.spark.executor.Executor] - Running task 21.0 in stage 6.0 (TID 109)
2021-12-03 19:33:56,641 [Executor task launch worker for task 104] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 19:33:56,641 [Executor task launch worker for task 104] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 19:33:56,642 [Executor task launch worker for task 108] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 19:33:56,642 [Executor task launch worker for task 108] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 19:33:56,642 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 6.0 (TID 89) in 494 ms on localhost (executor driver) (10/22)
2021-12-03 19:33:56,644 [Executor task launch worker for task 109] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 19:33:56,645 [Executor task launch worker for task 109] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 1 ms
2021-12-03 19:33:56,683 [Executor task launch worker for task 94] INFO [org.apache.spark.executor.Executor] - Finished task 6.0 in stage 6.0 (TID 94). 1224 bytes result sent to driver
2021-12-03 19:33:56,683 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 6.0 in stage 6.0 (TID 94) in 535 ms on localhost (executor driver) (11/22)
2021-12-03 19:33:56,742 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 99
2021-12-03 19:33:56,744 [dispatcher-event-loop-2] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_4_piece0 on qb:62255 in memory (size: 2.4 KB, free: 1990.8 MB)
2021-12-03 19:33:56,747 [Executor task launch worker for task 92] INFO [org.apache.spark.executor.Executor] - Finished task 4.0 in stage 6.0 (TID 92). 1267 bytes result sent to driver
2021-12-03 19:33:56,747 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 78
2021-12-03 19:33:56,747 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 85
2021-12-03 19:33:56,747 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 80
2021-12-03 19:33:56,747 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 84
2021-12-03 19:33:56,748 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 75
2021-12-03 19:33:56,748 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 90
2021-12-03 19:33:56,748 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 94
2021-12-03 19:33:56,748 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 82
2021-12-03 19:33:56,748 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 81
2021-12-03 19:33:56,748 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 89
2021-12-03 19:33:56,748 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 79
2021-12-03 19:33:56,748 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 87
2021-12-03 19:33:56,748 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 97
2021-12-03 19:33:56,748 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 83
2021-12-03 19:33:56,748 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 77
2021-12-03 19:33:56,748 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 91
2021-12-03 19:33:56,748 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 76
2021-12-03 19:33:56,748 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 95
2021-12-03 19:33:56,748 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 92
2021-12-03 19:33:56,748 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 96
2021-12-03 19:33:56,749 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 86
2021-12-03 19:33:56,749 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 93
2021-12-03 19:33:56,749 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 98
2021-12-03 19:33:56,749 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 88
2021-12-03 19:33:56,751 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 4.0 in stage 6.0 (TID 92) in 603 ms on localhost (executor driver) (12/22)
2021-12-03 19:33:57,079 [Executor task launch worker for task 101] INFO [org.apache.spark.executor.Executor] - Finished task 13.0 in stage 6.0 (TID 101). 1267 bytes result sent to driver
2021-12-03 19:33:57,080 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 13.0 in stage 6.0 (TID 101) in 481 ms on localhost (executor driver) (13/22)
2021-12-03 19:33:57,090 [Executor task launch worker for task 100] INFO [org.apache.spark.executor.Executor] - Finished task 12.0 in stage 6.0 (TID 100). 1310 bytes result sent to driver
2021-12-03 19:33:57,090 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 12.0 in stage 6.0 (TID 100) in 514 ms on localhost (executor driver) (14/22)
2021-12-03 19:33:57,104 [Executor task launch worker for task 102] INFO [org.apache.spark.executor.Executor] - Finished task 14.0 in stage 6.0 (TID 102). 1310 bytes result sent to driver
2021-12-03 19:33:57,105 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 14.0 in stage 6.0 (TID 102) in 495 ms on localhost (executor driver) (15/22)
2021-12-03 19:33:57,108 [Executor task launch worker for task 107] INFO [org.apache.spark.executor.Executor] - Finished task 19.0 in stage 6.0 (TID 107). 1267 bytes result sent to driver
2021-12-03 19:33:57,109 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 19.0 in stage 6.0 (TID 107) in 473 ms on localhost (executor driver) (16/22)
2021-12-03 19:33:57,122 [Executor task launch worker for task 108] INFO [org.apache.spark.executor.Executor] - Finished task 20.0 in stage 6.0 (TID 108). 1267 bytes result sent to driver
2021-12-03 19:33:57,123 [Executor task launch worker for task 104] INFO [org.apache.spark.executor.Executor] - Finished task 16.0 in stage 6.0 (TID 104). 1267 bytes result sent to driver
2021-12-03 19:33:57,123 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 20.0 in stage 6.0 (TID 108) in 484 ms on localhost (executor driver) (17/22)
2021-12-03 19:33:57,124 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 16.0 in stage 6.0 (TID 104) in 490 ms on localhost (executor driver) (18/22)
2021-12-03 19:33:57,126 [Executor task launch worker for task 103] INFO [org.apache.spark.executor.Executor] - Finished task 15.0 in stage 6.0 (TID 103). 1267 bytes result sent to driver
2021-12-03 19:33:57,127 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 15.0 in stage 6.0 (TID 103) in 495 ms on localhost (executor driver) (19/22)
2021-12-03 19:33:57,129 [Executor task launch worker for task 109] INFO [org.apache.spark.executor.Executor] - Finished task 21.0 in stage 6.0 (TID 109). 1310 bytes result sent to driver
2021-12-03 19:33:57,129 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 21.0 in stage 6.0 (TID 109) in 488 ms on localhost (executor driver) (20/22)
2021-12-03 19:33:57,136 [Executor task launch worker for task 106] INFO [org.apache.spark.executor.Executor] - Finished task 18.0 in stage 6.0 (TID 106). 1267 bytes result sent to driver
2021-12-03 19:33:57,136 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 18.0 in stage 6.0 (TID 106) in 500 ms on localhost (executor driver) (21/22)
2021-12-03 19:33:57,149 [Executor task launch worker for task 105] INFO [org.apache.spark.executor.Executor] - Finished task 17.0 in stage 6.0 (TID 105). 1267 bytes result sent to driver
2021-12-03 19:33:57,149 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 17.0 in stage 6.0 (TID 105) in 514 ms on localhost (executor driver) (22/22)
2021-12-03 19:33:57,149 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 6.0, whose tasks have all completed, from pool 
2021-12-03 19:33:57,150 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ShuffleMapStage 6 (map at PaidPromotionAdjustParameter.scala:71) finished in 1.010 s
2021-12-03 19:33:57,150 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - looking for newly runnable stages
2021-12-03 19:33:57,150 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - running: Set()
2021-12-03 19:33:57,150 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - waiting: Set(ResultStage 7)
2021-12-03 19:33:57,150 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - failed: Set()
2021-12-03 19:33:57,150 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 7 (ShuffledRDD[8] at sortByKey at PaidPromotionAdjustParameter.scala:72), which has no missing parents
2021-12-03 19:33:57,152 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_6 stored as values in memory (estimated size 3.4 KB, free 1990.5 MB)
2021-12-03 19:33:57,154 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_6_piece0 stored as bytes in memory (estimated size 2.0 KB, free 1990.4 MB)
2021-12-03 19:33:57,154 [dispatcher-event-loop-6] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_6_piece0 in memory on qb:62255 (size: 2.0 KB, free: 1990.8 MB)
2021-12-03 19:33:57,155 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 6 from broadcast at DAGScheduler.scala:1039
2021-12-03 19:33:57,155 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 21 missing tasks from ResultStage 7 (ShuffledRDD[8] at sortByKey at PaidPromotionAdjustParameter.scala:72) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14))
2021-12-03 19:33:57,155 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 7.0 with 21 tasks
2021-12-03 19:33:57,155 [dispatcher-event-loop-9] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 7.0 (TID 110, localhost, executor driver, partition 0, ANY, 7649 bytes)
2021-12-03 19:33:57,156 [dispatcher-event-loop-9] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 7.0 (TID 111, localhost, executor driver, partition 1, ANY, 7649 bytes)
2021-12-03 19:33:57,156 [dispatcher-event-loop-9] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 2.0 in stage 7.0 (TID 112, localhost, executor driver, partition 2, ANY, 7649 bytes)
2021-12-03 19:33:57,156 [dispatcher-event-loop-9] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 3.0 in stage 7.0 (TID 113, localhost, executor driver, partition 3, ANY, 7649 bytes)
2021-12-03 19:33:57,156 [dispatcher-event-loop-9] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 4.0 in stage 7.0 (TID 114, localhost, executor driver, partition 4, ANY, 7649 bytes)
2021-12-03 19:33:57,156 [dispatcher-event-loop-9] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 5.0 in stage 7.0 (TID 115, localhost, executor driver, partition 5, ANY, 7649 bytes)
2021-12-03 19:33:57,156 [dispatcher-event-loop-9] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 6.0 in stage 7.0 (TID 116, localhost, executor driver, partition 6, ANY, 7649 bytes)
2021-12-03 19:33:57,156 [dispatcher-event-loop-9] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 7.0 in stage 7.0 (TID 117, localhost, executor driver, partition 7, ANY, 7649 bytes)
2021-12-03 19:33:57,156 [dispatcher-event-loop-9] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 8.0 in stage 7.0 (TID 118, localhost, executor driver, partition 8, ANY, 7649 bytes)
2021-12-03 19:33:57,156 [dispatcher-event-loop-9] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 9.0 in stage 7.0 (TID 119, localhost, executor driver, partition 9, ANY, 7649 bytes)
2021-12-03 19:33:57,156 [dispatcher-event-loop-9] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 10.0 in stage 7.0 (TID 120, localhost, executor driver, partition 10, ANY, 7649 bytes)
2021-12-03 19:33:57,156 [dispatcher-event-loop-9] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 11.0 in stage 7.0 (TID 121, localhost, executor driver, partition 11, ANY, 7649 bytes)
2021-12-03 19:33:57,156 [Executor task launch worker for task 110] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 7.0 (TID 110)
2021-12-03 19:33:57,156 [Executor task launch worker for task 117] INFO [org.apache.spark.executor.Executor] - Running task 7.0 in stage 7.0 (TID 117)
2021-12-03 19:33:57,156 [Executor task launch worker for task 119] INFO [org.apache.spark.executor.Executor] - Running task 9.0 in stage 7.0 (TID 119)
2021-12-03 19:33:57,156 [Executor task launch worker for task 116] INFO [org.apache.spark.executor.Executor] - Running task 6.0 in stage 7.0 (TID 116)
2021-12-03 19:33:57,156 [Executor task launch worker for task 113] INFO [org.apache.spark.executor.Executor] - Running task 3.0 in stage 7.0 (TID 113)
2021-12-03 19:33:57,156 [Executor task launch worker for task 115] INFO [org.apache.spark.executor.Executor] - Running task 5.0 in stage 7.0 (TID 115)
2021-12-03 19:33:57,156 [Executor task launch worker for task 111] INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 7.0 (TID 111)
2021-12-03 19:33:57,156 [Executor task launch worker for task 114] INFO [org.apache.spark.executor.Executor] - Running task 4.0 in stage 7.0 (TID 114)
2021-12-03 19:33:57,156 [Executor task launch worker for task 112] INFO [org.apache.spark.executor.Executor] - Running task 2.0 in stage 7.0 (TID 112)
2021-12-03 19:33:57,156 [Executor task launch worker for task 120] INFO [org.apache.spark.executor.Executor] - Running task 10.0 in stage 7.0 (TID 120)
2021-12-03 19:33:57,156 [Executor task launch worker for task 118] INFO [org.apache.spark.executor.Executor] - Running task 8.0 in stage 7.0 (TID 118)
2021-12-03 19:33:57,156 [Executor task launch worker for task 121] INFO [org.apache.spark.executor.Executor] - Running task 11.0 in stage 7.0 (TID 121)
2021-12-03 19:33:57,159 [Executor task launch worker for task 121] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 19:33:57,159 [Executor task launch worker for task 121] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 19:33:57,160 [Executor task launch worker for task 117] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 19:33:57,160 [Executor task launch worker for task 117] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 19:33:57,160 [Executor task launch worker for task 114] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 19:33:57,160 [Executor task launch worker for task 114] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 19:33:57,160 [Executor task launch worker for task 120] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 19:33:57,160 [Executor task launch worker for task 120] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 19:33:57,160 [Executor task launch worker for task 118] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 19:33:57,160 [Executor task launch worker for task 118] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 19:33:57,161 [Executor task launch worker for task 112] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 19:33:57,161 [Executor task launch worker for task 112] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 19:33:57,161 [Executor task launch worker for task 113] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 19:33:57,161 [Executor task launch worker for task 113] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 19:33:57,162 [Executor task launch worker for task 115] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 19:33:57,162 [Executor task launch worker for task 115] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 19:33:57,162 [Executor task launch worker for task 116] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 19:33:57,162 [Executor task launch worker for task 116] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 19:33:57,163 [Executor task launch worker for task 119] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 19:33:57,163 [Executor task launch worker for task 119] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 19:33:57,163 [Executor task launch worker for task 111] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 19:33:57,163 [Executor task launch worker for task 111] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 19:33:57,163 [Executor task launch worker for task 110] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 19:33:57,163 [Executor task launch worker for task 110] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 19:33:57,757 [Executor task launch worker for task 119] INFO [org.apache.spark.executor.Executor] - Finished task 9.0 in stage 7.0 (TID 119). 1098 bytes result sent to driver
2021-12-03 19:33:57,758 [dispatcher-event-loop-7] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 12.0 in stage 7.0 (TID 122, localhost, executor driver, partition 12, ANY, 7649 bytes)
2021-12-03 19:33:57,758 [Executor task launch worker for task 122] INFO [org.apache.spark.executor.Executor] - Running task 12.0 in stage 7.0 (TID 122)
2021-12-03 19:33:57,760 [Executor task launch worker for task 122] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 19:33:57,760 [Executor task launch worker for task 122] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 19:33:57,763 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 9.0 in stage 7.0 (TID 119) in 607 ms on localhost (executor driver) (1/21)
2021-12-03 19:33:57,766 [Executor task launch worker for task 115] INFO [org.apache.spark.executor.Executor] - Finished task 5.0 in stage 7.0 (TID 115). 1098 bytes result sent to driver
2021-12-03 19:33:57,767 [Executor task launch worker for task 111] INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 7.0 (TID 111). 1055 bytes result sent to driver
2021-12-03 19:33:57,770 [Executor task launch worker for task 121] INFO [org.apache.spark.executor.Executor] - Finished task 11.0 in stage 7.0 (TID 121). 1098 bytes result sent to driver
2021-12-03 19:33:57,770 [dispatcher-event-loop-11] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 13.0 in stage 7.0 (TID 123, localhost, executor driver, partition 13, ANY, 7649 bytes)
2021-12-03 19:33:57,771 [dispatcher-event-loop-11] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 14.0 in stage 7.0 (TID 124, localhost, executor driver, partition 14, ANY, 7649 bytes)
2021-12-03 19:33:57,771 [Executor task launch worker for task 123] INFO [org.apache.spark.executor.Executor] - Running task 13.0 in stage 7.0 (TID 123)
2021-12-03 19:33:57,771 [dispatcher-event-loop-11] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 15.0 in stage 7.0 (TID 125, localhost, executor driver, partition 15, ANY, 7649 bytes)
2021-12-03 19:33:57,771 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 5.0 in stage 7.0 (TID 115) in 615 ms on localhost (executor driver) (2/21)
2021-12-03 19:33:57,771 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 7.0 (TID 111) in 616 ms on localhost (executor driver) (3/21)
2021-12-03 19:33:57,771 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 11.0 in stage 7.0 (TID 121) in 615 ms on localhost (executor driver) (4/21)
2021-12-03 19:33:57,773 [Executor task launch worker for task 123] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 19:33:57,773 [Executor task launch worker for task 123] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 19:33:57,774 [Executor task launch worker for task 120] INFO [org.apache.spark.executor.Executor] - Finished task 10.0 in stage 7.0 (TID 120). 1055 bytes result sent to driver
2021-12-03 19:33:57,774 [Executor task launch worker for task 124] INFO [org.apache.spark.executor.Executor] - Running task 14.0 in stage 7.0 (TID 124)
2021-12-03 19:33:57,774 [dispatcher-event-loop-8] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 16.0 in stage 7.0 (TID 126, localhost, executor driver, partition 16, ANY, 7649 bytes)
2021-12-03 19:33:57,774 [Executor task launch worker for task 125] INFO [org.apache.spark.executor.Executor] - Running task 15.0 in stage 7.0 (TID 125)
2021-12-03 19:33:57,775 [Executor task launch worker for task 110] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 7.0 (TID 110). 1098 bytes result sent to driver
2021-12-03 19:33:57,774 [Executor task launch worker for task 117] INFO [org.apache.spark.executor.Executor] - Finished task 7.0 in stage 7.0 (TID 117). 1098 bytes result sent to driver
2021-12-03 19:33:57,776 [dispatcher-event-loop-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 17.0 in stage 7.0 (TID 127, localhost, executor driver, partition 17, ANY, 7649 bytes)
2021-12-03 19:33:57,776 [dispatcher-event-loop-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 18.0 in stage 7.0 (TID 128, localhost, executor driver, partition 18, ANY, 7649 bytes)
2021-12-03 19:33:57,776 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 10.0 in stage 7.0 (TID 120) in 620 ms on localhost (executor driver) (5/21)
2021-12-03 19:33:57,776 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 7.0 (TID 110) in 621 ms on localhost (executor driver) (6/21)
2021-12-03 19:33:57,777 [Executor task launch worker for task 125] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 19:33:57,777 [Executor task launch worker for task 126] INFO [org.apache.spark.executor.Executor] - Running task 16.0 in stage 7.0 (TID 126)
2021-12-03 19:33:57,777 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 7.0 in stage 7.0 (TID 117) in 621 ms on localhost (executor driver) (7/21)
2021-12-03 19:33:57,777 [Executor task launch worker for task 127] INFO [org.apache.spark.executor.Executor] - Running task 17.0 in stage 7.0 (TID 127)
2021-12-03 19:33:57,777 [Executor task launch worker for task 124] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 19:33:57,777 [Executor task launch worker for task 124] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 19:33:57,777 [Executor task launch worker for task 125] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 1 ms
2021-12-03 19:33:57,777 [Executor task launch worker for task 128] INFO [org.apache.spark.executor.Executor] - Running task 18.0 in stage 7.0 (TID 128)
2021-12-03 19:33:57,779 [Executor task launch worker for task 127] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 19:33:57,779 [Executor task launch worker for task 127] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 19:33:57,780 [Executor task launch worker for task 128] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 19:33:57,780 [Executor task launch worker for task 128] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 19:33:57,783 [Executor task launch worker for task 126] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 19:33:57,783 [Executor task launch worker for task 126] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 19:33:57,810 [Executor task launch worker for task 116] INFO [org.apache.spark.executor.Executor] - Finished task 6.0 in stage 7.0 (TID 116). 1098 bytes result sent to driver
2021-12-03 19:33:57,810 [dispatcher-event-loop-10] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 19.0 in stage 7.0 (TID 129, localhost, executor driver, partition 19, ANY, 7649 bytes)
2021-12-03 19:33:57,810 [Executor task launch worker for task 129] INFO [org.apache.spark.executor.Executor] - Running task 19.0 in stage 7.0 (TID 129)
2021-12-03 19:33:57,810 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 6.0 in stage 7.0 (TID 116) in 654 ms on localhost (executor driver) (8/21)
2021-12-03 19:33:57,813 [Executor task launch worker for task 129] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 19:33:57,813 [Executor task launch worker for task 129] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 19:33:57,818 [Executor task launch worker for task 112] INFO [org.apache.spark.executor.Executor] - Finished task 2.0 in stage 7.0 (TID 112). 1055 bytes result sent to driver
2021-12-03 19:33:57,818 [dispatcher-event-loop-4] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 20.0 in stage 7.0 (TID 130, localhost, executor driver, partition 20, ANY, 7649 bytes)
2021-12-03 19:33:57,820 [Executor task launch worker for task 114] INFO [org.apache.spark.executor.Executor] - Finished task 4.0 in stage 7.0 (TID 114). 1098 bytes result sent to driver
2021-12-03 19:33:57,820 [Executor task launch worker for task 130] INFO [org.apache.spark.executor.Executor] - Running task 20.0 in stage 7.0 (TID 130)
2021-12-03 19:33:57,820 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 2.0 in stage 7.0 (TID 112) in 664 ms on localhost (executor driver) (9/21)
2021-12-03 19:33:57,821 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 4.0 in stage 7.0 (TID 114) in 665 ms on localhost (executor driver) (10/21)
2021-12-03 19:33:57,830 [Executor task launch worker for task 130] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 19:33:57,830 [Executor task launch worker for task 130] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 1 ms
2021-12-03 19:33:57,836 [Executor task launch worker for task 113] INFO [org.apache.spark.executor.Executor] - Finished task 3.0 in stage 7.0 (TID 113). 1055 bytes result sent to driver
2021-12-03 19:33:57,840 [Executor task launch worker for task 118] INFO [org.apache.spark.executor.Executor] - Finished task 8.0 in stage 7.0 (TID 118). 1055 bytes result sent to driver
2021-12-03 19:33:57,841 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 8.0 in stage 7.0 (TID 118) in 685 ms on localhost (executor driver) (11/21)
2021-12-03 19:33:57,842 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 3.0 in stage 7.0 (TID 113) in 686 ms on localhost (executor driver) (12/21)
2021-12-03 19:33:57,857 [Executor task launch worker for task 124] INFO [org.apache.spark.executor.Executor] - Finished task 14.0 in stage 7.0 (TID 124). 1055 bytes result sent to driver
2021-12-03 19:33:57,863 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 14.0 in stage 7.0 (TID 124) in 92 ms on localhost (executor driver) (13/21)
2021-12-03 19:33:57,866 [Executor task launch worker for task 123] INFO [org.apache.spark.executor.Executor] - Finished task 13.0 in stage 7.0 (TID 123). 1055 bytes result sent to driver
2021-12-03 19:33:57,867 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 13.0 in stage 7.0 (TID 123) in 97 ms on localhost (executor driver) (14/21)
2021-12-03 19:33:57,871 [Executor task launch worker for task 126] INFO [org.apache.spark.executor.Executor] - Finished task 16.0 in stage 7.0 (TID 126). 1055 bytes result sent to driver
2021-12-03 19:33:57,876 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 16.0 in stage 7.0 (TID 126) in 102 ms on localhost (executor driver) (15/21)
2021-12-03 19:33:57,884 [Executor task launch worker for task 128] INFO [org.apache.spark.executor.Executor] - Finished task 18.0 in stage 7.0 (TID 128). 1055 bytes result sent to driver
2021-12-03 19:33:57,884 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 18.0 in stage 7.0 (TID 128) in 108 ms on localhost (executor driver) (16/21)
2021-12-03 19:33:57,886 [Executor task launch worker for task 122] INFO [org.apache.spark.executor.Executor] - Finished task 12.0 in stage 7.0 (TID 122). 1055 bytes result sent to driver
2021-12-03 19:33:57,887 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 12.0 in stage 7.0 (TID 122) in 129 ms on localhost (executor driver) (17/21)
2021-12-03 19:33:57,887 [Executor task launch worker for task 125] INFO [org.apache.spark.executor.Executor] - Finished task 15.0 in stage 7.0 (TID 125). 1055 bytes result sent to driver
2021-12-03 19:33:57,887 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 15.0 in stage 7.0 (TID 125) in 116 ms on localhost (executor driver) (18/21)
2021-12-03 19:33:57,894 [Executor task launch worker for task 127] INFO [org.apache.spark.executor.Executor] - Finished task 17.0 in stage 7.0 (TID 127). 1055 bytes result sent to driver
2021-12-03 19:33:57,894 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 17.0 in stage 7.0 (TID 127) in 119 ms on localhost (executor driver) (19/21)
2021-12-03 19:33:57,907 [Executor task launch worker for task 129] INFO [org.apache.spark.executor.Executor] - Finished task 19.0 in stage 7.0 (TID 129). 1055 bytes result sent to driver
2021-12-03 19:33:57,908 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 19.0 in stage 7.0 (TID 129) in 98 ms on localhost (executor driver) (20/21)
2021-12-03 19:33:57,948 [Executor task launch worker for task 130] INFO [org.apache.spark.executor.Executor] - Finished task 20.0 in stage 7.0 (TID 130). 1055 bytes result sent to driver
2021-12-03 19:33:57,948 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 20.0 in stage 7.0 (TID 130) in 130 ms on localhost (executor driver) (21/21)
2021-12-03 19:33:57,948 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 7.0, whose tasks have all completed, from pool 
2021-12-03 19:33:57,948 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 7 (zipWithIndex at PaidPromotionAdjustParameter.scala:73) finished in 0.797 s
2021-12-03 19:33:57,948 [main] INFO [org.apache.spark.scheduler.DAGScheduler] - Job 3 finished: zipWithIndex at PaidPromotionAdjustParameter.scala:73, took 1.809856 s
2021-12-03 19:33:57,957 [dispatcher-event-loop-2] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_6_piece0 on qb:62255 in memory (size: 2.0 KB, free: 1990.8 MB)
2021-12-03 19:33:57,967 [main] INFO [org.apache.spark.SparkContext] - Starting job: takeSample at PaidPromotionAdjustParameter.scala:76
2021-12-03 19:33:57,967 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 4 (takeSample at PaidPromotionAdjustParameter.scala:76) with 22 output partitions
2021-12-03 19:33:57,967 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 10 (takeSample at PaidPromotionAdjustParameter.scala:76)
2021-12-03 19:33:57,967 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 9)
2021-12-03 19:33:57,967 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2021-12-03 19:33:57,967 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 10 (MapPartitionsRDD[11] at map at PaidPromotionAdjustParameter.scala:75), which has no missing parents
2021-12-03 19:33:57,971 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_7 stored as values in memory (estimated size 4.2 KB, free 1990.5 MB)
2021-12-03 19:33:57,972 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_7_piece0 stored as bytes in memory (estimated size 2.4 KB, free 1990.4 MB)
2021-12-03 19:33:57,973 [dispatcher-event-loop-9] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_7_piece0 in memory on qb:62255 (size: 2.4 KB, free: 1990.8 MB)
2021-12-03 19:33:57,973 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 7 from broadcast at DAGScheduler.scala:1039
2021-12-03 19:33:57,973 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 22 missing tasks from ResultStage 10 (MapPartitionsRDD[11] at map at PaidPromotionAdjustParameter.scala:75) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14))
2021-12-03 19:33:57,973 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 10.0 with 22 tasks
2021-12-03 19:33:57,974 [dispatcher-event-loop-6] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 10.0 (TID 131, localhost, executor driver, partition 0, ANY, 7759 bytes)
2021-12-03 19:33:57,974 [dispatcher-event-loop-6] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 10.0 (TID 132, localhost, executor driver, partition 1, ANY, 7759 bytes)
2021-12-03 19:33:57,974 [dispatcher-event-loop-6] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 2.0 in stage 10.0 (TID 133, localhost, executor driver, partition 2, ANY, 7759 bytes)
2021-12-03 19:33:57,974 [dispatcher-event-loop-6] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 3.0 in stage 10.0 (TID 134, localhost, executor driver, partition 3, ANY, 7759 bytes)
2021-12-03 19:33:57,974 [dispatcher-event-loop-6] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 4.0 in stage 10.0 (TID 135, localhost, executor driver, partition 4, ANY, 7759 bytes)
2021-12-03 19:33:57,975 [dispatcher-event-loop-6] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 5.0 in stage 10.0 (TID 136, localhost, executor driver, partition 5, ANY, 7759 bytes)
2021-12-03 19:33:57,975 [dispatcher-event-loop-6] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 6.0 in stage 10.0 (TID 137, localhost, executor driver, partition 6, ANY, 7759 bytes)
2021-12-03 19:33:57,975 [dispatcher-event-loop-6] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 7.0 in stage 10.0 (TID 138, localhost, executor driver, partition 7, ANY, 7759 bytes)
2021-12-03 19:33:57,975 [dispatcher-event-loop-6] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 8.0 in stage 10.0 (TID 139, localhost, executor driver, partition 8, ANY, 7759 bytes)
2021-12-03 19:33:57,975 [dispatcher-event-loop-6] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 9.0 in stage 10.0 (TID 140, localhost, executor driver, partition 9, ANY, 7759 bytes)
2021-12-03 19:33:57,975 [dispatcher-event-loop-6] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 10.0 in stage 10.0 (TID 141, localhost, executor driver, partition 10, ANY, 7759 bytes)
2021-12-03 19:33:57,975 [dispatcher-event-loop-6] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 11.0 in stage 10.0 (TID 142, localhost, executor driver, partition 11, ANY, 7759 bytes)
2021-12-03 19:33:57,975 [Executor task launch worker for task 134] INFO [org.apache.spark.executor.Executor] - Running task 3.0 in stage 10.0 (TID 134)
2021-12-03 19:33:57,975 [Executor task launch worker for task 135] INFO [org.apache.spark.executor.Executor] - Running task 4.0 in stage 10.0 (TID 135)
2021-12-03 19:33:57,975 [Executor task launch worker for task 142] INFO [org.apache.spark.executor.Executor] - Running task 11.0 in stage 10.0 (TID 142)
2021-12-03 19:33:57,975 [Executor task launch worker for task 141] INFO [org.apache.spark.executor.Executor] - Running task 10.0 in stage 10.0 (TID 141)
2021-12-03 19:33:57,975 [Executor task launch worker for task 140] INFO [org.apache.spark.executor.Executor] - Running task 9.0 in stage 10.0 (TID 140)
2021-12-03 19:33:57,975 [Executor task launch worker for task 139] INFO [org.apache.spark.executor.Executor] - Running task 8.0 in stage 10.0 (TID 139)
2021-12-03 19:33:57,975 [Executor task launch worker for task 138] INFO [org.apache.spark.executor.Executor] - Running task 7.0 in stage 10.0 (TID 138)
2021-12-03 19:33:57,975 [Executor task launch worker for task 137] INFO [org.apache.spark.executor.Executor] - Running task 6.0 in stage 10.0 (TID 137)
2021-12-03 19:33:57,975 [Executor task launch worker for task 133] INFO [org.apache.spark.executor.Executor] - Running task 2.0 in stage 10.0 (TID 133)
2021-12-03 19:33:57,975 [Executor task launch worker for task 132] INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 10.0 (TID 132)
2021-12-03 19:33:57,975 [Executor task launch worker for task 131] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 10.0 (TID 131)
2021-12-03 19:33:57,979 [Executor task launch worker for task 136] INFO [org.apache.spark.executor.Executor] - Running task 5.0 in stage 10.0 (TID 136)
2021-12-03 19:33:57,979 [Executor task launch worker for task 140] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 19:33:57,979 [Executor task launch worker for task 138] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 19:33:57,979 [Executor task launch worker for task 134] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 19:33:57,979 [Executor task launch worker for task 138] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 19:33:57,979 [Executor task launch worker for task 140] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 19:33:57,979 [Executor task launch worker for task 142] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 19:33:57,979 [Executor task launch worker for task 134] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 19:33:57,979 [Executor task launch worker for task 142] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 19:33:57,980 [Executor task launch worker for task 137] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 19:33:57,980 [Executor task launch worker for task 137] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 19:33:57,980 [Executor task launch worker for task 131] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 19:33:57,980 [Executor task launch worker for task 131] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 19:33:57,981 [Executor task launch worker for task 139] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 19:33:57,981 [Executor task launch worker for task 139] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 1 ms
2021-12-03 19:33:57,981 [Executor task launch worker for task 133] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 19:33:57,981 [Executor task launch worker for task 133] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 19:33:57,981 [Executor task launch worker for task 132] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 19:33:57,981 [Executor task launch worker for task 132] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 19:33:57,981 [Executor task launch worker for task 136] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 19:33:57,981 [Executor task launch worker for task 136] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 19:33:57,982 [Executor task launch worker for task 141] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 19:33:57,982 [Executor task launch worker for task 141] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 19:33:57,982 [Executor task launch worker for task 135] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 19:33:57,982 [Executor task launch worker for task 135] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 19:33:58,087 [Executor task launch worker for task 136] INFO [org.apache.spark.executor.Executor] - Finished task 5.0 in stage 10.0 (TID 136). 1053 bytes result sent to driver
2021-12-03 19:33:58,087 [Executor task launch worker for task 140] INFO [org.apache.spark.executor.Executor] - Finished task 9.0 in stage 10.0 (TID 140). 1053 bytes result sent to driver
2021-12-03 19:33:58,089 [dispatcher-event-loop-5] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 12.0 in stage 10.0 (TID 143, localhost, executor driver, partition 12, ANY, 7759 bytes)
2021-12-03 19:33:58,089 [Executor task launch worker for task 142] INFO [org.apache.spark.executor.Executor] - Finished task 11.0 in stage 10.0 (TID 142). 1053 bytes result sent to driver
2021-12-03 19:33:58,089 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 5.0 in stage 10.0 (TID 136) in 115 ms on localhost (executor driver) (1/22)
2021-12-03 19:33:58,089 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 9.0 in stage 10.0 (TID 140) in 114 ms on localhost (executor driver) (2/22)
2021-12-03 19:33:58,090 [Executor task launch worker for task 143] INFO [org.apache.spark.executor.Executor] - Running task 12.0 in stage 10.0 (TID 143)
2021-12-03 19:33:58,090 [dispatcher-event-loop-5] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 13.0 in stage 10.0 (TID 144, localhost, executor driver, partition 13, ANY, 7759 bytes)
2021-12-03 19:33:58,091 [Executor task launch worker for task 144] INFO [org.apache.spark.executor.Executor] - Running task 13.0 in stage 10.0 (TID 144)
2021-12-03 19:33:58,091 [dispatcher-event-loop-5] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 14.0 in stage 10.0 (TID 145, localhost, executor driver, partition 14, ANY, 7759 bytes)
2021-12-03 19:33:58,091 [Executor task launch worker for task 145] INFO [org.apache.spark.executor.Executor] - Running task 14.0 in stage 10.0 (TID 145)
2021-12-03 19:33:58,091 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 11.0 in stage 10.0 (TID 142) in 116 ms on localhost (executor driver) (3/22)
2021-12-03 19:33:58,091 [Executor task launch worker for task 141] INFO [org.apache.spark.executor.Executor] - Finished task 10.0 in stage 10.0 (TID 141). 1053 bytes result sent to driver
2021-12-03 19:33:58,091 [dispatcher-event-loop-8] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 15.0 in stage 10.0 (TID 146, localhost, executor driver, partition 15, ANY, 7759 bytes)
2021-12-03 19:33:58,092 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 10.0 in stage 10.0 (TID 141) in 117 ms on localhost (executor driver) (4/22)
2021-12-03 19:33:58,092 [Executor task launch worker for task 146] INFO [org.apache.spark.executor.Executor] - Running task 15.0 in stage 10.0 (TID 146)
2021-12-03 19:33:58,093 [Executor task launch worker for task 143] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 19:33:58,093 [Executor task launch worker for task 143] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 19:33:58,093 [Executor task launch worker for task 144] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 19:33:58,093 [Executor task launch worker for task 144] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 19:33:58,094 [Executor task launch worker for task 131] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 10.0 (TID 131). 1053 bytes result sent to driver
2021-12-03 19:33:58,094 [Executor task launch worker for task 146] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 19:33:58,094 [Executor task launch worker for task 146] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 19:33:58,094 [dispatcher-event-loop-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 16.0 in stage 10.0 (TID 147, localhost, executor driver, partition 16, ANY, 7759 bytes)
2021-12-03 19:33:58,094 [Executor task launch worker for task 147] INFO [org.apache.spark.executor.Executor] - Running task 16.0 in stage 10.0 (TID 147)
2021-12-03 19:33:58,094 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 10.0 (TID 131) in 120 ms on localhost (executor driver) (5/22)
2021-12-03 19:33:58,095 [Executor task launch worker for task 145] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 19:33:58,095 [Executor task launch worker for task 145] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 19:33:58,097 [Executor task launch worker for task 147] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 19:33:58,097 [Executor task launch worker for task 147] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 19:33:58,097 [Executor task launch worker for task 137] INFO [org.apache.spark.executor.Executor] - Finished task 6.0 in stage 10.0 (TID 137). 1053 bytes result sent to driver
2021-12-03 19:33:58,097 [Executor task launch worker for task 139] INFO [org.apache.spark.executor.Executor] - Finished task 8.0 in stage 10.0 (TID 139). 1053 bytes result sent to driver
2021-12-03 19:33:58,098 [dispatcher-event-loop-9] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 17.0 in stage 10.0 (TID 148, localhost, executor driver, partition 17, ANY, 7759 bytes)
2021-12-03 19:33:58,098 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 6.0 in stage 10.0 (TID 137) in 123 ms on localhost (executor driver) (6/22)
2021-12-03 19:33:58,098 [Executor task launch worker for task 148] INFO [org.apache.spark.executor.Executor] - Running task 17.0 in stage 10.0 (TID 148)
2021-12-03 19:33:58,098 [dispatcher-event-loop-9] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 18.0 in stage 10.0 (TID 149, localhost, executor driver, partition 18, ANY, 7759 bytes)
2021-12-03 19:33:58,098 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 8.0 in stage 10.0 (TID 139) in 123 ms on localhost (executor driver) (7/22)
2021-12-03 19:33:58,098 [Executor task launch worker for task 149] INFO [org.apache.spark.executor.Executor] - Running task 18.0 in stage 10.0 (TID 149)
2021-12-03 19:33:58,101 [Executor task launch worker for task 148] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 19:33:58,101 [Executor task launch worker for task 148] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 19:33:58,101 [Executor task launch worker for task 149] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 19:33:58,101 [Executor task launch worker for task 149] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 19:33:58,102 [Executor task launch worker for task 138] INFO [org.apache.spark.executor.Executor] - Finished task 7.0 in stage 10.0 (TID 138). 1053 bytes result sent to driver
2021-12-03 19:33:58,102 [dispatcher-event-loop-10] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 19.0 in stage 10.0 (TID 150, localhost, executor driver, partition 19, ANY, 7759 bytes)
2021-12-03 19:33:58,102 [Executor task launch worker for task 150] INFO [org.apache.spark.executor.Executor] - Running task 19.0 in stage 10.0 (TID 150)
2021-12-03 19:33:58,102 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 7.0 in stage 10.0 (TID 138) in 127 ms on localhost (executor driver) (8/22)
2021-12-03 19:33:58,104 [Executor task launch worker for task 135] INFO [org.apache.spark.executor.Executor] - Finished task 4.0 in stage 10.0 (TID 135). 1053 bytes result sent to driver
2021-12-03 19:33:58,104 [dispatcher-event-loop-4] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 20.0 in stage 10.0 (TID 151, localhost, executor driver, partition 20, ANY, 7759 bytes)
2021-12-03 19:33:58,104 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 4.0 in stage 10.0 (TID 135) in 130 ms on localhost (executor driver) (9/22)
2021-12-03 19:33:58,104 [Executor task launch worker for task 151] INFO [org.apache.spark.executor.Executor] - Running task 20.0 in stage 10.0 (TID 151)
2021-12-03 19:33:58,105 [Executor task launch worker for task 150] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 19:33:58,105 [Executor task launch worker for task 150] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 19:33:58,106 [Executor task launch worker for task 134] INFO [org.apache.spark.executor.Executor] - Finished task 3.0 in stage 10.0 (TID 134). 1053 bytes result sent to driver
2021-12-03 19:33:58,106 [dispatcher-event-loop-8] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 21.0 in stage 10.0 (TID 152, localhost, executor driver, partition 21, ANY, 7759 bytes)
2021-12-03 19:33:58,106 [Executor task launch worker for task 152] INFO [org.apache.spark.executor.Executor] - Running task 21.0 in stage 10.0 (TID 152)
2021-12-03 19:33:58,106 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 3.0 in stage 10.0 (TID 134) in 132 ms on localhost (executor driver) (10/22)
2021-12-03 19:33:58,107 [Executor task launch worker for task 151] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 19:33:58,107 [Executor task launch worker for task 151] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 19:33:58,109 [Executor task launch worker for task 152] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 19:33:58,109 [Executor task launch worker for task 152] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 19:33:58,128 [Executor task launch worker for task 133] INFO [org.apache.spark.executor.Executor] - Finished task 2.0 in stage 10.0 (TID 133). 1053 bytes result sent to driver
2021-12-03 19:33:58,129 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 2.0 in stage 10.0 (TID 133) in 155 ms on localhost (executor driver) (11/22)
2021-12-03 19:33:58,136 [Executor task launch worker for task 132] INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 10.0 (TID 132). 1053 bytes result sent to driver
2021-12-03 19:33:58,136 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 10.0 (TID 132) in 162 ms on localhost (executor driver) (12/22)
2021-12-03 19:33:58,157 [Executor task launch worker for task 145] INFO [org.apache.spark.executor.Executor] - Finished task 14.0 in stage 10.0 (TID 145). 1053 bytes result sent to driver
2021-12-03 19:33:58,158 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 14.0 in stage 10.0 (TID 145) in 67 ms on localhost (executor driver) (13/22)
2021-12-03 19:33:58,167 [Executor task launch worker for task 147] INFO [org.apache.spark.executor.Executor] - Finished task 16.0 in stage 10.0 (TID 147). 1096 bytes result sent to driver
2021-12-03 19:33:58,167 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 16.0 in stage 10.0 (TID 147) in 73 ms on localhost (executor driver) (14/22)
2021-12-03 19:33:58,173 [Executor task launch worker for task 146] INFO [org.apache.spark.executor.Executor] - Finished task 15.0 in stage 10.0 (TID 146). 1053 bytes result sent to driver
2021-12-03 19:33:58,173 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 15.0 in stage 10.0 (TID 146) in 82 ms on localhost (executor driver) (15/22)
2021-12-03 19:33:58,176 [Executor task launch worker for task 149] INFO [org.apache.spark.executor.Executor] - Finished task 18.0 in stage 10.0 (TID 149). 1053 bytes result sent to driver
2021-12-03 19:33:58,177 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 18.0 in stage 10.0 (TID 149) in 79 ms on localhost (executor driver) (16/22)
2021-12-03 19:33:58,182 [Executor task launch worker for task 150] INFO [org.apache.spark.executor.Executor] - Finished task 19.0 in stage 10.0 (TID 150). 1053 bytes result sent to driver
2021-12-03 19:33:58,182 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 19.0 in stage 10.0 (TID 150) in 80 ms on localhost (executor driver) (17/22)
2021-12-03 19:33:58,186 [Executor task launch worker for task 151] INFO [org.apache.spark.executor.Executor] - Finished task 20.0 in stage 10.0 (TID 151). 1053 bytes result sent to driver
2021-12-03 19:33:58,186 [Executor task launch worker for task 144] INFO [org.apache.spark.executor.Executor] - Finished task 13.0 in stage 10.0 (TID 144). 1053 bytes result sent to driver
2021-12-03 19:33:58,186 [Executor task launch worker for task 143] INFO [org.apache.spark.executor.Executor] - Finished task 12.0 in stage 10.0 (TID 143). 1053 bytes result sent to driver
2021-12-03 19:33:58,186 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 20.0 in stage 10.0 (TID 151) in 82 ms on localhost (executor driver) (18/22)
2021-12-03 19:33:58,186 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 13.0 in stage 10.0 (TID 144) in 96 ms on localhost (executor driver) (19/22)
2021-12-03 19:33:58,186 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 12.0 in stage 10.0 (TID 143) in 97 ms on localhost (executor driver) (20/22)
2021-12-03 19:33:58,191 [Executor task launch worker for task 152] INFO [org.apache.spark.executor.Executor] - Finished task 21.0 in stage 10.0 (TID 152). 1053 bytes result sent to driver
2021-12-03 19:33:58,191 [Executor task launch worker for task 148] INFO [org.apache.spark.executor.Executor] - Finished task 17.0 in stage 10.0 (TID 148). 1053 bytes result sent to driver
2021-12-03 19:33:58,191 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 21.0 in stage 10.0 (TID 152) in 85 ms on localhost (executor driver) (21/22)
2021-12-03 19:33:58,191 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 17.0 in stage 10.0 (TID 148) in 94 ms on localhost (executor driver) (22/22)
2021-12-03 19:33:58,191 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 10.0, whose tasks have all completed, from pool 
2021-12-03 19:33:58,191 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 10 (takeSample at PaidPromotionAdjustParameter.scala:76) finished in 0.222 s
2021-12-03 19:33:58,192 [main] INFO [org.apache.spark.scheduler.DAGScheduler] - Job 4 finished: takeSample at PaidPromotionAdjustParameter.scala:76, took 0.225120 s
2021-12-03 19:33:58,198 [main] INFO [org.apache.spark.SparkContext] - Starting job: takeSample at PaidPromotionAdjustParameter.scala:76
2021-12-03 19:33:58,199 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 5 (takeSample at PaidPromotionAdjustParameter.scala:76) with 22 output partitions
2021-12-03 19:33:58,199 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 13 (takeSample at PaidPromotionAdjustParameter.scala:76)
2021-12-03 19:33:58,199 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 12)
2021-12-03 19:33:58,199 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2021-12-03 19:33:58,199 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 13 (MapPartitionsRDD[11] at map at PaidPromotionAdjustParameter.scala:75), which has no missing parents
2021-12-03 19:33:58,201 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_8 stored as values in memory (estimated size 4.3 KB, free 1990.4 MB)
2021-12-03 19:33:58,202 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_8_piece0 stored as bytes in memory (estimated size 2.5 KB, free 1990.4 MB)
2021-12-03 19:33:58,202 [dispatcher-event-loop-3] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_8_piece0 in memory on qb:62255 (size: 2.5 KB, free: 1990.8 MB)
2021-12-03 19:33:58,202 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 8 from broadcast at DAGScheduler.scala:1039
2021-12-03 19:33:58,203 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 22 missing tasks from ResultStage 13 (MapPartitionsRDD[11] at map at PaidPromotionAdjustParameter.scala:75) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14))
2021-12-03 19:33:58,203 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 13.0 with 22 tasks
2021-12-03 19:33:58,203 [dispatcher-event-loop-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 13.0 (TID 153, localhost, executor driver, partition 0, ANY, 7759 bytes)
2021-12-03 19:33:58,203 [dispatcher-event-loop-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 13.0 (TID 154, localhost, executor driver, partition 1, ANY, 7759 bytes)
2021-12-03 19:33:58,203 [dispatcher-event-loop-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 2.0 in stage 13.0 (TID 155, localhost, executor driver, partition 2, ANY, 7759 bytes)
2021-12-03 19:33:58,203 [dispatcher-event-loop-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 3.0 in stage 13.0 (TID 156, localhost, executor driver, partition 3, ANY, 7759 bytes)
2021-12-03 19:33:58,203 [dispatcher-event-loop-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 4.0 in stage 13.0 (TID 157, localhost, executor driver, partition 4, ANY, 7759 bytes)
2021-12-03 19:33:58,203 [dispatcher-event-loop-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 5.0 in stage 13.0 (TID 158, localhost, executor driver, partition 5, ANY, 7759 bytes)
2021-12-03 19:33:58,203 [dispatcher-event-loop-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 6.0 in stage 13.0 (TID 159, localhost, executor driver, partition 6, ANY, 7759 bytes)
2021-12-03 19:33:58,203 [dispatcher-event-loop-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 7.0 in stage 13.0 (TID 160, localhost, executor driver, partition 7, ANY, 7759 bytes)
2021-12-03 19:33:58,204 [dispatcher-event-loop-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 8.0 in stage 13.0 (TID 161, localhost, executor driver, partition 8, ANY, 7759 bytes)
2021-12-03 19:33:58,204 [dispatcher-event-loop-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 9.0 in stage 13.0 (TID 162, localhost, executor driver, partition 9, ANY, 7759 bytes)
2021-12-03 19:33:58,204 [dispatcher-event-loop-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 10.0 in stage 13.0 (TID 163, localhost, executor driver, partition 10, ANY, 7759 bytes)
2021-12-03 19:33:58,204 [dispatcher-event-loop-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 11.0 in stage 13.0 (TID 164, localhost, executor driver, partition 11, ANY, 7759 bytes)
2021-12-03 19:33:58,204 [Executor task launch worker for task 156] INFO [org.apache.spark.executor.Executor] - Running task 3.0 in stage 13.0 (TID 156)
2021-12-03 19:33:58,204 [Executor task launch worker for task 160] INFO [org.apache.spark.executor.Executor] - Running task 7.0 in stage 13.0 (TID 160)
2021-12-03 19:33:58,204 [Executor task launch worker for task 159] INFO [org.apache.spark.executor.Executor] - Running task 6.0 in stage 13.0 (TID 159)
2021-12-03 19:33:58,204 [Executor task launch worker for task 158] INFO [org.apache.spark.executor.Executor] - Running task 5.0 in stage 13.0 (TID 158)
2021-12-03 19:33:58,204 [Executor task launch worker for task 154] INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 13.0 (TID 154)
2021-12-03 19:33:58,204 [Executor task launch worker for task 155] INFO [org.apache.spark.executor.Executor] - Running task 2.0 in stage 13.0 (TID 155)
2021-12-03 19:33:58,204 [Executor task launch worker for task 153] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 13.0 (TID 153)
2021-12-03 19:33:58,204 [Executor task launch worker for task 157] INFO [org.apache.spark.executor.Executor] - Running task 4.0 in stage 13.0 (TID 157)
2021-12-03 19:33:58,204 [Executor task launch worker for task 164] INFO [org.apache.spark.executor.Executor] - Running task 11.0 in stage 13.0 (TID 164)
2021-12-03 19:33:58,204 [Executor task launch worker for task 163] INFO [org.apache.spark.executor.Executor] - Running task 10.0 in stage 13.0 (TID 163)
2021-12-03 19:33:58,204 [Executor task launch worker for task 162] INFO [org.apache.spark.executor.Executor] - Running task 9.0 in stage 13.0 (TID 162)
2021-12-03 19:33:58,204 [Executor task launch worker for task 161] INFO [org.apache.spark.executor.Executor] - Running task 8.0 in stage 13.0 (TID 161)
2021-12-03 19:33:58,206 [Executor task launch worker for task 155] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 19:33:58,206 [Executor task launch worker for task 155] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 19:33:58,206 [Executor task launch worker for task 153] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 19:33:58,206 [Executor task launch worker for task 153] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 19:33:58,207 [Executor task launch worker for task 164] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 19:33:58,207 [Executor task launch worker for task 164] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 19:33:58,207 [Executor task launch worker for task 156] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 19:33:58,207 [Executor task launch worker for task 156] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 19:33:58,208 [Executor task launch worker for task 159] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 19:33:58,208 [Executor task launch worker for task 159] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 19:33:58,208 [Executor task launch worker for task 160] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 19:33:58,209 [Executor task launch worker for task 160] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 1 ms
2021-12-03 19:33:58,209 [Executor task launch worker for task 162] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 19:33:58,209 [Executor task launch worker for task 162] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 19:33:58,209 [Executor task launch worker for task 154] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 19:33:58,209 [Executor task launch worker for task 154] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 19:33:58,210 [Executor task launch worker for task 158] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 19:33:58,210 [Executor task launch worker for task 158] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 19:33:58,210 [Executor task launch worker for task 163] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 19:33:58,210 [Executor task launch worker for task 163] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 19:33:58,211 [Executor task launch worker for task 161] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 19:33:58,211 [Executor task launch worker for task 161] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 19:33:58,211 [Executor task launch worker for task 157] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 19:33:58,211 [Executor task launch worker for task 157] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 19:33:58,284 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 158
2021-12-03 19:33:58,284 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 152
2021-12-03 19:33:58,284 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 174
2021-12-03 19:33:58,284 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 164
2021-12-03 19:33:58,284 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 166
2021-12-03 19:33:58,284 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 160
2021-12-03 19:33:58,287 [dispatcher-event-loop-9] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_7_piece0 on qb:62255 in memory (size: 2.4 KB, free: 1990.8 MB)
2021-12-03 19:33:58,291 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 167
2021-12-03 19:33:58,291 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 169
2021-12-03 19:33:58,292 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 172
2021-12-03 19:33:58,292 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 165
2021-12-03 19:33:58,292 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 162
2021-12-03 19:33:58,292 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 150
2021-12-03 19:33:58,292 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 159
2021-12-03 19:33:58,292 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 161
2021-12-03 19:33:58,292 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 156
2021-12-03 19:33:58,292 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 163
2021-12-03 19:33:58,292 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 171
2021-12-03 19:33:58,292 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 151
2021-12-03 19:33:58,292 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 170
2021-12-03 19:33:58,292 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 173
2021-12-03 19:33:58,292 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 157
2021-12-03 19:33:58,292 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 168
2021-12-03 19:33:58,293 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 154
2021-12-03 19:33:58,293 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 153
2021-12-03 19:33:58,293 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 155
2021-12-03 19:33:58,316 [Executor task launch worker for task 164] INFO [org.apache.spark.executor.Executor] - Finished task 11.0 in stage 13.0 (TID 164). 1097 bytes result sent to driver
2021-12-03 19:33:58,318 [dispatcher-event-loop-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 12.0 in stage 13.0 (TID 165, localhost, executor driver, partition 12, ANY, 7759 bytes)
2021-12-03 19:33:58,318 [Executor task launch worker for task 165] INFO [org.apache.spark.executor.Executor] - Running task 12.0 in stage 13.0 (TID 165)
2021-12-03 19:33:58,320 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 11.0 in stage 13.0 (TID 164) in 116 ms on localhost (executor driver) (1/22)
2021-12-03 19:33:58,321 [Executor task launch worker for task 165] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 19:33:58,321 [Executor task launch worker for task 165] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 19:33:58,325 [Executor task launch worker for task 158] INFO [org.apache.spark.executor.Executor] - Finished task 5.0 in stage 13.0 (TID 158). 1140 bytes result sent to driver
2021-12-03 19:33:58,326 [dispatcher-event-loop-4] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 13.0 in stage 13.0 (TID 166, localhost, executor driver, partition 13, ANY, 7759 bytes)
2021-12-03 19:33:58,326 [Executor task launch worker for task 166] INFO [org.apache.spark.executor.Executor] - Running task 13.0 in stage 13.0 (TID 166)
2021-12-03 19:33:58,329 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 5.0 in stage 13.0 (TID 158) in 126 ms on localhost (executor driver) (2/22)
2021-12-03 19:33:58,329 [Executor task launch worker for task 166] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 19:33:58,329 [Executor task launch worker for task 166] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 19:33:58,333 [Executor task launch worker for task 163] INFO [org.apache.spark.executor.Executor] - Finished task 10.0 in stage 13.0 (TID 163). 1140 bytes result sent to driver
2021-12-03 19:33:58,333 [dispatcher-event-loop-5] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 14.0 in stage 13.0 (TID 167, localhost, executor driver, partition 14, ANY, 7759 bytes)
2021-12-03 19:33:58,333 [Executor task launch worker for task 167] INFO [org.apache.spark.executor.Executor] - Running task 14.0 in stage 13.0 (TID 167)
2021-12-03 19:33:58,333 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 10.0 in stage 13.0 (TID 163) in 129 ms on localhost (executor driver) (3/22)
2021-12-03 19:33:58,335 [Executor task launch worker for task 153] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 13.0 (TID 153). 1140 bytes result sent to driver
2021-12-03 19:33:58,335 [Executor task launch worker for task 162] INFO [org.apache.spark.executor.Executor] - Finished task 9.0 in stage 13.0 (TID 162). 1140 bytes result sent to driver
2021-12-03 19:33:58,335 [dispatcher-event-loop-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 15.0 in stage 13.0 (TID 168, localhost, executor driver, partition 15, ANY, 7759 bytes)
2021-12-03 19:33:58,335 [Executor task launch worker for task 168] INFO [org.apache.spark.executor.Executor] - Running task 15.0 in stage 13.0 (TID 168)
2021-12-03 19:33:58,335 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 13.0 (TID 153) in 132 ms on localhost (executor driver) (4/22)
2021-12-03 19:33:58,335 [dispatcher-event-loop-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 16.0 in stage 13.0 (TID 169, localhost, executor driver, partition 16, ANY, 7759 bytes)
2021-12-03 19:33:58,335 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 9.0 in stage 13.0 (TID 162) in 131 ms on localhost (executor driver) (5/22)
2021-12-03 19:33:58,336 [Executor task launch worker for task 169] INFO [org.apache.spark.executor.Executor] - Running task 16.0 in stage 13.0 (TID 169)
2021-12-03 19:33:58,336 [Executor task launch worker for task 167] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 19:33:58,336 [Executor task launch worker for task 167] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 19:33:58,338 [Executor task launch worker for task 169] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 19:33:58,338 [Executor task launch worker for task 169] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 19:33:58,338 [Executor task launch worker for task 168] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 19:33:58,338 [Executor task launch worker for task 168] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 19:33:58,339 [Executor task launch worker for task 159] INFO [org.apache.spark.executor.Executor] - Finished task 6.0 in stage 13.0 (TID 159). 1140 bytes result sent to driver
2021-12-03 19:33:58,340 [dispatcher-event-loop-7] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 17.0 in stage 13.0 (TID 170, localhost, executor driver, partition 17, ANY, 7759 bytes)
2021-12-03 19:33:58,340 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 6.0 in stage 13.0 (TID 159) in 137 ms on localhost (executor driver) (6/22)
2021-12-03 19:33:58,340 [Executor task launch worker for task 170] INFO [org.apache.spark.executor.Executor] - Running task 17.0 in stage 13.0 (TID 170)
2021-12-03 19:33:58,345 [Executor task launch worker for task 170] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 19:33:58,345 [Executor task launch worker for task 170] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 19:33:58,351 [Executor task launch worker for task 161] INFO [org.apache.spark.executor.Executor] - Finished task 8.0 in stage 13.0 (TID 161). 1140 bytes result sent to driver
2021-12-03 19:33:58,352 [Executor task launch worker for task 156] INFO [org.apache.spark.executor.Executor] - Finished task 3.0 in stage 13.0 (TID 156). 1140 bytes result sent to driver
2021-12-03 19:33:58,353 [dispatcher-event-loop-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 18.0 in stage 13.0 (TID 171, localhost, executor driver, partition 18, ANY, 7759 bytes)
2021-12-03 19:33:58,353 [dispatcher-event-loop-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 19.0 in stage 13.0 (TID 172, localhost, executor driver, partition 19, ANY, 7759 bytes)
2021-12-03 19:33:58,353 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 8.0 in stage 13.0 (TID 161) in 149 ms on localhost (executor driver) (7/22)
2021-12-03 19:33:58,353 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 3.0 in stage 13.0 (TID 156) in 150 ms on localhost (executor driver) (8/22)
2021-12-03 19:33:58,354 [Executor task launch worker for task 171] INFO [org.apache.spark.executor.Executor] - Running task 18.0 in stage 13.0 (TID 171)
2021-12-03 19:33:58,357 [Executor task launch worker for task 171] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 19:33:58,357 [Executor task launch worker for task 171] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 19:33:58,358 [Executor task launch worker for task 172] INFO [org.apache.spark.executor.Executor] - Running task 19.0 in stage 13.0 (TID 172)
2021-12-03 19:33:58,359 [Executor task launch worker for task 157] INFO [org.apache.spark.executor.Executor] - Finished task 4.0 in stage 13.0 (TID 157). 1140 bytes result sent to driver
2021-12-03 19:33:58,360 [dispatcher-event-loop-5] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 20.0 in stage 13.0 (TID 173, localhost, executor driver, partition 20, ANY, 7759 bytes)
2021-12-03 19:33:58,360 [Executor task launch worker for task 173] INFO [org.apache.spark.executor.Executor] - Running task 20.0 in stage 13.0 (TID 173)
2021-12-03 19:33:58,361 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 4.0 in stage 13.0 (TID 157) in 158 ms on localhost (executor driver) (9/22)
2021-12-03 19:33:58,361 [Executor task launch worker for task 172] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 19:33:58,361 [Executor task launch worker for task 172] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 19:33:58,362 [Executor task launch worker for task 160] INFO [org.apache.spark.executor.Executor] - Finished task 7.0 in stage 13.0 (TID 160). 1140 bytes result sent to driver
2021-12-03 19:33:58,362 [dispatcher-event-loop-8] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 21.0 in stage 13.0 (TID 174, localhost, executor driver, partition 21, ANY, 7759 bytes)
2021-12-03 19:33:58,363 [Executor task launch worker for task 173] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 19:33:58,363 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 7.0 in stage 13.0 (TID 160) in 160 ms on localhost (executor driver) (10/22)
2021-12-03 19:33:58,363 [Executor task launch worker for task 173] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 19:33:58,363 [Executor task launch worker for task 174] INFO [org.apache.spark.executor.Executor] - Running task 21.0 in stage 13.0 (TID 174)
2021-12-03 19:33:58,366 [Executor task launch worker for task 174] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 19:33:58,366 [Executor task launch worker for task 154] INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 13.0 (TID 154). 1140 bytes result sent to driver
2021-12-03 19:33:58,366 [Executor task launch worker for task 174] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 19:33:58,366 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 13.0 (TID 154) in 163 ms on localhost (executor driver) (11/22)
2021-12-03 19:33:58,372 [Executor task launch worker for task 155] INFO [org.apache.spark.executor.Executor] - Finished task 2.0 in stage 13.0 (TID 155). 1173 bytes result sent to driver
2021-12-03 19:33:58,373 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 2.0 in stage 13.0 (TID 155) in 170 ms on localhost (executor driver) (12/22)
2021-12-03 19:33:58,402 [Executor task launch worker for task 167] INFO [org.apache.spark.executor.Executor] - Finished task 14.0 in stage 13.0 (TID 167). 1054 bytes result sent to driver
2021-12-03 19:33:58,403 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 14.0 in stage 13.0 (TID 167) in 70 ms on localhost (executor driver) (13/22)
2021-12-03 19:33:58,413 [Executor task launch worker for task 169] INFO [org.apache.spark.executor.Executor] - Finished task 16.0 in stage 13.0 (TID 169). 1054 bytes result sent to driver
2021-12-03 19:33:58,414 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 16.0 in stage 13.0 (TID 169) in 79 ms on localhost (executor driver) (14/22)
2021-12-03 19:33:58,415 [Executor task launch worker for task 166] INFO [org.apache.spark.executor.Executor] - Finished task 13.0 in stage 13.0 (TID 166). 1054 bytes result sent to driver
2021-12-03 19:33:58,415 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 13.0 in stage 13.0 (TID 166) in 89 ms on localhost (executor driver) (15/22)
2021-12-03 19:33:58,416 [Executor task launch worker for task 165] INFO [org.apache.spark.executor.Executor] - Finished task 12.0 in stage 13.0 (TID 165). 1054 bytes result sent to driver
2021-12-03 19:33:58,417 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 12.0 in stage 13.0 (TID 165) in 99 ms on localhost (executor driver) (16/22)
2021-12-03 19:33:58,424 [Executor task launch worker for task 168] INFO [org.apache.spark.executor.Executor] - Finished task 15.0 in stage 13.0 (TID 168). 1054 bytes result sent to driver
2021-12-03 19:33:58,424 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 15.0 in stage 13.0 (TID 168) in 89 ms on localhost (executor driver) (17/22)
2021-12-03 19:33:58,433 [Executor task launch worker for task 171] INFO [org.apache.spark.executor.Executor] - Finished task 18.0 in stage 13.0 (TID 171). 1054 bytes result sent to driver
2021-12-03 19:33:58,433 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 18.0 in stage 13.0 (TID 171) in 81 ms on localhost (executor driver) (18/22)
2021-12-03 19:33:58,436 [Executor task launch worker for task 173] INFO [org.apache.spark.executor.Executor] - Finished task 20.0 in stage 13.0 (TID 173). 1140 bytes result sent to driver
2021-12-03 19:33:58,436 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 20.0 in stage 13.0 (TID 173) in 76 ms on localhost (executor driver) (19/22)
2021-12-03 19:33:58,441 [Executor task launch worker for task 172] INFO [org.apache.spark.executor.Executor] - Finished task 19.0 in stage 13.0 (TID 172). 1054 bytes result sent to driver
2021-12-03 19:33:58,441 [Executor task launch worker for task 174] INFO [org.apache.spark.executor.Executor] - Finished task 21.0 in stage 13.0 (TID 174). 1054 bytes result sent to driver
2021-12-03 19:33:58,441 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 19.0 in stage 13.0 (TID 172) in 88 ms on localhost (executor driver) (20/22)
2021-12-03 19:33:58,442 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 21.0 in stage 13.0 (TID 174) in 80 ms on localhost (executor driver) (21/22)
2021-12-03 19:33:58,444 [Executor task launch worker for task 170] INFO [org.apache.spark.executor.Executor] - Finished task 17.0 in stage 13.0 (TID 170). 1054 bytes result sent to driver
2021-12-03 19:33:58,444 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 17.0 in stage 13.0 (TID 170) in 105 ms on localhost (executor driver) (22/22)
2021-12-03 19:33:58,444 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 13.0, whose tasks have all completed, from pool 
2021-12-03 19:33:58,444 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 13 (takeSample at PaidPromotionAdjustParameter.scala:76) finished in 0.244 s
2021-12-03 19:33:58,444 [main] INFO [org.apache.spark.scheduler.DAGScheduler] - Job 5 finished: takeSample at PaidPromotionAdjustParameter.scala:76, took 0.245245 s
2021-12-03 19:33:58,449 [main] INFO [org.apache.spark.SparkContext] - Starting job: count at PaidPromotionAdjustParameter.scala:80
2021-12-03 19:33:58,450 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 6 (count at PaidPromotionAdjustParameter.scala:80) with 22 output partitions
2021-12-03 19:33:58,450 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 14 (count at PaidPromotionAdjustParameter.scala:80)
2021-12-03 19:33:58,450 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List()
2021-12-03 19:33:58,450 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2021-12-03 19:33:58,450 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 14 (MapPartitionsRDD[13] at map at PaidPromotionAdjustParameter.scala:79), which has no missing parents
2021-12-03 19:33:58,451 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_9 stored as values in memory (estimated size 3.7 KB, free 1990.4 MB)
2021-12-03 19:33:58,452 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_9_piece0 stored as bytes in memory (estimated size 2.2 KB, free 1990.4 MB)
2021-12-03 19:33:58,452 [dispatcher-event-loop-3] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_9_piece0 in memory on qb:62255 (size: 2.2 KB, free: 1990.8 MB)
2021-12-03 19:33:58,453 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 9 from broadcast at DAGScheduler.scala:1039
2021-12-03 19:33:58,453 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 22 missing tasks from ResultStage 14 (MapPartitionsRDD[13] at map at PaidPromotionAdjustParameter.scala:79) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14))
2021-12-03 19:33:58,453 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 14.0 with 22 tasks
2021-12-03 19:33:58,453 [dispatcher-event-loop-6] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 14.0 (TID 175, localhost, executor driver, partition 0, ANY, 7899 bytes)
2021-12-03 19:33:58,453 [dispatcher-event-loop-6] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 14.0 (TID 176, localhost, executor driver, partition 1, ANY, 7899 bytes)
2021-12-03 19:33:58,453 [dispatcher-event-loop-6] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 2.0 in stage 14.0 (TID 177, localhost, executor driver, partition 2, ANY, 7899 bytes)
2021-12-03 19:33:58,454 [dispatcher-event-loop-6] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 3.0 in stage 14.0 (TID 178, localhost, executor driver, partition 3, ANY, 7899 bytes)
2021-12-03 19:33:58,454 [dispatcher-event-loop-6] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 4.0 in stage 14.0 (TID 179, localhost, executor driver, partition 4, ANY, 7899 bytes)
2021-12-03 19:33:58,454 [dispatcher-event-loop-6] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 5.0 in stage 14.0 (TID 180, localhost, executor driver, partition 5, ANY, 7899 bytes)
2021-12-03 19:33:58,454 [dispatcher-event-loop-6] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 6.0 in stage 14.0 (TID 181, localhost, executor driver, partition 6, ANY, 7899 bytes)
2021-12-03 19:33:58,454 [dispatcher-event-loop-6] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 7.0 in stage 14.0 (TID 182, localhost, executor driver, partition 7, ANY, 7899 bytes)
2021-12-03 19:33:58,454 [dispatcher-event-loop-6] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 8.0 in stage 14.0 (TID 183, localhost, executor driver, partition 8, ANY, 7899 bytes)
2021-12-03 19:33:58,454 [dispatcher-event-loop-6] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 9.0 in stage 14.0 (TID 184, localhost, executor driver, partition 9, ANY, 7899 bytes)
2021-12-03 19:33:58,454 [dispatcher-event-loop-6] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 10.0 in stage 14.0 (TID 185, localhost, executor driver, partition 10, ANY, 7899 bytes)
2021-12-03 19:33:58,454 [dispatcher-event-loop-6] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 11.0 in stage 14.0 (TID 186, localhost, executor driver, partition 11, ANY, 7899 bytes)
2021-12-03 19:33:58,454 [Executor task launch worker for task 175] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 14.0 (TID 175)
2021-12-03 19:33:58,454 [Executor task launch worker for task 181] INFO [org.apache.spark.executor.Executor] - Running task 6.0 in stage 14.0 (TID 181)
2021-12-03 19:33:58,454 [Executor task launch worker for task 180] INFO [org.apache.spark.executor.Executor] - Running task 5.0 in stage 14.0 (TID 180)
2021-12-03 19:33:58,454 [Executor task launch worker for task 179] INFO [org.apache.spark.executor.Executor] - Running task 4.0 in stage 14.0 (TID 179)
2021-12-03 19:33:58,454 [Executor task launch worker for task 177] INFO [org.apache.spark.executor.Executor] - Running task 2.0 in stage 14.0 (TID 177)
2021-12-03 19:33:58,454 [Executor task launch worker for task 178] INFO [org.apache.spark.executor.Executor] - Running task 3.0 in stage 14.0 (TID 178)
2021-12-03 19:33:58,454 [Executor task launch worker for task 176] INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 14.0 (TID 176)
2021-12-03 19:33:58,454 [Executor task launch worker for task 182] INFO [org.apache.spark.executor.Executor] - Running task 7.0 in stage 14.0 (TID 182)
2021-12-03 19:33:58,454 [Executor task launch worker for task 185] INFO [org.apache.spark.executor.Executor] - Running task 10.0 in stage 14.0 (TID 185)
2021-12-03 19:33:58,454 [Executor task launch worker for task 186] INFO [org.apache.spark.executor.Executor] - Running task 11.0 in stage 14.0 (TID 186)
2021-12-03 19:33:58,454 [Executor task launch worker for task 184] INFO [org.apache.spark.executor.Executor] - Running task 9.0 in stage 14.0 (TID 184)
2021-12-03 19:33:58,455 [Executor task launch worker for task 176] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:134217728+134217728
2021-12-03 19:33:58,455 [Executor task launch worker for task 178] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:402653184+134217728
2021-12-03 19:33:58,455 [Executor task launch worker for task 185] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:1342177280+134217728
2021-12-03 19:33:58,454 [Executor task launch worker for task 183] INFO [org.apache.spark.executor.Executor] - Running task 8.0 in stage 14.0 (TID 183)
2021-12-03 19:33:58,456 [Executor task launch worker for task 177] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:268435456+134217728
2021-12-03 19:33:58,456 [Executor task launch worker for task 175] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:0+134217728
2021-12-03 19:33:58,456 [Executor task launch worker for task 179] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:536870912+134217728
2021-12-03 19:33:58,456 [Executor task launch worker for task 184] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:1207959552+134217728
2021-12-03 19:33:58,456 [Executor task launch worker for task 183] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:1073741824+134217728
2021-12-03 19:33:58,456 [Executor task launch worker for task 186] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:1476395008+134217728
2021-12-03 19:33:58,456 [Executor task launch worker for task 180] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:671088640+134217728
2021-12-03 19:33:58,455 [Executor task launch worker for task 182] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:939524096+134217728
2021-12-03 19:33:58,455 [Executor task launch worker for task 181] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:805306368+134217728
2021-12-03 19:34:00,165 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 175
2021-12-03 19:34:00,165 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 195
2021-12-03 19:34:00,165 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 185
2021-12-03 19:34:00,165 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 181
2021-12-03 19:34:00,165 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 191
2021-12-03 19:34:00,165 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 177
2021-12-03 19:34:00,165 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 194
2021-12-03 19:34:00,165 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 198
2021-12-03 19:34:00,165 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 196
2021-12-03 19:34:00,165 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 179
2021-12-03 19:34:00,165 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 199
2021-12-03 19:34:00,165 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 183
2021-12-03 19:34:00,165 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 186
2021-12-03 19:34:00,165 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 176
2021-12-03 19:34:00,165 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 188
2021-12-03 19:34:00,165 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 182
2021-12-03 19:34:00,165 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 197
2021-12-03 19:34:00,165 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 190
2021-12-03 19:34:00,166 [dispatcher-event-loop-10] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_8_piece0 on qb:62255 in memory (size: 2.5 KB, free: 1990.8 MB)
2021-12-03 19:34:00,166 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 189
2021-12-03 19:34:00,166 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 187
2021-12-03 19:34:00,166 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 192
2021-12-03 19:34:00,166 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 184
2021-12-03 19:34:00,166 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 178
2021-12-03 19:34:00,166 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 193
2021-12-03 19:34:00,166 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 180
2021-12-03 19:35:46,427 [Executor task launch worker for task 177] INFO [org.apache.spark.executor.Executor] - Finished task 2.0 in stage 14.0 (TID 177). 752 bytes result sent to driver
2021-12-03 19:35:46,428 [dispatcher-event-loop-9] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 12.0 in stage 14.0 (TID 187, localhost, executor driver, partition 12, ANY, 7899 bytes)
2021-12-03 19:35:46,428 [Executor task launch worker for task 187] INFO [org.apache.spark.executor.Executor] - Running task 12.0 in stage 14.0 (TID 187)
2021-12-03 19:35:46,428 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 2.0 in stage 14.0 (TID 177) in 107975 ms on localhost (executor driver) (1/22)
2021-12-03 19:35:46,428 [Executor task launch worker for task 187] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:1610612736+134217728
2021-12-03 19:35:50,824 [Executor task launch worker for task 186] INFO [org.apache.spark.executor.Executor] - Finished task 11.0 in stage 14.0 (TID 186). 752 bytes result sent to driver
2021-12-03 19:35:50,824 [dispatcher-event-loop-4] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 13.0 in stage 14.0 (TID 188, localhost, executor driver, partition 13, ANY, 7899 bytes)
2021-12-03 19:35:50,825 [Executor task launch worker for task 188] INFO [org.apache.spark.executor.Executor] - Running task 13.0 in stage 14.0 (TID 188)
2021-12-03 19:35:50,825 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 11.0 in stage 14.0 (TID 186) in 112371 ms on localhost (executor driver) (2/22)
2021-12-03 19:35:50,825 [Executor task launch worker for task 188] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:1744830464+134217728
2021-12-03 19:35:52,176 [Executor task launch worker for task 175] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 14.0 (TID 175). 795 bytes result sent to driver
2021-12-03 19:35:52,176 [dispatcher-event-loop-5] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 14.0 in stage 14.0 (TID 189, localhost, executor driver, partition 14, ANY, 7899 bytes)
2021-12-03 19:35:52,176 [Executor task launch worker for task 189] INFO [org.apache.spark.executor.Executor] - Running task 14.0 in stage 14.0 (TID 189)
2021-12-03 19:35:52,176 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 14.0 (TID 175) in 113723 ms on localhost (executor driver) (3/22)
2021-12-03 19:35:52,177 [Executor task launch worker for task 189] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:1879048192+134217728
2021-12-03 19:36:11,825 [Executor task launch worker for task 184] INFO [org.apache.spark.executor.Executor] - Finished task 9.0 in stage 14.0 (TID 184). 795 bytes result sent to driver
2021-12-03 19:36:11,826 [dispatcher-event-loop-7] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 15.0 in stage 14.0 (TID 190, localhost, executor driver, partition 15, ANY, 7899 bytes)
2021-12-03 19:36:11,826 [Executor task launch worker for task 190] INFO [org.apache.spark.executor.Executor] - Running task 15.0 in stage 14.0 (TID 190)
2021-12-03 19:36:11,826 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 9.0 in stage 14.0 (TID 184) in 133372 ms on localhost (executor driver) (4/22)
2021-12-03 19:36:11,826 [Executor task launch worker for task 190] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:2013265920+134217728
2021-12-03 19:36:16,223 [Executor task launch worker for task 178] INFO [org.apache.spark.executor.Executor] - Finished task 3.0 in stage 14.0 (TID 178). 752 bytes result sent to driver
2021-12-03 19:36:16,223 [dispatcher-event-loop-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 16.0 in stage 14.0 (TID 191, localhost, executor driver, partition 16, ANY, 7899 bytes)
2021-12-03 19:36:16,224 [Executor task launch worker for task 191] INFO [org.apache.spark.executor.Executor] - Running task 16.0 in stage 14.0 (TID 191)
2021-12-03 19:36:16,224 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 3.0 in stage 14.0 (TID 178) in 137770 ms on localhost (executor driver) (5/22)
2021-12-03 19:36:16,224 [Executor task launch worker for task 191] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:2147483648+134217728
2021-12-03 19:36:21,651 [Executor task launch worker for task 180] INFO [org.apache.spark.executor.Executor] - Finished task 5.0 in stage 14.0 (TID 180). 752 bytes result sent to driver
2021-12-03 19:36:21,652 [dispatcher-event-loop-8] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 17.0 in stage 14.0 (TID 192, localhost, executor driver, partition 17, ANY, 7899 bytes)
2021-12-03 19:36:21,652 [Executor task launch worker for task 192] INFO [org.apache.spark.executor.Executor] - Running task 17.0 in stage 14.0 (TID 192)
2021-12-03 19:36:21,652 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 5.0 in stage 14.0 (TID 180) in 143198 ms on localhost (executor driver) (6/22)
2021-12-03 19:36:21,652 [Executor task launch worker for task 192] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:2281701376+134217728
2021-12-03 19:36:26,874 [Executor task launch worker for task 176] INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 14.0 (TID 176). 752 bytes result sent to driver
2021-12-03 19:36:26,875 [dispatcher-event-loop-6] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 18.0 in stage 14.0 (TID 193, localhost, executor driver, partition 18, ANY, 7899 bytes)
2021-12-03 19:36:26,875 [Executor task launch worker for task 193] INFO [org.apache.spark.executor.Executor] - Running task 18.0 in stage 14.0 (TID 193)
2021-12-03 19:36:26,875 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 14.0 (TID 176) in 148422 ms on localhost (executor driver) (7/22)
2021-12-03 19:36:26,875 [Executor task launch worker for task 193] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:2415919104+134217728
2021-12-03 19:36:30,866 [Executor task launch worker for task 179] INFO [org.apache.spark.executor.Executor] - Finished task 4.0 in stage 14.0 (TID 179). 752 bytes result sent to driver
2021-12-03 19:36:30,867 [dispatcher-event-loop-7] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 19.0 in stage 14.0 (TID 194, localhost, executor driver, partition 19, ANY, 7899 bytes)
2021-12-03 19:36:30,867 [Executor task launch worker for task 194] INFO [org.apache.spark.executor.Executor] - Running task 19.0 in stage 14.0 (TID 194)
2021-12-03 19:36:30,867 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 4.0 in stage 14.0 (TID 179) in 152413 ms on localhost (executor driver) (8/22)
2021-12-03 19:36:30,867 [Executor task launch worker for task 194] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:2550136832+134217728
2021-12-03 19:36:31,909 [Executor task launch worker for task 181] INFO [org.apache.spark.executor.Executor] - Finished task 6.0 in stage 14.0 (TID 181). 752 bytes result sent to driver
2021-12-03 19:36:31,909 [dispatcher-event-loop-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 20.0 in stage 14.0 (TID 195, localhost, executor driver, partition 20, ANY, 7899 bytes)
2021-12-03 19:36:31,909 [Executor task launch worker for task 195] INFO [org.apache.spark.executor.Executor] - Running task 20.0 in stage 14.0 (TID 195)
2021-12-03 19:36:31,909 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 6.0 in stage 14.0 (TID 181) in 153455 ms on localhost (executor driver) (9/22)
2021-12-03 19:36:31,909 [Executor task launch worker for task 195] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:2684354560+134217728
2021-12-03 19:36:44,789 [Executor task launch worker for task 185] INFO [org.apache.spark.executor.Executor] - Finished task 10.0 in stage 14.0 (TID 185). 752 bytes result sent to driver
2021-12-03 19:36:44,790 [dispatcher-event-loop-8] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 21.0 in stage 14.0 (TID 196, localhost, executor driver, partition 21, ANY, 7899 bytes)
2021-12-03 19:36:44,790 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 10.0 in stage 14.0 (TID 185) in 166336 ms on localhost (executor driver) (10/22)
2021-12-03 19:36:44,790 [Executor task launch worker for task 196] INFO [org.apache.spark.executor.Executor] - Running task 21.0 in stage 14.0 (TID 196)
2021-12-03 19:36:44,791 [Executor task launch worker for task 196] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:2818572288+147216171
2021-12-03 19:36:47,983 [Executor task launch worker for task 183] INFO [org.apache.spark.executor.Executor] - Finished task 8.0 in stage 14.0 (TID 183). 752 bytes result sent to driver
2021-12-03 19:36:47,983 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 8.0 in stage 14.0 (TID 183) in 169529 ms on localhost (executor driver) (11/22)
2021-12-03 19:36:56,193 [Executor task launch worker for task 182] INFO [org.apache.spark.executor.Executor] - Finished task 7.0 in stage 14.0 (TID 182). 752 bytes result sent to driver
2021-12-03 19:36:56,193 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 7.0 in stage 14.0 (TID 182) in 177739 ms on localhost (executor driver) (12/22)
2021-12-03 19:37:41,786 [Executor task launch worker for task 190] INFO [org.apache.spark.executor.Executor] - Finished task 15.0 in stage 14.0 (TID 190). 709 bytes result sent to driver
2021-12-03 19:37:41,787 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 15.0 in stage 14.0 (TID 190) in 89961 ms on localhost (executor driver) (13/22)
2021-12-03 19:37:59,333 [Executor task launch worker for task 189] INFO [org.apache.spark.executor.Executor] - Finished task 14.0 in stage 14.0 (TID 189). 752 bytes result sent to driver
2021-12-03 19:37:59,333 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 14.0 in stage 14.0 (TID 189) in 127157 ms on localhost (executor driver) (14/22)
2021-12-03 19:38:11,144 [Executor task launch worker for task 191] INFO [org.apache.spark.executor.Executor] - Finished task 16.0 in stage 14.0 (TID 191). 709 bytes result sent to driver
2021-12-03 19:38:11,144 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 16.0 in stage 14.0 (TID 191) in 114921 ms on localhost (executor driver) (15/22)
2021-12-03 19:38:14,202 [Executor task launch worker for task 196] INFO [org.apache.spark.executor.Executor] - Finished task 21.0 in stage 14.0 (TID 196). 752 bytes result sent to driver
2021-12-03 19:38:14,203 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 21.0 in stage 14.0 (TID 196) in 89413 ms on localhost (executor driver) (16/22)
2021-12-03 19:38:14,616 [Executor task launch worker for task 187] INFO [org.apache.spark.executor.Executor] - Finished task 12.0 in stage 14.0 (TID 187). 710 bytes result sent to driver
2021-12-03 19:38:14,617 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 12.0 in stage 14.0 (TID 187) in 148190 ms on localhost (executor driver) (17/22)
2021-12-03 19:38:14,978 [Executor task launch worker for task 188] INFO [org.apache.spark.executor.Executor] - Finished task 13.0 in stage 14.0 (TID 188). 709 bytes result sent to driver
2021-12-03 19:38:14,978 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 13.0 in stage 14.0 (TID 188) in 144154 ms on localhost (executor driver) (18/22)
2021-12-03 19:38:16,493 [Executor task launch worker for task 195] INFO [org.apache.spark.executor.Executor] - Finished task 20.0 in stage 14.0 (TID 195). 709 bytes result sent to driver
2021-12-03 19:38:16,493 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 20.0 in stage 14.0 (TID 195) in 104584 ms on localhost (executor driver) (19/22)
2021-12-03 19:38:18,207 [Executor task launch worker for task 193] INFO [org.apache.spark.executor.Executor] - Finished task 18.0 in stage 14.0 (TID 193). 709 bytes result sent to driver
2021-12-03 19:38:18,207 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 18.0 in stage 14.0 (TID 193) in 111333 ms on localhost (executor driver) (20/22)
2021-12-03 19:38:18,650 [Executor task launch worker for task 194] INFO [org.apache.spark.executor.Executor] - Finished task 19.0 in stage 14.0 (TID 194). 709 bytes result sent to driver
2021-12-03 19:38:18,650 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 19.0 in stage 14.0 (TID 194) in 107783 ms on localhost (executor driver) (21/22)
2021-12-03 19:38:19,228 [Executor task launch worker for task 192] INFO [org.apache.spark.executor.Executor] - Finished task 17.0 in stage 14.0 (TID 192). 709 bytes result sent to driver
2021-12-03 19:38:19,229 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 17.0 in stage 14.0 (TID 192) in 117577 ms on localhost (executor driver) (22/22)
2021-12-03 19:38:19,229 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 14.0, whose tasks have all completed, from pool 
2021-12-03 19:38:19,229 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 14 (count at PaidPromotionAdjustParameter.scala:80) finished in 260.778 s
2021-12-03 19:38:19,229 [main] INFO [org.apache.spark.scheduler.DAGScheduler] - Job 6 finished: count at PaidPromotionAdjustParameter.scala:80, took 260.779353 s
2021-12-03 19:38:19,229 [main] INFO [PaidPromotion$] - 抽样总数：127
2021-12-03 19:38:19,242 [main] INFO [org.apache.hadoop.conf.Configuration.deprecation] - mapred.output.dir is deprecated. Instead, use mapreduce.output.fileoutputformat.outputdir
2021-12-03 19:38:19,244 [main] INFO [org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter] - File Output Committer Algorithm version is 1
2021-12-03 19:38:19,272 [main] INFO [org.apache.spark.SparkContext] - Starting job: runJob at SparkHadoopWriter.scala:78
2021-12-03 19:38:19,272 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 7 (runJob at SparkHadoopWriter.scala:78) with 22 output partitions
2021-12-03 19:38:19,272 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 15 (runJob at SparkHadoopWriter.scala:78)
2021-12-03 19:38:19,272 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List()
2021-12-03 19:38:19,272 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2021-12-03 19:38:19,273 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 15 (MapPartitionsRDD[14] at saveAsTextFile at PaidPromotionAdjustParameter.scala:82), which has no missing parents
2021-12-03 19:38:19,281 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_10 stored as values in memory (estimated size 79.9 KB, free 1990.4 MB)
2021-12-03 19:38:19,283 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_10_piece0 stored as bytes in memory (estimated size 30.5 KB, free 1990.3 MB)
2021-12-03 19:38:19,283 [dispatcher-event-loop-8] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_10_piece0 in memory on qb:62255 (size: 30.5 KB, free: 1990.7 MB)
2021-12-03 19:38:19,284 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 10 from broadcast at DAGScheduler.scala:1039
2021-12-03 19:38:19,284 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 22 missing tasks from ResultStage 15 (MapPartitionsRDD[14] at saveAsTextFile at PaidPromotionAdjustParameter.scala:82) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14))
2021-12-03 19:38:19,284 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 15.0 with 22 tasks
2021-12-03 19:38:19,284 [dispatcher-event-loop-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 15.0 (TID 197, localhost, executor driver, partition 0, ANY, 7899 bytes)
2021-12-03 19:38:19,284 [dispatcher-event-loop-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 15.0 (TID 198, localhost, executor driver, partition 1, ANY, 7899 bytes)
2021-12-03 19:38:19,285 [dispatcher-event-loop-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 2.0 in stage 15.0 (TID 199, localhost, executor driver, partition 2, ANY, 7899 bytes)
2021-12-03 19:38:19,285 [dispatcher-event-loop-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 3.0 in stage 15.0 (TID 200, localhost, executor driver, partition 3, ANY, 7899 bytes)
2021-12-03 19:38:19,285 [dispatcher-event-loop-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 4.0 in stage 15.0 (TID 201, localhost, executor driver, partition 4, ANY, 7899 bytes)
2021-12-03 19:38:19,285 [dispatcher-event-loop-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 5.0 in stage 15.0 (TID 202, localhost, executor driver, partition 5, ANY, 7899 bytes)
2021-12-03 19:38:19,285 [dispatcher-event-loop-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 6.0 in stage 15.0 (TID 203, localhost, executor driver, partition 6, ANY, 7899 bytes)
2021-12-03 19:38:19,285 [dispatcher-event-loop-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 7.0 in stage 15.0 (TID 204, localhost, executor driver, partition 7, ANY, 7899 bytes)
2021-12-03 19:38:19,285 [dispatcher-event-loop-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 8.0 in stage 15.0 (TID 205, localhost, executor driver, partition 8, ANY, 7899 bytes)
2021-12-03 19:38:19,285 [dispatcher-event-loop-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 9.0 in stage 15.0 (TID 206, localhost, executor driver, partition 9, ANY, 7899 bytes)
2021-12-03 19:38:19,285 [dispatcher-event-loop-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 10.0 in stage 15.0 (TID 207, localhost, executor driver, partition 10, ANY, 7899 bytes)
2021-12-03 19:38:19,285 [dispatcher-event-loop-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 11.0 in stage 15.0 (TID 208, localhost, executor driver, partition 11, ANY, 7899 bytes)
2021-12-03 19:38:19,285 [Executor task launch worker for task 198] INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 15.0 (TID 198)
2021-12-03 19:38:19,285 [Executor task launch worker for task 202] INFO [org.apache.spark.executor.Executor] - Running task 5.0 in stage 15.0 (TID 202)
2021-12-03 19:38:19,285 [Executor task launch worker for task 206] INFO [org.apache.spark.executor.Executor] - Running task 9.0 in stage 15.0 (TID 206)
2021-12-03 19:38:19,285 [Executor task launch worker for task 199] INFO [org.apache.spark.executor.Executor] - Running task 2.0 in stage 15.0 (TID 199)
2021-12-03 19:38:19,285 [Executor task launch worker for task 197] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 15.0 (TID 197)
2021-12-03 19:38:19,285 [Executor task launch worker for task 200] INFO [org.apache.spark.executor.Executor] - Running task 3.0 in stage 15.0 (TID 200)
2021-12-03 19:38:19,285 [Executor task launch worker for task 204] INFO [org.apache.spark.executor.Executor] - Running task 7.0 in stage 15.0 (TID 204)
2021-12-03 19:38:19,285 [Executor task launch worker for task 201] INFO [org.apache.spark.executor.Executor] - Running task 4.0 in stage 15.0 (TID 201)
2021-12-03 19:38:19,285 [Executor task launch worker for task 203] INFO [org.apache.spark.executor.Executor] - Running task 6.0 in stage 15.0 (TID 203)
2021-12-03 19:38:19,285 [Executor task launch worker for task 205] INFO [org.apache.spark.executor.Executor] - Running task 8.0 in stage 15.0 (TID 205)
2021-12-03 19:38:19,286 [Executor task launch worker for task 207] INFO [org.apache.spark.executor.Executor] - Running task 10.0 in stage 15.0 (TID 207)
2021-12-03 19:38:19,286 [Executor task launch worker for task 208] INFO [org.apache.spark.executor.Executor] - Running task 11.0 in stage 15.0 (TID 208)
2021-12-03 19:38:19,306 [Executor task launch worker for task 208] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:1476395008+134217728
2021-12-03 19:38:19,306 [Executor task launch worker for task 204] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:939524096+134217728
2021-12-03 19:38:19,306 [Executor task launch worker for task 197] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:0+134217728
2021-12-03 19:38:19,307 [Executor task launch worker for task 200] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:402653184+134217728
2021-12-03 19:38:19,307 [Executor task launch worker for task 201] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:536870912+134217728
2021-12-03 19:38:19,307 [Executor task launch worker for task 205] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:1073741824+134217728
2021-12-03 19:38:19,308 [Executor task launch worker for task 198] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:134217728+134217728
2021-12-03 19:38:19,309 [Executor task launch worker for task 202] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:671088640+134217728
2021-12-03 19:38:19,309 [Executor task launch worker for task 199] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:268435456+134217728
2021-12-03 19:38:19,309 [Executor task launch worker for task 207] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:1342177280+134217728
2021-12-03 19:38:19,310 [Executor task launch worker for task 203] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:805306368+134217728
2021-12-03 19:38:19,310 [Executor task launch worker for task 206] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:1207959552+134217728
2021-12-03 19:38:19,318 [Executor task launch worker for task 197] INFO [org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter] - File Output Committer Algorithm version is 1
2021-12-03 19:38:19,339 [Executor task launch worker for task 201] INFO [org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter] - File Output Committer Algorithm version is 1
2021-12-03 19:38:19,376 [Executor task launch worker for task 202] INFO [org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter] - File Output Committer Algorithm version is 1
2021-12-03 19:38:19,440 [Executor task launch worker for task 198] INFO [org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter] - File Output Committer Algorithm version is 1
2021-12-03 19:38:19,516 [Executor task launch worker for task 205] INFO [org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter] - File Output Committer Algorithm version is 1
2021-12-03 19:38:19,554 [Executor task launch worker for task 200] INFO [org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter] - File Output Committer Algorithm version is 1
2021-12-03 19:38:19,565 [Executor task launch worker for task 204] INFO [org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter] - File Output Committer Algorithm version is 1
2021-12-03 19:38:19,582 [Executor task launch worker for task 199] INFO [org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter] - File Output Committer Algorithm version is 1
2021-12-03 19:38:19,620 [Executor task launch worker for task 203] INFO [org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter] - File Output Committer Algorithm version is 1
2021-12-03 19:38:19,636 [Executor task launch worker for task 206] INFO [org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter] - File Output Committer Algorithm version is 1
2021-12-03 19:38:19,681 [Executor task launch worker for task 208] INFO [org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter] - File Output Committer Algorithm version is 1
2021-12-03 19:38:19,709 [Executor task launch worker for task 207] INFO [org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter] - File Output Committer Algorithm version is 1
2021-12-03 19:40:24,087 [Executor task launch worker for task 198] INFO [org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter] - Saved output of task 'attempt_20211203193819_0014_m_000001_0' to hdfs://hdp1:8020/sk/chongqing/sample_data/filter-sample-device-video-data.bcp/_temporary/0/task_20211203193819_0014_m_000001
2021-12-03 19:40:24,087 [Executor task launch worker for task 198] INFO [org.apache.spark.mapred.SparkHadoopMapRedUtil] - attempt_20211203193819_0014_m_000001_0: Committed
2021-12-03 19:40:24,089 [Executor task launch worker for task 198] INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 15.0 (TID 198). 912 bytes result sent to driver
2021-12-03 19:40:24,089 [dispatcher-event-loop-7] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 12.0 in stage 15.0 (TID 209, localhost, executor driver, partition 12, ANY, 7899 bytes)
2021-12-03 19:40:24,089 [Executor task launch worker for task 209] INFO [org.apache.spark.executor.Executor] - Running task 12.0 in stage 15.0 (TID 209)
2021-12-03 19:40:24,090 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 15.0 (TID 198) in 124806 ms on localhost (executor driver) (1/22)
2021-12-03 19:40:24,093 [Executor task launch worker for task 209] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:1610612736+134217728
2021-12-03 19:40:25,166 [Executor task launch worker for task 209] INFO [org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter] - File Output Committer Algorithm version is 1
2021-12-03 19:40:38,666 [Executor task launch worker for task 202] INFO [org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter] - Saved output of task 'attempt_20211203193819_0014_m_000005_0' to hdfs://hdp1:8020/sk/chongqing/sample_data/filter-sample-device-video-data.bcp/_temporary/0/task_20211203193819_0014_m_000005
2021-12-03 19:40:38,666 [Executor task launch worker for task 202] INFO [org.apache.spark.mapred.SparkHadoopMapRedUtil] - attempt_20211203193819_0014_m_000005_0: Committed
2021-12-03 19:40:38,667 [Executor task launch worker for task 202] INFO [org.apache.spark.executor.Executor] - Finished task 5.0 in stage 15.0 (TID 202). 912 bytes result sent to driver
2021-12-03 19:40:38,667 [dispatcher-event-loop-8] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 13.0 in stage 15.0 (TID 210, localhost, executor driver, partition 13, ANY, 7899 bytes)
2021-12-03 19:40:38,667 [Executor task launch worker for task 210] INFO [org.apache.spark.executor.Executor] - Running task 13.0 in stage 15.0 (TID 210)
2021-12-03 19:40:38,668 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 5.0 in stage 15.0 (TID 202) in 139383 ms on localhost (executor driver) (2/22)
2021-12-03 19:40:38,670 [Executor task launch worker for task 210] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:1744830464+134217728
2021-12-03 19:40:39,101 [Executor task launch worker for task 197] INFO [org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter] - Saved output of task 'attempt_20211203193819_0014_m_000000_0' to hdfs://hdp1:8020/sk/chongqing/sample_data/filter-sample-device-video-data.bcp/_temporary/0/task_20211203193819_0014_m_000000
2021-12-03 19:40:39,101 [Executor task launch worker for task 197] INFO [org.apache.spark.mapred.SparkHadoopMapRedUtil] - attempt_20211203193819_0014_m_000000_0: Committed
2021-12-03 19:40:39,102 [Executor task launch worker for task 197] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 15.0 (TID 197). 912 bytes result sent to driver
2021-12-03 19:40:39,102 [dispatcher-event-loop-6] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 14.0 in stage 15.0 (TID 211, localhost, executor driver, partition 14, ANY, 7899 bytes)
2021-12-03 19:40:39,103 [Executor task launch worker for task 211] INFO [org.apache.spark.executor.Executor] - Running task 14.0 in stage 15.0 (TID 211)
2021-12-03 19:40:39,103 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 15.0 (TID 197) in 139819 ms on localhost (executor driver) (3/22)
2021-12-03 19:40:39,105 [Executor task launch worker for task 211] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:1879048192+134217728
2021-12-03 19:40:39,157 [Executor task launch worker for task 210] INFO [org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter] - File Output Committer Algorithm version is 1
2021-12-03 19:40:39,417 [Executor task launch worker for task 201] INFO [org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter] - Saved output of task 'attempt_20211203193819_0014_m_000004_0' to hdfs://hdp1:8020/sk/chongqing/sample_data/filter-sample-device-video-data.bcp/_temporary/0/task_20211203193819_0014_m_000004
2021-12-03 19:40:39,417 [Executor task launch worker for task 201] INFO [org.apache.spark.mapred.SparkHadoopMapRedUtil] - attempt_20211203193819_0014_m_000004_0: Committed
2021-12-03 19:40:39,418 [Executor task launch worker for task 201] INFO [org.apache.spark.executor.Executor] - Finished task 4.0 in stage 15.0 (TID 201). 869 bytes result sent to driver
2021-12-03 19:40:39,418 [dispatcher-event-loop-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 15.0 in stage 15.0 (TID 212, localhost, executor driver, partition 15, ANY, 7899 bytes)
2021-12-03 19:40:39,418 [Executor task launch worker for task 212] INFO [org.apache.spark.executor.Executor] - Running task 15.0 in stage 15.0 (TID 212)
2021-12-03 19:40:39,419 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 4.0 in stage 15.0 (TID 201) in 140134 ms on localhost (executor driver) (4/22)
2021-12-03 19:40:39,421 [Executor task launch worker for task 212] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:2013265920+134217728
2021-12-03 19:40:39,631 [Executor task launch worker for task 207] INFO [org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter] - Saved output of task 'attempt_20211203193819_0014_m_000010_0' to hdfs://hdp1:8020/sk/chongqing/sample_data/filter-sample-device-video-data.bcp/_temporary/0/task_20211203193819_0014_m_000010
2021-12-03 19:40:39,631 [Executor task launch worker for task 207] INFO [org.apache.spark.mapred.SparkHadoopMapRedUtil] - attempt_20211203193819_0014_m_000010_0: Committed
2021-12-03 19:40:39,632 [Executor task launch worker for task 207] INFO [org.apache.spark.executor.Executor] - Finished task 10.0 in stage 15.0 (TID 207). 869 bytes result sent to driver
2021-12-03 19:40:39,633 [dispatcher-event-loop-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 16.0 in stage 15.0 (TID 213, localhost, executor driver, partition 16, ANY, 7899 bytes)
2021-12-03 19:40:39,633 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 10.0 in stage 15.0 (TID 207) in 140348 ms on localhost (executor driver) (5/22)
2021-12-03 19:40:39,633 [Executor task launch worker for task 213] INFO [org.apache.spark.executor.Executor] - Running task 16.0 in stage 15.0 (TID 213)
2021-12-03 19:40:39,635 [Executor task launch worker for task 213] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:2147483648+134217728
2021-12-03 19:40:39,667 [Executor task launch worker for task 211] INFO [org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter] - File Output Committer Algorithm version is 1
2021-12-03 19:40:39,844 [Executor task launch worker for task 212] INFO [org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter] - File Output Committer Algorithm version is 1
2021-12-03 19:40:40,309 [Executor task launch worker for task 213] INFO [org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter] - File Output Committer Algorithm version is 1
2021-12-03 19:40:42,064 [Executor task launch worker for task 206] INFO [org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter] - Saved output of task 'attempt_20211203193819_0014_m_000009_0' to hdfs://hdp1:8020/sk/chongqing/sample_data/filter-sample-device-video-data.bcp/_temporary/0/task_20211203193819_0014_m_000009
2021-12-03 19:40:42,064 [Executor task launch worker for task 206] INFO [org.apache.spark.mapred.SparkHadoopMapRedUtil] - attempt_20211203193819_0014_m_000009_0: Committed
2021-12-03 19:40:42,065 [Executor task launch worker for task 206] INFO [org.apache.spark.executor.Executor] - Finished task 9.0 in stage 15.0 (TID 206). 912 bytes result sent to driver
2021-12-03 19:40:42,065 [dispatcher-event-loop-8] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 17.0 in stage 15.0 (TID 214, localhost, executor driver, partition 17, ANY, 7899 bytes)
2021-12-03 19:40:42,066 [Executor task launch worker for task 214] INFO [org.apache.spark.executor.Executor] - Running task 17.0 in stage 15.0 (TID 214)
2021-12-03 19:40:42,066 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 9.0 in stage 15.0 (TID 206) in 142781 ms on localhost (executor driver) (6/22)
2021-12-03 19:40:42,069 [Executor task launch worker for task 214] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:2281701376+134217728
2021-12-03 19:40:42,579 [Executor task launch worker for task 214] INFO [org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter] - File Output Committer Algorithm version is 1
2021-12-03 19:40:46,701 [Executor task launch worker for task 204] INFO [org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter] - Saved output of task 'attempt_20211203193819_0014_m_000007_0' to hdfs://hdp1:8020/sk/chongqing/sample_data/filter-sample-device-video-data.bcp/_temporary/0/task_20211203193819_0014_m_000007
2021-12-03 19:40:46,701 [Executor task launch worker for task 204] INFO [org.apache.spark.mapred.SparkHadoopMapRedUtil] - attempt_20211203193819_0014_m_000007_0: Committed
2021-12-03 19:40:46,702 [Executor task launch worker for task 204] INFO [org.apache.spark.executor.Executor] - Finished task 7.0 in stage 15.0 (TID 204). 912 bytes result sent to driver
2021-12-03 19:40:46,702 [dispatcher-event-loop-6] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 18.0 in stage 15.0 (TID 215, localhost, executor driver, partition 18, ANY, 7899 bytes)
2021-12-03 19:40:46,702 [Executor task launch worker for task 215] INFO [org.apache.spark.executor.Executor] - Running task 18.0 in stage 15.0 (TID 215)
2021-12-03 19:40:46,702 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 7.0 in stage 15.0 (TID 204) in 147417 ms on localhost (executor driver) (7/22)
2021-12-03 19:40:46,706 [Executor task launch worker for task 215] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:2415919104+134217728
2021-12-03 19:40:47,435 [Executor task launch worker for task 215] INFO [org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter] - File Output Committer Algorithm version is 1
2021-12-03 19:40:48,161 [Executor task launch worker for task 205] INFO [org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter] - Saved output of task 'attempt_20211203193819_0014_m_000008_0' to hdfs://hdp1:8020/sk/chongqing/sample_data/filter-sample-device-video-data.bcp/_temporary/0/task_20211203193819_0014_m_000008
2021-12-03 19:40:48,161 [Executor task launch worker for task 205] INFO [org.apache.spark.mapred.SparkHadoopMapRedUtil] - attempt_20211203193819_0014_m_000008_0: Committed
2021-12-03 19:40:48,162 [Executor task launch worker for task 205] INFO [org.apache.spark.executor.Executor] - Finished task 8.0 in stage 15.0 (TID 205). 912 bytes result sent to driver
2021-12-03 19:40:48,162 [dispatcher-event-loop-4] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 19.0 in stage 15.0 (TID 216, localhost, executor driver, partition 19, ANY, 7899 bytes)
2021-12-03 19:40:48,162 [Executor task launch worker for task 216] INFO [org.apache.spark.executor.Executor] - Running task 19.0 in stage 15.0 (TID 216)
2021-12-03 19:40:48,162 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 8.0 in stage 15.0 (TID 205) in 148877 ms on localhost (executor driver) (8/22)
2021-12-03 19:40:48,165 [Executor task launch worker for task 216] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:2550136832+134217728
2021-12-03 19:40:49,827 [Executor task launch worker for task 216] INFO [org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter] - File Output Committer Algorithm version is 1
2021-12-03 19:40:52,497 [Executor task launch worker for task 203] INFO [org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter] - Saved output of task 'attempt_20211203193819_0014_m_000006_0' to hdfs://hdp1:8020/sk/chongqing/sample_data/filter-sample-device-video-data.bcp/_temporary/0/task_20211203193819_0014_m_000006
2021-12-03 19:40:52,497 [Executor task launch worker for task 203] INFO [org.apache.spark.mapred.SparkHadoopMapRedUtil] - attempt_20211203193819_0014_m_000006_0: Committed
2021-12-03 19:40:52,498 [Executor task launch worker for task 203] INFO [org.apache.spark.executor.Executor] - Finished task 6.0 in stage 15.0 (TID 203). 869 bytes result sent to driver
2021-12-03 19:40:52,499 [dispatcher-event-loop-5] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 20.0 in stage 15.0 (TID 217, localhost, executor driver, partition 20, ANY, 7899 bytes)
2021-12-03 19:40:52,499 [Executor task launch worker for task 217] INFO [org.apache.spark.executor.Executor] - Running task 20.0 in stage 15.0 (TID 217)
2021-12-03 19:40:52,499 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 6.0 in stage 15.0 (TID 203) in 153214 ms on localhost (executor driver) (9/22)
2021-12-03 19:40:52,501 [Executor task launch worker for task 217] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:2684354560+134217728
2021-12-03 19:40:53,115 [Executor task launch worker for task 217] INFO [org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter] - File Output Committer Algorithm version is 1
2021-12-03 19:40:56,322 [Executor task launch worker for task 200] INFO [org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter] - Saved output of task 'attempt_20211203193819_0014_m_000003_0' to hdfs://hdp1:8020/sk/chongqing/sample_data/filter-sample-device-video-data.bcp/_temporary/0/task_20211203193819_0014_m_000003
2021-12-03 19:40:56,323 [Executor task launch worker for task 200] INFO [org.apache.spark.mapred.SparkHadoopMapRedUtil] - attempt_20211203193819_0014_m_000003_0: Committed
2021-12-03 19:40:56,323 [Executor task launch worker for task 200] INFO [org.apache.spark.executor.Executor] - Finished task 3.0 in stage 15.0 (TID 200). 912 bytes result sent to driver
2021-12-03 19:40:56,324 [dispatcher-event-loop-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 21.0 in stage 15.0 (TID 218, localhost, executor driver, partition 21, ANY, 7899 bytes)
2021-12-03 19:40:56,324 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 3.0 in stage 15.0 (TID 200) in 157039 ms on localhost (executor driver) (10/22)
2021-12-03 19:40:56,324 [Executor task launch worker for task 218] INFO [org.apache.spark.executor.Executor] - Running task 21.0 in stage 15.0 (TID 218)
2021-12-03 19:40:56,327 [Executor task launch worker for task 218] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:2818572288+147216171
2021-12-03 19:40:56,999 [Executor task launch worker for task 218] INFO [org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter] - File Output Committer Algorithm version is 1
2021-12-03 19:40:58,966 [Executor task launch worker for task 208] INFO [org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter] - Saved output of task 'attempt_20211203193819_0014_m_000011_0' to hdfs://hdp1:8020/sk/chongqing/sample_data/filter-sample-device-video-data.bcp/_temporary/0/task_20211203193819_0014_m_000011
2021-12-03 19:40:58,966 [Executor task launch worker for task 208] INFO [org.apache.spark.mapred.SparkHadoopMapRedUtil] - attempt_20211203193819_0014_m_000011_0: Committed
2021-12-03 19:40:58,967 [Executor task launch worker for task 208] INFO [org.apache.spark.executor.Executor] - Finished task 11.0 in stage 15.0 (TID 208). 912 bytes result sent to driver
2021-12-03 19:40:58,967 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 11.0 in stage 15.0 (TID 208) in 159682 ms on localhost (executor driver) (11/22)
2021-12-03 19:41:01,499 [Executor task launch worker for task 199] INFO [org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter] - Saved output of task 'attempt_20211203193819_0014_m_000002_0' to hdfs://hdp1:8020/sk/chongqing/sample_data/filter-sample-device-video-data.bcp/_temporary/0/task_20211203193819_0014_m_000002
2021-12-03 19:41:01,499 [Executor task launch worker for task 199] INFO [org.apache.spark.mapred.SparkHadoopMapRedUtil] - attempt_20211203193819_0014_m_000002_0: Committed
2021-12-03 19:41:01,500 [Executor task launch worker for task 199] INFO [org.apache.spark.executor.Executor] - Finished task 2.0 in stage 15.0 (TID 199). 869 bytes result sent to driver
2021-12-03 19:41:01,501 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 2.0 in stage 15.0 (TID 199) in 162216 ms on localhost (executor driver) (12/22)
2021-12-03 19:42:04,187 [Executor task launch worker for task 217] INFO [org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter] - Saved output of task 'attempt_20211203193819_0014_m_000020_0' to hdfs://hdp1:8020/sk/chongqing/sample_data/filter-sample-device-video-data.bcp/_temporary/0/task_20211203193819_0014_m_000020
2021-12-03 19:42:04,187 [Executor task launch worker for task 217] INFO [org.apache.spark.mapred.SparkHadoopMapRedUtil] - attempt_20211203193819_0014_m_000020_0: Committed
2021-12-03 19:42:04,188 [Executor task launch worker for task 217] INFO [org.apache.spark.executor.Executor] - Finished task 20.0 in stage 15.0 (TID 217). 869 bytes result sent to driver
2021-12-03 19:42:04,188 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 20.0 in stage 15.0 (TID 217) in 71690 ms on localhost (executor driver) (13/22)
2021-12-03 19:42:13,171 [Executor task launch worker for task 212] INFO [org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter] - Saved output of task 'attempt_20211203193819_0014_m_000015_0' to hdfs://hdp1:8020/sk/chongqing/sample_data/filter-sample-device-video-data.bcp/_temporary/0/task_20211203193819_0014_m_000015
2021-12-03 19:42:13,171 [Executor task launch worker for task 212] INFO [org.apache.spark.mapred.SparkHadoopMapRedUtil] - attempt_20211203193819_0014_m_000015_0: Committed
2021-12-03 19:42:13,172 [Executor task launch worker for task 212] INFO [org.apache.spark.executor.Executor] - Finished task 15.0 in stage 15.0 (TID 212). 869 bytes result sent to driver
2021-12-03 19:42:13,172 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 15.0 in stage 15.0 (TID 212) in 93754 ms on localhost (executor driver) (14/22)
2021-12-03 19:42:20,446 [Executor task launch worker for task 213] INFO [org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter] - Saved output of task 'attempt_20211203193819_0014_m_000016_0' to hdfs://hdp1:8020/sk/chongqing/sample_data/filter-sample-device-video-data.bcp/_temporary/0/task_20211203193819_0014_m_000016
2021-12-03 19:42:20,446 [Executor task launch worker for task 213] INFO [org.apache.spark.mapred.SparkHadoopMapRedUtil] - attempt_20211203193819_0014_m_000016_0: Committed
2021-12-03 19:42:20,447 [Executor task launch worker for task 213] INFO [org.apache.spark.executor.Executor] - Finished task 16.0 in stage 15.0 (TID 213). 869 bytes result sent to driver
2021-12-03 19:42:20,447 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 16.0 in stage 15.0 (TID 213) in 100815 ms on localhost (executor driver) (15/22)
2021-12-03 19:42:23,622 [Executor task launch worker for task 211] INFO [org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter] - Saved output of task 'attempt_20211203193819_0014_m_000014_0' to hdfs://hdp1:8020/sk/chongqing/sample_data/filter-sample-device-video-data.bcp/_temporary/0/task_20211203193819_0014_m_000014
2021-12-03 19:42:23,622 [Executor task launch worker for task 211] INFO [org.apache.spark.mapred.SparkHadoopMapRedUtil] - attempt_20211203193819_0014_m_000014_0: Committed
2021-12-03 19:42:23,623 [Executor task launch worker for task 211] INFO [org.apache.spark.executor.Executor] - Finished task 14.0 in stage 15.0 (TID 211). 869 bytes result sent to driver
2021-12-03 19:42:23,623 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 14.0 in stage 15.0 (TID 211) in 104521 ms on localhost (executor driver) (16/22)
2021-12-03 19:42:30,033 [Executor task launch worker for task 216] INFO [org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter] - Saved output of task 'attempt_20211203193819_0014_m_000019_0' to hdfs://hdp1:8020/sk/chongqing/sample_data/filter-sample-device-video-data.bcp/_temporary/0/task_20211203193819_0014_m_000019
2021-12-03 19:42:30,033 [Executor task launch worker for task 216] INFO [org.apache.spark.mapred.SparkHadoopMapRedUtil] - attempt_20211203193819_0014_m_000019_0: Committed
2021-12-03 19:42:30,035 [Executor task launch worker for task 216] INFO [org.apache.spark.executor.Executor] - Finished task 19.0 in stage 15.0 (TID 216). 912 bytes result sent to driver
2021-12-03 19:42:30,035 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 19.0 in stage 15.0 (TID 216) in 101873 ms on localhost (executor driver) (17/22)
2021-12-03 19:42:32,746 [Executor task launch worker for task 209] INFO [org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter] - Saved output of task 'attempt_20211203193819_0014_m_000012_0' to hdfs://hdp1:8020/sk/chongqing/sample_data/filter-sample-device-video-data.bcp/_temporary/0/task_20211203193819_0014_m_000012
2021-12-03 19:42:32,746 [Executor task launch worker for task 209] INFO [org.apache.spark.mapred.SparkHadoopMapRedUtil] - attempt_20211203193819_0014_m_000012_0: Committed
2021-12-03 19:42:32,747 [Executor task launch worker for task 209] INFO [org.apache.spark.executor.Executor] - Finished task 12.0 in stage 15.0 (TID 209). 955 bytes result sent to driver
2021-12-03 19:42:32,747 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 12.0 in stage 15.0 (TID 209) in 128658 ms on localhost (executor driver) (18/22)
2021-12-03 19:42:36,141 [Executor task launch worker for task 214] INFO [org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter] - Saved output of task 'attempt_20211203193819_0014_m_000017_0' to hdfs://hdp1:8020/sk/chongqing/sample_data/filter-sample-device-video-data.bcp/_temporary/0/task_20211203193819_0014_m_000017
2021-12-03 19:42:36,141 [Executor task launch worker for task 214] INFO [org.apache.spark.mapred.SparkHadoopMapRedUtil] - attempt_20211203193819_0014_m_000017_0: Committed
2021-12-03 19:42:36,142 [Executor task launch worker for task 214] INFO [org.apache.spark.executor.Executor] - Finished task 17.0 in stage 15.0 (TID 214). 869 bytes result sent to driver
2021-12-03 19:42:36,142 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 17.0 in stage 15.0 (TID 214) in 114077 ms on localhost (executor driver) (19/22)
2021-12-03 19:42:42,182 [Executor task launch worker for task 210] INFO [org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter] - Saved output of task 'attempt_20211203193819_0014_m_000013_0' to hdfs://hdp1:8020/sk/chongqing/sample_data/filter-sample-device-video-data.bcp/_temporary/0/task_20211203193819_0014_m_000013
2021-12-03 19:42:42,182 [Executor task launch worker for task 210] INFO [org.apache.spark.mapred.SparkHadoopMapRedUtil] - attempt_20211203193819_0014_m_000013_0: Committed
2021-12-03 19:42:42,183 [Executor task launch worker for task 210] INFO [org.apache.spark.executor.Executor] - Finished task 13.0 in stage 15.0 (TID 210). 869 bytes result sent to driver
2021-12-03 19:42:42,184 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 13.0 in stage 15.0 (TID 210) in 123517 ms on localhost (executor driver) (20/22)
2021-12-03 19:42:44,960 [Executor task launch worker for task 215] INFO [org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter] - Saved output of task 'attempt_20211203193819_0014_m_000018_0' to hdfs://hdp1:8020/sk/chongqing/sample_data/filter-sample-device-video-data.bcp/_temporary/0/task_20211203193819_0014_m_000018
2021-12-03 19:42:44,960 [Executor task launch worker for task 215] INFO [org.apache.spark.mapred.SparkHadoopMapRedUtil] - attempt_20211203193819_0014_m_000018_0: Committed
2021-12-03 19:42:44,961 [Executor task launch worker for task 215] INFO [org.apache.spark.executor.Executor] - Finished task 18.0 in stage 15.0 (TID 215). 912 bytes result sent to driver
2021-12-03 19:42:44,961 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 18.0 in stage 15.0 (TID 215) in 118259 ms on localhost (executor driver) (21/22)
2021-12-03 19:42:45,985 [Executor task launch worker for task 218] INFO [org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter] - Saved output of task 'attempt_20211203193819_0014_m_000021_0' to hdfs://hdp1:8020/sk/chongqing/sample_data/filter-sample-device-video-data.bcp/_temporary/0/task_20211203193819_0014_m_000021
2021-12-03 19:42:45,985 [Executor task launch worker for task 218] INFO [org.apache.spark.mapred.SparkHadoopMapRedUtil] - attempt_20211203193819_0014_m_000021_0: Committed
2021-12-03 19:42:45,986 [Executor task launch worker for task 218] INFO [org.apache.spark.executor.Executor] - Finished task 21.0 in stage 15.0 (TID 218). 869 bytes result sent to driver
2021-12-03 19:42:45,986 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 21.0 in stage 15.0 (TID 218) in 109662 ms on localhost (executor driver) (22/22)
2021-12-03 19:42:45,986 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 15.0, whose tasks have all completed, from pool 
2021-12-03 19:42:45,986 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 15 (runJob at SparkHadoopWriter.scala:78) finished in 266.713 s
2021-12-03 19:42:45,986 [main] INFO [org.apache.spark.scheduler.DAGScheduler] - Job 7 finished: runJob at SparkHadoopWriter.scala:78, took 266.713381 s
2021-12-03 19:42:46,389 [main] INFO [org.apache.spark.internal.io.SparkHadoopWriter] - Job job_20211203193819_0014 committed.
2021-12-03 19:42:46,395 [main] INFO [org.spark_project.jetty.server.AbstractConnector] - Stopped Spark@5b800468{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2021-12-03 19:42:46,396 [main] INFO [org.apache.spark.ui.SparkUI] - Stopped Spark web UI at http://qb:4040
2021-12-03 19:42:46,404 [dispatcher-event-loop-10] INFO [org.apache.spark.MapOutputTrackerMasterEndpoint] - MapOutputTrackerMasterEndpoint stopped!
2021-12-03 19:42:46,484 [main] INFO [org.apache.spark.storage.memory.MemoryStore] - MemoryStore cleared
2021-12-03 19:42:46,485 [main] INFO [org.apache.spark.storage.BlockManager] - BlockManager stopped
2021-12-03 19:42:46,485 [main] INFO [org.apache.spark.storage.BlockManagerMaster] - BlockManagerMaster stopped
2021-12-03 19:42:46,487 [dispatcher-event-loop-5] INFO [org.apache.spark.scheduler.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint] - OutputCommitCoordinator stopped!
2021-12-03 19:42:46,490 [main] INFO [org.apache.spark.SparkContext] - Successfully stopped SparkContext
2021-12-03 19:42:46,492 [Thread-1] INFO [org.apache.spark.util.ShutdownHookManager] - Shutdown hook called
2021-12-03 19:42:46,492 [Thread-1] INFO [org.apache.spark.util.ShutdownHookManager] - Deleting directory C:\Users\ACER\AppData\Local\Temp\spark-32c08da6-6b56-468f-b1e4-df9f3d8e77dd
2021-12-03 19:55:17,886 [main] INFO [org.apache.spark.SparkContext] - Running Spark version 2.3.0
2021-12-03 19:55:18,148 [main] INFO [org.apache.spark.SparkContext] - Submitted application: PaidPromotion
2021-12-03 19:55:18,195 [main] INFO [org.apache.spark.SecurityManager] - Changing view acls to: ACER,root
2021-12-03 19:55:18,195 [main] INFO [org.apache.spark.SecurityManager] - Changing modify acls to: ACER,root
2021-12-03 19:55:18,195 [main] INFO [org.apache.spark.SecurityManager] - Changing view acls groups to: 
2021-12-03 19:55:18,196 [main] INFO [org.apache.spark.SecurityManager] - Changing modify acls groups to: 
2021-12-03 19:55:18,196 [main] INFO [org.apache.spark.SecurityManager] - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(ACER, root); groups with view permissions: Set(); users  with modify permissions: Set(ACER, root); groups with modify permissions: Set()
2021-12-03 19:55:18,770 [main] INFO [org.apache.spark.util.Utils] - Successfully started service 'sparkDriver' on port 50027.
2021-12-03 19:55:18,787 [main] INFO [org.apache.spark.SparkEnv] - Registering MapOutputTracker
2021-12-03 19:55:18,802 [main] INFO [org.apache.spark.SparkEnv] - Registering BlockManagerMaster
2021-12-03 19:55:18,804 [main] INFO [org.apache.spark.storage.BlockManagerMasterEndpoint] - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2021-12-03 19:55:18,804 [main] INFO [org.apache.spark.storage.BlockManagerMasterEndpoint] - BlockManagerMasterEndpoint up
2021-12-03 19:55:18,812 [main] INFO [org.apache.spark.storage.DiskBlockManager] - Created local directory at C:\Users\ACER\AppData\Local\Temp\blockmgr-f541fb3a-8416-4c5a-a445-5c1ef19dae2e
2021-12-03 19:55:18,827 [main] INFO [org.apache.spark.storage.memory.MemoryStore] - MemoryStore started with capacity 1990.8 MB
2021-12-03 19:55:18,838 [main] INFO [org.apache.spark.SparkEnv] - Registering OutputCommitCoordinator
2021-12-03 19:55:18,891 [main] INFO [org.spark_project.jetty.util.log] - Logging initialized @1809ms
2021-12-03 19:55:18,938 [main] INFO [org.spark_project.jetty.server.Server] - jetty-9.3.z-SNAPSHOT
2021-12-03 19:55:18,950 [main] INFO [org.spark_project.jetty.server.Server] - Started @1868ms
2021-12-03 19:55:18,976 [main] INFO [org.spark_project.jetty.server.AbstractConnector] - Started ServerConnector@5b800468{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2021-12-03 19:55:18,976 [main] INFO [org.apache.spark.util.Utils] - Successfully started service 'SparkUI' on port 4040.
2021-12-03 19:55:18,994 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@1568159{/jobs,null,AVAILABLE,@Spark}
2021-12-03 19:55:18,995 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@63cd604c{/jobs/json,null,AVAILABLE,@Spark}
2021-12-03 19:55:18,996 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@3954d008{/jobs/job,null,AVAILABLE,@Spark}
2021-12-03 19:55:18,998 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@6d8792db{/jobs/job/json,null,AVAILABLE,@Spark}
2021-12-03 19:55:18,999 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@3a1d593e{/stages,null,AVAILABLE,@Spark}
2021-12-03 19:55:19,000 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@285d851a{/stages/json,null,AVAILABLE,@Spark}
2021-12-03 19:55:19,001 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@7876d598{/stages/stage,null,AVAILABLE,@Spark}
2021-12-03 19:55:19,002 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@4985cbcb{/stages/stage/json,null,AVAILABLE,@Spark}
2021-12-03 19:55:19,003 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@54361a9{/stages/pool,null,AVAILABLE,@Spark}
2021-12-03 19:55:19,004 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@293bb8a5{/stages/pool/json,null,AVAILABLE,@Spark}
2021-12-03 19:55:19,005 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@290b1b2e{/storage,null,AVAILABLE,@Spark}
2021-12-03 19:55:19,006 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@5db4c359{/storage/json,null,AVAILABLE,@Spark}
2021-12-03 19:55:19,007 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@6fefce9e{/storage/rdd,null,AVAILABLE,@Spark}
2021-12-03 19:55:19,008 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@8a589a2{/storage/rdd/json,null,AVAILABLE,@Spark}
2021-12-03 19:55:19,009 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@5cc69cfe{/environment,null,AVAILABLE,@Spark}
2021-12-03 19:55:19,010 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@11dee337{/environment/json,null,AVAILABLE,@Spark}
2021-12-03 19:55:19,011 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@74bdc168{/executors,null,AVAILABLE,@Spark}
2021-12-03 19:55:19,012 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@7bb3a9fe{/executors/json,null,AVAILABLE,@Spark}
2021-12-03 19:55:19,013 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@f19c9d2{/executors/threadDump,null,AVAILABLE,@Spark}
2021-12-03 19:55:19,014 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@a77614d{/executors/threadDump/json,null,AVAILABLE,@Spark}
2021-12-03 19:55:19,021 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@523424b5{/static,null,AVAILABLE,@Spark}
2021-12-03 19:55:19,022 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@12cd9150{/,null,AVAILABLE,@Spark}
2021-12-03 19:55:19,023 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@32fe9d0a{/api,null,AVAILABLE,@Spark}
2021-12-03 19:55:19,024 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@59fc684e{/jobs/job/kill,null,AVAILABLE,@Spark}
2021-12-03 19:55:19,026 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@355e34c7{/stages/stage/kill,null,AVAILABLE,@Spark}
2021-12-03 19:55:19,028 [main] INFO [org.apache.spark.ui.SparkUI] - Bound SparkUI to 0.0.0.0, and started at http://qb:4040
2021-12-03 19:55:19,103 [main] INFO [org.apache.spark.executor.Executor] - Starting executor ID driver on host localhost
2021-12-03 19:55:19,152 [main] INFO [org.apache.spark.util.Utils] - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 50070.
2021-12-03 19:55:19,153 [main] INFO [org.apache.spark.network.netty.NettyBlockTransferService] - Server created on qb:50070
2021-12-03 19:55:19,154 [main] INFO [org.apache.spark.storage.BlockManager] - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2021-12-03 19:55:19,156 [main] INFO [org.apache.spark.storage.BlockManagerMaster] - Registering BlockManager BlockManagerId(driver, qb, 50070, None)
2021-12-03 19:55:19,158 [dispatcher-event-loop-7] INFO [org.apache.spark.storage.BlockManagerMasterEndpoint] - Registering block manager qb:50070 with 1990.8 MB RAM, BlockManagerId(driver, qb, 50070, None)
2021-12-03 19:55:19,159 [main] INFO [org.apache.spark.storage.BlockManagerMaster] - Registered BlockManager BlockManagerId(driver, qb, 50070, None)
2021-12-03 19:55:19,159 [main] INFO [org.apache.spark.storage.BlockManager] - Initialized BlockManager: BlockManagerId(driver, qb, 50070, None)
2021-12-03 19:55:19,294 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@6fe46b62{/metrics/json,null,AVAILABLE,@Spark}
2021-12-03 19:55:19,751 [main] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_0 stored as values in memory (estimated size 312.7 KB, free 1990.5 MB)
2021-12-03 19:55:19,959 [main] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_0_piece0 stored as bytes in memory (estimated size 27.3 KB, free 1990.5 MB)
2021-12-03 19:55:19,961 [dispatcher-event-loop-0] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_0_piece0 in memory on qb:50070 (size: 27.3 KB, free: 1990.8 MB)
2021-12-03 19:55:19,965 [main] INFO [org.apache.spark.SparkContext] - Created broadcast 0 from textFile at PaidPromotionAdjustParameter.scala:57
2021-12-03 19:55:20,341 [main] WARN [org.apache.hadoop.hdfs.shortcircuit.DomainSocketFactory] - The short-circuit local reads feature cannot be used because UNIX Domain sockets are not available on Windows.
2021-12-03 19:55:20,448 [main] INFO [org.apache.hadoop.mapred.FileInputFormat] - Total input paths to process : 1
2021-12-03 19:55:20,485 [main] INFO [org.apache.hadoop.net.NetworkTopology] - Adding a new node: /default-rack/192.168.1.34:50010
2021-12-03 19:55:20,485 [main] INFO [org.apache.hadoop.net.NetworkTopology] - Adding a new node: /default-rack/192.168.1.33:50010
2021-12-03 19:55:20,485 [main] INFO [org.apache.hadoop.net.NetworkTopology] - Adding a new node: /default-rack/172.16.1.222:50010
2021-12-03 19:55:20,491 [main] INFO [org.apache.spark.SparkContext] - Starting job: count at PaidPromotionAdjustParameter.scala:59
2021-12-03 19:55:20,503 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 0 (count at PaidPromotionAdjustParameter.scala:59) with 22 output partitions
2021-12-03 19:55:20,504 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 0 (count at PaidPromotionAdjustParameter.scala:59)
2021-12-03 19:55:20,504 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List()
2021-12-03 19:55:20,506 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2021-12-03 19:55:20,513 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 0 (/sk/chongqing/data/behavior_data.bcp MapPartitionsRDD[1] at textFile at PaidPromotionAdjustParameter.scala:57), which has no missing parents
2021-12-03 19:55:20,543 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_1 stored as values in memory (estimated size 3.1 KB, free 1990.5 MB)
2021-12-03 19:55:20,548 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_1_piece0 stored as bytes in memory (estimated size 1903.0 B, free 1990.5 MB)
2021-12-03 19:55:20,548 [dispatcher-event-loop-1] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_1_piece0 in memory on qb:50070 (size: 1903.0 B, free: 1990.8 MB)
2021-12-03 19:55:20,548 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 1 from broadcast at DAGScheduler.scala:1039
2021-12-03 19:55:20,558 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 22 missing tasks from ResultStage 0 (/sk/chongqing/data/behavior_data.bcp MapPartitionsRDD[1] at textFile at PaidPromotionAdjustParameter.scala:57) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14))
2021-12-03 19:55:20,559 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 0.0 with 22 tasks
2021-12-03 19:55:20,591 [dispatcher-event-loop-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 0.0 (TID 0, localhost, executor driver, partition 0, ANY, 7899 bytes)
2021-12-03 19:55:20,592 [dispatcher-event-loop-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 0.0 (TID 1, localhost, executor driver, partition 1, ANY, 7899 bytes)
2021-12-03 19:55:20,593 [dispatcher-event-loop-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 2.0 in stage 0.0 (TID 2, localhost, executor driver, partition 2, ANY, 7899 bytes)
2021-12-03 19:55:20,593 [dispatcher-event-loop-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 3.0 in stage 0.0 (TID 3, localhost, executor driver, partition 3, ANY, 7899 bytes)
2021-12-03 19:55:20,593 [dispatcher-event-loop-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 4.0 in stage 0.0 (TID 4, localhost, executor driver, partition 4, ANY, 7899 bytes)
2021-12-03 19:55:20,594 [dispatcher-event-loop-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 5.0 in stage 0.0 (TID 5, localhost, executor driver, partition 5, ANY, 7899 bytes)
2021-12-03 19:55:20,594 [dispatcher-event-loop-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 6.0 in stage 0.0 (TID 6, localhost, executor driver, partition 6, ANY, 7899 bytes)
2021-12-03 19:55:20,594 [dispatcher-event-loop-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 7.0 in stage 0.0 (TID 7, localhost, executor driver, partition 7, ANY, 7899 bytes)
2021-12-03 19:55:20,594 [dispatcher-event-loop-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 8.0 in stage 0.0 (TID 8, localhost, executor driver, partition 8, ANY, 7899 bytes)
2021-12-03 19:55:20,595 [dispatcher-event-loop-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 9.0 in stage 0.0 (TID 9, localhost, executor driver, partition 9, ANY, 7899 bytes)
2021-12-03 19:55:20,595 [dispatcher-event-loop-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 10.0 in stage 0.0 (TID 10, localhost, executor driver, partition 10, ANY, 7899 bytes)
2021-12-03 19:55:20,595 [dispatcher-event-loop-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 11.0 in stage 0.0 (TID 11, localhost, executor driver, partition 11, ANY, 7899 bytes)
2021-12-03 19:55:20,599 [Executor task launch worker for task 6] INFO [org.apache.spark.executor.Executor] - Running task 6.0 in stage 0.0 (TID 6)
2021-12-03 19:55:20,599 [Executor task launch worker for task 4] INFO [org.apache.spark.executor.Executor] - Running task 4.0 in stage 0.0 (TID 4)
2021-12-03 19:55:20,600 [Executor task launch worker for task 10] INFO [org.apache.spark.executor.Executor] - Running task 10.0 in stage 0.0 (TID 10)
2021-12-03 19:55:20,599 [Executor task launch worker for task 3] INFO [org.apache.spark.executor.Executor] - Running task 3.0 in stage 0.0 (TID 3)
2021-12-03 19:55:20,599 [Executor task launch worker for task 2] INFO [org.apache.spark.executor.Executor] - Running task 2.0 in stage 0.0 (TID 2)
2021-12-03 19:55:20,599 [Executor task launch worker for task 11] INFO [org.apache.spark.executor.Executor] - Running task 11.0 in stage 0.0 (TID 11)
2021-12-03 19:55:20,599 [Executor task launch worker for task 5] INFO [org.apache.spark.executor.Executor] - Running task 5.0 in stage 0.0 (TID 5)
2021-12-03 19:55:20,599 [Executor task launch worker for task 0] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 0.0 (TID 0)
2021-12-03 19:55:20,599 [Executor task launch worker for task 8] INFO [org.apache.spark.executor.Executor] - Running task 8.0 in stage 0.0 (TID 8)
2021-12-03 19:55:20,599 [Executor task launch worker for task 7] INFO [org.apache.spark.executor.Executor] - Running task 7.0 in stage 0.0 (TID 7)
2021-12-03 19:55:20,599 [Executor task launch worker for task 9] INFO [org.apache.spark.executor.Executor] - Running task 9.0 in stage 0.0 (TID 9)
2021-12-03 19:55:20,599 [Executor task launch worker for task 1] INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 0.0 (TID 1)
2021-12-03 19:55:20,638 [Executor task launch worker for task 0] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:0+134217728
2021-12-03 19:55:20,638 [Executor task launch worker for task 8] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:1073741824+134217728
2021-12-03 19:55:20,638 [Executor task launch worker for task 6] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:805306368+134217728
2021-12-03 19:55:20,638 [Executor task launch worker for task 5] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:671088640+134217728
2021-12-03 19:55:20,638 [Executor task launch worker for task 2] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:268435456+134217728
2021-12-03 19:55:20,638 [Executor task launch worker for task 4] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:536870912+134217728
2021-12-03 19:55:20,638 [Executor task launch worker for task 1] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:134217728+134217728
2021-12-03 19:55:20,638 [Executor task launch worker for task 9] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:1207959552+134217728
2021-12-03 19:55:20,638 [Executor task launch worker for task 11] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:1476395008+134217728
2021-12-03 19:55:20,638 [Executor task launch worker for task 3] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:402653184+134217728
2021-12-03 19:55:20,638 [Executor task launch worker for task 7] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:939524096+134217728
2021-12-03 19:55:20,638 [Executor task launch worker for task 10] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:1342177280+134217728
2021-12-03 19:56:53,854 [Executor task launch worker for task 2] INFO [org.apache.spark.executor.Executor] - Finished task 2.0 in stage 0.0 (TID 2). 755 bytes result sent to driver
2021-12-03 19:56:53,856 [dispatcher-event-loop-9] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 12.0 in stage 0.0 (TID 12, localhost, executor driver, partition 12, ANY, 7899 bytes)
2021-12-03 19:56:53,856 [Executor task launch worker for task 12] INFO [org.apache.spark.executor.Executor] - Running task 12.0 in stage 0.0 (TID 12)
2021-12-03 19:56:53,858 [Executor task launch worker for task 12] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:1610612736+134217728
2021-12-03 19:56:53,863 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 2.0 in stage 0.0 (TID 2) in 93269 ms on localhost (executor driver) (1/22)
2021-12-03 19:57:05,335 [Executor task launch worker for task 0] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 0.0 (TID 0). 755 bytes result sent to driver
2021-12-03 19:57:05,336 [dispatcher-event-loop-5] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 13.0 in stage 0.0 (TID 13, localhost, executor driver, partition 13, ANY, 7899 bytes)
2021-12-03 19:57:05,336 [Executor task launch worker for task 13] INFO [org.apache.spark.executor.Executor] - Running task 13.0 in stage 0.0 (TID 13)
2021-12-03 19:57:05,337 [Executor task launch worker for task 13] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:1744830464+134217728
2021-12-03 19:57:05,340 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 0.0 (TID 0) in 104758 ms on localhost (executor driver) (2/22)
2021-12-03 19:57:11,057 [Executor task launch worker for task 8] INFO [org.apache.spark.executor.Executor] - Finished task 8.0 in stage 0.0 (TID 8). 755 bytes result sent to driver
2021-12-03 19:57:11,058 [dispatcher-event-loop-10] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 14.0 in stage 0.0 (TID 14, localhost, executor driver, partition 14, ANY, 7899 bytes)
2021-12-03 19:57:11,058 [Executor task launch worker for task 14] INFO [org.apache.spark.executor.Executor] - Running task 14.0 in stage 0.0 (TID 14)
2021-12-03 19:57:11,059 [Executor task launch worker for task 14] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:1879048192+134217728
2021-12-03 19:57:11,060 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 8.0 in stage 0.0 (TID 8) in 110466 ms on localhost (executor driver) (3/22)
2021-12-03 19:57:17,894 [Executor task launch worker for task 6] INFO [org.apache.spark.executor.Executor] - Finished task 6.0 in stage 0.0 (TID 6). 755 bytes result sent to driver
2021-12-03 19:57:17,895 [dispatcher-event-loop-9] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 15.0 in stage 0.0 (TID 15, localhost, executor driver, partition 15, ANY, 7899 bytes)
2021-12-03 19:57:17,895 [Executor task launch worker for task 15] INFO [org.apache.spark.executor.Executor] - Running task 15.0 in stage 0.0 (TID 15)
2021-12-03 19:57:17,897 [Executor task launch worker for task 15] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:2013265920+134217728
2021-12-03 19:57:17,897 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 6.0 in stage 0.0 (TID 6) in 117303 ms on localhost (executor driver) (4/22)
2021-12-03 19:57:19,317 [Executor task launch worker for task 1] INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 0.0 (TID 1). 755 bytes result sent to driver
2021-12-03 19:57:19,317 [dispatcher-event-loop-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 16.0 in stage 0.0 (TID 16, localhost, executor driver, partition 16, ANY, 7899 bytes)
2021-12-03 19:57:19,317 [Executor task launch worker for task 16] INFO [org.apache.spark.executor.Executor] - Running task 16.0 in stage 0.0 (TID 16)
2021-12-03 19:57:19,317 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 0.0 (TID 1) in 118725 ms on localhost (executor driver) (5/22)
2021-12-03 19:57:19,319 [Executor task launch worker for task 16] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:2147483648+134217728
2021-12-03 19:57:24,037 [Executor task launch worker for task 10] INFO [org.apache.spark.executor.Executor] - Finished task 10.0 in stage 0.0 (TID 10). 755 bytes result sent to driver
2021-12-03 19:57:24,037 [dispatcher-event-loop-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 17.0 in stage 0.0 (TID 17, localhost, executor driver, partition 17, ANY, 7899 bytes)
2021-12-03 19:57:24,038 [Executor task launch worker for task 17] INFO [org.apache.spark.executor.Executor] - Running task 17.0 in stage 0.0 (TID 17)
2021-12-03 19:57:24,038 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 10.0 in stage 0.0 (TID 10) in 123443 ms on localhost (executor driver) (6/22)
2021-12-03 19:57:24,039 [Executor task launch worker for task 17] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:2281701376+134217728
2021-12-03 19:57:26,882 [Executor task launch worker for task 7] INFO [org.apache.spark.executor.Executor] - Finished task 7.0 in stage 0.0 (TID 7). 798 bytes result sent to driver
2021-12-03 19:57:26,882 [dispatcher-event-loop-6] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 18.0 in stage 0.0 (TID 18, localhost, executor driver, partition 18, ANY, 7899 bytes)
2021-12-03 19:57:26,882 [Executor task launch worker for task 18] INFO [org.apache.spark.executor.Executor] - Running task 18.0 in stage 0.0 (TID 18)
2021-12-03 19:57:26,882 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 7.0 in stage 0.0 (TID 7) in 126288 ms on localhost (executor driver) (7/22)
2021-12-03 19:57:26,883 [Executor task launch worker for task 18] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:2415919104+134217728
2021-12-03 19:57:32,736 [Executor task launch worker for task 4] INFO [org.apache.spark.executor.Executor] - Finished task 4.0 in stage 0.0 (TID 4). 755 bytes result sent to driver
2021-12-03 19:57:32,737 [dispatcher-event-loop-4] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 19.0 in stage 0.0 (TID 19, localhost, executor driver, partition 19, ANY, 7899 bytes)
2021-12-03 19:57:32,737 [Executor task launch worker for task 19] INFO [org.apache.spark.executor.Executor] - Running task 19.0 in stage 0.0 (TID 19)
2021-12-03 19:57:32,737 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 4.0 in stage 0.0 (TID 4) in 132144 ms on localhost (executor driver) (8/22)
2021-12-03 19:57:32,737 [Executor task launch worker for task 19] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:2550136832+134217728
2021-12-03 19:58:24,861 [Executor task launch worker for task 14] INFO [org.apache.spark.executor.Executor] - Finished task 14.0 in stage 0.0 (TID 14). 755 bytes result sent to driver
2021-12-03 19:58:24,861 [dispatcher-event-loop-9] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 20.0 in stage 0.0 (TID 20, localhost, executor driver, partition 20, ANY, 7899 bytes)
2021-12-03 19:58:24,862 [Executor task launch worker for task 20] INFO [org.apache.spark.executor.Executor] - Running task 20.0 in stage 0.0 (TID 20)
2021-12-03 19:58:24,862 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 14.0 in stage 0.0 (TID 14) in 73804 ms on localhost (executor driver) (9/22)
2021-12-03 19:58:24,863 [Executor task launch worker for task 20] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:2684354560+134217728
2021-12-03 19:58:33,202 [Executor task launch worker for task 15] INFO [org.apache.spark.executor.Executor] - Finished task 15.0 in stage 0.0 (TID 15). 755 bytes result sent to driver
2021-12-03 19:58:33,203 [dispatcher-event-loop-5] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 21.0 in stage 0.0 (TID 21, localhost, executor driver, partition 21, ANY, 7899 bytes)
2021-12-03 19:58:33,203 [Executor task launch worker for task 21] INFO [org.apache.spark.executor.Executor] - Running task 21.0 in stage 0.0 (TID 21)
2021-12-03 19:58:33,203 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 15.0 in stage 0.0 (TID 15) in 75308 ms on localhost (executor driver) (10/22)
2021-12-03 19:58:33,203 [Executor task launch worker for task 21] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:2818572288+147216171
2021-12-03 19:58:33,232 [Executor task launch worker for task 17] INFO [org.apache.spark.executor.Executor] - Finished task 17.0 in stage 0.0 (TID 17). 755 bytes result sent to driver
2021-12-03 19:58:33,234 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 17.0 in stage 0.0 (TID 17) in 69197 ms on localhost (executor driver) (11/22)
2021-12-03 19:58:34,285 [Executor task launch worker for task 16] INFO [org.apache.spark.executor.Executor] - Finished task 16.0 in stage 0.0 (TID 16). 755 bytes result sent to driver
2021-12-03 19:58:34,285 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 16.0 in stage 0.0 (TID 16) in 74968 ms on localhost (executor driver) (12/22)
2021-12-03 19:58:53,314 [Executor task launch worker for task 11] INFO [org.apache.spark.executor.Executor] - Finished task 11.0 in stage 0.0 (TID 11). 755 bytes result sent to driver
2021-12-03 19:58:53,314 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 11.0 in stage 0.0 (TID 11) in 212719 ms on localhost (executor driver) (13/22)
2021-12-03 19:58:53,905 [Executor task launch worker for task 20] INFO [org.apache.spark.executor.Executor] - Finished task 20.0 in stage 0.0 (TID 20). 755 bytes result sent to driver
2021-12-03 19:58:53,906 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 20.0 in stage 0.0 (TID 20) in 29045 ms on localhost (executor driver) (14/22)
2021-12-03 19:58:58,053 [Executor task launch worker for task 5] INFO [org.apache.spark.executor.Executor] - Finished task 5.0 in stage 0.0 (TID 5). 755 bytes result sent to driver
2021-12-03 19:58:58,053 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 5.0 in stage 0.0 (TID 5) in 217460 ms on localhost (executor driver) (15/22)
2021-12-03 19:59:22,918 [Executor task launch worker for task 9] INFO [org.apache.spark.executor.Executor] - Finished task 9.0 in stage 0.0 (TID 9). 755 bytes result sent to driver
2021-12-03 19:59:22,918 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 9.0 in stage 0.0 (TID 9) in 242324 ms on localhost (executor driver) (16/22)
2021-12-03 19:59:23,118 [Executor task launch worker for task 12] INFO [org.apache.spark.executor.Executor] - Finished task 12.0 in stage 0.0 (TID 12). 798 bytes result sent to driver
2021-12-03 19:59:23,118 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 12.0 in stage 0.0 (TID 12) in 149263 ms on localhost (executor driver) (17/22)
2021-12-03 19:59:37,092 [Executor task launch worker for task 3] INFO [org.apache.spark.executor.Executor] - Finished task 3.0 in stage 0.0 (TID 3). 755 bytes result sent to driver
2021-12-03 19:59:37,092 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 3.0 in stage 0.0 (TID 3) in 256499 ms on localhost (executor driver) (18/22)
2021-12-03 20:00:19,149 [Executor task launch worker for task 13] INFO [org.apache.spark.executor.Executor] - Finished task 13.0 in stage 0.0 (TID 13). 712 bytes result sent to driver
2021-12-03 20:00:19,150 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 13.0 in stage 0.0 (TID 13) in 193815 ms on localhost (executor driver) (19/22)
2021-12-03 20:00:19,940 [Executor task launch worker for task 19] INFO [org.apache.spark.executor.Executor] - Finished task 19.0 in stage 0.0 (TID 19). 712 bytes result sent to driver
2021-12-03 20:00:19,940 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 19.0 in stage 0.0 (TID 19) in 167204 ms on localhost (executor driver) (20/22)
2021-12-03 20:00:27,277 [Executor task launch worker for task 18] INFO [org.apache.spark.executor.Executor] - Finished task 18.0 in stage 0.0 (TID 18). 755 bytes result sent to driver
2021-12-03 20:00:27,277 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 18.0 in stage 0.0 (TID 18) in 180395 ms on localhost (executor driver) (21/22)
2021-12-03 20:00:31,959 [Executor task launch worker for task 21] INFO [org.apache.spark.executor.Executor] - Finished task 21.0 in stage 0.0 (TID 21). 712 bytes result sent to driver
2021-12-03 20:00:31,959 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 21.0 in stage 0.0 (TID 21) in 118757 ms on localhost (executor driver) (22/22)
2021-12-03 20:00:31,960 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 0.0, whose tasks have all completed, from pool 
2021-12-03 20:00:31,960 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 0 (count at PaidPromotionAdjustParameter.scala:59) finished in 311.433 s
2021-12-03 20:00:31,964 [main] INFO [org.apache.spark.scheduler.DAGScheduler] - Job 0 finished: count at PaidPromotionAdjustParameter.scala:59, took 311.473311 s
2021-12-03 20:00:31,966 [main] INFO [PaidPromotion$] - 收视总数68489201
2021-12-03 20:00:31,986 [main] INFO [org.apache.spark.SparkContext] - Starting job: count at PaidPromotionAdjustParameter.scala:68
2021-12-03 20:00:31,993 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 3 (map at PaidPromotionAdjustParameter.scala:67)
2021-12-03 20:00:31,994 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 1 (count at PaidPromotionAdjustParameter.scala:68) with 22 output partitions
2021-12-03 20:00:31,994 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 2 (count at PaidPromotionAdjustParameter.scala:68)
2021-12-03 20:00:31,994 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 1)
2021-12-03 20:00:31,995 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List(ShuffleMapStage 1)
2021-12-03 20:00:31,995 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ShuffleMapStage 1 (MapPartitionsRDD[3] at map at PaidPromotionAdjustParameter.scala:67), which has no missing parents
2021-12-03 20:00:32,005 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_2 stored as values in memory (estimated size 4.7 KB, free 1990.5 MB)
2021-12-03 20:00:32,009 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_2_piece0 stored as bytes in memory (estimated size 2.7 KB, free 1990.5 MB)
2021-12-03 20:00:32,010 [dispatcher-event-loop-10] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_2_piece0 in memory on qb:50070 (size: 2.7 KB, free: 1990.8 MB)
2021-12-03 20:00:32,010 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 2 from broadcast at DAGScheduler.scala:1039
2021-12-03 20:00:32,012 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 22 missing tasks from ShuffleMapStage 1 (MapPartitionsRDD[3] at map at PaidPromotionAdjustParameter.scala:67) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14))
2021-12-03 20:00:32,012 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 1.0 with 22 tasks
2021-12-03 20:00:32,013 [dispatcher-event-loop-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 1.0 (TID 22, localhost, executor driver, partition 0, ANY, 7888 bytes)
2021-12-03 20:00:32,013 [dispatcher-event-loop-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 1.0 (TID 23, localhost, executor driver, partition 1, ANY, 7888 bytes)
2021-12-03 20:00:32,014 [dispatcher-event-loop-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 2.0 in stage 1.0 (TID 24, localhost, executor driver, partition 2, ANY, 7888 bytes)
2021-12-03 20:00:32,014 [dispatcher-event-loop-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 3.0 in stage 1.0 (TID 25, localhost, executor driver, partition 3, ANY, 7888 bytes)
2021-12-03 20:00:32,014 [dispatcher-event-loop-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 4.0 in stage 1.0 (TID 26, localhost, executor driver, partition 4, ANY, 7888 bytes)
2021-12-03 20:00:32,014 [dispatcher-event-loop-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 5.0 in stage 1.0 (TID 27, localhost, executor driver, partition 5, ANY, 7888 bytes)
2021-12-03 20:00:32,014 [dispatcher-event-loop-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 6.0 in stage 1.0 (TID 28, localhost, executor driver, partition 6, ANY, 7888 bytes)
2021-12-03 20:00:32,014 [dispatcher-event-loop-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 7.0 in stage 1.0 (TID 29, localhost, executor driver, partition 7, ANY, 7888 bytes)
2021-12-03 20:00:32,015 [dispatcher-event-loop-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 8.0 in stage 1.0 (TID 30, localhost, executor driver, partition 8, ANY, 7888 bytes)
2021-12-03 20:00:32,015 [dispatcher-event-loop-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 9.0 in stage 1.0 (TID 31, localhost, executor driver, partition 9, ANY, 7888 bytes)
2021-12-03 20:00:32,015 [dispatcher-event-loop-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 10.0 in stage 1.0 (TID 32, localhost, executor driver, partition 10, ANY, 7888 bytes)
2021-12-03 20:00:32,015 [dispatcher-event-loop-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 11.0 in stage 1.0 (TID 33, localhost, executor driver, partition 11, ANY, 7888 bytes)
2021-12-03 20:00:32,015 [Executor task launch worker for task 23] INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 1.0 (TID 23)
2021-12-03 20:00:32,015 [Executor task launch worker for task 26] INFO [org.apache.spark.executor.Executor] - Running task 4.0 in stage 1.0 (TID 26)
2021-12-03 20:00:32,015 [Executor task launch worker for task 24] INFO [org.apache.spark.executor.Executor] - Running task 2.0 in stage 1.0 (TID 24)
2021-12-03 20:00:32,015 [Executor task launch worker for task 22] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 1.0 (TID 22)
2021-12-03 20:00:32,015 [Executor task launch worker for task 25] INFO [org.apache.spark.executor.Executor] - Running task 3.0 in stage 1.0 (TID 25)
2021-12-03 20:00:32,016 [Executor task launch worker for task 27] INFO [org.apache.spark.executor.Executor] - Running task 5.0 in stage 1.0 (TID 27)
2021-12-03 20:00:32,016 [Executor task launch worker for task 28] INFO [org.apache.spark.executor.Executor] - Running task 6.0 in stage 1.0 (TID 28)
2021-12-03 20:00:32,018 [Executor task launch worker for task 31] INFO [org.apache.spark.executor.Executor] - Running task 9.0 in stage 1.0 (TID 31)
2021-12-03 20:00:32,018 [Executor task launch worker for task 29] INFO [org.apache.spark.executor.Executor] - Running task 7.0 in stage 1.0 (TID 29)
2021-12-03 20:00:32,019 [Executor task launch worker for task 30] INFO [org.apache.spark.executor.Executor] - Running task 8.0 in stage 1.0 (TID 30)
2021-12-03 20:00:32,020 [Executor task launch worker for task 33] INFO [org.apache.spark.executor.Executor] - Running task 11.0 in stage 1.0 (TID 33)
2021-12-03 20:00:32,020 [Executor task launch worker for task 32] INFO [org.apache.spark.executor.Executor] - Running task 10.0 in stage 1.0 (TID 32)
2021-12-03 20:00:32,020 [Executor task launch worker for task 24] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:268435456+134217728
2021-12-03 20:00:32,020 [Executor task launch worker for task 26] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:536870912+134217728
2021-12-03 20:00:32,020 [Executor task launch worker for task 31] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:1207959552+134217728
2021-12-03 20:00:32,021 [Executor task launch worker for task 23] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:134217728+134217728
2021-12-03 20:00:32,021 [Executor task launch worker for task 30] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:1073741824+134217728
2021-12-03 20:00:32,022 [Executor task launch worker for task 22] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:0+134217728
2021-12-03 20:00:32,022 [Executor task launch worker for task 32] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:1342177280+134217728
2021-12-03 20:00:32,022 [Executor task launch worker for task 28] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:805306368+134217728
2021-12-03 20:00:32,022 [Executor task launch worker for task 25] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:402653184+134217728
2021-12-03 20:00:32,022 [Executor task launch worker for task 27] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:671088640+134217728
2021-12-03 20:00:32,022 [Executor task launch worker for task 29] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:939524096+134217728
2021-12-03 20:00:32,022 [Executor task launch worker for task 33] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:1476395008+134217728
2021-12-03 20:01:13,091 [Executor task launch worker for task 26] INFO [org.apache.spark.executor.Executor] - Finished task 4.0 in stage 1.0 (TID 26). 1052 bytes result sent to driver
2021-12-03 20:01:13,091 [dispatcher-event-loop-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 12.0 in stage 1.0 (TID 34, localhost, executor driver, partition 12, ANY, 7888 bytes)
2021-12-03 20:01:13,092 [Executor task launch worker for task 34] INFO [org.apache.spark.executor.Executor] - Running task 12.0 in stage 1.0 (TID 34)
2021-12-03 20:01:13,093 [Executor task launch worker for task 34] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:1610612736+134217728
2021-12-03 20:01:13,109 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 4.0 in stage 1.0 (TID 26) in 41095 ms on localhost (executor driver) (1/22)
2021-12-03 20:02:23,132 [Executor task launch worker for task 32] INFO [org.apache.spark.executor.Executor] - Finished task 10.0 in stage 1.0 (TID 32). 1052 bytes result sent to driver
2021-12-03 20:02:23,132 [dispatcher-event-loop-7] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 13.0 in stage 1.0 (TID 35, localhost, executor driver, partition 13, ANY, 7888 bytes)
2021-12-03 20:02:23,133 [Executor task launch worker for task 35] INFO [org.apache.spark.executor.Executor] - Running task 13.0 in stage 1.0 (TID 35)
2021-12-03 20:02:23,133 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 10.0 in stage 1.0 (TID 32) in 111118 ms on localhost (executor driver) (2/22)
2021-12-03 20:02:23,134 [Executor task launch worker for task 35] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:1744830464+134217728
2021-12-03 20:02:41,104 [Executor task launch worker for task 31] INFO [org.apache.spark.executor.Executor] - Finished task 9.0 in stage 1.0 (TID 31). 1052 bytes result sent to driver
2021-12-03 20:02:41,105 [dispatcher-event-loop-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 14.0 in stage 1.0 (TID 36, localhost, executor driver, partition 14, ANY, 7888 bytes)
2021-12-03 20:02:41,105 [Executor task launch worker for task 36] INFO [org.apache.spark.executor.Executor] - Running task 14.0 in stage 1.0 (TID 36)
2021-12-03 20:02:41,105 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 9.0 in stage 1.0 (TID 31) in 129090 ms on localhost (executor driver) (3/22)
2021-12-03 20:02:41,106 [Executor task launch worker for task 36] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:1879048192+134217728
2021-12-03 20:02:49,554 [Executor task launch worker for task 30] INFO [org.apache.spark.executor.Executor] - Finished task 8.0 in stage 1.0 (TID 30). 1052 bytes result sent to driver
2021-12-03 20:02:49,555 [dispatcher-event-loop-9] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 15.0 in stage 1.0 (TID 37, localhost, executor driver, partition 15, ANY, 7888 bytes)
2021-12-03 20:02:49,555 [Executor task launch worker for task 37] INFO [org.apache.spark.executor.Executor] - Running task 15.0 in stage 1.0 (TID 37)
2021-12-03 20:02:49,555 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 8.0 in stage 1.0 (TID 30) in 137541 ms on localhost (executor driver) (4/22)
2021-12-03 20:02:49,556 [Executor task launch worker for task 37] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:2013265920+134217728
2021-12-03 20:02:51,640 [Executor task launch worker for task 23] INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 1.0 (TID 23). 1052 bytes result sent to driver
2021-12-03 20:02:51,640 [dispatcher-event-loop-7] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 16.0 in stage 1.0 (TID 38, localhost, executor driver, partition 16, ANY, 7888 bytes)
2021-12-03 20:02:51,640 [Executor task launch worker for task 38] INFO [org.apache.spark.executor.Executor] - Running task 16.0 in stage 1.0 (TID 38)
2021-12-03 20:02:51,640 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 1.0 (TID 23) in 139627 ms on localhost (executor driver) (5/22)
2021-12-03 20:02:51,641 [Executor task launch worker for task 38] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:2147483648+134217728
2021-12-03 20:03:08,424 [Executor task launch worker for task 25] INFO [org.apache.spark.executor.Executor] - Finished task 3.0 in stage 1.0 (TID 25). 1052 bytes result sent to driver
2021-12-03 20:03:08,424 [dispatcher-event-loop-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 17.0 in stage 1.0 (TID 39, localhost, executor driver, partition 17, ANY, 7888 bytes)
2021-12-03 20:03:08,424 [Executor task launch worker for task 39] INFO [org.apache.spark.executor.Executor] - Running task 17.0 in stage 1.0 (TID 39)
2021-12-03 20:03:08,424 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 3.0 in stage 1.0 (TID 25) in 156410 ms on localhost (executor driver) (6/22)
2021-12-03 20:03:08,425 [Executor task launch worker for task 39] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:2281701376+134217728
2021-12-03 20:03:11,110 [Executor task launch worker for task 22] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 1.0 (TID 22). 1052 bytes result sent to driver
2021-12-03 20:03:11,110 [dispatcher-event-loop-10] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 18.0 in stage 1.0 (TID 40, localhost, executor driver, partition 18, ANY, 7888 bytes)
2021-12-03 20:03:11,110 [Executor task launch worker for task 40] INFO [org.apache.spark.executor.Executor] - Running task 18.0 in stage 1.0 (TID 40)
2021-12-03 20:03:11,110 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 1.0 (TID 22) in 159098 ms on localhost (executor driver) (7/22)
2021-12-03 20:03:11,111 [Executor task launch worker for task 40] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:2415919104+134217728
2021-12-03 20:03:11,504 [Executor task launch worker for task 27] INFO [org.apache.spark.executor.Executor] - Finished task 5.0 in stage 1.0 (TID 27). 1052 bytes result sent to driver
2021-12-03 20:03:11,505 [dispatcher-event-loop-9] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 19.0 in stage 1.0 (TID 41, localhost, executor driver, partition 19, ANY, 7888 bytes)
2021-12-03 20:03:11,505 [Executor task launch worker for task 41] INFO [org.apache.spark.executor.Executor] - Running task 19.0 in stage 1.0 (TID 41)
2021-12-03 20:03:11,505 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 5.0 in stage 1.0 (TID 27) in 159491 ms on localhost (executor driver) (8/22)
2021-12-03 20:03:11,506 [Executor task launch worker for task 41] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:2550136832+134217728
2021-12-03 20:03:11,817 [Executor task launch worker for task 33] INFO [org.apache.spark.executor.Executor] - Finished task 11.0 in stage 1.0 (TID 33). 1052 bytes result sent to driver
2021-12-03 20:03:11,818 [dispatcher-event-loop-7] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 20.0 in stage 1.0 (TID 42, localhost, executor driver, partition 20, ANY, 7888 bytes)
2021-12-03 20:03:11,818 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 11.0 in stage 1.0 (TID 33) in 159803 ms on localhost (executor driver) (9/22)
2021-12-03 20:03:11,818 [Executor task launch worker for task 42] INFO [org.apache.spark.executor.Executor] - Running task 20.0 in stage 1.0 (TID 42)
2021-12-03 20:03:11,819 [Executor task launch worker for task 42] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:2684354560+134217728
2021-12-03 20:03:14,673 [Executor task launch worker for task 28] INFO [org.apache.spark.executor.Executor] - Finished task 6.0 in stage 1.0 (TID 28). 1052 bytes result sent to driver
2021-12-03 20:03:14,675 [dispatcher-event-loop-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 21.0 in stage 1.0 (TID 43, localhost, executor driver, partition 21, ANY, 7888 bytes)
2021-12-03 20:03:14,675 [Executor task launch worker for task 43] INFO [org.apache.spark.executor.Executor] - Running task 21.0 in stage 1.0 (TID 43)
2021-12-03 20:03:14,675 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 6.0 in stage 1.0 (TID 28) in 162661 ms on localhost (executor driver) (10/22)
2021-12-03 20:03:14,676 [Executor task launch worker for task 43] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:2818572288+147216171
2021-12-03 20:03:15,182 [Executor task launch worker for task 24] INFO [org.apache.spark.executor.Executor] - Finished task 2.0 in stage 1.0 (TID 24). 1052 bytes result sent to driver
2021-12-03 20:03:15,183 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 2.0 in stage 1.0 (TID 24) in 163169 ms on localhost (executor driver) (11/22)
2021-12-03 20:03:15,483 [Executor task launch worker for task 29] INFO [org.apache.spark.executor.Executor] - Finished task 7.0 in stage 1.0 (TID 29). 1052 bytes result sent to driver
2021-12-03 20:03:15,483 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 7.0 in stage 1.0 (TID 29) in 163469 ms on localhost (executor driver) (12/22)
2021-12-03 20:03:19,554 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 14
2021-12-03 20:03:19,555 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 4
2021-12-03 20:03:19,555 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 21
2021-12-03 20:03:19,555 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 10
2021-12-03 20:03:19,555 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 20
2021-12-03 20:03:19,555 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 22
2021-12-03 20:03:19,555 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 17
2021-12-03 20:03:19,555 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 9
2021-12-03 20:03:19,555 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 2
2021-12-03 20:03:19,555 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 19
2021-12-03 20:03:19,555 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 11
2021-12-03 20:03:19,555 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 5
2021-12-03 20:03:19,555 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 16
2021-12-03 20:03:19,555 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 8
2021-12-03 20:03:19,555 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 3
2021-12-03 20:03:19,555 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 12
2021-12-03 20:03:19,555 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 0
2021-12-03 20:03:19,564 [dispatcher-event-loop-4] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_1_piece0 on qb:50070 in memory (size: 1903.0 B, free: 1990.8 MB)
2021-12-03 20:03:19,566 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 24
2021-12-03 20:03:19,566 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 18
2021-12-03 20:03:19,566 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 6
2021-12-03 20:03:19,566 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 15
2021-12-03 20:03:19,566 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 7
2021-12-03 20:03:19,566 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 13
2021-12-03 20:03:19,566 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1
2021-12-03 20:03:19,566 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 23
2021-12-03 20:03:53,281 [Executor task launch worker for task 34] INFO [org.apache.spark.executor.Executor] - Finished task 12.0 in stage 1.0 (TID 34). 1052 bytes result sent to driver
2021-12-03 20:03:53,281 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 12.0 in stage 1.0 (TID 34) in 160190 ms on localhost (executor driver) (13/22)
2021-12-03 20:04:05,617 [Executor task launch worker for task 35] INFO [org.apache.spark.executor.Executor] - Finished task 13.0 in stage 1.0 (TID 35). 1052 bytes result sent to driver
2021-12-03 20:04:05,617 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 13.0 in stage 1.0 (TID 35) in 102485 ms on localhost (executor driver) (14/22)
2021-12-03 20:04:26,458 [Executor task launch worker for task 37] INFO [org.apache.spark.executor.Executor] - Finished task 15.0 in stage 1.0 (TID 37). 1009 bytes result sent to driver
2021-12-03 20:04:26,458 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 15.0 in stage 1.0 (TID 37) in 96903 ms on localhost (executor driver) (15/22)
2021-12-03 20:04:28,109 [Executor task launch worker for task 38] INFO [org.apache.spark.executor.Executor] - Finished task 16.0 in stage 1.0 (TID 38). 1052 bytes result sent to driver
2021-12-03 20:04:28,109 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 16.0 in stage 1.0 (TID 38) in 96469 ms on localhost (executor driver) (16/22)
2021-12-03 20:04:37,577 [Executor task launch worker for task 43] INFO [org.apache.spark.executor.Executor] - Finished task 21.0 in stage 1.0 (TID 43). 1052 bytes result sent to driver
2021-12-03 20:04:37,577 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 21.0 in stage 1.0 (TID 43) in 82902 ms on localhost (executor driver) (17/22)
2021-12-03 20:04:40,774 [Executor task launch worker for task 39] INFO [org.apache.spark.executor.Executor] - Finished task 17.0 in stage 1.0 (TID 39). 1009 bytes result sent to driver
2021-12-03 20:04:40,775 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 17.0 in stage 1.0 (TID 39) in 92351 ms on localhost (executor driver) (18/22)
2021-12-03 20:04:41,610 [Executor task launch worker for task 36] INFO [org.apache.spark.executor.Executor] - Finished task 14.0 in stage 1.0 (TID 36). 1052 bytes result sent to driver
2021-12-03 20:04:41,611 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 14.0 in stage 1.0 (TID 36) in 120506 ms on localhost (executor driver) (19/22)
2021-12-03 20:04:47,445 [Executor task launch worker for task 40] INFO [org.apache.spark.executor.Executor] - Finished task 18.0 in stage 1.0 (TID 40). 1009 bytes result sent to driver
2021-12-03 20:04:47,446 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 18.0 in stage 1.0 (TID 40) in 96336 ms on localhost (executor driver) (20/22)
2021-12-03 20:04:48,561 [Executor task launch worker for task 42] INFO [org.apache.spark.executor.Executor] - Finished task 20.0 in stage 1.0 (TID 42). 1009 bytes result sent to driver
2021-12-03 20:04:48,561 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 20.0 in stage 1.0 (TID 42) in 96743 ms on localhost (executor driver) (21/22)
2021-12-03 20:04:48,730 [Executor task launch worker for task 41] INFO [org.apache.spark.executor.Executor] - Finished task 19.0 in stage 1.0 (TID 41). 1052 bytes result sent to driver
2021-12-03 20:04:48,731 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 19.0 in stage 1.0 (TID 41) in 97226 ms on localhost (executor driver) (22/22)
2021-12-03 20:04:48,731 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 1.0, whose tasks have all completed, from pool 
2021-12-03 20:04:48,731 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ShuffleMapStage 1 (map at PaidPromotionAdjustParameter.scala:67) finished in 256.733 s
2021-12-03 20:04:48,731 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - looking for newly runnable stages
2021-12-03 20:04:48,732 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - running: Set()
2021-12-03 20:04:48,732 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - waiting: Set(ResultStage 2)
2021-12-03 20:04:48,732 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - failed: Set()
2021-12-03 20:04:48,734 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 2 (ShuffledRDD[4] at reduceByKey at PaidPromotionAdjustParameter.scala:67), which has no missing parents
2021-12-03 20:04:48,739 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_3 stored as values in memory (estimated size 3.0 KB, free 1990.5 MB)
2021-12-03 20:04:48,741 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_3_piece0 stored as bytes in memory (estimated size 1906.0 B, free 1990.5 MB)
2021-12-03 20:04:48,741 [dispatcher-event-loop-1] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_3_piece0 in memory on qb:50070 (size: 1906.0 B, free: 1990.8 MB)
2021-12-03 20:04:48,742 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 3 from broadcast at DAGScheduler.scala:1039
2021-12-03 20:04:48,742 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 22 missing tasks from ResultStage 2 (ShuffledRDD[4] at reduceByKey at PaidPromotionAdjustParameter.scala:67) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14))
2021-12-03 20:04:48,742 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 2.0 with 22 tasks
2021-12-03 20:04:48,743 [dispatcher-event-loop-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 2.0 (TID 44, localhost, executor driver, partition 0, ANY, 7649 bytes)
2021-12-03 20:04:48,743 [dispatcher-event-loop-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 2.0 (TID 45, localhost, executor driver, partition 1, ANY, 7649 bytes)
2021-12-03 20:04:48,743 [dispatcher-event-loop-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 2.0 in stage 2.0 (TID 46, localhost, executor driver, partition 2, ANY, 7649 bytes)
2021-12-03 20:04:48,743 [dispatcher-event-loop-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 3.0 in stage 2.0 (TID 47, localhost, executor driver, partition 3, ANY, 7649 bytes)
2021-12-03 20:04:48,743 [dispatcher-event-loop-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 4.0 in stage 2.0 (TID 48, localhost, executor driver, partition 4, ANY, 7649 bytes)
2021-12-03 20:04:48,744 [dispatcher-event-loop-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 5.0 in stage 2.0 (TID 49, localhost, executor driver, partition 5, ANY, 7649 bytes)
2021-12-03 20:04:48,744 [dispatcher-event-loop-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 6.0 in stage 2.0 (TID 50, localhost, executor driver, partition 6, ANY, 7649 bytes)
2021-12-03 20:04:48,744 [dispatcher-event-loop-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 7.0 in stage 2.0 (TID 51, localhost, executor driver, partition 7, ANY, 7649 bytes)
2021-12-03 20:04:48,744 [dispatcher-event-loop-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 8.0 in stage 2.0 (TID 52, localhost, executor driver, partition 8, ANY, 7649 bytes)
2021-12-03 20:04:48,744 [dispatcher-event-loop-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 9.0 in stage 2.0 (TID 53, localhost, executor driver, partition 9, ANY, 7649 bytes)
2021-12-03 20:04:48,744 [dispatcher-event-loop-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 10.0 in stage 2.0 (TID 54, localhost, executor driver, partition 10, ANY, 7649 bytes)
2021-12-03 20:04:48,744 [dispatcher-event-loop-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 11.0 in stage 2.0 (TID 55, localhost, executor driver, partition 11, ANY, 7649 bytes)
2021-12-03 20:04:48,744 [Executor task launch worker for task 45] INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 2.0 (TID 45)
2021-12-03 20:04:48,744 [Executor task launch worker for task 49] INFO [org.apache.spark.executor.Executor] - Running task 5.0 in stage 2.0 (TID 49)
2021-12-03 20:04:48,744 [Executor task launch worker for task 44] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 2.0 (TID 44)
2021-12-03 20:04:48,744 [Executor task launch worker for task 51] INFO [org.apache.spark.executor.Executor] - Running task 7.0 in stage 2.0 (TID 51)
2021-12-03 20:04:48,744 [Executor task launch worker for task 48] INFO [org.apache.spark.executor.Executor] - Running task 4.0 in stage 2.0 (TID 48)
2021-12-03 20:04:48,744 [Executor task launch worker for task 50] INFO [org.apache.spark.executor.Executor] - Running task 6.0 in stage 2.0 (TID 50)
2021-12-03 20:04:48,744 [Executor task launch worker for task 46] INFO [org.apache.spark.executor.Executor] - Running task 2.0 in stage 2.0 (TID 46)
2021-12-03 20:04:48,744 [Executor task launch worker for task 47] INFO [org.apache.spark.executor.Executor] - Running task 3.0 in stage 2.0 (TID 47)
2021-12-03 20:04:48,744 [Executor task launch worker for task 53] INFO [org.apache.spark.executor.Executor] - Running task 9.0 in stage 2.0 (TID 53)
2021-12-03 20:04:48,744 [Executor task launch worker for task 52] INFO [org.apache.spark.executor.Executor] - Running task 8.0 in stage 2.0 (TID 52)
2021-12-03 20:04:48,745 [Executor task launch worker for task 54] INFO [org.apache.spark.executor.Executor] - Running task 10.0 in stage 2.0 (TID 54)
2021-12-03 20:04:48,745 [Executor task launch worker for task 55] INFO [org.apache.spark.executor.Executor] - Running task 11.0 in stage 2.0 (TID 55)
2021-12-03 20:04:48,756 [Executor task launch worker for task 44] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 20:04:48,756 [Executor task launch worker for task 51] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 20:04:48,756 [Executor task launch worker for task 48] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 20:04:48,756 [Executor task launch worker for task 45] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 20:04:48,756 [Executor task launch worker for task 46] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 20:04:48,756 [Executor task launch worker for task 50] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 20:04:48,756 [Executor task launch worker for task 49] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 20:04:48,756 [Executor task launch worker for task 47] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 20:04:48,756 [Executor task launch worker for task 55] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 20:04:48,756 [Executor task launch worker for task 54] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 20:04:48,756 [Executor task launch worker for task 52] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 20:04:48,756 [Executor task launch worker for task 53] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 20:04:48,757 [Executor task launch worker for task 44] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 5 ms
2021-12-03 20:04:48,758 [Executor task launch worker for task 48] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 6 ms
2021-12-03 20:04:48,758 [Executor task launch worker for task 52] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 6 ms
2021-12-03 20:04:48,757 [Executor task launch worker for task 47] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 5 ms
2021-12-03 20:04:48,757 [Executor task launch worker for task 54] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 5 ms
2021-12-03 20:04:48,757 [Executor task launch worker for task 50] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 5 ms
2021-12-03 20:04:48,757 [Executor task launch worker for task 55] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 5 ms
2021-12-03 20:04:48,757 [Executor task launch worker for task 53] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 5 ms
2021-12-03 20:04:48,758 [Executor task launch worker for task 49] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 6 ms
2021-12-03 20:04:48,757 [Executor task launch worker for task 46] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 5 ms
2021-12-03 20:04:48,757 [Executor task launch worker for task 51] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 5 ms
2021-12-03 20:04:48,757 [Executor task launch worker for task 45] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 5 ms
2021-12-03 20:04:49,142 [Executor task launch worker for task 50] INFO [org.apache.spark.executor.Executor] - Finished task 6.0 in stage 2.0 (TID 50). 1098 bytes result sent to driver
2021-12-03 20:04:49,142 [Executor task launch worker for task 52] INFO [org.apache.spark.executor.Executor] - Finished task 8.0 in stage 2.0 (TID 52). 1098 bytes result sent to driver
2021-12-03 20:04:49,143 [dispatcher-event-loop-10] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 12.0 in stage 2.0 (TID 56, localhost, executor driver, partition 12, ANY, 7649 bytes)
2021-12-03 20:04:49,143 [Executor task launch worker for task 56] INFO [org.apache.spark.executor.Executor] - Running task 12.0 in stage 2.0 (TID 56)
2021-12-03 20:04:49,143 [dispatcher-event-loop-10] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 13.0 in stage 2.0 (TID 57, localhost, executor driver, partition 13, ANY, 7649 bytes)
2021-12-03 20:04:49,143 [Executor task launch worker for task 57] INFO [org.apache.spark.executor.Executor] - Running task 13.0 in stage 2.0 (TID 57)
2021-12-03 20:04:49,144 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 8.0 in stage 2.0 (TID 52) in 400 ms on localhost (executor driver) (1/22)
2021-12-03 20:04:49,144 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 6.0 in stage 2.0 (TID 50) in 400 ms on localhost (executor driver) (2/22)
2021-12-03 20:04:49,144 [Executor task launch worker for task 53] INFO [org.apache.spark.executor.Executor] - Finished task 9.0 in stage 2.0 (TID 53). 1098 bytes result sent to driver
2021-12-03 20:04:49,145 [Executor task launch worker for task 51] INFO [org.apache.spark.executor.Executor] - Finished task 7.0 in stage 2.0 (TID 51). 1098 bytes result sent to driver
2021-12-03 20:04:49,146 [Executor task launch worker for task 54] INFO [org.apache.spark.executor.Executor] - Finished task 10.0 in stage 2.0 (TID 54). 1098 bytes result sent to driver
2021-12-03 20:04:49,146 [Executor task launch worker for task 56] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 20:04:49,146 [Executor task launch worker for task 56] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 20:04:49,146 [dispatcher-event-loop-7] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 14.0 in stage 2.0 (TID 58, localhost, executor driver, partition 14, ANY, 7649 bytes)
2021-12-03 20:04:49,147 [Executor task launch worker for task 57] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 20:04:49,147 [Executor task launch worker for task 57] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 20:04:49,147 [dispatcher-event-loop-7] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 15.0 in stage 2.0 (TID 59, localhost, executor driver, partition 15, ANY, 7649 bytes)
2021-12-03 20:04:49,147 [Executor task launch worker for task 58] INFO [org.apache.spark.executor.Executor] - Running task 14.0 in stage 2.0 (TID 58)
2021-12-03 20:04:49,147 [dispatcher-event-loop-7] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 16.0 in stage 2.0 (TID 60, localhost, executor driver, partition 16, ANY, 7649 bytes)
2021-12-03 20:04:49,147 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 9.0 in stage 2.0 (TID 53) in 403 ms on localhost (executor driver) (3/22)
2021-12-03 20:04:49,147 [Executor task launch worker for task 46] INFO [org.apache.spark.executor.Executor] - Finished task 2.0 in stage 2.0 (TID 46). 1098 bytes result sent to driver
2021-12-03 20:04:49,147 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 7.0 in stage 2.0 (TID 51) in 403 ms on localhost (executor driver) (4/22)
2021-12-03 20:04:49,147 [Executor task launch worker for task 60] INFO [org.apache.spark.executor.Executor] - Running task 16.0 in stage 2.0 (TID 60)
2021-12-03 20:04:49,148 [dispatcher-event-loop-5] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 17.0 in stage 2.0 (TID 61, localhost, executor driver, partition 17, ANY, 7649 bytes)
2021-12-03 20:04:49,148 [Executor task launch worker for task 59] INFO [org.apache.spark.executor.Executor] - Running task 15.0 in stage 2.0 (TID 59)
2021-12-03 20:04:49,148 [Executor task launch worker for task 61] INFO [org.apache.spark.executor.Executor] - Running task 17.0 in stage 2.0 (TID 61)
2021-12-03 20:04:49,149 [Executor task launch worker for task 61] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 20:04:49,149 [Executor task launch worker for task 45] INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 2.0 (TID 45). 1098 bytes result sent to driver
2021-12-03 20:04:49,149 [Executor task launch worker for task 59] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 20:04:49,149 [Executor task launch worker for task 59] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 20:04:49,149 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 10.0 in stage 2.0 (TID 54) in 405 ms on localhost (executor driver) (5/22)
2021-12-03 20:04:49,149 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 2.0 in stage 2.0 (TID 46) in 406 ms on localhost (executor driver) (6/22)
2021-12-03 20:04:49,149 [Executor task launch worker for task 61] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 20:04:49,150 [Executor task launch worker for task 58] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 20:04:49,150 [Executor task launch worker for task 58] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 20:04:49,151 [dispatcher-event-loop-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 18.0 in stage 2.0 (TID 62, localhost, executor driver, partition 18, ANY, 7649 bytes)
2021-12-03 20:04:49,151 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 2.0 (TID 45) in 408 ms on localhost (executor driver) (7/22)
2021-12-03 20:04:49,152 [Executor task launch worker for task 62] INFO [org.apache.spark.executor.Executor] - Running task 18.0 in stage 2.0 (TID 62)
2021-12-03 20:04:49,152 [Executor task launch worker for task 60] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 20:04:49,152 [Executor task launch worker for task 60] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 20:04:49,152 [Executor task launch worker for task 49] INFO [org.apache.spark.executor.Executor] - Finished task 5.0 in stage 2.0 (TID 49). 1098 bytes result sent to driver
2021-12-03 20:04:49,152 [Executor task launch worker for task 55] INFO [org.apache.spark.executor.Executor] - Finished task 11.0 in stage 2.0 (TID 55). 1098 bytes result sent to driver
2021-12-03 20:04:49,152 [Executor task launch worker for task 44] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 2.0 (TID 44). 1098 bytes result sent to driver
2021-12-03 20:04:49,153 [Executor task launch worker for task 62] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 20:04:49,153 [Executor task launch worker for task 62] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 20:04:49,153 [dispatcher-event-loop-10] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 19.0 in stage 2.0 (TID 63, localhost, executor driver, partition 19, ANY, 7649 bytes)
2021-12-03 20:04:49,153 [Executor task launch worker for task 63] INFO [org.apache.spark.executor.Executor] - Running task 19.0 in stage 2.0 (TID 63)
2021-12-03 20:04:49,153 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 5.0 in stage 2.0 (TID 49) in 410 ms on localhost (executor driver) (8/22)
2021-12-03 20:04:49,154 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 11.0 in stage 2.0 (TID 55) in 410 ms on localhost (executor driver) (9/22)
2021-12-03 20:04:49,154 [dispatcher-event-loop-10] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 20.0 in stage 2.0 (TID 64, localhost, executor driver, partition 20, ANY, 7649 bytes)
2021-12-03 20:04:49,154 [Executor task launch worker for task 64] INFO [org.apache.spark.executor.Executor] - Running task 20.0 in stage 2.0 (TID 64)
2021-12-03 20:04:49,154 [dispatcher-event-loop-10] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 21.0 in stage 2.0 (TID 65, localhost, executor driver, partition 21, ANY, 7649 bytes)
2021-12-03 20:04:49,155 [Executor task launch worker for task 65] INFO [org.apache.spark.executor.Executor] - Running task 21.0 in stage 2.0 (TID 65)
2021-12-03 20:04:49,155 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 2.0 (TID 44) in 413 ms on localhost (executor driver) (10/22)
2021-12-03 20:04:49,156 [Executor task launch worker for task 48] INFO [org.apache.spark.executor.Executor] - Finished task 4.0 in stage 2.0 (TID 48). 1098 bytes result sent to driver
2021-12-03 20:04:49,156 [Executor task launch worker for task 63] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 20:04:49,156 [Executor task launch worker for task 63] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 20:04:49,156 [Executor task launch worker for task 64] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 20:04:49,157 [Executor task launch worker for task 64] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 1 ms
2021-12-03 20:04:49,157 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 4.0 in stage 2.0 (TID 48) in 414 ms on localhost (executor driver) (11/22)
2021-12-03 20:04:49,157 [Executor task launch worker for task 47] INFO [org.apache.spark.executor.Executor] - Finished task 3.0 in stage 2.0 (TID 47). 1098 bytes result sent to driver
2021-12-03 20:04:49,157 [Executor task launch worker for task 65] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 20:04:49,157 [Executor task launch worker for task 65] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 20:04:49,157 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 3.0 in stage 2.0 (TID 47) in 414 ms on localhost (executor driver) (12/22)
2021-12-03 20:04:49,240 [Executor task launch worker for task 57] INFO [org.apache.spark.executor.Executor] - Finished task 13.0 in stage 2.0 (TID 57). 1055 bytes result sent to driver
2021-12-03 20:04:49,240 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 13.0 in stage 2.0 (TID 57) in 97 ms on localhost (executor driver) (13/22)
2021-12-03 20:04:49,245 [Executor task launch worker for task 60] INFO [org.apache.spark.executor.Executor] - Finished task 16.0 in stage 2.0 (TID 60). 1055 bytes result sent to driver
2021-12-03 20:04:49,245 [Executor task launch worker for task 61] INFO [org.apache.spark.executor.Executor] - Finished task 17.0 in stage 2.0 (TID 61). 1055 bytes result sent to driver
2021-12-03 20:04:49,246 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 16.0 in stage 2.0 (TID 60) in 99 ms on localhost (executor driver) (14/22)
2021-12-03 20:04:49,246 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 17.0 in stage 2.0 (TID 61) in 98 ms on localhost (executor driver) (15/22)
2021-12-03 20:04:49,246 [Executor task launch worker for task 56] INFO [org.apache.spark.executor.Executor] - Finished task 12.0 in stage 2.0 (TID 56). 1055 bytes result sent to driver
2021-12-03 20:04:49,247 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 12.0 in stage 2.0 (TID 56) in 105 ms on localhost (executor driver) (16/22)
2021-12-03 20:04:49,247 [Executor task launch worker for task 63] INFO [org.apache.spark.executor.Executor] - Finished task 19.0 in stage 2.0 (TID 63). 1055 bytes result sent to driver
2021-12-03 20:04:49,248 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 19.0 in stage 2.0 (TID 63) in 96 ms on localhost (executor driver) (17/22)
2021-12-03 20:04:49,249 [Executor task launch worker for task 64] INFO [org.apache.spark.executor.Executor] - Finished task 20.0 in stage 2.0 (TID 64). 1055 bytes result sent to driver
2021-12-03 20:04:49,250 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 20.0 in stage 2.0 (TID 64) in 96 ms on localhost (executor driver) (18/22)
2021-12-03 20:04:49,251 [Executor task launch worker for task 62] INFO [org.apache.spark.executor.Executor] - Finished task 18.0 in stage 2.0 (TID 62). 1012 bytes result sent to driver
2021-12-03 20:04:49,252 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 18.0 in stage 2.0 (TID 62) in 101 ms on localhost (executor driver) (19/22)
2021-12-03 20:04:49,253 [Executor task launch worker for task 59] INFO [org.apache.spark.executor.Executor] - Finished task 15.0 in stage 2.0 (TID 59). 1055 bytes result sent to driver
2021-12-03 20:04:49,253 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 15.0 in stage 2.0 (TID 59) in 106 ms on localhost (executor driver) (20/22)
2021-12-03 20:04:49,254 [Executor task launch worker for task 65] INFO [org.apache.spark.executor.Executor] - Finished task 21.0 in stage 2.0 (TID 65). 1055 bytes result sent to driver
2021-12-03 20:04:49,254 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 21.0 in stage 2.0 (TID 65) in 100 ms on localhost (executor driver) (21/22)
2021-12-03 20:04:49,254 [Executor task launch worker for task 58] INFO [org.apache.spark.executor.Executor] - Finished task 14.0 in stage 2.0 (TID 58). 1055 bytes result sent to driver
2021-12-03 20:04:49,254 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 14.0 in stage 2.0 (TID 58) in 108 ms on localhost (executor driver) (22/22)
2021-12-03 20:04:49,254 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 2.0, whose tasks have all completed, from pool 
2021-12-03 20:04:49,254 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 2 (count at PaidPromotionAdjustParameter.scala:68) finished in 0.517 s
2021-12-03 20:04:49,255 [main] INFO [org.apache.spark.scheduler.DAGScheduler] - Job 1 finished: count at PaidPromotionAdjustParameter.scala:68, took 257.268303 s
2021-12-03 20:04:49,274 [main] INFO [org.apache.spark.SparkContext] - Starting job: sortByKey at PaidPromotionAdjustParameter.scala:72
2021-12-03 20:04:49,275 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 2 (sortByKey at PaidPromotionAdjustParameter.scala:72) with 22 output partitions
2021-12-03 20:04:49,275 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 4 (sortByKey at PaidPromotionAdjustParameter.scala:72)
2021-12-03 20:04:49,275 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 3)
2021-12-03 20:04:49,275 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2021-12-03 20:04:49,275 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 4 (MapPartitionsRDD[7] at sortByKey at PaidPromotionAdjustParameter.scala:72), which has no missing parents
2021-12-03 20:04:49,278 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_4 stored as values in memory (estimated size 4.1 KB, free 1990.5 MB)
2021-12-03 20:04:49,279 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_4_piece0 stored as bytes in memory (estimated size 2.4 KB, free 1990.4 MB)
2021-12-03 20:04:49,279 [dispatcher-event-loop-0] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_4_piece0 in memory on qb:50070 (size: 2.4 KB, free: 1990.8 MB)
2021-12-03 20:04:49,280 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 4 from broadcast at DAGScheduler.scala:1039
2021-12-03 20:04:49,280 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 22 missing tasks from ResultStage 4 (MapPartitionsRDD[7] at sortByKey at PaidPromotionAdjustParameter.scala:72) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14))
2021-12-03 20:04:49,280 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 4.0 with 22 tasks
2021-12-03 20:04:49,281 [dispatcher-event-loop-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 4.0 (TID 66, localhost, executor driver, partition 0, ANY, 7649 bytes)
2021-12-03 20:04:49,281 [dispatcher-event-loop-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 4.0 (TID 67, localhost, executor driver, partition 1, ANY, 7649 bytes)
2021-12-03 20:04:49,281 [dispatcher-event-loop-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 2.0 in stage 4.0 (TID 68, localhost, executor driver, partition 2, ANY, 7649 bytes)
2021-12-03 20:04:49,281 [dispatcher-event-loop-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 3.0 in stage 4.0 (TID 69, localhost, executor driver, partition 3, ANY, 7649 bytes)
2021-12-03 20:04:49,281 [dispatcher-event-loop-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 4.0 in stage 4.0 (TID 70, localhost, executor driver, partition 4, ANY, 7649 bytes)
2021-12-03 20:04:49,281 [dispatcher-event-loop-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 5.0 in stage 4.0 (TID 71, localhost, executor driver, partition 5, ANY, 7649 bytes)
2021-12-03 20:04:49,281 [dispatcher-event-loop-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 6.0 in stage 4.0 (TID 72, localhost, executor driver, partition 6, ANY, 7649 bytes)
2021-12-03 20:04:49,281 [dispatcher-event-loop-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 7.0 in stage 4.0 (TID 73, localhost, executor driver, partition 7, ANY, 7649 bytes)
2021-12-03 20:04:49,281 [dispatcher-event-loop-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 8.0 in stage 4.0 (TID 74, localhost, executor driver, partition 8, ANY, 7649 bytes)
2021-12-03 20:04:49,281 [dispatcher-event-loop-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 9.0 in stage 4.0 (TID 75, localhost, executor driver, partition 9, ANY, 7649 bytes)
2021-12-03 20:04:49,281 [dispatcher-event-loop-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 10.0 in stage 4.0 (TID 76, localhost, executor driver, partition 10, ANY, 7649 bytes)
2021-12-03 20:04:49,282 [dispatcher-event-loop-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 11.0 in stage 4.0 (TID 77, localhost, executor driver, partition 11, ANY, 7649 bytes)
2021-12-03 20:04:49,282 [Executor task launch worker for task 66] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 4.0 (TID 66)
2021-12-03 20:04:49,282 [Executor task launch worker for task 70] INFO [org.apache.spark.executor.Executor] - Running task 4.0 in stage 4.0 (TID 70)
2021-12-03 20:04:49,282 [Executor task launch worker for task 73] INFO [org.apache.spark.executor.Executor] - Running task 7.0 in stage 4.0 (TID 73)
2021-12-03 20:04:49,282 [Executor task launch worker for task 67] INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 4.0 (TID 67)
2021-12-03 20:04:49,282 [Executor task launch worker for task 69] INFO [org.apache.spark.executor.Executor] - Running task 3.0 in stage 4.0 (TID 69)
2021-12-03 20:04:49,282 [Executor task launch worker for task 71] INFO [org.apache.spark.executor.Executor] - Running task 5.0 in stage 4.0 (TID 71)
2021-12-03 20:04:49,282 [Executor task launch worker for task 72] INFO [org.apache.spark.executor.Executor] - Running task 6.0 in stage 4.0 (TID 72)
2021-12-03 20:04:49,282 [Executor task launch worker for task 68] INFO [org.apache.spark.executor.Executor] - Running task 2.0 in stage 4.0 (TID 68)
2021-12-03 20:04:49,282 [Executor task launch worker for task 75] INFO [org.apache.spark.executor.Executor] - Running task 9.0 in stage 4.0 (TID 75)
2021-12-03 20:04:49,282 [Executor task launch worker for task 74] INFO [org.apache.spark.executor.Executor] - Running task 8.0 in stage 4.0 (TID 74)
2021-12-03 20:04:49,282 [Executor task launch worker for task 76] INFO [org.apache.spark.executor.Executor] - Running task 10.0 in stage 4.0 (TID 76)
2021-12-03 20:04:49,282 [Executor task launch worker for task 77] INFO [org.apache.spark.executor.Executor] - Running task 11.0 in stage 4.0 (TID 77)
2021-12-03 20:04:49,284 [Executor task launch worker for task 77] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 20:04:49,284 [Executor task launch worker for task 77] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 20:04:49,284 [Executor task launch worker for task 68] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 20:04:49,284 [Executor task launch worker for task 68] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 20:04:49,284 [Executor task launch worker for task 72] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 20:04:49,284 [Executor task launch worker for task 72] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 20:04:49,284 [Executor task launch worker for task 70] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 20:04:49,284 [Executor task launch worker for task 73] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 20:04:49,284 [Executor task launch worker for task 70] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 20:04:49,284 [Executor task launch worker for task 73] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 20:04:49,284 [Executor task launch worker for task 71] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 20:04:49,284 [Executor task launch worker for task 71] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 20:04:49,284 [Executor task launch worker for task 76] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 20:04:49,284 [Executor task launch worker for task 76] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 20:04:49,284 [Executor task launch worker for task 69] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 20:04:49,284 [Executor task launch worker for task 69] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 20:04:49,284 [Executor task launch worker for task 75] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 20:04:49,284 [Executor task launch worker for task 75] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 20:04:49,284 [Executor task launch worker for task 66] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 20:04:49,284 [Executor task launch worker for task 67] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 20:04:49,284 [Executor task launch worker for task 66] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 20:04:49,284 [Executor task launch worker for task 67] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 20:04:49,285 [Executor task launch worker for task 74] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 20:04:49,285 [Executor task launch worker for task 74] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 1 ms
2021-12-03 20:04:49,391 [Executor task launch worker for task 70] INFO [org.apache.spark.executor.Executor] - Finished task 4.0 in stage 4.0 (TID 70). 1187 bytes result sent to driver
2021-12-03 20:04:49,391 [dispatcher-event-loop-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 12.0 in stage 4.0 (TID 78, localhost, executor driver, partition 12, ANY, 7649 bytes)
2021-12-03 20:04:49,392 [Executor task launch worker for task 78] INFO [org.apache.spark.executor.Executor] - Running task 12.0 in stage 4.0 (TID 78)
2021-12-03 20:04:49,392 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 4.0 in stage 4.0 (TID 70) in 111 ms on localhost (executor driver) (1/22)
2021-12-03 20:04:49,393 [Executor task launch worker for task 78] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 20:04:49,393 [Executor task launch worker for task 78] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 20:04:49,393 [Executor task launch worker for task 74] INFO [org.apache.spark.executor.Executor] - Finished task 8.0 in stage 4.0 (TID 74). 1144 bytes result sent to driver
2021-12-03 20:04:49,394 [dispatcher-event-loop-8] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 13.0 in stage 4.0 (TID 79, localhost, executor driver, partition 13, ANY, 7649 bytes)
2021-12-03 20:04:49,394 [Executor task launch worker for task 79] INFO [org.apache.spark.executor.Executor] - Running task 13.0 in stage 4.0 (TID 79)
2021-12-03 20:04:49,394 [Executor task launch worker for task 66] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 4.0 (TID 66). 1145 bytes result sent to driver
2021-12-03 20:04:49,394 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 8.0 in stage 4.0 (TID 74) in 113 ms on localhost (executor driver) (2/22)
2021-12-03 20:04:49,395 [Executor task launch worker for task 79] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 20:04:49,395 [Executor task launch worker for task 79] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 20:04:49,395 [Executor task launch worker for task 77] INFO [org.apache.spark.executor.Executor] - Finished task 11.0 in stage 4.0 (TID 77). 1099 bytes result sent to driver
2021-12-03 20:04:49,395 [dispatcher-event-loop-9] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 14.0 in stage 4.0 (TID 80, localhost, executor driver, partition 14, ANY, 7649 bytes)
2021-12-03 20:04:49,395 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 4.0 (TID 66) in 115 ms on localhost (executor driver) (3/22)
2021-12-03 20:04:49,396 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 11.0 in stage 4.0 (TID 77) in 114 ms on localhost (executor driver) (4/22)
2021-12-03 20:04:49,397 [dispatcher-event-loop-9] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 15.0 in stage 4.0 (TID 81, localhost, executor driver, partition 15, ANY, 7649 bytes)
2021-12-03 20:04:49,398 [Executor task launch worker for task 81] INFO [org.apache.spark.executor.Executor] - Running task 15.0 in stage 4.0 (TID 81)
2021-12-03 20:04:49,398 [Executor task launch worker for task 81] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 20:04:49,399 [Executor task launch worker for task 81] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 1 ms
2021-12-03 20:04:49,400 [Executor task launch worker for task 75] INFO [org.apache.spark.executor.Executor] - Finished task 9.0 in stage 4.0 (TID 75). 1106 bytes result sent to driver
2021-12-03 20:04:49,401 [dispatcher-event-loop-10] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 16.0 in stage 4.0 (TID 82, localhost, executor driver, partition 16, ANY, 7649 bytes)
2021-12-03 20:04:49,401 [Executor task launch worker for task 82] INFO [org.apache.spark.executor.Executor] - Running task 16.0 in stage 4.0 (TID 82)
2021-12-03 20:04:49,401 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 9.0 in stage 4.0 (TID 75) in 120 ms on localhost (executor driver) (5/22)
2021-12-03 20:04:49,402 [Executor task launch worker for task 82] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 20:04:49,402 [Executor task launch worker for task 82] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 20:04:49,403 [Executor task launch worker for task 80] INFO [org.apache.spark.executor.Executor] - Running task 14.0 in stage 4.0 (TID 80)
2021-12-03 20:04:49,404 [Executor task launch worker for task 76] INFO [org.apache.spark.executor.Executor] - Finished task 10.0 in stage 4.0 (TID 76). 1187 bytes result sent to driver
2021-12-03 20:04:49,404 [Executor task launch worker for task 80] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 20:04:49,404 [Executor task launch worker for task 80] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 20:04:49,405 [dispatcher-event-loop-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 17.0 in stage 4.0 (TID 83, localhost, executor driver, partition 17, ANY, 7649 bytes)
2021-12-03 20:04:49,405 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 10.0 in stage 4.0 (TID 76) in 124 ms on localhost (executor driver) (6/22)
2021-12-03 20:04:49,405 [Executor task launch worker for task 83] INFO [org.apache.spark.executor.Executor] - Running task 17.0 in stage 4.0 (TID 83)
2021-12-03 20:04:49,406 [Executor task launch worker for task 83] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 20:04:49,406 [Executor task launch worker for task 83] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 20:04:49,408 [Executor task launch worker for task 72] INFO [org.apache.spark.executor.Executor] - Finished task 6.0 in stage 4.0 (TID 72). 1138 bytes result sent to driver
2021-12-03 20:04:49,408 [dispatcher-event-loop-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 18.0 in stage 4.0 (TID 84, localhost, executor driver, partition 18, ANY, 7649 bytes)
2021-12-03 20:04:49,408 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 6.0 in stage 4.0 (TID 72) in 127 ms on localhost (executor driver) (7/22)
2021-12-03 20:04:49,408 [Executor task launch worker for task 84] INFO [org.apache.spark.executor.Executor] - Running task 18.0 in stage 4.0 (TID 84)
2021-12-03 20:04:49,409 [Executor task launch worker for task 84] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 20:04:49,409 [Executor task launch worker for task 84] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 20:04:49,411 [Executor task launch worker for task 68] INFO [org.apache.spark.executor.Executor] - Finished task 2.0 in stage 4.0 (TID 68). 1146 bytes result sent to driver
2021-12-03 20:04:49,412 [dispatcher-event-loop-8] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 19.0 in stage 4.0 (TID 85, localhost, executor driver, partition 19, ANY, 7649 bytes)
2021-12-03 20:04:49,412 [Executor task launch worker for task 85] INFO [org.apache.spark.executor.Executor] - Running task 19.0 in stage 4.0 (TID 85)
2021-12-03 20:04:49,412 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 2.0 in stage 4.0 (TID 68) in 131 ms on localhost (executor driver) (8/22)
2021-12-03 20:04:49,413 [Executor task launch worker for task 85] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 20:04:49,413 [Executor task launch worker for task 85] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 20:04:49,413 [Executor task launch worker for task 67] INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 4.0 (TID 67). 1140 bytes result sent to driver
2021-12-03 20:04:49,413 [Executor task launch worker for task 69] INFO [org.apache.spark.executor.Executor] - Finished task 3.0 in stage 4.0 (TID 69). 1184 bytes result sent to driver
2021-12-03 20:04:49,414 [dispatcher-event-loop-4] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 20.0 in stage 4.0 (TID 86, localhost, executor driver, partition 20, ANY, 7649 bytes)
2021-12-03 20:04:49,415 [dispatcher-event-loop-4] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 21.0 in stage 4.0 (TID 87, localhost, executor driver, partition 21, ANY, 7649 bytes)
2021-12-03 20:04:49,415 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 4.0 (TID 67) in 134 ms on localhost (executor driver) (9/22)
2021-12-03 20:04:49,415 [Executor task launch worker for task 86] INFO [org.apache.spark.executor.Executor] - Running task 20.0 in stage 4.0 (TID 86)
2021-12-03 20:04:49,415 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 3.0 in stage 4.0 (TID 69) in 134 ms on localhost (executor driver) (10/22)
2021-12-03 20:04:49,416 [Executor task launch worker for task 87] INFO [org.apache.spark.executor.Executor] - Running task 21.0 in stage 4.0 (TID 87)
2021-12-03 20:04:49,416 [Executor task launch worker for task 86] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 20:04:49,416 [Executor task launch worker for task 86] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 20:04:49,429 [Executor task launch worker for task 87] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 20:04:49,430 [Executor task launch worker for task 87] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 1 ms
2021-12-03 20:04:49,431 [Executor task launch worker for task 73] INFO [org.apache.spark.executor.Executor] - Finished task 7.0 in stage 4.0 (TID 73). 1229 bytes result sent to driver
2021-12-03 20:04:49,431 [Executor task launch worker for task 71] INFO [org.apache.spark.executor.Executor] - Finished task 5.0 in stage 4.0 (TID 71). 1189 bytes result sent to driver
2021-12-03 20:04:49,433 [dispatcher-event-loop-0] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_3_piece0 on qb:50070 in memory (size: 1906.0 B, free: 1990.8 MB)
2021-12-03 20:04:49,433 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 7.0 in stage 4.0 (TID 73) in 152 ms on localhost (executor driver) (11/22)
2021-12-03 20:04:49,433 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 5.0 in stage 4.0 (TID 71) in 152 ms on localhost (executor driver) (12/22)
2021-12-03 20:04:49,497 [Executor task launch worker for task 79] INFO [org.apache.spark.executor.Executor] - Finished task 13.0 in stage 4.0 (TID 79). 1184 bytes result sent to driver
2021-12-03 20:04:49,497 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 13.0 in stage 4.0 (TID 79) in 103 ms on localhost (executor driver) (13/22)
2021-12-03 20:04:49,497 [Executor task launch worker for task 81] INFO [org.apache.spark.executor.Executor] - Finished task 15.0 in stage 4.0 (TID 81). 1137 bytes result sent to driver
2021-12-03 20:04:49,498 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 15.0 in stage 4.0 (TID 81) in 101 ms on localhost (executor driver) (14/22)
2021-12-03 20:04:49,505 [Executor task launch worker for task 78] INFO [org.apache.spark.executor.Executor] - Finished task 12.0 in stage 4.0 (TID 78). 1142 bytes result sent to driver
2021-12-03 20:04:49,506 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 12.0 in stage 4.0 (TID 78) in 115 ms on localhost (executor driver) (15/22)
2021-12-03 20:04:49,508 [Executor task launch worker for task 82] INFO [org.apache.spark.executor.Executor] - Finished task 16.0 in stage 4.0 (TID 82). 1186 bytes result sent to driver
2021-12-03 20:04:49,509 [Executor task launch worker for task 83] INFO [org.apache.spark.executor.Executor] - Finished task 17.0 in stage 4.0 (TID 83). 1185 bytes result sent to driver
2021-12-03 20:04:49,509 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 16.0 in stage 4.0 (TID 82) in 108 ms on localhost (executor driver) (16/22)
2021-12-03 20:04:49,509 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 17.0 in stage 4.0 (TID 83) in 105 ms on localhost (executor driver) (17/22)
2021-12-03 20:04:49,510 [Executor task launch worker for task 84] INFO [org.apache.spark.executor.Executor] - Finished task 18.0 in stage 4.0 (TID 84). 1137 bytes result sent to driver
2021-12-03 20:04:49,510 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 18.0 in stage 4.0 (TID 84) in 102 ms on localhost (executor driver) (18/22)
2021-12-03 20:04:49,514 [Executor task launch worker for task 85] INFO [org.apache.spark.executor.Executor] - Finished task 19.0 in stage 4.0 (TID 85). 1146 bytes result sent to driver
2021-12-03 20:04:49,515 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 19.0 in stage 4.0 (TID 85) in 102 ms on localhost (executor driver) (19/22)
2021-12-03 20:04:49,522 [Executor task launch worker for task 80] INFO [org.apache.spark.executor.Executor] - Finished task 14.0 in stage 4.0 (TID 80). 1185 bytes result sent to driver
2021-12-03 20:04:49,522 [Executor task launch worker for task 86] INFO [org.apache.spark.executor.Executor] - Finished task 20.0 in stage 4.0 (TID 86). 1146 bytes result sent to driver
2021-12-03 20:04:49,522 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 14.0 in stage 4.0 (TID 80) in 127 ms on localhost (executor driver) (20/22)
2021-12-03 20:04:49,522 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 20.0 in stage 4.0 (TID 86) in 108 ms on localhost (executor driver) (21/22)
2021-12-03 20:04:49,522 [Executor task launch worker for task 87] INFO [org.apache.spark.executor.Executor] - Finished task 21.0 in stage 4.0 (TID 87). 1144 bytes result sent to driver
2021-12-03 20:04:49,523 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 21.0 in stage 4.0 (TID 87) in 108 ms on localhost (executor driver) (22/22)
2021-12-03 20:04:49,523 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 4.0, whose tasks have all completed, from pool 
2021-12-03 20:04:49,523 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 4 (sortByKey at PaidPromotionAdjustParameter.scala:72) finished in 0.246 s
2021-12-03 20:04:49,523 [main] INFO [org.apache.spark.scheduler.DAGScheduler] - Job 2 finished: sortByKey at PaidPromotionAdjustParameter.scala:72, took 0.249023 s
2021-12-03 20:04:49,537 [main] INFO [org.apache.spark.SparkContext] - Starting job: zipWithIndex at PaidPromotionAdjustParameter.scala:73
2021-12-03 20:04:49,537 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 5 (map at PaidPromotionAdjustParameter.scala:71)
2021-12-03 20:04:49,538 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 3 (zipWithIndex at PaidPromotionAdjustParameter.scala:73) with 21 output partitions
2021-12-03 20:04:49,538 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 7 (zipWithIndex at PaidPromotionAdjustParameter.scala:73)
2021-12-03 20:04:49,538 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 6)
2021-12-03 20:04:49,538 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List(ShuffleMapStage 6)
2021-12-03 20:04:49,538 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ShuffleMapStage 6 (MapPartitionsRDD[5] at map at PaidPromotionAdjustParameter.scala:71), which has no missing parents
2021-12-03 20:04:49,544 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_5 stored as values in memory (estimated size 4.1 KB, free 1990.5 MB)
2021-12-03 20:04:49,546 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_5_piece0 stored as bytes in memory (estimated size 2.4 KB, free 1990.4 MB)
2021-12-03 20:04:49,546 [dispatcher-event-loop-0] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_5_piece0 in memory on qb:50070 (size: 2.4 KB, free: 1990.8 MB)
2021-12-03 20:04:49,546 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 5 from broadcast at DAGScheduler.scala:1039
2021-12-03 20:04:49,547 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 22 missing tasks from ShuffleMapStage 6 (MapPartitionsRDD[5] at map at PaidPromotionAdjustParameter.scala:71) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14))
2021-12-03 20:04:49,547 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 6.0 with 22 tasks
2021-12-03 20:04:49,547 [dispatcher-event-loop-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 6.0 (TID 88, localhost, executor driver, partition 0, ANY, 7638 bytes)
2021-12-03 20:04:49,547 [dispatcher-event-loop-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 6.0 (TID 89, localhost, executor driver, partition 1, ANY, 7638 bytes)
2021-12-03 20:04:49,547 [dispatcher-event-loop-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 2.0 in stage 6.0 (TID 90, localhost, executor driver, partition 2, ANY, 7638 bytes)
2021-12-03 20:04:49,547 [dispatcher-event-loop-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 3.0 in stage 6.0 (TID 91, localhost, executor driver, partition 3, ANY, 7638 bytes)
2021-12-03 20:04:49,547 [dispatcher-event-loop-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 4.0 in stage 6.0 (TID 92, localhost, executor driver, partition 4, ANY, 7638 bytes)
2021-12-03 20:04:49,548 [dispatcher-event-loop-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 5.0 in stage 6.0 (TID 93, localhost, executor driver, partition 5, ANY, 7638 bytes)
2021-12-03 20:04:49,548 [dispatcher-event-loop-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 6.0 in stage 6.0 (TID 94, localhost, executor driver, partition 6, ANY, 7638 bytes)
2021-12-03 20:04:49,548 [dispatcher-event-loop-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 7.0 in stage 6.0 (TID 95, localhost, executor driver, partition 7, ANY, 7638 bytes)
2021-12-03 20:04:49,548 [dispatcher-event-loop-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 8.0 in stage 6.0 (TID 96, localhost, executor driver, partition 8, ANY, 7638 bytes)
2021-12-03 20:04:49,548 [dispatcher-event-loop-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 9.0 in stage 6.0 (TID 97, localhost, executor driver, partition 9, ANY, 7638 bytes)
2021-12-03 20:04:49,548 [dispatcher-event-loop-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 10.0 in stage 6.0 (TID 98, localhost, executor driver, partition 10, ANY, 7638 bytes)
2021-12-03 20:04:49,548 [dispatcher-event-loop-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 11.0 in stage 6.0 (TID 99, localhost, executor driver, partition 11, ANY, 7638 bytes)
2021-12-03 20:04:49,548 [Executor task launch worker for task 89] INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 6.0 (TID 89)
2021-12-03 20:04:49,548 [Executor task launch worker for task 93] INFO [org.apache.spark.executor.Executor] - Running task 5.0 in stage 6.0 (TID 93)
2021-12-03 20:04:49,548 [Executor task launch worker for task 96] INFO [org.apache.spark.executor.Executor] - Running task 8.0 in stage 6.0 (TID 96)
2021-12-03 20:04:49,548 [Executor task launch worker for task 94] INFO [org.apache.spark.executor.Executor] - Running task 6.0 in stage 6.0 (TID 94)
2021-12-03 20:04:49,548 [Executor task launch worker for task 91] INFO [org.apache.spark.executor.Executor] - Running task 3.0 in stage 6.0 (TID 91)
2021-12-03 20:04:49,548 [Executor task launch worker for task 95] INFO [org.apache.spark.executor.Executor] - Running task 7.0 in stage 6.0 (TID 95)
2021-12-03 20:04:49,548 [Executor task launch worker for task 92] INFO [org.apache.spark.executor.Executor] - Running task 4.0 in stage 6.0 (TID 92)
2021-12-03 20:04:49,548 [Executor task launch worker for task 88] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 6.0 (TID 88)
2021-12-03 20:04:49,548 [Executor task launch worker for task 90] INFO [org.apache.spark.executor.Executor] - Running task 2.0 in stage 6.0 (TID 90)
2021-12-03 20:04:49,548 [Executor task launch worker for task 98] INFO [org.apache.spark.executor.Executor] - Running task 10.0 in stage 6.0 (TID 98)
2021-12-03 20:04:49,548 [Executor task launch worker for task 99] INFO [org.apache.spark.executor.Executor] - Running task 11.0 in stage 6.0 (TID 99)
2021-12-03 20:04:49,548 [Executor task launch worker for task 97] INFO [org.apache.spark.executor.Executor] - Running task 9.0 in stage 6.0 (TID 97)
2021-12-03 20:04:49,556 [Executor task launch worker for task 97] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 20:04:49,556 [Executor task launch worker for task 96] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 20:04:49,556 [Executor task launch worker for task 88] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 20:04:49,556 [Executor task launch worker for task 96] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 20:04:49,556 [Executor task launch worker for task 94] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 20:04:49,556 [Executor task launch worker for task 97] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 20:04:49,556 [Executor task launch worker for task 98] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 20:04:49,556 [Executor task launch worker for task 94] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 20:04:49,556 [Executor task launch worker for task 88] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 20:04:49,556 [Executor task launch worker for task 92] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 20:04:49,556 [Executor task launch worker for task 95] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 20:04:49,556 [Executor task launch worker for task 98] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 20:04:49,556 [Executor task launch worker for task 95] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 20:04:49,556 [Executor task launch worker for task 92] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 20:04:49,556 [Executor task launch worker for task 93] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 20:04:49,556 [Executor task launch worker for task 91] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 20:04:49,556 [Executor task launch worker for task 93] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 20:04:49,556 [Executor task launch worker for task 89] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 20:04:49,556 [Executor task launch worker for task 89] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 20:04:49,556 [Executor task launch worker for task 91] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 20:04:49,556 [Executor task launch worker for task 99] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 20:04:49,556 [Executor task launch worker for task 90] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 20:04:49,557 [Executor task launch worker for task 99] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 1 ms
2021-12-03 20:04:49,557 [Executor task launch worker for task 90] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 1 ms
2021-12-03 20:04:50,015 [Executor task launch worker for task 94] INFO [org.apache.spark.executor.Executor] - Finished task 6.0 in stage 6.0 (TID 94). 1224 bytes result sent to driver
2021-12-03 20:04:50,016 [dispatcher-event-loop-8] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 12.0 in stage 6.0 (TID 100, localhost, executor driver, partition 12, ANY, 7638 bytes)
2021-12-03 20:04:50,016 [Executor task launch worker for task 100] INFO [org.apache.spark.executor.Executor] - Running task 12.0 in stage 6.0 (TID 100)
2021-12-03 20:04:50,016 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 6.0 in stage 6.0 (TID 94) in 468 ms on localhost (executor driver) (1/22)
2021-12-03 20:04:50,022 [Executor task launch worker for task 96] INFO [org.apache.spark.executor.Executor] - Finished task 8.0 in stage 6.0 (TID 96). 1224 bytes result sent to driver
2021-12-03 20:04:50,023 [Executor task launch worker for task 100] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 20:04:50,023 [Executor task launch worker for task 100] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 20:04:50,024 [dispatcher-event-loop-6] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 13.0 in stage 6.0 (TID 101, localhost, executor driver, partition 13, ANY, 7638 bytes)
2021-12-03 20:04:50,024 [Executor task launch worker for task 101] INFO [org.apache.spark.executor.Executor] - Running task 13.0 in stage 6.0 (TID 101)
2021-12-03 20:04:50,025 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 8.0 in stage 6.0 (TID 96) in 476 ms on localhost (executor driver) (2/22)
2021-12-03 20:04:50,028 [Executor task launch worker for task 101] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 20:04:50,028 [Executor task launch worker for task 101] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 20:04:50,030 [Executor task launch worker for task 97] INFO [org.apache.spark.executor.Executor] - Finished task 9.0 in stage 6.0 (TID 97). 1224 bytes result sent to driver
2021-12-03 20:04:50,031 [dispatcher-event-loop-4] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 14.0 in stage 6.0 (TID 102, localhost, executor driver, partition 14, ANY, 7638 bytes)
2021-12-03 20:04:50,031 [Executor task launch worker for task 102] INFO [org.apache.spark.executor.Executor] - Running task 14.0 in stage 6.0 (TID 102)
2021-12-03 20:04:50,031 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 9.0 in stage 6.0 (TID 97) in 483 ms on localhost (executor driver) (3/22)
2021-12-03 20:04:50,034 [Executor task launch worker for task 91] INFO [org.apache.spark.executor.Executor] - Finished task 3.0 in stage 6.0 (TID 91). 1224 bytes result sent to driver
2021-12-03 20:04:50,035 [dispatcher-event-loop-10] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 15.0 in stage 6.0 (TID 103, localhost, executor driver, partition 15, ANY, 7638 bytes)
2021-12-03 20:04:50,037 [Executor task launch worker for task 102] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 20:04:50,037 [Executor task launch worker for task 102] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 20:04:50,038 [Executor task launch worker for task 92] INFO [org.apache.spark.executor.Executor] - Finished task 4.0 in stage 6.0 (TID 92). 1267 bytes result sent to driver
2021-12-03 20:04:50,039 [dispatcher-event-loop-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 16.0 in stage 6.0 (TID 104, localhost, executor driver, partition 16, ANY, 7638 bytes)
2021-12-03 20:04:50,039 [Executor task launch worker for task 104] INFO [org.apache.spark.executor.Executor] - Running task 16.0 in stage 6.0 (TID 104)
2021-12-03 20:04:50,039 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 4.0 in stage 6.0 (TID 92) in 492 ms on localhost (executor driver) (4/22)
2021-12-03 20:04:50,042 [Executor task launch worker for task 104] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 20:04:50,042 [Executor task launch worker for task 104] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 20:04:50,043 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 3.0 in stage 6.0 (TID 91) in 496 ms on localhost (executor driver) (5/22)
2021-12-03 20:04:50,043 [Executor task launch worker for task 103] INFO [org.apache.spark.executor.Executor] - Running task 15.0 in stage 6.0 (TID 103)
2021-12-03 20:04:50,049 [Executor task launch worker for task 103] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 20:04:50,049 [Executor task launch worker for task 103] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 20:04:50,062 [Executor task launch worker for task 95] INFO [org.apache.spark.executor.Executor] - Finished task 7.0 in stage 6.0 (TID 95). 1267 bytes result sent to driver
2021-12-03 20:04:50,062 [dispatcher-event-loop-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 17.0 in stage 6.0 (TID 105, localhost, executor driver, partition 17, ANY, 7638 bytes)
2021-12-03 20:04:50,063 [Executor task launch worker for task 105] INFO [org.apache.spark.executor.Executor] - Running task 17.0 in stage 6.0 (TID 105)
2021-12-03 20:04:50,063 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 7.0 in stage 6.0 (TID 95) in 515 ms on localhost (executor driver) (6/22)
2021-12-03 20:04:50,066 [Executor task launch worker for task 105] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 20:04:50,066 [Executor task launch worker for task 105] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 20:04:50,068 [Executor task launch worker for task 93] INFO [org.apache.spark.executor.Executor] - Finished task 5.0 in stage 6.0 (TID 93). 1224 bytes result sent to driver
2021-12-03 20:04:50,068 [dispatcher-event-loop-8] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 18.0 in stage 6.0 (TID 106, localhost, executor driver, partition 18, ANY, 7638 bytes)
2021-12-03 20:04:50,068 [Executor task launch worker for task 106] INFO [org.apache.spark.executor.Executor] - Running task 18.0 in stage 6.0 (TID 106)
2021-12-03 20:04:50,069 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 5.0 in stage 6.0 (TID 93) in 522 ms on localhost (executor driver) (7/22)
2021-12-03 20:04:50,071 [Executor task launch worker for task 106] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 20:04:50,072 [Executor task launch worker for task 106] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 1 ms
2021-12-03 20:04:50,106 [Executor task launch worker for task 90] INFO [org.apache.spark.executor.Executor] - Finished task 2.0 in stage 6.0 (TID 90). 1267 bytes result sent to driver
2021-12-03 20:04:50,107 [dispatcher-event-loop-6] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 19.0 in stage 6.0 (TID 107, localhost, executor driver, partition 19, ANY, 7638 bytes)
2021-12-03 20:04:50,107 [Executor task launch worker for task 107] INFO [org.apache.spark.executor.Executor] - Running task 19.0 in stage 6.0 (TID 107)
2021-12-03 20:04:50,107 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 2.0 in stage 6.0 (TID 90) in 560 ms on localhost (executor driver) (8/22)
2021-12-03 20:04:50,110 [Executor task launch worker for task 107] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 20:04:50,110 [Executor task launch worker for task 107] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 20:04:50,177 [dispatcher-event-loop-10] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_4_piece0 on qb:50070 in memory (size: 2.4 KB, free: 1990.8 MB)
2021-12-03 20:04:50,206 [Executor task launch worker for task 99] INFO [org.apache.spark.executor.Executor] - Finished task 11.0 in stage 6.0 (TID 99). 1267 bytes result sent to driver
2021-12-03 20:04:50,206 [Executor task launch worker for task 88] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 6.0 (TID 88). 1310 bytes result sent to driver
2021-12-03 20:04:50,206 [dispatcher-event-loop-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 20.0 in stage 6.0 (TID 108, localhost, executor driver, partition 20, ANY, 7638 bytes)
2021-12-03 20:04:50,206 [Executor task launch worker for task 108] INFO [org.apache.spark.executor.Executor] - Running task 20.0 in stage 6.0 (TID 108)
2021-12-03 20:04:50,206 [dispatcher-event-loop-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 21.0 in stage 6.0 (TID 109, localhost, executor driver, partition 21, ANY, 7638 bytes)
2021-12-03 20:04:50,207 [Executor task launch worker for task 109] INFO [org.apache.spark.executor.Executor] - Running task 21.0 in stage 6.0 (TID 109)
2021-12-03 20:04:50,207 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 11.0 in stage 6.0 (TID 99) in 659 ms on localhost (executor driver) (9/22)
2021-12-03 20:04:50,207 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 6.0 (TID 88) in 660 ms on localhost (executor driver) (10/22)
2021-12-03 20:04:50,210 [Executor task launch worker for task 108] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 20:04:50,210 [Executor task launch worker for task 108] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 1 ms
2021-12-03 20:04:50,210 [Executor task launch worker for task 109] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 20:04:50,210 [Executor task launch worker for task 109] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 20:04:50,343 [Executor task launch worker for task 98] INFO [org.apache.spark.executor.Executor] - Finished task 10.0 in stage 6.0 (TID 98). 1267 bytes result sent to driver
2021-12-03 20:04:50,343 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 10.0 in stage 6.0 (TID 98) in 795 ms on localhost (executor driver) (11/22)
2021-12-03 20:04:50,350 [Executor task launch worker for task 89] INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 6.0 (TID 89). 1267 bytes result sent to driver
2021-12-03 20:04:50,351 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 6.0 (TID 89) in 804 ms on localhost (executor driver) (12/22)
2021-12-03 20:04:50,446 [Executor task launch worker for task 101] INFO [org.apache.spark.executor.Executor] - Finished task 13.0 in stage 6.0 (TID 101). 1310 bytes result sent to driver
2021-12-03 20:04:50,447 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 13.0 in stage 6.0 (TID 101) in 425 ms on localhost (executor driver) (13/22)
2021-12-03 20:04:50,453 [Executor task launch worker for task 100] INFO [org.apache.spark.executor.Executor] - Finished task 12.0 in stage 6.0 (TID 100). 1267 bytes result sent to driver
2021-12-03 20:04:50,453 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 12.0 in stage 6.0 (TID 100) in 437 ms on localhost (executor driver) (14/22)
2021-12-03 20:04:50,459 [Executor task launch worker for task 103] INFO [org.apache.spark.executor.Executor] - Finished task 15.0 in stage 6.0 (TID 103). 1310 bytes result sent to driver
2021-12-03 20:04:50,460 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 15.0 in stage 6.0 (TID 103) in 425 ms on localhost (executor driver) (15/22)
2021-12-03 20:04:50,478 [Executor task launch worker for task 104] INFO [org.apache.spark.executor.Executor] - Finished task 16.0 in stage 6.0 (TID 104). 1267 bytes result sent to driver
2021-12-03 20:04:50,478 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 16.0 in stage 6.0 (TID 104) in 440 ms on localhost (executor driver) (16/22)
2021-12-03 20:04:50,494 [Executor task launch worker for task 102] INFO [org.apache.spark.executor.Executor] - Finished task 14.0 in stage 6.0 (TID 102). 1267 bytes result sent to driver
2021-12-03 20:04:50,494 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 14.0 in stage 6.0 (TID 102) in 463 ms on localhost (executor driver) (17/22)
2021-12-03 20:04:50,507 [Executor task launch worker for task 105] INFO [org.apache.spark.executor.Executor] - Finished task 17.0 in stage 6.0 (TID 105). 1310 bytes result sent to driver
2021-12-03 20:04:50,508 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 17.0 in stage 6.0 (TID 105) in 446 ms on localhost (executor driver) (18/22)
2021-12-03 20:04:50,508 [Executor task launch worker for task 106] INFO [org.apache.spark.executor.Executor] - Finished task 18.0 in stage 6.0 (TID 106). 1267 bytes result sent to driver
2021-12-03 20:04:50,508 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 18.0 in stage 6.0 (TID 106) in 440 ms on localhost (executor driver) (19/22)
2021-12-03 20:04:50,568 [Executor task launch worker for task 107] INFO [org.apache.spark.executor.Executor] - Finished task 19.0 in stage 6.0 (TID 107). 1267 bytes result sent to driver
2021-12-03 20:04:50,568 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 19.0 in stage 6.0 (TID 107) in 462 ms on localhost (executor driver) (20/22)
2021-12-03 20:04:50,584 [Executor task launch worker for task 109] INFO [org.apache.spark.executor.Executor] - Finished task 21.0 in stage 6.0 (TID 109). 1224 bytes result sent to driver
2021-12-03 20:04:50,584 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 21.0 in stage 6.0 (TID 109) in 378 ms on localhost (executor driver) (21/22)
2021-12-03 20:04:50,588 [Executor task launch worker for task 108] INFO [org.apache.spark.executor.Executor] - Finished task 20.0 in stage 6.0 (TID 108). 1224 bytes result sent to driver
2021-12-03 20:04:50,588 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 20.0 in stage 6.0 (TID 108) in 382 ms on localhost (executor driver) (22/22)
2021-12-03 20:04:50,588 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 6.0, whose tasks have all completed, from pool 
2021-12-03 20:04:50,589 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ShuffleMapStage 6 (map at PaidPromotionAdjustParameter.scala:71) finished in 1.050 s
2021-12-03 20:04:50,589 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - looking for newly runnable stages
2021-12-03 20:04:50,589 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - running: Set()
2021-12-03 20:04:50,589 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - waiting: Set(ResultStage 7)
2021-12-03 20:04:50,589 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - failed: Set()
2021-12-03 20:04:50,589 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 7 (ShuffledRDD[8] at sortByKey at PaidPromotionAdjustParameter.scala:72), which has no missing parents
2021-12-03 20:04:50,591 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_6 stored as values in memory (estimated size 3.4 KB, free 1990.5 MB)
2021-12-03 20:04:50,592 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_6_piece0 stored as bytes in memory (estimated size 2.0 KB, free 1990.4 MB)
2021-12-03 20:04:50,593 [dispatcher-event-loop-2] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_6_piece0 in memory on qb:50070 (size: 2.0 KB, free: 1990.8 MB)
2021-12-03 20:04:50,593 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 6 from broadcast at DAGScheduler.scala:1039
2021-12-03 20:04:50,593 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 21 missing tasks from ResultStage 7 (ShuffledRDD[8] at sortByKey at PaidPromotionAdjustParameter.scala:72) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14))
2021-12-03 20:04:50,593 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 7.0 with 21 tasks
2021-12-03 20:04:50,594 [dispatcher-event-loop-8] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 7.0 (TID 110, localhost, executor driver, partition 0, ANY, 7649 bytes)
2021-12-03 20:04:50,594 [dispatcher-event-loop-8] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 7.0 (TID 111, localhost, executor driver, partition 1, ANY, 7649 bytes)
2021-12-03 20:04:50,594 [dispatcher-event-loop-8] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 2.0 in stage 7.0 (TID 112, localhost, executor driver, partition 2, ANY, 7649 bytes)
2021-12-03 20:04:50,594 [dispatcher-event-loop-8] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 3.0 in stage 7.0 (TID 113, localhost, executor driver, partition 3, ANY, 7649 bytes)
2021-12-03 20:04:50,594 [dispatcher-event-loop-8] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 4.0 in stage 7.0 (TID 114, localhost, executor driver, partition 4, ANY, 7649 bytes)
2021-12-03 20:04:50,594 [dispatcher-event-loop-8] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 5.0 in stage 7.0 (TID 115, localhost, executor driver, partition 5, ANY, 7649 bytes)
2021-12-03 20:04:50,594 [dispatcher-event-loop-8] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 6.0 in stage 7.0 (TID 116, localhost, executor driver, partition 6, ANY, 7649 bytes)
2021-12-03 20:04:50,594 [dispatcher-event-loop-8] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 7.0 in stage 7.0 (TID 117, localhost, executor driver, partition 7, ANY, 7649 bytes)
2021-12-03 20:04:50,594 [dispatcher-event-loop-8] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 8.0 in stage 7.0 (TID 118, localhost, executor driver, partition 8, ANY, 7649 bytes)
2021-12-03 20:04:50,594 [dispatcher-event-loop-8] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 9.0 in stage 7.0 (TID 119, localhost, executor driver, partition 9, ANY, 7649 bytes)
2021-12-03 20:04:50,594 [dispatcher-event-loop-8] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 10.0 in stage 7.0 (TID 120, localhost, executor driver, partition 10, ANY, 7649 bytes)
2021-12-03 20:04:50,594 [dispatcher-event-loop-8] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 11.0 in stage 7.0 (TID 121, localhost, executor driver, partition 11, ANY, 7649 bytes)
2021-12-03 20:04:50,594 [Executor task launch worker for task 112] INFO [org.apache.spark.executor.Executor] - Running task 2.0 in stage 7.0 (TID 112)
2021-12-03 20:04:50,594 [Executor task launch worker for task 117] INFO [org.apache.spark.executor.Executor] - Running task 7.0 in stage 7.0 (TID 117)
2021-12-03 20:04:50,594 [Executor task launch worker for task 121] INFO [org.apache.spark.executor.Executor] - Running task 11.0 in stage 7.0 (TID 121)
2021-12-03 20:04:50,594 [Executor task launch worker for task 120] INFO [org.apache.spark.executor.Executor] - Running task 10.0 in stage 7.0 (TID 120)
2021-12-03 20:04:50,594 [Executor task launch worker for task 118] INFO [org.apache.spark.executor.Executor] - Running task 8.0 in stage 7.0 (TID 118)
2021-12-03 20:04:50,594 [Executor task launch worker for task 119] INFO [org.apache.spark.executor.Executor] - Running task 9.0 in stage 7.0 (TID 119)
2021-12-03 20:04:50,594 [Executor task launch worker for task 116] INFO [org.apache.spark.executor.Executor] - Running task 6.0 in stage 7.0 (TID 116)
2021-12-03 20:04:50,594 [Executor task launch worker for task 115] INFO [org.apache.spark.executor.Executor] - Running task 5.0 in stage 7.0 (TID 115)
2021-12-03 20:04:50,594 [Executor task launch worker for task 113] INFO [org.apache.spark.executor.Executor] - Running task 3.0 in stage 7.0 (TID 113)
2021-12-03 20:04:50,594 [Executor task launch worker for task 114] INFO [org.apache.spark.executor.Executor] - Running task 4.0 in stage 7.0 (TID 114)
2021-12-03 20:04:50,594 [Executor task launch worker for task 111] INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 7.0 (TID 111)
2021-12-03 20:04:50,594 [Executor task launch worker for task 110] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 7.0 (TID 110)
2021-12-03 20:04:50,597 [Executor task launch worker for task 116] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 20:04:50,597 [Executor task launch worker for task 118] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 20:04:50,597 [Executor task launch worker for task 116] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 20:04:50,597 [Executor task launch worker for task 118] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 20:04:50,598 [Executor task launch worker for task 113] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 20:04:50,598 [Executor task launch worker for task 113] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 20:04:50,598 [Executor task launch worker for task 114] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 20:04:50,598 [Executor task launch worker for task 114] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 20:04:50,599 [Executor task launch worker for task 110] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 20:04:50,599 [Executor task launch worker for task 110] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 1 ms
2021-12-03 20:04:50,599 [Executor task launch worker for task 119] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 20:04:50,599 [Executor task launch worker for task 119] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 20:04:50,599 [Executor task launch worker for task 121] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 20:04:50,599 [Executor task launch worker for task 121] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 20:04:50,600 [Executor task launch worker for task 115] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 20:04:50,600 [Executor task launch worker for task 115] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 20:04:50,600 [Executor task launch worker for task 111] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 20:04:50,600 [Executor task launch worker for task 111] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 20:04:50,600 [Executor task launch worker for task 112] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 20:04:50,600 [Executor task launch worker for task 112] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 20:04:50,601 [Executor task launch worker for task 117] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 20:04:50,601 [Executor task launch worker for task 117] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 20:04:50,601 [Executor task launch worker for task 120] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 20:04:50,601 [Executor task launch worker for task 120] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 20:04:50,880 [Executor task launch worker for task 119] INFO [org.apache.spark.executor.Executor] - Finished task 9.0 in stage 7.0 (TID 119). 1098 bytes result sent to driver
2021-12-03 20:04:50,880 [dispatcher-event-loop-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 12.0 in stage 7.0 (TID 122, localhost, executor driver, partition 12, ANY, 7649 bytes)
2021-12-03 20:04:50,881 [Executor task launch worker for task 122] INFO [org.apache.spark.executor.Executor] - Running task 12.0 in stage 7.0 (TID 122)
2021-12-03 20:04:50,881 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 9.0 in stage 7.0 (TID 119) in 287 ms on localhost (executor driver) (1/21)
2021-12-03 20:04:50,883 [Executor task launch worker for task 122] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 20:04:50,883 [Executor task launch worker for task 122] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 20:04:50,891 [Executor task launch worker for task 121] INFO [org.apache.spark.executor.Executor] - Finished task 11.0 in stage 7.0 (TID 121). 1098 bytes result sent to driver
2021-12-03 20:04:50,891 [Executor task launch worker for task 118] INFO [org.apache.spark.executor.Executor] - Finished task 8.0 in stage 7.0 (TID 118). 1098 bytes result sent to driver
2021-12-03 20:04:50,891 [Executor task launch worker for task 114] INFO [org.apache.spark.executor.Executor] - Finished task 4.0 in stage 7.0 (TID 114). 1098 bytes result sent to driver
2021-12-03 20:04:50,891 [Executor task launch worker for task 113] INFO [org.apache.spark.executor.Executor] - Finished task 3.0 in stage 7.0 (TID 113). 1098 bytes result sent to driver
2021-12-03 20:04:50,892 [dispatcher-event-loop-9] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 13.0 in stage 7.0 (TID 123, localhost, executor driver, partition 13, ANY, 7649 bytes)
2021-12-03 20:04:50,892 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 11.0 in stage 7.0 (TID 121) in 298 ms on localhost (executor driver) (2/21)
2021-12-03 20:04:50,892 [Executor task launch worker for task 123] INFO [org.apache.spark.executor.Executor] - Running task 13.0 in stage 7.0 (TID 123)
2021-12-03 20:04:50,892 [dispatcher-event-loop-9] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 14.0 in stage 7.0 (TID 124, localhost, executor driver, partition 14, ANY, 7649 bytes)
2021-12-03 20:04:50,892 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 8.0 in stage 7.0 (TID 118) in 298 ms on localhost (executor driver) (3/21)
2021-12-03 20:04:50,892 [dispatcher-event-loop-9] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 15.0 in stage 7.0 (TID 125, localhost, executor driver, partition 15, ANY, 7649 bytes)
2021-12-03 20:04:50,893 [Executor task launch worker for task 125] INFO [org.apache.spark.executor.Executor] - Running task 15.0 in stage 7.0 (TID 125)
2021-12-03 20:04:50,893 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 4.0 in stage 7.0 (TID 114) in 299 ms on localhost (executor driver) (4/21)
2021-12-03 20:04:50,893 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 3.0 in stage 7.0 (TID 113) in 299 ms on localhost (executor driver) (5/21)
2021-12-03 20:04:50,893 [dispatcher-event-loop-9] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 16.0 in stage 7.0 (TID 126, localhost, executor driver, partition 16, ANY, 7649 bytes)
2021-12-03 20:04:50,893 [Executor task launch worker for task 126] INFO [org.apache.spark.executor.Executor] - Running task 16.0 in stage 7.0 (TID 126)
2021-12-03 20:04:50,895 [Executor task launch worker for task 124] INFO [org.apache.spark.executor.Executor] - Running task 14.0 in stage 7.0 (TID 124)
2021-12-03 20:04:50,896 [Executor task launch worker for task 123] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 20:04:50,896 [Executor task launch worker for task 123] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 20:04:50,896 [Executor task launch worker for task 117] INFO [org.apache.spark.executor.Executor] - Finished task 7.0 in stage 7.0 (TID 117). 1055 bytes result sent to driver
2021-12-03 20:04:50,896 [Executor task launch worker for task 126] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 20:04:50,896 [Executor task launch worker for task 126] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 20:04:50,896 [Executor task launch worker for task 115] INFO [org.apache.spark.executor.Executor] - Finished task 5.0 in stage 7.0 (TID 115). 1098 bytes result sent to driver
2021-12-03 20:04:50,896 [dispatcher-event-loop-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 17.0 in stage 7.0 (TID 127, localhost, executor driver, partition 17, ANY, 7649 bytes)
2021-12-03 20:04:50,897 [Executor task launch worker for task 125] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 20:04:50,897 [Executor task launch worker for task 125] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 1 ms
2021-12-03 20:04:50,897 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 7.0 in stage 7.0 (TID 117) in 303 ms on localhost (executor driver) (6/21)
2021-12-03 20:04:50,897 [Executor task launch worker for task 127] INFO [org.apache.spark.executor.Executor] - Running task 17.0 in stage 7.0 (TID 127)
2021-12-03 20:04:50,897 [dispatcher-event-loop-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 18.0 in stage 7.0 (TID 128, localhost, executor driver, partition 18, ANY, 7649 bytes)
2021-12-03 20:04:50,897 [Executor task launch worker for task 128] INFO [org.apache.spark.executor.Executor] - Running task 18.0 in stage 7.0 (TID 128)
2021-12-03 20:04:50,897 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 5.0 in stage 7.0 (TID 115) in 303 ms on localhost (executor driver) (7/21)
2021-12-03 20:04:50,899 [Executor task launch worker for task 127] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 20:04:50,899 [Executor task launch worker for task 127] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 20:04:50,899 [Executor task launch worker for task 120] INFO [org.apache.spark.executor.Executor] - Finished task 10.0 in stage 7.0 (TID 120). 1055 bytes result sent to driver
2021-12-03 20:04:50,900 [Executor task launch worker for task 124] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 20:04:50,900 [Executor task launch worker for task 124] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 20:04:50,900 [dispatcher-event-loop-4] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 19.0 in stage 7.0 (TID 129, localhost, executor driver, partition 19, ANY, 7649 bytes)
2021-12-03 20:04:50,900 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 10.0 in stage 7.0 (TID 120) in 306 ms on localhost (executor driver) (8/21)
2021-12-03 20:04:50,900 [Executor task launch worker for task 129] INFO [org.apache.spark.executor.Executor] - Running task 19.0 in stage 7.0 (TID 129)
2021-12-03 20:04:50,900 [Executor task launch worker for task 128] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 20:04:50,900 [Executor task launch worker for task 128] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 20:04:50,902 [Executor task launch worker for task 129] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 20:04:50,902 [Executor task launch worker for task 129] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 20:04:50,903 [Executor task launch worker for task 116] INFO [org.apache.spark.executor.Executor] - Finished task 6.0 in stage 7.0 (TID 116). 1098 bytes result sent to driver
2021-12-03 20:04:50,903 [dispatcher-event-loop-10] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 20.0 in stage 7.0 (TID 130, localhost, executor driver, partition 20, ANY, 7649 bytes)
2021-12-03 20:04:50,903 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 6.0 in stage 7.0 (TID 116) in 309 ms on localhost (executor driver) (9/21)
2021-12-03 20:04:50,903 [Executor task launch worker for task 130] INFO [org.apache.spark.executor.Executor] - Running task 20.0 in stage 7.0 (TID 130)
2021-12-03 20:04:50,904 [Executor task launch worker for task 112] INFO [org.apache.spark.executor.Executor] - Finished task 2.0 in stage 7.0 (TID 112). 1055 bytes result sent to driver
2021-12-03 20:04:50,905 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 2.0 in stage 7.0 (TID 112) in 311 ms on localhost (executor driver) (10/21)
2021-12-03 20:04:50,906 [Executor task launch worker for task 130] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 20:04:50,906 [Executor task launch worker for task 130] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 20:04:50,906 [Executor task launch worker for task 110] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 7.0 (TID 110). 1098 bytes result sent to driver
2021-12-03 20:04:50,906 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 7.0 (TID 110) in 313 ms on localhost (executor driver) (11/21)
2021-12-03 20:04:50,913 [Executor task launch worker for task 111] INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 7.0 (TID 111). 1098 bytes result sent to driver
2021-12-03 20:04:50,914 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 7.0 (TID 111) in 320 ms on localhost (executor driver) (12/21)
2021-12-03 20:04:50,957 [Executor task launch worker for task 124] INFO [org.apache.spark.executor.Executor] - Finished task 14.0 in stage 7.0 (TID 124). 1055 bytes result sent to driver
2021-12-03 20:04:50,958 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 14.0 in stage 7.0 (TID 124) in 66 ms on localhost (executor driver) (13/21)
2021-12-03 20:04:50,959 [Executor task launch worker for task 122] INFO [org.apache.spark.executor.Executor] - Finished task 12.0 in stage 7.0 (TID 122). 1055 bytes result sent to driver
2021-12-03 20:04:50,960 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 12.0 in stage 7.0 (TID 122) in 80 ms on localhost (executor driver) (14/21)
2021-12-03 20:04:50,961 [Executor task launch worker for task 126] INFO [org.apache.spark.executor.Executor] - Finished task 16.0 in stage 7.0 (TID 126). 1055 bytes result sent to driver
2021-12-03 20:04:50,962 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 16.0 in stage 7.0 (TID 126) in 69 ms on localhost (executor driver) (15/21)
2021-12-03 20:04:50,967 [Executor task launch worker for task 128] INFO [org.apache.spark.executor.Executor] - Finished task 18.0 in stage 7.0 (TID 128). 1055 bytes result sent to driver
2021-12-03 20:04:50,968 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 18.0 in stage 7.0 (TID 128) in 71 ms on localhost (executor driver) (16/21)
2021-12-03 20:04:50,969 [Executor task launch worker for task 123] INFO [org.apache.spark.executor.Executor] - Finished task 13.0 in stage 7.0 (TID 123). 1098 bytes result sent to driver
2021-12-03 20:04:50,969 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 13.0 in stage 7.0 (TID 123) in 78 ms on localhost (executor driver) (17/21)
2021-12-03 20:04:50,970 [Executor task launch worker for task 125] INFO [org.apache.spark.executor.Executor] - Finished task 15.0 in stage 7.0 (TID 125). 1055 bytes result sent to driver
2021-12-03 20:04:50,971 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 15.0 in stage 7.0 (TID 125) in 79 ms on localhost (executor driver) (18/21)
2021-12-03 20:04:50,973 [Executor task launch worker for task 130] INFO [org.apache.spark.executor.Executor] - Finished task 20.0 in stage 7.0 (TID 130). 1055 bytes result sent to driver
2021-12-03 20:04:50,973 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 20.0 in stage 7.0 (TID 130) in 70 ms on localhost (executor driver) (19/21)
2021-12-03 20:04:50,975 [Executor task launch worker for task 129] INFO [org.apache.spark.executor.Executor] - Finished task 19.0 in stage 7.0 (TID 129). 1055 bytes result sent to driver
2021-12-03 20:04:50,976 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 19.0 in stage 7.0 (TID 129) in 76 ms on localhost (executor driver) (20/21)
2021-12-03 20:04:50,980 [Executor task launch worker for task 127] INFO [org.apache.spark.executor.Executor] - Finished task 17.0 in stage 7.0 (TID 127). 1055 bytes result sent to driver
2021-12-03 20:04:50,980 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 17.0 in stage 7.0 (TID 127) in 84 ms on localhost (executor driver) (21/21)
2021-12-03 20:04:50,980 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 7.0, whose tasks have all completed, from pool 
2021-12-03 20:04:50,980 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 7 (zipWithIndex at PaidPromotionAdjustParameter.scala:73) finished in 0.390 s
2021-12-03 20:04:50,980 [main] INFO [org.apache.spark.scheduler.DAGScheduler] - Job 3 finished: zipWithIndex at PaidPromotionAdjustParameter.scala:73, took 1.443625 s
2021-12-03 20:04:50,991 [main] INFO [org.apache.spark.SparkContext] - Starting job: takeSample at PaidPromotionAdjustParameter.scala:76
2021-12-03 20:04:50,991 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 4 (takeSample at PaidPromotionAdjustParameter.scala:76) with 22 output partitions
2021-12-03 20:04:50,991 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 10 (takeSample at PaidPromotionAdjustParameter.scala:76)
2021-12-03 20:04:50,991 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 9)
2021-12-03 20:04:50,991 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2021-12-03 20:04:50,991 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 10 (MapPartitionsRDD[11] at map at PaidPromotionAdjustParameter.scala:75), which has no missing parents
2021-12-03 20:04:50,994 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_7 stored as values in memory (estimated size 4.2 KB, free 1990.4 MB)
2021-12-03 20:04:51,008 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_7_piece0 stored as bytes in memory (estimated size 2.4 KB, free 1990.4 MB)
2021-12-03 20:04:51,008 [dispatcher-event-loop-5] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_7_piece0 in memory on qb:50070 (size: 2.4 KB, free: 1990.8 MB)
2021-12-03 20:04:51,008 [dispatcher-event-loop-5] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_6_piece0 on qb:50070 in memory (size: 2.0 KB, free: 1990.8 MB)
2021-12-03 20:04:51,008 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 7 from broadcast at DAGScheduler.scala:1039
2021-12-03 20:04:51,009 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 22 missing tasks from ResultStage 10 (MapPartitionsRDD[11] at map at PaidPromotionAdjustParameter.scala:75) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14))
2021-12-03 20:04:51,009 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 10.0 with 22 tasks
2021-12-03 20:04:51,010 [dispatcher-event-loop-8] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 10.0 (TID 131, localhost, executor driver, partition 0, ANY, 7759 bytes)
2021-12-03 20:04:51,010 [dispatcher-event-loop-8] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 10.0 (TID 132, localhost, executor driver, partition 1, ANY, 7759 bytes)
2021-12-03 20:04:51,010 [dispatcher-event-loop-8] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 2.0 in stage 10.0 (TID 133, localhost, executor driver, partition 2, ANY, 7759 bytes)
2021-12-03 20:04:51,010 [dispatcher-event-loop-8] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 3.0 in stage 10.0 (TID 134, localhost, executor driver, partition 3, ANY, 7759 bytes)
2021-12-03 20:04:51,010 [dispatcher-event-loop-8] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 4.0 in stage 10.0 (TID 135, localhost, executor driver, partition 4, ANY, 7759 bytes)
2021-12-03 20:04:51,010 [dispatcher-event-loop-8] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 5.0 in stage 10.0 (TID 136, localhost, executor driver, partition 5, ANY, 7759 bytes)
2021-12-03 20:04:51,010 [dispatcher-event-loop-8] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 6.0 in stage 10.0 (TID 137, localhost, executor driver, partition 6, ANY, 7759 bytes)
2021-12-03 20:04:51,010 [dispatcher-event-loop-8] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 7.0 in stage 10.0 (TID 138, localhost, executor driver, partition 7, ANY, 7759 bytes)
2021-12-03 20:04:51,010 [dispatcher-event-loop-8] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 8.0 in stage 10.0 (TID 139, localhost, executor driver, partition 8, ANY, 7759 bytes)
2021-12-03 20:04:51,010 [dispatcher-event-loop-8] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 9.0 in stage 10.0 (TID 140, localhost, executor driver, partition 9, ANY, 7759 bytes)
2021-12-03 20:04:51,010 [dispatcher-event-loop-8] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 10.0 in stage 10.0 (TID 141, localhost, executor driver, partition 10, ANY, 7759 bytes)
2021-12-03 20:04:51,010 [dispatcher-event-loop-8] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 11.0 in stage 10.0 (TID 142, localhost, executor driver, partition 11, ANY, 7759 bytes)
2021-12-03 20:04:51,010 [Executor task launch worker for task 132] INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 10.0 (TID 132)
2021-12-03 20:04:51,010 [Executor task launch worker for task 139] INFO [org.apache.spark.executor.Executor] - Running task 8.0 in stage 10.0 (TID 139)
2021-12-03 20:04:51,010 [Executor task launch worker for task 140] INFO [org.apache.spark.executor.Executor] - Running task 9.0 in stage 10.0 (TID 140)
2021-12-03 20:04:51,010 [Executor task launch worker for task 131] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 10.0 (TID 131)
2021-12-03 20:04:51,010 [Executor task launch worker for task 138] INFO [org.apache.spark.executor.Executor] - Running task 7.0 in stage 10.0 (TID 138)
2021-12-03 20:04:51,010 [Executor task launch worker for task 137] INFO [org.apache.spark.executor.Executor] - Running task 6.0 in stage 10.0 (TID 137)
2021-12-03 20:04:51,010 [Executor task launch worker for task 136] INFO [org.apache.spark.executor.Executor] - Running task 5.0 in stage 10.0 (TID 136)
2021-12-03 20:04:51,010 [Executor task launch worker for task 134] INFO [org.apache.spark.executor.Executor] - Running task 3.0 in stage 10.0 (TID 134)
2021-12-03 20:04:51,010 [Executor task launch worker for task 133] INFO [org.apache.spark.executor.Executor] - Running task 2.0 in stage 10.0 (TID 133)
2021-12-03 20:04:51,010 [Executor task launch worker for task 135] INFO [org.apache.spark.executor.Executor] - Running task 4.0 in stage 10.0 (TID 135)
2021-12-03 20:04:51,010 [Executor task launch worker for task 142] INFO [org.apache.spark.executor.Executor] - Running task 11.0 in stage 10.0 (TID 142)
2021-12-03 20:04:51,010 [Executor task launch worker for task 141] INFO [org.apache.spark.executor.Executor] - Running task 10.0 in stage 10.0 (TID 141)
2021-12-03 20:04:51,013 [Executor task launch worker for task 138] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 20:04:51,013 [Executor task launch worker for task 133] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 20:04:51,013 [Executor task launch worker for task 138] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 20:04:51,013 [Executor task launch worker for task 133] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 20:04:51,013 [Executor task launch worker for task 132] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 20:04:51,014 [Executor task launch worker for task 132] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 1 ms
2021-12-03 20:04:51,015 [Executor task launch worker for task 139] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 20:04:51,015 [Executor task launch worker for task 139] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 20:04:51,015 [Executor task launch worker for task 136] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 20:04:51,015 [Executor task launch worker for task 136] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 20:04:51,015 [Executor task launch worker for task 142] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 20:04:51,015 [Executor task launch worker for task 141] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 20:04:51,015 [Executor task launch worker for task 142] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 20:04:51,015 [Executor task launch worker for task 141] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 20:04:51,016 [Executor task launch worker for task 137] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 20:04:51,016 [Executor task launch worker for task 137] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 1 ms
2021-12-03 20:04:51,016 [Executor task launch worker for task 140] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 20:04:51,016 [Executor task launch worker for task 140] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 20:04:51,017 [Executor task launch worker for task 134] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 20:04:51,017 [Executor task launch worker for task 135] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 20:04:51,017 [Executor task launch worker for task 131] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 20:04:51,017 [Executor task launch worker for task 134] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 20:04:51,017 [Executor task launch worker for task 131] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 20:04:51,017 [Executor task launch worker for task 135] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 20:04:51,111 [Executor task launch worker for task 136] INFO [org.apache.spark.executor.Executor] - Finished task 5.0 in stage 10.0 (TID 136). 1053 bytes result sent to driver
2021-12-03 20:04:51,121 [dispatcher-event-loop-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 12.0 in stage 10.0 (TID 143, localhost, executor driver, partition 12, ANY, 7759 bytes)
2021-12-03 20:04:51,122 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 5.0 in stage 10.0 (TID 136) in 112 ms on localhost (executor driver) (1/22)
2021-12-03 20:04:51,122 [Executor task launch worker for task 143] INFO [org.apache.spark.executor.Executor] - Running task 12.0 in stage 10.0 (TID 143)
2021-12-03 20:04:51,125 [Executor task launch worker for task 143] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 20:04:51,125 [Executor task launch worker for task 143] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 20:04:51,133 [Executor task launch worker for task 141] INFO [org.apache.spark.executor.Executor] - Finished task 10.0 in stage 10.0 (TID 141). 1053 bytes result sent to driver
2021-12-03 20:04:51,133 [Executor task launch worker for task 134] INFO [org.apache.spark.executor.Executor] - Finished task 3.0 in stage 10.0 (TID 134). 1053 bytes result sent to driver
2021-12-03 20:04:51,133 [Executor task launch worker for task 139] INFO [org.apache.spark.executor.Executor] - Finished task 8.0 in stage 10.0 (TID 139). 1053 bytes result sent to driver
2021-12-03 20:04:51,133 [dispatcher-event-loop-6] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 13.0 in stage 10.0 (TID 144, localhost, executor driver, partition 13, ANY, 7759 bytes)
2021-12-03 20:04:51,134 [Executor task launch worker for task 144] INFO [org.apache.spark.executor.Executor] - Running task 13.0 in stage 10.0 (TID 144)
2021-12-03 20:04:51,134 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 10.0 in stage 10.0 (TID 141) in 124 ms on localhost (executor driver) (2/22)
2021-12-03 20:04:51,134 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 3.0 in stage 10.0 (TID 134) in 124 ms on localhost (executor driver) (3/22)
2021-12-03 20:04:51,134 [dispatcher-event-loop-6] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 14.0 in stage 10.0 (TID 145, localhost, executor driver, partition 14, ANY, 7759 bytes)
2021-12-03 20:04:51,134 [dispatcher-event-loop-6] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 15.0 in stage 10.0 (TID 146, localhost, executor driver, partition 15, ANY, 7759 bytes)
2021-12-03 20:04:51,134 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 8.0 in stage 10.0 (TID 139) in 124 ms on localhost (executor driver) (4/22)
2021-12-03 20:04:51,134 [Executor task launch worker for task 145] INFO [org.apache.spark.executor.Executor] - Running task 14.0 in stage 10.0 (TID 145)
2021-12-03 20:04:51,134 [Executor task launch worker for task 146] INFO [org.apache.spark.executor.Executor] - Running task 15.0 in stage 10.0 (TID 146)
2021-12-03 20:04:51,135 [Executor task launch worker for task 131] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 10.0 (TID 131). 1053 bytes result sent to driver
2021-12-03 20:04:51,136 [dispatcher-event-loop-9] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 16.0 in stage 10.0 (TID 147, localhost, executor driver, partition 16, ANY, 7759 bytes)
2021-12-03 20:04:51,136 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 10.0 (TID 131) in 127 ms on localhost (executor driver) (5/22)
2021-12-03 20:04:51,136 [Executor task launch worker for task 147] INFO [org.apache.spark.executor.Executor] - Running task 16.0 in stage 10.0 (TID 147)
2021-12-03 20:04:51,136 [Executor task launch worker for task 144] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 20:04:51,136 [Executor task launch worker for task 144] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 20:04:51,137 [Executor task launch worker for task 145] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 20:04:51,137 [Executor task launch worker for task 145] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 20:04:51,137 [Executor task launch worker for task 146] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 20:04:51,138 [Executor task launch worker for task 146] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 1 ms
2021-12-03 20:04:51,139 [Executor task launch worker for task 147] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 20:04:51,139 [Executor task launch worker for task 147] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 20:04:51,140 [Executor task launch worker for task 135] INFO [org.apache.spark.executor.Executor] - Finished task 4.0 in stage 10.0 (TID 135). 1053 bytes result sent to driver
2021-12-03 20:04:51,141 [dispatcher-event-loop-5] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 17.0 in stage 10.0 (TID 148, localhost, executor driver, partition 17, ANY, 7759 bytes)
2021-12-03 20:04:51,141 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 4.0 in stage 10.0 (TID 135) in 131 ms on localhost (executor driver) (6/22)
2021-12-03 20:04:51,141 [Executor task launch worker for task 148] INFO [org.apache.spark.executor.Executor] - Running task 17.0 in stage 10.0 (TID 148)
2021-12-03 20:04:51,143 [Executor task launch worker for task 138] INFO [org.apache.spark.executor.Executor] - Finished task 7.0 in stage 10.0 (TID 138). 1053 bytes result sent to driver
2021-12-03 20:04:51,143 [dispatcher-event-loop-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 18.0 in stage 10.0 (TID 149, localhost, executor driver, partition 18, ANY, 7759 bytes)
2021-12-03 20:04:51,143 [Executor task launch worker for task 149] INFO [org.apache.spark.executor.Executor] - Running task 18.0 in stage 10.0 (TID 149)
2021-12-03 20:04:51,143 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 7.0 in stage 10.0 (TID 138) in 133 ms on localhost (executor driver) (7/22)
2021-12-03 20:04:51,144 [Executor task launch worker for task 148] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 20:04:51,144 [Executor task launch worker for task 148] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 20:04:51,146 [Executor task launch worker for task 132] INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 10.0 (TID 132). 1096 bytes result sent to driver
2021-12-03 20:04:51,146 [Executor task launch worker for task 149] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 20:04:51,146 [Executor task launch worker for task 149] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 20:04:51,147 [dispatcher-event-loop-4] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 19.0 in stage 10.0 (TID 150, localhost, executor driver, partition 19, ANY, 7759 bytes)
2021-12-03 20:04:51,147 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 10.0 (TID 132) in 137 ms on localhost (executor driver) (8/22)
2021-12-03 20:04:51,147 [Executor task launch worker for task 150] INFO [org.apache.spark.executor.Executor] - Running task 19.0 in stage 10.0 (TID 150)
2021-12-03 20:04:51,147 [Executor task launch worker for task 142] INFO [org.apache.spark.executor.Executor] - Finished task 11.0 in stage 10.0 (TID 142). 1053 bytes result sent to driver
2021-12-03 20:04:51,148 [dispatcher-event-loop-10] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 20.0 in stage 10.0 (TID 151, localhost, executor driver, partition 20, ANY, 7759 bytes)
2021-12-03 20:04:51,148 [Executor task launch worker for task 151] INFO [org.apache.spark.executor.Executor] - Running task 20.0 in stage 10.0 (TID 151)
2021-12-03 20:04:51,148 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 11.0 in stage 10.0 (TID 142) in 138 ms on localhost (executor driver) (9/22)
2021-12-03 20:04:51,150 [Executor task launch worker for task 151] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 20:04:51,150 [Executor task launch worker for task 151] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 20:04:51,150 [Executor task launch worker for task 150] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 20:04:51,150 [Executor task launch worker for task 150] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 20:04:51,164 [Executor task launch worker for task 133] INFO [org.apache.spark.executor.Executor] - Finished task 2.0 in stage 10.0 (TID 133). 1053 bytes result sent to driver
2021-12-03 20:04:51,165 [dispatcher-event-loop-7] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 21.0 in stage 10.0 (TID 152, localhost, executor driver, partition 21, ANY, 7759 bytes)
2021-12-03 20:04:51,165 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 2.0 in stage 10.0 (TID 133) in 155 ms on localhost (executor driver) (10/22)
2021-12-03 20:04:51,165 [Executor task launch worker for task 152] INFO [org.apache.spark.executor.Executor] - Running task 21.0 in stage 10.0 (TID 152)
2021-12-03 20:04:51,167 [Executor task launch worker for task 140] INFO [org.apache.spark.executor.Executor] - Finished task 9.0 in stage 10.0 (TID 140). 1053 bytes result sent to driver
2021-12-03 20:04:51,168 [Executor task launch worker for task 152] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 20:04:51,168 [Executor task launch worker for task 152] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 20:04:51,176 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 9.0 in stage 10.0 (TID 140) in 166 ms on localhost (executor driver) (11/22)
2021-12-03 20:04:51,183 [Executor task launch worker for task 137] INFO [org.apache.spark.executor.Executor] - Finished task 6.0 in stage 10.0 (TID 137). 1053 bytes result sent to driver
2021-12-03 20:04:51,184 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 6.0 in stage 10.0 (TID 137) in 174 ms on localhost (executor driver) (12/22)
2021-12-03 20:04:51,207 [Executor task launch worker for task 145] INFO [org.apache.spark.executor.Executor] - Finished task 14.0 in stage 10.0 (TID 145). 1053 bytes result sent to driver
2021-12-03 20:04:51,207 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 14.0 in stage 10.0 (TID 145) in 73 ms on localhost (executor driver) (13/22)
2021-12-03 20:04:51,212 [Executor task launch worker for task 147] INFO [org.apache.spark.executor.Executor] - Finished task 16.0 in stage 10.0 (TID 147). 1053 bytes result sent to driver
2021-12-03 20:04:51,213 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 16.0 in stage 10.0 (TID 147) in 78 ms on localhost (executor driver) (14/22)
2021-12-03 20:04:51,221 [Executor task launch worker for task 149] INFO [org.apache.spark.executor.Executor] - Finished task 18.0 in stage 10.0 (TID 149). 1053 bytes result sent to driver
2021-12-03 20:04:51,222 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 18.0 in stage 10.0 (TID 149) in 79 ms on localhost (executor driver) (15/22)
2021-12-03 20:04:51,226 [Executor task launch worker for task 143] INFO [org.apache.spark.executor.Executor] - Finished task 12.0 in stage 10.0 (TID 143). 1053 bytes result sent to driver
2021-12-03 20:04:51,226 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 12.0 in stage 10.0 (TID 143) in 105 ms on localhost (executor driver) (16/22)
2021-12-03 20:04:51,230 [Executor task launch worker for task 144] INFO [org.apache.spark.executor.Executor] - Finished task 13.0 in stage 10.0 (TID 144). 1053 bytes result sent to driver
2021-12-03 20:04:51,230 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 13.0 in stage 10.0 (TID 144) in 97 ms on localhost (executor driver) (17/22)
2021-12-03 20:04:51,232 [Executor task launch worker for task 151] INFO [org.apache.spark.executor.Executor] - Finished task 20.0 in stage 10.0 (TID 151). 1053 bytes result sent to driver
2021-12-03 20:04:51,232 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 20.0 in stage 10.0 (TID 151) in 85 ms on localhost (executor driver) (18/22)
2021-12-03 20:04:51,232 [Executor task launch worker for task 148] INFO [org.apache.spark.executor.Executor] - Finished task 17.0 in stage 10.0 (TID 148). 1096 bytes result sent to driver
2021-12-03 20:04:51,232 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 17.0 in stage 10.0 (TID 148) in 91 ms on localhost (executor driver) (19/22)
2021-12-03 20:04:51,234 [Executor task launch worker for task 150] INFO [org.apache.spark.executor.Executor] - Finished task 19.0 in stage 10.0 (TID 150). 1053 bytes result sent to driver
2021-12-03 20:04:51,234 [Executor task launch worker for task 146] INFO [org.apache.spark.executor.Executor] - Finished task 15.0 in stage 10.0 (TID 146). 1053 bytes result sent to driver
2021-12-03 20:04:51,234 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 19.0 in stage 10.0 (TID 150) in 87 ms on localhost (executor driver) (20/22)
2021-12-03 20:04:51,234 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 15.0 in stage 10.0 (TID 146) in 100 ms on localhost (executor driver) (21/22)
2021-12-03 20:04:51,240 [Executor task launch worker for task 152] INFO [org.apache.spark.executor.Executor] - Finished task 21.0 in stage 10.0 (TID 152). 1053 bytes result sent to driver
2021-12-03 20:04:51,240 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 21.0 in stage 10.0 (TID 152) in 75 ms on localhost (executor driver) (22/22)
2021-12-03 20:04:51,240 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 10.0, whose tasks have all completed, from pool 
2021-12-03 20:04:51,240 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 10 (takeSample at PaidPromotionAdjustParameter.scala:76) finished in 0.247 s
2021-12-03 20:04:51,241 [main] INFO [org.apache.spark.scheduler.DAGScheduler] - Job 4 finished: takeSample at PaidPromotionAdjustParameter.scala:76, took 0.249208 s
2021-12-03 20:04:51,247 [main] INFO [org.apache.spark.SparkContext] - Starting job: takeSample at PaidPromotionAdjustParameter.scala:76
2021-12-03 20:04:51,248 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 5 (takeSample at PaidPromotionAdjustParameter.scala:76) with 22 output partitions
2021-12-03 20:04:51,248 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 13 (takeSample at PaidPromotionAdjustParameter.scala:76)
2021-12-03 20:04:51,248 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 12)
2021-12-03 20:04:51,248 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2021-12-03 20:04:51,248 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 13 (MapPartitionsRDD[11] at map at PaidPromotionAdjustParameter.scala:75), which has no missing parents
2021-12-03 20:04:51,250 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_8 stored as values in memory (estimated size 4.3 KB, free 1990.4 MB)
2021-12-03 20:04:51,251 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_8_piece0 stored as bytes in memory (estimated size 2.5 KB, free 1990.4 MB)
2021-12-03 20:04:51,252 [dispatcher-event-loop-9] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_8_piece0 in memory on qb:50070 (size: 2.5 KB, free: 1990.8 MB)
2021-12-03 20:04:51,252 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 8 from broadcast at DAGScheduler.scala:1039
2021-12-03 20:04:51,252 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 22 missing tasks from ResultStage 13 (MapPartitionsRDD[11] at map at PaidPromotionAdjustParameter.scala:75) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14))
2021-12-03 20:04:51,252 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 13.0 with 22 tasks
2021-12-03 20:04:51,252 [dispatcher-event-loop-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 13.0 (TID 153, localhost, executor driver, partition 0, ANY, 7759 bytes)
2021-12-03 20:04:51,253 [dispatcher-event-loop-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 13.0 (TID 154, localhost, executor driver, partition 1, ANY, 7759 bytes)
2021-12-03 20:04:51,253 [dispatcher-event-loop-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 2.0 in stage 13.0 (TID 155, localhost, executor driver, partition 2, ANY, 7759 bytes)
2021-12-03 20:04:51,253 [dispatcher-event-loop-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 3.0 in stage 13.0 (TID 156, localhost, executor driver, partition 3, ANY, 7759 bytes)
2021-12-03 20:04:51,253 [dispatcher-event-loop-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 4.0 in stage 13.0 (TID 157, localhost, executor driver, partition 4, ANY, 7759 bytes)
2021-12-03 20:04:51,253 [dispatcher-event-loop-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 5.0 in stage 13.0 (TID 158, localhost, executor driver, partition 5, ANY, 7759 bytes)
2021-12-03 20:04:51,253 [dispatcher-event-loop-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 6.0 in stage 13.0 (TID 159, localhost, executor driver, partition 6, ANY, 7759 bytes)
2021-12-03 20:04:51,253 [dispatcher-event-loop-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 7.0 in stage 13.0 (TID 160, localhost, executor driver, partition 7, ANY, 7759 bytes)
2021-12-03 20:04:51,253 [dispatcher-event-loop-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 8.0 in stage 13.0 (TID 161, localhost, executor driver, partition 8, ANY, 7759 bytes)
2021-12-03 20:04:51,253 [dispatcher-event-loop-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 9.0 in stage 13.0 (TID 162, localhost, executor driver, partition 9, ANY, 7759 bytes)
2021-12-03 20:04:51,253 [dispatcher-event-loop-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 10.0 in stage 13.0 (TID 163, localhost, executor driver, partition 10, ANY, 7759 bytes)
2021-12-03 20:04:51,253 [dispatcher-event-loop-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 11.0 in stage 13.0 (TID 164, localhost, executor driver, partition 11, ANY, 7759 bytes)
2021-12-03 20:04:51,253 [Executor task launch worker for task 154] INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 13.0 (TID 154)
2021-12-03 20:04:51,253 [Executor task launch worker for task 159] INFO [org.apache.spark.executor.Executor] - Running task 6.0 in stage 13.0 (TID 159)
2021-12-03 20:04:51,253 [Executor task launch worker for task 164] INFO [org.apache.spark.executor.Executor] - Running task 11.0 in stage 13.0 (TID 164)
2021-12-03 20:04:51,253 [Executor task launch worker for task 158] INFO [org.apache.spark.executor.Executor] - Running task 5.0 in stage 13.0 (TID 158)
2021-12-03 20:04:51,253 [Executor task launch worker for task 157] INFO [org.apache.spark.executor.Executor] - Running task 4.0 in stage 13.0 (TID 157)
2021-12-03 20:04:51,253 [Executor task launch worker for task 155] INFO [org.apache.spark.executor.Executor] - Running task 2.0 in stage 13.0 (TID 155)
2021-12-03 20:04:51,253 [Executor task launch worker for task 153] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 13.0 (TID 153)
2021-12-03 20:04:51,253 [Executor task launch worker for task 156] INFO [org.apache.spark.executor.Executor] - Running task 3.0 in stage 13.0 (TID 156)
2021-12-03 20:04:51,253 [Executor task launch worker for task 163] INFO [org.apache.spark.executor.Executor] - Running task 10.0 in stage 13.0 (TID 163)
2021-12-03 20:04:51,253 [Executor task launch worker for task 162] INFO [org.apache.spark.executor.Executor] - Running task 9.0 in stage 13.0 (TID 162)
2021-12-03 20:04:51,253 [Executor task launch worker for task 160] INFO [org.apache.spark.executor.Executor] - Running task 7.0 in stage 13.0 (TID 160)
2021-12-03 20:04:51,253 [Executor task launch worker for task 161] INFO [org.apache.spark.executor.Executor] - Running task 8.0 in stage 13.0 (TID 161)
2021-12-03 20:04:51,256 [Executor task launch worker for task 161] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 20:04:51,256 [Executor task launch worker for task 161] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 20:04:51,256 [Executor task launch worker for task 157] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 20:04:51,256 [Executor task launch worker for task 157] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 20:04:51,256 [Executor task launch worker for task 158] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 20:04:51,256 [Executor task launch worker for task 158] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 20:04:51,257 [Executor task launch worker for task 163] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 20:04:51,257 [Executor task launch worker for task 163] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 1 ms
2021-12-03 20:04:51,257 [Executor task launch worker for task 153] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 20:04:51,257 [Executor task launch worker for task 153] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 20:04:51,257 [Executor task launch worker for task 159] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 20:04:51,257 [Executor task launch worker for task 159] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 20:04:51,257 [Executor task launch worker for task 154] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 20:04:51,257 [Executor task launch worker for task 154] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 20:04:51,258 [Executor task launch worker for task 162] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 20:04:51,258 [Executor task launch worker for task 162] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 20:04:51,258 [Executor task launch worker for task 160] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 20:04:51,258 [Executor task launch worker for task 160] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 20:04:51,258 [Executor task launch worker for task 155] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 20:04:51,258 [Executor task launch worker for task 155] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 20:04:51,259 [Executor task launch worker for task 156] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 20:04:51,259 [Executor task launch worker for task 156] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 20:04:51,259 [Executor task launch worker for task 164] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 20:04:51,259 [Executor task launch worker for task 164] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 20:04:51,338 [dispatcher-event-loop-3] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_7_piece0 on qb:50070 in memory (size: 2.4 KB, free: 1990.8 MB)
2021-12-03 20:04:51,345 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 163
2021-12-03 20:04:51,345 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 153
2021-12-03 20:04:51,345 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 155
2021-12-03 20:04:51,345 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 159
2021-12-03 20:04:51,345 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 172
2021-12-03 20:04:51,345 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 151
2021-12-03 20:04:51,345 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 162
2021-12-03 20:04:51,345 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 156
2021-12-03 20:04:51,346 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 154
2021-12-03 20:04:51,346 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 158
2021-12-03 20:04:51,346 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 168
2021-12-03 20:04:51,346 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 174
2021-12-03 20:04:51,346 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 166
2021-12-03 20:04:51,346 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 157
2021-12-03 20:04:51,346 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 160
2021-12-03 20:04:51,346 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 169
2021-12-03 20:04:51,346 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 171
2021-12-03 20:04:51,346 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 165
2021-12-03 20:04:51,346 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 152
2021-12-03 20:04:51,346 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 167
2021-12-03 20:04:51,346 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 164
2021-12-03 20:04:51,346 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 150
2021-12-03 20:04:51,346 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 161
2021-12-03 20:04:51,346 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 170
2021-12-03 20:04:51,346 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 173
2021-12-03 20:04:51,366 [Executor task launch worker for task 162] INFO [org.apache.spark.executor.Executor] - Finished task 9.0 in stage 13.0 (TID 162). 1097 bytes result sent to driver
2021-12-03 20:04:51,366 [dispatcher-event-loop-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 12.0 in stage 13.0 (TID 165, localhost, executor driver, partition 12, ANY, 7759 bytes)
2021-12-03 20:04:51,367 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 9.0 in stage 13.0 (TID 162) in 113 ms on localhost (executor driver) (1/22)
2021-12-03 20:04:51,367 [Executor task launch worker for task 165] INFO [org.apache.spark.executor.Executor] - Running task 12.0 in stage 13.0 (TID 165)
2021-12-03 20:04:51,367 [Executor task launch worker for task 158] INFO [org.apache.spark.executor.Executor] - Finished task 5.0 in stage 13.0 (TID 158). 1097 bytes result sent to driver
2021-12-03 20:04:51,369 [dispatcher-event-loop-4] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 13.0 in stage 13.0 (TID 166, localhost, executor driver, partition 13, ANY, 7759 bytes)
2021-12-03 20:04:51,369 [Executor task launch worker for task 166] INFO [org.apache.spark.executor.Executor] - Running task 13.0 in stage 13.0 (TID 166)
2021-12-03 20:04:51,370 [Executor task launch worker for task 165] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 20:04:51,370 [Executor task launch worker for task 165] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 20:04:51,371 [Executor task launch worker for task 161] INFO [org.apache.spark.executor.Executor] - Finished task 8.0 in stage 13.0 (TID 161). 1097 bytes result sent to driver
2021-12-03 20:04:51,372 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 5.0 in stage 13.0 (TID 158) in 119 ms on localhost (executor driver) (2/22)
2021-12-03 20:04:51,372 [Executor task launch worker for task 166] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 20:04:51,372 [Executor task launch worker for task 166] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 20:04:51,373 [dispatcher-event-loop-10] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 14.0 in stage 13.0 (TID 167, localhost, executor driver, partition 14, ANY, 7759 bytes)
2021-12-03 20:04:51,373 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 8.0 in stage 13.0 (TID 161) in 120 ms on localhost (executor driver) (3/22)
2021-12-03 20:04:51,373 [Executor task launch worker for task 167] INFO [org.apache.spark.executor.Executor] - Running task 14.0 in stage 13.0 (TID 167)
2021-12-03 20:04:51,375 [Executor task launch worker for task 159] INFO [org.apache.spark.executor.Executor] - Finished task 6.0 in stage 13.0 (TID 159). 1097 bytes result sent to driver
2021-12-03 20:04:51,375 [Executor task launch worker for task 156] INFO [org.apache.spark.executor.Executor] - Finished task 3.0 in stage 13.0 (TID 156). 1097 bytes result sent to driver
2021-12-03 20:04:51,375 [dispatcher-event-loop-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 15.0 in stage 13.0 (TID 168, localhost, executor driver, partition 15, ANY, 7759 bytes)
2021-12-03 20:04:51,376 [Executor task launch worker for task 168] INFO [org.apache.spark.executor.Executor] - Running task 15.0 in stage 13.0 (TID 168)
2021-12-03 20:04:51,376 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 6.0 in stage 13.0 (TID 159) in 123 ms on localhost (executor driver) (4/22)
2021-12-03 20:04:51,376 [Executor task launch worker for task 167] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 20:04:51,376 [Executor task launch worker for task 167] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 20:04:51,376 [dispatcher-event-loop-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 16.0 in stage 13.0 (TID 169, localhost, executor driver, partition 16, ANY, 7759 bytes)
2021-12-03 20:04:51,376 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 3.0 in stage 13.0 (TID 156) in 123 ms on localhost (executor driver) (5/22)
2021-12-03 20:04:51,376 [Executor task launch worker for task 169] INFO [org.apache.spark.executor.Executor] - Running task 16.0 in stage 13.0 (TID 169)
2021-12-03 20:04:51,376 [Executor task launch worker for task 163] INFO [org.apache.spark.executor.Executor] - Finished task 10.0 in stage 13.0 (TID 163). 1097 bytes result sent to driver
2021-12-03 20:04:51,377 [dispatcher-event-loop-8] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 17.0 in stage 13.0 (TID 170, localhost, executor driver, partition 17, ANY, 7759 bytes)
2021-12-03 20:04:51,377 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 10.0 in stage 13.0 (TID 163) in 124 ms on localhost (executor driver) (6/22)
2021-12-03 20:04:51,377 [Executor task launch worker for task 170] INFO [org.apache.spark.executor.Executor] - Running task 17.0 in stage 13.0 (TID 170)
2021-12-03 20:04:51,378 [Executor task launch worker for task 168] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 20:04:51,378 [Executor task launch worker for task 168] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 20:04:51,379 [Executor task launch worker for task 169] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 20:04:51,379 [Executor task launch worker for task 169] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 20:04:51,379 [Executor task launch worker for task 153] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 13.0 (TID 153). 1097 bytes result sent to driver
2021-12-03 20:04:51,379 [dispatcher-event-loop-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 18.0 in stage 13.0 (TID 171, localhost, executor driver, partition 18, ANY, 7759 bytes)
2021-12-03 20:04:51,380 [Executor task launch worker for task 171] INFO [org.apache.spark.executor.Executor] - Running task 18.0 in stage 13.0 (TID 171)
2021-12-03 20:04:51,380 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 13.0 (TID 153) in 128 ms on localhost (executor driver) (7/22)
2021-12-03 20:04:51,380 [Executor task launch worker for task 170] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 20:04:51,380 [Executor task launch worker for task 170] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 20:04:51,382 [Executor task launch worker for task 171] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 20:04:51,383 [Executor task launch worker for task 171] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 1 ms
2021-12-03 20:04:51,383 [Executor task launch worker for task 157] INFO [org.apache.spark.executor.Executor] - Finished task 4.0 in stage 13.0 (TID 157). 1097 bytes result sent to driver
2021-12-03 20:04:51,383 [dispatcher-event-loop-4] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 19.0 in stage 13.0 (TID 172, localhost, executor driver, partition 19, ANY, 7759 bytes)
2021-12-03 20:04:51,383 [Executor task launch worker for task 172] INFO [org.apache.spark.executor.Executor] - Running task 19.0 in stage 13.0 (TID 172)
2021-12-03 20:04:51,383 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 4.0 in stage 13.0 (TID 157) in 130 ms on localhost (executor driver) (8/22)
2021-12-03 20:04:51,386 [Executor task launch worker for task 172] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 20:04:51,386 [Executor task launch worker for task 172] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 20:04:51,394 [Executor task launch worker for task 164] INFO [org.apache.spark.executor.Executor] - Finished task 11.0 in stage 13.0 (TID 164). 1097 bytes result sent to driver
2021-12-03 20:04:51,395 [dispatcher-event-loop-10] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 20.0 in stage 13.0 (TID 173, localhost, executor driver, partition 20, ANY, 7759 bytes)
2021-12-03 20:04:51,395 [Executor task launch worker for task 173] INFO [org.apache.spark.executor.Executor] - Running task 20.0 in stage 13.0 (TID 173)
2021-12-03 20:04:51,395 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 11.0 in stage 13.0 (TID 164) in 142 ms on localhost (executor driver) (9/22)
2021-12-03 20:04:51,398 [Executor task launch worker for task 173] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 20:04:51,398 [Executor task launch worker for task 173] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 20:04:51,403 [Executor task launch worker for task 154] INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 13.0 (TID 154). 1097 bytes result sent to driver
2021-12-03 20:04:51,403 [dispatcher-event-loop-9] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 21.0 in stage 13.0 (TID 174, localhost, executor driver, partition 21, ANY, 7759 bytes)
2021-12-03 20:04:51,403 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 13.0 (TID 154) in 151 ms on localhost (executor driver) (10/22)
2021-12-03 20:04:51,403 [Executor task launch worker for task 174] INFO [org.apache.spark.executor.Executor] - Running task 21.0 in stage 13.0 (TID 174)
2021-12-03 20:04:51,406 [Executor task launch worker for task 174] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 20:04:51,406 [Executor task launch worker for task 174] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 20:04:51,409 [Executor task launch worker for task 160] INFO [org.apache.spark.executor.Executor] - Finished task 7.0 in stage 13.0 (TID 160). 1097 bytes result sent to driver
2021-12-03 20:04:51,409 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 7.0 in stage 13.0 (TID 160) in 156 ms on localhost (executor driver) (11/22)
2021-12-03 20:04:51,419 [Executor task launch worker for task 155] INFO [org.apache.spark.executor.Executor] - Finished task 2.0 in stage 13.0 (TID 155). 1130 bytes result sent to driver
2021-12-03 20:04:51,419 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 2.0 in stage 13.0 (TID 155) in 166 ms on localhost (executor driver) (12/22)
2021-12-03 20:04:51,441 [Executor task launch worker for task 167] INFO [org.apache.spark.executor.Executor] - Finished task 14.0 in stage 13.0 (TID 167). 1054 bytes result sent to driver
2021-12-03 20:04:51,441 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 14.0 in stage 13.0 (TID 167) in 68 ms on localhost (executor driver) (13/22)
2021-12-03 20:04:51,448 [Executor task launch worker for task 169] INFO [org.apache.spark.executor.Executor] - Finished task 16.0 in stage 13.0 (TID 169). 1054 bytes result sent to driver
2021-12-03 20:04:51,449 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 16.0 in stage 13.0 (TID 169) in 73 ms on localhost (executor driver) (14/22)
2021-12-03 20:04:51,462 [Executor task launch worker for task 171] INFO [org.apache.spark.executor.Executor] - Finished task 18.0 in stage 13.0 (TID 171). 1054 bytes result sent to driver
2021-12-03 20:04:51,462 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 18.0 in stage 13.0 (TID 171) in 83 ms on localhost (executor driver) (15/22)
2021-12-03 20:04:51,462 [Executor task launch worker for task 168] INFO [org.apache.spark.executor.Executor] - Finished task 15.0 in stage 13.0 (TID 168). 1097 bytes result sent to driver
2021-12-03 20:04:51,463 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 15.0 in stage 13.0 (TID 168) in 88 ms on localhost (executor driver) (16/22)
2021-12-03 20:04:51,465 [Executor task launch worker for task 165] INFO [org.apache.spark.executor.Executor] - Finished task 12.0 in stage 13.0 (TID 165). 1054 bytes result sent to driver
2021-12-03 20:04:51,465 [Executor task launch worker for task 166] INFO [org.apache.spark.executor.Executor] - Finished task 13.0 in stage 13.0 (TID 166). 1054 bytes result sent to driver
2021-12-03 20:04:51,466 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 12.0 in stage 13.0 (TID 165) in 100 ms on localhost (executor driver) (17/22)
2021-12-03 20:04:51,466 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 13.0 in stage 13.0 (TID 166) in 97 ms on localhost (executor driver) (18/22)
2021-12-03 20:04:51,467 [Executor task launch worker for task 172] INFO [org.apache.spark.executor.Executor] - Finished task 19.0 in stage 13.0 (TID 172). 1054 bytes result sent to driver
2021-12-03 20:04:51,467 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 19.0 in stage 13.0 (TID 172) in 84 ms on localhost (executor driver) (19/22)
2021-12-03 20:04:51,470 [Executor task launch worker for task 170] INFO [org.apache.spark.executor.Executor] - Finished task 17.0 in stage 13.0 (TID 170). 1054 bytes result sent to driver
2021-12-03 20:04:51,470 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 17.0 in stage 13.0 (TID 170) in 94 ms on localhost (executor driver) (20/22)
2021-12-03 20:04:51,472 [Executor task launch worker for task 173] INFO [org.apache.spark.executor.Executor] - Finished task 20.0 in stage 13.0 (TID 173). 1054 bytes result sent to driver
2021-12-03 20:04:51,472 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 20.0 in stage 13.0 (TID 173) in 77 ms on localhost (executor driver) (21/22)
2021-12-03 20:04:51,480 [Executor task launch worker for task 174] INFO [org.apache.spark.executor.Executor] - Finished task 21.0 in stage 13.0 (TID 174). 1054 bytes result sent to driver
2021-12-03 20:04:51,481 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 21.0 in stage 13.0 (TID 174) in 78 ms on localhost (executor driver) (22/22)
2021-12-03 20:04:51,481 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 13.0, whose tasks have all completed, from pool 
2021-12-03 20:04:51,481 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 13 (takeSample at PaidPromotionAdjustParameter.scala:76) finished in 0.232 s
2021-12-03 20:04:51,481 [main] INFO [org.apache.spark.scheduler.DAGScheduler] - Job 5 finished: takeSample at PaidPromotionAdjustParameter.scala:76, took 0.234047 s
2021-12-03 20:04:51,486 [main] INFO [org.apache.spark.SparkContext] - Starting job: count at PaidPromotionAdjustParameter.scala:80
2021-12-03 20:04:51,487 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 6 (count at PaidPromotionAdjustParameter.scala:80) with 22 output partitions
2021-12-03 20:04:51,487 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 14 (count at PaidPromotionAdjustParameter.scala:80)
2021-12-03 20:04:51,487 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List()
2021-12-03 20:04:51,487 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2021-12-03 20:04:51,487 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 14 (MapPartitionsRDD[13] at map at PaidPromotionAdjustParameter.scala:79), which has no missing parents
2021-12-03 20:04:51,488 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_9 stored as values in memory (estimated size 3.7 KB, free 1990.4 MB)
2021-12-03 20:04:51,490 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_9_piece0 stored as bytes in memory (estimated size 2.2 KB, free 1990.4 MB)
2021-12-03 20:04:51,490 [dispatcher-event-loop-1] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_9_piece0 in memory on qb:50070 (size: 2.2 KB, free: 1990.8 MB)
2021-12-03 20:04:51,491 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 9 from broadcast at DAGScheduler.scala:1039
2021-12-03 20:04:51,491 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 22 missing tasks from ResultStage 14 (MapPartitionsRDD[13] at map at PaidPromotionAdjustParameter.scala:79) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14))
2021-12-03 20:04:51,491 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 14.0 with 22 tasks
2021-12-03 20:04:51,491 [dispatcher-event-loop-5] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 14.0 (TID 175, localhost, executor driver, partition 0, ANY, 7899 bytes)
2021-12-03 20:04:51,491 [dispatcher-event-loop-5] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 14.0 (TID 176, localhost, executor driver, partition 1, ANY, 7899 bytes)
2021-12-03 20:04:51,492 [dispatcher-event-loop-5] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 2.0 in stage 14.0 (TID 177, localhost, executor driver, partition 2, ANY, 7899 bytes)
2021-12-03 20:04:51,492 [dispatcher-event-loop-5] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 3.0 in stage 14.0 (TID 178, localhost, executor driver, partition 3, ANY, 7899 bytes)
2021-12-03 20:04:51,492 [dispatcher-event-loop-5] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 4.0 in stage 14.0 (TID 179, localhost, executor driver, partition 4, ANY, 7899 bytes)
2021-12-03 20:04:51,492 [dispatcher-event-loop-5] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 5.0 in stage 14.0 (TID 180, localhost, executor driver, partition 5, ANY, 7899 bytes)
2021-12-03 20:04:51,492 [dispatcher-event-loop-5] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 6.0 in stage 14.0 (TID 181, localhost, executor driver, partition 6, ANY, 7899 bytes)
2021-12-03 20:04:51,492 [dispatcher-event-loop-5] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 7.0 in stage 14.0 (TID 182, localhost, executor driver, partition 7, ANY, 7899 bytes)
2021-12-03 20:04:51,492 [dispatcher-event-loop-5] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 8.0 in stage 14.0 (TID 183, localhost, executor driver, partition 8, ANY, 7899 bytes)
2021-12-03 20:04:51,492 [dispatcher-event-loop-5] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 9.0 in stage 14.0 (TID 184, localhost, executor driver, partition 9, ANY, 7899 bytes)
2021-12-03 20:04:51,492 [dispatcher-event-loop-5] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 10.0 in stage 14.0 (TID 185, localhost, executor driver, partition 10, ANY, 7899 bytes)
2021-12-03 20:04:51,492 [dispatcher-event-loop-5] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 11.0 in stage 14.0 (TID 186, localhost, executor driver, partition 11, ANY, 7899 bytes)
2021-12-03 20:04:51,492 [Executor task launch worker for task 176] INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 14.0 (TID 176)
2021-12-03 20:04:51,492 [Executor task launch worker for task 175] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 14.0 (TID 175)
2021-12-03 20:04:51,492 [Executor task launch worker for task 182] INFO [org.apache.spark.executor.Executor] - Running task 7.0 in stage 14.0 (TID 182)
2021-12-03 20:04:51,492 [Executor task launch worker for task 181] INFO [org.apache.spark.executor.Executor] - Running task 6.0 in stage 14.0 (TID 181)
2021-12-03 20:04:51,492 [Executor task launch worker for task 180] INFO [org.apache.spark.executor.Executor] - Running task 5.0 in stage 14.0 (TID 180)
2021-12-03 20:04:51,492 [Executor task launch worker for task 179] INFO [org.apache.spark.executor.Executor] - Running task 4.0 in stage 14.0 (TID 179)
2021-12-03 20:04:51,492 [Executor task launch worker for task 178] INFO [org.apache.spark.executor.Executor] - Running task 3.0 in stage 14.0 (TID 178)
2021-12-03 20:04:51,492 [Executor task launch worker for task 177] INFO [org.apache.spark.executor.Executor] - Running task 2.0 in stage 14.0 (TID 177)
2021-12-03 20:04:51,492 [Executor task launch worker for task 184] INFO [org.apache.spark.executor.Executor] - Running task 9.0 in stage 14.0 (TID 184)
2021-12-03 20:04:51,492 [Executor task launch worker for task 185] INFO [org.apache.spark.executor.Executor] - Running task 10.0 in stage 14.0 (TID 185)
2021-12-03 20:04:51,492 [Executor task launch worker for task 186] INFO [org.apache.spark.executor.Executor] - Running task 11.0 in stage 14.0 (TID 186)
2021-12-03 20:04:51,492 [Executor task launch worker for task 183] INFO [org.apache.spark.executor.Executor] - Running task 8.0 in stage 14.0 (TID 183)
2021-12-03 20:04:51,493 [Executor task launch worker for task 184] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:1207959552+134217728
2021-12-03 20:04:51,493 [Executor task launch worker for task 183] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:1073741824+134217728
2021-12-03 20:04:51,493 [Executor task launch worker for task 177] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:268435456+134217728
2021-12-03 20:04:51,493 [Executor task launch worker for task 186] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:1476395008+134217728
2021-12-03 20:04:51,493 [Executor task launch worker for task 185] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:1342177280+134217728
2021-12-03 20:04:51,493 [Executor task launch worker for task 176] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:134217728+134217728
2021-12-03 20:04:51,493 [Executor task launch worker for task 182] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:939524096+134217728
2021-12-03 20:04:51,493 [Executor task launch worker for task 175] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:0+134217728
2021-12-03 20:04:51,493 [Executor task launch worker for task 178] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:402653184+134217728
2021-12-03 20:04:51,493 [Executor task launch worker for task 181] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:805306368+134217728
2021-12-03 20:04:51,493 [Executor task launch worker for task 180] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:671088640+134217728
2021-12-03 20:04:51,493 [Executor task launch worker for task 179] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:536870912+134217728
2021-12-03 20:04:53,214 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 176
2021-12-03 20:04:53,214 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 178
2021-12-03 20:04:53,214 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 180
2021-12-03 20:04:53,214 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 192
2021-12-03 20:04:53,214 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 184
2021-12-03 20:04:53,214 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 197
2021-12-03 20:04:53,214 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 186
2021-12-03 20:04:53,214 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 191
2021-12-03 20:04:53,214 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 194
2021-12-03 20:04:53,214 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 188
2021-12-03 20:04:53,214 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 193
2021-12-03 20:04:53,215 [dispatcher-event-loop-2] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_8_piece0 on qb:50070 in memory (size: 2.5 KB, free: 1990.8 MB)
2021-12-03 20:04:53,215 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 189
2021-12-03 20:04:53,216 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 177
2021-12-03 20:04:53,216 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 182
2021-12-03 20:04:53,216 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 195
2021-12-03 20:04:53,216 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 185
2021-12-03 20:04:53,216 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 199
2021-12-03 20:04:53,216 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 187
2021-12-03 20:04:53,216 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 183
2021-12-03 20:04:53,216 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 196
2021-12-03 20:04:53,216 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 179
2021-12-03 20:04:53,216 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 181
2021-12-03 20:04:53,216 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 175
2021-12-03 20:04:53,216 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 190
2021-12-03 20:04:53,216 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 198
2021-12-03 20:06:35,874 [Executor task launch worker for task 186] INFO [org.apache.spark.executor.Executor] - Finished task 11.0 in stage 14.0 (TID 186). 752 bytes result sent to driver
2021-12-03 20:06:35,875 [dispatcher-event-loop-8] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 12.0 in stage 14.0 (TID 187, localhost, executor driver, partition 12, ANY, 7899 bytes)
2021-12-03 20:06:35,875 [Executor task launch worker for task 187] INFO [org.apache.spark.executor.Executor] - Running task 12.0 in stage 14.0 (TID 187)
2021-12-03 20:06:35,875 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 11.0 in stage 14.0 (TID 186) in 104383 ms on localhost (executor driver) (1/22)
2021-12-03 20:06:35,875 [Executor task launch worker for task 187] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:1610612736+134217728
2021-12-03 20:06:41,172 [Executor task launch worker for task 181] INFO [org.apache.spark.executor.Executor] - Finished task 6.0 in stage 14.0 (TID 181). 752 bytes result sent to driver
2021-12-03 20:06:41,172 [dispatcher-event-loop-4] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 13.0 in stage 14.0 (TID 188, localhost, executor driver, partition 13, ANY, 7899 bytes)
2021-12-03 20:06:41,172 [Executor task launch worker for task 188] INFO [org.apache.spark.executor.Executor] - Running task 13.0 in stage 14.0 (TID 188)
2021-12-03 20:06:41,172 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 6.0 in stage 14.0 (TID 181) in 109680 ms on localhost (executor driver) (2/22)
2021-12-03 20:06:41,173 [Executor task launch worker for task 188] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:1744830464+134217728
2021-12-03 20:06:54,318 [Executor task launch worker for task 185] INFO [org.apache.spark.executor.Executor] - Finished task 10.0 in stage 14.0 (TID 185). 752 bytes result sent to driver
2021-12-03 20:06:54,319 [dispatcher-event-loop-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 14.0 in stage 14.0 (TID 189, localhost, executor driver, partition 14, ANY, 7899 bytes)
2021-12-03 20:06:54,319 [Executor task launch worker for task 189] INFO [org.apache.spark.executor.Executor] - Running task 14.0 in stage 14.0 (TID 189)
2021-12-03 20:06:54,319 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 10.0 in stage 14.0 (TID 185) in 122827 ms on localhost (executor driver) (3/22)
2021-12-03 20:06:54,319 [Executor task launch worker for task 189] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:1879048192+134217728
2021-12-03 20:07:00,780 [Executor task launch worker for task 178] INFO [org.apache.spark.executor.Executor] - Finished task 3.0 in stage 14.0 (TID 178). 752 bytes result sent to driver
2021-12-03 20:07:00,780 [dispatcher-event-loop-8] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 15.0 in stage 14.0 (TID 190, localhost, executor driver, partition 15, ANY, 7899 bytes)
2021-12-03 20:07:00,780 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 3.0 in stage 14.0 (TID 178) in 129288 ms on localhost (executor driver) (4/22)
2021-12-03 20:07:00,780 [Executor task launch worker for task 190] INFO [org.apache.spark.executor.Executor] - Running task 15.0 in stage 14.0 (TID 190)
2021-12-03 20:07:00,781 [Executor task launch worker for task 190] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:2013265920+134217728
2021-12-03 20:07:01,997 [Executor task launch worker for task 183] INFO [org.apache.spark.executor.Executor] - Finished task 8.0 in stage 14.0 (TID 183). 752 bytes result sent to driver
2021-12-03 20:07:01,998 [dispatcher-event-loop-11] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 16.0 in stage 14.0 (TID 191, localhost, executor driver, partition 16, ANY, 7899 bytes)
2021-12-03 20:07:01,998 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 8.0 in stage 14.0 (TID 183) in 130506 ms on localhost (executor driver) (5/22)
2021-12-03 20:07:01,998 [Executor task launch worker for task 191] INFO [org.apache.spark.executor.Executor] - Running task 16.0 in stage 14.0 (TID 191)
2021-12-03 20:07:01,998 [Executor task launch worker for task 191] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:2147483648+134217728
2021-12-03 20:07:02,113 [Executor task launch worker for task 179] INFO [org.apache.spark.executor.Executor] - Finished task 4.0 in stage 14.0 (TID 179). 752 bytes result sent to driver
2021-12-03 20:07:02,114 [dispatcher-event-loop-4] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 17.0 in stage 14.0 (TID 192, localhost, executor driver, partition 17, ANY, 7899 bytes)
2021-12-03 20:07:02,114 [Executor task launch worker for task 192] INFO [org.apache.spark.executor.Executor] - Running task 17.0 in stage 14.0 (TID 192)
2021-12-03 20:07:02,114 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 4.0 in stage 14.0 (TID 179) in 130622 ms on localhost (executor driver) (6/22)
2021-12-03 20:07:02,114 [Executor task launch worker for task 192] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:2281701376+134217728
2021-12-03 20:07:23,989 [Executor task launch worker for task 176] INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 14.0 (TID 176). 795 bytes result sent to driver
2021-12-03 20:07:23,989 [dispatcher-event-loop-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 18.0 in stage 14.0 (TID 193, localhost, executor driver, partition 18, ANY, 7899 bytes)
2021-12-03 20:07:23,989 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 14.0 (TID 176) in 152498 ms on localhost (executor driver) (7/22)
2021-12-03 20:07:23,989 [Executor task launch worker for task 193] INFO [org.apache.spark.executor.Executor] - Running task 18.0 in stage 14.0 (TID 193)
2021-12-03 20:07:23,990 [Executor task launch worker for task 193] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:2415919104+134217728
2021-12-03 20:07:39,243 [Executor task launch worker for task 180] INFO [org.apache.spark.executor.Executor] - Finished task 5.0 in stage 14.0 (TID 180). 752 bytes result sent to driver
2021-12-03 20:07:39,243 [dispatcher-event-loop-10] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 19.0 in stage 14.0 (TID 194, localhost, executor driver, partition 19, ANY, 7899 bytes)
2021-12-03 20:07:39,244 [Executor task launch worker for task 194] INFO [org.apache.spark.executor.Executor] - Running task 19.0 in stage 14.0 (TID 194)
2021-12-03 20:07:39,244 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 5.0 in stage 14.0 (TID 180) in 167752 ms on localhost (executor driver) (8/22)
2021-12-03 20:07:39,244 [Executor task launch worker for task 194] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:2550136832+134217728
2021-12-03 20:07:45,690 [Executor task launch worker for task 182] INFO [org.apache.spark.executor.Executor] - Finished task 7.0 in stage 14.0 (TID 182). 752 bytes result sent to driver
2021-12-03 20:07:45,691 [dispatcher-event-loop-7] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 20.0 in stage 14.0 (TID 195, localhost, executor driver, partition 20, ANY, 7899 bytes)
2021-12-03 20:07:45,691 [Executor task launch worker for task 195] INFO [org.apache.spark.executor.Executor] - Running task 20.0 in stage 14.0 (TID 195)
2021-12-03 20:07:45,691 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 7.0 in stage 14.0 (TID 182) in 174199 ms on localhost (executor driver) (9/22)
2021-12-03 20:07:45,691 [Executor task launch worker for task 195] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:2684354560+134217728
2021-12-03 20:07:55,269 [Executor task launch worker for task 184] INFO [org.apache.spark.executor.Executor] - Finished task 9.0 in stage 14.0 (TID 184). 752 bytes result sent to driver
2021-12-03 20:07:55,270 [dispatcher-event-loop-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 21.0 in stage 14.0 (TID 196, localhost, executor driver, partition 21, ANY, 7899 bytes)
2021-12-03 20:07:55,270 [Executor task launch worker for task 196] INFO [org.apache.spark.executor.Executor] - Running task 21.0 in stage 14.0 (TID 196)
2021-12-03 20:07:55,270 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 9.0 in stage 14.0 (TID 184) in 183778 ms on localhost (executor driver) (10/22)
2021-12-03 20:07:55,270 [Executor task launch worker for task 196] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:2818572288+147216171
2021-12-03 20:07:58,570 [Executor task launch worker for task 177] INFO [org.apache.spark.executor.Executor] - Finished task 2.0 in stage 14.0 (TID 177). 752 bytes result sent to driver
2021-12-03 20:07:58,570 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 2.0 in stage 14.0 (TID 177) in 187079 ms on localhost (executor driver) (11/22)
2021-12-03 20:08:02,067 [Executor task launch worker for task 187] INFO [org.apache.spark.executor.Executor] - Finished task 12.0 in stage 14.0 (TID 187). 753 bytes result sent to driver
2021-12-03 20:08:02,067 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 12.0 in stage 14.0 (TID 187) in 86193 ms on localhost (executor driver) (12/22)
2021-12-03 20:08:03,805 [Executor task launch worker for task 175] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 14.0 (TID 175). 752 bytes result sent to driver
2021-12-03 20:08:03,805 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 14.0 (TID 175) in 192314 ms on localhost (executor driver) (13/22)
2021-12-03 20:08:37,164 [Executor task launch worker for task 188] INFO [org.apache.spark.executor.Executor] - Finished task 13.0 in stage 14.0 (TID 188). 709 bytes result sent to driver
2021-12-03 20:08:37,165 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 13.0 in stage 14.0 (TID 188) in 115993 ms on localhost (executor driver) (14/22)
2021-12-03 20:08:49,406 [Executor task launch worker for task 192] INFO [org.apache.spark.executor.Executor] - Finished task 17.0 in stage 14.0 (TID 192). 709 bytes result sent to driver
2021-12-03 20:08:49,406 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 17.0 in stage 14.0 (TID 192) in 107292 ms on localhost (executor driver) (15/22)
2021-12-03 20:08:49,751 [Executor task launch worker for task 193] INFO [org.apache.spark.executor.Executor] - Finished task 18.0 in stage 14.0 (TID 193). 709 bytes result sent to driver
2021-12-03 20:08:49,751 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 18.0 in stage 14.0 (TID 193) in 85762 ms on localhost (executor driver) (16/22)
2021-12-03 20:08:54,543 [Executor task launch worker for task 191] INFO [org.apache.spark.executor.Executor] - Finished task 16.0 in stage 14.0 (TID 191). 709 bytes result sent to driver
2021-12-03 20:08:54,544 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 16.0 in stage 14.0 (TID 191) in 112546 ms on localhost (executor driver) (17/22)
2021-12-03 20:08:58,043 [Executor task launch worker for task 194] INFO [org.apache.spark.executor.Executor] - Finished task 19.0 in stage 14.0 (TID 194). 709 bytes result sent to driver
2021-12-03 20:08:58,043 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 19.0 in stage 14.0 (TID 194) in 78800 ms on localhost (executor driver) (18/22)
2021-12-03 20:09:00,482 [Executor task launch worker for task 189] INFO [org.apache.spark.executor.Executor] - Finished task 14.0 in stage 14.0 (TID 189). 709 bytes result sent to driver
2021-12-03 20:09:00,482 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 14.0 in stage 14.0 (TID 189) in 126163 ms on localhost (executor driver) (19/22)
2021-12-03 20:09:04,475 [Executor task launch worker for task 190] INFO [org.apache.spark.executor.Executor] - Finished task 15.0 in stage 14.0 (TID 190). 709 bytes result sent to driver
2021-12-03 20:09:04,475 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 15.0 in stage 14.0 (TID 190) in 123695 ms on localhost (executor driver) (20/22)
2021-12-03 20:09:10,642 [Executor task launch worker for task 196] INFO [org.apache.spark.executor.Executor] - Finished task 21.0 in stage 14.0 (TID 196). 709 bytes result sent to driver
2021-12-03 20:09:10,643 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 21.0 in stage 14.0 (TID 196) in 75373 ms on localhost (executor driver) (21/22)
2021-12-03 20:09:10,667 [Executor task launch worker for task 195] INFO [org.apache.spark.executor.Executor] - Finished task 20.0 in stage 14.0 (TID 195). 709 bytes result sent to driver
2021-12-03 20:09:10,667 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 20.0 in stage 14.0 (TID 195) in 84976 ms on localhost (executor driver) (22/22)
2021-12-03 20:09:10,667 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 14.0, whose tasks have all completed, from pool 
2021-12-03 20:09:10,667 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 14 (count at PaidPromotionAdjustParameter.scala:80) finished in 259.179 s
2021-12-03 20:09:10,667 [main] INFO [org.apache.spark.scheduler.DAGScheduler] - Job 6 finished: count at PaidPromotionAdjustParameter.scala:80, took 259.180635 s
2021-12-03 20:09:10,668 [main] INFO [PaidPromotion$] - 抽样总数：127
2021-12-03 20:09:10,684 [main] INFO [org.apache.hadoop.conf.Configuration.deprecation] - mapred.output.dir is deprecated. Instead, use mapreduce.output.fileoutputformat.outputdir
2021-12-03 20:09:10,686 [main] INFO [org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter] - File Output Committer Algorithm version is 1
2021-12-03 20:09:10,877 [main] INFO [org.apache.spark.SparkContext] - Starting job: runJob at SparkHadoopWriter.scala:78
2021-12-03 20:09:10,878 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 7 (runJob at SparkHadoopWriter.scala:78) with 1 output partitions
2021-12-03 20:09:10,878 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 15 (runJob at SparkHadoopWriter.scala:78)
2021-12-03 20:09:10,878 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List()
2021-12-03 20:09:10,878 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2021-12-03 20:09:10,878 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 15 (MapPartitionsRDD[15] at saveAsTextFile at PaidPromotionAdjustParameter.scala:82), which has no missing parents
2021-12-03 20:09:10,889 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_10 stored as values in memory (estimated size 80.2 KB, free 1990.4 MB)
2021-12-03 20:09:10,890 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_10_piece0 stored as bytes in memory (estimated size 30.6 KB, free 1990.3 MB)
2021-12-03 20:09:10,891 [dispatcher-event-loop-9] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_10_piece0 in memory on qb:50070 (size: 30.6 KB, free: 1990.7 MB)
2021-12-03 20:09:10,891 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 10 from broadcast at DAGScheduler.scala:1039
2021-12-03 20:09:10,891 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 15 (MapPartitionsRDD[15] at saveAsTextFile at PaidPromotionAdjustParameter.scala:82) (first 15 tasks are for partitions Vector(0))
2021-12-03 20:09:10,891 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 15.0 with 1 tasks
2021-12-03 20:09:10,898 [dispatcher-event-loop-7] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 15.0 (TID 197, localhost, executor driver, partition 0, ANY, 11703 bytes)
2021-12-03 20:09:10,898 [Executor task launch worker for task 197] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 15.0 (TID 197)
2021-12-03 20:09:10,915 [Executor task launch worker for task 197] INFO [org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter] - File Output Committer Algorithm version is 1
2021-12-03 20:09:11,046 [Executor task launch worker for task 197] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:0+134217728
2021-12-03 20:09:22,909 [Executor task launch worker for task 197] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:134217728+134217728
2021-12-03 20:10:09,348 [Executor task launch worker for task 197] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:268435456+134217728
2021-12-03 20:10:21,238 [Executor task launch worker for task 197] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:402653184+134217728
2021-12-03 20:10:33,099 [Executor task launch worker for task 197] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:536870912+134217728
2021-12-03 20:10:44,753 [Executor task launch worker for task 197] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:671088640+134217728
2021-12-03 20:10:58,096 [Executor task launch worker for task 197] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:805306368+134217728
2021-12-03 20:11:41,863 [Executor task launch worker for task 197] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:939524096+134217728
2021-12-03 20:12:13,160 [Executor task launch worker for task 197] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:1073741824+134217728
2021-12-03 20:12:26,629 [Executor task launch worker for task 197] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:1207959552+134217728
2021-12-03 20:13:13,521 [Executor task launch worker for task 197] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:1342177280+134217728
2021-12-03 20:13:25,576 [Executor task launch worker for task 197] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:1476395008+134217728
2021-12-03 20:13:45,497 [Executor task launch worker for task 197] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:1610612736+134217728
2021-12-03 20:14:20,126 [Executor task launch worker for task 197] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:1744830464+134217728
2021-12-03 20:14:52,842 [Executor task launch worker for task 197] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:1879048192+134217728
2021-12-03 20:15:28,339 [Executor task launch worker for task 197] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:2013265920+134217728
2021-12-03 20:15:39,988 [Executor task launch worker for task 197] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:2147483648+134217728
2021-12-03 20:16:07,951 [Executor task launch worker for task 197] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:2281701376+134217728
2021-12-03 20:16:38,336 [Executor task launch worker for task 197] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:2415919104+134217728
2021-12-03 20:17:10,936 [Executor task launch worker for task 197] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:2550136832+134217728
2021-12-03 20:17:22,626 [Executor task launch worker for task 197] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:2684354560+134217728
2021-12-03 20:18:00,885 [Executor task launch worker for task 197] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:2818572288+147216171
2021-12-03 20:18:19,434 [Executor task launch worker for task 197] INFO [org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter] - Saved output of task 'attempt_20211203200910_0015_m_000000_0' to hdfs://hdp1:8020/sk/chongqing/sample_data/filter-sample-device-video-data.bcp/_temporary/0/task_20211203200910_0015_m_000000
2021-12-03 20:18:19,434 [Executor task launch worker for task 197] INFO [org.apache.spark.mapred.SparkHadoopMapRedUtil] - attempt_20211203200910_0015_m_000000_0: Committed
2021-12-03 20:18:19,436 [Executor task launch worker for task 197] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 15.0 (TID 197). 1041 bytes result sent to driver
2021-12-03 20:18:19,437 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 15.0 (TID 197) in 548546 ms on localhost (executor driver) (1/1)
2021-12-03 20:18:19,437 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 15.0, whose tasks have all completed, from pool 
2021-12-03 20:18:19,437 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 15 (runJob at SparkHadoopWriter.scala:78) finished in 548.559 s
2021-12-03 20:18:19,437 [main] INFO [org.apache.spark.scheduler.DAGScheduler] - Job 7 finished: runJob at SparkHadoopWriter.scala:78, took 548.560389 s
2021-12-03 20:18:20,014 [main] INFO [org.apache.spark.internal.io.SparkHadoopWriter] - Job job_20211203200910_0015 committed.
2021-12-03 20:18:20,015 [main] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_11 stored as values in memory (estimated size 312.7 KB, free 1990.0 MB)
2021-12-03 20:18:20,023 [main] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_11_piece0 stored as bytes in memory (estimated size 27.3 KB, free 1990.0 MB)
2021-12-03 20:18:20,023 [dispatcher-event-loop-3] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_11_piece0 in memory on qb:50070 (size: 27.3 KB, free: 1990.7 MB)
2021-12-03 20:18:20,024 [main] INFO [org.apache.spark.SparkContext] - Created broadcast 11 from textFile at PaidPromotionAdjustParameter.scala:93
2021-12-03 20:18:20,085 [main] INFO [org.apache.hadoop.mapred.FileInputFormat] - Total input paths to process : 1
2021-12-03 20:18:20,123 [main] INFO [org.apache.spark.SparkContext] - Starting job: count at PaidPromotionAdjustParameter.scala:95
2021-12-03 20:18:20,124 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 8 (count at PaidPromotionAdjustParameter.scala:95) with 2 output partitions
2021-12-03 20:18:20,124 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 16 (count at PaidPromotionAdjustParameter.scala:95)
2021-12-03 20:18:20,124 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List()
2021-12-03 20:18:20,124 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2021-12-03 20:18:20,124 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 16 (/sk/chongqing/data/order_data.bcp MapPartitionsRDD[17] at textFile at PaidPromotionAdjustParameter.scala:93), which has no missing parents
2021-12-03 20:18:20,125 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_12 stored as values in memory (estimated size 3.1 KB, free 1990.0 MB)
2021-12-03 20:18:20,126 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_12_piece0 stored as bytes in memory (estimated size 1897.0 B, free 1990.0 MB)
2021-12-03 20:18:20,126 [dispatcher-event-loop-8] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_12_piece0 in memory on qb:50070 (size: 1897.0 B, free: 1990.7 MB)
2021-12-03 20:18:20,126 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 12 from broadcast at DAGScheduler.scala:1039
2021-12-03 20:18:20,127 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from ResultStage 16 (/sk/chongqing/data/order_data.bcp MapPartitionsRDD[17] at textFile at PaidPromotionAdjustParameter.scala:93) (first 15 tasks are for partitions Vector(0, 1))
2021-12-03 20:18:20,127 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 16.0 with 2 tasks
2021-12-03 20:18:20,127 [dispatcher-event-loop-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 16.0 (TID 198, localhost, executor driver, partition 0, ANY, 7896 bytes)
2021-12-03 20:18:20,127 [dispatcher-event-loop-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 16.0 (TID 199, localhost, executor driver, partition 1, ANY, 7896 bytes)
2021-12-03 20:18:20,127 [Executor task launch worker for task 198] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 16.0 (TID 198)
2021-12-03 20:18:20,128 [Executor task launch worker for task 199] INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 16.0 (TID 199)
2021-12-03 20:18:20,128 [Executor task launch worker for task 199] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/order_data.bcp:3442194+3442195
2021-12-03 20:18:20,128 [Executor task launch worker for task 198] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/order_data.bcp:0+3442194
2021-12-03 20:18:20,701 [Executor task launch worker for task 199] INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 16.0 (TID 199). 668 bytes result sent to driver
2021-12-03 20:18:20,701 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 16.0 (TID 199) in 574 ms on localhost (executor driver) (1/2)
2021-12-03 20:18:21,795 [Executor task launch worker for task 198] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 16.0 (TID 198). 668 bytes result sent to driver
2021-12-03 20:18:21,795 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 16.0 (TID 198) in 1668 ms on localhost (executor driver) (2/2)
2021-12-03 20:18:21,796 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 16.0, whose tasks have all completed, from pool 
2021-12-03 20:18:21,796 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 16 (count at PaidPromotionAdjustParameter.scala:95) finished in 1.672 s
2021-12-03 20:18:21,796 [main] INFO [org.apache.spark.scheduler.DAGScheduler] - Job 8 finished: count at PaidPromotionAdjustParameter.scala:95, took 1.672537 s
2021-12-03 20:18:21,796 [main] INFO [PaidPromotion$] - 订购总数107294
2021-12-03 20:18:21,800 [main] INFO [org.apache.spark.SparkContext] - Starting job: count at PaidPromotionAdjustParameter.scala:103
2021-12-03 20:18:21,800 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 9 (count at PaidPromotionAdjustParameter.scala:103) with 2 output partitions
2021-12-03 20:18:21,800 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 17 (count at PaidPromotionAdjustParameter.scala:103)
2021-12-03 20:18:21,800 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List()
2021-12-03 20:18:21,800 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2021-12-03 20:18:21,800 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 17 (MapPartitionsRDD[18] at map at PaidPromotionAdjustParameter.scala:99), which has no missing parents
2021-12-03 20:18:21,801 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_13 stored as values in memory (estimated size 3.3 KB, free 1990.0 MB)
2021-12-03 20:18:21,802 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_13_piece0 stored as bytes in memory (estimated size 1975.0 B, free 1990.0 MB)
2021-12-03 20:18:21,803 [dispatcher-event-loop-9] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_13_piece0 in memory on qb:50070 (size: 1975.0 B, free: 1990.7 MB)
2021-12-03 20:18:21,803 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 13 from broadcast at DAGScheduler.scala:1039
2021-12-03 20:18:21,803 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from ResultStage 17 (MapPartitionsRDD[18] at map at PaidPromotionAdjustParameter.scala:99) (first 15 tasks are for partitions Vector(0, 1))
2021-12-03 20:18:21,803 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 17.0 with 2 tasks
2021-12-03 20:18:21,804 [dispatcher-event-loop-7] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 17.0 (TID 200, localhost, executor driver, partition 0, ANY, 7896 bytes)
2021-12-03 20:18:21,804 [dispatcher-event-loop-7] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 17.0 (TID 201, localhost, executor driver, partition 1, ANY, 7896 bytes)
2021-12-03 20:18:21,804 [Executor task launch worker for task 200] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 17.0 (TID 200)
2021-12-03 20:18:21,804 [Executor task launch worker for task 201] INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 17.0 (TID 201)
2021-12-03 20:18:21,805 [Executor task launch worker for task 200] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/order_data.bcp:0+3442194
2021-12-03 20:18:21,805 [Executor task launch worker for task 201] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/order_data.bcp:3442194+3442195
2021-12-03 20:18:22,741 [Executor task launch worker for task 201] INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 17.0 (TID 201). 711 bytes result sent to driver
2021-12-03 20:18:22,741 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 17.0 (TID 201) in 937 ms on localhost (executor driver) (1/2)
2021-12-03 20:18:22,788 [Executor task launch worker for task 200] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 17.0 (TID 200). 711 bytes result sent to driver
2021-12-03 20:18:22,789 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 17.0 (TID 200) in 985 ms on localhost (executor driver) (2/2)
2021-12-03 20:18:22,789 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 17.0, whose tasks have all completed, from pool 
2021-12-03 20:18:22,789 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 17 (count at PaidPromotionAdjustParameter.scala:103) finished in 0.988 s
2021-12-03 20:18:22,789 [main] INFO [org.apache.spark.scheduler.DAGScheduler] - Job 9 finished: count at PaidPromotionAdjustParameter.scala:103, took 0.989072 s
2021-12-03 20:18:22,789 [main] INFO [PaidPromotion$] - 订购总数：107294
2021-12-03 20:18:22,799 [main] INFO [org.apache.spark.SparkContext] - Starting job: count at PaidPromotionAdjustParameter.scala:116
2021-12-03 20:18:22,800 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 10 (count at PaidPromotionAdjustParameter.scala:116) with 2 output partitions
2021-12-03 20:18:22,800 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 18 (count at PaidPromotionAdjustParameter.scala:116)
2021-12-03 20:18:22,800 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List()
2021-12-03 20:18:22,800 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2021-12-03 20:18:22,800 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 18 (MapPartitionsRDD[19] at randomSplit at PaidPromotionAdjustParameter.scala:109), which has no missing parents
2021-12-03 20:18:22,800 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_14 stored as values in memory (estimated size 3.6 KB, free 1990.0 MB)
2021-12-03 20:18:22,801 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_14_piece0 stored as bytes in memory (estimated size 2.1 KB, free 1990.0 MB)
2021-12-03 20:18:22,802 [dispatcher-event-loop-8] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_14_piece0 in memory on qb:50070 (size: 2.1 KB, free: 1990.7 MB)
2021-12-03 20:18:22,802 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 14 from broadcast at DAGScheduler.scala:1039
2021-12-03 20:18:22,802 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from ResultStage 18 (MapPartitionsRDD[19] at randomSplit at PaidPromotionAdjustParameter.scala:109) (first 15 tasks are for partitions Vector(0, 1))
2021-12-03 20:18:22,802 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 18.0 with 2 tasks
2021-12-03 20:18:22,802 [dispatcher-event-loop-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 18.0 (TID 202, localhost, executor driver, partition 0, ANY, 7896 bytes)
2021-12-03 20:18:22,802 [dispatcher-event-loop-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 18.0 (TID 203, localhost, executor driver, partition 1, ANY, 7896 bytes)
2021-12-03 20:18:22,803 [Executor task launch worker for task 203] INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 18.0 (TID 203)
2021-12-03 20:18:22,803 [Executor task launch worker for task 202] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 18.0 (TID 202)
2021-12-03 20:18:22,803 [Executor task launch worker for task 203] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/order_data.bcp:3442194+3442195
2021-12-03 20:18:22,803 [Executor task launch worker for task 202] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/order_data.bcp:0+3442194
2021-12-03 20:18:23,045 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 289
2021-12-03 20:18:23,045 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 269
2021-12-03 20:18:23,045 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 292
2021-12-03 20:18:23,045 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 296
2021-12-03 20:18:23,045 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 288
2021-12-03 20:18:23,046 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 298
2021-12-03 20:18:23,046 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 256
2021-12-03 20:18:23,046 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 263
2021-12-03 20:18:23,046 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 271
2021-12-03 20:18:23,046 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 272
2021-12-03 20:18:23,046 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 259
2021-12-03 20:18:23,046 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 294
2021-12-03 20:18:23,046 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 251
2021-12-03 20:18:23,046 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 279
2021-12-03 20:18:23,046 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 293
2021-12-03 20:18:23,047 [dispatcher-event-loop-9] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_12_piece0 on qb:50070 in memory (size: 1897.0 B, free: 1990.7 MB)
2021-12-03 20:18:23,047 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 274
2021-12-03 20:18:23,047 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 252
2021-12-03 20:18:23,047 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 286
2021-12-03 20:18:23,047 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 262
2021-12-03 20:18:23,047 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 278
2021-12-03 20:18:23,047 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 284
2021-12-03 20:18:23,047 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 258
2021-12-03 20:18:23,047 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 257
2021-12-03 20:18:23,047 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 280
2021-12-03 20:18:23,047 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 282
2021-12-03 20:18:23,047 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 254
2021-12-03 20:18:23,047 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 268
2021-12-03 20:18:23,047 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 273
2021-12-03 20:18:23,047 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 253
2021-12-03 20:18:23,047 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 250
2021-12-03 20:18:23,047 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 283
2021-12-03 20:18:23,047 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 270
2021-12-03 20:18:23,047 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 255
2021-12-03 20:18:23,047 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 264
2021-12-03 20:18:23,047 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 260
2021-12-03 20:18:23,047 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 287
2021-12-03 20:18:23,047 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 275
2021-12-03 20:18:23,048 [dispatcher-event-loop-1] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_13_piece0 on qb:50070 in memory (size: 1975.0 B, free: 1990.7 MB)
2021-12-03 20:18:23,048 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 291
2021-12-03 20:18:23,048 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 265
2021-12-03 20:18:23,048 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 285
2021-12-03 20:18:23,048 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 267
2021-12-03 20:18:23,048 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 266
2021-12-03 20:18:23,048 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 276
2021-12-03 20:18:23,048 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 297
2021-12-03 20:18:23,048 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 295
2021-12-03 20:18:23,048 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 281
2021-12-03 20:18:23,048 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 277
2021-12-03 20:18:23,048 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 261
2021-12-03 20:18:23,048 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 299
2021-12-03 20:18:23,048 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 290
2021-12-03 20:18:23,480 [Executor task launch worker for task 202] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 18.0 (TID 202). 711 bytes result sent to driver
2021-12-03 20:18:23,480 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 18.0 (TID 202) in 678 ms on localhost (executor driver) (1/2)
2021-12-03 20:18:24,108 [Executor task launch worker for task 203] INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 18.0 (TID 203). 711 bytes result sent to driver
2021-12-03 20:18:24,108 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 18.0 (TID 203) in 1306 ms on localhost (executor driver) (2/2)
2021-12-03 20:18:24,108 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 18.0, whose tasks have all completed, from pool 
2021-12-03 20:18:24,108 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 18 (count at PaidPromotionAdjustParameter.scala:116) finished in 1.308 s
2021-12-03 20:18:24,108 [main] INFO [org.apache.spark.scheduler.DAGScheduler] - Job 10 finished: count at PaidPromotionAdjustParameter.scala:116, took 1.309658 s
2021-12-03 20:18:24,109 [main] INFO [PaidPromotion$] - 初次切分训练集数量：87267
2021-12-03 20:18:24,110 [main] INFO [org.apache.spark.SparkContext] - Starting job: count at PaidPromotionAdjustParameter.scala:117
2021-12-03 20:18:24,111 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 11 (count at PaidPromotionAdjustParameter.scala:117) with 2 output partitions
2021-12-03 20:18:24,111 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 19 (count at PaidPromotionAdjustParameter.scala:117)
2021-12-03 20:18:24,111 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List()
2021-12-03 20:18:24,111 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2021-12-03 20:18:24,111 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 19 (MapPartitionsRDD[20] at randomSplit at PaidPromotionAdjustParameter.scala:109), which has no missing parents
2021-12-03 20:18:24,111 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_15 stored as values in memory (estimated size 3.6 KB, free 1990.0 MB)
2021-12-03 20:18:24,112 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_15_piece0 stored as bytes in memory (estimated size 2.1 KB, free 1990.0 MB)
2021-12-03 20:18:24,113 [dispatcher-event-loop-8] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_15_piece0 in memory on qb:50070 (size: 2.1 KB, free: 1990.7 MB)
2021-12-03 20:18:24,113 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 15 from broadcast at DAGScheduler.scala:1039
2021-12-03 20:18:24,113 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from ResultStage 19 (MapPartitionsRDD[20] at randomSplit at PaidPromotionAdjustParameter.scala:109) (first 15 tasks are for partitions Vector(0, 1))
2021-12-03 20:18:24,113 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 19.0 with 2 tasks
2021-12-03 20:18:24,113 [dispatcher-event-loop-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 19.0 (TID 204, localhost, executor driver, partition 0, ANY, 7896 bytes)
2021-12-03 20:18:24,113 [dispatcher-event-loop-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 19.0 (TID 205, localhost, executor driver, partition 1, ANY, 7896 bytes)
2021-12-03 20:18:24,114 [Executor task launch worker for task 205] INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 19.0 (TID 205)
2021-12-03 20:18:24,114 [Executor task launch worker for task 204] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 19.0 (TID 204)
2021-12-03 20:18:24,114 [Executor task launch worker for task 204] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/order_data.bcp:0+3442194
2021-12-03 20:18:24,114 [Executor task launch worker for task 205] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/order_data.bcp:3442194+3442195
2021-12-03 20:18:24,595 [Executor task launch worker for task 204] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 19.0 (TID 204). 668 bytes result sent to driver
2021-12-03 20:18:24,595 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 19.0 (TID 204) in 482 ms on localhost (executor driver) (1/2)
2021-12-03 20:18:24,957 [Executor task launch worker for task 205] INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 19.0 (TID 205). 668 bytes result sent to driver
2021-12-03 20:18:24,958 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 19.0 (TID 205) in 845 ms on localhost (executor driver) (2/2)
2021-12-03 20:18:24,958 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 19.0, whose tasks have all completed, from pool 
2021-12-03 20:18:24,958 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 19 (count at PaidPromotionAdjustParameter.scala:117) finished in 0.847 s
2021-12-03 20:18:24,958 [main] INFO [org.apache.spark.scheduler.DAGScheduler] - Job 11 finished: count at PaidPromotionAdjustParameter.scala:117, took 0.847632 s
2021-12-03 20:18:24,958 [main] INFO [PaidPromotion$] - 初次切分验证集数量：20027
2021-12-03 20:18:25,002 [main] INFO [PaidPromotion$] - -----------------------------------
2021-12-03 20:18:25,003 [main] INFO [org.apache.spark.SparkContext] - Starting job: count at PaidPromotionAdjustParameter.scala:133
2021-12-03 20:18:25,003 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 22 (distinct at PaidPromotionAdjustParameter.scala:123)
2021-12-03 20:18:25,003 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 12 (count at PaidPromotionAdjustParameter.scala:133) with 2 output partitions
2021-12-03 20:18:25,003 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 21 (count at PaidPromotionAdjustParameter.scala:133)
2021-12-03 20:18:25,003 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 20)
2021-12-03 20:18:25,004 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List(ShuffleMapStage 20)
2021-12-03 20:18:25,004 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ShuffleMapStage 20 (MapPartitionsRDD[22] at distinct at PaidPromotionAdjustParameter.scala:123), which has no missing parents
2021-12-03 20:18:25,004 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_16 stored as values in memory (estimated size 5.2 KB, free 1990.0 MB)
2021-12-03 20:18:25,005 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_16_piece0 stored as bytes in memory (estimated size 2.9 KB, free 1990.0 MB)
2021-12-03 20:18:25,006 [dispatcher-event-loop-9] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_16_piece0 in memory on qb:50070 (size: 2.9 KB, free: 1990.7 MB)
2021-12-03 20:18:25,006 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 16 from broadcast at DAGScheduler.scala:1039
2021-12-03 20:18:25,006 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from ShuffleMapStage 20 (MapPartitionsRDD[22] at distinct at PaidPromotionAdjustParameter.scala:123) (first 15 tasks are for partitions Vector(0, 1))
2021-12-03 20:18:25,006 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 20.0 with 2 tasks
2021-12-03 20:18:25,006 [dispatcher-event-loop-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 20.0 (TID 206, localhost, executor driver, partition 0, ANY, 7885 bytes)
2021-12-03 20:18:25,007 [dispatcher-event-loop-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 20.0 (TID 207, localhost, executor driver, partition 1, ANY, 7885 bytes)
2021-12-03 20:18:25,007 [Executor task launch worker for task 206] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 20.0 (TID 206)
2021-12-03 20:18:25,007 [Executor task launch worker for task 207] INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 20.0 (TID 207)
2021-12-03 20:18:25,007 [Executor task launch worker for task 207] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/order_data.bcp:3442194+3442195
2021-12-03 20:18:25,007 [Executor task launch worker for task 206] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/order_data.bcp:0+3442194
2021-12-03 20:18:25,311 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 330
2021-12-03 20:18:25,311 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 328
2021-12-03 20:18:25,311 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 327
2021-12-03 20:18:25,311 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 346
2021-12-03 20:18:25,311 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 348
2021-12-03 20:18:25,311 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 344
2021-12-03 20:18:25,311 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 339
2021-12-03 20:18:25,311 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 326
2021-12-03 20:18:25,312 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 334
2021-12-03 20:18:25,312 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 347
2021-12-03 20:18:25,312 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 325
2021-12-03 20:18:25,312 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 343
2021-12-03 20:18:25,312 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 340
2021-12-03 20:18:25,312 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 332
2021-12-03 20:18:25,312 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 329
2021-12-03 20:18:25,312 [dispatcher-event-loop-8] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_15_piece0 on qb:50070 in memory (size: 2.1 KB, free: 1990.7 MB)
2021-12-03 20:18:25,312 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 333
2021-12-03 20:18:25,312 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 345
2021-12-03 20:18:25,312 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 336
2021-12-03 20:18:25,313 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 331
2021-12-03 20:18:25,313 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 342
2021-12-03 20:18:25,313 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 335
2021-12-03 20:18:25,313 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 349
2021-12-03 20:18:25,313 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 337
2021-12-03 20:18:25,313 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 341
2021-12-03 20:18:25,313 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 338
2021-12-03 20:18:25,622 [Executor task launch worker for task 206] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 20.0 (TID 206). 989 bytes result sent to driver
2021-12-03 20:18:25,622 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 20.0 (TID 206) in 616 ms on localhost (executor driver) (1/2)
2021-12-03 20:18:25,866 [Executor task launch worker for task 207] INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 20.0 (TID 207). 989 bytes result sent to driver
2021-12-03 20:18:25,867 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 20.0 (TID 207) in 861 ms on localhost (executor driver) (2/2)
2021-12-03 20:18:25,867 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 20.0, whose tasks have all completed, from pool 
2021-12-03 20:18:25,867 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ShuffleMapStage 20 (distinct at PaidPromotionAdjustParameter.scala:123) finished in 0.863 s
2021-12-03 20:18:25,867 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - looking for newly runnable stages
2021-12-03 20:18:25,867 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - running: Set()
2021-12-03 20:18:25,867 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - waiting: Set(ResultStage 21)
2021-12-03 20:18:25,867 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - failed: Set()
2021-12-03 20:18:25,867 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 21 (MapPartitionsRDD[24] at distinct at PaidPromotionAdjustParameter.scala:123), which has no missing parents
2021-12-03 20:18:25,869 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_17 stored as values in memory (estimated size 3.7 KB, free 1990.0 MB)
2021-12-03 20:18:25,870 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_17_piece0 stored as bytes in memory (estimated size 2.2 KB, free 1990.0 MB)
2021-12-03 20:18:25,870 [dispatcher-event-loop-6] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_17_piece0 in memory on qb:50070 (size: 2.2 KB, free: 1990.7 MB)
2021-12-03 20:18:25,871 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 17 from broadcast at DAGScheduler.scala:1039
2021-12-03 20:18:25,871 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from ResultStage 21 (MapPartitionsRDD[24] at distinct at PaidPromotionAdjustParameter.scala:123) (first 15 tasks are for partitions Vector(0, 1))
2021-12-03 20:18:25,871 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 21.0 with 2 tasks
2021-12-03 20:18:25,871 [dispatcher-event-loop-4] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 21.0 (TID 208, localhost, executor driver, partition 0, ANY, 7649 bytes)
2021-12-03 20:18:25,872 [dispatcher-event-loop-4] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 21.0 (TID 209, localhost, executor driver, partition 1, ANY, 7649 bytes)
2021-12-03 20:18:25,872 [Executor task launch worker for task 208] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 21.0 (TID 208)
2021-12-03 20:18:25,872 [Executor task launch worker for task 209] INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 21.0 (TID 209)
2021-12-03 20:18:25,873 [Executor task launch worker for task 208] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 2 non-empty blocks out of 2 blocks
2021-12-03 20:18:25,873 [Executor task launch worker for task 209] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 2 non-empty blocks out of 2 blocks
2021-12-03 20:18:25,873 [Executor task launch worker for task 208] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 1 ms
2021-12-03 20:18:25,873 [Executor task launch worker for task 209] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 1 ms
2021-12-03 20:18:25,912 [Executor task launch worker for task 209] INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 21.0 (TID 209). 1012 bytes result sent to driver
2021-12-03 20:18:25,912 [Executor task launch worker for task 208] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 21.0 (TID 208). 1012 bytes result sent to driver
2021-12-03 20:18:25,912 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 21.0 (TID 209) in 40 ms on localhost (executor driver) (1/2)
2021-12-03 20:18:25,912 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 21.0 (TID 208) in 41 ms on localhost (executor driver) (2/2)
2021-12-03 20:18:25,912 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 21.0, whose tasks have all completed, from pool 
2021-12-03 20:18:25,912 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 21 (count at PaidPromotionAdjustParameter.scala:133) finished in 0.044 s
2021-12-03 20:18:25,912 [main] INFO [org.apache.spark.scheduler.DAGScheduler] - Job 12 finished: count at PaidPromotionAdjustParameter.scala:133, took 0.909344 s
2021-12-03 20:18:25,913 [main] INFO [PaidPromotion$] - 训练集用户数 = 79047
2021-12-03 20:18:25,915 [main] INFO [org.apache.spark.SparkContext] - Starting job: count at PaidPromotionAdjustParameter.scala:134
2021-12-03 20:18:25,915 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 26 (distinct at PaidPromotionAdjustParameter.scala:124)
2021-12-03 20:18:25,915 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 13 (count at PaidPromotionAdjustParameter.scala:134) with 2 output partitions
2021-12-03 20:18:25,915 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 23 (count at PaidPromotionAdjustParameter.scala:134)
2021-12-03 20:18:25,915 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 22)
2021-12-03 20:18:25,915 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List(ShuffleMapStage 22)
2021-12-03 20:18:25,915 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ShuffleMapStage 22 (MapPartitionsRDD[26] at distinct at PaidPromotionAdjustParameter.scala:124), which has no missing parents
2021-12-03 20:18:25,916 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_18 stored as values in memory (estimated size 5.2 KB, free 1990.0 MB)
2021-12-03 20:18:25,917 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_18_piece0 stored as bytes in memory (estimated size 2.9 KB, free 1990.0 MB)
2021-12-03 20:18:25,917 [dispatcher-event-loop-7] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_18_piece0 in memory on qb:50070 (size: 2.9 KB, free: 1990.7 MB)
2021-12-03 20:18:25,918 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 18 from broadcast at DAGScheduler.scala:1039
2021-12-03 20:18:25,918 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from ShuffleMapStage 22 (MapPartitionsRDD[26] at distinct at PaidPromotionAdjustParameter.scala:124) (first 15 tasks are for partitions Vector(0, 1))
2021-12-03 20:18:25,918 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 22.0 with 2 tasks
2021-12-03 20:18:25,918 [dispatcher-event-loop-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 22.0 (TID 210, localhost, executor driver, partition 0, ANY, 7885 bytes)
2021-12-03 20:18:25,918 [dispatcher-event-loop-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 22.0 (TID 211, localhost, executor driver, partition 1, ANY, 7885 bytes)
2021-12-03 20:18:25,918 [Executor task launch worker for task 210] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 22.0 (TID 210)
2021-12-03 20:18:25,918 [Executor task launch worker for task 211] INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 22.0 (TID 211)
2021-12-03 20:18:25,919 [Executor task launch worker for task 211] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/order_data.bcp:3442194+3442195
2021-12-03 20:18:25,919 [Executor task launch worker for task 210] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/order_data.bcp:0+3442194
2021-12-03 20:18:26,477 [Executor task launch worker for task 211] INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 22.0 (TID 211). 946 bytes result sent to driver
2021-12-03 20:18:26,477 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 22.0 (TID 211) in 559 ms on localhost (executor driver) (1/2)
2021-12-03 20:18:26,865 [Executor task launch worker for task 210] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 22.0 (TID 210). 946 bytes result sent to driver
2021-12-03 20:18:26,865 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 22.0 (TID 210) in 947 ms on localhost (executor driver) (2/2)
2021-12-03 20:18:26,865 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 22.0, whose tasks have all completed, from pool 
2021-12-03 20:18:26,866 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ShuffleMapStage 22 (distinct at PaidPromotionAdjustParameter.scala:124) finished in 0.950 s
2021-12-03 20:18:26,866 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - looking for newly runnable stages
2021-12-03 20:18:26,866 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - running: Set()
2021-12-03 20:18:26,866 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - waiting: Set(ResultStage 23)
2021-12-03 20:18:26,866 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - failed: Set()
2021-12-03 20:18:26,866 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 23 (MapPartitionsRDD[28] at distinct at PaidPromotionAdjustParameter.scala:124), which has no missing parents
2021-12-03 20:18:26,866 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_19 stored as values in memory (estimated size 3.7 KB, free 1990.0 MB)
2021-12-03 20:18:26,868 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_19_piece0 stored as bytes in memory (estimated size 2.2 KB, free 1990.0 MB)
2021-12-03 20:18:26,868 [dispatcher-event-loop-6] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_19_piece0 in memory on qb:50070 (size: 2.2 KB, free: 1990.7 MB)
2021-12-03 20:18:26,868 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 19 from broadcast at DAGScheduler.scala:1039
2021-12-03 20:18:26,868 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from ResultStage 23 (MapPartitionsRDD[28] at distinct at PaidPromotionAdjustParameter.scala:124) (first 15 tasks are for partitions Vector(0, 1))
2021-12-03 20:18:26,868 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 23.0 with 2 tasks
2021-12-03 20:18:26,868 [dispatcher-event-loop-4] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 23.0 (TID 212, localhost, executor driver, partition 0, ANY, 7649 bytes)
2021-12-03 20:18:26,869 [dispatcher-event-loop-4] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 23.0 (TID 213, localhost, executor driver, partition 1, ANY, 7649 bytes)
2021-12-03 20:18:26,869 [Executor task launch worker for task 212] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 23.0 (TID 212)
2021-12-03 20:18:26,869 [Executor task launch worker for task 213] INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 23.0 (TID 213)
2021-12-03 20:18:26,869 [Executor task launch worker for task 213] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 2 non-empty blocks out of 2 blocks
2021-12-03 20:18:26,869 [Executor task launch worker for task 212] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 2 non-empty blocks out of 2 blocks
2021-12-03 20:18:26,869 [Executor task launch worker for task 212] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 20:18:26,869 [Executor task launch worker for task 213] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 20:18:26,892 [Executor task launch worker for task 212] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 23.0 (TID 212). 1012 bytes result sent to driver
2021-12-03 20:18:26,892 [Executor task launch worker for task 213] INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 23.0 (TID 213). 1012 bytes result sent to driver
2021-12-03 20:18:26,892 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 23.0 (TID 212) in 24 ms on localhost (executor driver) (1/2)
2021-12-03 20:18:26,892 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 23.0 (TID 213) in 23 ms on localhost (executor driver) (2/2)
2021-12-03 20:18:26,892 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 23.0, whose tasks have all completed, from pool 
2021-12-03 20:18:26,893 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 23 (count at PaidPromotionAdjustParameter.scala:134) finished in 0.026 s
2021-12-03 20:18:26,893 [main] INFO [org.apache.spark.scheduler.DAGScheduler] - Job 13 finished: count at PaidPromotionAdjustParameter.scala:134, took 0.977197 s
2021-12-03 20:18:26,893 [main] INFO [PaidPromotion$] - 验证集用户数 = 19523
2021-12-03 20:18:26,899 [main] INFO [org.apache.spark.SparkContext] - Starting job: count at PaidPromotionAdjustParameter.scala:135
2021-12-03 20:18:26,900 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 30 (intersection at PaidPromotionAdjustParameter.scala:125)
2021-12-03 20:18:26,900 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 29 (intersection at PaidPromotionAdjustParameter.scala:125)
2021-12-03 20:18:26,900 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 14 (count at PaidPromotionAdjustParameter.scala:135) with 2 output partitions
2021-12-03 20:18:26,900 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 28 (count at PaidPromotionAdjustParameter.scala:135)
2021-12-03 20:18:26,900 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 27, ShuffleMapStage 25)
2021-12-03 20:18:26,900 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List(ShuffleMapStage 27, ShuffleMapStage 25)
2021-12-03 20:18:26,900 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ShuffleMapStage 25 (MapPartitionsRDD[30] at intersection at PaidPromotionAdjustParameter.scala:125), which has no missing parents
2021-12-03 20:18:26,901 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_20 stored as values in memory (estimated size 4.0 KB, free 1990.0 MB)
2021-12-03 20:18:26,903 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_20_piece0 stored as bytes in memory (estimated size 2.3 KB, free 1990.0 MB)
2021-12-03 20:18:26,903 [dispatcher-event-loop-7] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_20_piece0 in memory on qb:50070 (size: 2.3 KB, free: 1990.7 MB)
2021-12-03 20:18:26,903 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 20 from broadcast at DAGScheduler.scala:1039
2021-12-03 20:18:26,903 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from ShuffleMapStage 25 (MapPartitionsRDD[30] at intersection at PaidPromotionAdjustParameter.scala:125) (first 15 tasks are for partitions Vector(0, 1))
2021-12-03 20:18:26,903 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 25.0 with 2 tasks
2021-12-03 20:18:26,904 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ShuffleMapStage 27 (MapPartitionsRDD[29] at intersection at PaidPromotionAdjustParameter.scala:125), which has no missing parents
2021-12-03 20:18:26,904 [dispatcher-event-loop-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 25.0 (TID 214, localhost, executor driver, partition 0, ANY, 7638 bytes)
2021-12-03 20:18:26,904 [dispatcher-event-loop-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 25.0 (TID 215, localhost, executor driver, partition 1, ANY, 7638 bytes)
2021-12-03 20:18:26,904 [Executor task launch worker for task 214] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 25.0 (TID 214)
2021-12-03 20:18:26,904 [Executor task launch worker for task 215] INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 25.0 (TID 215)
2021-12-03 20:18:26,904 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_21 stored as values in memory (estimated size 4.0 KB, free 1990.0 MB)
2021-12-03 20:18:26,905 [Executor task launch worker for task 214] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 2 non-empty blocks out of 2 blocks
2021-12-03 20:18:26,905 [Executor task launch worker for task 214] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 1 ms
2021-12-03 20:18:26,905 [Executor task launch worker for task 215] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 2 non-empty blocks out of 2 blocks
2021-12-03 20:18:26,905 [Executor task launch worker for task 215] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 1 ms
2021-12-03 20:18:26,911 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 426
2021-12-03 20:18:26,912 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 437
2021-12-03 20:18:26,912 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 409
2021-12-03 20:18:26,912 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 429
2021-12-03 20:18:26,912 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 447
2021-12-03 20:18:26,912 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 402
2021-12-03 20:18:26,912 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 431
2021-12-03 20:18:26,912 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_21_piece0 stored as bytes in memory (estimated size 2.3 KB, free 1990.0 MB)
2021-12-03 20:18:26,912 [dispatcher-event-loop-2] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_21_piece0 in memory on qb:50070 (size: 2.3 KB, free: 1990.7 MB)
2021-12-03 20:18:26,912 [dispatcher-event-loop-2] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_18_piece0 on qb:50070 in memory (size: 2.9 KB, free: 1990.7 MB)
2021-12-03 20:18:26,912 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 21 from broadcast at DAGScheduler.scala:1039
2021-12-03 20:18:26,913 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from ShuffleMapStage 27 (MapPartitionsRDD[29] at intersection at PaidPromotionAdjustParameter.scala:125) (first 15 tasks are for partitions Vector(0, 1))
2021-12-03 20:18:26,913 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 417
2021-12-03 20:18:26,913 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 27.0 with 2 tasks
2021-12-03 20:18:26,913 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 406
2021-12-03 20:18:26,913 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 424
2021-12-03 20:18:26,913 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 433
2021-12-03 20:18:26,913 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 421
2021-12-03 20:18:26,913 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 427
2021-12-03 20:18:26,913 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 422
2021-12-03 20:18:26,913 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 423
2021-12-03 20:18:26,913 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 419
2021-12-03 20:18:26,913 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 443
2021-12-03 20:18:26,913 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 436
2021-12-03 20:18:26,913 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 448
2021-12-03 20:18:26,913 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 404
2021-12-03 20:18:26,913 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 434
2021-12-03 20:18:26,913 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 445
2021-12-03 20:18:26,913 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 405
2021-12-03 20:18:26,913 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 420
2021-12-03 20:18:26,913 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 401
2021-12-03 20:18:26,913 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 442
2021-12-03 20:18:26,913 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 403
2021-12-03 20:18:26,913 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 418
2021-12-03 20:18:26,913 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 410
2021-12-03 20:18:26,913 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 446
2021-12-03 20:18:26,913 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 425
2021-12-03 20:18:26,913 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 432
2021-12-03 20:18:26,913 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 438
2021-12-03 20:18:26,913 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 439
2021-12-03 20:18:26,913 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 411
2021-12-03 20:18:26,913 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 449
2021-12-03 20:18:26,913 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 415
2021-12-03 20:18:26,913 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 414
2021-12-03 20:18:26,913 [dispatcher-event-loop-9] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 27.0 (TID 216, localhost, executor driver, partition 0, ANY, 7638 bytes)
2021-12-03 20:18:26,913 [dispatcher-event-loop-9] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 27.0 (TID 217, localhost, executor driver, partition 1, ANY, 7638 bytes)
2021-12-03 20:18:26,914 [Executor task launch worker for task 216] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 27.0 (TID 216)
2021-12-03 20:18:26,914 [dispatcher-event-loop-1] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_17_piece0 on qb:50070 in memory (size: 2.2 KB, free: 1990.7 MB)
2021-12-03 20:18:26,914 [Executor task launch worker for task 217] INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 27.0 (TID 217)
2021-12-03 20:18:26,914 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 428
2021-12-03 20:18:26,914 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 400
2021-12-03 20:18:26,914 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 413
2021-12-03 20:18:26,914 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 440
2021-12-03 20:18:26,914 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 407
2021-12-03 20:18:26,914 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 412
2021-12-03 20:18:26,915 [dispatcher-event-loop-11] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_19_piece0 on qb:50070 in memory (size: 2.2 KB, free: 1990.7 MB)
2021-12-03 20:18:26,915 [Executor task launch worker for task 216] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 2 non-empty blocks out of 2 blocks
2021-12-03 20:18:26,915 [Executor task launch worker for task 217] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 2 non-empty blocks out of 2 blocks
2021-12-03 20:18:26,915 [Executor task launch worker for task 216] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 20:18:26,915 [Executor task launch worker for task 217] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 20:18:26,915 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 416
2021-12-03 20:18:26,915 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 441
2021-12-03 20:18:26,915 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 444
2021-12-03 20:18:26,915 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 430
2021-12-03 20:18:26,915 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 408
2021-12-03 20:18:26,915 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 435
2021-12-03 20:18:26,941 [Executor task launch worker for task 214] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 25.0 (TID 214). 1204 bytes result sent to driver
2021-12-03 20:18:26,941 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 25.0 (TID 214) in 37 ms on localhost (executor driver) (1/2)
2021-12-03 20:18:26,942 [Executor task launch worker for task 215] INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 25.0 (TID 215). 1204 bytes result sent to driver
2021-12-03 20:18:26,942 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 25.0 (TID 215) in 38 ms on localhost (executor driver) (2/2)
2021-12-03 20:18:26,942 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 25.0, whose tasks have all completed, from pool 
2021-12-03 20:18:26,943 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ShuffleMapStage 25 (intersection at PaidPromotionAdjustParameter.scala:125) finished in 0.041 s
2021-12-03 20:18:26,943 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - looking for newly runnable stages
2021-12-03 20:18:26,943 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - running: Set(ShuffleMapStage 27)
2021-12-03 20:18:26,943 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - waiting: Set(ResultStage 28)
2021-12-03 20:18:26,943 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - failed: Set()
2021-12-03 20:18:26,977 [Executor task launch worker for task 217] INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 27.0 (TID 217). 1204 bytes result sent to driver
2021-12-03 20:18:26,978 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 27.0 (TID 217) in 65 ms on localhost (executor driver) (1/2)
2021-12-03 20:18:26,978 [Executor task launch worker for task 216] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 27.0 (TID 216). 1204 bytes result sent to driver
2021-12-03 20:18:26,978 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 27.0 (TID 216) in 65 ms on localhost (executor driver) (2/2)
2021-12-03 20:18:26,978 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 27.0, whose tasks have all completed, from pool 
2021-12-03 20:18:26,978 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ShuffleMapStage 27 (intersection at PaidPromotionAdjustParameter.scala:125) finished in 0.074 s
2021-12-03 20:18:26,978 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - looking for newly runnable stages
2021-12-03 20:18:26,978 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - running: Set()
2021-12-03 20:18:26,978 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - waiting: Set(ResultStage 28)
2021-12-03 20:18:26,979 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - failed: Set()
2021-12-03 20:18:26,979 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 28 (MapPartitionsRDD[34] at intersection at PaidPromotionAdjustParameter.scala:125), which has no missing parents
2021-12-03 20:18:26,980 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_22 stored as values in memory (estimated size 3.6 KB, free 1990.0 MB)
2021-12-03 20:18:26,981 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_22_piece0 stored as bytes in memory (estimated size 2.1 KB, free 1990.0 MB)
2021-12-03 20:18:26,981 [dispatcher-event-loop-10] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_22_piece0 in memory on qb:50070 (size: 2.1 KB, free: 1990.7 MB)
2021-12-03 20:18:26,981 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 22 from broadcast at DAGScheduler.scala:1039
2021-12-03 20:18:26,982 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from ResultStage 28 (MapPartitionsRDD[34] at intersection at PaidPromotionAdjustParameter.scala:125) (first 15 tasks are for partitions Vector(0, 1))
2021-12-03 20:18:26,982 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 28.0 with 2 tasks
2021-12-03 20:18:26,983 [dispatcher-event-loop-9] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 28.0 (TID 218, localhost, executor driver, partition 0, PROCESS_LOCAL, 7712 bytes)
2021-12-03 20:18:26,983 [dispatcher-event-loop-9] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 28.0 (TID 219, localhost, executor driver, partition 1, PROCESS_LOCAL, 7712 bytes)
2021-12-03 20:18:26,984 [Executor task launch worker for task 218] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 28.0 (TID 218)
2021-12-03 20:18:26,984 [Executor task launch worker for task 219] INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 28.0 (TID 219)
2021-12-03 20:18:26,986 [Executor task launch worker for task 218] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2021-12-03 20:18:26,986 [Executor task launch worker for task 219] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2021-12-03 20:18:26,986 [Executor task launch worker for task 218] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 20:18:26,986 [Executor task launch worker for task 219] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 20:18:26,987 [Executor task launch worker for task 218] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2021-12-03 20:18:26,987 [Executor task launch worker for task 219] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2021-12-03 20:18:26,987 [Executor task launch worker for task 218] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 20:18:26,987 [Executor task launch worker for task 219] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 20:18:27,108 [Executor task launch worker for task 219] INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 28.0 (TID 219). 1011 bytes result sent to driver
2021-12-03 20:18:27,109 [Executor task launch worker for task 218] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 28.0 (TID 218). 1011 bytes result sent to driver
2021-12-03 20:18:27,109 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 28.0 (TID 219) in 126 ms on localhost (executor driver) (1/2)
2021-12-03 20:18:27,109 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 28.0 (TID 218) in 127 ms on localhost (executor driver) (2/2)
2021-12-03 20:18:27,109 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 28.0, whose tasks have all completed, from pool 
2021-12-03 20:18:27,109 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 28 (count at PaidPromotionAdjustParameter.scala:135) finished in 0.130 s
2021-12-03 20:18:27,109 [main] INFO [org.apache.spark.scheduler.DAGScheduler] - Job 14 finished: count at PaidPromotionAdjustParameter.scala:135, took 0.210162 s
2021-12-03 20:18:27,110 [main] INFO [PaidPromotion$] - 共 同 用户数 = 3247
2021-12-03 20:18:27,112 [main] INFO [org.apache.spark.SparkContext] - Starting job: count at PaidPromotionAdjustParameter.scala:136
2021-12-03 20:18:27,112 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 36 (distinct at PaidPromotionAdjustParameter.scala:128)
2021-12-03 20:18:27,112 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 15 (count at PaidPromotionAdjustParameter.scala:136) with 2 output partitions
2021-12-03 20:18:27,112 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 30 (count at PaidPromotionAdjustParameter.scala:136)
2021-12-03 20:18:27,112 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 29)
2021-12-03 20:18:27,112 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List(ShuffleMapStage 29)
2021-12-03 20:18:27,113 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ShuffleMapStage 29 (MapPartitionsRDD[36] at distinct at PaidPromotionAdjustParameter.scala:128), which has no missing parents
2021-12-03 20:18:27,113 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_23 stored as values in memory (estimated size 5.2 KB, free 1990.0 MB)
2021-12-03 20:18:27,115 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_23_piece0 stored as bytes in memory (estimated size 2.9 KB, free 1990.0 MB)
2021-12-03 20:18:27,115 [dispatcher-event-loop-5] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_23_piece0 in memory on qb:50070 (size: 2.9 KB, free: 1990.7 MB)
2021-12-03 20:18:27,115 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 23 from broadcast at DAGScheduler.scala:1039
2021-12-03 20:18:27,115 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from ShuffleMapStage 29 (MapPartitionsRDD[36] at distinct at PaidPromotionAdjustParameter.scala:128) (first 15 tasks are for partitions Vector(0, 1))
2021-12-03 20:18:27,115 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 29.0 with 2 tasks
2021-12-03 20:18:27,116 [dispatcher-event-loop-11] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 29.0 (TID 220, localhost, executor driver, partition 0, ANY, 7885 bytes)
2021-12-03 20:18:27,116 [dispatcher-event-loop-11] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 29.0 (TID 221, localhost, executor driver, partition 1, ANY, 7885 bytes)
2021-12-03 20:18:27,116 [Executor task launch worker for task 221] INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 29.0 (TID 221)
2021-12-03 20:18:27,116 [Executor task launch worker for task 220] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 29.0 (TID 220)
2021-12-03 20:18:27,117 [Executor task launch worker for task 220] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/order_data.bcp:0+3442194
2021-12-03 20:18:27,117 [Executor task launch worker for task 221] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/order_data.bcp:3442194+3442195
2021-12-03 20:18:27,683 [Executor task launch worker for task 221] INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 29.0 (TID 221). 946 bytes result sent to driver
2021-12-03 20:18:27,683 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 29.0 (TID 221) in 567 ms on localhost (executor driver) (1/2)
2021-12-03 20:18:27,951 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 456
2021-12-03 20:18:27,951 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 466
2021-12-03 20:18:27,951 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 521
2021-12-03 20:18:27,951 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 518
2021-12-03 20:18:27,951 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 450
2021-12-03 20:18:27,951 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 488
2021-12-03 20:18:27,951 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 512
2021-12-03 20:18:27,951 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 470
2021-12-03 20:18:27,951 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 451
2021-12-03 20:18:27,951 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 506
2021-12-03 20:18:27,951 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 460
2021-12-03 20:18:27,951 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 500
2021-12-03 20:18:27,951 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 481
2021-12-03 20:18:27,951 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 462
2021-12-03 20:18:27,951 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 484
2021-12-03 20:18:27,951 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 487
2021-12-03 20:18:27,951 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 485
2021-12-03 20:18:27,951 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 492
2021-12-03 20:18:27,951 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 457
2021-12-03 20:18:27,951 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 453
2021-12-03 20:18:27,951 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 465
2021-12-03 20:18:27,951 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 509
2021-12-03 20:18:27,951 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 502
2021-12-03 20:18:27,951 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 514
2021-12-03 20:18:27,951 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 516
2021-12-03 20:18:27,952 [dispatcher-event-loop-3] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_22_piece0 on qb:50070 in memory (size: 2.1 KB, free: 1990.7 MB)
2021-12-03 20:18:27,952 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 459
2021-12-03 20:18:27,952 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 455
2021-12-03 20:18:27,952 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 475
2021-12-03 20:18:27,952 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 468
2021-12-03 20:18:27,952 [dispatcher-event-loop-5] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_21_piece0 on qb:50070 in memory (size: 2.3 KB, free: 1990.7 MB)
2021-12-03 20:18:27,953 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 513
2021-12-03 20:18:27,953 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 464
2021-12-03 20:18:27,953 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 510
2021-12-03 20:18:27,953 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 471
2021-12-03 20:18:27,953 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 522
2021-12-03 20:18:27,953 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 503
2021-12-03 20:18:27,953 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 469
2021-12-03 20:18:27,953 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 476
2021-12-03 20:18:27,953 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 511
2021-12-03 20:18:27,953 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 491
2021-12-03 20:18:27,953 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 524
2021-12-03 20:18:27,953 [Executor task launch worker for task 220] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 29.0 (TID 220). 989 bytes result sent to driver
2021-12-03 20:18:27,953 [dispatcher-event-loop-2] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_20_piece0 on qb:50070 in memory (size: 2.3 KB, free: 1990.7 MB)
2021-12-03 20:18:27,954 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 29.0 (TID 220) in 838 ms on localhost (executor driver) (2/2)
2021-12-03 20:18:27,954 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 29.0, whose tasks have all completed, from pool 
2021-12-03 20:18:27,954 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 483
2021-12-03 20:18:27,954 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ShuffleMapStage 29 (distinct at PaidPromotionAdjustParameter.scala:128) finished in 0.841 s
2021-12-03 20:18:27,954 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 477
2021-12-03 20:18:27,954 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - looking for newly runnable stages
2021-12-03 20:18:27,954 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 517
2021-12-03 20:18:27,954 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 515
2021-12-03 20:18:27,954 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 467
2021-12-03 20:18:27,954 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 489
2021-12-03 20:18:27,954 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - running: Set()
2021-12-03 20:18:27,954 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - waiting: Set(ResultStage 30)
2021-12-03 20:18:27,954 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 523
2021-12-03 20:18:27,954 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 478
2021-12-03 20:18:27,954 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 474
2021-12-03 20:18:27,954 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 472
2021-12-03 20:18:27,954 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - failed: Set()
2021-12-03 20:18:27,954 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 490
2021-12-03 20:18:27,954 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 473
2021-12-03 20:18:27,954 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 452
2021-12-03 20:18:27,954 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 504
2021-12-03 20:18:27,954 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 486
2021-12-03 20:18:27,954 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 454
2021-12-03 20:18:27,954 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 482
2021-12-03 20:18:27,954 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 495
2021-12-03 20:18:27,954 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 508
2021-12-03 20:18:27,954 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 498
2021-12-03 20:18:27,954 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 501
2021-12-03 20:18:27,954 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 519
2021-12-03 20:18:27,954 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 30 (MapPartitionsRDD[38] at distinct at PaidPromotionAdjustParameter.scala:128), which has no missing parents
2021-12-03 20:18:27,954 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 497
2021-12-03 20:18:27,954 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 458
2021-12-03 20:18:27,954 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 496
2021-12-03 20:18:27,954 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 479
2021-12-03 20:18:27,954 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 480
2021-12-03 20:18:27,954 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 520
2021-12-03 20:18:27,954 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 494
2021-12-03 20:18:27,954 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 461
2021-12-03 20:18:27,954 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 463
2021-12-03 20:18:27,954 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 505
2021-12-03 20:18:27,954 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 493
2021-12-03 20:18:27,954 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 499
2021-12-03 20:18:27,954 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 507
2021-12-03 20:18:27,955 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_24 stored as values in memory (estimated size 3.7 KB, free 1990.0 MB)
2021-12-03 20:18:27,956 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_24_piece0 stored as bytes in memory (estimated size 2.2 KB, free 1990.0 MB)
2021-12-03 20:18:27,957 [dispatcher-event-loop-0] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_24_piece0 in memory on qb:50070 (size: 2.2 KB, free: 1990.7 MB)
2021-12-03 20:18:27,957 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 24 from broadcast at DAGScheduler.scala:1039
2021-12-03 20:18:27,957 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from ResultStage 30 (MapPartitionsRDD[38] at distinct at PaidPromotionAdjustParameter.scala:128) (first 15 tasks are for partitions Vector(0, 1))
2021-12-03 20:18:27,957 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 30.0 with 2 tasks
2021-12-03 20:18:27,958 [dispatcher-event-loop-10] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 30.0 (TID 222, localhost, executor driver, partition 0, ANY, 7649 bytes)
2021-12-03 20:18:27,958 [dispatcher-event-loop-10] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 30.0 (TID 223, localhost, executor driver, partition 1, ANY, 7649 bytes)
2021-12-03 20:18:27,958 [Executor task launch worker for task 222] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 30.0 (TID 222)
2021-12-03 20:18:27,958 [Executor task launch worker for task 223] INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 30.0 (TID 223)
2021-12-03 20:18:27,959 [Executor task launch worker for task 222] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 2 non-empty blocks out of 2 blocks
2021-12-03 20:18:27,959 [Executor task launch worker for task 223] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 2 non-empty blocks out of 2 blocks
2021-12-03 20:18:27,959 [Executor task launch worker for task 222] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 20:18:27,959 [Executor task launch worker for task 223] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 20:18:27,970 [Executor task launch worker for task 223] INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 30.0 (TID 223). 968 bytes result sent to driver
2021-12-03 20:18:27,970 [Executor task launch worker for task 222] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 30.0 (TID 222). 968 bytes result sent to driver
2021-12-03 20:18:27,970 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 30.0 (TID 223) in 12 ms on localhost (executor driver) (1/2)
2021-12-03 20:18:27,971 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 30.0 (TID 222) in 14 ms on localhost (executor driver) (2/2)
2021-12-03 20:18:27,971 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 30.0, whose tasks have all completed, from pool 
2021-12-03 20:18:27,971 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 30 (count at PaidPromotionAdjustParameter.scala:136) finished in 0.016 s
2021-12-03 20:18:27,971 [main] INFO [org.apache.spark.scheduler.DAGScheduler] - Job 15 finished: count at PaidPromotionAdjustParameter.scala:136, took 0.859133 s
2021-12-03 20:18:27,971 [main] INFO [PaidPromotion$] - 训练集节目数 = 131
2021-12-03 20:18:27,974 [main] INFO [org.apache.spark.SparkContext] - Starting job: count at PaidPromotionAdjustParameter.scala:137
2021-12-03 20:18:27,974 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 40 (distinct at PaidPromotionAdjustParameter.scala:129)
2021-12-03 20:18:27,974 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 16 (count at PaidPromotionAdjustParameter.scala:137) with 2 output partitions
2021-12-03 20:18:27,974 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 32 (count at PaidPromotionAdjustParameter.scala:137)
2021-12-03 20:18:27,974 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 31)
2021-12-03 20:18:27,974 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List(ShuffleMapStage 31)
2021-12-03 20:18:27,974 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ShuffleMapStage 31 (MapPartitionsRDD[40] at distinct at PaidPromotionAdjustParameter.scala:129), which has no missing parents
2021-12-03 20:18:27,975 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_25 stored as values in memory (estimated size 5.2 KB, free 1990.0 MB)
2021-12-03 20:18:27,976 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_25_piece0 stored as bytes in memory (estimated size 2.9 KB, free 1990.0 MB)
2021-12-03 20:18:27,976 [dispatcher-event-loop-1] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_25_piece0 in memory on qb:50070 (size: 2.9 KB, free: 1990.7 MB)
2021-12-03 20:18:27,976 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 25 from broadcast at DAGScheduler.scala:1039
2021-12-03 20:18:27,976 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from ShuffleMapStage 31 (MapPartitionsRDD[40] at distinct at PaidPromotionAdjustParameter.scala:129) (first 15 tasks are for partitions Vector(0, 1))
2021-12-03 20:18:27,976 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 31.0 with 2 tasks
2021-12-03 20:18:27,977 [dispatcher-event-loop-5] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 31.0 (TID 224, localhost, executor driver, partition 0, ANY, 7885 bytes)
2021-12-03 20:18:27,977 [dispatcher-event-loop-5] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 31.0 (TID 225, localhost, executor driver, partition 1, ANY, 7885 bytes)
2021-12-03 20:18:27,977 [Executor task launch worker for task 224] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 31.0 (TID 224)
2021-12-03 20:18:27,977 [Executor task launch worker for task 225] INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 31.0 (TID 225)
2021-12-03 20:18:27,977 [Executor task launch worker for task 225] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/order_data.bcp:3442194+3442195
2021-12-03 20:18:27,977 [Executor task launch worker for task 224] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/order_data.bcp:0+3442194
2021-12-03 20:18:28,436 [Executor task launch worker for task 224] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 31.0 (TID 224). 946 bytes result sent to driver
2021-12-03 20:18:28,436 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 31.0 (TID 224) in 459 ms on localhost (executor driver) (1/2)
2021-12-03 20:18:29,151 [Executor task launch worker for task 225] INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 31.0 (TID 225). 946 bytes result sent to driver
2021-12-03 20:18:29,151 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 31.0 (TID 225) in 1174 ms on localhost (executor driver) (2/2)
2021-12-03 20:18:29,151 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 31.0, whose tasks have all completed, from pool 
2021-12-03 20:18:29,151 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ShuffleMapStage 31 (distinct at PaidPromotionAdjustParameter.scala:129) finished in 1.177 s
2021-12-03 20:18:29,151 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - looking for newly runnable stages
2021-12-03 20:18:29,151 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - running: Set()
2021-12-03 20:18:29,151 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - waiting: Set(ResultStage 32)
2021-12-03 20:18:29,151 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - failed: Set()
2021-12-03 20:18:29,151 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 32 (MapPartitionsRDD[42] at distinct at PaidPromotionAdjustParameter.scala:129), which has no missing parents
2021-12-03 20:18:29,152 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_26 stored as values in memory (estimated size 3.7 KB, free 1990.0 MB)
2021-12-03 20:18:29,153 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_26_piece0 stored as bytes in memory (estimated size 2.2 KB, free 1990.0 MB)
2021-12-03 20:18:29,154 [dispatcher-event-loop-0] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_26_piece0 in memory on qb:50070 (size: 2.2 KB, free: 1990.7 MB)
2021-12-03 20:18:29,155 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 26 from broadcast at DAGScheduler.scala:1039
2021-12-03 20:18:29,155 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from ResultStage 32 (MapPartitionsRDD[42] at distinct at PaidPromotionAdjustParameter.scala:129) (first 15 tasks are for partitions Vector(0, 1))
2021-12-03 20:18:29,155 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 32.0 with 2 tasks
2021-12-03 20:18:29,155 [dispatcher-event-loop-10] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 32.0 (TID 226, localhost, executor driver, partition 0, ANY, 7649 bytes)
2021-12-03 20:18:29,155 [dispatcher-event-loop-10] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 32.0 (TID 227, localhost, executor driver, partition 1, ANY, 7649 bytes)
2021-12-03 20:18:29,155 [Executor task launch worker for task 226] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 32.0 (TID 226)
2021-12-03 20:18:29,155 [Executor task launch worker for task 227] INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 32.0 (TID 227)
2021-12-03 20:18:29,156 [Executor task launch worker for task 226] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 2 non-empty blocks out of 2 blocks
2021-12-03 20:18:29,156 [Executor task launch worker for task 227] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 2 non-empty blocks out of 2 blocks
2021-12-03 20:18:29,156 [Executor task launch worker for task 226] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 20:18:29,156 [Executor task launch worker for task 227] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 20:18:29,166 [Executor task launch worker for task 227] INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 32.0 (TID 227). 1053 bytes result sent to driver
2021-12-03 20:18:29,166 [Executor task launch worker for task 226] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 32.0 (TID 226). 1053 bytes result sent to driver
2021-12-03 20:18:29,167 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 32.0 (TID 226) in 12 ms on localhost (executor driver) (1/2)
2021-12-03 20:18:29,167 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 32.0 (TID 227) in 12 ms on localhost (executor driver) (2/2)
2021-12-03 20:18:29,167 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 32.0, whose tasks have all completed, from pool 
2021-12-03 20:18:29,167 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 32 (count at PaidPromotionAdjustParameter.scala:137) finished in 0.015 s
2021-12-03 20:18:29,167 [main] INFO [org.apache.spark.scheduler.DAGScheduler] - Job 16 finished: count at PaidPromotionAdjustParameter.scala:137, took 1.193284 s
2021-12-03 20:18:29,167 [main] INFO [PaidPromotion$] - 验证集节目数 = 104
2021-12-03 20:18:29,169 [main] INFO [org.apache.spark.SparkContext] - Starting job: count at PaidPromotionAdjustParameter.scala:138
2021-12-03 20:18:29,170 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 43 (intersection at PaidPromotionAdjustParameter.scala:130)
2021-12-03 20:18:29,170 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 44 (intersection at PaidPromotionAdjustParameter.scala:130)
2021-12-03 20:18:29,170 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 17 (count at PaidPromotionAdjustParameter.scala:138) with 2 output partitions
2021-12-03 20:18:29,170 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 37 (count at PaidPromotionAdjustParameter.scala:138)
2021-12-03 20:18:29,170 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 34, ShuffleMapStage 36)
2021-12-03 20:18:29,170 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List(ShuffleMapStage 34, ShuffleMapStage 36)
2021-12-03 20:18:29,170 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ShuffleMapStage 34 (MapPartitionsRDD[43] at intersection at PaidPromotionAdjustParameter.scala:130), which has no missing parents
2021-12-03 20:18:29,171 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_27 stored as values in memory (estimated size 4.0 KB, free 1990.0 MB)
2021-12-03 20:18:29,172 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_27_piece0 stored as bytes in memory (estimated size 2.3 KB, free 1990.0 MB)
2021-12-03 20:18:29,173 [dispatcher-event-loop-1] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_27_piece0 in memory on qb:50070 (size: 2.3 KB, free: 1990.7 MB)
2021-12-03 20:18:29,173 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 27 from broadcast at DAGScheduler.scala:1039
2021-12-03 20:18:29,173 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from ShuffleMapStage 34 (MapPartitionsRDD[43] at intersection at PaidPromotionAdjustParameter.scala:130) (first 15 tasks are for partitions Vector(0, 1))
2021-12-03 20:18:29,173 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 34.0 with 2 tasks
2021-12-03 20:18:29,173 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ShuffleMapStage 36 (MapPartitionsRDD[44] at intersection at PaidPromotionAdjustParameter.scala:130), which has no missing parents
2021-12-03 20:18:29,174 [dispatcher-event-loop-5] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 34.0 (TID 228, localhost, executor driver, partition 0, ANY, 7638 bytes)
2021-12-03 20:18:29,174 [dispatcher-event-loop-5] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 34.0 (TID 229, localhost, executor driver, partition 1, ANY, 7638 bytes)
2021-12-03 20:18:29,174 [Executor task launch worker for task 229] INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 34.0 (TID 229)
2021-12-03 20:18:29,174 [Executor task launch worker for task 228] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 34.0 (TID 228)
2021-12-03 20:18:29,174 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_28 stored as values in memory (estimated size 4.0 KB, free 1990.0 MB)
2021-12-03 20:18:29,174 [Executor task launch worker for task 229] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 2 non-empty blocks out of 2 blocks
2021-12-03 20:18:29,174 [Executor task launch worker for task 228] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 2 non-empty blocks out of 2 blocks
2021-12-03 20:18:29,174 [Executor task launch worker for task 229] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 20:18:29,174 [Executor task launch worker for task 228] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 20:18:29,175 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_28_piece0 stored as bytes in memory (estimated size 2.3 KB, free 1990.0 MB)
2021-12-03 20:18:29,176 [dispatcher-event-loop-4] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_28_piece0 in memory on qb:50070 (size: 2.3 KB, free: 1990.7 MB)
2021-12-03 20:18:29,176 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 28 from broadcast at DAGScheduler.scala:1039
2021-12-03 20:18:29,176 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from ShuffleMapStage 36 (MapPartitionsRDD[44] at intersection at PaidPromotionAdjustParameter.scala:130) (first 15 tasks are for partitions Vector(0, 1))
2021-12-03 20:18:29,176 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 36.0 with 2 tasks
2021-12-03 20:18:29,176 [dispatcher-event-loop-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 36.0 (TID 230, localhost, executor driver, partition 0, ANY, 7638 bytes)
2021-12-03 20:18:29,177 [dispatcher-event-loop-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 36.0 (TID 231, localhost, executor driver, partition 1, ANY, 7638 bytes)
2021-12-03 20:18:29,177 [Executor task launch worker for task 230] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 36.0 (TID 230)
2021-12-03 20:18:29,177 [Executor task launch worker for task 231] INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 36.0 (TID 231)
2021-12-03 20:18:29,177 [Executor task launch worker for task 231] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 2 non-empty blocks out of 2 blocks
2021-12-03 20:18:29,177 [Executor task launch worker for task 230] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 2 non-empty blocks out of 2 blocks
2021-12-03 20:18:29,177 [Executor task launch worker for task 230] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 20:18:29,177 [Executor task launch worker for task 231] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 20:18:29,187 [Executor task launch worker for task 229] INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 34.0 (TID 229). 1118 bytes result sent to driver
2021-12-03 20:18:29,187 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 34.0 (TID 229) in 13 ms on localhost (executor driver) (1/2)
2021-12-03 20:18:29,187 [Executor task launch worker for task 228] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 34.0 (TID 228). 1118 bytes result sent to driver
2021-12-03 20:18:29,188 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 34.0 (TID 228) in 15 ms on localhost (executor driver) (2/2)
2021-12-03 20:18:29,188 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 34.0, whose tasks have all completed, from pool 
2021-12-03 20:18:29,188 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ShuffleMapStage 34 (intersection at PaidPromotionAdjustParameter.scala:130) finished in 0.017 s
2021-12-03 20:18:29,188 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - looking for newly runnable stages
2021-12-03 20:18:29,188 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - running: Set(ShuffleMapStage 36)
2021-12-03 20:18:29,188 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - waiting: Set(ResultStage 37)
2021-12-03 20:18:29,188 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - failed: Set()
2021-12-03 20:18:29,189 [Executor task launch worker for task 231] INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 36.0 (TID 231). 1118 bytes result sent to driver
2021-12-03 20:18:29,189 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 36.0 (TID 231) in 13 ms on localhost (executor driver) (1/2)
2021-12-03 20:18:29,190 [Executor task launch worker for task 230] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 36.0 (TID 230). 1118 bytes result sent to driver
2021-12-03 20:18:29,190 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 36.0 (TID 230) in 14 ms on localhost (executor driver) (2/2)
2021-12-03 20:18:29,190 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 36.0, whose tasks have all completed, from pool 
2021-12-03 20:18:29,190 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ShuffleMapStage 36 (intersection at PaidPromotionAdjustParameter.scala:130) finished in 0.016 s
2021-12-03 20:18:29,190 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - looking for newly runnable stages
2021-12-03 20:18:29,190 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - running: Set()
2021-12-03 20:18:29,190 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - waiting: Set(ResultStage 37)
2021-12-03 20:18:29,190 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - failed: Set()
2021-12-03 20:18:29,190 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 37 (MapPartitionsRDD[48] at intersection at PaidPromotionAdjustParameter.scala:130), which has no missing parents
2021-12-03 20:18:29,191 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_29 stored as values in memory (estimated size 3.6 KB, free 1990.0 MB)
2021-12-03 20:18:29,192 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_29_piece0 stored as bytes in memory (estimated size 2.1 KB, free 1989.9 MB)
2021-12-03 20:18:29,192 [dispatcher-event-loop-1] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_29_piece0 in memory on qb:50070 (size: 2.1 KB, free: 1990.7 MB)
2021-12-03 20:18:29,192 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 29 from broadcast at DAGScheduler.scala:1039
2021-12-03 20:18:29,192 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from ResultStage 37 (MapPartitionsRDD[48] at intersection at PaidPromotionAdjustParameter.scala:130) (first 15 tasks are for partitions Vector(0, 1))
2021-12-03 20:18:29,192 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 37.0 with 2 tasks
2021-12-03 20:18:29,193 [dispatcher-event-loop-5] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 37.0 (TID 232, localhost, executor driver, partition 0, PROCESS_LOCAL, 7712 bytes)
2021-12-03 20:18:29,193 [dispatcher-event-loop-5] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 37.0 (TID 233, localhost, executor driver, partition 1, PROCESS_LOCAL, 7712 bytes)
2021-12-03 20:18:29,193 [Executor task launch worker for task 233] INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 37.0 (TID 233)
2021-12-03 20:18:29,193 [Executor task launch worker for task 232] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 37.0 (TID 232)
2021-12-03 20:18:29,194 [Executor task launch worker for task 233] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2021-12-03 20:18:29,194 [Executor task launch worker for task 232] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2021-12-03 20:18:29,194 [Executor task launch worker for task 233] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 20:18:29,194 [Executor task launch worker for task 232] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 20:18:29,195 [Executor task launch worker for task 232] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2021-12-03 20:18:29,195 [Executor task launch worker for task 233] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2021-12-03 20:18:29,195 [Executor task launch worker for task 232] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 20:18:29,195 [Executor task launch worker for task 233] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 20:18:29,199 [Executor task launch worker for task 232] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 37.0 (TID 232). 967 bytes result sent to driver
2021-12-03 20:18:29,199 [Executor task launch worker for task 233] INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 37.0 (TID 233). 967 bytes result sent to driver
2021-12-03 20:18:29,199 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 37.0 (TID 232) in 6 ms on localhost (executor driver) (1/2)
2021-12-03 20:18:29,199 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 37.0 (TID 233) in 6 ms on localhost (executor driver) (2/2)
2021-12-03 20:18:29,199 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 37.0, whose tasks have all completed, from pool 
2021-12-03 20:18:29,199 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 37 (count at PaidPromotionAdjustParameter.scala:138) finished in 0.009 s
2021-12-03 20:18:29,200 [main] INFO [org.apache.spark.scheduler.DAGScheduler] - Job 17 finished: count at PaidPromotionAdjustParameter.scala:138, took 0.030063 s
2021-12-03 20:18:29,200 [main] INFO [PaidPromotion$] - 共 同 节目数 = 103
2021-12-03 20:18:29,205 [main] INFO [org.apache.spark.SparkContext] - Starting job: collect at PaidPromotionAdjustParameter.scala:141
2021-12-03 20:18:29,205 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 18 (collect at PaidPromotionAdjustParameter.scala:141) with 2 output partitions
2021-12-03 20:18:29,205 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 42 (collect at PaidPromotionAdjustParameter.scala:141)
2021-12-03 20:18:29,205 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 39, ShuffleMapStage 41)
2021-12-03 20:18:29,205 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2021-12-03 20:18:29,205 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 42 (MapPartitionsRDD[34] at intersection at PaidPromotionAdjustParameter.scala:125), which has no missing parents
2021-12-03 20:18:29,206 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_30 stored as values in memory (estimated size 3.8 KB, free 1989.9 MB)
2021-12-03 20:18:29,207 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_30_piece0 stored as bytes in memory (estimated size 2.2 KB, free 1989.9 MB)
2021-12-03 20:18:29,207 [dispatcher-event-loop-0] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_30_piece0 in memory on qb:50070 (size: 2.2 KB, free: 1990.7 MB)
2021-12-03 20:18:29,207 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 30 from broadcast at DAGScheduler.scala:1039
2021-12-03 20:18:29,208 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from ResultStage 42 (MapPartitionsRDD[34] at intersection at PaidPromotionAdjustParameter.scala:125) (first 15 tasks are for partitions Vector(0, 1))
2021-12-03 20:18:29,208 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 42.0 with 2 tasks
2021-12-03 20:18:29,208 [dispatcher-event-loop-10] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 42.0 (TID 234, localhost, executor driver, partition 0, PROCESS_LOCAL, 7712 bytes)
2021-12-03 20:18:29,208 [dispatcher-event-loop-10] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 42.0 (TID 235, localhost, executor driver, partition 1, PROCESS_LOCAL, 7712 bytes)
2021-12-03 20:18:29,208 [Executor task launch worker for task 234] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 42.0 (TID 234)
2021-12-03 20:18:29,208 [Executor task launch worker for task 235] INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 42.0 (TID 235)
2021-12-03 20:18:29,209 [Executor task launch worker for task 235] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2021-12-03 20:18:29,209 [Executor task launch worker for task 234] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2021-12-03 20:18:29,209 [Executor task launch worker for task 235] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 20:18:29,209 [Executor task launch worker for task 234] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 20:18:29,210 [Executor task launch worker for task 235] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2021-12-03 20:18:29,210 [Executor task launch worker for task 234] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2021-12-03 20:18:29,210 [Executor task launch worker for task 235] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 20:18:29,210 [Executor task launch worker for task 234] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 20:18:29,274 [Executor task launch worker for task 234] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 42.0 (TID 234). 54818 bytes result sent to driver
2021-12-03 20:18:29,274 [Executor task launch worker for task 235] INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 42.0 (TID 235). 55052 bytes result sent to driver
2021-12-03 20:18:29,275 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 42.0 (TID 234) in 67 ms on localhost (executor driver) (1/2)
2021-12-03 20:18:29,275 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 42.0 (TID 235) in 67 ms on localhost (executor driver) (2/2)
2021-12-03 20:18:29,275 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 42.0, whose tasks have all completed, from pool 
2021-12-03 20:18:29,276 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 42 (collect at PaidPromotionAdjustParameter.scala:141) finished in 0.069 s
2021-12-03 20:18:29,276 [main] INFO [org.apache.spark.scheduler.DAGScheduler] - Job 18 finished: collect at PaidPromotionAdjustParameter.scala:141, took 0.070767 s
2021-12-03 20:18:29,279 [main] INFO [org.apache.spark.SparkContext] - Starting job: collect at PaidPromotionAdjustParameter.scala:142
2021-12-03 20:18:29,279 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 19 (collect at PaidPromotionAdjustParameter.scala:142) with 2 output partitions
2021-12-03 20:18:29,279 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 47 (collect at PaidPromotionAdjustParameter.scala:142)
2021-12-03 20:18:29,279 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 46, ShuffleMapStage 44)
2021-12-03 20:18:29,279 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2021-12-03 20:18:29,280 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 47 (MapPartitionsRDD[48] at intersection at PaidPromotionAdjustParameter.scala:130), which has no missing parents
2021-12-03 20:18:29,280 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_31 stored as values in memory (estimated size 3.8 KB, free 1989.9 MB)
2021-12-03 20:18:29,282 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_31_piece0 stored as bytes in memory (estimated size 2.2 KB, free 1989.9 MB)
2021-12-03 20:18:29,282 [dispatcher-event-loop-1] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_31_piece0 in memory on qb:50070 (size: 2.2 KB, free: 1990.7 MB)
2021-12-03 20:18:29,282 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 31 from broadcast at DAGScheduler.scala:1039
2021-12-03 20:18:29,282 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from ResultStage 47 (MapPartitionsRDD[48] at intersection at PaidPromotionAdjustParameter.scala:130) (first 15 tasks are for partitions Vector(0, 1))
2021-12-03 20:18:29,282 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 47.0 with 2 tasks
2021-12-03 20:18:29,283 [dispatcher-event-loop-5] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 47.0 (TID 236, localhost, executor driver, partition 0, PROCESS_LOCAL, 7712 bytes)
2021-12-03 20:18:29,283 [dispatcher-event-loop-5] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 47.0 (TID 237, localhost, executor driver, partition 1, PROCESS_LOCAL, 7712 bytes)
2021-12-03 20:18:29,283 [Executor task launch worker for task 236] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 47.0 (TID 236)
2021-12-03 20:18:29,283 [Executor task launch worker for task 237] INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 47.0 (TID 237)
2021-12-03 20:18:29,284 [Executor task launch worker for task 237] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2021-12-03 20:18:29,284 [Executor task launch worker for task 236] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2021-12-03 20:18:29,284 [Executor task launch worker for task 237] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 20:18:29,284 [Executor task launch worker for task 236] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 20:18:29,285 [Executor task launch worker for task 237] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2021-12-03 20:18:29,285 [Executor task launch worker for task 237] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 20:18:29,285 [Executor task launch worker for task 236] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2021-12-03 20:18:29,285 [Executor task launch worker for task 236] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 20:18:29,288 [Executor task launch worker for task 237] INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 47.0 (TID 237). 2460 bytes result sent to driver
2021-12-03 20:18:29,288 [Executor task launch worker for task 236] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 47.0 (TID 236). 2691 bytes result sent to driver
2021-12-03 20:18:29,289 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 47.0 (TID 237) in 6 ms on localhost (executor driver) (1/2)
2021-12-03 20:18:29,289 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 47.0 (TID 236) in 6 ms on localhost (executor driver) (2/2)
2021-12-03 20:18:29,289 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 47.0, whose tasks have all completed, from pool 
2021-12-03 20:18:29,289 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 47 (collect at PaidPromotionAdjustParameter.scala:142) finished in 0.009 s
2021-12-03 20:18:29,289 [main] INFO [org.apache.spark.scheduler.DAGScheduler] - Job 19 finished: collect at PaidPromotionAdjustParameter.scala:142, took 0.010097 s
2021-12-03 20:18:29,304 [main] INFO [org.apache.spark.SparkContext] - Starting job: count at PaidPromotionAdjustParameter.scala:151
2021-12-03 20:18:29,305 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 20 (count at PaidPromotionAdjustParameter.scala:151) with 4 output partitions
2021-12-03 20:18:29,305 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 48 (count at PaidPromotionAdjustParameter.scala:151)
2021-12-03 20:18:29,305 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List()
2021-12-03 20:18:29,305 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2021-12-03 20:18:29,306 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 48 (UnionRDD[51] at union at PaidPromotionAdjustParameter.scala:149), which has no missing parents
2021-12-03 20:18:29,309 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_32 stored as values in memory (estimated size 118.6 KB, free 1989.8 MB)
2021-12-03 20:18:29,310 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_32_piece0 stored as bytes in memory (estimated size 42.5 KB, free 1989.8 MB)
2021-12-03 20:18:29,311 [dispatcher-event-loop-0] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_32_piece0 in memory on qb:50070 (size: 42.5 KB, free: 1990.6 MB)
2021-12-03 20:18:29,311 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 32 from broadcast at DAGScheduler.scala:1039
2021-12-03 20:18:29,311 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 4 missing tasks from ResultStage 48 (UnionRDD[51] at union at PaidPromotionAdjustParameter.scala:149) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
2021-12-03 20:18:29,311 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 48.0 with 4 tasks
2021-12-03 20:18:29,314 [dispatcher-event-loop-10] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 48.0 (TID 238, localhost, executor driver, partition 0, ANY, 8005 bytes)
2021-12-03 20:18:29,314 [dispatcher-event-loop-10] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 48.0 (TID 239, localhost, executor driver, partition 1, ANY, 8005 bytes)
2021-12-03 20:18:29,314 [dispatcher-event-loop-10] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 2.0 in stage 48.0 (TID 240, localhost, executor driver, partition 2, ANY, 8005 bytes)
2021-12-03 20:18:29,314 [dispatcher-event-loop-10] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 3.0 in stage 48.0 (TID 241, localhost, executor driver, partition 3, ANY, 8005 bytes)
2021-12-03 20:18:29,314 [Executor task launch worker for task 238] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 48.0 (TID 238)
2021-12-03 20:18:29,314 [Executor task launch worker for task 240] INFO [org.apache.spark.executor.Executor] - Running task 2.0 in stage 48.0 (TID 240)
2021-12-03 20:18:29,314 [Executor task launch worker for task 239] INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 48.0 (TID 239)
2021-12-03 20:18:29,314 [Executor task launch worker for task 241] INFO [org.apache.spark.executor.Executor] - Running task 3.0 in stage 48.0 (TID 241)
2021-12-03 20:18:29,316 [Executor task launch worker for task 239] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/order_data.bcp:3442194+3442195
2021-12-03 20:18:29,316 [Executor task launch worker for task 241] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/order_data.bcp:3442194+3442195
2021-12-03 20:18:29,316 [Executor task launch worker for task 240] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/order_data.bcp:0+3442194
2021-12-03 20:18:29,316 [Executor task launch worker for task 238] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/order_data.bcp:0+3442194
2021-12-03 20:18:29,430 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 704
2021-12-03 20:18:29,430 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 528
2021-12-03 20:18:29,431 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 665
2021-12-03 20:18:29,431 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 686
2021-12-03 20:18:29,431 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 532
2021-12-03 20:18:29,431 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 745
2021-12-03 20:18:29,431 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 743
2021-12-03 20:18:29,431 [dispatcher-event-loop-6] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_27_piece0 on qb:50070 in memory (size: 2.3 KB, free: 1990.6 MB)
2021-12-03 20:18:29,431 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 696
2021-12-03 20:18:29,431 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 542
2021-12-03 20:18:29,431 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 675
2021-12-03 20:18:29,431 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 678
2021-12-03 20:18:29,431 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 742
2021-12-03 20:18:29,431 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 699
2021-12-03 20:18:29,432 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 655
2021-12-03 20:18:29,432 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 701
2021-12-03 20:18:29,432 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 727
2021-12-03 20:18:29,432 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 739
2021-12-03 20:18:29,432 [dispatcher-event-loop-2] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_31_piece0 on qb:50070 in memory (size: 2.2 KB, free: 1990.6 MB)
2021-12-03 20:18:29,432 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 535
2021-12-03 20:18:29,432 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 717
2021-12-03 20:18:29,432 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 749
2021-12-03 20:18:29,432 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 657
2021-12-03 20:18:29,432 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 628
2021-12-03 20:18:29,432 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 680
2021-12-03 20:18:29,432 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 549
2021-12-03 20:18:29,432 [dispatcher-event-loop-9] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_28_piece0 on qb:50070 in memory (size: 2.3 KB, free: 1990.6 MB)
2021-12-03 20:18:29,433 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 529
2021-12-03 20:18:29,433 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 544
2021-12-03 20:18:29,433 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 561
2021-12-03 20:18:29,433 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 693
2021-12-03 20:18:29,433 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 652
2021-12-03 20:18:29,433 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 692
2021-12-03 20:18:29,433 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 726
2021-12-03 20:18:29,433 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 555
2021-12-03 20:18:29,433 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 610
2021-12-03 20:18:29,433 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 645
2021-12-03 20:18:29,433 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 689
2021-12-03 20:18:29,433 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 673
2021-12-03 20:18:29,433 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 566
2021-12-03 20:18:29,433 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 670
2021-12-03 20:18:29,433 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 602
2021-12-03 20:18:29,433 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 630
2021-12-03 20:18:29,433 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 588
2021-12-03 20:18:29,433 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 541
2021-12-03 20:18:29,433 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 654
2021-12-03 20:18:29,433 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 725
2021-12-03 20:18:29,433 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 537
2021-12-03 20:18:29,433 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 677
2021-12-03 20:18:29,433 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 648
2021-12-03 20:18:29,433 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 685
2021-12-03 20:18:29,433 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 737
2021-12-03 20:18:29,433 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 560
2021-12-03 20:18:29,433 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 649
2021-12-03 20:18:29,433 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 548
2021-12-03 20:18:29,433 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 669
2021-12-03 20:18:29,433 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 551
2021-12-03 20:18:29,433 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 599
2021-12-03 20:18:29,433 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 646
2021-12-03 20:18:29,433 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 698
2021-12-03 20:18:29,433 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 626
2021-12-03 20:18:29,433 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 644
2021-12-03 20:18:29,433 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 581
2021-12-03 20:18:29,433 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 664
2021-12-03 20:18:29,433 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 567
2021-12-03 20:18:29,433 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 719
2021-12-03 20:18:29,434 [dispatcher-event-loop-8] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_30_piece0 on qb:50070 in memory (size: 2.2 KB, free: 1990.7 MB)
2021-12-03 20:18:29,434 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 600
2021-12-03 20:18:29,434 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 553
2021-12-03 20:18:29,434 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 592
2021-12-03 20:18:29,434 [dispatcher-event-loop-6] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_26_piece0 on qb:50070 in memory (size: 2.2 KB, free: 1990.7 MB)
2021-12-03 20:18:29,435 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 747
2021-12-03 20:18:29,435 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 716
2021-12-03 20:18:29,435 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 611
2021-12-03 20:18:29,435 [dispatcher-event-loop-2] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_24_piece0 on qb:50070 in memory (size: 2.2 KB, free: 1990.7 MB)
2021-12-03 20:18:29,435 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 679
2021-12-03 20:18:29,435 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 622
2021-12-03 20:18:29,435 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 572
2021-12-03 20:18:29,435 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 533
2021-12-03 20:18:29,435 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 700
2021-12-03 20:18:29,435 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 636
2021-12-03 20:18:29,435 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 647
2021-12-03 20:18:29,435 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 740
2021-12-03 20:18:29,435 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 536
2021-12-03 20:18:29,435 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 707
2021-12-03 20:18:29,435 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 589
2021-12-03 20:18:29,435 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 586
2021-12-03 20:18:29,435 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 593
2021-12-03 20:18:29,435 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 546
2021-12-03 20:18:29,435 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 651
2021-12-03 20:18:29,435 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 577
2021-12-03 20:18:29,436 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 606
2021-12-03 20:18:29,436 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 538
2021-12-03 20:18:29,436 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 653
2021-12-03 20:18:29,436 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 590
2021-12-03 20:18:29,436 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 609
2021-12-03 20:18:29,436 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 582
2021-12-03 20:18:29,436 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 658
2021-12-03 20:18:29,436 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 557
2021-12-03 20:18:29,436 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 570
2021-12-03 20:18:29,436 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 619
2021-12-03 20:18:29,436 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 573
2021-12-03 20:18:29,436 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 667
2021-12-03 20:18:29,436 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 660
2021-12-03 20:18:29,436 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 642
2021-12-03 20:18:29,436 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 641
2021-12-03 20:18:29,436 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 744
2021-12-03 20:18:29,436 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 585
2021-12-03 20:18:29,436 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 534
2021-12-03 20:18:29,436 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 732
2021-12-03 20:18:29,436 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 584
2021-12-03 20:18:29,436 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 603
2021-12-03 20:18:29,436 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 722
2021-12-03 20:18:29,436 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 530
2021-12-03 20:18:29,436 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 616
2021-12-03 20:18:29,436 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 629
2021-12-03 20:18:29,436 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 731
2021-12-03 20:18:29,436 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 705
2021-12-03 20:18:29,436 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 525
2021-12-03 20:18:29,436 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 668
2021-12-03 20:18:29,436 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 695
2021-12-03 20:18:29,436 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 702
2021-12-03 20:18:29,436 [dispatcher-event-loop-9] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_23_piece0 on qb:50070 in memory (size: 2.9 KB, free: 1990.7 MB)
2021-12-03 20:18:29,436 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 638
2021-12-03 20:18:29,436 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 565
2021-12-03 20:18:29,436 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 661
2021-12-03 20:18:29,436 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 729
2021-12-03 20:18:29,436 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 650
2021-12-03 20:18:29,436 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 671
2021-12-03 20:18:29,436 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 676
2021-12-03 20:18:29,436 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 564
2021-12-03 20:18:29,436 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 614
2021-12-03 20:18:29,436 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 625
2021-12-03 20:18:29,437 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 608
2021-12-03 20:18:29,437 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 643
2021-12-03 20:18:29,437 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 631
2021-12-03 20:18:29,437 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 720
2021-12-03 20:18:29,437 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 733
2021-12-03 20:18:29,437 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 612
2021-12-03 20:18:29,437 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 706
2021-12-03 20:18:29,437 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 713
2021-12-03 20:18:29,437 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 574
2021-12-03 20:18:29,437 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 674
2021-12-03 20:18:29,437 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 721
2021-12-03 20:18:29,437 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 598
2021-12-03 20:18:29,437 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 562
2021-12-03 20:18:29,437 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 576
2021-12-03 20:18:29,437 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 633
2021-12-03 20:18:29,437 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 738
2021-12-03 20:18:29,437 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 688
2021-12-03 20:18:29,437 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 601
2021-12-03 20:18:29,437 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 594
2021-12-03 20:18:29,437 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 615
2021-12-03 20:18:29,437 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 563
2021-12-03 20:18:29,437 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 547
2021-12-03 20:18:29,437 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 728
2021-12-03 20:18:29,437 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 703
2021-12-03 20:18:29,437 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 579
2021-12-03 20:18:29,437 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 617
2021-12-03 20:18:29,437 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 746
2021-12-03 20:18:29,437 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 550
2021-12-03 20:18:29,437 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 587
2021-12-03 20:18:29,437 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 734
2021-12-03 20:18:29,437 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 591
2021-12-03 20:18:29,437 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 552
2021-12-03 20:18:29,437 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 712
2021-12-03 20:18:29,437 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 578
2021-12-03 20:18:29,437 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 735
2021-12-03 20:18:29,437 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 621
2021-12-03 20:18:29,437 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 596
2021-12-03 20:18:29,437 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 613
2021-12-03 20:18:29,437 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 527
2021-12-03 20:18:29,437 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 559
2021-12-03 20:18:29,437 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 663
2021-12-03 20:18:29,437 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 595
2021-12-03 20:18:29,437 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 715
2021-12-03 20:18:29,437 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 575
2021-12-03 20:18:29,437 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 723
2021-12-03 20:18:29,437 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 736
2021-12-03 20:18:29,437 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 659
2021-12-03 20:18:29,437 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 554
2021-12-03 20:18:29,437 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 656
2021-12-03 20:18:29,437 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 558
2021-12-03 20:18:29,437 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 556
2021-12-03 20:18:29,437 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 545
2021-12-03 20:18:29,437 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 697
2021-12-03 20:18:29,437 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 681
2021-12-03 20:18:29,437 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 748
2021-12-03 20:18:29,437 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 634
2021-12-03 20:18:29,437 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 531
2021-12-03 20:18:29,437 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 708
2021-12-03 20:18:29,437 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 627
2021-12-03 20:18:29,437 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 604
2021-12-03 20:18:29,437 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 711
2021-12-03 20:18:29,437 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 583
2021-12-03 20:18:29,437 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 666
2021-12-03 20:18:29,437 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 632
2021-12-03 20:18:29,437 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 620
2021-12-03 20:18:29,437 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 724
2021-12-03 20:18:29,437 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 640
2021-12-03 20:18:29,437 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 709
2021-12-03 20:18:29,437 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 568
2021-12-03 20:18:29,437 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 718
2021-12-03 20:18:29,437 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 637
2021-12-03 20:18:29,437 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 624
2021-12-03 20:18:29,437 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 607
2021-12-03 20:18:29,437 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 543
2021-12-03 20:18:29,437 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 597
2021-12-03 20:18:29,437 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 672
2021-12-03 20:18:29,437 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 714
2021-12-03 20:18:29,437 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 730
2021-12-03 20:18:29,437 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 682
2021-12-03 20:18:29,437 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 580
2021-12-03 20:18:29,438 [dispatcher-event-loop-8] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_25_piece0 on qb:50070 in memory (size: 2.9 KB, free: 1990.7 MB)
2021-12-03 20:18:29,438 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 571
2021-12-03 20:18:29,438 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 618
2021-12-03 20:18:29,438 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 639
2021-12-03 20:18:29,438 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 690
2021-12-03 20:18:29,438 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 526
2021-12-03 20:18:29,438 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 569
2021-12-03 20:18:29,438 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 635
2021-12-03 20:18:29,438 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 694
2021-12-03 20:18:29,438 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 691
2021-12-03 20:18:29,438 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 741
2021-12-03 20:18:29,438 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 662
2021-12-03 20:18:29,438 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 684
2021-12-03 20:18:29,438 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 687
2021-12-03 20:18:29,438 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 540
2021-12-03 20:18:29,438 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 605
2021-12-03 20:18:29,438 [dispatcher-event-loop-6] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_29_piece0 on qb:50070 in memory (size: 2.1 KB, free: 1990.7 MB)
2021-12-03 20:18:29,439 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 683
2021-12-03 20:18:29,439 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 710
2021-12-03 20:18:29,439 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 539
2021-12-03 20:18:29,439 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 623
2021-12-03 20:18:30,006 [Executor task launch worker for task 241] INFO [org.apache.spark.executor.Executor] - Finished task 3.0 in stage 48.0 (TID 241). 797 bytes result sent to driver
2021-12-03 20:18:30,006 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 3.0 in stage 48.0 (TID 241) in 692 ms on localhost (executor driver) (1/4)
2021-12-03 20:18:30,642 [Executor task launch worker for task 238] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 48.0 (TID 238). 797 bytes result sent to driver
2021-12-03 20:18:30,642 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 48.0 (TID 238) in 1330 ms on localhost (executor driver) (2/4)
2021-12-03 20:18:30,664 [Executor task launch worker for task 240] INFO [org.apache.spark.executor.Executor] - Finished task 2.0 in stage 48.0 (TID 240). 797 bytes result sent to driver
2021-12-03 20:18:30,664 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 2.0 in stage 48.0 (TID 240) in 1350 ms on localhost (executor driver) (3/4)
2021-12-03 20:18:31,062 [Executor task launch worker for task 239] INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 48.0 (TID 239). 796 bytes result sent to driver
2021-12-03 20:18:31,062 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 48.0 (TID 239) in 1748 ms on localhost (executor driver) (4/4)
2021-12-03 20:18:31,062 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 48.0, whose tasks have all completed, from pool 
2021-12-03 20:18:31,062 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 48 (count at PaidPromotionAdjustParameter.scala:151) finished in 1.756 s
2021-12-03 20:18:31,062 [main] INFO [org.apache.spark.scheduler.DAGScheduler] - Job 20 finished: count at PaidPromotionAdjustParameter.scala:151, took 1.758577 s
2021-12-03 20:18:31,063 [main] INFO [PaidPromotion$] - 最终训练集数量：103796
2021-12-03 20:18:31,064 [main] INFO [org.apache.spark.SparkContext] - Starting job: count at PaidPromotionAdjustParameter.scala:152
2021-12-03 20:18:31,064 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 21 (count at PaidPromotionAdjustParameter.scala:152) with 2 output partitions
2021-12-03 20:18:31,064 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 49 (count at PaidPromotionAdjustParameter.scala:152)
2021-12-03 20:18:31,064 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List()
2021-12-03 20:18:31,064 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2021-12-03 20:18:31,065 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 49 (MapPartitionsRDD[49] at filter at PaidPromotionAdjustParameter.scala:145), which has no missing parents
2021-12-03 20:18:31,066 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_33 stored as values in memory (estimated size 118.0 KB, free 1989.7 MB)
2021-12-03 20:18:31,067 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_33_piece0 stored as bytes in memory (estimated size 42.1 KB, free 1989.7 MB)
2021-12-03 20:18:31,067 [dispatcher-event-loop-10] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_33_piece0 in memory on qb:50070 (size: 42.1 KB, free: 1990.6 MB)
2021-12-03 20:18:31,067 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 33 from broadcast at DAGScheduler.scala:1039
2021-12-03 20:18:31,067 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from ResultStage 49 (MapPartitionsRDD[49] at filter at PaidPromotionAdjustParameter.scala:145) (first 15 tasks are for partitions Vector(0, 1))
2021-12-03 20:18:31,067 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 49.0 with 2 tasks
2021-12-03 20:18:31,068 [dispatcher-event-loop-9] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 49.0 (TID 242, localhost, executor driver, partition 0, ANY, 7896 bytes)
2021-12-03 20:18:31,068 [dispatcher-event-loop-9] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 49.0 (TID 243, localhost, executor driver, partition 1, ANY, 7896 bytes)
2021-12-03 20:18:31,068 [Executor task launch worker for task 242] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 49.0 (TID 242)
2021-12-03 20:18:31,068 [Executor task launch worker for task 243] INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 49.0 (TID 243)
2021-12-03 20:18:31,069 [Executor task launch worker for task 243] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/order_data.bcp:3442194+3442195
2021-12-03 20:18:31,069 [Executor task launch worker for task 242] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/order_data.bcp:0+3442194
2021-12-03 20:18:31,447 [Executor task launch worker for task 242] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 49.0 (TID 242). 710 bytes result sent to driver
2021-12-03 20:18:31,447 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 49.0 (TID 242) in 379 ms on localhost (executor driver) (1/2)
2021-12-03 20:18:32,211 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 758
2021-12-03 20:18:32,211 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 762
2021-12-03 20:18:32,211 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 755
2021-12-03 20:18:32,211 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 753
2021-12-03 20:18:32,211 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 771
2021-12-03 20:18:32,211 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 765
2021-12-03 20:18:32,211 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 754
2021-12-03 20:18:32,211 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 774
2021-12-03 20:18:32,211 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 767
2021-12-03 20:18:32,211 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 750
2021-12-03 20:18:32,211 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 756
2021-12-03 20:18:32,212 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 751
2021-12-03 20:18:32,212 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 764
2021-12-03 20:18:32,212 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 769
2021-12-03 20:18:32,212 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 759
2021-12-03 20:18:32,212 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 763
2021-12-03 20:18:32,212 [dispatcher-event-loop-6] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_32_piece0 on qb:50070 in memory (size: 42.5 KB, free: 1990.7 MB)
2021-12-03 20:18:32,213 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 757
2021-12-03 20:18:32,213 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 772
2021-12-03 20:18:32,213 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 761
2021-12-03 20:18:32,213 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 760
2021-12-03 20:18:32,213 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 768
2021-12-03 20:18:32,213 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 752
2021-12-03 20:18:32,213 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 766
2021-12-03 20:18:32,213 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 770
2021-12-03 20:18:32,213 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 773
2021-12-03 20:18:32,623 [Executor task launch worker for task 243] INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 49.0 (TID 243). 753 bytes result sent to driver
2021-12-03 20:18:32,624 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 49.0 (TID 243) in 1556 ms on localhost (executor driver) (2/2)
2021-12-03 20:18:32,624 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 49.0, whose tasks have all completed, from pool 
2021-12-03 20:18:32,624 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 49 (count at PaidPromotionAdjustParameter.scala:152) finished in 1.559 s
2021-12-03 20:18:32,624 [main] INFO [org.apache.spark.scheduler.DAGScheduler] - Job 21 finished: count at PaidPromotionAdjustParameter.scala:152, took 1.559219 s
2021-12-03 20:18:32,624 [main] INFO [PaidPromotion$] - 最终验证集数量：3498
2021-12-03 20:18:32,653 [main] INFO [PaidPromotion$] - -----------------------------------
2021-12-03 20:18:32,654 [main] INFO [org.apache.spark.SparkContext] - Starting job: count at PaidPromotionAdjustParameter.scala:164
2021-12-03 20:18:32,654 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 53 (distinct at PaidPromotionAdjustParameter.scala:155)
2021-12-03 20:18:32,654 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 22 (count at PaidPromotionAdjustParameter.scala:164) with 4 output partitions
2021-12-03 20:18:32,654 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 51 (count at PaidPromotionAdjustParameter.scala:164)
2021-12-03 20:18:32,654 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 50)
2021-12-03 20:18:32,654 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List(ShuffleMapStage 50)
2021-12-03 20:18:32,655 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ShuffleMapStage 50 (MapPartitionsRDD[53] at distinct at PaidPromotionAdjustParameter.scala:155), which has no missing parents
2021-12-03 20:18:32,656 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_34 stored as values in memory (estimated size 120.1 KB, free 1989.7 MB)
2021-12-03 20:18:32,657 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_34_piece0 stored as bytes in memory (estimated size 43.4 KB, free 1989.7 MB)
2021-12-03 20:18:32,657 [dispatcher-event-loop-4] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_34_piece0 in memory on qb:50070 (size: 43.4 KB, free: 1990.6 MB)
2021-12-03 20:18:32,657 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 34 from broadcast at DAGScheduler.scala:1039
2021-12-03 20:18:32,658 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 4 missing tasks from ShuffleMapStage 50 (MapPartitionsRDD[53] at distinct at PaidPromotionAdjustParameter.scala:155) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
2021-12-03 20:18:32,658 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 50.0 with 4 tasks
2021-12-03 20:18:32,658 [dispatcher-event-loop-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 50.0 (TID 244, localhost, executor driver, partition 0, ANY, 7994 bytes)
2021-12-03 20:18:32,658 [dispatcher-event-loop-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 50.0 (TID 245, localhost, executor driver, partition 1, ANY, 7994 bytes)
2021-12-03 20:18:32,658 [dispatcher-event-loop-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 2.0 in stage 50.0 (TID 246, localhost, executor driver, partition 2, ANY, 7994 bytes)
2021-12-03 20:18:32,658 [dispatcher-event-loop-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 3.0 in stage 50.0 (TID 247, localhost, executor driver, partition 3, ANY, 7994 bytes)
2021-12-03 20:18:32,658 [Executor task launch worker for task 244] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 50.0 (TID 244)
2021-12-03 20:18:32,658 [Executor task launch worker for task 246] INFO [org.apache.spark.executor.Executor] - Running task 2.0 in stage 50.0 (TID 246)
2021-12-03 20:18:32,658 [Executor task launch worker for task 245] INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 50.0 (TID 245)
2021-12-03 20:18:32,658 [Executor task launch worker for task 247] INFO [org.apache.spark.executor.Executor] - Running task 3.0 in stage 50.0 (TID 247)
2021-12-03 20:18:32,660 [Executor task launch worker for task 245] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/order_data.bcp:3442194+3442195
2021-12-03 20:18:32,660 [Executor task launch worker for task 244] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/order_data.bcp:0+3442194
2021-12-03 20:18:32,660 [Executor task launch worker for task 246] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/order_data.bcp:0+3442194
2021-12-03 20:18:32,660 [Executor task launch worker for task 247] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/order_data.bcp:3442194+3442195
2021-12-03 20:18:33,435 [Executor task launch worker for task 247] INFO [org.apache.spark.executor.Executor] - Finished task 3.0 in stage 50.0 (TID 247). 991 bytes result sent to driver
2021-12-03 20:18:33,435 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 3.0 in stage 50.0 (TID 247) in 777 ms on localhost (executor driver) (1/4)
2021-12-03 20:18:33,556 [Executor task launch worker for task 244] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 50.0 (TID 244). 991 bytes result sent to driver
2021-12-03 20:18:33,557 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 50.0 (TID 244) in 899 ms on localhost (executor driver) (2/4)
2021-12-03 20:18:33,726 [Executor task launch worker for task 246] INFO [org.apache.spark.executor.Executor] - Finished task 2.0 in stage 50.0 (TID 246). 991 bytes result sent to driver
2021-12-03 20:18:33,726 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 2.0 in stage 50.0 (TID 246) in 1068 ms on localhost (executor driver) (3/4)
2021-12-03 20:18:35,105 [Executor task launch worker for task 245] INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 50.0 (TID 245). 991 bytes result sent to driver
2021-12-03 20:18:35,105 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 50.0 (TID 245) in 2447 ms on localhost (executor driver) (4/4)
2021-12-03 20:18:35,105 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 50.0, whose tasks have all completed, from pool 
2021-12-03 20:18:35,106 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ShuffleMapStage 50 (distinct at PaidPromotionAdjustParameter.scala:155) finished in 2.450 s
2021-12-03 20:18:35,106 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - looking for newly runnable stages
2021-12-03 20:18:35,106 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - running: Set()
2021-12-03 20:18:35,106 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - waiting: Set(ResultStage 51)
2021-12-03 20:18:35,106 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - failed: Set()
2021-12-03 20:18:35,106 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 51 (MapPartitionsRDD[55] at distinct at PaidPromotionAdjustParameter.scala:155), which has no missing parents
2021-12-03 20:18:35,106 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_35 stored as values in memory (estimated size 3.7 KB, free 1989.7 MB)
2021-12-03 20:18:35,108 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_35_piece0 stored as bytes in memory (estimated size 2.2 KB, free 1989.7 MB)
2021-12-03 20:18:35,108 [dispatcher-event-loop-6] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_35_piece0 in memory on qb:50070 (size: 2.2 KB, free: 1990.6 MB)
2021-12-03 20:18:35,108 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 35 from broadcast at DAGScheduler.scala:1039
2021-12-03 20:18:35,108 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 4 missing tasks from ResultStage 51 (MapPartitionsRDD[55] at distinct at PaidPromotionAdjustParameter.scala:155) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
2021-12-03 20:18:35,108 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 51.0 with 4 tasks
2021-12-03 20:18:35,108 [dispatcher-event-loop-11] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 51.0 (TID 248, localhost, executor driver, partition 0, ANY, 7649 bytes)
2021-12-03 20:18:35,109 [dispatcher-event-loop-11] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 51.0 (TID 249, localhost, executor driver, partition 1, ANY, 7649 bytes)
2021-12-03 20:18:35,109 [dispatcher-event-loop-11] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 2.0 in stage 51.0 (TID 250, localhost, executor driver, partition 2, ANY, 7649 bytes)
2021-12-03 20:18:35,109 [dispatcher-event-loop-11] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 3.0 in stage 51.0 (TID 251, localhost, executor driver, partition 3, ANY, 7649 bytes)
2021-12-03 20:18:35,109 [Executor task launch worker for task 250] INFO [org.apache.spark.executor.Executor] - Running task 2.0 in stage 51.0 (TID 250)
2021-12-03 20:18:35,109 [Executor task launch worker for task 248] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 51.0 (TID 248)
2021-12-03 20:18:35,109 [Executor task launch worker for task 251] INFO [org.apache.spark.executor.Executor] - Running task 3.0 in stage 51.0 (TID 251)
2021-12-03 20:18:35,109 [Executor task launch worker for task 249] INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 51.0 (TID 249)
2021-12-03 20:18:35,109 [Executor task launch worker for task 251] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 4 non-empty blocks out of 4 blocks
2021-12-03 20:18:35,109 [Executor task launch worker for task 248] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 4 non-empty blocks out of 4 blocks
2021-12-03 20:18:35,110 [Executor task launch worker for task 251] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 1 ms
2021-12-03 20:18:35,110 [Executor task launch worker for task 248] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 1 ms
2021-12-03 20:18:35,110 [Executor task launch worker for task 249] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 4 non-empty blocks out of 4 blocks
2021-12-03 20:18:35,110 [Executor task launch worker for task 250] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 4 non-empty blocks out of 4 blocks
2021-12-03 20:18:35,110 [Executor task launch worker for task 250] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 1 ms
2021-12-03 20:18:35,110 [Executor task launch worker for task 249] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 20:18:35,130 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 791
2021-12-03 20:18:35,130 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 779
2021-12-03 20:18:35,130 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 776
2021-12-03 20:18:35,130 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 780
2021-12-03 20:18:35,130 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 786
2021-12-03 20:18:35,130 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 785
2021-12-03 20:18:35,130 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 777
2021-12-03 20:18:35,130 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 783
2021-12-03 20:18:35,130 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 778
2021-12-03 20:18:35,130 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 794
2021-12-03 20:18:35,130 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 796
2021-12-03 20:18:35,130 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 799
2021-12-03 20:18:35,130 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 793
2021-12-03 20:18:35,130 [dispatcher-event-loop-3] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_34_piece0 on qb:50070 in memory (size: 43.4 KB, free: 1990.7 MB)
2021-12-03 20:18:35,131 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 795
2021-12-03 20:18:35,131 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 787
2021-12-03 20:18:35,131 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 789
2021-12-03 20:18:35,131 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 781
2021-12-03 20:18:35,131 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 797
2021-12-03 20:18:35,131 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 788
2021-12-03 20:18:35,131 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 782
2021-12-03 20:18:35,131 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 790
2021-12-03 20:18:35,131 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 775
2021-12-03 20:18:35,131 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 798
2021-12-03 20:18:35,131 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 792
2021-12-03 20:18:35,131 [dispatcher-event-loop-5] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_33_piece0 on qb:50070 in memory (size: 42.1 KB, free: 1990.7 MB)
2021-12-03 20:18:35,131 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 784
2021-12-03 20:18:35,155 [Executor task launch worker for task 248] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 51.0 (TID 248). 1055 bytes result sent to driver
2021-12-03 20:18:35,155 [Executor task launch worker for task 249] INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 51.0 (TID 249). 1055 bytes result sent to driver
2021-12-03 20:18:35,155 [Executor task launch worker for task 251] INFO [org.apache.spark.executor.Executor] - Finished task 3.0 in stage 51.0 (TID 251). 1055 bytes result sent to driver
2021-12-03 20:18:35,155 [Executor task launch worker for task 250] INFO [org.apache.spark.executor.Executor] - Finished task 2.0 in stage 51.0 (TID 250). 1055 bytes result sent to driver
2021-12-03 20:18:35,155 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 51.0 (TID 248) in 47 ms on localhost (executor driver) (1/4)
2021-12-03 20:18:35,155 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 51.0 (TID 249) in 47 ms on localhost (executor driver) (2/4)
2021-12-03 20:18:35,155 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 3.0 in stage 51.0 (TID 251) in 46 ms on localhost (executor driver) (3/4)
2021-12-03 20:18:35,155 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 2.0 in stage 51.0 (TID 250) in 46 ms on localhost (executor driver) (4/4)
2021-12-03 20:18:35,155 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 51.0, whose tasks have all completed, from pool 
2021-12-03 20:18:35,155 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 51 (count at PaidPromotionAdjustParameter.scala:164) finished in 0.049 s
2021-12-03 20:18:35,156 [main] INFO [org.apache.spark.scheduler.DAGScheduler] - Job 22 finished: count at PaidPromotionAdjustParameter.scala:164, took 2.501877 s
2021-12-03 20:18:35,156 [main] INFO [PaidPromotion$] - 最终训练集用户数 = 95323
2021-12-03 20:18:35,158 [main] INFO [org.apache.spark.SparkContext] - Starting job: count at PaidPromotionAdjustParameter.scala:165
2021-12-03 20:18:35,158 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 57 (distinct at PaidPromotionAdjustParameter.scala:156)
2021-12-03 20:18:35,158 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 23 (count at PaidPromotionAdjustParameter.scala:165) with 2 output partitions
2021-12-03 20:18:35,158 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 53 (count at PaidPromotionAdjustParameter.scala:165)
2021-12-03 20:18:35,158 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 52)
2021-12-03 20:18:35,158 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List(ShuffleMapStage 52)
2021-12-03 20:18:35,158 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ShuffleMapStage 52 (MapPartitionsRDD[57] at distinct at PaidPromotionAdjustParameter.scala:156), which has no missing parents
2021-12-03 20:18:35,160 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_36 stored as values in memory (estimated size 119.6 KB, free 1989.9 MB)
2021-12-03 20:18:35,161 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_36_piece0 stored as bytes in memory (estimated size 43.1 KB, free 1989.8 MB)
2021-12-03 20:18:35,161 [dispatcher-event-loop-0] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_36_piece0 in memory on qb:50070 (size: 43.1 KB, free: 1990.7 MB)
2021-12-03 20:18:35,162 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 36 from broadcast at DAGScheduler.scala:1039
2021-12-03 20:18:35,162 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from ShuffleMapStage 52 (MapPartitionsRDD[57] at distinct at PaidPromotionAdjustParameter.scala:156) (first 15 tasks are for partitions Vector(0, 1))
2021-12-03 20:18:35,162 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 52.0 with 2 tasks
2021-12-03 20:18:35,162 [dispatcher-event-loop-10] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 52.0 (TID 252, localhost, executor driver, partition 0, ANY, 7885 bytes)
2021-12-03 20:18:35,162 [dispatcher-event-loop-10] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 52.0 (TID 253, localhost, executor driver, partition 1, ANY, 7885 bytes)
2021-12-03 20:18:35,162 [Executor task launch worker for task 253] INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 52.0 (TID 253)
2021-12-03 20:18:35,162 [Executor task launch worker for task 252] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 52.0 (TID 252)
2021-12-03 20:18:35,164 [Executor task launch worker for task 253] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/order_data.bcp:3442194+3442195
2021-12-03 20:18:35,164 [Executor task launch worker for task 252] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/order_data.bcp:0+3442194
2021-12-03 20:18:35,597 [Executor task launch worker for task 253] INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 52.0 (TID 253). 989 bytes result sent to driver
2021-12-03 20:18:35,597 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 52.0 (TID 253) in 435 ms on localhost (executor driver) (1/2)
2021-12-03 20:18:37,011 [Executor task launch worker for task 252] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 52.0 (TID 252). 989 bytes result sent to driver
2021-12-03 20:18:37,011 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 52.0 (TID 252) in 1849 ms on localhost (executor driver) (2/2)
2021-12-03 20:18:37,011 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 52.0, whose tasks have all completed, from pool 
2021-12-03 20:18:37,011 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ShuffleMapStage 52 (distinct at PaidPromotionAdjustParameter.scala:156) finished in 1.852 s
2021-12-03 20:18:37,011 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - looking for newly runnable stages
2021-12-03 20:18:37,011 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - running: Set()
2021-12-03 20:18:37,011 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - waiting: Set(ResultStage 53)
2021-12-03 20:18:37,011 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - failed: Set()
2021-12-03 20:18:37,011 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 53 (MapPartitionsRDD[59] at distinct at PaidPromotionAdjustParameter.scala:156), which has no missing parents
2021-12-03 20:18:37,012 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_37 stored as values in memory (estimated size 3.7 KB, free 1989.8 MB)
2021-12-03 20:18:37,013 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_37_piece0 stored as bytes in memory (estimated size 2.2 KB, free 1989.8 MB)
2021-12-03 20:18:37,014 [dispatcher-event-loop-8] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_37_piece0 in memory on qb:50070 (size: 2.2 KB, free: 1990.7 MB)
2021-12-03 20:18:37,014 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 37 from broadcast at DAGScheduler.scala:1039
2021-12-03 20:18:37,014 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from ResultStage 53 (MapPartitionsRDD[59] at distinct at PaidPromotionAdjustParameter.scala:156) (first 15 tasks are for partitions Vector(0, 1))
2021-12-03 20:18:37,014 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 53.0 with 2 tasks
2021-12-03 20:18:37,014 [dispatcher-event-loop-5] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 53.0 (TID 254, localhost, executor driver, partition 0, ANY, 7649 bytes)
2021-12-03 20:18:37,014 [dispatcher-event-loop-5] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 53.0 (TID 255, localhost, executor driver, partition 1, ANY, 7649 bytes)
2021-12-03 20:18:37,015 [Executor task launch worker for task 254] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 53.0 (TID 254)
2021-12-03 20:18:37,015 [Executor task launch worker for task 255] INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 53.0 (TID 255)
2021-12-03 20:18:37,016 [Executor task launch worker for task 254] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 2 non-empty blocks out of 2 blocks
2021-12-03 20:18:37,016 [Executor task launch worker for task 255] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 2 non-empty blocks out of 2 blocks
2021-12-03 20:18:37,016 [Executor task launch worker for task 255] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 20:18:37,016 [Executor task launch worker for task 254] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 20:18:37,032 [Executor task launch worker for task 255] INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 53.0 (TID 255). 1011 bytes result sent to driver
2021-12-03 20:18:37,032 [Executor task launch worker for task 254] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 53.0 (TID 254). 1011 bytes result sent to driver
2021-12-03 20:18:37,032 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 53.0 (TID 255) in 18 ms on localhost (executor driver) (1/2)
2021-12-03 20:18:37,032 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 53.0 (TID 254) in 18 ms on localhost (executor driver) (2/2)
2021-12-03 20:18:37,032 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 53.0, whose tasks have all completed, from pool 
2021-12-03 20:18:37,032 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 53 (count at PaidPromotionAdjustParameter.scala:165) finished in 0.020 s
2021-12-03 20:18:37,033 [main] INFO [org.apache.spark.scheduler.DAGScheduler] - Job 23 finished: count at PaidPromotionAdjustParameter.scala:165, took 1.875177 s
2021-12-03 20:18:37,033 [main] INFO [PaidPromotion$] - 最终验证集用户数 = 3247
2021-12-03 20:18:37,035 [main] INFO [org.apache.spark.SparkContext] - Starting job: count at PaidPromotionAdjustParameter.scala:166
2021-12-03 20:18:37,035 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 60 (intersection at PaidPromotionAdjustParameter.scala:157)
2021-12-03 20:18:37,035 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 61 (intersection at PaidPromotionAdjustParameter.scala:157)
2021-12-03 20:18:37,036 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 24 (count at PaidPromotionAdjustParameter.scala:166) with 4 output partitions
2021-12-03 20:18:37,036 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 58 (count at PaidPromotionAdjustParameter.scala:166)
2021-12-03 20:18:37,036 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 57, ShuffleMapStage 55)
2021-12-03 20:18:37,036 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List(ShuffleMapStage 57, ShuffleMapStage 55)
2021-12-03 20:18:37,036 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ShuffleMapStage 55 (MapPartitionsRDD[60] at intersection at PaidPromotionAdjustParameter.scala:157), which has no missing parents
2021-12-03 20:18:37,036 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_38 stored as values in memory (estimated size 4.0 KB, free 1989.8 MB)
2021-12-03 20:18:37,037 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_38_piece0 stored as bytes in memory (estimated size 2.3 KB, free 1989.8 MB)
2021-12-03 20:18:37,038 [dispatcher-event-loop-0] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_38_piece0 in memory on qb:50070 (size: 2.3 KB, free: 1990.7 MB)
2021-12-03 20:18:37,038 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 38 from broadcast at DAGScheduler.scala:1039
2021-12-03 20:18:37,038 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 4 missing tasks from ShuffleMapStage 55 (MapPartitionsRDD[60] at intersection at PaidPromotionAdjustParameter.scala:157) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
2021-12-03 20:18:37,038 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 55.0 with 4 tasks
2021-12-03 20:18:37,038 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ShuffleMapStage 57 (MapPartitionsRDD[61] at intersection at PaidPromotionAdjustParameter.scala:157), which has no missing parents
2021-12-03 20:18:37,038 [dispatcher-event-loop-10] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 55.0 (TID 256, localhost, executor driver, partition 0, ANY, 7638 bytes)
2021-12-03 20:18:37,039 [dispatcher-event-loop-10] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 55.0 (TID 257, localhost, executor driver, partition 1, ANY, 7638 bytes)
2021-12-03 20:18:37,039 [dispatcher-event-loop-10] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 2.0 in stage 55.0 (TID 258, localhost, executor driver, partition 2, ANY, 7638 bytes)
2021-12-03 20:18:37,039 [dispatcher-event-loop-10] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 3.0 in stage 55.0 (TID 259, localhost, executor driver, partition 3, ANY, 7638 bytes)
2021-12-03 20:18:37,039 [Executor task launch worker for task 256] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 55.0 (TID 256)
2021-12-03 20:18:37,039 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_39 stored as values in memory (estimated size 4.0 KB, free 1989.8 MB)
2021-12-03 20:18:37,039 [Executor task launch worker for task 258] INFO [org.apache.spark.executor.Executor] - Running task 2.0 in stage 55.0 (TID 258)
2021-12-03 20:18:37,039 [Executor task launch worker for task 257] INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 55.0 (TID 257)
2021-12-03 20:18:37,039 [Executor task launch worker for task 259] INFO [org.apache.spark.executor.Executor] - Running task 3.0 in stage 55.0 (TID 259)
2021-12-03 20:18:37,040 [Executor task launch worker for task 258] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 4 non-empty blocks out of 4 blocks
2021-12-03 20:18:37,040 [Executor task launch worker for task 259] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 4 non-empty blocks out of 4 blocks
2021-12-03 20:18:37,040 [Executor task launch worker for task 256] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 4 non-empty blocks out of 4 blocks
2021-12-03 20:18:37,040 [Executor task launch worker for task 257] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 4 non-empty blocks out of 4 blocks
2021-12-03 20:18:37,040 [Executor task launch worker for task 259] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 1 ms
2021-12-03 20:18:37,040 [Executor task launch worker for task 258] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 1 ms
2021-12-03 20:18:37,040 [Executor task launch worker for task 257] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 20:18:37,040 [Executor task launch worker for task 256] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 1 ms
2021-12-03 20:18:37,040 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_39_piece0 stored as bytes in memory (estimated size 2.3 KB, free 1989.8 MB)
2021-12-03 20:18:37,040 [dispatcher-event-loop-8] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_39_piece0 in memory on qb:50070 (size: 2.3 KB, free: 1990.7 MB)
2021-12-03 20:18:37,041 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 39 from broadcast at DAGScheduler.scala:1039
2021-12-03 20:18:37,041 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from ShuffleMapStage 57 (MapPartitionsRDD[61] at intersection at PaidPromotionAdjustParameter.scala:157) (first 15 tasks are for partitions Vector(0, 1))
2021-12-03 20:18:37,041 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 57.0 with 2 tasks
2021-12-03 20:18:37,041 [dispatcher-event-loop-5] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 57.0 (TID 260, localhost, executor driver, partition 0, ANY, 7638 bytes)
2021-12-03 20:18:37,041 [dispatcher-event-loop-5] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 57.0 (TID 261, localhost, executor driver, partition 1, ANY, 7638 bytes)
2021-12-03 20:18:37,042 [Executor task launch worker for task 260] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 57.0 (TID 260)
2021-12-03 20:18:37,042 [Executor task launch worker for task 261] INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 57.0 (TID 261)
2021-12-03 20:18:37,043 [Executor task launch worker for task 261] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 2 non-empty blocks out of 2 blocks
2021-12-03 20:18:37,043 [Executor task launch worker for task 260] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 2 non-empty blocks out of 2 blocks
2021-12-03 20:18:37,043 [Executor task launch worker for task 261] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 20:18:37,043 [Executor task launch worker for task 260] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 20:18:37,071 [Executor task launch worker for task 261] INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 57.0 (TID 261). 1206 bytes result sent to driver
2021-12-03 20:18:37,072 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 57.0 (TID 261) in 31 ms on localhost (executor driver) (1/2)
2021-12-03 20:18:37,072 [Executor task launch worker for task 260] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 57.0 (TID 260). 1206 bytes result sent to driver
2021-12-03 20:18:37,073 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 57.0 (TID 260) in 31 ms on localhost (executor driver) (2/2)
2021-12-03 20:18:37,073 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 57.0, whose tasks have all completed, from pool 
2021-12-03 20:18:37,073 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ShuffleMapStage 57 (intersection at PaidPromotionAdjustParameter.scala:157) finished in 0.034 s
2021-12-03 20:18:37,073 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - looking for newly runnable stages
2021-12-03 20:18:37,073 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - running: Set(ShuffleMapStage 55)
2021-12-03 20:18:37,073 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - waiting: Set(ResultStage 58)
2021-12-03 20:18:37,073 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - failed: Set()
2021-12-03 20:18:37,091 [Executor task launch worker for task 259] INFO [org.apache.spark.executor.Executor] - Finished task 3.0 in stage 55.0 (TID 259). 1163 bytes result sent to driver
2021-12-03 20:18:37,091 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 3.0 in stage 55.0 (TID 259) in 52 ms on localhost (executor driver) (1/4)
2021-12-03 20:18:37,095 [Executor task launch worker for task 257] INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 55.0 (TID 257). 1163 bytes result sent to driver
2021-12-03 20:18:37,096 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 55.0 (TID 257) in 58 ms on localhost (executor driver) (2/4)
2021-12-03 20:18:37,097 [Executor task launch worker for task 258] INFO [org.apache.spark.executor.Executor] - Finished task 2.0 in stage 55.0 (TID 258). 1163 bytes result sent to driver
2021-12-03 20:18:37,097 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 2.0 in stage 55.0 (TID 258) in 58 ms on localhost (executor driver) (3/4)
2021-12-03 20:18:37,100 [Executor task launch worker for task 256] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 55.0 (TID 256). 1163 bytes result sent to driver
2021-12-03 20:18:37,100 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 55.0 (TID 256) in 62 ms on localhost (executor driver) (4/4)
2021-12-03 20:18:37,100 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 55.0, whose tasks have all completed, from pool 
2021-12-03 20:18:37,101 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ShuffleMapStage 55 (intersection at PaidPromotionAdjustParameter.scala:157) finished in 0.064 s
2021-12-03 20:18:37,101 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - looking for newly runnable stages
2021-12-03 20:18:37,101 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - running: Set()
2021-12-03 20:18:37,101 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - waiting: Set(ResultStage 58)
2021-12-03 20:18:37,101 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - failed: Set()
2021-12-03 20:18:37,101 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 58 (MapPartitionsRDD[65] at intersection at PaidPromotionAdjustParameter.scala:157), which has no missing parents
2021-12-03 20:18:37,101 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_40 stored as values in memory (estimated size 3.6 KB, free 1989.8 MB)
2021-12-03 20:18:37,102 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_40_piece0 stored as bytes in memory (estimated size 2.1 KB, free 1989.8 MB)
2021-12-03 20:18:37,102 [dispatcher-event-loop-3] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_40_piece0 in memory on qb:50070 (size: 2.1 KB, free: 1990.7 MB)
2021-12-03 20:18:37,103 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 40 from broadcast at DAGScheduler.scala:1039
2021-12-03 20:18:37,103 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 4 missing tasks from ResultStage 58 (MapPartitionsRDD[65] at intersection at PaidPromotionAdjustParameter.scala:157) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
2021-12-03 20:18:37,103 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 58.0 with 4 tasks
2021-12-03 20:18:37,103 [dispatcher-event-loop-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 58.0 (TID 262, localhost, executor driver, partition 0, PROCESS_LOCAL, 7712 bytes)
2021-12-03 20:18:37,103 [dispatcher-event-loop-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 58.0 (TID 263, localhost, executor driver, partition 1, PROCESS_LOCAL, 7712 bytes)
2021-12-03 20:18:37,103 [dispatcher-event-loop-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 2.0 in stage 58.0 (TID 264, localhost, executor driver, partition 2, PROCESS_LOCAL, 7712 bytes)
2021-12-03 20:18:37,103 [dispatcher-event-loop-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 3.0 in stage 58.0 (TID 265, localhost, executor driver, partition 3, PROCESS_LOCAL, 7712 bytes)
2021-12-03 20:18:37,103 [Executor task launch worker for task 264] INFO [org.apache.spark.executor.Executor] - Running task 2.0 in stage 58.0 (TID 264)
2021-12-03 20:18:37,103 [Executor task launch worker for task 262] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 58.0 (TID 262)
2021-12-03 20:18:37,103 [Executor task launch worker for task 263] INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 58.0 (TID 263)
2021-12-03 20:18:37,103 [Executor task launch worker for task 265] INFO [org.apache.spark.executor.Executor] - Running task 3.0 in stage 58.0 (TID 265)
2021-12-03 20:18:37,104 [Executor task launch worker for task 263] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 4 blocks
2021-12-03 20:18:37,104 [Executor task launch worker for task 262] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 4 blocks
2021-12-03 20:18:37,104 [Executor task launch worker for task 263] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 20:18:37,104 [Executor task launch worker for task 262] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 20:18:37,104 [Executor task launch worker for task 265] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 4 blocks
2021-12-03 20:18:37,104 [Executor task launch worker for task 264] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 4 blocks
2021-12-03 20:18:37,104 [Executor task launch worker for task 265] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 20:18:37,104 [Executor task launch worker for task 264] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 20:18:37,106 [Executor task launch worker for task 262] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2021-12-03 20:18:37,106 [Executor task launch worker for task 263] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2021-12-03 20:18:37,106 [Executor task launch worker for task 265] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2021-12-03 20:18:37,106 [Executor task launch worker for task 265] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 20:18:37,106 [Executor task launch worker for task 262] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 20:18:37,106 [Executor task launch worker for task 264] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2021-12-03 20:18:37,106 [Executor task launch worker for task 264] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 20:18:37,106 [Executor task launch worker for task 263] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 20:18:37,146 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 802
2021-12-03 20:18:37,146 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 895
2021-12-03 20:18:37,146 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 832
2021-12-03 20:18:37,146 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 854
2021-12-03 20:18:37,146 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 800
2021-12-03 20:18:37,146 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 887
2021-12-03 20:18:37,146 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 815
2021-12-03 20:18:37,146 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 839
2021-12-03 20:18:37,146 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 870
2021-12-03 20:18:37,146 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 880
2021-12-03 20:18:37,146 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 807
2021-12-03 20:18:37,146 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 857
2021-12-03 20:18:37,146 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 824
2021-12-03 20:18:37,146 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 834
2021-12-03 20:18:37,146 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 875
2021-12-03 20:18:37,147 [dispatcher-event-loop-0] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_37_piece0 on qb:50070 in memory (size: 2.2 KB, free: 1990.7 MB)
2021-12-03 20:18:37,147 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 843
2021-12-03 20:18:37,147 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 861
2021-12-03 20:18:37,147 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 842
2021-12-03 20:18:37,147 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 892
2021-12-03 20:18:37,147 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 831
2021-12-03 20:18:37,147 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 837
2021-12-03 20:18:37,147 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 801
2021-12-03 20:18:37,147 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 825
2021-12-03 20:18:37,147 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 883
2021-12-03 20:18:37,147 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 822
2021-12-03 20:18:37,147 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 827
2021-12-03 20:18:37,147 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 862
2021-12-03 20:18:37,147 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 868
2021-12-03 20:18:37,147 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 899
2021-12-03 20:18:37,147 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 811
2021-12-03 20:18:37,147 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 810
2021-12-03 20:18:37,147 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 849
2021-12-03 20:18:37,147 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 805
2021-12-03 20:18:37,147 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 867
2021-12-03 20:18:37,147 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 889
2021-12-03 20:18:37,147 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 885
2021-12-03 20:18:37,147 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 869
2021-12-03 20:18:37,147 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 826
2021-12-03 20:18:37,147 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 882
2021-12-03 20:18:37,147 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 833
2021-12-03 20:18:37,147 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 819
2021-12-03 20:18:37,147 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 829
2021-12-03 20:18:37,147 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 859
2021-12-03 20:18:37,147 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 898
2021-12-03 20:18:37,147 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 864
2021-12-03 20:18:37,147 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 846
2021-12-03 20:18:37,147 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 894
2021-12-03 20:18:37,147 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 850
2021-12-03 20:18:37,147 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 835
2021-12-03 20:18:37,148 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 865
2021-12-03 20:18:37,148 [dispatcher-event-loop-7] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_38_piece0 on qb:50070 in memory (size: 2.3 KB, free: 1990.7 MB)
2021-12-03 20:18:37,148 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 890
2021-12-03 20:18:37,148 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 876
2021-12-03 20:18:37,148 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 812
2021-12-03 20:18:37,148 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 866
2021-12-03 20:18:37,148 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 823
2021-12-03 20:18:37,148 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 808
2021-12-03 20:18:37,148 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 838
2021-12-03 20:18:37,148 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 841
2021-12-03 20:18:37,148 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 809
2021-12-03 20:18:37,148 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 879
2021-12-03 20:18:37,148 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 886
2021-12-03 20:18:37,148 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 845
2021-12-03 20:18:37,148 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 863
2021-12-03 20:18:37,148 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 818
2021-12-03 20:18:37,148 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 888
2021-12-03 20:18:37,149 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 856
2021-12-03 20:18:37,149 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 874
2021-12-03 20:18:37,149 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 816
2021-12-03 20:18:37,149 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 813
2021-12-03 20:18:37,149 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 897
2021-12-03 20:18:37,149 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 896
2021-12-03 20:18:37,149 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 893
2021-12-03 20:18:37,149 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 858
2021-12-03 20:18:37,149 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 840
2021-12-03 20:18:37,149 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 871
2021-12-03 20:18:37,149 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 817
2021-12-03 20:18:37,149 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 806
2021-12-03 20:18:37,149 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 872
2021-12-03 20:18:37,149 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 852
2021-12-03 20:18:37,149 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 814
2021-12-03 20:18:37,149 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 821
2021-12-03 20:18:37,149 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 884
2021-12-03 20:18:37,149 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 891
2021-12-03 20:18:37,149 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 881
2021-12-03 20:18:37,149 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 877
2021-12-03 20:18:37,149 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 851
2021-12-03 20:18:37,149 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 853
2021-12-03 20:18:37,149 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 860
2021-12-03 20:18:37,149 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 820
2021-12-03 20:18:37,149 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 830
2021-12-03 20:18:37,149 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 847
2021-12-03 20:18:37,149 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 878
2021-12-03 20:18:37,149 [dispatcher-event-loop-8] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_36_piece0 on qb:50070 in memory (size: 43.1 KB, free: 1990.7 MB)
2021-12-03 20:18:37,150 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 848
2021-12-03 20:18:37,150 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 803
2021-12-03 20:18:37,150 [dispatcher-event-loop-4] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_39_piece0 on qb:50070 in memory (size: 2.3 KB, free: 1990.7 MB)
2021-12-03 20:18:37,150 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 836
2021-12-03 20:18:37,150 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 844
2021-12-03 20:18:37,151 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 873
2021-12-03 20:18:37,151 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 828
2021-12-03 20:18:37,151 [dispatcher-event-loop-0] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_35_piece0 on qb:50070 in memory (size: 2.2 KB, free: 1990.7 MB)
2021-12-03 20:18:37,151 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 855
2021-12-03 20:18:37,165 [Executor task launch worker for task 263] INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 58.0 (TID 263). 1097 bytes result sent to driver
2021-12-03 20:18:37,166 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 58.0 (TID 263) in 63 ms on localhost (executor driver) (1/4)
2021-12-03 20:18:37,166 [Executor task launch worker for task 265] INFO [org.apache.spark.executor.Executor] - Finished task 3.0 in stage 58.0 (TID 265). 1097 bytes result sent to driver
2021-12-03 20:18:37,166 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 3.0 in stage 58.0 (TID 265) in 63 ms on localhost (executor driver) (2/4)
2021-12-03 20:18:37,167 [Executor task launch worker for task 262] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 58.0 (TID 262). 1097 bytes result sent to driver
2021-12-03 20:18:37,167 [Executor task launch worker for task 264] INFO [org.apache.spark.executor.Executor] - Finished task 2.0 in stage 58.0 (TID 264). 1097 bytes result sent to driver
2021-12-03 20:18:37,167 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 58.0 (TID 262) in 64 ms on localhost (executor driver) (3/4)
2021-12-03 20:18:37,167 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 2.0 in stage 58.0 (TID 264) in 64 ms on localhost (executor driver) (4/4)
2021-12-03 20:18:37,167 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 58.0, whose tasks have all completed, from pool 
2021-12-03 20:18:37,167 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 58 (count at PaidPromotionAdjustParameter.scala:166) finished in 0.066 s
2021-12-03 20:18:37,167 [main] INFO [org.apache.spark.scheduler.DAGScheduler] - Job 24 finished: count at PaidPromotionAdjustParameter.scala:166, took 0.131812 s
2021-12-03 20:18:37,168 [main] INFO [PaidPromotion$] - 最终共 同 用户数 = 3247
2021-12-03 20:18:37,170 [main] INFO [org.apache.spark.SparkContext] - Starting job: count at PaidPromotionAdjustParameter.scala:167
2021-12-03 20:18:37,170 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 67 (distinct at PaidPromotionAdjustParameter.scala:159)
2021-12-03 20:18:37,170 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 25 (count at PaidPromotionAdjustParameter.scala:167) with 4 output partitions
2021-12-03 20:18:37,170 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 60 (count at PaidPromotionAdjustParameter.scala:167)
2021-12-03 20:18:37,170 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 59)
2021-12-03 20:18:37,170 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List(ShuffleMapStage 59)
2021-12-03 20:18:37,171 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ShuffleMapStage 59 (MapPartitionsRDD[67] at distinct at PaidPromotionAdjustParameter.scala:159), which has no missing parents
2021-12-03 20:18:37,172 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_41 stored as values in memory (estimated size 120.1 KB, free 1989.9 MB)
2021-12-03 20:18:37,173 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_41_piece0 stored as bytes in memory (estimated size 43.4 KB, free 1989.8 MB)
2021-12-03 20:18:37,174 [dispatcher-event-loop-3] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_41_piece0 in memory on qb:50070 (size: 43.4 KB, free: 1990.7 MB)
2021-12-03 20:18:37,174 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 41 from broadcast at DAGScheduler.scala:1039
2021-12-03 20:18:37,174 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 4 missing tasks from ShuffleMapStage 59 (MapPartitionsRDD[67] at distinct at PaidPromotionAdjustParameter.scala:159) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
2021-12-03 20:18:37,174 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 59.0 with 4 tasks
2021-12-03 20:18:37,175 [dispatcher-event-loop-8] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 59.0 (TID 266, localhost, executor driver, partition 0, ANY, 7994 bytes)
2021-12-03 20:18:37,175 [dispatcher-event-loop-8] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 59.0 (TID 267, localhost, executor driver, partition 1, ANY, 7994 bytes)
2021-12-03 20:18:37,175 [dispatcher-event-loop-8] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 2.0 in stage 59.0 (TID 268, localhost, executor driver, partition 2, ANY, 7994 bytes)
2021-12-03 20:18:37,175 [dispatcher-event-loop-8] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 3.0 in stage 59.0 (TID 269, localhost, executor driver, partition 3, ANY, 7994 bytes)
2021-12-03 20:18:37,175 [Executor task launch worker for task 267] INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 59.0 (TID 267)
2021-12-03 20:18:37,175 [Executor task launch worker for task 266] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 59.0 (TID 266)
2021-12-03 20:18:37,175 [Executor task launch worker for task 268] INFO [org.apache.spark.executor.Executor] - Running task 2.0 in stage 59.0 (TID 268)
2021-12-03 20:18:37,175 [Executor task launch worker for task 269] INFO [org.apache.spark.executor.Executor] - Running task 3.0 in stage 59.0 (TID 269)
2021-12-03 20:18:37,177 [Executor task launch worker for task 267] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/order_data.bcp:3442194+3442195
2021-12-03 20:18:37,177 [Executor task launch worker for task 266] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/order_data.bcp:0+3442194
2021-12-03 20:18:37,177 [Executor task launch worker for task 269] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/order_data.bcp:3442194+3442195
2021-12-03 20:18:37,177 [Executor task launch worker for task 268] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/order_data.bcp:0+3442194
2021-12-03 20:18:37,742 [Executor task launch worker for task 269] INFO [org.apache.spark.executor.Executor] - Finished task 3.0 in stage 59.0 (TID 269). 991 bytes result sent to driver
2021-12-03 20:18:37,743 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 3.0 in stage 59.0 (TID 269) in 568 ms on localhost (executor driver) (1/4)
2021-12-03 20:18:38,308 [Executor task launch worker for task 268] INFO [org.apache.spark.executor.Executor] - Finished task 2.0 in stage 59.0 (TID 268). 991 bytes result sent to driver
2021-12-03 20:18:38,308 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 2.0 in stage 59.0 (TID 268) in 1133 ms on localhost (executor driver) (2/4)
2021-12-03 20:18:38,327 [Executor task launch worker for task 266] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 59.0 (TID 266). 991 bytes result sent to driver
2021-12-03 20:18:38,327 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 59.0 (TID 266) in 1153 ms on localhost (executor driver) (3/4)
2021-12-03 20:18:38,466 [Executor task launch worker for task 267] INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 59.0 (TID 267). 991 bytes result sent to driver
2021-12-03 20:18:38,466 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 59.0 (TID 267) in 1291 ms on localhost (executor driver) (4/4)
2021-12-03 20:18:38,466 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 59.0, whose tasks have all completed, from pool 
2021-12-03 20:18:38,467 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ShuffleMapStage 59 (distinct at PaidPromotionAdjustParameter.scala:159) finished in 1.296 s
2021-12-03 20:18:38,467 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - looking for newly runnable stages
2021-12-03 20:18:38,467 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - running: Set()
2021-12-03 20:18:38,467 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - waiting: Set(ResultStage 60)
2021-12-03 20:18:38,467 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - failed: Set()
2021-12-03 20:18:38,467 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 60 (MapPartitionsRDD[69] at distinct at PaidPromotionAdjustParameter.scala:159), which has no missing parents
2021-12-03 20:18:38,467 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_42 stored as values in memory (estimated size 3.7 KB, free 1989.8 MB)
2021-12-03 20:18:38,469 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_42_piece0 stored as bytes in memory (estimated size 2.2 KB, free 1989.8 MB)
2021-12-03 20:18:38,469 [dispatcher-event-loop-3] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_42_piece0 in memory on qb:50070 (size: 2.2 KB, free: 1990.7 MB)
2021-12-03 20:18:38,469 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 42 from broadcast at DAGScheduler.scala:1039
2021-12-03 20:18:38,470 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 4 missing tasks from ResultStage 60 (MapPartitionsRDD[69] at distinct at PaidPromotionAdjustParameter.scala:159) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
2021-12-03 20:18:38,470 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 60.0 with 4 tasks
2021-12-03 20:18:38,470 [dispatcher-event-loop-8] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 60.0 (TID 270, localhost, executor driver, partition 0, ANY, 7649 bytes)
2021-12-03 20:18:38,470 [dispatcher-event-loop-8] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 60.0 (TID 271, localhost, executor driver, partition 1, ANY, 7649 bytes)
2021-12-03 20:18:38,470 [dispatcher-event-loop-8] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 2.0 in stage 60.0 (TID 272, localhost, executor driver, partition 2, ANY, 7649 bytes)
2021-12-03 20:18:38,470 [dispatcher-event-loop-8] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 3.0 in stage 60.0 (TID 273, localhost, executor driver, partition 3, ANY, 7649 bytes)
2021-12-03 20:18:38,470 [Executor task launch worker for task 272] INFO [org.apache.spark.executor.Executor] - Running task 2.0 in stage 60.0 (TID 272)
2021-12-03 20:18:38,470 [Executor task launch worker for task 270] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 60.0 (TID 270)
2021-12-03 20:18:38,470 [Executor task launch worker for task 273] INFO [org.apache.spark.executor.Executor] - Running task 3.0 in stage 60.0 (TID 273)
2021-12-03 20:18:38,470 [Executor task launch worker for task 271] INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 60.0 (TID 271)
2021-12-03 20:18:38,471 [Executor task launch worker for task 271] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 4 non-empty blocks out of 4 blocks
2021-12-03 20:18:38,471 [Executor task launch worker for task 273] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 4 non-empty blocks out of 4 blocks
2021-12-03 20:18:38,471 [Executor task launch worker for task 271] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 20:18:38,471 [Executor task launch worker for task 270] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 4 non-empty blocks out of 4 blocks
2021-12-03 20:18:38,471 [Executor task launch worker for task 272] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 4 non-empty blocks out of 4 blocks
2021-12-03 20:18:38,471 [Executor task launch worker for task 273] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 20:18:38,471 [Executor task launch worker for task 272] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 20:18:38,471 [Executor task launch worker for task 270] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 20:18:38,489 [Executor task launch worker for task 272] INFO [org.apache.spark.executor.Executor] - Finished task 2.0 in stage 60.0 (TID 272). 1010 bytes result sent to driver
2021-12-03 20:18:38,489 [Executor task launch worker for task 271] INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 60.0 (TID 271). 1010 bytes result sent to driver
2021-12-03 20:18:38,489 [Executor task launch worker for task 270] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 60.0 (TID 270). 1010 bytes result sent to driver
2021-12-03 20:18:38,489 [Executor task launch worker for task 273] INFO [org.apache.spark.executor.Executor] - Finished task 3.0 in stage 60.0 (TID 273). 1053 bytes result sent to driver
2021-12-03 20:18:38,490 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 2.0 in stage 60.0 (TID 272) in 20 ms on localhost (executor driver) (1/4)
2021-12-03 20:18:38,490 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 60.0 (TID 271) in 20 ms on localhost (executor driver) (2/4)
2021-12-03 20:18:38,490 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 60.0 (TID 270) in 20 ms on localhost (executor driver) (3/4)
2021-12-03 20:18:38,490 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 3.0 in stage 60.0 (TID 273) in 20 ms on localhost (executor driver) (4/4)
2021-12-03 20:18:38,490 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 60.0, whose tasks have all completed, from pool 
2021-12-03 20:18:38,490 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 60 (count at PaidPromotionAdjustParameter.scala:167) finished in 0.023 s
2021-12-03 20:18:38,490 [main] INFO [org.apache.spark.scheduler.DAGScheduler] - Job 25 finished: count at PaidPromotionAdjustParameter.scala:167, took 1.320521 s
2021-12-03 20:18:38,490 [main] INFO [PaidPromotion$] - 最终训练集节目数 = 132
2021-12-03 20:18:38,492 [main] INFO [org.apache.spark.SparkContext] - Starting job: count at PaidPromotionAdjustParameter.scala:168
2021-12-03 20:18:38,493 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 71 (distinct at PaidPromotionAdjustParameter.scala:160)
2021-12-03 20:18:38,493 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 26 (count at PaidPromotionAdjustParameter.scala:168) with 2 output partitions
2021-12-03 20:18:38,493 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 62 (count at PaidPromotionAdjustParameter.scala:168)
2021-12-03 20:18:38,493 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 61)
2021-12-03 20:18:38,493 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List(ShuffleMapStage 61)
2021-12-03 20:18:38,493 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ShuffleMapStage 61 (MapPartitionsRDD[71] at distinct at PaidPromotionAdjustParameter.scala:160), which has no missing parents
2021-12-03 20:18:38,494 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_43 stored as values in memory (estimated size 119.6 KB, free 1989.7 MB)
2021-12-03 20:18:38,495 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_43_piece0 stored as bytes in memory (estimated size 43.1 KB, free 1989.7 MB)
2021-12-03 20:18:38,495 [dispatcher-event-loop-1] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_43_piece0 in memory on qb:50070 (size: 43.1 KB, free: 1990.6 MB)
2021-12-03 20:18:38,496 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 43 from broadcast at DAGScheduler.scala:1039
2021-12-03 20:18:38,496 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from ShuffleMapStage 61 (MapPartitionsRDD[71] at distinct at PaidPromotionAdjustParameter.scala:160) (first 15 tasks are for partitions Vector(0, 1))
2021-12-03 20:18:38,496 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 61.0 with 2 tasks
2021-12-03 20:18:38,496 [dispatcher-event-loop-7] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 61.0 (TID 274, localhost, executor driver, partition 0, ANY, 7885 bytes)
2021-12-03 20:18:38,496 [dispatcher-event-loop-7] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 61.0 (TID 275, localhost, executor driver, partition 1, ANY, 7885 bytes)
2021-12-03 20:18:38,496 [Executor task launch worker for task 274] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 61.0 (TID 274)
2021-12-03 20:18:38,496 [Executor task launch worker for task 275] INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 61.0 (TID 275)
2021-12-03 20:18:38,497 [Executor task launch worker for task 274] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/order_data.bcp:0+3442194
2021-12-03 20:18:38,497 [Executor task launch worker for task 275] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/order_data.bcp:3442194+3442195
2021-12-03 20:18:38,575 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1012
2021-12-03 20:18:38,575 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1018
2021-12-03 20:18:38,575 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 991
2021-12-03 20:18:38,575 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1024
2021-12-03 20:18:38,575 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1002
2021-12-03 20:18:38,575 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1022
2021-12-03 20:18:38,575 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1014
2021-12-03 20:18:38,575 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 999
2021-12-03 20:18:38,575 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 977
2021-12-03 20:18:38,575 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 987
2021-12-03 20:18:38,575 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1008
2021-12-03 20:18:38,575 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1011
2021-12-03 20:18:38,575 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 992
2021-12-03 20:18:38,575 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1010
2021-12-03 20:18:38,575 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 990
2021-12-03 20:18:38,575 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 996
2021-12-03 20:18:38,575 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 981
2021-12-03 20:18:38,575 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1013
2021-12-03 20:18:38,575 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 994
2021-12-03 20:18:38,575 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 995
2021-12-03 20:18:38,575 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1019
2021-12-03 20:18:38,575 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 975
2021-12-03 20:18:38,575 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1021
2021-12-03 20:18:38,575 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 985
2021-12-03 20:18:38,575 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1023
2021-12-03 20:18:38,575 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 979
2021-12-03 20:18:38,575 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1000
2021-12-03 20:18:38,575 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1004
2021-12-03 20:18:38,575 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 976
2021-12-03 20:18:38,575 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 993
2021-12-03 20:18:38,576 [dispatcher-event-loop-4] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_41_piece0 on qb:50070 in memory (size: 43.4 KB, free: 1990.7 MB)
2021-12-03 20:18:38,576 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 978
2021-12-03 20:18:38,576 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 989
2021-12-03 20:18:38,576 [dispatcher-event-loop-9] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_42_piece0 on qb:50070 in memory (size: 2.2 KB, free: 1990.7 MB)
2021-12-03 20:18:38,577 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1001
2021-12-03 20:18:38,577 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 980
2021-12-03 20:18:38,577 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1017
2021-12-03 20:18:38,577 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 998
2021-12-03 20:18:38,577 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1005
2021-12-03 20:18:38,577 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1003
2021-12-03 20:18:38,577 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1015
2021-12-03 20:18:38,577 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1016
2021-12-03 20:18:38,577 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1009
2021-12-03 20:18:38,577 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 982
2021-12-03 20:18:38,577 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 988
2021-12-03 20:18:38,577 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 983
2021-12-03 20:18:38,577 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 997
2021-12-03 20:18:38,577 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1006
2021-12-03 20:18:38,577 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 984
2021-12-03 20:18:38,577 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1007
2021-12-03 20:18:38,577 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 986
2021-12-03 20:18:38,577 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1020
2021-12-03 20:18:38,940 [Executor task launch worker for task 275] INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 61.0 (TID 275). 1032 bytes result sent to driver
2021-12-03 20:18:38,940 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 61.0 (TID 275) in 444 ms on localhost (executor driver) (1/2)
2021-12-03 20:18:39,115 [Executor task launch worker for task 274] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 61.0 (TID 274). 1032 bytes result sent to driver
2021-12-03 20:18:39,116 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 61.0 (TID 274) in 620 ms on localhost (executor driver) (2/2)
2021-12-03 20:18:39,116 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 61.0, whose tasks have all completed, from pool 
2021-12-03 20:18:39,116 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ShuffleMapStage 61 (distinct at PaidPromotionAdjustParameter.scala:160) finished in 0.623 s
2021-12-03 20:18:39,116 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - looking for newly runnable stages
2021-12-03 20:18:39,116 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - running: Set()
2021-12-03 20:18:39,116 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - waiting: Set(ResultStage 62)
2021-12-03 20:18:39,116 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - failed: Set()
2021-12-03 20:18:39,116 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 62 (MapPartitionsRDD[73] at distinct at PaidPromotionAdjustParameter.scala:160), which has no missing parents
2021-12-03 20:18:39,117 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_44 stored as values in memory (estimated size 3.7 KB, free 1989.8 MB)
2021-12-03 20:18:39,118 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_44_piece0 stored as bytes in memory (estimated size 2.2 KB, free 1989.8 MB)
2021-12-03 20:18:39,118 [dispatcher-event-loop-1] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_44_piece0 in memory on qb:50070 (size: 2.2 KB, free: 1990.7 MB)
2021-12-03 20:18:39,118 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 44 from broadcast at DAGScheduler.scala:1039
2021-12-03 20:18:39,118 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from ResultStage 62 (MapPartitionsRDD[73] at distinct at PaidPromotionAdjustParameter.scala:160) (first 15 tasks are for partitions Vector(0, 1))
2021-12-03 20:18:39,119 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 62.0 with 2 tasks
2021-12-03 20:18:39,119 [dispatcher-event-loop-7] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 62.0 (TID 276, localhost, executor driver, partition 0, ANY, 7649 bytes)
2021-12-03 20:18:39,119 [dispatcher-event-loop-7] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 62.0 (TID 277, localhost, executor driver, partition 1, ANY, 7649 bytes)
2021-12-03 20:18:39,119 [Executor task launch worker for task 277] INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 62.0 (TID 277)
2021-12-03 20:18:39,119 [Executor task launch worker for task 276] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 62.0 (TID 276)
2021-12-03 20:18:39,120 [Executor task launch worker for task 277] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 2 non-empty blocks out of 2 blocks
2021-12-03 20:18:39,120 [Executor task launch worker for task 276] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 2 non-empty blocks out of 2 blocks
2021-12-03 20:18:39,120 [Executor task launch worker for task 277] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 20:18:39,120 [Executor task launch worker for task 276] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 20:18:39,130 [Executor task launch worker for task 276] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 62.0 (TID 276). 1010 bytes result sent to driver
2021-12-03 20:18:39,130 [Executor task launch worker for task 277] INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 62.0 (TID 277). 1010 bytes result sent to driver
2021-12-03 20:18:39,130 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 62.0 (TID 276) in 11 ms on localhost (executor driver) (1/2)
2021-12-03 20:18:39,130 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 62.0 (TID 277) in 11 ms on localhost (executor driver) (2/2)
2021-12-03 20:18:39,130 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 62.0, whose tasks have all completed, from pool 
2021-12-03 20:18:39,131 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 62 (count at PaidPromotionAdjustParameter.scala:168) finished in 0.015 s
2021-12-03 20:18:39,131 [main] INFO [org.apache.spark.scheduler.DAGScheduler] - Job 26 finished: count at PaidPromotionAdjustParameter.scala:168, took 0.637851 s
2021-12-03 20:18:39,131 [main] INFO [PaidPromotion$] - 最终验证集节目数 = 75
2021-12-03 20:18:39,133 [main] INFO [org.apache.spark.SparkContext] - Starting job: count at PaidPromotionAdjustParameter.scala:169
2021-12-03 20:18:39,134 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 75 (intersection at PaidPromotionAdjustParameter.scala:161)
2021-12-03 20:18:39,134 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 74 (intersection at PaidPromotionAdjustParameter.scala:161)
2021-12-03 20:18:39,134 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 27 (count at PaidPromotionAdjustParameter.scala:169) with 4 output partitions
2021-12-03 20:18:39,134 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 67 (count at PaidPromotionAdjustParameter.scala:169)
2021-12-03 20:18:39,134 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 66, ShuffleMapStage 64)
2021-12-03 20:18:39,134 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List(ShuffleMapStage 66, ShuffleMapStage 64)
2021-12-03 20:18:39,134 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ShuffleMapStage 64 (MapPartitionsRDD[75] at intersection at PaidPromotionAdjustParameter.scala:161), which has no missing parents
2021-12-03 20:18:39,135 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_45 stored as values in memory (estimated size 4.0 KB, free 1989.8 MB)
2021-12-03 20:18:39,136 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_45_piece0 stored as bytes in memory (estimated size 2.3 KB, free 1989.8 MB)
2021-12-03 20:18:39,136 [dispatcher-event-loop-4] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_45_piece0 in memory on qb:50070 (size: 2.3 KB, free: 1990.7 MB)
2021-12-03 20:18:39,136 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 45 from broadcast at DAGScheduler.scala:1039
2021-12-03 20:18:39,136 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from ShuffleMapStage 64 (MapPartitionsRDD[75] at intersection at PaidPromotionAdjustParameter.scala:161) (first 15 tasks are for partitions Vector(0, 1))
2021-12-03 20:18:39,136 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 64.0 with 2 tasks
2021-12-03 20:18:39,136 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ShuffleMapStage 66 (MapPartitionsRDD[74] at intersection at PaidPromotionAdjustParameter.scala:161), which has no missing parents
2021-12-03 20:18:39,136 [dispatcher-event-loop-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 64.0 (TID 278, localhost, executor driver, partition 0, ANY, 7638 bytes)
2021-12-03 20:18:39,137 [dispatcher-event-loop-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 64.0 (TID 279, localhost, executor driver, partition 1, ANY, 7638 bytes)
2021-12-03 20:18:39,137 [Executor task launch worker for task 279] INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 64.0 (TID 279)
2021-12-03 20:18:39,137 [Executor task launch worker for task 278] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 64.0 (TID 278)
2021-12-03 20:18:39,137 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_46 stored as values in memory (estimated size 4.0 KB, free 1989.8 MB)
2021-12-03 20:18:39,137 [Executor task launch worker for task 279] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 2 non-empty blocks out of 2 blocks
2021-12-03 20:18:39,137 [Executor task launch worker for task 278] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 2 non-empty blocks out of 2 blocks
2021-12-03 20:18:39,137 [Executor task launch worker for task 279] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 20:18:39,137 [Executor task launch worker for task 278] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 20:18:39,138 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_46_piece0 stored as bytes in memory (estimated size 2.3 KB, free 1989.8 MB)
2021-12-03 20:18:39,138 [dispatcher-event-loop-10] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_46_piece0 in memory on qb:50070 (size: 2.3 KB, free: 1990.7 MB)
2021-12-03 20:18:39,138 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 46 from broadcast at DAGScheduler.scala:1039
2021-12-03 20:18:39,138 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 4 missing tasks from ShuffleMapStage 66 (MapPartitionsRDD[74] at intersection at PaidPromotionAdjustParameter.scala:161) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
2021-12-03 20:18:39,138 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 66.0 with 4 tasks
2021-12-03 20:18:39,139 [dispatcher-event-loop-6] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 66.0 (TID 280, localhost, executor driver, partition 0, ANY, 7638 bytes)
2021-12-03 20:18:39,139 [dispatcher-event-loop-6] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 66.0 (TID 281, localhost, executor driver, partition 1, ANY, 7638 bytes)
2021-12-03 20:18:39,139 [dispatcher-event-loop-6] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 2.0 in stage 66.0 (TID 282, localhost, executor driver, partition 2, ANY, 7638 bytes)
2021-12-03 20:18:39,139 [dispatcher-event-loop-6] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 3.0 in stage 66.0 (TID 283, localhost, executor driver, partition 3, ANY, 7638 bytes)
2021-12-03 20:18:39,139 [Executor task launch worker for task 280] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 66.0 (TID 280)
2021-12-03 20:18:39,139 [Executor task launch worker for task 283] INFO [org.apache.spark.executor.Executor] - Running task 3.0 in stage 66.0 (TID 283)
2021-12-03 20:18:39,139 [Executor task launch worker for task 282] INFO [org.apache.spark.executor.Executor] - Running task 2.0 in stage 66.0 (TID 282)
2021-12-03 20:18:39,139 [Executor task launch worker for task 281] INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 66.0 (TID 281)
2021-12-03 20:18:39,140 [Executor task launch worker for task 282] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 4 non-empty blocks out of 4 blocks
2021-12-03 20:18:39,140 [Executor task launch worker for task 280] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 4 non-empty blocks out of 4 blocks
2021-12-03 20:18:39,140 [Executor task launch worker for task 281] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 4 non-empty blocks out of 4 blocks
2021-12-03 20:18:39,140 [Executor task launch worker for task 280] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 1 ms
2021-12-03 20:18:39,140 [Executor task launch worker for task 283] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 4 non-empty blocks out of 4 blocks
2021-12-03 20:18:39,140 [Executor task launch worker for task 282] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 1 ms
2021-12-03 20:18:39,140 [Executor task launch worker for task 283] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 20:18:39,140 [Executor task launch worker for task 281] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 1 ms
2021-12-03 20:18:39,154 [Executor task launch worker for task 283] INFO [org.apache.spark.executor.Executor] - Finished task 3.0 in stage 66.0 (TID 283). 1163 bytes result sent to driver
2021-12-03 20:18:39,154 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 3.0 in stage 66.0 (TID 283) in 15 ms on localhost (executor driver) (1/4)
2021-12-03 20:18:39,155 [Executor task launch worker for task 280] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 66.0 (TID 280). 1163 bytes result sent to driver
2021-12-03 20:18:39,155 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 66.0 (TID 280) in 16 ms on localhost (executor driver) (2/4)
2021-12-03 20:18:39,156 [Executor task launch worker for task 281] INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 66.0 (TID 281). 1163 bytes result sent to driver
2021-12-03 20:18:39,156 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 66.0 (TID 281) in 17 ms on localhost (executor driver) (3/4)
2021-12-03 20:18:39,157 [Executor task launch worker for task 282] INFO [org.apache.spark.executor.Executor] - Finished task 2.0 in stage 66.0 (TID 282). 1163 bytes result sent to driver
2021-12-03 20:18:39,157 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 2.0 in stage 66.0 (TID 282) in 18 ms on localhost (executor driver) (4/4)
2021-12-03 20:18:39,157 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 66.0, whose tasks have all completed, from pool 
2021-12-03 20:18:39,157 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ShuffleMapStage 66 (intersection at PaidPromotionAdjustParameter.scala:161) finished in 0.020 s
2021-12-03 20:18:39,157 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - looking for newly runnable stages
2021-12-03 20:18:39,157 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - running: Set(ShuffleMapStage 64)
2021-12-03 20:18:39,157 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - waiting: Set(ResultStage 67)
2021-12-03 20:18:39,157 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - failed: Set()
2021-12-03 20:18:39,158 [Executor task launch worker for task 278] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 64.0 (TID 278). 1163 bytes result sent to driver
2021-12-03 20:18:39,158 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 64.0 (TID 278) in 22 ms on localhost (executor driver) (1/2)
2021-12-03 20:18:39,159 [Executor task launch worker for task 279] INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 64.0 (TID 279). 1163 bytes result sent to driver
2021-12-03 20:18:39,159 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 64.0 (TID 279) in 23 ms on localhost (executor driver) (2/2)
2021-12-03 20:18:39,159 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 64.0, whose tasks have all completed, from pool 
2021-12-03 20:18:39,159 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ShuffleMapStage 64 (intersection at PaidPromotionAdjustParameter.scala:161) finished in 0.025 s
2021-12-03 20:18:39,159 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - looking for newly runnable stages
2021-12-03 20:18:39,159 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - running: Set()
2021-12-03 20:18:39,159 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - waiting: Set(ResultStage 67)
2021-12-03 20:18:39,159 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - failed: Set()
2021-12-03 20:18:39,159 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 67 (MapPartitionsRDD[79] at intersection at PaidPromotionAdjustParameter.scala:161), which has no missing parents
2021-12-03 20:18:39,160 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_47 stored as values in memory (estimated size 3.6 KB, free 1989.8 MB)
2021-12-03 20:18:39,161 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_47_piece0 stored as bytes in memory (estimated size 2.1 KB, free 1989.8 MB)
2021-12-03 20:18:39,161 [dispatcher-event-loop-10] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_47_piece0 in memory on qb:50070 (size: 2.1 KB, free: 1990.7 MB)
2021-12-03 20:18:39,161 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 47 from broadcast at DAGScheduler.scala:1039
2021-12-03 20:18:39,161 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 4 missing tasks from ResultStage 67 (MapPartitionsRDD[79] at intersection at PaidPromotionAdjustParameter.scala:161) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
2021-12-03 20:18:39,161 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 67.0 with 4 tasks
2021-12-03 20:18:39,162 [dispatcher-event-loop-6] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 67.0 (TID 284, localhost, executor driver, partition 0, PROCESS_LOCAL, 7712 bytes)
2021-12-03 20:18:39,162 [dispatcher-event-loop-6] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 67.0 (TID 285, localhost, executor driver, partition 1, PROCESS_LOCAL, 7712 bytes)
2021-12-03 20:18:39,162 [dispatcher-event-loop-6] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 2.0 in stage 67.0 (TID 286, localhost, executor driver, partition 2, PROCESS_LOCAL, 7712 bytes)
2021-12-03 20:18:39,162 [dispatcher-event-loop-6] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 3.0 in stage 67.0 (TID 287, localhost, executor driver, partition 3, PROCESS_LOCAL, 7712 bytes)
2021-12-03 20:18:39,162 [Executor task launch worker for task 284] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 67.0 (TID 284)
2021-12-03 20:18:39,162 [Executor task launch worker for task 287] INFO [org.apache.spark.executor.Executor] - Running task 3.0 in stage 67.0 (TID 287)
2021-12-03 20:18:39,162 [Executor task launch worker for task 286] INFO [org.apache.spark.executor.Executor] - Running task 2.0 in stage 67.0 (TID 286)
2021-12-03 20:18:39,162 [Executor task launch worker for task 285] INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 67.0 (TID 285)
2021-12-03 20:18:39,164 [Executor task launch worker for task 287] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 4 blocks
2021-12-03 20:18:39,164 [Executor task launch worker for task 284] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 4 blocks
2021-12-03 20:18:39,164 [Executor task launch worker for task 287] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 20:18:39,164 [Executor task launch worker for task 286] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 4 blocks
2021-12-03 20:18:39,164 [Executor task launch worker for task 285] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 4 blocks
2021-12-03 20:18:39,164 [Executor task launch worker for task 286] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 20:18:39,164 [Executor task launch worker for task 284] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 20:18:39,164 [Executor task launch worker for task 285] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 20:18:39,165 [Executor task launch worker for task 287] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2021-12-03 20:18:39,165 [Executor task launch worker for task 287] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 20:18:39,165 [Executor task launch worker for task 284] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2021-12-03 20:18:39,165 [Executor task launch worker for task 285] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2021-12-03 20:18:39,165 [Executor task launch worker for task 284] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 20:18:39,165 [Executor task launch worker for task 286] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2021-12-03 20:18:39,165 [Executor task launch worker for task 285] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 20:18:39,165 [Executor task launch worker for task 286] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 20:18:39,172 [Executor task launch worker for task 286] INFO [org.apache.spark.executor.Executor] - Finished task 2.0 in stage 67.0 (TID 286). 967 bytes result sent to driver
2021-12-03 20:18:39,172 [Executor task launch worker for task 284] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 67.0 (TID 284). 967 bytes result sent to driver
2021-12-03 20:18:39,172 [Executor task launch worker for task 285] INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 67.0 (TID 285). 967 bytes result sent to driver
2021-12-03 20:18:39,172 [Executor task launch worker for task 287] INFO [org.apache.spark.executor.Executor] - Finished task 3.0 in stage 67.0 (TID 287). 967 bytes result sent to driver
2021-12-03 20:18:39,172 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 2.0 in stage 67.0 (TID 286) in 10 ms on localhost (executor driver) (1/4)
2021-12-03 20:18:39,172 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 67.0 (TID 284) in 10 ms on localhost (executor driver) (2/4)
2021-12-03 20:18:39,172 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 67.0 (TID 285) in 10 ms on localhost (executor driver) (3/4)
2021-12-03 20:18:39,172 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 3.0 in stage 67.0 (TID 287) in 10 ms on localhost (executor driver) (4/4)
2021-12-03 20:18:39,172 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 67.0, whose tasks have all completed, from pool 
2021-12-03 20:18:39,172 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 67 (count at PaidPromotionAdjustParameter.scala:169) finished in 0.012 s
2021-12-03 20:18:39,173 [main] INFO [org.apache.spark.scheduler.DAGScheduler] - Job 27 finished: count at PaidPromotionAdjustParameter.scala:169, took 0.039097 s
2021-12-03 20:18:39,173 [main] INFO [PaidPromotion$] - 最终共 同 节目数 = 75
2021-12-03 20:18:39,177 [main] INFO [org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter] - File Output Committer Algorithm version is 1
2021-12-03 20:18:39,204 [main] INFO [org.apache.spark.SparkContext] - Starting job: runJob at SparkHadoopWriter.scala:78
2021-12-03 20:18:39,204 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 28 (runJob at SparkHadoopWriter.scala:78) with 1 output partitions
2021-12-03 20:18:39,204 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 68 (runJob at SparkHadoopWriter.scala:78)
2021-12-03 20:18:39,204 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List()
2021-12-03 20:18:39,205 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2021-12-03 20:18:39,205 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 68 (MapPartitionsRDD[82] at saveAsTextFile at PaidPromotionAdjustParameter.scala:174), which has no missing parents
2021-12-03 20:18:39,214 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_48 stored as values in memory (estimated size 195.2 KB, free 1989.6 MB)
2021-12-03 20:18:39,216 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_48_piece0 stored as bytes in memory (estimated size 71.6 KB, free 1989.5 MB)
2021-12-03 20:18:39,216 [dispatcher-event-loop-2] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_48_piece0 in memory on qb:50070 (size: 71.6 KB, free: 1990.6 MB)
2021-12-03 20:18:39,216 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 48 from broadcast at DAGScheduler.scala:1039
2021-12-03 20:18:39,216 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 68 (MapPartitionsRDD[82] at saveAsTextFile at PaidPromotionAdjustParameter.scala:174) (first 15 tasks are for partitions Vector(0))
2021-12-03 20:18:39,216 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 68.0 with 1 tasks
2021-12-03 20:18:39,217 [dispatcher-event-loop-9] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 68.0 (TID 288, localhost, executor driver, partition 0, ANY, 8509 bytes)
2021-12-03 20:18:39,217 [Executor task launch worker for task 288] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 68.0 (TID 288)
2021-12-03 20:18:39,222 [Executor task launch worker for task 288] INFO [org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter] - File Output Committer Algorithm version is 1
2021-12-03 20:18:39,236 [Executor task launch worker for task 288] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/order_data.bcp:0+3442194
2021-12-03 20:18:39,553 [Executor task launch worker for task 288] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/order_data.bcp:3442194+3442195
2021-12-03 20:18:39,884 [Executor task launch worker for task 288] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/order_data.bcp:0+3442194
2021-12-03 20:18:40,610 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1037
2021-12-03 20:18:40,611 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1128
2021-12-03 20:18:40,611 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1073
2021-12-03 20:18:40,611 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1038
2021-12-03 20:18:40,611 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1097
2021-12-03 20:18:40,612 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1052
2021-12-03 20:18:40,612 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1092
2021-12-03 20:18:40,612 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1102
2021-12-03 20:18:40,612 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1109
2021-12-03 20:18:40,612 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1091
2021-12-03 20:18:40,612 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1046
2021-12-03 20:18:40,612 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1027
2021-12-03 20:18:40,612 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1099
2021-12-03 20:18:40,612 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1045
2021-12-03 20:18:40,612 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1036
2021-12-03 20:18:40,612 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1032
2021-12-03 20:18:40,612 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1145
2021-12-03 20:18:40,612 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1089
2021-12-03 20:18:40,612 [dispatcher-event-loop-7] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_45_piece0 on qb:50070 in memory (size: 2.3 KB, free: 1990.6 MB)
2021-12-03 20:18:40,613 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1127
2021-12-03 20:18:40,613 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1126
2021-12-03 20:18:40,613 [dispatcher-event-loop-5] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_44_piece0 on qb:50070 in memory (size: 2.2 KB, free: 1990.6 MB)
2021-12-03 20:18:40,613 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1107
2021-12-03 20:18:40,613 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1029
2021-12-03 20:18:40,613 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1129
2021-12-03 20:18:40,613 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1104
2021-12-03 20:18:40,613 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1028
2021-12-03 20:18:40,613 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1025
2021-12-03 20:18:40,613 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1041
2021-12-03 20:18:40,613 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1080
2021-12-03 20:18:40,613 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1134
2021-12-03 20:18:40,613 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1143
2021-12-03 20:18:40,613 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1057
2021-12-03 20:18:40,613 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1103
2021-12-03 20:18:40,613 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1133
2021-12-03 20:18:40,613 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1142
2021-12-03 20:18:40,613 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1083
2021-12-03 20:18:40,613 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1048
2021-12-03 20:18:40,613 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1116
2021-12-03 20:18:40,613 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1100
2021-12-03 20:18:40,613 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1043
2021-12-03 20:18:40,613 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1044
2021-12-03 20:18:40,613 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1031
2021-12-03 20:18:40,613 [dispatcher-event-loop-11] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_47_piece0 on qb:50070 in memory (size: 2.1 KB, free: 1990.6 MB)
2021-12-03 20:18:40,614 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1136
2021-12-03 20:18:40,614 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1085
2021-12-03 20:18:40,614 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1071
2021-12-03 20:18:40,614 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1140
2021-12-03 20:18:40,614 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1111
2021-12-03 20:18:40,614 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1138
2021-12-03 20:18:40,614 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1132
2021-12-03 20:18:40,614 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1059
2021-12-03 20:18:40,614 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1125
2021-12-03 20:18:40,614 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1146
2021-12-03 20:18:40,614 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1105
2021-12-03 20:18:40,614 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1060
2021-12-03 20:18:40,614 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1137
2021-12-03 20:18:40,614 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1147
2021-12-03 20:18:40,614 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1123
2021-12-03 20:18:40,614 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1118
2021-12-03 20:18:40,614 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1042
2021-12-03 20:18:40,614 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1075
2021-12-03 20:18:40,614 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1068
2021-12-03 20:18:40,614 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1050
2021-12-03 20:18:40,614 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1033
2021-12-03 20:18:40,614 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1087
2021-12-03 20:18:40,614 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1084
2021-12-03 20:18:40,614 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1079
2021-12-03 20:18:40,614 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1078
2021-12-03 20:18:40,614 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1101
2021-12-03 20:18:40,614 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1124
2021-12-03 20:18:40,614 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1081
2021-12-03 20:18:40,614 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1115
2021-12-03 20:18:40,614 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1119
2021-12-03 20:18:40,614 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1096
2021-12-03 20:18:40,614 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1034
2021-12-03 20:18:40,614 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1094
2021-12-03 20:18:40,614 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1090
2021-12-03 20:18:40,614 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1144
2021-12-03 20:18:40,614 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1077
2021-12-03 20:18:40,614 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1114
2021-12-03 20:18:40,614 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1088
2021-12-03 20:18:40,614 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1063
2021-12-03 20:18:40,614 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1149
2021-12-03 20:18:40,614 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1064
2021-12-03 20:18:40,614 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1054
2021-12-03 20:18:40,614 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1056
2021-12-03 20:18:40,614 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1065
2021-12-03 20:18:40,614 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1093
2021-12-03 20:18:40,614 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1135
2021-12-03 20:18:40,614 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1148
2021-12-03 20:18:40,614 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1039
2021-12-03 20:18:40,614 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1062
2021-12-03 20:18:40,614 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1139
2021-12-03 20:18:40,614 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1069
2021-12-03 20:18:40,614 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1117
2021-12-03 20:18:40,614 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1120
2021-12-03 20:18:40,614 [dispatcher-event-loop-10] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_43_piece0 on qb:50070 in memory (size: 43.1 KB, free: 1990.6 MB)
2021-12-03 20:18:40,615 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1121
2021-12-03 20:18:40,615 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1110
2021-12-03 20:18:40,615 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1106
2021-12-03 20:18:40,615 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1055
2021-12-03 20:18:40,615 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1051
2021-12-03 20:18:40,615 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1095
2021-12-03 20:18:40,615 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1141
2021-12-03 20:18:40,615 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1047
2021-12-03 20:18:40,615 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1058
2021-12-03 20:18:40,615 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1061
2021-12-03 20:18:40,615 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1086
2021-12-03 20:18:40,615 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1076
2021-12-03 20:18:40,615 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1082
2021-12-03 20:18:40,615 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1112
2021-12-03 20:18:40,615 [dispatcher-event-loop-7] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_46_piece0 on qb:50070 in memory (size: 2.3 KB, free: 1990.6 MB)
2021-12-03 20:18:40,615 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1130
2021-12-03 20:18:40,615 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1074
2021-12-03 20:18:40,615 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1122
2021-12-03 20:18:40,615 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1066
2021-12-03 20:18:40,615 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1098
2021-12-03 20:18:40,615 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1108
2021-12-03 20:18:40,615 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1040
2021-12-03 20:18:40,615 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1030
2021-12-03 20:18:40,615 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1053
2021-12-03 20:18:40,615 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1070
2021-12-03 20:18:40,615 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1072
2021-12-03 20:18:40,615 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1049
2021-12-03 20:18:40,615 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1131
2021-12-03 20:18:40,615 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1113
2021-12-03 20:18:40,615 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1035
2021-12-03 20:18:40,615 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1067
2021-12-03 20:18:40,615 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1026
2021-12-03 20:18:40,995 [Executor task launch worker for task 288] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/order_data.bcp:3442194+3442195
2021-12-03 20:18:41,746 [Executor task launch worker for task 288] INFO [org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter] - Saved output of task 'attempt_20211203201839_0082_m_000000_0' to hdfs://hdp1:8020/sk/chongqing/sample_data/set-train-device-production-data.bcp/_temporary/0/task_20211203201839_0082_m_000000
2021-12-03 20:18:41,746 [Executor task launch worker for task 288] INFO [org.apache.spark.mapred.SparkHadoopMapRedUtil] - attempt_20211203201839_0082_m_000000_0: Committed
2021-12-03 20:18:41,747 [Executor task launch worker for task 288] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 68.0 (TID 288). 998 bytes result sent to driver
2021-12-03 20:18:41,747 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 68.0 (TID 288) in 2530 ms on localhost (executor driver) (1/1)
2021-12-03 20:18:41,747 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 68.0, whose tasks have all completed, from pool 
2021-12-03 20:18:41,747 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 68 (runJob at SparkHadoopWriter.scala:78) finished in 2.542 s
2021-12-03 20:18:41,747 [main] INFO [org.apache.spark.scheduler.DAGScheduler] - Job 28 finished: runJob at SparkHadoopWriter.scala:78, took 2.543915 s
2021-12-03 20:18:41,790 [main] INFO [org.apache.spark.internal.io.SparkHadoopWriter] - Job job_20211203201839_0082 committed.
2021-12-03 20:18:41,794 [main] INFO [org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter] - File Output Committer Algorithm version is 1
2021-12-03 20:18:41,815 [main] INFO [org.apache.spark.SparkContext] - Starting job: runJob at SparkHadoopWriter.scala:78
2021-12-03 20:18:41,816 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 29 (runJob at SparkHadoopWriter.scala:78) with 1 output partitions
2021-12-03 20:18:41,816 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 69 (runJob at SparkHadoopWriter.scala:78)
2021-12-03 20:18:41,816 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List()
2021-12-03 20:18:41,816 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2021-12-03 20:18:41,816 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 69 (MapPartitionsRDD[85] at saveAsTextFile at PaidPromotionAdjustParameter.scala:177), which has no missing parents
2021-12-03 20:18:41,825 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_49 stored as values in memory (estimated size 194.7 KB, free 1989.5 MB)
2021-12-03 20:18:41,827 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_49_piece0 stored as bytes in memory (estimated size 71.3 KB, free 1989.5 MB)
2021-12-03 20:18:41,827 [dispatcher-event-loop-5] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_49_piece0 in memory on qb:50070 (size: 71.3 KB, free: 1990.6 MB)
2021-12-03 20:18:41,827 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 49 from broadcast at DAGScheduler.scala:1039
2021-12-03 20:18:41,828 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 69 (MapPartitionsRDD[85] at saveAsTextFile at PaidPromotionAdjustParameter.scala:177) (first 15 tasks are for partitions Vector(0))
2021-12-03 20:18:41,828 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 69.0 with 1 tasks
2021-12-03 20:18:41,828 [dispatcher-event-loop-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 69.0 (TID 289, localhost, executor driver, partition 0, ANY, 8337 bytes)
2021-12-03 20:18:41,828 [Executor task launch worker for task 289] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 69.0 (TID 289)
2021-12-03 20:18:41,833 [Executor task launch worker for task 289] INFO [org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter] - File Output Committer Algorithm version is 1
2021-12-03 20:18:41,839 [Executor task launch worker for task 289] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/order_data.bcp:0+3442194
2021-12-03 20:18:42,149 [Executor task launch worker for task 289] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/order_data.bcp:3442194+3442195
2021-12-03 20:18:42,938 [Executor task launch worker for task 289] INFO [org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter] - Saved output of task 'attempt_20211203201841_0085_m_000000_0' to hdfs://hdp1:8020/sk/chongqing/sample_data/set-validation-device-production-data.bcp/_temporary/0/task_20211203201841_0085_m_000000
2021-12-03 20:18:42,938 [Executor task launch worker for task 289] INFO [org.apache.spark.mapred.SparkHadoopMapRedUtil] - attempt_20211203201841_0085_m_000000_0: Committed
2021-12-03 20:18:42,939 [Executor task launch worker for task 289] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 69.0 (TID 289). 955 bytes result sent to driver
2021-12-03 20:18:42,940 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 69.0 (TID 289) in 1112 ms on localhost (executor driver) (1/1)
2021-12-03 20:18:42,940 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 69.0, whose tasks have all completed, from pool 
2021-12-03 20:18:42,940 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 69 (runJob at SparkHadoopWriter.scala:78) finished in 1.124 s
2021-12-03 20:18:42,940 [main] INFO [org.apache.spark.scheduler.DAGScheduler] - Job 29 finished: runJob at SparkHadoopWriter.scala:78, took 1.125333 s
2021-12-03 20:18:42,982 [main] INFO [org.apache.spark.internal.io.SparkHadoopWriter] - Job job_20211203201841_0085 committed.
2021-12-03 20:18:42,992 [main] INFO [PaidPromotion$] - 验证集用户实际观看列表-----------------------------------
2021-12-03 20:18:42,993 [main] INFO [org.apache.spark.SparkContext] - Starting job: count at PaidPromotionAdjustParameter.scala:187
2021-12-03 20:18:42,993 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 49 (filter at PaidPromotionAdjustParameter.scala:145)
2021-12-03 20:18:42,993 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 30 (count at PaidPromotionAdjustParameter.scala:187) with 2 output partitions
2021-12-03 20:18:42,993 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 71 (count at PaidPromotionAdjustParameter.scala:187)
2021-12-03 20:18:42,993 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 70)
2021-12-03 20:18:42,993 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List(ShuffleMapStage 70)
2021-12-03 20:18:42,993 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ShuffleMapStage 70 (MapPartitionsRDD[49] at filter at PaidPromotionAdjustParameter.scala:145), which has no missing parents
2021-12-03 20:18:42,994 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_50 stored as values in memory (estimated size 120.0 KB, free 1989.4 MB)
2021-12-03 20:18:42,996 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_50_piece0 stored as bytes in memory (estimated size 43.2 KB, free 1989.3 MB)
2021-12-03 20:18:42,996 [dispatcher-event-loop-2] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_50_piece0 in memory on qb:50070 (size: 43.2 KB, free: 1990.5 MB)
2021-12-03 20:18:42,996 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 50 from broadcast at DAGScheduler.scala:1039
2021-12-03 20:18:42,996 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from ShuffleMapStage 70 (MapPartitionsRDD[49] at filter at PaidPromotionAdjustParameter.scala:145) (first 15 tasks are for partitions Vector(0, 1))
2021-12-03 20:18:42,996 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 70.0 with 2 tasks
2021-12-03 20:18:42,996 [dispatcher-event-loop-10] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 70.0 (TID 290, localhost, executor driver, partition 0, ANY, 7885 bytes)
2021-12-03 20:18:42,997 [dispatcher-event-loop-10] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 70.0 (TID 291, localhost, executor driver, partition 1, ANY, 7885 bytes)
2021-12-03 20:18:42,997 [Executor task launch worker for task 290] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 70.0 (TID 290)
2021-12-03 20:18:42,997 [Executor task launch worker for task 291] INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 70.0 (TID 291)
2021-12-03 20:18:42,998 [Executor task launch worker for task 291] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/order_data.bcp:3442194+3442195
2021-12-03 20:18:42,998 [Executor task launch worker for task 290] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/order_data.bcp:0+3442194
2021-12-03 20:18:43,880 [Executor task launch worker for task 291] INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 70.0 (TID 291). 860 bytes result sent to driver
2021-12-03 20:18:43,881 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 70.0 (TID 291) in 885 ms on localhost (executor driver) (1/2)
2021-12-03 20:18:43,963 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1194
2021-12-03 20:18:43,963 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1162
2021-12-03 20:18:43,963 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1170
2021-12-03 20:18:43,963 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1151
2021-12-03 20:18:43,963 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1178
2021-12-03 20:18:43,964 [dispatcher-event-loop-5] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_49_piece0 on qb:50070 in memory (size: 71.3 KB, free: 1990.6 MB)
2021-12-03 20:18:43,964 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1152
2021-12-03 20:18:43,964 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1185
2021-12-03 20:18:43,964 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1180
2021-12-03 20:18:43,964 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1191
2021-12-03 20:18:43,964 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1190
2021-12-03 20:18:43,964 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1195
2021-12-03 20:18:43,964 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1196
2021-12-03 20:18:43,964 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1193
2021-12-03 20:18:43,964 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1198
2021-12-03 20:18:43,964 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1189
2021-12-03 20:18:43,964 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1157
2021-12-03 20:18:43,964 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1181
2021-12-03 20:18:43,964 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1174
2021-12-03 20:18:43,964 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1183
2021-12-03 20:18:43,964 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1173
2021-12-03 20:18:43,964 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1154
2021-12-03 20:18:43,964 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1175
2021-12-03 20:18:43,964 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1182
2021-12-03 20:18:43,964 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1184
2021-12-03 20:18:43,964 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1171
2021-12-03 20:18:43,964 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1169
2021-12-03 20:18:43,964 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1176
2021-12-03 20:18:43,964 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1197
2021-12-03 20:18:43,964 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1159
2021-12-03 20:18:43,965 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1155
2021-12-03 20:18:43,965 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1166
2021-12-03 20:18:43,965 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1187
2021-12-03 20:18:43,965 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1168
2021-12-03 20:18:43,965 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1199
2021-12-03 20:18:43,965 [dispatcher-event-loop-11] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_48_piece0 on qb:50070 in memory (size: 71.6 KB, free: 1990.7 MB)
2021-12-03 20:18:43,965 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1172
2021-12-03 20:18:43,965 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1153
2021-12-03 20:18:43,965 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1188
2021-12-03 20:18:43,965 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1192
2021-12-03 20:18:43,965 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1160
2021-12-03 20:18:43,965 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1156
2021-12-03 20:18:43,965 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1158
2021-12-03 20:18:43,965 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1186
2021-12-03 20:18:43,965 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1167
2021-12-03 20:18:43,965 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1163
2021-12-03 20:18:43,965 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1161
2021-12-03 20:18:43,965 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1179
2021-12-03 20:18:43,965 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1177
2021-12-03 20:18:43,965 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1150
2021-12-03 20:18:43,965 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1165
2021-12-03 20:18:43,965 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1164
2021-12-03 20:18:44,098 [Executor task launch worker for task 290] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 70.0 (TID 290). 946 bytes result sent to driver
2021-12-03 20:18:44,098 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 70.0 (TID 290) in 1102 ms on localhost (executor driver) (2/2)
2021-12-03 20:18:44,098 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 70.0, whose tasks have all completed, from pool 
2021-12-03 20:18:44,098 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ShuffleMapStage 70 (filter at PaidPromotionAdjustParameter.scala:145) finished in 1.104 s
2021-12-03 20:18:44,098 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - looking for newly runnable stages
2021-12-03 20:18:44,098 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - running: Set()
2021-12-03 20:18:44,098 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - waiting: Set(ResultStage 71)
2021-12-03 20:18:44,098 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - failed: Set()
2021-12-03 20:18:44,098 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 71 (MapPartitionsRDD[87] at map at PaidPromotionAdjustParameter.scala:181), which has no missing parents
2021-12-03 20:18:44,100 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_51 stored as values in memory (estimated size 120.9 KB, free 1989.7 MB)
2021-12-03 20:18:44,102 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_51_piece0 stored as bytes in memory (estimated size 43.7 KB, free 1989.7 MB)
2021-12-03 20:18:44,102 [dispatcher-event-loop-2] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_51_piece0 in memory on qb:50070 (size: 43.7 KB, free: 1990.6 MB)
2021-12-03 20:18:44,102 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 51 from broadcast at DAGScheduler.scala:1039
2021-12-03 20:18:44,102 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from ResultStage 71 (MapPartitionsRDD[87] at map at PaidPromotionAdjustParameter.scala:181) (first 15 tasks are for partitions Vector(0, 1))
2021-12-03 20:18:44,102 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 71.0 with 2 tasks
2021-12-03 20:18:44,103 [dispatcher-event-loop-10] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 71.0 (TID 292, localhost, executor driver, partition 0, ANY, 7649 bytes)
2021-12-03 20:18:44,103 [dispatcher-event-loop-10] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 71.0 (TID 293, localhost, executor driver, partition 1, ANY, 7649 bytes)
2021-12-03 20:18:44,103 [Executor task launch worker for task 293] INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 71.0 (TID 293)
2021-12-03 20:18:44,103 [Executor task launch worker for task 292] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 71.0 (TID 292)
2021-12-03 20:18:44,104 [Executor task launch worker for task 293] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 2 non-empty blocks out of 2 blocks
2021-12-03 20:18:44,104 [Executor task launch worker for task 292] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 2 non-empty blocks out of 2 blocks
2021-12-03 20:18:44,104 [Executor task launch worker for task 293] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 20:18:44,104 [Executor task launch worker for task 292] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 20:18:44,130 [Executor task launch worker for task 293] INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 71.0 (TID 293). 1054 bytes result sent to driver
2021-12-03 20:18:44,130 [Executor task launch worker for task 292] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 71.0 (TID 292). 1054 bytes result sent to driver
2021-12-03 20:18:44,130 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 71.0 (TID 293) in 27 ms on localhost (executor driver) (1/2)
2021-12-03 20:18:44,130 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 71.0 (TID 292) in 28 ms on localhost (executor driver) (2/2)
2021-12-03 20:18:44,131 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 71.0, whose tasks have all completed, from pool 
2021-12-03 20:18:44,131 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 71 (count at PaidPromotionAdjustParameter.scala:187) finished in 0.033 s
2021-12-03 20:18:44,131 [main] INFO [org.apache.spark.scheduler.DAGScheduler] - Job 30 finished: count at PaidPromotionAdjustParameter.scala:187, took 1.137486 s
2021-12-03 20:18:44,131 [main] INFO [PaidPromotion$] - 验证集用户列表数量：3247
2021-12-03 20:18:44,138 [main] INFO [org.apache.spark.SparkContext] - Starting job: take at PaidPromotionAdjustParameter.scala:188
2021-12-03 20:18:44,138 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 31 (take at PaidPromotionAdjustParameter.scala:188) with 1 output partitions
2021-12-03 20:18:44,139 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 73 (take at PaidPromotionAdjustParameter.scala:188)
2021-12-03 20:18:44,139 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 72)
2021-12-03 20:18:44,139 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2021-12-03 20:18:44,139 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 73 (MapPartitionsRDD[87] at map at PaidPromotionAdjustParameter.scala:181), which has no missing parents
2021-12-03 20:18:44,140 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_52 stored as values in memory (estimated size 121.1 KB, free 1989.6 MB)
2021-12-03 20:18:44,141 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_52_piece0 stored as bytes in memory (estimated size 43.7 KB, free 1989.5 MB)
2021-12-03 20:18:44,142 [dispatcher-event-loop-8] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_52_piece0 in memory on qb:50070 (size: 43.7 KB, free: 1990.6 MB)
2021-12-03 20:18:44,142 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 52 from broadcast at DAGScheduler.scala:1039
2021-12-03 20:18:44,142 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 73 (MapPartitionsRDD[87] at map at PaidPromotionAdjustParameter.scala:181) (first 15 tasks are for partitions Vector(0))
2021-12-03 20:18:44,142 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 73.0 with 1 tasks
2021-12-03 20:18:44,142 [dispatcher-event-loop-5] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 73.0 (TID 294, localhost, executor driver, partition 0, ANY, 7649 bytes)
2021-12-03 20:18:44,142 [Executor task launch worker for task 294] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 73.0 (TID 294)
2021-12-03 20:18:44,144 [Executor task launch worker for task 294] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 2 non-empty blocks out of 2 blocks
2021-12-03 20:18:44,144 [Executor task launch worker for task 294] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 20:18:44,156 [Executor task launch worker for task 294] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 73.0 (TID 294). 2530 bytes result sent to driver
2021-12-03 20:18:44,156 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 73.0 (TID 294) in 14 ms on localhost (executor driver) (1/1)
2021-12-03 20:18:44,156 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 73.0, whose tasks have all completed, from pool 
2021-12-03 20:18:44,157 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 73 (take at PaidPromotionAdjustParameter.scala:188) finished in 0.018 s
2021-12-03 20:18:44,157 [main] INFO [org.apache.spark.scheduler.DAGScheduler] - Job 31 finished: take at PaidPromotionAdjustParameter.scala:188, took 0.018514 s
2021-12-03 20:18:44,165 [main] INFO [PaidPromotion$] - 训练集用户实际观看列表-----------------------------------
2021-12-03 20:18:44,167 [main] INFO [org.apache.spark.SparkContext] - Starting job: count at PaidPromotionAdjustParameter.scala:198
2021-12-03 20:18:44,167 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 51 (union at PaidPromotionAdjustParameter.scala:149)
2021-12-03 20:18:44,167 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 32 (count at PaidPromotionAdjustParameter.scala:198) with 4 output partitions
2021-12-03 20:18:44,167 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 75 (count at PaidPromotionAdjustParameter.scala:198)
2021-12-03 20:18:44,167 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 74)
2021-12-03 20:18:44,167 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List(ShuffleMapStage 74)
2021-12-03 20:18:44,167 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ShuffleMapStage 74 (UnionRDD[51] at union at PaidPromotionAdjustParameter.scala:149), which has no missing parents
2021-12-03 20:18:44,168 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_53 stored as values in memory (estimated size 120.6 KB, free 1989.4 MB)
2021-12-03 20:18:44,170 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_53_piece0 stored as bytes in memory (estimated size 43.5 KB, free 1989.3 MB)
2021-12-03 20:18:44,170 [dispatcher-event-loop-11] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_53_piece0 in memory on qb:50070 (size: 43.5 KB, free: 1990.5 MB)
2021-12-03 20:18:44,170 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 53 from broadcast at DAGScheduler.scala:1039
2021-12-03 20:18:44,170 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 4 missing tasks from ShuffleMapStage 74 (UnionRDD[51] at union at PaidPromotionAdjustParameter.scala:149) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
2021-12-03 20:18:44,170 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 74.0 with 4 tasks
2021-12-03 20:18:44,171 [dispatcher-event-loop-9] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 74.0 (TID 295, localhost, executor driver, partition 0, ANY, 7994 bytes)
2021-12-03 20:18:44,171 [dispatcher-event-loop-9] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 74.0 (TID 296, localhost, executor driver, partition 1, ANY, 7994 bytes)
2021-12-03 20:18:44,171 [dispatcher-event-loop-9] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 2.0 in stage 74.0 (TID 297, localhost, executor driver, partition 2, ANY, 7994 bytes)
2021-12-03 20:18:44,171 [dispatcher-event-loop-9] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 3.0 in stage 74.0 (TID 298, localhost, executor driver, partition 3, ANY, 7994 bytes)
2021-12-03 20:18:44,171 [Executor task launch worker for task 296] INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 74.0 (TID 296)
2021-12-03 20:18:44,171 [Executor task launch worker for task 295] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 74.0 (TID 295)
2021-12-03 20:18:44,171 [Executor task launch worker for task 298] INFO [org.apache.spark.executor.Executor] - Running task 3.0 in stage 74.0 (TID 298)
2021-12-03 20:18:44,171 [Executor task launch worker for task 297] INFO [org.apache.spark.executor.Executor] - Running task 2.0 in stage 74.0 (TID 297)
2021-12-03 20:18:44,172 [Executor task launch worker for task 298] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/order_data.bcp:3442194+3442195
2021-12-03 20:18:44,173 [Executor task launch worker for task 295] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/order_data.bcp:0+3442194
2021-12-03 20:18:44,173 [Executor task launch worker for task 297] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/order_data.bcp:0+3442194
2021-12-03 20:18:44,173 [Executor task launch worker for task 296] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/order_data.bcp:3442194+3442195
2021-12-03 20:18:44,776 [Executor task launch worker for task 297] INFO [org.apache.spark.executor.Executor] - Finished task 2.0 in stage 74.0 (TID 297). 862 bytes result sent to driver
2021-12-03 20:18:44,776 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 2.0 in stage 74.0 (TID 297) in 605 ms on localhost (executor driver) (1/4)
2021-12-03 20:18:45,219 [Executor task launch worker for task 298] INFO [org.apache.spark.executor.Executor] - Finished task 3.0 in stage 74.0 (TID 298). 862 bytes result sent to driver
2021-12-03 20:18:45,219 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 3.0 in stage 74.0 (TID 298) in 1048 ms on localhost (executor driver) (2/4)
2021-12-03 20:18:45,222 [Executor task launch worker for task 295] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 74.0 (TID 295). 862 bytes result sent to driver
2021-12-03 20:18:45,222 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 74.0 (TID 295) in 1051 ms on localhost (executor driver) (3/4)
2021-12-03 20:18:45,991 [Executor task launch worker for task 296] INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 74.0 (TID 296). 862 bytes result sent to driver
2021-12-03 20:18:45,992 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 74.0 (TID 296) in 1821 ms on localhost (executor driver) (4/4)
2021-12-03 20:18:45,992 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 74.0, whose tasks have all completed, from pool 
2021-12-03 20:18:45,992 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ShuffleMapStage 74 (union at PaidPromotionAdjustParameter.scala:149) finished in 1.825 s
2021-12-03 20:18:45,992 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - looking for newly runnable stages
2021-12-03 20:18:45,992 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - running: Set()
2021-12-03 20:18:45,992 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - waiting: Set(ResultStage 75)
2021-12-03 20:18:45,992 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - failed: Set()
2021-12-03 20:18:45,992 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 75 (MapPartitionsRDD[89] at map at PaidPromotionAdjustParameter.scala:192), which has no missing parents
2021-12-03 20:18:45,993 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_54 stored as values in memory (estimated size 121.5 KB, free 1989.2 MB)
2021-12-03 20:18:45,994 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_54_piece0 stored as bytes in memory (estimated size 43.9 KB, free 1989.2 MB)
2021-12-03 20:18:45,994 [dispatcher-event-loop-4] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_54_piece0 in memory on qb:50070 (size: 43.9 KB, free: 1990.5 MB)
2021-12-03 20:18:45,995 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 54 from broadcast at DAGScheduler.scala:1039
2021-12-03 20:18:45,995 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 4 missing tasks from ResultStage 75 (MapPartitionsRDD[89] at map at PaidPromotionAdjustParameter.scala:192) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
2021-12-03 20:18:45,995 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 75.0 with 4 tasks
2021-12-03 20:18:45,995 [dispatcher-event-loop-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 75.0 (TID 299, localhost, executor driver, partition 0, ANY, 7649 bytes)
2021-12-03 20:18:45,995 [dispatcher-event-loop-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 75.0 (TID 300, localhost, executor driver, partition 1, ANY, 7649 bytes)
2021-12-03 20:18:45,995 [dispatcher-event-loop-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 2.0 in stage 75.0 (TID 301, localhost, executor driver, partition 2, ANY, 7649 bytes)
2021-12-03 20:18:45,995 [dispatcher-event-loop-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 3.0 in stage 75.0 (TID 302, localhost, executor driver, partition 3, ANY, 7649 bytes)
2021-12-03 20:18:45,995 [Executor task launch worker for task 300] INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 75.0 (TID 300)
2021-12-03 20:18:45,995 [Executor task launch worker for task 302] INFO [org.apache.spark.executor.Executor] - Running task 3.0 in stage 75.0 (TID 302)
2021-12-03 20:18:45,995 [Executor task launch worker for task 301] INFO [org.apache.spark.executor.Executor] - Running task 2.0 in stage 75.0 (TID 301)
2021-12-03 20:18:45,995 [Executor task launch worker for task 299] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 75.0 (TID 299)
2021-12-03 20:18:45,997 [Executor task launch worker for task 301] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 4 non-empty blocks out of 4 blocks
2021-12-03 20:18:45,997 [Executor task launch worker for task 300] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 4 non-empty blocks out of 4 blocks
2021-12-03 20:18:45,997 [Executor task launch worker for task 301] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 20:18:45,997 [Executor task launch worker for task 300] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 20:18:45,997 [Executor task launch worker for task 299] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 4 non-empty blocks out of 4 blocks
2021-12-03 20:18:45,997 [Executor task launch worker for task 299] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 20:18:45,997 [Executor task launch worker for task 302] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 4 non-empty blocks out of 4 blocks
2021-12-03 20:18:45,997 [Executor task launch worker for task 302] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 20:18:46,134 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 358
2021-12-03 20:18:46,134 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1273
2021-12-03 20:18:46,134 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1245
2021-12-03 20:18:46,134 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1270
2021-12-03 20:18:46,134 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1242
2021-12-03 20:18:46,134 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1266
2021-12-03 20:18:46,134 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1252
2021-12-03 20:18:46,134 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1248
2021-12-03 20:18:46,134 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1222
2021-12-03 20:18:46,134 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1213
2021-12-03 20:18:46,134 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1269
2021-12-03 20:18:46,134 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1272
2021-12-03 20:18:46,134 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1210
2021-12-03 20:18:46,134 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1226
2021-12-03 20:18:46,134 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1260
2021-12-03 20:18:46,134 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1207
2021-12-03 20:18:46,134 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1218
2021-12-03 20:18:46,134 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1271
2021-12-03 20:18:46,134 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1202
2021-12-03 20:18:46,134 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1219
2021-12-03 20:18:46,134 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1257
2021-12-03 20:18:46,134 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1234
2021-12-03 20:18:46,134 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1204
2021-12-03 20:18:46,134 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1258
2021-12-03 20:18:46,135 [dispatcher-event-loop-3] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_50_piece0 on qb:50070 in memory (size: 43.2 KB, free: 1990.5 MB)
2021-12-03 20:18:46,135 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1227
2021-12-03 20:18:46,135 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1267
2021-12-03 20:18:46,135 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1251
2021-12-03 20:18:46,136 [dispatcher-event-loop-5] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_52_piece0 on qb:50070 in memory (size: 43.7 KB, free: 1990.6 MB)
2021-12-03 20:18:46,136 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1235
2021-12-03 20:18:46,136 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1274
2021-12-03 20:18:46,136 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1254
2021-12-03 20:18:46,136 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1239
2021-12-03 20:18:46,136 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1259
2021-12-03 20:18:46,136 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1263
2021-12-03 20:18:46,136 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1203
2021-12-03 20:18:46,136 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1206
2021-12-03 20:18:46,136 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1231
2021-12-03 20:18:46,136 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1200
2021-12-03 20:18:46,136 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1264
2021-12-03 20:18:46,136 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1205
2021-12-03 20:18:46,136 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1232
2021-12-03 20:18:46,136 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1217
2021-12-03 20:18:46,136 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1228
2021-12-03 20:18:46,136 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1262
2021-12-03 20:18:46,136 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1256
2021-12-03 20:18:46,136 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1241
2021-12-03 20:18:46,136 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1201
2021-12-03 20:18:46,136 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1221
2021-12-03 20:18:46,136 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1246
2021-12-03 20:18:46,136 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1237
2021-12-03 20:18:46,136 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1209
2021-12-03 20:18:46,136 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1229
2021-12-03 20:18:46,136 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1216
2021-12-03 20:18:46,136 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1225
2021-12-03 20:18:46,136 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1247
2021-12-03 20:18:46,136 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1255
2021-12-03 20:18:46,136 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1250
2021-12-03 20:18:46,136 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1220
2021-12-03 20:18:46,137 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1240
2021-12-03 20:18:46,137 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1243
2021-12-03 20:18:46,137 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1253
2021-12-03 20:18:46,137 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1244
2021-12-03 20:18:46,137 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1261
2021-12-03 20:18:46,137 [dispatcher-event-loop-11] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_51_piece0 on qb:50070 in memory (size: 43.7 KB, free: 1990.6 MB)
2021-12-03 20:18:46,137 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1215
2021-12-03 20:18:46,137 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1208
2021-12-03 20:18:46,137 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1224
2021-12-03 20:18:46,137 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1211
2021-12-03 20:18:46,137 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1265
2021-12-03 20:18:46,137 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1223
2021-12-03 20:18:46,137 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1249
2021-12-03 20:18:46,137 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1230
2021-12-03 20:18:46,137 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1212
2021-12-03 20:18:46,137 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1214
2021-12-03 20:18:46,138 [dispatcher-event-loop-10] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_53_piece0 on qb:50070 in memory (size: 43.5 KB, free: 1990.7 MB)
2021-12-03 20:18:46,138 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1233
2021-12-03 20:18:46,138 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1238
2021-12-03 20:18:46,138 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1236
2021-12-03 20:18:46,138 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1268
2021-12-03 20:18:46,138 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 377
2021-12-03 20:18:46,138 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 247
2021-12-03 20:18:46,138 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 35
2021-12-03 20:18:46,138 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 373
2021-12-03 20:18:46,138 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 110
2021-12-03 20:18:46,138 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 934
2021-12-03 20:18:46,138 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 27
2021-12-03 20:18:46,138 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 928
2021-12-03 20:18:46,138 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 309
2021-12-03 20:18:46,138 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 79
2021-12-03 20:18:46,138 [dispatcher-event-loop-3] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_16_piece0 on qb:50070 in memory (size: 2.9 KB, free: 1990.7 MB)
2021-12-03 20:18:46,138 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 314
2021-12-03 20:18:46,138 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 943
2021-12-03 20:18:46,138 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 912
2021-12-03 20:18:46,138 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 966
2021-12-03 20:18:46,138 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 36
2021-12-03 20:18:46,138 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 221
2021-12-03 20:18:46,138 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 308
2021-12-03 20:18:46,139 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 922
2021-12-03 20:18:46,139 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 135
2021-12-03 20:18:46,139 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 953
2021-12-03 20:18:46,139 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 225
2021-12-03 20:18:46,139 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 379
2021-12-03 20:18:46,139 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 378
2021-12-03 20:18:46,139 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 394
2021-12-03 20:18:46,139 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 55
2021-12-03 20:18:46,139 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 941
2021-12-03 20:18:46,139 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 118
2021-12-03 20:18:46,139 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 241
2021-12-03 20:18:46,139 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 96
2021-12-03 20:18:46,139 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 30
2021-12-03 20:18:46,139 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 305
2021-12-03 20:18:46,139 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 322
2021-12-03 20:18:46,139 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 201
2021-12-03 20:18:46,139 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 50
2021-12-03 20:18:46,139 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 958
2021-12-03 20:18:46,139 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 126
2021-12-03 20:18:46,139 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 70
2021-12-03 20:18:46,139 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 387
2021-12-03 20:18:46,139 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 927
2021-12-03 20:18:46,139 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 239
2021-12-03 20:18:46,139 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 134
2021-12-03 20:18:46,139 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 380
2021-12-03 20:18:46,139 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 61
2021-12-03 20:18:46,139 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 246
2021-12-03 20:18:46,139 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 930
2021-12-03 20:18:46,139 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 129
2021-12-03 20:18:46,139 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 94
2021-12-03 20:18:46,139 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 102
2021-12-03 20:18:46,139 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 249
2021-12-03 20:18:46,139 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 318
2021-12-03 20:18:46,139 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 224
2021-12-03 20:18:46,139 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 227
2021-12-03 20:18:46,139 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 300
2021-12-03 20:18:46,139 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 938
2021-12-03 20:18:46,139 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 353
2021-12-03 20:18:46,139 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 104
2021-12-03 20:18:46,139 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 954
2021-12-03 20:18:46,139 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 303
2021-12-03 20:18:46,139 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 956
2021-12-03 20:18:46,139 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 90
2021-12-03 20:18:46,139 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 366
2021-12-03 20:18:46,139 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 82
2021-12-03 20:18:46,139 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 38
2021-12-03 20:18:46,139 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 74
2021-12-03 20:18:46,139 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 148
2021-12-03 20:18:46,139 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 125
2021-12-03 20:18:46,139 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 364
2021-12-03 20:18:46,139 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 220
2021-12-03 20:18:46,139 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 51
2021-12-03 20:18:46,139 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 357
2021-12-03 20:18:46,139 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 130
2021-12-03 20:18:46,139 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 208
2021-12-03 20:18:46,139 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 123
2021-12-03 20:18:46,139 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 972
2021-12-03 20:18:46,139 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 116
2021-12-03 20:18:46,139 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 64
2021-12-03 20:18:46,139 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 901
2021-12-03 20:18:46,139 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 399
2021-12-03 20:18:46,139 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 206
2021-12-03 20:18:46,139 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 91
2021-12-03 20:18:46,139 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 950
2021-12-03 20:18:46,139 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 63
2021-12-03 20:18:46,139 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 100
2021-12-03 20:18:46,139 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 952
2021-12-03 20:18:46,139 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 365
2021-12-03 20:18:46,139 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 237
2021-12-03 20:18:46,139 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 929
2021-12-03 20:18:46,139 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 388
2021-12-03 20:18:46,139 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 226
2021-12-03 20:18:46,139 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 376
2021-12-03 20:18:46,139 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 970
2021-12-03 20:18:46,139 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 389
2021-12-03 20:18:46,139 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 139
2021-12-03 20:18:46,139 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 43
2021-12-03 20:18:46,139 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 909
2021-12-03 20:18:46,139 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 316
2021-12-03 20:18:46,139 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 903
2021-12-03 20:18:46,139 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 46
2021-12-03 20:18:46,139 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 142
2021-12-03 20:18:46,139 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 236
2021-12-03 20:18:46,139 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 33
2021-12-03 20:18:46,139 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 245
2021-12-03 20:18:46,140 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 203
2021-12-03 20:18:46,140 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 119
2021-12-03 20:18:46,140 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 924
2021-12-03 20:18:46,140 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 396
2021-12-03 20:18:46,140 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 315
2021-12-03 20:18:46,140 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 207
2021-12-03 20:18:46,140 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 936
2021-12-03 20:18:46,140 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 370
2021-12-03 20:18:46,140 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 942
2021-12-03 20:18:46,140 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 383
2021-12-03 20:18:46,140 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 52
2021-12-03 20:18:46,140 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 212
2021-12-03 20:18:46,140 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 113
2021-12-03 20:18:46,140 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 31
2021-12-03 20:18:46,140 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 969
2021-12-03 20:18:46,141 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 81
2021-12-03 20:18:46,141 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 951
2021-12-03 20:18:46,141 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 931
2021-12-03 20:18:46,141 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 25
2021-12-03 20:18:46,141 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 242
2021-12-03 20:18:46,141 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 957
2021-12-03 20:18:46,141 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 228
2021-12-03 20:18:46,141 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 109
2021-12-03 20:18:46,141 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 95
2021-12-03 20:18:46,141 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 918
2021-12-03 20:18:46,141 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 248
2021-12-03 20:18:46,141 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 906
2021-12-03 20:18:46,141 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 375
2021-12-03 20:18:46,141 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 124
2021-12-03 20:18:46,141 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 128
2021-12-03 20:18:46,141 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 354
2021-12-03 20:18:46,141 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 217
2021-12-03 20:18:46,141 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 234
2021-12-03 20:18:46,141 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 960
2021-12-03 20:18:46,141 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 915
2021-12-03 20:18:46,141 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 350
2021-12-03 20:18:46,141 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 319
2021-12-03 20:18:46,141 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 361
2021-12-03 20:18:46,144 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned shuffle 1
2021-12-03 20:18:46,144 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 47
2021-12-03 20:18:46,144 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 65
2021-12-03 20:18:46,144 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 121
2021-12-03 20:18:46,144 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 385
2021-12-03 20:18:46,145 [dispatcher-event-loop-4] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_5_piece0 on qb:50070 in memory (size: 2.4 KB, free: 1990.7 MB)
2021-12-03 20:18:46,145 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 71
2021-12-03 20:18:46,146 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 911
2021-12-03 20:18:46,146 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 923
2021-12-03 20:18:46,146 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 963
2021-12-03 20:18:46,146 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 29
2021-12-03 20:18:46,146 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 85
2021-12-03 20:18:46,146 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 962
2021-12-03 20:18:46,146 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 304
2021-12-03 20:18:46,146 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 92
2021-12-03 20:18:46,146 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 76
2021-12-03 20:18:46,146 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 311
2021-12-03 20:18:46,146 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 904
2021-12-03 20:18:46,146 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 40
2021-12-03 20:18:46,146 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 362
2021-12-03 20:18:46,146 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 949
2021-12-03 20:18:46,146 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 382
2021-12-03 20:18:46,146 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 313
2021-12-03 20:18:46,146 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 88
2021-12-03 20:18:46,146 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 106
2021-12-03 20:18:46,146 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 108
2021-12-03 20:18:46,146 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 32
2021-12-03 20:18:46,146 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 959
2021-12-03 20:18:46,146 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 948
2021-12-03 20:18:46,146 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 910
2021-12-03 20:18:46,146 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 908
2021-12-03 20:18:46,146 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 145
2021-12-03 20:18:46,146 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 210
2021-12-03 20:18:46,146 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 240
2021-12-03 20:18:46,146 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 932
2021-12-03 20:18:46,146 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 140
2021-12-03 20:18:46,146 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 355
2021-12-03 20:18:46,146 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 222
2021-12-03 20:18:46,146 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 944
2021-12-03 20:18:46,146 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 67
2021-12-03 20:18:46,146 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 946
2021-12-03 20:18:46,146 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 964
2021-12-03 20:18:46,146 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 386
2021-12-03 20:18:46,146 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 940
2021-12-03 20:18:46,147 [dispatcher-event-loop-9] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_2_piece0 on qb:50070 in memory (size: 2.7 KB, free: 1990.7 MB)
2021-12-03 20:18:46,147 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 902
2021-12-03 20:18:46,147 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 371
2021-12-03 20:18:46,147 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 131
2021-12-03 20:18:46,147 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 218
2021-12-03 20:18:46,147 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 229
2021-12-03 20:18:46,147 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 961
2021-12-03 20:18:46,147 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 914
2021-12-03 20:18:46,147 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 137
2021-12-03 20:18:46,147 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 112
2021-12-03 20:18:46,147 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 905
2021-12-03 20:18:46,147 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 200
2021-12-03 20:18:46,147 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 351
2021-12-03 20:18:46,147 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 72
2021-12-03 20:18:46,147 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 66
2021-12-03 20:18:46,147 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 935
2021-12-03 20:18:46,147 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 397
2021-12-03 20:18:46,147 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 393
2021-12-03 20:18:46,147 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 59
2021-12-03 20:18:46,147 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 83
2021-12-03 20:18:46,147 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 244
2021-12-03 20:18:46,147 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 374
2021-12-03 20:18:46,147 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 99
2021-12-03 20:18:46,147 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 215
2021-12-03 20:18:46,147 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 34
2021-12-03 20:18:46,147 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 114
2021-12-03 20:18:46,147 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 323
2021-12-03 20:18:46,147 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 243
2021-12-03 20:18:46,147 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 58
2021-12-03 20:18:46,147 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 204
2021-12-03 20:18:46,147 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 235
2021-12-03 20:18:46,147 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 395
2021-12-03 20:18:46,147 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 955
2021-12-03 20:18:46,147 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 398
2021-12-03 20:18:46,147 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 37
2021-12-03 20:18:46,147 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 302
2021-12-03 20:18:46,147 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 219
2021-12-03 20:18:46,147 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 117
2021-12-03 20:18:46,147 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 93
2021-12-03 20:18:46,147 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 75
2021-12-03 20:18:46,147 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 230
2021-12-03 20:18:46,147 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 352
2021-12-03 20:18:46,147 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 68
2021-12-03 20:18:46,147 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 86
2021-12-03 20:18:46,147 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 97
2021-12-03 20:18:46,147 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 363
2021-12-03 20:18:46,147 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 971
2021-12-03 20:18:46,147 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 78
2021-12-03 20:18:46,148 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 120
2021-12-03 20:18:46,148 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 136
2021-12-03 20:18:46,148 [dispatcher-event-loop-1] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_10_piece0 on qb:50070 in memory (size: 30.6 KB, free: 1990.7 MB)
2021-12-03 20:18:46,148 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 320
2021-12-03 20:18:46,148 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 372
2021-12-03 20:18:46,148 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 907
2021-12-03 20:18:46,148 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 214
2021-12-03 20:18:46,148 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 368
2021-12-03 20:18:46,148 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 919
2021-12-03 20:18:46,148 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 232
2021-12-03 20:18:46,148 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 968
2021-12-03 20:18:46,148 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 392
2021-12-03 20:18:46,148 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 917
2021-12-03 20:18:46,148 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned shuffle 0
2021-12-03 20:18:46,149 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 41
2021-12-03 20:18:46,149 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 974
2021-12-03 20:18:46,149 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 947
2021-12-03 20:18:46,149 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 913
2021-12-03 20:18:46,149 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 54
2021-12-03 20:18:46,149 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 60
2021-12-03 20:18:46,149 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 77
2021-12-03 20:18:46,149 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 56
2021-12-03 20:18:46,149 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 306
2021-12-03 20:18:46,149 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 80
2021-12-03 20:18:46,149 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 900
2021-12-03 20:18:46,149 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 39
2021-12-03 20:18:46,149 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 381
2021-12-03 20:18:46,149 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 98
2021-12-03 20:18:46,149 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 127
2021-12-03 20:18:46,149 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 307
2021-12-03 20:18:46,149 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 45
2021-12-03 20:18:46,149 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 147
2021-12-03 20:18:46,149 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 143
2021-12-03 20:18:46,149 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 69
2021-12-03 20:18:46,149 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 146
2021-12-03 20:18:46,149 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 84
2021-12-03 20:18:46,149 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 53
2021-12-03 20:18:46,149 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 916
2021-12-03 20:18:46,149 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 369
2021-12-03 20:18:46,149 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 211
2021-12-03 20:18:46,149 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 310
2021-12-03 20:18:46,149 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 105
2021-12-03 20:18:46,149 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 356
2021-12-03 20:18:46,149 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 945
2021-12-03 20:18:46,149 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 231
2021-12-03 20:18:46,149 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 973
2021-12-03 20:18:46,149 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 384
2021-12-03 20:18:46,149 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 312
2021-12-03 20:18:46,149 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 926
2021-12-03 20:18:46,149 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 107
2021-12-03 20:18:46,149 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 132
2021-12-03 20:18:46,150 [dispatcher-event-loop-5] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_0_piece0 on qb:50070 in memory (size: 27.3 KB, free: 1990.7 MB)
2021-12-03 20:18:46,150 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 321
2021-12-03 20:18:46,150 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 367
2021-12-03 20:18:46,150 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 324
2021-12-03 20:18:46,150 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 115
2021-12-03 20:18:46,150 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 233
2021-12-03 20:18:46,150 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 390
2021-12-03 20:18:46,150 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 28
2021-12-03 20:18:46,150 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 62
2021-12-03 20:18:46,150 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 921
2021-12-03 20:18:46,150 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 205
2021-12-03 20:18:46,150 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 87
2021-12-03 20:18:46,150 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 925
2021-12-03 20:18:46,150 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 209
2021-12-03 20:18:46,150 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 360
2021-12-03 20:18:46,151 [dispatcher-event-loop-11] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_14_piece0 on qb:50070 in memory (size: 2.1 KB, free: 1990.7 MB)
2021-12-03 20:18:46,151 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 138
2021-12-03 20:18:46,151 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 48
2021-12-03 20:18:46,151 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 391
2021-12-03 20:18:46,151 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 804
2021-12-03 20:18:46,151 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 144
2021-12-03 20:18:46,151 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 122
2021-12-03 20:18:46,151 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 937
2021-12-03 20:18:46,151 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 103
2021-12-03 20:18:46,151 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 57
2021-12-03 20:18:46,151 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 967
2021-12-03 20:18:46,151 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 141
2021-12-03 20:18:46,152 [dispatcher-event-loop-10] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_9_piece0 on qb:50070 in memory (size: 2.2 KB, free: 1990.7 MB)
2021-12-03 20:18:46,152 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 933
2021-12-03 20:18:46,152 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 359
2021-12-03 20:18:46,153 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 213
2021-12-03 20:18:46,153 [dispatcher-event-loop-3] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_40_piece0 on qb:50070 in memory (size: 2.1 KB, free: 1990.7 MB)
2021-12-03 20:18:46,153 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 216
2021-12-03 20:18:46,153 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 317
2021-12-03 20:18:46,153 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 223
2021-12-03 20:18:46,153 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 44
2021-12-03 20:18:46,153 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 26
2021-12-03 20:18:46,153 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 238
2021-12-03 20:18:46,153 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 965
2021-12-03 20:18:46,153 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 920
2021-12-03 20:18:46,153 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 49
2021-12-03 20:18:46,153 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 301
2021-12-03 20:18:46,153 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 149
2021-12-03 20:18:46,153 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 101
2021-12-03 20:18:46,153 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 89
2021-12-03 20:18:46,153 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 133
2021-12-03 20:18:46,153 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 73
2021-12-03 20:18:46,153 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 939
2021-12-03 20:18:46,153 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 111
2021-12-03 20:18:46,153 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 202
2021-12-03 20:18:46,153 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 42
2021-12-03 20:18:46,197 [Executor task launch worker for task 300] INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 75.0 (TID 300). 1098 bytes result sent to driver
2021-12-03 20:18:46,197 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 75.0 (TID 300) in 202 ms on localhost (executor driver) (1/4)
2021-12-03 20:18:46,198 [Executor task launch worker for task 301] INFO [org.apache.spark.executor.Executor] - Finished task 2.0 in stage 75.0 (TID 301). 1098 bytes result sent to driver
2021-12-03 20:18:46,198 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 2.0 in stage 75.0 (TID 301) in 203 ms on localhost (executor driver) (2/4)
2021-12-03 20:18:46,199 [Executor task launch worker for task 302] INFO [org.apache.spark.executor.Executor] - Finished task 3.0 in stage 75.0 (TID 302). 1098 bytes result sent to driver
2021-12-03 20:18:46,199 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 3.0 in stage 75.0 (TID 302) in 204 ms on localhost (executor driver) (3/4)
2021-12-03 20:18:46,199 [Executor task launch worker for task 299] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 75.0 (TID 299). 1098 bytes result sent to driver
2021-12-03 20:18:46,199 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 75.0 (TID 299) in 204 ms on localhost (executor driver) (4/4)
2021-12-03 20:18:46,199 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 75.0, whose tasks have all completed, from pool 
2021-12-03 20:18:46,199 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 75 (count at PaidPromotionAdjustParameter.scala:198) finished in 0.207 s
2021-12-03 20:18:46,199 [main] INFO [org.apache.spark.scheduler.DAGScheduler] - Job 32 finished: count at PaidPromotionAdjustParameter.scala:198, took 2.032657 s
2021-12-03 20:18:46,199 [main] INFO [PaidPromotion$] - 训练集用户列表数量：95323
2021-12-03 20:18:46,206 [main] INFO [org.apache.spark.SparkContext] - Starting job: take at PaidPromotionAdjustParameter.scala:199
2021-12-03 20:18:46,207 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 33 (take at PaidPromotionAdjustParameter.scala:199) with 1 output partitions
2021-12-03 20:18:46,207 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 77 (take at PaidPromotionAdjustParameter.scala:199)
2021-12-03 20:18:46,207 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 76)
2021-12-03 20:18:46,207 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2021-12-03 20:18:46,207 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 77 (MapPartitionsRDD[89] at map at PaidPromotionAdjustParameter.scala:192), which has no missing parents
2021-12-03 20:18:46,208 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_55 stored as values in memory (estimated size 121.6 KB, free 1990.2 MB)
2021-12-03 20:18:46,209 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_55_piece0 stored as bytes in memory (estimated size 44.0 KB, free 1990.1 MB)
2021-12-03 20:18:46,210 [dispatcher-event-loop-4] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_55_piece0 in memory on qb:50070 (size: 44.0 KB, free: 1990.7 MB)
2021-12-03 20:18:46,210 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 55 from broadcast at DAGScheduler.scala:1039
2021-12-03 20:18:46,210 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 77 (MapPartitionsRDD[89] at map at PaidPromotionAdjustParameter.scala:192) (first 15 tasks are for partitions Vector(0))
2021-12-03 20:18:46,210 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 77.0 with 1 tasks
2021-12-03 20:18:46,210 [dispatcher-event-loop-11] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 77.0 (TID 303, localhost, executor driver, partition 0, ANY, 7649 bytes)
2021-12-03 20:18:46,210 [Executor task launch worker for task 303] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 77.0 (TID 303)
2021-12-03 20:18:46,212 [Executor task launch worker for task 303] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 4 non-empty blocks out of 4 blocks
2021-12-03 20:18:46,212 [Executor task launch worker for task 303] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 20:18:46,242 [Executor task launch worker for task 303] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 77.0 (TID 303). 2431 bytes result sent to driver
2021-12-03 20:18:46,242 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 77.0 (TID 303) in 32 ms on localhost (executor driver) (1/1)
2021-12-03 20:18:46,242 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 77.0, whose tasks have all completed, from pool 
2021-12-03 20:18:46,242 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 77 (take at PaidPromotionAdjustParameter.scala:199) finished in 0.035 s
2021-12-03 20:18:46,242 [main] INFO [org.apache.spark.scheduler.DAGScheduler] - Job 33 finished: take at PaidPromotionAdjustParameter.scala:199, took 0.036135 s
2021-12-03 20:18:46,245 [main] INFO [org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter] - File Output Committer Algorithm version is 1
2021-12-03 20:18:46,264 [main] INFO [org.apache.spark.SparkContext] - Starting job: runJob at SparkHadoopWriter.scala:78
2021-12-03 20:18:46,265 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 34 (runJob at SparkHadoopWriter.scala:78) with 1 output partitions
2021-12-03 20:18:46,265 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 79 (runJob at SparkHadoopWriter.scala:78)
2021-12-03 20:18:46,265 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 78)
2021-12-03 20:18:46,265 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2021-12-03 20:18:46,265 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 79 (MapPartitionsRDD[91] at saveAsTextFile at PaidPromotionAdjustParameter.scala:201), which has no missing parents
2021-12-03 20:18:46,273 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_56 stored as values in memory (estimated size 197.4 KB, free 1990.0 MB)
2021-12-03 20:18:46,275 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_56_piece0 stored as bytes in memory (estimated size 72.5 KB, free 1989.9 MB)
2021-12-03 20:18:46,275 [dispatcher-event-loop-10] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_56_piece0 in memory on qb:50070 (size: 72.5 KB, free: 1990.6 MB)
2021-12-03 20:18:46,275 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 56 from broadcast at DAGScheduler.scala:1039
2021-12-03 20:18:46,275 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 79 (MapPartitionsRDD[91] at saveAsTextFile at PaidPromotionAdjustParameter.scala:201) (first 15 tasks are for partitions Vector(0))
2021-12-03 20:18:46,275 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 79.0 with 1 tasks
2021-12-03 20:18:46,275 [dispatcher-event-loop-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 79.0 (TID 304, localhost, executor driver, partition 0, ANY, 7943 bytes)
2021-12-03 20:18:46,275 [Executor task launch worker for task 304] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 79.0 (TID 304)
2021-12-03 20:18:46,281 [Executor task launch worker for task 304] INFO [org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter] - File Output Committer Algorithm version is 1
2021-12-03 20:18:46,290 [Executor task launch worker for task 304] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 2 non-empty blocks out of 2 blocks
2021-12-03 20:18:46,290 [Executor task launch worker for task 304] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 20:18:46,302 [Executor task launch worker for task 304] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 2 non-empty blocks out of 2 blocks
2021-12-03 20:18:46,302 [Executor task launch worker for task 304] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 20:18:46,389 [Executor task launch worker for task 304] INFO [org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter] - Saved output of task 'attempt_20211203201846_0091_m_000000_0' to hdfs://hdp1:8020/sk/chongqing/list/validation.bcp/_temporary/0/task_20211203201846_0091_m_000000
2021-12-03 20:18:46,389 [Executor task launch worker for task 304] INFO [org.apache.spark.mapred.SparkHadoopMapRedUtil] - attempt_20211203201846_0091_m_000000_0: Committed
2021-12-03 20:18:46,390 [Executor task launch worker for task 304] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 79.0 (TID 304). 1299 bytes result sent to driver
2021-12-03 20:18:46,390 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 79.0 (TID 304) in 115 ms on localhost (executor driver) (1/1)
2021-12-03 20:18:46,390 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 79.0, whose tasks have all completed, from pool 
2021-12-03 20:18:46,390 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 79 (runJob at SparkHadoopWriter.scala:78) finished in 0.125 s
2021-12-03 20:18:46,390 [main] INFO [org.apache.spark.scheduler.DAGScheduler] - Job 34 finished: runJob at SparkHadoopWriter.scala:78, took 0.126323 s
2021-12-03 20:18:46,432 [main] INFO [org.apache.spark.internal.io.SparkHadoopWriter] - Job job_20211203201846_0091 committed.
2021-12-03 20:18:46,434 [main] INFO [org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter] - File Output Committer Algorithm version is 1
2021-12-03 20:18:46,447 [main] INFO [org.apache.spark.SparkContext] - Starting job: runJob at SparkHadoopWriter.scala:78
2021-12-03 20:18:46,447 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 35 (runJob at SparkHadoopWriter.scala:78) with 1 output partitions
2021-12-03 20:18:46,447 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 81 (runJob at SparkHadoopWriter.scala:78)
2021-12-03 20:18:46,447 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 80)
2021-12-03 20:18:46,447 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2021-12-03 20:18:46,447 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 81 (MapPartitionsRDD[93] at saveAsTextFile at PaidPromotionAdjustParameter.scala:202), which has no missing parents
2021-12-03 20:18:46,456 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_57 stored as values in memory (estimated size 197.9 KB, free 1989.7 MB)
2021-12-03 20:18:46,458 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_57_piece0 stored as bytes in memory (estimated size 72.8 KB, free 1989.6 MB)
2021-12-03 20:18:46,458 [dispatcher-event-loop-7] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_57_piece0 in memory on qb:50070 (size: 72.8 KB, free: 1990.5 MB)
2021-12-03 20:18:46,458 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 57 from broadcast at DAGScheduler.scala:1039
2021-12-03 20:18:46,458 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 81 (MapPartitionsRDD[93] at saveAsTextFile at PaidPromotionAdjustParameter.scala:202) (first 15 tasks are for partitions Vector(0))
2021-12-03 20:18:46,458 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 81.0 with 1 tasks
2021-12-03 20:18:46,459 [dispatcher-event-loop-5] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 81.0 (TID 305, localhost, executor driver, partition 0, ANY, 7979 bytes)
2021-12-03 20:18:46,459 [Executor task launch worker for task 305] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 81.0 (TID 305)
2021-12-03 20:18:46,463 [Executor task launch worker for task 305] INFO [org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter] - File Output Committer Algorithm version is 1
2021-12-03 20:18:46,473 [Executor task launch worker for task 305] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 4 non-empty blocks out of 4 blocks
2021-12-03 20:18:46,473 [Executor task launch worker for task 305] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 20:18:46,530 [Executor task launch worker for task 305] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 4 non-empty blocks out of 4 blocks
2021-12-03 20:18:46,530 [Executor task launch worker for task 305] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 20:18:46,585 [Executor task launch worker for task 305] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 4 non-empty blocks out of 4 blocks
2021-12-03 20:18:46,585 [Executor task launch worker for task 305] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 20:18:46,631 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1343
2021-12-03 20:18:46,631 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1363
2021-12-03 20:18:46,631 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1360
2021-12-03 20:18:46,631 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1367
2021-12-03 20:18:46,631 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1327
2021-12-03 20:18:46,631 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1350
2021-12-03 20:18:46,631 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1359
2021-12-03 20:18:46,631 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1335
2021-12-03 20:18:46,631 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1356
2021-12-03 20:18:46,631 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1325
2021-12-03 20:18:46,631 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1345
2021-12-03 20:18:46,631 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1340
2021-12-03 20:18:46,631 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1370
2021-12-03 20:18:46,631 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1341
2021-12-03 20:18:46,631 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1331
2021-12-03 20:18:46,631 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1329
2021-12-03 20:18:46,631 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1369
2021-12-03 20:18:46,631 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1342
2021-12-03 20:18:46,631 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1372
2021-12-03 20:18:46,631 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1326
2021-12-03 20:18:46,631 [dispatcher-event-loop-9] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_56_piece0 on qb:50070 in memory (size: 72.5 KB, free: 1990.6 MB)
2021-12-03 20:18:46,631 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1351
2021-12-03 20:18:46,632 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1338
2021-12-03 20:18:46,632 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1371
2021-12-03 20:18:46,632 [dispatcher-event-loop-1] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_55_piece0 on qb:50070 in memory (size: 44.0 KB, free: 1990.7 MB)
2021-12-03 20:18:46,632 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1353
2021-12-03 20:18:46,632 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1355
2021-12-03 20:18:46,632 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1333
2021-12-03 20:18:46,632 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1347
2021-12-03 20:18:46,632 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1361
2021-12-03 20:18:46,632 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1334
2021-12-03 20:18:46,632 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1368
2021-12-03 20:18:46,632 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1349
2021-12-03 20:18:46,632 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1330
2021-12-03 20:18:46,632 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1348
2021-12-03 20:18:46,632 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1362
2021-12-03 20:18:46,632 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1337
2021-12-03 20:18:46,632 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1373
2021-12-03 20:18:46,632 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1328
2021-12-03 20:18:46,632 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1357
2021-12-03 20:18:46,632 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1346
2021-12-03 20:18:46,632 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1358
2021-12-03 20:18:46,632 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1339
2021-12-03 20:18:46,632 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1374
2021-12-03 20:18:46,632 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1354
2021-12-03 20:18:46,632 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1352
2021-12-03 20:18:46,632 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1344
2021-12-03 20:18:46,632 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1364
2021-12-03 20:18:46,632 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1365
2021-12-03 20:18:46,632 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1332
2021-12-03 20:18:46,632 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1366
2021-12-03 20:18:46,632 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1336
2021-12-03 20:18:46,648 [Executor task launch worker for task 305] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 4 non-empty blocks out of 4 blocks
2021-12-03 20:18:46,648 [Executor task launch worker for task 305] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 20:18:48,238 [Executor task launch worker for task 305] INFO [org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter] - Saved output of task 'attempt_20211203201846_0093_m_000000_0' to hdfs://hdp1:8020/sk/chongqing/list/train.bcp/_temporary/0/task_20211203201846_0093_m_000000
2021-12-03 20:18:48,239 [Executor task launch worker for task 305] INFO [org.apache.spark.mapred.SparkHadoopMapRedUtil] - attempt_20211203201846_0093_m_000000_0: Committed
2021-12-03 20:18:48,239 [Executor task launch worker for task 305] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 81.0 (TID 305). 1299 bytes result sent to driver
2021-12-03 20:18:48,239 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 81.0 (TID 305) in 1780 ms on localhost (executor driver) (1/1)
2021-12-03 20:18:48,239 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 81.0, whose tasks have all completed, from pool 
2021-12-03 20:18:48,240 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 81 (runJob at SparkHadoopWriter.scala:78) finished in 1.792 s
2021-12-03 20:18:48,240 [main] INFO [org.apache.spark.scheduler.DAGScheduler] - Job 35 finished: runJob at SparkHadoopWriter.scala:78, took 1.792458 s
2021-12-03 20:18:48,416 [main] INFO [org.apache.spark.internal.io.SparkHadoopWriter] - Job job_20211203201846_0093 committed.
2021-12-03 20:18:48,421 [main] INFO [org.spark_project.jetty.server.AbstractConnector] - Stopped Spark@5b800468{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2021-12-03 20:18:48,422 [main] INFO [org.apache.spark.ui.SparkUI] - Stopped Spark web UI at http://qb:4040
2021-12-03 20:18:48,429 [dispatcher-event-loop-11] INFO [org.apache.spark.MapOutputTrackerMasterEndpoint] - MapOutputTrackerMasterEndpoint stopped!
2021-12-03 20:18:48,510 [main] INFO [org.apache.spark.storage.memory.MemoryStore] - MemoryStore cleared
2021-12-03 20:18:48,510 [main] INFO [org.apache.spark.storage.BlockManager] - BlockManager stopped
2021-12-03 20:18:48,511 [main] INFO [org.apache.spark.storage.BlockManagerMaster] - BlockManagerMaster stopped
2021-12-03 20:18:48,513 [dispatcher-event-loop-1] INFO [org.apache.spark.scheduler.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint] - OutputCommitCoordinator stopped!
2021-12-03 20:18:48,515 [main] INFO [org.apache.spark.SparkContext] - Successfully stopped SparkContext
2021-12-03 20:18:48,517 [Thread-1] INFO [org.apache.spark.util.ShutdownHookManager] - Shutdown hook called
2021-12-03 20:18:48,518 [Thread-1] INFO [org.apache.spark.util.ShutdownHookManager] - Deleting directory C:\Users\ACER\AppData\Local\Temp\spark-582ceb11-bee5-4dad-941f-3678b90267f2
2021-12-03 20:28:58,548 [main] INFO [org.apache.spark.SparkContext] - Running Spark version 2.3.0
2021-12-03 20:28:58,826 [main] INFO [org.apache.spark.SparkContext] - Submitted application: PaidPromotion
2021-12-03 20:28:58,877 [main] INFO [org.apache.spark.SecurityManager] - Changing view acls to: ACER,root
2021-12-03 20:28:58,877 [main] INFO [org.apache.spark.SecurityManager] - Changing modify acls to: ACER,root
2021-12-03 20:28:58,877 [main] INFO [org.apache.spark.SecurityManager] - Changing view acls groups to: 
2021-12-03 20:28:58,878 [main] INFO [org.apache.spark.SecurityManager] - Changing modify acls groups to: 
2021-12-03 20:28:58,878 [main] INFO [org.apache.spark.SecurityManager] - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(ACER, root); groups with view permissions: Set(); users  with modify permissions: Set(ACER, root); groups with modify permissions: Set()
2021-12-03 20:28:59,498 [main] INFO [org.apache.spark.util.Utils] - Successfully started service 'sparkDriver' on port 53158.
2021-12-03 20:28:59,513 [main] INFO [org.apache.spark.SparkEnv] - Registering MapOutputTracker
2021-12-03 20:28:59,527 [main] INFO [org.apache.spark.SparkEnv] - Registering BlockManagerMaster
2021-12-03 20:28:59,530 [main] INFO [org.apache.spark.storage.BlockManagerMasterEndpoint] - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2021-12-03 20:28:59,530 [main] INFO [org.apache.spark.storage.BlockManagerMasterEndpoint] - BlockManagerMasterEndpoint up
2021-12-03 20:28:59,538 [main] INFO [org.apache.spark.storage.DiskBlockManager] - Created local directory at C:\Users\ACER\AppData\Local\Temp\blockmgr-5e54f82e-c2fe-4876-a359-5a318df670ed
2021-12-03 20:28:59,551 [main] INFO [org.apache.spark.storage.memory.MemoryStore] - MemoryStore started with capacity 1990.8 MB
2021-12-03 20:28:59,560 [main] INFO [org.apache.spark.SparkEnv] - Registering OutputCommitCoordinator
2021-12-03 20:28:59,610 [main] INFO [org.spark_project.jetty.util.log] - Logging initialized @1888ms
2021-12-03 20:28:59,653 [main] INFO [org.spark_project.jetty.server.Server] - jetty-9.3.z-SNAPSHOT
2021-12-03 20:28:59,663 [main] INFO [org.spark_project.jetty.server.Server] - Started @1942ms
2021-12-03 20:28:59,684 [main] INFO [org.spark_project.jetty.server.AbstractConnector] - Started ServerConnector@5b800468{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2021-12-03 20:28:59,684 [main] INFO [org.apache.spark.util.Utils] - Successfully started service 'SparkUI' on port 4040.
2021-12-03 20:28:59,702 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@1568159{/jobs,null,AVAILABLE,@Spark}
2021-12-03 20:28:59,702 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@63cd604c{/jobs/json,null,AVAILABLE,@Spark}
2021-12-03 20:28:59,703 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@3954d008{/jobs/job,null,AVAILABLE,@Spark}
2021-12-03 20:28:59,704 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@6d8792db{/jobs/job/json,null,AVAILABLE,@Spark}
2021-12-03 20:28:59,705 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@3a1d593e{/stages,null,AVAILABLE,@Spark}
2021-12-03 20:28:59,706 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@285d851a{/stages/json,null,AVAILABLE,@Spark}
2021-12-03 20:28:59,707 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@7876d598{/stages/stage,null,AVAILABLE,@Spark}
2021-12-03 20:28:59,709 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@4985cbcb{/stages/stage/json,null,AVAILABLE,@Spark}
2021-12-03 20:28:59,710 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@54361a9{/stages/pool,null,AVAILABLE,@Spark}
2021-12-03 20:28:59,711 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@293bb8a5{/stages/pool/json,null,AVAILABLE,@Spark}
2021-12-03 20:28:59,712 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@290b1b2e{/storage,null,AVAILABLE,@Spark}
2021-12-03 20:28:59,712 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@5db4c359{/storage/json,null,AVAILABLE,@Spark}
2021-12-03 20:28:59,713 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@6fefce9e{/storage/rdd,null,AVAILABLE,@Spark}
2021-12-03 20:28:59,714 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@8a589a2{/storage/rdd/json,null,AVAILABLE,@Spark}
2021-12-03 20:28:59,715 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@5cc69cfe{/environment,null,AVAILABLE,@Spark}
2021-12-03 20:28:59,716 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@11dee337{/environment/json,null,AVAILABLE,@Spark}
2021-12-03 20:28:59,717 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@74bdc168{/executors,null,AVAILABLE,@Spark}
2021-12-03 20:28:59,718 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@7bb3a9fe{/executors/json,null,AVAILABLE,@Spark}
2021-12-03 20:28:59,719 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@f19c9d2{/executors/threadDump,null,AVAILABLE,@Spark}
2021-12-03 20:28:59,720 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@a77614d{/executors/threadDump/json,null,AVAILABLE,@Spark}
2021-12-03 20:28:59,728 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@523424b5{/static,null,AVAILABLE,@Spark}
2021-12-03 20:28:59,729 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@12cd9150{/,null,AVAILABLE,@Spark}
2021-12-03 20:28:59,731 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@32fe9d0a{/api,null,AVAILABLE,@Spark}
2021-12-03 20:28:59,732 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@59fc684e{/jobs/job/kill,null,AVAILABLE,@Spark}
2021-12-03 20:28:59,733 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@355e34c7{/stages/stage/kill,null,AVAILABLE,@Spark}
2021-12-03 20:28:59,735 [main] INFO [org.apache.spark.ui.SparkUI] - Bound SparkUI to 0.0.0.0, and started at http://qb:4040
2021-12-03 20:28:59,806 [main] INFO [org.apache.spark.executor.Executor] - Starting executor ID driver on host localhost
2021-12-03 20:28:59,849 [main] INFO [org.apache.spark.util.Utils] - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 53199.
2021-12-03 20:28:59,849 [main] INFO [org.apache.spark.network.netty.NettyBlockTransferService] - Server created on qb:53199
2021-12-03 20:28:59,850 [main] INFO [org.apache.spark.storage.BlockManager] - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2021-12-03 20:28:59,851 [main] INFO [org.apache.spark.storage.BlockManagerMaster] - Registering BlockManager BlockManagerId(driver, qb, 53199, None)
2021-12-03 20:28:59,854 [dispatcher-event-loop-10] INFO [org.apache.spark.storage.BlockManagerMasterEndpoint] - Registering block manager qb:53199 with 1990.8 MB RAM, BlockManagerId(driver, qb, 53199, None)
2021-12-03 20:28:59,855 [main] INFO [org.apache.spark.storage.BlockManagerMaster] - Registered BlockManager BlockManagerId(driver, qb, 53199, None)
2021-12-03 20:28:59,855 [main] INFO [org.apache.spark.storage.BlockManager] - Initialized BlockManager: BlockManagerId(driver, qb, 53199, None)
2021-12-03 20:28:59,968 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@6fe46b62{/metrics/json,null,AVAILABLE,@Spark}
2021-12-03 20:29:00,437 [main] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_0 stored as values in memory (estimated size 312.7 KB, free 1990.5 MB)
2021-12-03 20:29:00,658 [main] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_0_piece0 stored as bytes in memory (estimated size 27.3 KB, free 1990.5 MB)
2021-12-03 20:29:00,661 [dispatcher-event-loop-0] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_0_piece0 in memory on qb:53199 (size: 27.3 KB, free: 1990.8 MB)
2021-12-03 20:29:00,665 [main] INFO [org.apache.spark.SparkContext] - Created broadcast 0 from textFile at PaidPromotionAdjustParameter.scala:57
2021-12-03 20:29:01,017 [main] WARN [org.apache.hadoop.hdfs.shortcircuit.DomainSocketFactory] - The short-circuit local reads feature cannot be used because UNIX Domain sockets are not available on Windows.
2021-12-03 20:29:01,087 [main] INFO [org.apache.hadoop.mapred.FileInputFormat] - Total input paths to process : 1
2021-12-03 20:29:01,120 [main] INFO [org.apache.hadoop.net.NetworkTopology] - Adding a new node: /default-rack/192.168.1.33:50010
2021-12-03 20:29:01,120 [main] INFO [org.apache.hadoop.net.NetworkTopology] - Adding a new node: /default-rack/192.168.1.34:50010
2021-12-03 20:29:01,120 [main] INFO [org.apache.hadoop.net.NetworkTopology] - Adding a new node: /default-rack/172.16.1.222:50010
2021-12-03 20:29:01,128 [main] INFO [org.apache.spark.SparkContext] - Starting job: count at PaidPromotionAdjustParameter.scala:59
2021-12-03 20:29:01,138 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 0 (count at PaidPromotionAdjustParameter.scala:59) with 22 output partitions
2021-12-03 20:29:01,138 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 0 (count at PaidPromotionAdjustParameter.scala:59)
2021-12-03 20:29:01,139 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List()
2021-12-03 20:29:01,139 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2021-12-03 20:29:01,148 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 0 (/sk/chongqing/data/behavior_data.bcp MapPartitionsRDD[1] at textFile at PaidPromotionAdjustParameter.scala:57), which has no missing parents
2021-12-03 20:29:01,181 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_1 stored as values in memory (estimated size 3.1 KB, free 1990.5 MB)
2021-12-03 20:29:01,187 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_1_piece0 stored as bytes in memory (estimated size 1903.0 B, free 1990.5 MB)
2021-12-03 20:29:01,188 [dispatcher-event-loop-2] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_1_piece0 in memory on qb:53199 (size: 1903.0 B, free: 1990.8 MB)
2021-12-03 20:29:01,188 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 1 from broadcast at DAGScheduler.scala:1039
2021-12-03 20:29:01,199 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 22 missing tasks from ResultStage 0 (/sk/chongqing/data/behavior_data.bcp MapPartitionsRDD[1] at textFile at PaidPromotionAdjustParameter.scala:57) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14))
2021-12-03 20:29:01,199 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 0.0 with 22 tasks
2021-12-03 20:29:01,230 [dispatcher-event-loop-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 0.0 (TID 0, localhost, executor driver, partition 0, ANY, 7899 bytes)
2021-12-03 20:29:01,231 [dispatcher-event-loop-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 0.0 (TID 1, localhost, executor driver, partition 1, ANY, 7899 bytes)
2021-12-03 20:29:01,232 [dispatcher-event-loop-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 2.0 in stage 0.0 (TID 2, localhost, executor driver, partition 2, ANY, 7899 bytes)
2021-12-03 20:29:01,232 [dispatcher-event-loop-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 3.0 in stage 0.0 (TID 3, localhost, executor driver, partition 3, ANY, 7899 bytes)
2021-12-03 20:29:01,232 [dispatcher-event-loop-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 4.0 in stage 0.0 (TID 4, localhost, executor driver, partition 4, ANY, 7899 bytes)
2021-12-03 20:29:01,233 [dispatcher-event-loop-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 5.0 in stage 0.0 (TID 5, localhost, executor driver, partition 5, ANY, 7899 bytes)
2021-12-03 20:29:01,233 [dispatcher-event-loop-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 6.0 in stage 0.0 (TID 6, localhost, executor driver, partition 6, ANY, 7899 bytes)
2021-12-03 20:29:01,233 [dispatcher-event-loop-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 7.0 in stage 0.0 (TID 7, localhost, executor driver, partition 7, ANY, 7899 bytes)
2021-12-03 20:29:01,233 [dispatcher-event-loop-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 8.0 in stage 0.0 (TID 8, localhost, executor driver, partition 8, ANY, 7899 bytes)
2021-12-03 20:29:01,234 [dispatcher-event-loop-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 9.0 in stage 0.0 (TID 9, localhost, executor driver, partition 9, ANY, 7899 bytes)
2021-12-03 20:29:01,234 [dispatcher-event-loop-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 10.0 in stage 0.0 (TID 10, localhost, executor driver, partition 10, ANY, 7899 bytes)
2021-12-03 20:29:01,234 [dispatcher-event-loop-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 11.0 in stage 0.0 (TID 11, localhost, executor driver, partition 11, ANY, 7899 bytes)
2021-12-03 20:29:01,239 [Executor task launch worker for task 8] INFO [org.apache.spark.executor.Executor] - Running task 8.0 in stage 0.0 (TID 8)
2021-12-03 20:29:01,239 [Executor task launch worker for task 11] INFO [org.apache.spark.executor.Executor] - Running task 11.0 in stage 0.0 (TID 11)
2021-12-03 20:29:01,239 [Executor task launch worker for task 3] INFO [org.apache.spark.executor.Executor] - Running task 3.0 in stage 0.0 (TID 3)
2021-12-03 20:29:01,239 [Executor task launch worker for task 1] INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 0.0 (TID 1)
2021-12-03 20:29:01,239 [Executor task launch worker for task 4] INFO [org.apache.spark.executor.Executor] - Running task 4.0 in stage 0.0 (TID 4)
2021-12-03 20:29:01,239 [Executor task launch worker for task 7] INFO [org.apache.spark.executor.Executor] - Running task 7.0 in stage 0.0 (TID 7)
2021-12-03 20:29:01,239 [Executor task launch worker for task 5] INFO [org.apache.spark.executor.Executor] - Running task 5.0 in stage 0.0 (TID 5)
2021-12-03 20:29:01,239 [Executor task launch worker for task 10] INFO [org.apache.spark.executor.Executor] - Running task 10.0 in stage 0.0 (TID 10)
2021-12-03 20:29:01,239 [Executor task launch worker for task 0] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 0.0 (TID 0)
2021-12-03 20:29:01,239 [Executor task launch worker for task 2] INFO [org.apache.spark.executor.Executor] - Running task 2.0 in stage 0.0 (TID 2)
2021-12-03 20:29:01,239 [Executor task launch worker for task 6] INFO [org.apache.spark.executor.Executor] - Running task 6.0 in stage 0.0 (TID 6)
2021-12-03 20:29:01,239 [Executor task launch worker for task 9] INFO [org.apache.spark.executor.Executor] - Running task 9.0 in stage 0.0 (TID 9)
2021-12-03 20:29:01,280 [Executor task launch worker for task 0] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:0+134217728
2021-12-03 20:29:01,280 [Executor task launch worker for task 4] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:536870912+134217728
2021-12-03 20:29:01,280 [Executor task launch worker for task 9] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:1207959552+134217728
2021-12-03 20:29:01,280 [Executor task launch worker for task 3] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:402653184+134217728
2021-12-03 20:29:01,280 [Executor task launch worker for task 5] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:671088640+134217728
2021-12-03 20:29:01,280 [Executor task launch worker for task 7] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:939524096+134217728
2021-12-03 20:29:01,280 [Executor task launch worker for task 6] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:805306368+134217728
2021-12-03 20:29:01,280 [Executor task launch worker for task 11] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:1476395008+134217728
2021-12-03 20:29:01,280 [Executor task launch worker for task 10] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:1342177280+134217728
2021-12-03 20:29:01,280 [Executor task launch worker for task 1] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:134217728+134217728
2021-12-03 20:29:01,280 [Executor task launch worker for task 8] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:1073741824+134217728
2021-12-03 20:29:01,280 [Executor task launch worker for task 2] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:268435456+134217728
2021-12-03 20:30:38,703 [Executor task launch worker for task 1] INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 0.0 (TID 1). 798 bytes result sent to driver
2021-12-03 20:30:38,705 [dispatcher-event-loop-4] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 12.0 in stage 0.0 (TID 12, localhost, executor driver, partition 12, ANY, 7899 bytes)
2021-12-03 20:30:38,705 [Executor task launch worker for task 12] INFO [org.apache.spark.executor.Executor] - Running task 12.0 in stage 0.0 (TID 12)
2021-12-03 20:30:38,708 [Executor task launch worker for task 12] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:1610612736+134217728
2021-12-03 20:30:38,712 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 0.0 (TID 1) in 97480 ms on localhost (executor driver) (1/22)
2021-12-03 20:30:53,771 [Executor task launch worker for task 11] INFO [org.apache.spark.executor.Executor] - Finished task 11.0 in stage 0.0 (TID 11). 755 bytes result sent to driver
2021-12-03 20:30:53,772 [dispatcher-event-loop-6] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 13.0 in stage 0.0 (TID 13, localhost, executor driver, partition 13, ANY, 7899 bytes)
2021-12-03 20:30:53,772 [Executor task launch worker for task 13] INFO [org.apache.spark.executor.Executor] - Running task 13.0 in stage 0.0 (TID 13)
2021-12-03 20:30:53,773 [Executor task launch worker for task 13] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:1744830464+134217728
2021-12-03 20:30:53,775 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 11.0 in stage 0.0 (TID 11) in 112541 ms on localhost (executor driver) (2/22)
2021-12-03 20:31:06,321 [Executor task launch worker for task 7] INFO [org.apache.spark.executor.Executor] - Finished task 7.0 in stage 0.0 (TID 7). 755 bytes result sent to driver
2021-12-03 20:31:06,322 [dispatcher-event-loop-11] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 14.0 in stage 0.0 (TID 14, localhost, executor driver, partition 14, ANY, 7899 bytes)
2021-12-03 20:31:06,322 [Executor task launch worker for task 14] INFO [org.apache.spark.executor.Executor] - Running task 14.0 in stage 0.0 (TID 14)
2021-12-03 20:31:06,323 [Executor task launch worker for task 14] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:1879048192+134217728
2021-12-03 20:31:06,325 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 7.0 in stage 0.0 (TID 7) in 125092 ms on localhost (executor driver) (3/22)
2021-12-03 20:31:13,998 [Executor task launch worker for task 0] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 0.0 (TID 0). 755 bytes result sent to driver
2021-12-03 20:31:13,999 [dispatcher-event-loop-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 15.0 in stage 0.0 (TID 15, localhost, executor driver, partition 15, ANY, 7899 bytes)
2021-12-03 20:31:13,999 [Executor task launch worker for task 15] INFO [org.apache.spark.executor.Executor] - Running task 15.0 in stage 0.0 (TID 15)
2021-12-03 20:31:14,000 [Executor task launch worker for task 15] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:2013265920+134217728
2021-12-03 20:31:14,001 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 0.0 (TID 0) in 132780 ms on localhost (executor driver) (4/22)
2021-12-03 20:31:24,806 [Executor task launch worker for task 4] INFO [org.apache.spark.executor.Executor] - Finished task 4.0 in stage 0.0 (TID 4). 755 bytes result sent to driver
2021-12-03 20:31:24,807 [dispatcher-event-loop-7] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 16.0 in stage 0.0 (TID 16, localhost, executor driver, partition 16, ANY, 7899 bytes)
2021-12-03 20:31:24,807 [Executor task launch worker for task 16] INFO [org.apache.spark.executor.Executor] - Running task 16.0 in stage 0.0 (TID 16)
2021-12-03 20:31:24,807 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 4.0 in stage 0.0 (TID 4) in 143575 ms on localhost (executor driver) (5/22)
2021-12-03 20:31:24,808 [Executor task launch worker for task 16] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:2147483648+134217728
2021-12-03 20:31:24,928 [Executor task launch worker for task 8] INFO [org.apache.spark.executor.Executor] - Finished task 8.0 in stage 0.0 (TID 8). 755 bytes result sent to driver
2021-12-03 20:31:24,928 [dispatcher-event-loop-9] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 17.0 in stage 0.0 (TID 17, localhost, executor driver, partition 17, ANY, 7899 bytes)
2021-12-03 20:31:24,928 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 8.0 in stage 0.0 (TID 8) in 143695 ms on localhost (executor driver) (6/22)
2021-12-03 20:31:24,928 [Executor task launch worker for task 17] INFO [org.apache.spark.executor.Executor] - Running task 17.0 in stage 0.0 (TID 17)
2021-12-03 20:31:24,930 [Executor task launch worker for task 17] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:2281701376+134217728
2021-12-03 20:31:31,541 [Executor task launch worker for task 9] INFO [org.apache.spark.executor.Executor] - Finished task 9.0 in stage 0.0 (TID 9). 755 bytes result sent to driver
2021-12-03 20:31:31,542 [dispatcher-event-loop-11] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 18.0 in stage 0.0 (TID 18, localhost, executor driver, partition 18, ANY, 7899 bytes)
2021-12-03 20:31:31,542 [Executor task launch worker for task 18] INFO [org.apache.spark.executor.Executor] - Running task 18.0 in stage 0.0 (TID 18)
2021-12-03 20:31:31,542 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 9.0 in stage 0.0 (TID 9) in 150309 ms on localhost (executor driver) (7/22)
2021-12-03 20:31:31,543 [Executor task launch worker for task 18] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:2415919104+134217728
2021-12-03 20:31:34,856 [Executor task launch worker for task 6] INFO [org.apache.spark.executor.Executor] - Finished task 6.0 in stage 0.0 (TID 6). 755 bytes result sent to driver
2021-12-03 20:31:34,856 [dispatcher-event-loop-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 19.0 in stage 0.0 (TID 19, localhost, executor driver, partition 19, ANY, 7899 bytes)
2021-12-03 20:31:34,857 [Executor task launch worker for task 19] INFO [org.apache.spark.executor.Executor] - Running task 19.0 in stage 0.0 (TID 19)
2021-12-03 20:31:34,857 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 6.0 in stage 0.0 (TID 6) in 153624 ms on localhost (executor driver) (8/22)
2021-12-03 20:31:34,857 [Executor task launch worker for task 19] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:2550136832+134217728
2021-12-03 20:31:38,543 [Executor task launch worker for task 3] INFO [org.apache.spark.executor.Executor] - Finished task 3.0 in stage 0.0 (TID 3). 755 bytes result sent to driver
2021-12-03 20:31:38,544 [dispatcher-event-loop-5] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 20.0 in stage 0.0 (TID 20, localhost, executor driver, partition 20, ANY, 7899 bytes)
2021-12-03 20:31:38,544 [Executor task launch worker for task 20] INFO [org.apache.spark.executor.Executor] - Running task 20.0 in stage 0.0 (TID 20)
2021-12-03 20:31:38,544 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 3.0 in stage 0.0 (TID 3) in 157312 ms on localhost (executor driver) (9/22)
2021-12-03 20:31:38,545 [Executor task launch worker for task 20] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:2684354560+134217728
2021-12-03 20:31:38,839 [Executor task launch worker for task 2] INFO [org.apache.spark.executor.Executor] - Finished task 2.0 in stage 0.0 (TID 2). 755 bytes result sent to driver
2021-12-03 20:31:38,839 [dispatcher-event-loop-7] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 21.0 in stage 0.0 (TID 21, localhost, executor driver, partition 21, ANY, 7899 bytes)
2021-12-03 20:31:38,840 [Executor task launch worker for task 21] INFO [org.apache.spark.executor.Executor] - Running task 21.0 in stage 0.0 (TID 21)
2021-12-03 20:31:38,840 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 2.0 in stage 0.0 (TID 2) in 157609 ms on localhost (executor driver) (10/22)
2021-12-03 20:31:38,840 [Executor task launch worker for task 21] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:2818572288+147216171
2021-12-03 20:31:43,898 [Executor task launch worker for task 10] INFO [org.apache.spark.executor.Executor] - Finished task 10.0 in stage 0.0 (TID 10). 755 bytes result sent to driver
2021-12-03 20:31:43,900 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 10.0 in stage 0.0 (TID 10) in 162666 ms on localhost (executor driver) (11/22)
2021-12-03 20:31:54,057 [Executor task launch worker for task 5] INFO [org.apache.spark.executor.Executor] - Finished task 5.0 in stage 0.0 (TID 5). 755 bytes result sent to driver
2021-12-03 20:31:54,058 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 5.0 in stage 0.0 (TID 5) in 172826 ms on localhost (executor driver) (12/22)
2021-12-03 20:32:28,698 [Executor task launch worker for task 12] INFO [org.apache.spark.executor.Executor] - Finished task 12.0 in stage 0.0 (TID 12). 755 bytes result sent to driver
2021-12-03 20:32:28,698 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 12.0 in stage 0.0 (TID 12) in 109993 ms on localhost (executor driver) (13/22)
2021-12-03 20:33:00,508 [Executor task launch worker for task 14] INFO [org.apache.spark.executor.Executor] - Finished task 14.0 in stage 0.0 (TID 14). 755 bytes result sent to driver
2021-12-03 20:33:00,508 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 14.0 in stage 0.0 (TID 14) in 114186 ms on localhost (executor driver) (14/22)
2021-12-03 20:33:01,543 [Executor task launch worker for task 19] INFO [org.apache.spark.executor.Executor] - Finished task 19.0 in stage 0.0 (TID 19). 712 bytes result sent to driver
2021-12-03 20:33:01,543 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 19.0 in stage 0.0 (TID 19) in 86687 ms on localhost (executor driver) (15/22)
2021-12-03 20:33:03,952 [Executor task launch worker for task 13] INFO [org.apache.spark.executor.Executor] - Finished task 13.0 in stage 0.0 (TID 13). 712 bytes result sent to driver
2021-12-03 20:33:03,952 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 13.0 in stage 0.0 (TID 13) in 130181 ms on localhost (executor driver) (16/22)
2021-12-03 20:33:07,475 [Executor task launch worker for task 17] INFO [org.apache.spark.executor.Executor] - Finished task 17.0 in stage 0.0 (TID 17). 755 bytes result sent to driver
2021-12-03 20:33:07,476 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 17.0 in stage 0.0 (TID 17) in 102548 ms on localhost (executor driver) (17/22)
2021-12-03 20:33:10,071 [Executor task launch worker for task 21] INFO [org.apache.spark.executor.Executor] - Finished task 21.0 in stage 0.0 (TID 21). 712 bytes result sent to driver
2021-12-03 20:33:10,071 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 21.0 in stage 0.0 (TID 21) in 91232 ms on localhost (executor driver) (18/22)
2021-12-03 20:33:13,804 [Executor task launch worker for task 18] INFO [org.apache.spark.executor.Executor] - Finished task 18.0 in stage 0.0 (TID 18). 712 bytes result sent to driver
2021-12-03 20:33:13,805 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 18.0 in stage 0.0 (TID 18) in 102263 ms on localhost (executor driver) (19/22)
2021-12-03 20:33:15,142 [Executor task launch worker for task 16] INFO [org.apache.spark.executor.Executor] - Finished task 16.0 in stage 0.0 (TID 16). 755 bytes result sent to driver
2021-12-03 20:33:15,143 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 16.0 in stage 0.0 (TID 16) in 110337 ms on localhost (executor driver) (20/22)
2021-12-03 20:33:16,305 [Executor task launch worker for task 15] INFO [org.apache.spark.executor.Executor] - Finished task 15.0 in stage 0.0 (TID 15). 755 bytes result sent to driver
2021-12-03 20:33:16,305 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 15.0 in stage 0.0 (TID 15) in 122307 ms on localhost (executor driver) (21/22)
2021-12-03 20:33:16,774 [Executor task launch worker for task 20] INFO [org.apache.spark.executor.Executor] - Finished task 20.0 in stage 0.0 (TID 20). 755 bytes result sent to driver
2021-12-03 20:33:16,775 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 20.0 in stage 0.0 (TID 20) in 98232 ms on localhost (executor driver) (22/22)
2021-12-03 20:33:16,776 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 0.0, whose tasks have all completed, from pool 
2021-12-03 20:33:16,776 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 0 (count at PaidPromotionAdjustParameter.scala:59) finished in 255.611 s
2021-12-03 20:33:16,780 [main] INFO [org.apache.spark.scheduler.DAGScheduler] - Job 0 finished: count at PaidPromotionAdjustParameter.scala:59, took 255.651495 s
2021-12-03 20:33:16,781 [main] INFO [PaidPromotion$] - 收视总数68489201
2021-12-03 20:33:16,797 [main] INFO [org.apache.spark.SparkContext] - Starting job: count at PaidPromotionAdjustParameter.scala:68
2021-12-03 20:33:16,806 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 3 (map at PaidPromotionAdjustParameter.scala:67)
2021-12-03 20:33:16,806 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 1 (count at PaidPromotionAdjustParameter.scala:68) with 22 output partitions
2021-12-03 20:33:16,807 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 2 (count at PaidPromotionAdjustParameter.scala:68)
2021-12-03 20:33:16,807 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 1)
2021-12-03 20:33:16,807 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List(ShuffleMapStage 1)
2021-12-03 20:33:16,808 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ShuffleMapStage 1 (MapPartitionsRDD[3] at map at PaidPromotionAdjustParameter.scala:67), which has no missing parents
2021-12-03 20:33:16,816 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_2 stored as values in memory (estimated size 4.7 KB, free 1990.5 MB)
2021-12-03 20:33:16,819 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_2_piece0 stored as bytes in memory (estimated size 2.7 KB, free 1990.5 MB)
2021-12-03 20:33:16,819 [dispatcher-event-loop-7] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_2_piece0 in memory on qb:53199 (size: 2.7 KB, free: 1990.8 MB)
2021-12-03 20:33:16,820 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 2 from broadcast at DAGScheduler.scala:1039
2021-12-03 20:33:16,822 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 22 missing tasks from ShuffleMapStage 1 (MapPartitionsRDD[3] at map at PaidPromotionAdjustParameter.scala:67) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14))
2021-12-03 20:33:16,822 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 1.0 with 22 tasks
2021-12-03 20:33:16,823 [dispatcher-event-loop-8] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 1.0 (TID 22, localhost, executor driver, partition 0, ANY, 7888 bytes)
2021-12-03 20:33:16,823 [dispatcher-event-loop-8] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 1.0 (TID 23, localhost, executor driver, partition 1, ANY, 7888 bytes)
2021-12-03 20:33:16,823 [dispatcher-event-loop-8] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 2.0 in stage 1.0 (TID 24, localhost, executor driver, partition 2, ANY, 7888 bytes)
2021-12-03 20:33:16,823 [dispatcher-event-loop-8] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 3.0 in stage 1.0 (TID 25, localhost, executor driver, partition 3, ANY, 7888 bytes)
2021-12-03 20:33:16,823 [dispatcher-event-loop-8] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 4.0 in stage 1.0 (TID 26, localhost, executor driver, partition 4, ANY, 7888 bytes)
2021-12-03 20:33:16,824 [dispatcher-event-loop-8] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 5.0 in stage 1.0 (TID 27, localhost, executor driver, partition 5, ANY, 7888 bytes)
2021-12-03 20:33:16,824 [dispatcher-event-loop-8] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 6.0 in stage 1.0 (TID 28, localhost, executor driver, partition 6, ANY, 7888 bytes)
2021-12-03 20:33:16,824 [dispatcher-event-loop-8] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 7.0 in stage 1.0 (TID 29, localhost, executor driver, partition 7, ANY, 7888 bytes)
2021-12-03 20:33:16,824 [dispatcher-event-loop-8] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 8.0 in stage 1.0 (TID 30, localhost, executor driver, partition 8, ANY, 7888 bytes)
2021-12-03 20:33:16,824 [dispatcher-event-loop-8] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 9.0 in stage 1.0 (TID 31, localhost, executor driver, partition 9, ANY, 7888 bytes)
2021-12-03 20:33:16,824 [dispatcher-event-loop-8] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 10.0 in stage 1.0 (TID 32, localhost, executor driver, partition 10, ANY, 7888 bytes)
2021-12-03 20:33:16,824 [dispatcher-event-loop-8] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 11.0 in stage 1.0 (TID 33, localhost, executor driver, partition 11, ANY, 7888 bytes)
2021-12-03 20:33:16,824 [Executor task launch worker for task 23] INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 1.0 (TID 23)
2021-12-03 20:33:16,824 [Executor task launch worker for task 22] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 1.0 (TID 22)
2021-12-03 20:33:16,824 [Executor task launch worker for task 31] INFO [org.apache.spark.executor.Executor] - Running task 9.0 in stage 1.0 (TID 31)
2021-12-03 20:33:16,824 [Executor task launch worker for task 30] INFO [org.apache.spark.executor.Executor] - Running task 8.0 in stage 1.0 (TID 30)
2021-12-03 20:33:16,824 [Executor task launch worker for task 28] INFO [org.apache.spark.executor.Executor] - Running task 6.0 in stage 1.0 (TID 28)
2021-12-03 20:33:16,824 [Executor task launch worker for task 26] INFO [org.apache.spark.executor.Executor] - Running task 4.0 in stage 1.0 (TID 26)
2021-12-03 20:33:16,824 [Executor task launch worker for task 25] INFO [org.apache.spark.executor.Executor] - Running task 3.0 in stage 1.0 (TID 25)
2021-12-03 20:33:16,824 [Executor task launch worker for task 27] INFO [org.apache.spark.executor.Executor] - Running task 5.0 in stage 1.0 (TID 27)
2021-12-03 20:33:16,825 [Executor task launch worker for task 33] INFO [org.apache.spark.executor.Executor] - Running task 11.0 in stage 1.0 (TID 33)
2021-12-03 20:33:16,824 [Executor task launch worker for task 24] INFO [org.apache.spark.executor.Executor] - Running task 2.0 in stage 1.0 (TID 24)
2021-12-03 20:33:16,825 [Executor task launch worker for task 32] INFO [org.apache.spark.executor.Executor] - Running task 10.0 in stage 1.0 (TID 32)
2021-12-03 20:33:16,824 [Executor task launch worker for task 29] INFO [org.apache.spark.executor.Executor] - Running task 7.0 in stage 1.0 (TID 29)
2021-12-03 20:33:16,829 [Executor task launch worker for task 24] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:268435456+134217728
2021-12-03 20:33:16,829 [Executor task launch worker for task 26] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:536870912+134217728
2021-12-03 20:33:16,829 [Executor task launch worker for task 23] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:134217728+134217728
2021-12-03 20:33:16,829 [Executor task launch worker for task 25] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:402653184+134217728
2021-12-03 20:33:16,829 [Executor task launch worker for task 30] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:1073741824+134217728
2021-12-03 20:33:16,829 [Executor task launch worker for task 27] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:671088640+134217728
2021-12-03 20:33:16,829 [Executor task launch worker for task 28] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:805306368+134217728
2021-12-03 20:33:16,829 [Executor task launch worker for task 33] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:1476395008+134217728
2021-12-03 20:33:16,829 [Executor task launch worker for task 31] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:1207959552+134217728
2021-12-03 20:33:16,829 [Executor task launch worker for task 22] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:0+134217728
2021-12-03 20:33:16,829 [Executor task launch worker for task 29] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:939524096+134217728
2021-12-03 20:33:16,829 [Executor task launch worker for task 32] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:1342177280+134217728
2021-12-03 20:35:06,541 [Executor task launch worker for task 24] INFO [org.apache.spark.executor.Executor] - Finished task 2.0 in stage 1.0 (TID 24). 1052 bytes result sent to driver
2021-12-03 20:35:06,542 [dispatcher-event-loop-10] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 12.0 in stage 1.0 (TID 34, localhost, executor driver, partition 12, ANY, 7888 bytes)
2021-12-03 20:35:06,542 [Executor task launch worker for task 34] INFO [org.apache.spark.executor.Executor] - Running task 12.0 in stage 1.0 (TID 34)
2021-12-03 20:35:06,543 [Executor task launch worker for task 34] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:1610612736+134217728
2021-12-03 20:35:06,556 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 2.0 in stage 1.0 (TID 24) in 109733 ms on localhost (executor driver) (1/22)
2021-12-03 20:35:06,597 [Executor task launch worker for task 25] INFO [org.apache.spark.executor.Executor] - Finished task 3.0 in stage 1.0 (TID 25). 1095 bytes result sent to driver
2021-12-03 20:35:06,597 [dispatcher-event-loop-4] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 13.0 in stage 1.0 (TID 35, localhost, executor driver, partition 13, ANY, 7888 bytes)
2021-12-03 20:35:06,598 [Executor task launch worker for task 35] INFO [org.apache.spark.executor.Executor] - Running task 13.0 in stage 1.0 (TID 35)
2021-12-03 20:35:06,598 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 3.0 in stage 1.0 (TID 25) in 109775 ms on localhost (executor driver) (2/22)
2021-12-03 20:35:06,598 [Executor task launch worker for task 35] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:1744830464+134217728
2021-12-03 20:35:07,817 [Executor task launch worker for task 32] INFO [org.apache.spark.executor.Executor] - Finished task 10.0 in stage 1.0 (TID 32). 1052 bytes result sent to driver
2021-12-03 20:35:07,817 [dispatcher-event-loop-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 14.0 in stage 1.0 (TID 36, localhost, executor driver, partition 14, ANY, 7888 bytes)
2021-12-03 20:35:07,818 [Executor task launch worker for task 36] INFO [org.apache.spark.executor.Executor] - Running task 14.0 in stage 1.0 (TID 36)
2021-12-03 20:35:07,818 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 10.0 in stage 1.0 (TID 32) in 110994 ms on localhost (executor driver) (3/22)
2021-12-03 20:35:07,819 [Executor task launch worker for task 36] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:1879048192+134217728
2021-12-03 20:35:27,742 [Executor task launch worker for task 23] INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 1.0 (TID 23). 1052 bytes result sent to driver
2021-12-03 20:35:27,743 [dispatcher-event-loop-7] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 15.0 in stage 1.0 (TID 37, localhost, executor driver, partition 15, ANY, 7888 bytes)
2021-12-03 20:35:27,743 [Executor task launch worker for task 37] INFO [org.apache.spark.executor.Executor] - Running task 15.0 in stage 1.0 (TID 37)
2021-12-03 20:35:27,743 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 1.0 (TID 23) in 130920 ms on localhost (executor driver) (4/22)
2021-12-03 20:35:27,744 [Executor task launch worker for task 37] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:2013265920+134217728
2021-12-03 20:35:34,637 [Executor task launch worker for task 30] INFO [org.apache.spark.executor.Executor] - Finished task 8.0 in stage 1.0 (TID 30). 1052 bytes result sent to driver
2021-12-03 20:35:34,637 [dispatcher-event-loop-4] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 16.0 in stage 1.0 (TID 38, localhost, executor driver, partition 16, ANY, 7888 bytes)
2021-12-03 20:35:34,638 [Executor task launch worker for task 38] INFO [org.apache.spark.executor.Executor] - Running task 16.0 in stage 1.0 (TID 38)
2021-12-03 20:35:34,638 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 8.0 in stage 1.0 (TID 30) in 137814 ms on localhost (executor driver) (5/22)
2021-12-03 20:35:34,638 [Executor task launch worker for task 38] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:2147483648+134217728
2021-12-03 20:35:35,109 [Executor task launch worker for task 31] INFO [org.apache.spark.executor.Executor] - Finished task 9.0 in stage 1.0 (TID 31). 1052 bytes result sent to driver
2021-12-03 20:35:35,110 [dispatcher-event-loop-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 17.0 in stage 1.0 (TID 39, localhost, executor driver, partition 17, ANY, 7888 bytes)
2021-12-03 20:35:35,110 [Executor task launch worker for task 39] INFO [org.apache.spark.executor.Executor] - Running task 17.0 in stage 1.0 (TID 39)
2021-12-03 20:35:35,110 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 9.0 in stage 1.0 (TID 31) in 138286 ms on localhost (executor driver) (6/22)
2021-12-03 20:35:35,111 [Executor task launch worker for task 39] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:2281701376+134217728
2021-12-03 20:35:35,620 [Executor task launch worker for task 26] INFO [org.apache.spark.executor.Executor] - Finished task 4.0 in stage 1.0 (TID 26). 1052 bytes result sent to driver
2021-12-03 20:35:35,621 [dispatcher-event-loop-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 18.0 in stage 1.0 (TID 40, localhost, executor driver, partition 18, ANY, 7888 bytes)
2021-12-03 20:35:35,621 [Executor task launch worker for task 40] INFO [org.apache.spark.executor.Executor] - Running task 18.0 in stage 1.0 (TID 40)
2021-12-03 20:35:35,621 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 4.0 in stage 1.0 (TID 26) in 138798 ms on localhost (executor driver) (7/22)
2021-12-03 20:35:35,622 [Executor task launch worker for task 40] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:2415919104+134217728
2021-12-03 20:35:37,149 [Executor task launch worker for task 33] INFO [org.apache.spark.executor.Executor] - Finished task 11.0 in stage 1.0 (TID 33). 1052 bytes result sent to driver
2021-12-03 20:35:37,150 [dispatcher-event-loop-5] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 19.0 in stage 1.0 (TID 41, localhost, executor driver, partition 19, ANY, 7888 bytes)
2021-12-03 20:35:37,150 [Executor task launch worker for task 41] INFO [org.apache.spark.executor.Executor] - Running task 19.0 in stage 1.0 (TID 41)
2021-12-03 20:35:37,150 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 11.0 in stage 1.0 (TID 33) in 140326 ms on localhost (executor driver) (8/22)
2021-12-03 20:35:37,151 [Executor task launch worker for task 41] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:2550136832+134217728
2021-12-03 20:35:43,349 [Executor task launch worker for task 29] INFO [org.apache.spark.executor.Executor] - Finished task 7.0 in stage 1.0 (TID 29). 1052 bytes result sent to driver
2021-12-03 20:35:43,349 [dispatcher-event-loop-10] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 20.0 in stage 1.0 (TID 42, localhost, executor driver, partition 20, ANY, 7888 bytes)
2021-12-03 20:35:43,349 [Executor task launch worker for task 42] INFO [org.apache.spark.executor.Executor] - Running task 20.0 in stage 1.0 (TID 42)
2021-12-03 20:35:43,350 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 7.0 in stage 1.0 (TID 29) in 146526 ms on localhost (executor driver) (9/22)
2021-12-03 20:35:43,351 [Executor task launch worker for task 42] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:2684354560+134217728
2021-12-03 20:35:59,370 [Executor task launch worker for task 28] INFO [org.apache.spark.executor.Executor] - Finished task 6.0 in stage 1.0 (TID 28). 1052 bytes result sent to driver
2021-12-03 20:35:59,371 [dispatcher-event-loop-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 21.0 in stage 1.0 (TID 43, localhost, executor driver, partition 21, ANY, 7888 bytes)
2021-12-03 20:35:59,371 [Executor task launch worker for task 43] INFO [org.apache.spark.executor.Executor] - Running task 21.0 in stage 1.0 (TID 43)
2021-12-03 20:35:59,371 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 6.0 in stage 1.0 (TID 28) in 162547 ms on localhost (executor driver) (10/22)
2021-12-03 20:35:59,372 [Executor task launch worker for task 43] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:2818572288+147216171
2021-12-03 20:36:00,612 [Executor task launch worker for task 27] INFO [org.apache.spark.executor.Executor] - Finished task 5.0 in stage 1.0 (TID 27). 1052 bytes result sent to driver
2021-12-03 20:36:00,613 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 5.0 in stage 1.0 (TID 27) in 163790 ms on localhost (executor driver) (11/22)
2021-12-03 20:36:05,050 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 16
2021-12-03 20:36:05,050 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 21
2021-12-03 20:36:05,050 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 5
2021-12-03 20:36:05,050 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 20
2021-12-03 20:36:05,050 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 10
2021-12-03 20:36:05,050 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 23
2021-12-03 20:36:05,050 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 24
2021-12-03 20:36:05,050 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 19
2021-12-03 20:36:05,050 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 15
2021-12-03 20:36:05,050 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 7
2021-12-03 20:36:05,050 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 9
2021-12-03 20:36:05,050 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 22
2021-12-03 20:36:05,050 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1
2021-12-03 20:36:05,050 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 17
2021-12-03 20:36:05,051 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 0
2021-12-03 20:36:05,051 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 6
2021-12-03 20:36:05,051 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 2
2021-12-03 20:36:05,051 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 11
2021-12-03 20:36:05,051 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 18
2021-12-03 20:36:05,060 [dispatcher-event-loop-10] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_1_piece0 on qb:53199 in memory (size: 1903.0 B, free: 1990.8 MB)
2021-12-03 20:36:05,062 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 3
2021-12-03 20:36:05,062 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 12
2021-12-03 20:36:05,062 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 4
2021-12-03 20:36:05,062 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 8
2021-12-03 20:36:05,062 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 14
2021-12-03 20:36:05,062 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 13
2021-12-03 20:36:19,025 [Executor task launch worker for task 22] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 1.0 (TID 22). 1052 bytes result sent to driver
2021-12-03 20:36:19,025 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 1.0 (TID 22) in 182203 ms on localhost (executor driver) (12/22)
2021-12-03 20:36:34,624 [Executor task launch worker for task 35] INFO [org.apache.spark.executor.Executor] - Finished task 13.0 in stage 1.0 (TID 35). 1009 bytes result sent to driver
2021-12-03 20:36:34,624 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 13.0 in stage 1.0 (TID 35) in 88027 ms on localhost (executor driver) (13/22)
2021-12-03 20:37:12,148 [Executor task launch worker for task 40] INFO [org.apache.spark.executor.Executor] - Finished task 18.0 in stage 1.0 (TID 40). 1052 bytes result sent to driver
2021-12-03 20:37:12,149 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 18.0 in stage 1.0 (TID 40) in 96528 ms on localhost (executor driver) (14/22)
2021-12-03 20:37:16,420 [Executor task launch worker for task 41] INFO [org.apache.spark.executor.Executor] - Finished task 19.0 in stage 1.0 (TID 41). 1052 bytes result sent to driver
2021-12-03 20:37:16,420 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 19.0 in stage 1.0 (TID 41) in 99270 ms on localhost (executor driver) (15/22)
2021-12-03 20:37:16,850 [Executor task launch worker for task 36] INFO [org.apache.spark.executor.Executor] - Finished task 14.0 in stage 1.0 (TID 36). 1052 bytes result sent to driver
2021-12-03 20:37:16,850 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 14.0 in stage 1.0 (TID 36) in 129033 ms on localhost (executor driver) (16/22)
2021-12-03 20:37:18,058 [Executor task launch worker for task 34] INFO [org.apache.spark.executor.Executor] - Finished task 12.0 in stage 1.0 (TID 34). 1052 bytes result sent to driver
2021-12-03 20:37:18,059 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 12.0 in stage 1.0 (TID 34) in 131516 ms on localhost (executor driver) (17/22)
2021-12-03 20:37:19,657 [Executor task launch worker for task 37] INFO [org.apache.spark.executor.Executor] - Finished task 15.0 in stage 1.0 (TID 37). 1009 bytes result sent to driver
2021-12-03 20:37:19,658 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 15.0 in stage 1.0 (TID 37) in 111914 ms on localhost (executor driver) (18/22)
2021-12-03 20:37:24,730 [Executor task launch worker for task 39] INFO [org.apache.spark.executor.Executor] - Finished task 17.0 in stage 1.0 (TID 39). 1009 bytes result sent to driver
2021-12-03 20:37:24,730 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 17.0 in stage 1.0 (TID 39) in 109621 ms on localhost (executor driver) (19/22)
2021-12-03 20:37:27,905 [Executor task launch worker for task 42] INFO [org.apache.spark.executor.Executor] - Finished task 20.0 in stage 1.0 (TID 42). 1052 bytes result sent to driver
2021-12-03 20:37:27,906 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 20.0 in stage 1.0 (TID 42) in 104557 ms on localhost (executor driver) (20/22)
2021-12-03 20:37:31,093 [Executor task launch worker for task 38] INFO [org.apache.spark.executor.Executor] - Finished task 16.0 in stage 1.0 (TID 38). 1009 bytes result sent to driver
2021-12-03 20:37:31,094 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 16.0 in stage 1.0 (TID 38) in 116457 ms on localhost (executor driver) (21/22)
2021-12-03 20:37:32,313 [Executor task launch worker for task 43] INFO [org.apache.spark.executor.Executor] - Finished task 21.0 in stage 1.0 (TID 43). 1009 bytes result sent to driver
2021-12-03 20:37:32,313 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 21.0 in stage 1.0 (TID 43) in 92942 ms on localhost (executor driver) (22/22)
2021-12-03 20:37:32,313 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 1.0, whose tasks have all completed, from pool 
2021-12-03 20:37:32,313 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ShuffleMapStage 1 (map at PaidPromotionAdjustParameter.scala:67) finished in 255.503 s
2021-12-03 20:37:32,314 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - looking for newly runnable stages
2021-12-03 20:37:32,314 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - running: Set()
2021-12-03 20:37:32,314 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - waiting: Set(ResultStage 2)
2021-12-03 20:37:32,315 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - failed: Set()
2021-12-03 20:37:32,317 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 2 (ShuffledRDD[4] at reduceByKey at PaidPromotionAdjustParameter.scala:67), which has no missing parents
2021-12-03 20:37:32,321 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_3 stored as values in memory (estimated size 3.0 KB, free 1990.5 MB)
2021-12-03 20:37:32,323 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_3_piece0 stored as bytes in memory (estimated size 1906.0 B, free 1990.5 MB)
2021-12-03 20:37:32,324 [dispatcher-event-loop-8] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_3_piece0 in memory on qb:53199 (size: 1906.0 B, free: 1990.8 MB)
2021-12-03 20:37:32,324 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 3 from broadcast at DAGScheduler.scala:1039
2021-12-03 20:37:32,324 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 22 missing tasks from ResultStage 2 (ShuffledRDD[4] at reduceByKey at PaidPromotionAdjustParameter.scala:67) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14))
2021-12-03 20:37:32,324 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 2.0 with 22 tasks
2021-12-03 20:37:32,325 [dispatcher-event-loop-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 2.0 (TID 44, localhost, executor driver, partition 0, ANY, 7649 bytes)
2021-12-03 20:37:32,325 [dispatcher-event-loop-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 2.0 (TID 45, localhost, executor driver, partition 1, ANY, 7649 bytes)
2021-12-03 20:37:32,325 [dispatcher-event-loop-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 2.0 in stage 2.0 (TID 46, localhost, executor driver, partition 2, ANY, 7649 bytes)
2021-12-03 20:37:32,326 [dispatcher-event-loop-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 3.0 in stage 2.0 (TID 47, localhost, executor driver, partition 3, ANY, 7649 bytes)
2021-12-03 20:37:32,326 [dispatcher-event-loop-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 4.0 in stage 2.0 (TID 48, localhost, executor driver, partition 4, ANY, 7649 bytes)
2021-12-03 20:37:32,326 [dispatcher-event-loop-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 5.0 in stage 2.0 (TID 49, localhost, executor driver, partition 5, ANY, 7649 bytes)
2021-12-03 20:37:32,326 [dispatcher-event-loop-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 6.0 in stage 2.0 (TID 50, localhost, executor driver, partition 6, ANY, 7649 bytes)
2021-12-03 20:37:32,326 [dispatcher-event-loop-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 7.0 in stage 2.0 (TID 51, localhost, executor driver, partition 7, ANY, 7649 bytes)
2021-12-03 20:37:32,326 [dispatcher-event-loop-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 8.0 in stage 2.0 (TID 52, localhost, executor driver, partition 8, ANY, 7649 bytes)
2021-12-03 20:37:32,326 [dispatcher-event-loop-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 9.0 in stage 2.0 (TID 53, localhost, executor driver, partition 9, ANY, 7649 bytes)
2021-12-03 20:37:32,326 [dispatcher-event-loop-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 10.0 in stage 2.0 (TID 54, localhost, executor driver, partition 10, ANY, 7649 bytes)
2021-12-03 20:37:32,326 [dispatcher-event-loop-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 11.0 in stage 2.0 (TID 55, localhost, executor driver, partition 11, ANY, 7649 bytes)
2021-12-03 20:37:32,327 [Executor task launch worker for task 44] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 2.0 (TID 44)
2021-12-03 20:37:32,327 [Executor task launch worker for task 46] INFO [org.apache.spark.executor.Executor] - Running task 2.0 in stage 2.0 (TID 46)
2021-12-03 20:37:32,327 [Executor task launch worker for task 52] INFO [org.apache.spark.executor.Executor] - Running task 8.0 in stage 2.0 (TID 52)
2021-12-03 20:37:32,327 [Executor task launch worker for task 47] INFO [org.apache.spark.executor.Executor] - Running task 3.0 in stage 2.0 (TID 47)
2021-12-03 20:37:32,327 [Executor task launch worker for task 48] INFO [org.apache.spark.executor.Executor] - Running task 4.0 in stage 2.0 (TID 48)
2021-12-03 20:37:32,327 [Executor task launch worker for task 45] INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 2.0 (TID 45)
2021-12-03 20:37:32,327 [Executor task launch worker for task 53] INFO [org.apache.spark.executor.Executor] - Running task 9.0 in stage 2.0 (TID 53)
2021-12-03 20:37:32,327 [Executor task launch worker for task 50] INFO [org.apache.spark.executor.Executor] - Running task 6.0 in stage 2.0 (TID 50)
2021-12-03 20:37:32,327 [Executor task launch worker for task 51] INFO [org.apache.spark.executor.Executor] - Running task 7.0 in stage 2.0 (TID 51)
2021-12-03 20:37:32,327 [Executor task launch worker for task 49] INFO [org.apache.spark.executor.Executor] - Running task 5.0 in stage 2.0 (TID 49)
2021-12-03 20:37:32,328 [Executor task launch worker for task 54] INFO [org.apache.spark.executor.Executor] - Running task 10.0 in stage 2.0 (TID 54)
2021-12-03 20:37:32,328 [Executor task launch worker for task 55] INFO [org.apache.spark.executor.Executor] - Running task 11.0 in stage 2.0 (TID 55)
2021-12-03 20:37:32,340 [Executor task launch worker for task 50] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 20:37:32,340 [Executor task launch worker for task 44] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 20:37:32,340 [Executor task launch worker for task 46] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 20:37:32,340 [Executor task launch worker for task 49] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 20:37:32,340 [Executor task launch worker for task 47] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 20:37:32,340 [Executor task launch worker for task 51] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 20:37:32,340 [Executor task launch worker for task 48] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 20:37:32,340 [Executor task launch worker for task 45] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 20:37:32,340 [Executor task launch worker for task 54] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 20:37:32,340 [Executor task launch worker for task 55] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 20:37:32,340 [Executor task launch worker for task 53] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 20:37:32,340 [Executor task launch worker for task 52] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 20:37:32,342 [Executor task launch worker for task 49] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 6 ms
2021-12-03 20:37:32,342 [Executor task launch worker for task 52] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 6 ms
2021-12-03 20:37:32,342 [Executor task launch worker for task 48] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 6 ms
2021-12-03 20:37:32,342 [Executor task launch worker for task 54] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 6 ms
2021-12-03 20:37:32,342 [Executor task launch worker for task 55] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 6 ms
2021-12-03 20:37:32,342 [Executor task launch worker for task 51] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 6 ms
2021-12-03 20:37:32,342 [Executor task launch worker for task 46] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 6 ms
2021-12-03 20:37:32,342 [Executor task launch worker for task 44] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 6 ms
2021-12-03 20:37:32,342 [Executor task launch worker for task 50] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 6 ms
2021-12-03 20:37:32,342 [Executor task launch worker for task 53] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 6 ms
2021-12-03 20:37:32,342 [Executor task launch worker for task 47] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 6 ms
2021-12-03 20:37:32,342 [Executor task launch worker for task 45] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 6 ms
2021-12-03 20:37:32,828 [Executor task launch worker for task 54] INFO [org.apache.spark.executor.Executor] - Finished task 10.0 in stage 2.0 (TID 54). 1055 bytes result sent to driver
2021-12-03 20:37:32,829 [Executor task launch worker for task 49] INFO [org.apache.spark.executor.Executor] - Finished task 5.0 in stage 2.0 (TID 49). 1055 bytes result sent to driver
2021-12-03 20:37:32,829 [dispatcher-event-loop-5] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 12.0 in stage 2.0 (TID 56, localhost, executor driver, partition 12, ANY, 7649 bytes)
2021-12-03 20:37:32,829 [Executor task launch worker for task 56] INFO [org.apache.spark.executor.Executor] - Running task 12.0 in stage 2.0 (TID 56)
2021-12-03 20:37:32,829 [dispatcher-event-loop-5] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 13.0 in stage 2.0 (TID 57, localhost, executor driver, partition 13, ANY, 7649 bytes)
2021-12-03 20:37:32,829 [Executor task launch worker for task 57] INFO [org.apache.spark.executor.Executor] - Running task 13.0 in stage 2.0 (TID 57)
2021-12-03 20:37:32,830 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 5.0 in stage 2.0 (TID 49) in 504 ms on localhost (executor driver) (1/22)
2021-12-03 20:37:32,830 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 10.0 in stage 2.0 (TID 54) in 504 ms on localhost (executor driver) (2/22)
2021-12-03 20:37:32,830 [Executor task launch worker for task 57] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 20:37:32,830 [Executor task launch worker for task 57] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 20:37:32,830 [Executor task launch worker for task 56] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 20:37:32,830 [Executor task launch worker for task 56] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 20:37:32,830 [Executor task launch worker for task 50] INFO [org.apache.spark.executor.Executor] - Finished task 6.0 in stage 2.0 (TID 50). 1055 bytes result sent to driver
2021-12-03 20:37:32,831 [dispatcher-event-loop-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 14.0 in stage 2.0 (TID 58, localhost, executor driver, partition 14, ANY, 7649 bytes)
2021-12-03 20:37:32,832 [Executor task launch worker for task 55] INFO [org.apache.spark.executor.Executor] - Finished task 11.0 in stage 2.0 (TID 55). 1055 bytes result sent to driver
2021-12-03 20:37:32,832 [Executor task launch worker for task 58] INFO [org.apache.spark.executor.Executor] - Running task 14.0 in stage 2.0 (TID 58)
2021-12-03 20:37:32,833 [dispatcher-event-loop-10] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 15.0 in stage 2.0 (TID 59, localhost, executor driver, partition 15, ANY, 7649 bytes)
2021-12-03 20:37:32,833 [Executor task launch worker for task 59] INFO [org.apache.spark.executor.Executor] - Running task 15.0 in stage 2.0 (TID 59)
2021-12-03 20:37:32,833 [Executor task launch worker for task 58] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 20:37:32,833 [Executor task launch worker for task 58] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 20:37:32,834 [Executor task launch worker for task 59] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 20:37:32,834 [Executor task launch worker for task 59] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 20:37:32,834 [Executor task launch worker for task 47] INFO [org.apache.spark.executor.Executor] - Finished task 3.0 in stage 2.0 (TID 47). 1055 bytes result sent to driver
2021-12-03 20:37:32,835 [dispatcher-event-loop-11] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 16.0 in stage 2.0 (TID 60, localhost, executor driver, partition 16, ANY, 7649 bytes)
2021-12-03 20:37:32,836 [Executor task launch worker for task 60] INFO [org.apache.spark.executor.Executor] - Running task 16.0 in stage 2.0 (TID 60)
2021-12-03 20:37:32,836 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 6.0 in stage 2.0 (TID 50) in 510 ms on localhost (executor driver) (3/22)
2021-12-03 20:37:32,836 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 11.0 in stage 2.0 (TID 55) in 510 ms on localhost (executor driver) (4/22)
2021-12-03 20:37:32,836 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 3.0 in stage 2.0 (TID 47) in 511 ms on localhost (executor driver) (5/22)
2021-12-03 20:37:32,838 [Executor task launch worker for task 48] INFO [org.apache.spark.executor.Executor] - Finished task 4.0 in stage 2.0 (TID 48). 1055 bytes result sent to driver
2021-12-03 20:37:32,838 [dispatcher-event-loop-8] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 17.0 in stage 2.0 (TID 61, localhost, executor driver, partition 17, ANY, 7649 bytes)
2021-12-03 20:37:32,838 [Executor task launch worker for task 61] INFO [org.apache.spark.executor.Executor] - Running task 17.0 in stage 2.0 (TID 61)
2021-12-03 20:37:32,838 [Executor task launch worker for task 53] INFO [org.apache.spark.executor.Executor] - Finished task 9.0 in stage 2.0 (TID 53). 1055 bytes result sent to driver
2021-12-03 20:37:32,839 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 4.0 in stage 2.0 (TID 48) in 512 ms on localhost (executor driver) (6/22)
2021-12-03 20:37:32,839 [dispatcher-event-loop-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 18.0 in stage 2.0 (TID 62, localhost, executor driver, partition 18, ANY, 7649 bytes)
2021-12-03 20:37:32,839 [Executor task launch worker for task 62] INFO [org.apache.spark.executor.Executor] - Running task 18.0 in stage 2.0 (TID 62)
2021-12-03 20:37:32,839 [Executor task launch worker for task 61] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 20:37:32,839 [Executor task launch worker for task 52] INFO [org.apache.spark.executor.Executor] - Finished task 8.0 in stage 2.0 (TID 52). 1055 bytes result sent to driver
2021-12-03 20:37:32,839 [Executor task launch worker for task 61] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 20:37:32,840 [Executor task launch worker for task 62] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 20:37:32,840 [Executor task launch worker for task 62] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 20:37:32,840 [dispatcher-event-loop-6] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 19.0 in stage 2.0 (TID 63, localhost, executor driver, partition 19, ANY, 7649 bytes)
2021-12-03 20:37:32,840 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 8.0 in stage 2.0 (TID 52) in 514 ms on localhost (executor driver) (7/22)
2021-12-03 20:37:32,840 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 9.0 in stage 2.0 (TID 53) in 514 ms on localhost (executor driver) (8/22)
2021-12-03 20:37:32,840 [Executor task launch worker for task 63] INFO [org.apache.spark.executor.Executor] - Running task 19.0 in stage 2.0 (TID 63)
2021-12-03 20:37:32,842 [Executor task launch worker for task 60] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 20:37:32,842 [Executor task launch worker for task 60] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 20:37:32,842 [Executor task launch worker for task 63] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 20:37:32,842 [Executor task launch worker for task 63] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 20:37:32,844 [Executor task launch worker for task 46] INFO [org.apache.spark.executor.Executor] - Finished task 2.0 in stage 2.0 (TID 46). 1055 bytes result sent to driver
2021-12-03 20:37:32,844 [Executor task launch worker for task 51] INFO [org.apache.spark.executor.Executor] - Finished task 7.0 in stage 2.0 (TID 51). 1055 bytes result sent to driver
2021-12-03 20:37:32,844 [Executor task launch worker for task 45] INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 2.0 (TID 45). 1055 bytes result sent to driver
2021-12-03 20:37:32,844 [dispatcher-event-loop-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 20.0 in stage 2.0 (TID 64, localhost, executor driver, partition 20, ANY, 7649 bytes)
2021-12-03 20:37:32,846 [Executor task launch worker for task 64] INFO [org.apache.spark.executor.Executor] - Running task 20.0 in stage 2.0 (TID 64)
2021-12-03 20:37:32,846 [dispatcher-event-loop-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 21.0 in stage 2.0 (TID 65, localhost, executor driver, partition 21, ANY, 7649 bytes)
2021-12-03 20:37:32,847 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 2.0 (TID 45) in 522 ms on localhost (executor driver) (9/22)
2021-12-03 20:37:32,847 [Executor task launch worker for task 65] INFO [org.apache.spark.executor.Executor] - Running task 21.0 in stage 2.0 (TID 65)
2021-12-03 20:37:32,847 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 2.0 in stage 2.0 (TID 46) in 522 ms on localhost (executor driver) (10/22)
2021-12-03 20:37:32,847 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 7.0 in stage 2.0 (TID 51) in 521 ms on localhost (executor driver) (11/22)
2021-12-03 20:37:32,847 [Executor task launch worker for task 64] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 20:37:32,847 [Executor task launch worker for task 64] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 20:37:32,848 [Executor task launch worker for task 65] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 20:37:32,848 [Executor task launch worker for task 65] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 20:37:32,848 [Executor task launch worker for task 44] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 2.0 (TID 44). 1055 bytes result sent to driver
2021-12-03 20:37:32,848 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 2.0 (TID 44) in 523 ms on localhost (executor driver) (12/22)
2021-12-03 20:37:32,939 [Executor task launch worker for task 58] INFO [org.apache.spark.executor.Executor] - Finished task 14.0 in stage 2.0 (TID 58). 1055 bytes result sent to driver
2021-12-03 20:37:32,939 [Executor task launch worker for task 59] INFO [org.apache.spark.executor.Executor] - Finished task 15.0 in stage 2.0 (TID 59). 1012 bytes result sent to driver
2021-12-03 20:37:32,940 [Executor task launch worker for task 56] INFO [org.apache.spark.executor.Executor] - Finished task 12.0 in stage 2.0 (TID 56). 1098 bytes result sent to driver
2021-12-03 20:37:32,940 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 14.0 in stage 2.0 (TID 58) in 109 ms on localhost (executor driver) (13/22)
2021-12-03 20:37:32,940 [Executor task launch worker for task 60] INFO [org.apache.spark.executor.Executor] - Finished task 16.0 in stage 2.0 (TID 60). 1055 bytes result sent to driver
2021-12-03 20:37:32,940 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 15.0 in stage 2.0 (TID 59) in 107 ms on localhost (executor driver) (14/22)
2021-12-03 20:37:32,941 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 12.0 in stage 2.0 (TID 56) in 111 ms on localhost (executor driver) (15/22)
2021-12-03 20:37:32,941 [Executor task launch worker for task 61] INFO [org.apache.spark.executor.Executor] - Finished task 17.0 in stage 2.0 (TID 61). 1055 bytes result sent to driver
2021-12-03 20:37:32,941 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 16.0 in stage 2.0 (TID 60) in 107 ms on localhost (executor driver) (16/22)
2021-12-03 20:37:32,941 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 17.0 in stage 2.0 (TID 61) in 103 ms on localhost (executor driver) (17/22)
2021-12-03 20:37:32,945 [Executor task launch worker for task 62] INFO [org.apache.spark.executor.Executor] - Finished task 18.0 in stage 2.0 (TID 62). 1055 bytes result sent to driver
2021-12-03 20:37:32,945 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 18.0 in stage 2.0 (TID 62) in 106 ms on localhost (executor driver) (18/22)
2021-12-03 20:37:32,949 [Executor task launch worker for task 63] INFO [org.apache.spark.executor.Executor] - Finished task 19.0 in stage 2.0 (TID 63). 1055 bytes result sent to driver
2021-12-03 20:37:32,949 [Executor task launch worker for task 57] INFO [org.apache.spark.executor.Executor] - Finished task 13.0 in stage 2.0 (TID 57). 1012 bytes result sent to driver
2021-12-03 20:37:32,950 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 19.0 in stage 2.0 (TID 63) in 110 ms on localhost (executor driver) (19/22)
2021-12-03 20:37:32,950 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 13.0 in stage 2.0 (TID 57) in 121 ms on localhost (executor driver) (20/22)
2021-12-03 20:37:32,950 [Executor task launch worker for task 65] INFO [org.apache.spark.executor.Executor] - Finished task 21.0 in stage 2.0 (TID 65). 1012 bytes result sent to driver
2021-12-03 20:37:32,950 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 21.0 in stage 2.0 (TID 65) in 105 ms on localhost (executor driver) (21/22)
2021-12-03 20:37:32,952 [Executor task launch worker for task 64] INFO [org.apache.spark.executor.Executor] - Finished task 20.0 in stage 2.0 (TID 64). 1055 bytes result sent to driver
2021-12-03 20:37:32,952 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 20.0 in stage 2.0 (TID 64) in 108 ms on localhost (executor driver) (22/22)
2021-12-03 20:37:32,952 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 2.0, whose tasks have all completed, from pool 
2021-12-03 20:37:32,952 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 2 (count at PaidPromotionAdjustParameter.scala:68) finished in 0.632 s
2021-12-03 20:37:32,953 [main] INFO [org.apache.spark.scheduler.DAGScheduler] - Job 1 finished: count at PaidPromotionAdjustParameter.scala:68, took 256.155509 s
2021-12-03 20:37:32,953 [main] INFO [PaidPromotion$] - 用户总数1207347
2021-12-03 20:37:32,971 [main] INFO [org.apache.spark.SparkContext] - Starting job: sortByKey at PaidPromotionAdjustParameter.scala:73
2021-12-03 20:37:32,972 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 2 (sortByKey at PaidPromotionAdjustParameter.scala:73) with 22 output partitions
2021-12-03 20:37:32,972 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 4 (sortByKey at PaidPromotionAdjustParameter.scala:73)
2021-12-03 20:37:32,972 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 3)
2021-12-03 20:37:32,972 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2021-12-03 20:37:32,972 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 4 (MapPartitionsRDD[7] at sortByKey at PaidPromotionAdjustParameter.scala:73), which has no missing parents
2021-12-03 20:37:32,974 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_4 stored as values in memory (estimated size 4.1 KB, free 1990.5 MB)
2021-12-03 20:37:32,977 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_4_piece0 stored as bytes in memory (estimated size 2.4 KB, free 1990.4 MB)
2021-12-03 20:37:32,977 [dispatcher-event-loop-8] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_4_piece0 in memory on qb:53199 (size: 2.4 KB, free: 1990.8 MB)
2021-12-03 20:37:32,977 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 4 from broadcast at DAGScheduler.scala:1039
2021-12-03 20:37:32,978 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 22 missing tasks from ResultStage 4 (MapPartitionsRDD[7] at sortByKey at PaidPromotionAdjustParameter.scala:73) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14))
2021-12-03 20:37:32,978 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 4.0 with 22 tasks
2021-12-03 20:37:32,978 [dispatcher-event-loop-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 4.0 (TID 66, localhost, executor driver, partition 0, ANY, 7649 bytes)
2021-12-03 20:37:32,978 [dispatcher-event-loop-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 4.0 (TID 67, localhost, executor driver, partition 1, ANY, 7649 bytes)
2021-12-03 20:37:32,978 [dispatcher-event-loop-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 2.0 in stage 4.0 (TID 68, localhost, executor driver, partition 2, ANY, 7649 bytes)
2021-12-03 20:37:32,978 [dispatcher-event-loop-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 3.0 in stage 4.0 (TID 69, localhost, executor driver, partition 3, ANY, 7649 bytes)
2021-12-03 20:37:32,978 [dispatcher-event-loop-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 4.0 in stage 4.0 (TID 70, localhost, executor driver, partition 4, ANY, 7649 bytes)
2021-12-03 20:37:32,979 [dispatcher-event-loop-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 5.0 in stage 4.0 (TID 71, localhost, executor driver, partition 5, ANY, 7649 bytes)
2021-12-03 20:37:32,979 [dispatcher-event-loop-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 6.0 in stage 4.0 (TID 72, localhost, executor driver, partition 6, ANY, 7649 bytes)
2021-12-03 20:37:32,979 [dispatcher-event-loop-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 7.0 in stage 4.0 (TID 73, localhost, executor driver, partition 7, ANY, 7649 bytes)
2021-12-03 20:37:32,979 [dispatcher-event-loop-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 8.0 in stage 4.0 (TID 74, localhost, executor driver, partition 8, ANY, 7649 bytes)
2021-12-03 20:37:32,979 [dispatcher-event-loop-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 9.0 in stage 4.0 (TID 75, localhost, executor driver, partition 9, ANY, 7649 bytes)
2021-12-03 20:37:32,979 [dispatcher-event-loop-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 10.0 in stage 4.0 (TID 76, localhost, executor driver, partition 10, ANY, 7649 bytes)
2021-12-03 20:37:32,979 [dispatcher-event-loop-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 11.0 in stage 4.0 (TID 77, localhost, executor driver, partition 11, ANY, 7649 bytes)
2021-12-03 20:37:32,979 [Executor task launch worker for task 68] INFO [org.apache.spark.executor.Executor] - Running task 2.0 in stage 4.0 (TID 68)
2021-12-03 20:37:32,979 [Executor task launch worker for task 66] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 4.0 (TID 66)
2021-12-03 20:37:32,979 [Executor task launch worker for task 73] INFO [org.apache.spark.executor.Executor] - Running task 7.0 in stage 4.0 (TID 73)
2021-12-03 20:37:32,979 [Executor task launch worker for task 69] INFO [org.apache.spark.executor.Executor] - Running task 3.0 in stage 4.0 (TID 69)
2021-12-03 20:37:32,979 [Executor task launch worker for task 71] INFO [org.apache.spark.executor.Executor] - Running task 5.0 in stage 4.0 (TID 71)
2021-12-03 20:37:32,979 [Executor task launch worker for task 70] INFO [org.apache.spark.executor.Executor] - Running task 4.0 in stage 4.0 (TID 70)
2021-12-03 20:37:32,979 [Executor task launch worker for task 67] INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 4.0 (TID 67)
2021-12-03 20:37:32,979 [Executor task launch worker for task 72] INFO [org.apache.spark.executor.Executor] - Running task 6.0 in stage 4.0 (TID 72)
2021-12-03 20:37:32,979 [Executor task launch worker for task 75] INFO [org.apache.spark.executor.Executor] - Running task 9.0 in stage 4.0 (TID 75)
2021-12-03 20:37:32,979 [Executor task launch worker for task 74] INFO [org.apache.spark.executor.Executor] - Running task 8.0 in stage 4.0 (TID 74)
2021-12-03 20:37:32,979 [Executor task launch worker for task 76] INFO [org.apache.spark.executor.Executor] - Running task 10.0 in stage 4.0 (TID 76)
2021-12-03 20:37:32,979 [Executor task launch worker for task 77] INFO [org.apache.spark.executor.Executor] - Running task 11.0 in stage 4.0 (TID 77)
2021-12-03 20:37:32,980 [Executor task launch worker for task 70] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 20:37:32,980 [Executor task launch worker for task 70] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 20:37:32,981 [Executor task launch worker for task 74] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 20:37:32,981 [Executor task launch worker for task 74] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 1 ms
2021-12-03 20:37:32,981 [Executor task launch worker for task 66] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 20:37:32,981 [Executor task launch worker for task 66] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 20:37:32,981 [Executor task launch worker for task 72] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 20:37:32,981 [Executor task launch worker for task 72] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 20:37:32,981 [Executor task launch worker for task 73] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 20:37:32,981 [Executor task launch worker for task 73] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 20:37:32,981 [Executor task launch worker for task 71] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 20:37:32,981 [Executor task launch worker for task 71] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 20:37:32,981 [Executor task launch worker for task 69] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 20:37:32,981 [Executor task launch worker for task 69] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 20:37:32,981 [Executor task launch worker for task 68] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 20:37:32,981 [Executor task launch worker for task 68] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 20:37:32,981 [Executor task launch worker for task 76] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 20:37:32,981 [Executor task launch worker for task 76] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 20:37:32,981 [Executor task launch worker for task 77] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 20:37:32,981 [Executor task launch worker for task 77] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 20:37:32,981 [Executor task launch worker for task 75] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 20:37:32,981 [Executor task launch worker for task 75] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 20:37:32,981 [Executor task launch worker for task 67] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 20:37:32,981 [Executor task launch worker for task 67] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 20:37:33,075 [dispatcher-event-loop-6] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_3_piece0 on qb:53199 in memory (size: 1906.0 B, free: 1990.8 MB)
2021-12-03 20:37:33,113 [Executor task launch worker for task 74] INFO [org.apache.spark.executor.Executor] - Finished task 8.0 in stage 4.0 (TID 74). 1187 bytes result sent to driver
2021-12-03 20:37:33,114 [Executor task launch worker for task 70] INFO [org.apache.spark.executor.Executor] - Finished task 4.0 in stage 4.0 (TID 70). 1144 bytes result sent to driver
2021-12-03 20:37:33,114 [Executor task launch worker for task 68] INFO [org.apache.spark.executor.Executor] - Finished task 2.0 in stage 4.0 (TID 68). 1189 bytes result sent to driver
2021-12-03 20:37:33,114 [Executor task launch worker for task 75] INFO [org.apache.spark.executor.Executor] - Finished task 9.0 in stage 4.0 (TID 75). 1192 bytes result sent to driver
2021-12-03 20:37:33,114 [dispatcher-event-loop-9] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 12.0 in stage 4.0 (TID 78, localhost, executor driver, partition 12, ANY, 7649 bytes)
2021-12-03 20:37:33,114 [Executor task launch worker for task 78] INFO [org.apache.spark.executor.Executor] - Running task 12.0 in stage 4.0 (TID 78)
2021-12-03 20:37:33,114 [dispatcher-event-loop-9] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 13.0 in stage 4.0 (TID 79, localhost, executor driver, partition 13, ANY, 7649 bytes)
2021-12-03 20:37:33,114 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 8.0 in stage 4.0 (TID 74) in 135 ms on localhost (executor driver) (1/22)
2021-12-03 20:37:33,114 [Executor task launch worker for task 79] INFO [org.apache.spark.executor.Executor] - Running task 13.0 in stage 4.0 (TID 79)
2021-12-03 20:37:33,114 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 4.0 in stage 4.0 (TID 70) in 136 ms on localhost (executor driver) (2/22)
2021-12-03 20:37:33,114 [dispatcher-event-loop-9] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 14.0 in stage 4.0 (TID 80, localhost, executor driver, partition 14, ANY, 7649 bytes)
2021-12-03 20:37:33,114 [Executor task launch worker for task 80] INFO [org.apache.spark.executor.Executor] - Running task 14.0 in stage 4.0 (TID 80)
2021-12-03 20:37:33,114 [dispatcher-event-loop-9] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 15.0 in stage 4.0 (TID 81, localhost, executor driver, partition 15, ANY, 7649 bytes)
2021-12-03 20:37:33,115 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 9.0 in stage 4.0 (TID 75) in 136 ms on localhost (executor driver) (3/22)
2021-12-03 20:37:33,115 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 2.0 in stage 4.0 (TID 68) in 137 ms on localhost (executor driver) (4/22)
2021-12-03 20:37:33,115 [Executor task launch worker for task 78] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 20:37:33,115 [Executor task launch worker for task 81] INFO [org.apache.spark.executor.Executor] - Running task 15.0 in stage 4.0 (TID 81)
2021-12-03 20:37:33,115 [Executor task launch worker for task 78] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 20:37:33,115 [Executor task launch worker for task 79] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 20:37:33,115 [Executor task launch worker for task 79] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 20:37:33,115 [Executor task launch worker for task 80] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 20:37:33,115 [Executor task launch worker for task 80] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 20:37:33,116 [Executor task launch worker for task 81] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 20:37:33,116 [Executor task launch worker for task 81] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 20:37:33,117 [Executor task launch worker for task 76] INFO [org.apache.spark.executor.Executor] - Finished task 10.0 in stage 4.0 (TID 76). 1187 bytes result sent to driver
2021-12-03 20:37:33,117 [dispatcher-event-loop-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 16.0 in stage 4.0 (TID 82, localhost, executor driver, partition 16, ANY, 7649 bytes)
2021-12-03 20:37:33,118 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 10.0 in stage 4.0 (TID 76) in 139 ms on localhost (executor driver) (5/22)
2021-12-03 20:37:33,118 [Executor task launch worker for task 82] INFO [org.apache.spark.executor.Executor] - Running task 16.0 in stage 4.0 (TID 82)
2021-12-03 20:37:33,119 [Executor task launch worker for task 82] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 20:37:33,119 [Executor task launch worker for task 82] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 20:37:33,120 [Executor task launch worker for task 69] INFO [org.apache.spark.executor.Executor] - Finished task 3.0 in stage 4.0 (TID 69). 1184 bytes result sent to driver
2021-12-03 20:37:33,120 [dispatcher-event-loop-5] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 17.0 in stage 4.0 (TID 83, localhost, executor driver, partition 17, ANY, 7649 bytes)
2021-12-03 20:37:33,121 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 3.0 in stage 4.0 (TID 69) in 143 ms on localhost (executor driver) (6/22)
2021-12-03 20:37:33,121 [Executor task launch worker for task 83] INFO [org.apache.spark.executor.Executor] - Running task 17.0 in stage 4.0 (TID 83)
2021-12-03 20:37:33,122 [Executor task launch worker for task 83] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 20:37:33,122 [Executor task launch worker for task 83] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 20:37:33,122 [Executor task launch worker for task 77] INFO [org.apache.spark.executor.Executor] - Finished task 11.0 in stage 4.0 (TID 77). 1185 bytes result sent to driver
2021-12-03 20:37:33,122 [dispatcher-event-loop-10] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 18.0 in stage 4.0 (TID 84, localhost, executor driver, partition 18, ANY, 7649 bytes)
2021-12-03 20:37:33,122 [Executor task launch worker for task 84] INFO [org.apache.spark.executor.Executor] - Running task 18.0 in stage 4.0 (TID 84)
2021-12-03 20:37:33,122 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 11.0 in stage 4.0 (TID 77) in 143 ms on localhost (executor driver) (7/22)
2021-12-03 20:37:33,123 [Executor task launch worker for task 67] INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 4.0 (TID 67). 1183 bytes result sent to driver
2021-12-03 20:37:33,124 [Executor task launch worker for task 84] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 20:37:33,124 [Executor task launch worker for task 84] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 20:37:33,124 [dispatcher-event-loop-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 19.0 in stage 4.0 (TID 85, localhost, executor driver, partition 19, ANY, 7649 bytes)
2021-12-03 20:37:33,125 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 4.0 (TID 67) in 147 ms on localhost (executor driver) (8/22)
2021-12-03 20:37:33,125 [Executor task launch worker for task 85] INFO [org.apache.spark.executor.Executor] - Running task 19.0 in stage 4.0 (TID 85)
2021-12-03 20:37:33,126 [Executor task launch worker for task 85] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 20:37:33,126 [Executor task launch worker for task 85] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 20:37:33,128 [Executor task launch worker for task 66] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 4.0 (TID 66). 1145 bytes result sent to driver
2021-12-03 20:37:33,129 [dispatcher-event-loop-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 20.0 in stage 4.0 (TID 86, localhost, executor driver, partition 20, ANY, 7649 bytes)
2021-12-03 20:37:33,129 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 4.0 (TID 66) in 151 ms on localhost (executor driver) (9/22)
2021-12-03 20:37:33,130 [Executor task launch worker for task 73] INFO [org.apache.spark.executor.Executor] - Finished task 7.0 in stage 4.0 (TID 73). 1143 bytes result sent to driver
2021-12-03 20:37:33,130 [Executor task launch worker for task 86] INFO [org.apache.spark.executor.Executor] - Running task 20.0 in stage 4.0 (TID 86)
2021-12-03 20:37:33,131 [Executor task launch worker for task 86] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 20:37:33,131 [Executor task launch worker for task 86] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 20:37:33,132 [dispatcher-event-loop-4] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 21.0 in stage 4.0 (TID 87, localhost, executor driver, partition 21, ANY, 7649 bytes)
2021-12-03 20:37:33,132 [Executor task launch worker for task 87] INFO [org.apache.spark.executor.Executor] - Running task 21.0 in stage 4.0 (TID 87)
2021-12-03 20:37:33,132 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 7.0 in stage 4.0 (TID 73) in 153 ms on localhost (executor driver) (10/22)
2021-12-03 20:37:33,133 [Executor task launch worker for task 87] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 20:37:33,133 [Executor task launch worker for task 87] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 20:37:33,139 [Executor task launch worker for task 72] INFO [org.apache.spark.executor.Executor] - Finished task 6.0 in stage 4.0 (TID 72). 1181 bytes result sent to driver
2021-12-03 20:37:33,140 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 6.0 in stage 4.0 (TID 72) in 160 ms on localhost (executor driver) (11/22)
2021-12-03 20:37:33,144 [Executor task launch worker for task 71] INFO [org.apache.spark.executor.Executor] - Finished task 5.0 in stage 4.0 (TID 71). 1146 bytes result sent to driver
2021-12-03 20:37:33,145 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 5.0 in stage 4.0 (TID 71) in 167 ms on localhost (executor driver) (12/22)
2021-12-03 20:37:33,201 [Executor task launch worker for task 81] INFO [org.apache.spark.executor.Executor] - Finished task 15.0 in stage 4.0 (TID 81). 1094 bytes result sent to driver
2021-12-03 20:37:33,201 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 15.0 in stage 4.0 (TID 81) in 87 ms on localhost (executor driver) (13/22)
2021-12-03 20:37:33,205 [Executor task launch worker for task 80] INFO [org.apache.spark.executor.Executor] - Finished task 14.0 in stage 4.0 (TID 80). 1099 bytes result sent to driver
2021-12-03 20:37:33,205 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 14.0 in stage 4.0 (TID 80) in 91 ms on localhost (executor driver) (14/22)
2021-12-03 20:37:33,208 [Executor task launch worker for task 78] INFO [org.apache.spark.executor.Executor] - Finished task 12.0 in stage 4.0 (TID 78). 1099 bytes result sent to driver
2021-12-03 20:37:33,208 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 12.0 in stage 4.0 (TID 78) in 95 ms on localhost (executor driver) (15/22)
2021-12-03 20:37:33,218 [Executor task launch worker for task 83] INFO [org.apache.spark.executor.Executor] - Finished task 17.0 in stage 4.0 (TID 83). 1142 bytes result sent to driver
2021-12-03 20:37:33,219 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 17.0 in stage 4.0 (TID 83) in 99 ms on localhost (executor driver) (16/22)
2021-12-03 20:37:33,224 [Executor task launch worker for task 87] INFO [org.apache.spark.executor.Executor] - Finished task 21.0 in stage 4.0 (TID 87). 1144 bytes result sent to driver
2021-12-03 20:37:33,224 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 21.0 in stage 4.0 (TID 87) in 93 ms on localhost (executor driver) (17/22)
2021-12-03 20:37:33,225 [Executor task launch worker for task 86] INFO [org.apache.spark.executor.Executor] - Finished task 20.0 in stage 4.0 (TID 86). 1103 bytes result sent to driver
2021-12-03 20:37:33,225 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 20.0 in stage 4.0 (TID 86) in 96 ms on localhost (executor driver) (18/22)
2021-12-03 20:37:33,225 [Executor task launch worker for task 82] INFO [org.apache.spark.executor.Executor] - Finished task 16.0 in stage 4.0 (TID 82). 1100 bytes result sent to driver
2021-12-03 20:37:33,226 [Executor task launch worker for task 84] INFO [org.apache.spark.executor.Executor] - Finished task 18.0 in stage 4.0 (TID 84). 1137 bytes result sent to driver
2021-12-03 20:37:33,226 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 16.0 in stage 4.0 (TID 82) in 109 ms on localhost (executor driver) (19/22)
2021-12-03 20:37:33,226 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 18.0 in stage 4.0 (TID 84) in 104 ms on localhost (executor driver) (20/22)
2021-12-03 20:37:33,229 [Executor task launch worker for task 85] INFO [org.apache.spark.executor.Executor] - Finished task 19.0 in stage 4.0 (TID 85). 1146 bytes result sent to driver
2021-12-03 20:37:33,230 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 19.0 in stage 4.0 (TID 85) in 106 ms on localhost (executor driver) (21/22)
2021-12-03 20:37:33,233 [Executor task launch worker for task 79] INFO [org.apache.spark.executor.Executor] - Finished task 13.0 in stage 4.0 (TID 79). 1141 bytes result sent to driver
2021-12-03 20:37:33,233 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 13.0 in stage 4.0 (TID 79) in 119 ms on localhost (executor driver) (22/22)
2021-12-03 20:37:33,233 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 4.0, whose tasks have all completed, from pool 
2021-12-03 20:37:33,234 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 4 (sortByKey at PaidPromotionAdjustParameter.scala:73) finished in 0.259 s
2021-12-03 20:37:33,234 [main] INFO [org.apache.spark.scheduler.DAGScheduler] - Job 2 finished: sortByKey at PaidPromotionAdjustParameter.scala:73, took 0.262882 s
2021-12-03 20:37:33,249 [main] INFO [org.apache.spark.SparkContext] - Starting job: zipWithIndex at PaidPromotionAdjustParameter.scala:74
2021-12-03 20:37:33,250 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 5 (map at PaidPromotionAdjustParameter.scala:72)
2021-12-03 20:37:33,250 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 3 (zipWithIndex at PaidPromotionAdjustParameter.scala:74) with 21 output partitions
2021-12-03 20:37:33,250 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 7 (zipWithIndex at PaidPromotionAdjustParameter.scala:74)
2021-12-03 20:37:33,250 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 6)
2021-12-03 20:37:33,250 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List(ShuffleMapStage 6)
2021-12-03 20:37:33,250 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ShuffleMapStage 6 (MapPartitionsRDD[5] at map at PaidPromotionAdjustParameter.scala:72), which has no missing parents
2021-12-03 20:37:33,256 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_5 stored as values in memory (estimated size 4.1 KB, free 1990.5 MB)
2021-12-03 20:37:33,258 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_5_piece0 stored as bytes in memory (estimated size 2.4 KB, free 1990.4 MB)
2021-12-03 20:37:33,258 [dispatcher-event-loop-3] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_5_piece0 in memory on qb:53199 (size: 2.4 KB, free: 1990.8 MB)
2021-12-03 20:37:33,259 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 5 from broadcast at DAGScheduler.scala:1039
2021-12-03 20:37:33,259 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 22 missing tasks from ShuffleMapStage 6 (MapPartitionsRDD[5] at map at PaidPromotionAdjustParameter.scala:72) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14))
2021-12-03 20:37:33,259 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 6.0 with 22 tasks
2021-12-03 20:37:33,259 [dispatcher-event-loop-7] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 6.0 (TID 88, localhost, executor driver, partition 0, ANY, 7638 bytes)
2021-12-03 20:37:33,260 [dispatcher-event-loop-7] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 6.0 (TID 89, localhost, executor driver, partition 1, ANY, 7638 bytes)
2021-12-03 20:37:33,260 [dispatcher-event-loop-7] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 2.0 in stage 6.0 (TID 90, localhost, executor driver, partition 2, ANY, 7638 bytes)
2021-12-03 20:37:33,260 [dispatcher-event-loop-7] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 3.0 in stage 6.0 (TID 91, localhost, executor driver, partition 3, ANY, 7638 bytes)
2021-12-03 20:37:33,260 [dispatcher-event-loop-7] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 4.0 in stage 6.0 (TID 92, localhost, executor driver, partition 4, ANY, 7638 bytes)
2021-12-03 20:37:33,260 [dispatcher-event-loop-7] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 5.0 in stage 6.0 (TID 93, localhost, executor driver, partition 5, ANY, 7638 bytes)
2021-12-03 20:37:33,260 [dispatcher-event-loop-7] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 6.0 in stage 6.0 (TID 94, localhost, executor driver, partition 6, ANY, 7638 bytes)
2021-12-03 20:37:33,260 [dispatcher-event-loop-7] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 7.0 in stage 6.0 (TID 95, localhost, executor driver, partition 7, ANY, 7638 bytes)
2021-12-03 20:37:33,260 [dispatcher-event-loop-7] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 8.0 in stage 6.0 (TID 96, localhost, executor driver, partition 8, ANY, 7638 bytes)
2021-12-03 20:37:33,260 [dispatcher-event-loop-7] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 9.0 in stage 6.0 (TID 97, localhost, executor driver, partition 9, ANY, 7638 bytes)
2021-12-03 20:37:33,260 [dispatcher-event-loop-7] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 10.0 in stage 6.0 (TID 98, localhost, executor driver, partition 10, ANY, 7638 bytes)
2021-12-03 20:37:33,260 [dispatcher-event-loop-7] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 11.0 in stage 6.0 (TID 99, localhost, executor driver, partition 11, ANY, 7638 bytes)
2021-12-03 20:37:33,260 [Executor task launch worker for task 88] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 6.0 (TID 88)
2021-12-03 20:37:33,260 [Executor task launch worker for task 93] INFO [org.apache.spark.executor.Executor] - Running task 5.0 in stage 6.0 (TID 93)
2021-12-03 20:37:33,260 [Executor task launch worker for task 98] INFO [org.apache.spark.executor.Executor] - Running task 10.0 in stage 6.0 (TID 98)
2021-12-03 20:37:33,260 [Executor task launch worker for task 99] INFO [org.apache.spark.executor.Executor] - Running task 11.0 in stage 6.0 (TID 99)
2021-12-03 20:37:33,260 [Executor task launch worker for task 91] INFO [org.apache.spark.executor.Executor] - Running task 3.0 in stage 6.0 (TID 91)
2021-12-03 20:37:33,260 [Executor task launch worker for task 94] INFO [org.apache.spark.executor.Executor] - Running task 6.0 in stage 6.0 (TID 94)
2021-12-03 20:37:33,260 [Executor task launch worker for task 90] INFO [org.apache.spark.executor.Executor] - Running task 2.0 in stage 6.0 (TID 90)
2021-12-03 20:37:33,260 [Executor task launch worker for task 92] INFO [org.apache.spark.executor.Executor] - Running task 4.0 in stage 6.0 (TID 92)
2021-12-03 20:37:33,260 [Executor task launch worker for task 89] INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 6.0 (TID 89)
2021-12-03 20:37:33,261 [Executor task launch worker for task 96] INFO [org.apache.spark.executor.Executor] - Running task 8.0 in stage 6.0 (TID 96)
2021-12-03 20:37:33,261 [Executor task launch worker for task 97] INFO [org.apache.spark.executor.Executor] - Running task 9.0 in stage 6.0 (TID 97)
2021-12-03 20:37:33,261 [Executor task launch worker for task 95] INFO [org.apache.spark.executor.Executor] - Running task 7.0 in stage 6.0 (TID 95)
2021-12-03 20:37:33,268 [Executor task launch worker for task 98] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 20:37:33,268 [Executor task launch worker for task 96] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 20:37:33,268 [Executor task launch worker for task 91] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 20:37:33,268 [Executor task launch worker for task 96] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 20:37:33,269 [Executor task launch worker for task 91] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 1 ms
2021-12-03 20:37:33,269 [Executor task launch worker for task 92] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 20:37:33,268 [Executor task launch worker for task 89] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 20:37:33,268 [Executor task launch worker for task 98] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 20:37:33,268 [Executor task launch worker for task 97] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 20:37:33,269 [Executor task launch worker for task 97] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 1 ms
2021-12-03 20:37:33,269 [Executor task launch worker for task 94] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 20:37:33,269 [Executor task launch worker for task 89] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 1 ms
2021-12-03 20:37:33,269 [Executor task launch worker for task 92] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 20:37:33,269 [Executor task launch worker for task 95] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 20:37:33,269 [Executor task launch worker for task 90] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 20:37:33,269 [Executor task launch worker for task 95] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 20:37:33,269 [Executor task launch worker for task 90] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 1 ms
2021-12-03 20:37:33,269 [Executor task launch worker for task 99] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 20:37:33,269 [Executor task launch worker for task 99] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 20:37:33,269 [Executor task launch worker for task 94] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 20:37:33,269 [Executor task launch worker for task 93] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 20:37:33,269 [Executor task launch worker for task 93] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 20:37:33,269 [Executor task launch worker for task 88] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 20:37:33,269 [Executor task launch worker for task 88] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 20:37:33,460 [dispatcher-event-loop-5] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_4_piece0 on qb:53199 in memory (size: 2.4 KB, free: 1990.8 MB)
2021-12-03 20:37:33,765 [Executor task launch worker for task 97] INFO [org.apache.spark.executor.Executor] - Finished task 9.0 in stage 6.0 (TID 97). 1310 bytes result sent to driver
2021-12-03 20:37:33,767 [dispatcher-event-loop-11] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 12.0 in stage 6.0 (TID 100, localhost, executor driver, partition 12, ANY, 7638 bytes)
2021-12-03 20:37:33,767 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 9.0 in stage 6.0 (TID 97) in 507 ms on localhost (executor driver) (1/22)
2021-12-03 20:37:33,767 [Executor task launch worker for task 100] INFO [org.apache.spark.executor.Executor] - Running task 12.0 in stage 6.0 (TID 100)
2021-12-03 20:37:33,771 [Executor task launch worker for task 100] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 20:37:33,771 [Executor task launch worker for task 100] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 20:37:33,777 [Executor task launch worker for task 92] INFO [org.apache.spark.executor.Executor] - Finished task 4.0 in stage 6.0 (TID 92). 1267 bytes result sent to driver
2021-12-03 20:37:33,777 [dispatcher-event-loop-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 13.0 in stage 6.0 (TID 101, localhost, executor driver, partition 13, ANY, 7638 bytes)
2021-12-03 20:37:33,777 [Executor task launch worker for task 101] INFO [org.apache.spark.executor.Executor] - Running task 13.0 in stage 6.0 (TID 101)
2021-12-03 20:37:33,777 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 4.0 in stage 6.0 (TID 92) in 517 ms on localhost (executor driver) (2/22)
2021-12-03 20:37:33,780 [Executor task launch worker for task 101] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 20:37:33,780 [Executor task launch worker for task 101] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 20:37:33,785 [Executor task launch worker for task 96] INFO [org.apache.spark.executor.Executor] - Finished task 8.0 in stage 6.0 (TID 96). 1310 bytes result sent to driver
2021-12-03 20:37:33,787 [dispatcher-event-loop-4] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 14.0 in stage 6.0 (TID 102, localhost, executor driver, partition 14, ANY, 7638 bytes)
2021-12-03 20:37:33,787 [Executor task launch worker for task 102] INFO [org.apache.spark.executor.Executor] - Running task 14.0 in stage 6.0 (TID 102)
2021-12-03 20:37:33,788 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 8.0 in stage 6.0 (TID 96) in 528 ms on localhost (executor driver) (3/22)
2021-12-03 20:37:33,790 [Executor task launch worker for task 102] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 20:37:33,790 [Executor task launch worker for task 102] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 20:37:33,792 [Executor task launch worker for task 99] INFO [org.apache.spark.executor.Executor] - Finished task 11.0 in stage 6.0 (TID 99). 1267 bytes result sent to driver
2021-12-03 20:37:33,793 [dispatcher-event-loop-8] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 15.0 in stage 6.0 (TID 103, localhost, executor driver, partition 15, ANY, 7638 bytes)
2021-12-03 20:37:33,793 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 11.0 in stage 6.0 (TID 99) in 533 ms on localhost (executor driver) (4/22)
2021-12-03 20:37:33,793 [Executor task launch worker for task 103] INFO [org.apache.spark.executor.Executor] - Running task 15.0 in stage 6.0 (TID 103)
2021-12-03 20:37:33,795 [Executor task launch worker for task 95] INFO [org.apache.spark.executor.Executor] - Finished task 7.0 in stage 6.0 (TID 95). 1267 bytes result sent to driver
2021-12-03 20:37:33,796 [dispatcher-event-loop-7] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 16.0 in stage 6.0 (TID 104, localhost, executor driver, partition 16, ANY, 7638 bytes)
2021-12-03 20:37:33,796 [Executor task launch worker for task 104] INFO [org.apache.spark.executor.Executor] - Running task 16.0 in stage 6.0 (TID 104)
2021-12-03 20:37:33,796 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 7.0 in stage 6.0 (TID 95) in 536 ms on localhost (executor driver) (5/22)
2021-12-03 20:37:33,800 [Executor task launch worker for task 103] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 20:37:33,800 [Executor task launch worker for task 104] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 20:37:33,800 [Executor task launch worker for task 104] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 20:37:33,800 [Executor task launch worker for task 103] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 20:37:33,801 [Executor task launch worker for task 94] INFO [org.apache.spark.executor.Executor] - Finished task 6.0 in stage 6.0 (TID 94). 1267 bytes result sent to driver
2021-12-03 20:37:33,801 [dispatcher-event-loop-6] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 17.0 in stage 6.0 (TID 105, localhost, executor driver, partition 17, ANY, 7638 bytes)
2021-12-03 20:37:33,802 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 6.0 in stage 6.0 (TID 94) in 542 ms on localhost (executor driver) (6/22)
2021-12-03 20:37:33,802 [Executor task launch worker for task 88] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 6.0 (TID 88). 1267 bytes result sent to driver
2021-12-03 20:37:33,802 [Executor task launch worker for task 93] INFO [org.apache.spark.executor.Executor] - Finished task 5.0 in stage 6.0 (TID 93). 1267 bytes result sent to driver
2021-12-03 20:37:33,802 [Executor task launch worker for task 105] INFO [org.apache.spark.executor.Executor] - Running task 17.0 in stage 6.0 (TID 105)
2021-12-03 20:37:33,804 [dispatcher-event-loop-5] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 18.0 in stage 6.0 (TID 106, localhost, executor driver, partition 18, ANY, 7638 bytes)
2021-12-03 20:37:33,804 [Executor task launch worker for task 106] INFO [org.apache.spark.executor.Executor] - Running task 18.0 in stage 6.0 (TID 106)
2021-12-03 20:37:33,805 [dispatcher-event-loop-5] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 19.0 in stage 6.0 (TID 107, localhost, executor driver, partition 19, ANY, 7638 bytes)
2021-12-03 20:37:33,805 [Executor task launch worker for task 105] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 20:37:33,806 [Executor task launch worker for task 105] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 1 ms
2021-12-03 20:37:33,807 [Executor task launch worker for task 107] INFO [org.apache.spark.executor.Executor] - Running task 19.0 in stage 6.0 (TID 107)
2021-12-03 20:37:33,808 [Executor task launch worker for task 106] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 20:37:33,808 [Executor task launch worker for task 106] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 20:37:33,808 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 5.0 in stage 6.0 (TID 93) in 548 ms on localhost (executor driver) (7/22)
2021-12-03 20:37:33,810 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 6.0 (TID 88) in 551 ms on localhost (executor driver) (8/22)
2021-12-03 20:37:33,814 [Executor task launch worker for task 107] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 20:37:33,814 [Executor task launch worker for task 107] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 20:37:33,835 [Executor task launch worker for task 89] INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 6.0 (TID 89). 1267 bytes result sent to driver
2021-12-03 20:37:33,836 [dispatcher-event-loop-4] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 20.0 in stage 6.0 (TID 108, localhost, executor driver, partition 20, ANY, 7638 bytes)
2021-12-03 20:37:33,836 [Executor task launch worker for task 108] INFO [org.apache.spark.executor.Executor] - Running task 20.0 in stage 6.0 (TID 108)
2021-12-03 20:37:33,839 [Executor task launch worker for task 108] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 20:37:33,840 [Executor task launch worker for task 108] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 1 ms
2021-12-03 20:37:33,840 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 6.0 (TID 89) in 581 ms on localhost (executor driver) (9/22)
2021-12-03 20:37:33,870 [Executor task launch worker for task 90] INFO [org.apache.spark.executor.Executor] - Finished task 2.0 in stage 6.0 (TID 90). 1267 bytes result sent to driver
2021-12-03 20:37:33,870 [dispatcher-event-loop-8] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 21.0 in stage 6.0 (TID 109, localhost, executor driver, partition 21, ANY, 7638 bytes)
2021-12-03 20:37:33,871 [Executor task launch worker for task 109] INFO [org.apache.spark.executor.Executor] - Running task 21.0 in stage 6.0 (TID 109)
2021-12-03 20:37:33,871 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 2.0 in stage 6.0 (TID 90) in 611 ms on localhost (executor driver) (10/22)
2021-12-03 20:37:33,874 [Executor task launch worker for task 109] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 20:37:33,874 [Executor task launch worker for task 109] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 20:37:33,882 [Executor task launch worker for task 98] INFO [org.apache.spark.executor.Executor] - Finished task 10.0 in stage 6.0 (TID 98). 1267 bytes result sent to driver
2021-12-03 20:37:33,885 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 10.0 in stage 6.0 (TID 98) in 625 ms on localhost (executor driver) (11/22)
2021-12-03 20:37:33,925 [Executor task launch worker for task 91] INFO [org.apache.spark.executor.Executor] - Finished task 3.0 in stage 6.0 (TID 91). 1267 bytes result sent to driver
2021-12-03 20:37:33,925 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 3.0 in stage 6.0 (TID 91) in 665 ms on localhost (executor driver) (12/22)
2021-12-03 20:37:34,175 [Executor task launch worker for task 100] INFO [org.apache.spark.executor.Executor] - Finished task 12.0 in stage 6.0 (TID 100). 1267 bytes result sent to driver
2021-12-03 20:37:34,176 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 12.0 in stage 6.0 (TID 100) in 410 ms on localhost (executor driver) (13/22)
2021-12-03 20:37:34,181 [Executor task launch worker for task 101] INFO [org.apache.spark.executor.Executor] - Finished task 13.0 in stage 6.0 (TID 101). 1224 bytes result sent to driver
2021-12-03 20:37:34,181 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 13.0 in stage 6.0 (TID 101) in 404 ms on localhost (executor driver) (14/22)
2021-12-03 20:37:34,197 [Executor task launch worker for task 106] INFO [org.apache.spark.executor.Executor] - Finished task 18.0 in stage 6.0 (TID 106). 1224 bytes result sent to driver
2021-12-03 20:37:34,197 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 18.0 in stage 6.0 (TID 106) in 393 ms on localhost (executor driver) (15/22)
2021-12-03 20:37:34,209 [Executor task launch worker for task 103] INFO [org.apache.spark.executor.Executor] - Finished task 15.0 in stage 6.0 (TID 103). 1267 bytes result sent to driver
2021-12-03 20:37:34,210 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 15.0 in stage 6.0 (TID 103) in 417 ms on localhost (executor driver) (16/22)
2021-12-03 20:37:34,211 [Executor task launch worker for task 104] INFO [org.apache.spark.executor.Executor] - Finished task 16.0 in stage 6.0 (TID 104). 1267 bytes result sent to driver
2021-12-03 20:37:34,212 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 16.0 in stage 6.0 (TID 104) in 416 ms on localhost (executor driver) (17/22)
2021-12-03 20:37:34,223 [Executor task launch worker for task 105] INFO [org.apache.spark.executor.Executor] - Finished task 17.0 in stage 6.0 (TID 105). 1224 bytes result sent to driver
2021-12-03 20:37:34,224 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 17.0 in stage 6.0 (TID 105) in 423 ms on localhost (executor driver) (18/22)
2021-12-03 20:37:34,224 [Executor task launch worker for task 102] INFO [org.apache.spark.executor.Executor] - Finished task 14.0 in stage 6.0 (TID 102). 1224 bytes result sent to driver
2021-12-03 20:37:34,225 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 14.0 in stage 6.0 (TID 102) in 438 ms on localhost (executor driver) (19/22)
2021-12-03 20:37:34,226 [Executor task launch worker for task 108] INFO [org.apache.spark.executor.Executor] - Finished task 20.0 in stage 6.0 (TID 108). 1224 bytes result sent to driver
2021-12-03 20:37:34,226 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 20.0 in stage 6.0 (TID 108) in 390 ms on localhost (executor driver) (20/22)
2021-12-03 20:37:34,269 [Executor task launch worker for task 109] INFO [org.apache.spark.executor.Executor] - Finished task 21.0 in stage 6.0 (TID 109). 1224 bytes result sent to driver
2021-12-03 20:37:34,270 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 21.0 in stage 6.0 (TID 109) in 400 ms on localhost (executor driver) (21/22)
2021-12-03 20:37:34,296 [Executor task launch worker for task 107] INFO [org.apache.spark.executor.Executor] - Finished task 19.0 in stage 6.0 (TID 107). 1224 bytes result sent to driver
2021-12-03 20:37:34,297 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 19.0 in stage 6.0 (TID 107) in 493 ms on localhost (executor driver) (22/22)
2021-12-03 20:37:34,297 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 6.0, whose tasks have all completed, from pool 
2021-12-03 20:37:34,297 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ShuffleMapStage 6 (map at PaidPromotionAdjustParameter.scala:72) finished in 1.046 s
2021-12-03 20:37:34,297 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - looking for newly runnable stages
2021-12-03 20:37:34,297 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - running: Set()
2021-12-03 20:37:34,297 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - waiting: Set(ResultStage 7)
2021-12-03 20:37:34,297 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - failed: Set()
2021-12-03 20:37:34,297 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 7 (ShuffledRDD[8] at sortByKey at PaidPromotionAdjustParameter.scala:73), which has no missing parents
2021-12-03 20:37:34,299 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_6 stored as values in memory (estimated size 3.4 KB, free 1990.5 MB)
2021-12-03 20:37:34,301 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_6_piece0 stored as bytes in memory (estimated size 2.0 KB, free 1990.4 MB)
2021-12-03 20:37:34,301 [dispatcher-event-loop-7] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_6_piece0 in memory on qb:53199 (size: 2.0 KB, free: 1990.8 MB)
2021-12-03 20:37:34,301 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 6 from broadcast at DAGScheduler.scala:1039
2021-12-03 20:37:34,301 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 21 missing tasks from ResultStage 7 (ShuffledRDD[8] at sortByKey at PaidPromotionAdjustParameter.scala:73) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14))
2021-12-03 20:37:34,301 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 7.0 with 21 tasks
2021-12-03 20:37:34,302 [dispatcher-event-loop-10] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 7.0 (TID 110, localhost, executor driver, partition 0, ANY, 7649 bytes)
2021-12-03 20:37:34,302 [dispatcher-event-loop-10] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 7.0 (TID 111, localhost, executor driver, partition 1, ANY, 7649 bytes)
2021-12-03 20:37:34,302 [dispatcher-event-loop-10] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 2.0 in stage 7.0 (TID 112, localhost, executor driver, partition 2, ANY, 7649 bytes)
2021-12-03 20:37:34,302 [dispatcher-event-loop-10] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 3.0 in stage 7.0 (TID 113, localhost, executor driver, partition 3, ANY, 7649 bytes)
2021-12-03 20:37:34,302 [dispatcher-event-loop-10] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 4.0 in stage 7.0 (TID 114, localhost, executor driver, partition 4, ANY, 7649 bytes)
2021-12-03 20:37:34,302 [dispatcher-event-loop-10] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 5.0 in stage 7.0 (TID 115, localhost, executor driver, partition 5, ANY, 7649 bytes)
2021-12-03 20:37:34,302 [dispatcher-event-loop-10] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 6.0 in stage 7.0 (TID 116, localhost, executor driver, partition 6, ANY, 7649 bytes)
2021-12-03 20:37:34,302 [dispatcher-event-loop-10] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 7.0 in stage 7.0 (TID 117, localhost, executor driver, partition 7, ANY, 7649 bytes)
2021-12-03 20:37:34,303 [dispatcher-event-loop-10] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 8.0 in stage 7.0 (TID 118, localhost, executor driver, partition 8, ANY, 7649 bytes)
2021-12-03 20:37:34,303 [dispatcher-event-loop-10] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 9.0 in stage 7.0 (TID 119, localhost, executor driver, partition 9, ANY, 7649 bytes)
2021-12-03 20:37:34,303 [dispatcher-event-loop-10] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 10.0 in stage 7.0 (TID 120, localhost, executor driver, partition 10, ANY, 7649 bytes)
2021-12-03 20:37:34,303 [dispatcher-event-loop-10] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 11.0 in stage 7.0 (TID 121, localhost, executor driver, partition 11, ANY, 7649 bytes)
2021-12-03 20:37:34,303 [Executor task launch worker for task 111] INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 7.0 (TID 111)
2021-12-03 20:37:34,303 [Executor task launch worker for task 117] INFO [org.apache.spark.executor.Executor] - Running task 7.0 in stage 7.0 (TID 117)
2021-12-03 20:37:34,303 [Executor task launch worker for task 121] INFO [org.apache.spark.executor.Executor] - Running task 11.0 in stage 7.0 (TID 121)
2021-12-03 20:37:34,303 [Executor task launch worker for task 120] INFO [org.apache.spark.executor.Executor] - Running task 10.0 in stage 7.0 (TID 120)
2021-12-03 20:37:34,303 [Executor task launch worker for task 119] INFO [org.apache.spark.executor.Executor] - Running task 9.0 in stage 7.0 (TID 119)
2021-12-03 20:37:34,303 [Executor task launch worker for task 118] INFO [org.apache.spark.executor.Executor] - Running task 8.0 in stage 7.0 (TID 118)
2021-12-03 20:37:34,303 [Executor task launch worker for task 116] INFO [org.apache.spark.executor.Executor] - Running task 6.0 in stage 7.0 (TID 116)
2021-12-03 20:37:34,303 [Executor task launch worker for task 115] INFO [org.apache.spark.executor.Executor] - Running task 5.0 in stage 7.0 (TID 115)
2021-12-03 20:37:34,303 [Executor task launch worker for task 114] INFO [org.apache.spark.executor.Executor] - Running task 4.0 in stage 7.0 (TID 114)
2021-12-03 20:37:34,303 [Executor task launch worker for task 112] INFO [org.apache.spark.executor.Executor] - Running task 2.0 in stage 7.0 (TID 112)
2021-12-03 20:37:34,303 [Executor task launch worker for task 110] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 7.0 (TID 110)
2021-12-03 20:37:34,303 [Executor task launch worker for task 113] INFO [org.apache.spark.executor.Executor] - Running task 3.0 in stage 7.0 (TID 113)
2021-12-03 20:37:34,306 [Executor task launch worker for task 112] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 20:37:34,306 [Executor task launch worker for task 112] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 20:37:34,306 [Executor task launch worker for task 119] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 20:37:34,306 [Executor task launch worker for task 119] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 20:37:34,306 [Executor task launch worker for task 115] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 20:37:34,306 [Executor task launch worker for task 115] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 20:37:34,306 [Executor task launch worker for task 110] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 20:37:34,306 [Executor task launch worker for task 110] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 20:37:34,307 [Executor task launch worker for task 114] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 20:37:34,307 [Executor task launch worker for task 114] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 20:37:34,307 [Executor task launch worker for task 117] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 20:37:34,307 [Executor task launch worker for task 117] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 20:37:34,307 [Executor task launch worker for task 113] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 20:37:34,307 [Executor task launch worker for task 113] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 20:37:34,308 [Executor task launch worker for task 116] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 20:37:34,308 [Executor task launch worker for task 116] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 20:37:34,308 [Executor task launch worker for task 118] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 20:37:34,308 [Executor task launch worker for task 118] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 20:37:34,308 [Executor task launch worker for task 121] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 20:37:34,308 [Executor task launch worker for task 121] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 20:37:34,309 [Executor task launch worker for task 111] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 20:37:34,309 [Executor task launch worker for task 111] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 1 ms
2021-12-03 20:37:34,309 [Executor task launch worker for task 120] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 20:37:34,309 [Executor task launch worker for task 120] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 20:37:34,603 [Executor task launch worker for task 115] INFO [org.apache.spark.executor.Executor] - Finished task 5.0 in stage 7.0 (TID 115). 1055 bytes result sent to driver
2021-12-03 20:37:34,609 [dispatcher-event-loop-6] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 12.0 in stage 7.0 (TID 122, localhost, executor driver, partition 12, ANY, 7649 bytes)
2021-12-03 20:37:34,609 [Executor task launch worker for task 122] INFO [org.apache.spark.executor.Executor] - Running task 12.0 in stage 7.0 (TID 122)
2021-12-03 20:37:34,610 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 5.0 in stage 7.0 (TID 115) in 308 ms on localhost (executor driver) (1/21)
2021-12-03 20:37:34,611 [Executor task launch worker for task 119] INFO [org.apache.spark.executor.Executor] - Finished task 9.0 in stage 7.0 (TID 119). 1055 bytes result sent to driver
2021-12-03 20:37:34,611 [Executor task launch worker for task 114] INFO [org.apache.spark.executor.Executor] - Finished task 4.0 in stage 7.0 (TID 114). 1055 bytes result sent to driver
2021-12-03 20:37:34,611 [Executor task launch worker for task 113] INFO [org.apache.spark.executor.Executor] - Finished task 3.0 in stage 7.0 (TID 113). 1055 bytes result sent to driver
2021-12-03 20:37:34,611 [Executor task launch worker for task 118] INFO [org.apache.spark.executor.Executor] - Finished task 8.0 in stage 7.0 (TID 118). 1055 bytes result sent to driver
2021-12-03 20:37:34,611 [dispatcher-event-loop-11] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 13.0 in stage 7.0 (TID 123, localhost, executor driver, partition 13, ANY, 7649 bytes)
2021-12-03 20:37:34,611 [dispatcher-event-loop-11] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 14.0 in stage 7.0 (TID 124, localhost, executor driver, partition 14, ANY, 7649 bytes)
2021-12-03 20:37:34,611 [Executor task launch worker for task 120] INFO [org.apache.spark.executor.Executor] - Finished task 10.0 in stage 7.0 (TID 120). 1055 bytes result sent to driver
2021-12-03 20:37:34,611 [Executor task launch worker for task 124] INFO [org.apache.spark.executor.Executor] - Running task 14.0 in stage 7.0 (TID 124)
2021-12-03 20:37:34,611 [dispatcher-event-loop-11] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 15.0 in stage 7.0 (TID 125, localhost, executor driver, partition 15, ANY, 7649 bytes)
2021-12-03 20:37:34,612 [Executor task launch worker for task 121] INFO [org.apache.spark.executor.Executor] - Finished task 11.0 in stage 7.0 (TID 121). 1055 bytes result sent to driver
2021-12-03 20:37:34,612 [Executor task launch worker for task 125] INFO [org.apache.spark.executor.Executor] - Running task 15.0 in stage 7.0 (TID 125)
2021-12-03 20:37:34,612 [Executor task launch worker for task 122] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 20:37:34,612 [Executor task launch worker for task 123] INFO [org.apache.spark.executor.Executor] - Running task 13.0 in stage 7.0 (TID 123)
2021-12-03 20:37:34,612 [Executor task launch worker for task 122] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 20:37:34,612 [dispatcher-event-loop-11] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 16.0 in stage 7.0 (TID 126, localhost, executor driver, partition 16, ANY, 7649 bytes)
2021-12-03 20:37:34,612 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 3.0 in stage 7.0 (TID 113) in 310 ms on localhost (executor driver) (2/21)
2021-12-03 20:37:34,612 [Executor task launch worker for task 111] INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 7.0 (TID 111). 1055 bytes result sent to driver
2021-12-03 20:37:34,612 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 4.0 in stage 7.0 (TID 114) in 310 ms on localhost (executor driver) (3/21)
2021-12-03 20:37:34,612 [Executor task launch worker for task 126] INFO [org.apache.spark.executor.Executor] - Running task 16.0 in stage 7.0 (TID 126)
2021-12-03 20:37:34,613 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 8.0 in stage 7.0 (TID 118) in 311 ms on localhost (executor driver) (4/21)
2021-12-03 20:37:34,613 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 9.0 in stage 7.0 (TID 119) in 310 ms on localhost (executor driver) (5/21)
2021-12-03 20:37:34,614 [Executor task launch worker for task 124] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 20:37:34,614 [Executor task launch worker for task 124] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 1 ms
2021-12-03 20:37:34,614 [Executor task launch worker for task 125] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 20:37:34,614 [dispatcher-event-loop-11] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 17.0 in stage 7.0 (TID 127, localhost, executor driver, partition 17, ANY, 7649 bytes)
2021-12-03 20:37:34,614 [Executor task launch worker for task 125] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 20:37:34,614 [Executor task launch worker for task 123] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 20:37:34,614 [Executor task launch worker for task 123] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 20:37:34,614 [dispatcher-event-loop-11] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 18.0 in stage 7.0 (TID 128, localhost, executor driver, partition 18, ANY, 7649 bytes)
2021-12-03 20:37:34,614 [Executor task launch worker for task 127] INFO [org.apache.spark.executor.Executor] - Running task 17.0 in stage 7.0 (TID 127)
2021-12-03 20:37:34,615 [dispatcher-event-loop-11] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 19.0 in stage 7.0 (TID 129, localhost, executor driver, partition 19, ANY, 7649 bytes)
2021-12-03 20:37:34,615 [Executor task launch worker for task 117] INFO [org.apache.spark.executor.Executor] - Finished task 7.0 in stage 7.0 (TID 117). 1055 bytes result sent to driver
2021-12-03 20:37:34,615 [Executor task launch worker for task 129] INFO [org.apache.spark.executor.Executor] - Running task 19.0 in stage 7.0 (TID 129)
2021-12-03 20:37:34,615 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 10.0 in stage 7.0 (TID 120) in 312 ms on localhost (executor driver) (6/21)
2021-12-03 20:37:34,615 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 7.0 (TID 111) in 313 ms on localhost (executor driver) (7/21)
2021-12-03 20:37:34,615 [Executor task launch worker for task 128] INFO [org.apache.spark.executor.Executor] - Running task 18.0 in stage 7.0 (TID 128)
2021-12-03 20:37:34,615 [dispatcher-event-loop-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 20.0 in stage 7.0 (TID 130, localhost, executor driver, partition 20, ANY, 7649 bytes)
2021-12-03 20:37:34,615 [Executor task launch worker for task 130] INFO [org.apache.spark.executor.Executor] - Running task 20.0 in stage 7.0 (TID 130)
2021-12-03 20:37:34,616 [Executor task launch worker for task 110] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 7.0 (TID 110). 1055 bytes result sent to driver
2021-12-03 20:37:34,616 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 11.0 in stage 7.0 (TID 121) in 313 ms on localhost (executor driver) (8/21)
2021-12-03 20:37:34,617 [Executor task launch worker for task 126] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 20:37:34,617 [Executor task launch worker for task 126] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 1 ms
2021-12-03 20:37:34,617 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 7.0 in stage 7.0 (TID 117) in 315 ms on localhost (executor driver) (9/21)
2021-12-03 20:37:34,617 [Executor task launch worker for task 116] INFO [org.apache.spark.executor.Executor] - Finished task 6.0 in stage 7.0 (TID 116). 1055 bytes result sent to driver
2021-12-03 20:37:34,617 [Executor task launch worker for task 112] INFO [org.apache.spark.executor.Executor] - Finished task 2.0 in stage 7.0 (TID 112). 1055 bytes result sent to driver
2021-12-03 20:37:34,617 [Executor task launch worker for task 128] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 20:37:34,617 [Executor task launch worker for task 128] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 20:37:34,618 [Executor task launch worker for task 130] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 20:37:34,618 [Executor task launch worker for task 130] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 20:37:34,618 [Executor task launch worker for task 127] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 20:37:34,618 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 2.0 in stage 7.0 (TID 112) in 316 ms on localhost (executor driver) (10/21)
2021-12-03 20:37:34,618 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 6.0 in stage 7.0 (TID 116) in 316 ms on localhost (executor driver) (11/21)
2021-12-03 20:37:34,618 [Executor task launch worker for task 127] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 20:37:34,619 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 7.0 (TID 110) in 317 ms on localhost (executor driver) (12/21)
2021-12-03 20:37:34,619 [Executor task launch worker for task 129] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 20:37:34,619 [Executor task launch worker for task 129] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 20:37:34,690 [Executor task launch worker for task 124] INFO [org.apache.spark.executor.Executor] - Finished task 14.0 in stage 7.0 (TID 124). 1141 bytes result sent to driver
2021-12-03 20:37:34,691 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 14.0 in stage 7.0 (TID 124) in 80 ms on localhost (executor driver) (13/21)
2021-12-03 20:37:34,699 [Executor task launch worker for task 126] INFO [org.apache.spark.executor.Executor] - Finished task 16.0 in stage 7.0 (TID 126). 1098 bytes result sent to driver
2021-12-03 20:37:34,699 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 16.0 in stage 7.0 (TID 126) in 87 ms on localhost (executor driver) (14/21)
2021-12-03 20:37:34,706 [Executor task launch worker for task 128] INFO [org.apache.spark.executor.Executor] - Finished task 18.0 in stage 7.0 (TID 128). 1098 bytes result sent to driver
2021-12-03 20:37:34,706 [Executor task launch worker for task 129] INFO [org.apache.spark.executor.Executor] - Finished task 19.0 in stage 7.0 (TID 129). 1098 bytes result sent to driver
2021-12-03 20:37:34,707 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 18.0 in stage 7.0 (TID 128) in 93 ms on localhost (executor driver) (15/21)
2021-12-03 20:37:34,707 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 19.0 in stage 7.0 (TID 129) in 92 ms on localhost (executor driver) (16/21)
2021-12-03 20:37:34,707 [Executor task launch worker for task 125] INFO [org.apache.spark.executor.Executor] - Finished task 15.0 in stage 7.0 (TID 125). 1098 bytes result sent to driver
2021-12-03 20:37:34,708 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 15.0 in stage 7.0 (TID 125) in 97 ms on localhost (executor driver) (17/21)
2021-12-03 20:37:34,710 [Executor task launch worker for task 123] INFO [org.apache.spark.executor.Executor] - Finished task 13.0 in stage 7.0 (TID 123). 1098 bytes result sent to driver
2021-12-03 20:37:34,710 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 13.0 in stage 7.0 (TID 123) in 99 ms on localhost (executor driver) (18/21)
2021-12-03 20:37:34,710 [Executor task launch worker for task 130] INFO [org.apache.spark.executor.Executor] - Finished task 20.0 in stage 7.0 (TID 130). 1098 bytes result sent to driver
2021-12-03 20:37:34,711 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 20.0 in stage 7.0 (TID 130) in 96 ms on localhost (executor driver) (19/21)
2021-12-03 20:37:34,714 [Executor task launch worker for task 122] INFO [org.apache.spark.executor.Executor] - Finished task 12.0 in stage 7.0 (TID 122). 1141 bytes result sent to driver
2021-12-03 20:37:34,715 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 12.0 in stage 7.0 (TID 122) in 106 ms on localhost (executor driver) (20/21)
2021-12-03 20:37:34,721 [Executor task launch worker for task 127] INFO [org.apache.spark.executor.Executor] - Finished task 17.0 in stage 7.0 (TID 127). 1098 bytes result sent to driver
2021-12-03 20:37:34,721 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 17.0 in stage 7.0 (TID 127) in 107 ms on localhost (executor driver) (21/21)
2021-12-03 20:37:34,721 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 7.0, whose tasks have all completed, from pool 
2021-12-03 20:37:34,721 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 7 (zipWithIndex at PaidPromotionAdjustParameter.scala:74) finished in 0.423 s
2021-12-03 20:37:34,721 [main] INFO [org.apache.spark.scheduler.DAGScheduler] - Job 3 finished: zipWithIndex at PaidPromotionAdjustParameter.scala:74, took 1.472116 s
2021-12-03 20:37:34,731 [main] INFO [org.apache.spark.SparkContext] - Starting job: takeSample at PaidPromotionAdjustParameter.scala:77
2021-12-03 20:37:34,731 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 4 (takeSample at PaidPromotionAdjustParameter.scala:77) with 22 output partitions
2021-12-03 20:37:34,731 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 10 (takeSample at PaidPromotionAdjustParameter.scala:77)
2021-12-03 20:37:34,731 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 9)
2021-12-03 20:37:34,731 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2021-12-03 20:37:34,732 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 10 (MapPartitionsRDD[11] at map at PaidPromotionAdjustParameter.scala:76), which has no missing parents
2021-12-03 20:37:34,735 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_7 stored as values in memory (estimated size 4.2 KB, free 1990.4 MB)
2021-12-03 20:37:34,736 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_7_piece0 stored as bytes in memory (estimated size 2.4 KB, free 1990.4 MB)
2021-12-03 20:37:34,736 [dispatcher-event-loop-3] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_7_piece0 in memory on qb:53199 (size: 2.4 KB, free: 1990.8 MB)
2021-12-03 20:37:34,736 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 7 from broadcast at DAGScheduler.scala:1039
2021-12-03 20:37:34,736 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 22 missing tasks from ResultStage 10 (MapPartitionsRDD[11] at map at PaidPromotionAdjustParameter.scala:76) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14))
2021-12-03 20:37:34,736 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 10.0 with 22 tasks
2021-12-03 20:37:34,737 [dispatcher-event-loop-8] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 10.0 (TID 131, localhost, executor driver, partition 0, ANY, 7759 bytes)
2021-12-03 20:37:34,737 [dispatcher-event-loop-8] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 10.0 (TID 132, localhost, executor driver, partition 1, ANY, 7759 bytes)
2021-12-03 20:37:34,737 [dispatcher-event-loop-8] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 2.0 in stage 10.0 (TID 133, localhost, executor driver, partition 2, ANY, 7759 bytes)
2021-12-03 20:37:34,737 [dispatcher-event-loop-8] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 3.0 in stage 10.0 (TID 134, localhost, executor driver, partition 3, ANY, 7759 bytes)
2021-12-03 20:37:34,737 [dispatcher-event-loop-8] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 4.0 in stage 10.0 (TID 135, localhost, executor driver, partition 4, ANY, 7759 bytes)
2021-12-03 20:37:34,738 [dispatcher-event-loop-8] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 5.0 in stage 10.0 (TID 136, localhost, executor driver, partition 5, ANY, 7759 bytes)
2021-12-03 20:37:34,738 [dispatcher-event-loop-8] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 6.0 in stage 10.0 (TID 137, localhost, executor driver, partition 6, ANY, 7759 bytes)
2021-12-03 20:37:34,738 [dispatcher-event-loop-8] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 7.0 in stage 10.0 (TID 138, localhost, executor driver, partition 7, ANY, 7759 bytes)
2021-12-03 20:37:34,738 [dispatcher-event-loop-8] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 8.0 in stage 10.0 (TID 139, localhost, executor driver, partition 8, ANY, 7759 bytes)
2021-12-03 20:37:34,738 [dispatcher-event-loop-8] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 9.0 in stage 10.0 (TID 140, localhost, executor driver, partition 9, ANY, 7759 bytes)
2021-12-03 20:37:34,738 [dispatcher-event-loop-8] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 10.0 in stage 10.0 (TID 141, localhost, executor driver, partition 10, ANY, 7759 bytes)
2021-12-03 20:37:34,738 [dispatcher-event-loop-8] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 11.0 in stage 10.0 (TID 142, localhost, executor driver, partition 11, ANY, 7759 bytes)
2021-12-03 20:37:34,738 [Executor task launch worker for task 131] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 10.0 (TID 131)
2021-12-03 20:37:34,738 [Executor task launch worker for task 139] INFO [org.apache.spark.executor.Executor] - Running task 8.0 in stage 10.0 (TID 139)
2021-12-03 20:37:34,738 [Executor task launch worker for task 142] INFO [org.apache.spark.executor.Executor] - Running task 11.0 in stage 10.0 (TID 142)
2021-12-03 20:37:34,738 [Executor task launch worker for task 140] INFO [org.apache.spark.executor.Executor] - Running task 9.0 in stage 10.0 (TID 140)
2021-12-03 20:37:34,738 [Executor task launch worker for task 141] INFO [org.apache.spark.executor.Executor] - Running task 10.0 in stage 10.0 (TID 141)
2021-12-03 20:37:34,738 [Executor task launch worker for task 138] INFO [org.apache.spark.executor.Executor] - Running task 7.0 in stage 10.0 (TID 138)
2021-12-03 20:37:34,738 [Executor task launch worker for task 137] INFO [org.apache.spark.executor.Executor] - Running task 6.0 in stage 10.0 (TID 137)
2021-12-03 20:37:34,738 [Executor task launch worker for task 136] INFO [org.apache.spark.executor.Executor] - Running task 5.0 in stage 10.0 (TID 136)
2021-12-03 20:37:34,738 [Executor task launch worker for task 135] INFO [org.apache.spark.executor.Executor] - Running task 4.0 in stage 10.0 (TID 135)
2021-12-03 20:37:34,738 [Executor task launch worker for task 134] INFO [org.apache.spark.executor.Executor] - Running task 3.0 in stage 10.0 (TID 134)
2021-12-03 20:37:34,738 [Executor task launch worker for task 132] INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 10.0 (TID 132)
2021-12-03 20:37:34,738 [Executor task launch worker for task 133] INFO [org.apache.spark.executor.Executor] - Running task 2.0 in stage 10.0 (TID 133)
2021-12-03 20:37:34,741 [Executor task launch worker for task 135] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 20:37:34,741 [Executor task launch worker for task 135] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 20:37:34,741 [Executor task launch worker for task 132] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 20:37:34,741 [Executor task launch worker for task 132] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 20:37:34,741 [Executor task launch worker for task 142] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 20:37:34,741 [Executor task launch worker for task 142] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 20:37:34,741 [Executor task launch worker for task 136] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 20:37:34,741 [Executor task launch worker for task 136] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 20:37:34,741 [Executor task launch worker for task 140] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 20:37:34,742 [Executor task launch worker for task 140] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 1 ms
2021-12-03 20:37:34,742 [Executor task launch worker for task 134] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 20:37:34,742 [Executor task launch worker for task 134] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 20:37:34,742 [Executor task launch worker for task 131] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 20:37:34,742 [Executor task launch worker for task 131] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 20:37:34,742 [Executor task launch worker for task 141] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 20:37:34,742 [Executor task launch worker for task 141] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 20:37:34,743 [Executor task launch worker for task 133] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 20:37:34,743 [Executor task launch worker for task 133] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 20:37:34,743 [Executor task launch worker for task 139] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 20:37:34,743 [Executor task launch worker for task 139] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 20:37:34,743 [Executor task launch worker for task 137] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 20:37:34,743 [Executor task launch worker for task 137] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 20:37:34,745 [Executor task launch worker for task 138] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 20:37:34,745 [Executor task launch worker for task 138] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 20:37:34,848 [Executor task launch worker for task 142] INFO [org.apache.spark.executor.Executor] - Finished task 11.0 in stage 10.0 (TID 142). 1053 bytes result sent to driver
2021-12-03 20:37:34,848 [dispatcher-event-loop-7] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 12.0 in stage 10.0 (TID 143, localhost, executor driver, partition 12, ANY, 7759 bytes)
2021-12-03 20:37:34,848 [Executor task launch worker for task 143] INFO [org.apache.spark.executor.Executor] - Running task 12.0 in stage 10.0 (TID 143)
2021-12-03 20:37:34,850 [Executor task launch worker for task 139] INFO [org.apache.spark.executor.Executor] - Finished task 8.0 in stage 10.0 (TID 139). 1053 bytes result sent to driver
2021-12-03 20:37:34,852 [Executor task launch worker for task 141] INFO [org.apache.spark.executor.Executor] - Finished task 10.0 in stage 10.0 (TID 141). 1053 bytes result sent to driver
2021-12-03 20:37:34,853 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 11.0 in stage 10.0 (TID 142) in 110 ms on localhost (executor driver) (1/22)
2021-12-03 20:37:34,853 [dispatcher-event-loop-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 13.0 in stage 10.0 (TID 144, localhost, executor driver, partition 13, ANY, 7759 bytes)
2021-12-03 20:37:34,853 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 8.0 in stage 10.0 (TID 139) in 115 ms on localhost (executor driver) (2/22)
2021-12-03 20:37:34,853 [Executor task launch worker for task 144] INFO [org.apache.spark.executor.Executor] - Running task 13.0 in stage 10.0 (TID 144)
2021-12-03 20:37:34,853 [Executor task launch worker for task 143] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 20:37:34,853 [Executor task launch worker for task 143] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 20:37:34,854 [dispatcher-event-loop-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 14.0 in stage 10.0 (TID 145, localhost, executor driver, partition 14, ANY, 7759 bytes)
2021-12-03 20:37:34,854 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 10.0 in stage 10.0 (TID 141) in 116 ms on localhost (executor driver) (3/22)
2021-12-03 20:37:34,854 [Executor task launch worker for task 145] INFO [org.apache.spark.executor.Executor] - Running task 14.0 in stage 10.0 (TID 145)
2021-12-03 20:37:34,855 [Executor task launch worker for task 137] INFO [org.apache.spark.executor.Executor] - Finished task 6.0 in stage 10.0 (TID 137). 1053 bytes result sent to driver
2021-12-03 20:37:34,855 [Executor task launch worker for task 132] INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 10.0 (TID 132). 1053 bytes result sent to driver
2021-12-03 20:37:34,855 [dispatcher-event-loop-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 15.0 in stage 10.0 (TID 146, localhost, executor driver, partition 15, ANY, 7759 bytes)
2021-12-03 20:37:34,855 [Executor task launch worker for task 146] INFO [org.apache.spark.executor.Executor] - Running task 15.0 in stage 10.0 (TID 146)
2021-12-03 20:37:34,855 [dispatcher-event-loop-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 16.0 in stage 10.0 (TID 147, localhost, executor driver, partition 16, ANY, 7759 bytes)
2021-12-03 20:37:34,855 [Executor task launch worker for task 147] INFO [org.apache.spark.executor.Executor] - Running task 16.0 in stage 10.0 (TID 147)
2021-12-03 20:37:34,855 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 10.0 (TID 132) in 118 ms on localhost (executor driver) (4/22)
2021-12-03 20:37:34,856 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 6.0 in stage 10.0 (TID 137) in 118 ms on localhost (executor driver) (5/22)
2021-12-03 20:37:34,856 [Executor task launch worker for task 144] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 20:37:34,856 [Executor task launch worker for task 144] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 20:37:34,858 [Executor task launch worker for task 146] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 20:37:34,858 [Executor task launch worker for task 146] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 20:37:34,858 [Executor task launch worker for task 147] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 20:37:34,858 [Executor task launch worker for task 147] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 20:37:34,859 [Executor task launch worker for task 145] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 20:37:34,859 [Executor task launch worker for task 145] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 20:37:34,868 [Executor task launch worker for task 136] INFO [org.apache.spark.executor.Executor] - Finished task 5.0 in stage 10.0 (TID 136). 1053 bytes result sent to driver
2021-12-03 20:37:34,869 [dispatcher-event-loop-8] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 17.0 in stage 10.0 (TID 148, localhost, executor driver, partition 17, ANY, 7759 bytes)
2021-12-03 20:37:34,869 [Executor task launch worker for task 148] INFO [org.apache.spark.executor.Executor] - Running task 17.0 in stage 10.0 (TID 148)
2021-12-03 20:37:34,869 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 5.0 in stage 10.0 (TID 136) in 131 ms on localhost (executor driver) (6/22)
2021-12-03 20:37:34,870 [Executor task launch worker for task 140] INFO [org.apache.spark.executor.Executor] - Finished task 9.0 in stage 10.0 (TID 140). 1053 bytes result sent to driver
2021-12-03 20:37:34,870 [dispatcher-event-loop-7] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 18.0 in stage 10.0 (TID 149, localhost, executor driver, partition 18, ANY, 7759 bytes)
2021-12-03 20:37:34,870 [Executor task launch worker for task 149] INFO [org.apache.spark.executor.Executor] - Running task 18.0 in stage 10.0 (TID 149)
2021-12-03 20:37:34,870 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 9.0 in stage 10.0 (TID 140) in 132 ms on localhost (executor driver) (7/22)
2021-12-03 20:37:34,871 [Executor task launch worker for task 148] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 20:37:34,871 [Executor task launch worker for task 148] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 20:37:34,873 [Executor task launch worker for task 149] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 20:37:34,873 [Executor task launch worker for task 149] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 20:37:34,878 [Executor task launch worker for task 133] INFO [org.apache.spark.executor.Executor] - Finished task 2.0 in stage 10.0 (TID 133). 1055 bytes result sent to driver
2021-12-03 20:37:34,878 [dispatcher-event-loop-11] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 19.0 in stage 10.0 (TID 150, localhost, executor driver, partition 19, ANY, 7759 bytes)
2021-12-03 20:37:34,879 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 2.0 in stage 10.0 (TID 133) in 142 ms on localhost (executor driver) (8/22)
2021-12-03 20:37:34,879 [Executor task launch worker for task 135] INFO [org.apache.spark.executor.Executor] - Finished task 4.0 in stage 10.0 (TID 135). 1053 bytes result sent to driver
2021-12-03 20:37:34,879 [dispatcher-event-loop-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 20.0 in stage 10.0 (TID 151, localhost, executor driver, partition 20, ANY, 7759 bytes)
2021-12-03 20:37:34,879 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 4.0 in stage 10.0 (TID 135) in 142 ms on localhost (executor driver) (9/22)
2021-12-03 20:37:34,879 [Executor task launch worker for task 151] INFO [org.apache.spark.executor.Executor] - Running task 20.0 in stage 10.0 (TID 151)
2021-12-03 20:37:34,880 [Executor task launch worker for task 150] INFO [org.apache.spark.executor.Executor] - Running task 19.0 in stage 10.0 (TID 150)
2021-12-03 20:37:34,880 [Executor task launch worker for task 134] INFO [org.apache.spark.executor.Executor] - Finished task 3.0 in stage 10.0 (TID 134). 1053 bytes result sent to driver
2021-12-03 20:37:34,880 [Executor task launch worker for task 131] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 10.0 (TID 131). 1053 bytes result sent to driver
2021-12-03 20:37:34,881 [dispatcher-event-loop-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 21.0 in stage 10.0 (TID 152, localhost, executor driver, partition 21, ANY, 7759 bytes)
2021-12-03 20:37:34,881 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 10.0 (TID 131) in 144 ms on localhost (executor driver) (10/22)
2021-12-03 20:37:34,882 [Executor task launch worker for task 152] INFO [org.apache.spark.executor.Executor] - Running task 21.0 in stage 10.0 (TID 152)
2021-12-03 20:37:34,883 [Executor task launch worker for task 151] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 20:37:34,883 [Executor task launch worker for task 151] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 1 ms
2021-12-03 20:37:34,886 [Executor task launch worker for task 152] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 20:37:34,886 [Executor task launch worker for task 152] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 20:37:34,886 [Executor task launch worker for task 150] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 20:37:34,886 [Executor task launch worker for task 150] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 20:37:34,886 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 3.0 in stage 10.0 (TID 134) in 149 ms on localhost (executor driver) (11/22)
2021-12-03 20:37:34,905 [Executor task launch worker for task 138] INFO [org.apache.spark.executor.Executor] - Finished task 7.0 in stage 10.0 (TID 138). 1053 bytes result sent to driver
2021-12-03 20:37:34,906 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 7.0 in stage 10.0 (TID 138) in 168 ms on localhost (executor driver) (12/22)
2021-12-03 20:37:34,939 [dispatcher-event-loop-7] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_6_piece0 on qb:53199 in memory (size: 2.0 KB, free: 1990.8 MB)
2021-12-03 20:37:34,945 [Executor task launch worker for task 145] INFO [org.apache.spark.executor.Executor] - Finished task 14.0 in stage 10.0 (TID 145). 1096 bytes result sent to driver
2021-12-03 20:37:34,946 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 14.0 in stage 10.0 (TID 145) in 92 ms on localhost (executor driver) (13/22)
2021-12-03 20:37:34,954 [Executor task launch worker for task 147] INFO [org.apache.spark.executor.Executor] - Finished task 16.0 in stage 10.0 (TID 147). 1096 bytes result sent to driver
2021-12-03 20:37:34,954 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 16.0 in stage 10.0 (TID 147) in 99 ms on localhost (executor driver) (14/22)
2021-12-03 20:37:34,959 [Executor task launch worker for task 146] INFO [org.apache.spark.executor.Executor] - Finished task 15.0 in stage 10.0 (TID 146). 1139 bytes result sent to driver
2021-12-03 20:37:34,959 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 15.0 in stage 10.0 (TID 146) in 104 ms on localhost (executor driver) (15/22)
2021-12-03 20:37:34,966 [Executor task launch worker for task 144] INFO [org.apache.spark.executor.Executor] - Finished task 13.0 in stage 10.0 (TID 144). 1096 bytes result sent to driver
2021-12-03 20:37:34,966 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 13.0 in stage 10.0 (TID 144) in 113 ms on localhost (executor driver) (16/22)
2021-12-03 20:37:34,971 [Executor task launch worker for task 143] INFO [org.apache.spark.executor.Executor] - Finished task 12.0 in stage 10.0 (TID 143). 1096 bytes result sent to driver
2021-12-03 20:37:34,972 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 12.0 in stage 10.0 (TID 143) in 124 ms on localhost (executor driver) (17/22)
2021-12-03 20:37:34,973 [Executor task launch worker for task 149] INFO [org.apache.spark.executor.Executor] - Finished task 18.0 in stage 10.0 (TID 149). 1096 bytes result sent to driver
2021-12-03 20:37:34,973 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 18.0 in stage 10.0 (TID 149) in 103 ms on localhost (executor driver) (18/22)
2021-12-03 20:37:34,978 [Executor task launch worker for task 151] INFO [org.apache.spark.executor.Executor] - Finished task 20.0 in stage 10.0 (TID 151). 1096 bytes result sent to driver
2021-12-03 20:37:34,978 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 20.0 in stage 10.0 (TID 151) in 99 ms on localhost (executor driver) (19/22)
2021-12-03 20:37:34,982 [Executor task launch worker for task 152] INFO [org.apache.spark.executor.Executor] - Finished task 21.0 in stage 10.0 (TID 152). 1096 bytes result sent to driver
2021-12-03 20:37:34,982 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 21.0 in stage 10.0 (TID 152) in 102 ms on localhost (executor driver) (20/22)
2021-12-03 20:37:34,984 [Executor task launch worker for task 150] INFO [org.apache.spark.executor.Executor] - Finished task 19.0 in stage 10.0 (TID 150). 1096 bytes result sent to driver
2021-12-03 20:37:34,985 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 19.0 in stage 10.0 (TID 150) in 107 ms on localhost (executor driver) (21/22)
2021-12-03 20:37:34,986 [Executor task launch worker for task 148] INFO [org.apache.spark.executor.Executor] - Finished task 17.0 in stage 10.0 (TID 148). 1096 bytes result sent to driver
2021-12-03 20:37:34,986 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 17.0 in stage 10.0 (TID 148) in 118 ms on localhost (executor driver) (22/22)
2021-12-03 20:37:34,986 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 10.0, whose tasks have all completed, from pool 
2021-12-03 20:37:34,986 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 10 (takeSample at PaidPromotionAdjustParameter.scala:77) finished in 0.253 s
2021-12-03 20:37:34,986 [main] INFO [org.apache.spark.scheduler.DAGScheduler] - Job 4 finished: takeSample at PaidPromotionAdjustParameter.scala:77, took 0.254724 s
2021-12-03 20:37:34,993 [main] INFO [org.apache.spark.SparkContext] - Starting job: takeSample at PaidPromotionAdjustParameter.scala:77
2021-12-03 20:37:34,994 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 5 (takeSample at PaidPromotionAdjustParameter.scala:77) with 22 output partitions
2021-12-03 20:37:34,994 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 13 (takeSample at PaidPromotionAdjustParameter.scala:77)
2021-12-03 20:37:34,994 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 12)
2021-12-03 20:37:34,994 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2021-12-03 20:37:34,994 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 13 (MapPartitionsRDD[11] at map at PaidPromotionAdjustParameter.scala:76), which has no missing parents
2021-12-03 20:37:34,996 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_8 stored as values in memory (estimated size 4.3 KB, free 1990.4 MB)
2021-12-03 20:37:34,997 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_8_piece0 stored as bytes in memory (estimated size 2.5 KB, free 1990.4 MB)
2021-12-03 20:37:34,998 [dispatcher-event-loop-8] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_8_piece0 in memory on qb:53199 (size: 2.5 KB, free: 1990.8 MB)
2021-12-03 20:37:34,998 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 8 from broadcast at DAGScheduler.scala:1039
2021-12-03 20:37:34,998 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 22 missing tasks from ResultStage 13 (MapPartitionsRDD[11] at map at PaidPromotionAdjustParameter.scala:76) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14))
2021-12-03 20:37:34,998 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 13.0 with 22 tasks
2021-12-03 20:37:34,998 [dispatcher-event-loop-7] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 13.0 (TID 153, localhost, executor driver, partition 0, ANY, 7759 bytes)
2021-12-03 20:37:34,999 [dispatcher-event-loop-7] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 13.0 (TID 154, localhost, executor driver, partition 1, ANY, 7759 bytes)
2021-12-03 20:37:34,999 [dispatcher-event-loop-7] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 2.0 in stage 13.0 (TID 155, localhost, executor driver, partition 2, ANY, 7759 bytes)
2021-12-03 20:37:34,999 [dispatcher-event-loop-7] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 3.0 in stage 13.0 (TID 156, localhost, executor driver, partition 3, ANY, 7759 bytes)
2021-12-03 20:37:34,999 [dispatcher-event-loop-7] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 4.0 in stage 13.0 (TID 157, localhost, executor driver, partition 4, ANY, 7759 bytes)
2021-12-03 20:37:34,999 [dispatcher-event-loop-7] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 5.0 in stage 13.0 (TID 158, localhost, executor driver, partition 5, ANY, 7759 bytes)
2021-12-03 20:37:34,999 [dispatcher-event-loop-7] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 6.0 in stage 13.0 (TID 159, localhost, executor driver, partition 6, ANY, 7759 bytes)
2021-12-03 20:37:34,999 [dispatcher-event-loop-7] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 7.0 in stage 13.0 (TID 160, localhost, executor driver, partition 7, ANY, 7759 bytes)
2021-12-03 20:37:34,999 [dispatcher-event-loop-7] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 8.0 in stage 13.0 (TID 161, localhost, executor driver, partition 8, ANY, 7759 bytes)
2021-12-03 20:37:34,999 [dispatcher-event-loop-7] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 9.0 in stage 13.0 (TID 162, localhost, executor driver, partition 9, ANY, 7759 bytes)
2021-12-03 20:37:34,999 [dispatcher-event-loop-7] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 10.0 in stage 13.0 (TID 163, localhost, executor driver, partition 10, ANY, 7759 bytes)
2021-12-03 20:37:34,999 [dispatcher-event-loop-7] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 11.0 in stage 13.0 (TID 164, localhost, executor driver, partition 11, ANY, 7759 bytes)
2021-12-03 20:37:34,999 [Executor task launch worker for task 153] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 13.0 (TID 153)
2021-12-03 20:37:34,999 [Executor task launch worker for task 160] INFO [org.apache.spark.executor.Executor] - Running task 7.0 in stage 13.0 (TID 160)
2021-12-03 20:37:34,999 [Executor task launch worker for task 164] INFO [org.apache.spark.executor.Executor] - Running task 11.0 in stage 13.0 (TID 164)
2021-12-03 20:37:34,999 [Executor task launch worker for task 161] INFO [org.apache.spark.executor.Executor] - Running task 8.0 in stage 13.0 (TID 161)
2021-12-03 20:37:34,999 [Executor task launch worker for task 154] INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 13.0 (TID 154)
2021-12-03 20:37:34,999 [Executor task launch worker for task 157] INFO [org.apache.spark.executor.Executor] - Running task 4.0 in stage 13.0 (TID 157)
2021-12-03 20:37:34,999 [Executor task launch worker for task 156] INFO [org.apache.spark.executor.Executor] - Running task 3.0 in stage 13.0 (TID 156)
2021-12-03 20:37:34,999 [Executor task launch worker for task 159] INFO [org.apache.spark.executor.Executor] - Running task 6.0 in stage 13.0 (TID 159)
2021-12-03 20:37:34,999 [Executor task launch worker for task 155] INFO [org.apache.spark.executor.Executor] - Running task 2.0 in stage 13.0 (TID 155)
2021-12-03 20:37:34,999 [Executor task launch worker for task 158] INFO [org.apache.spark.executor.Executor] - Running task 5.0 in stage 13.0 (TID 158)
2021-12-03 20:37:34,999 [Executor task launch worker for task 162] INFO [org.apache.spark.executor.Executor] - Running task 9.0 in stage 13.0 (TID 162)
2021-12-03 20:37:34,999 [Executor task launch worker for task 163] INFO [org.apache.spark.executor.Executor] - Running task 10.0 in stage 13.0 (TID 163)
2021-12-03 20:37:35,002 [Executor task launch worker for task 161] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 20:37:35,002 [Executor task launch worker for task 161] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 20:37:35,002 [Executor task launch worker for task 162] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 20:37:35,002 [Executor task launch worker for task 162] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 20:37:35,002 [Executor task launch worker for task 164] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 20:37:35,002 [Executor task launch worker for task 164] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 20:37:35,002 [Executor task launch worker for task 163] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 20:37:35,002 [Executor task launch worker for task 163] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 20:37:35,003 [Executor task launch worker for task 154] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 20:37:35,003 [Executor task launch worker for task 154] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 20:37:35,003 [Executor task launch worker for task 158] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 20:37:35,003 [Executor task launch worker for task 158] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 20:37:35,003 [Executor task launch worker for task 153] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 20:37:35,003 [Executor task launch worker for task 153] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 20:37:35,004 [Executor task launch worker for task 155] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 20:37:35,004 [Executor task launch worker for task 155] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 1 ms
2021-12-03 20:37:35,004 [Executor task launch worker for task 156] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 20:37:35,004 [Executor task launch worker for task 156] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 20:37:35,004 [Executor task launch worker for task 157] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 20:37:35,004 [Executor task launch worker for task 157] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 20:37:35,005 [Executor task launch worker for task 159] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 20:37:35,005 [Executor task launch worker for task 159] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 1 ms
2021-12-03 20:37:35,005 [Executor task launch worker for task 160] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 20:37:35,005 [Executor task launch worker for task 160] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 20:37:35,083 [Executor task launch worker for task 162] INFO [org.apache.spark.executor.Executor] - Finished task 9.0 in stage 13.0 (TID 162). 1054 bytes result sent to driver
2021-12-03 20:37:35,086 [dispatcher-event-loop-10] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 12.0 in stage 13.0 (TID 165, localhost, executor driver, partition 12, ANY, 7759 bytes)
2021-12-03 20:37:35,086 [Executor task launch worker for task 165] INFO [org.apache.spark.executor.Executor] - Running task 12.0 in stage 13.0 (TID 165)
2021-12-03 20:37:35,086 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 9.0 in stage 13.0 (TID 162) in 87 ms on localhost (executor driver) (1/22)
2021-12-03 20:37:35,088 [Executor task launch worker for task 163] INFO [org.apache.spark.executor.Executor] - Finished task 10.0 in stage 13.0 (TID 163). 1054 bytes result sent to driver
2021-12-03 20:37:35,089 [dispatcher-event-loop-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 13.0 in stage 13.0 (TID 166, localhost, executor driver, partition 13, ANY, 7759 bytes)
2021-12-03 20:37:35,089 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 10.0 in stage 13.0 (TID 163) in 90 ms on localhost (executor driver) (2/22)
2021-12-03 20:37:35,089 [Executor task launch worker for task 166] INFO [org.apache.spark.executor.Executor] - Running task 13.0 in stage 13.0 (TID 166)
2021-12-03 20:37:35,089 [Executor task launch worker for task 165] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 20:37:35,089 [Executor task launch worker for task 165] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 20:37:35,092 [Executor task launch worker for task 166] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 20:37:35,092 [Executor task launch worker for task 166] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 20:37:35,094 [Executor task launch worker for task 161] INFO [org.apache.spark.executor.Executor] - Finished task 8.0 in stage 13.0 (TID 161). 1054 bytes result sent to driver
2021-12-03 20:37:35,094 [Executor task launch worker for task 164] INFO [org.apache.spark.executor.Executor] - Finished task 11.0 in stage 13.0 (TID 164). 1054 bytes result sent to driver
2021-12-03 20:37:35,094 [dispatcher-event-loop-5] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 14.0 in stage 13.0 (TID 167, localhost, executor driver, partition 14, ANY, 7759 bytes)
2021-12-03 20:37:35,094 [Executor task launch worker for task 167] INFO [org.apache.spark.executor.Executor] - Running task 14.0 in stage 13.0 (TID 167)
2021-12-03 20:37:35,094 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 8.0 in stage 13.0 (TID 161) in 95 ms on localhost (executor driver) (3/22)
2021-12-03 20:37:35,095 [dispatcher-event-loop-5] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 15.0 in stage 13.0 (TID 168, localhost, executor driver, partition 15, ANY, 7759 bytes)
2021-12-03 20:37:35,095 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 11.0 in stage 13.0 (TID 164) in 96 ms on localhost (executor driver) (4/22)
2021-12-03 20:37:35,095 [Executor task launch worker for task 168] INFO [org.apache.spark.executor.Executor] - Running task 15.0 in stage 13.0 (TID 168)
2021-12-03 20:37:35,097 [Executor task launch worker for task 168] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 20:37:35,097 [Executor task launch worker for task 168] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 20:37:35,098 [Executor task launch worker for task 167] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 20:37:35,098 [Executor task launch worker for task 167] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 20:37:35,098 [Executor task launch worker for task 158] INFO [org.apache.spark.executor.Executor] - Finished task 5.0 in stage 13.0 (TID 158). 1097 bytes result sent to driver
2021-12-03 20:37:35,099 [dispatcher-event-loop-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 16.0 in stage 13.0 (TID 169, localhost, executor driver, partition 16, ANY, 7759 bytes)
2021-12-03 20:37:35,099 [Executor task launch worker for task 169] INFO [org.apache.spark.executor.Executor] - Running task 16.0 in stage 13.0 (TID 169)
2021-12-03 20:37:35,099 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 5.0 in stage 13.0 (TID 158) in 100 ms on localhost (executor driver) (5/22)
2021-12-03 20:37:35,100 [Executor task launch worker for task 156] INFO [org.apache.spark.executor.Executor] - Finished task 3.0 in stage 13.0 (TID 156). 1054 bytes result sent to driver
2021-12-03 20:37:35,100 [dispatcher-event-loop-8] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 17.0 in stage 13.0 (TID 170, localhost, executor driver, partition 17, ANY, 7759 bytes)
2021-12-03 20:37:35,101 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 3.0 in stage 13.0 (TID 156) in 102 ms on localhost (executor driver) (6/22)
2021-12-03 20:37:35,101 [Executor task launch worker for task 170] INFO [org.apache.spark.executor.Executor] - Running task 17.0 in stage 13.0 (TID 170)
2021-12-03 20:37:35,102 [Executor task launch worker for task 169] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 20:37:35,102 [Executor task launch worker for task 169] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 20:37:35,104 [Executor task launch worker for task 170] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 20:37:35,104 [Executor task launch worker for task 170] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 20:37:35,106 [Executor task launch worker for task 159] INFO [org.apache.spark.executor.Executor] - Finished task 6.0 in stage 13.0 (TID 159). 1054 bytes result sent to driver
2021-12-03 20:37:35,107 [dispatcher-event-loop-10] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 18.0 in stage 13.0 (TID 171, localhost, executor driver, partition 18, ANY, 7759 bytes)
2021-12-03 20:37:35,107 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 6.0 in stage 13.0 (TID 159) in 108 ms on localhost (executor driver) (7/22)
2021-12-03 20:37:35,107 [Executor task launch worker for task 171] INFO [org.apache.spark.executor.Executor] - Running task 18.0 in stage 13.0 (TID 171)
2021-12-03 20:37:35,110 [Executor task launch worker for task 171] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 20:37:35,110 [Executor task launch worker for task 171] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 20:37:35,114 [Executor task launch worker for task 153] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 13.0 (TID 153). 1097 bytes result sent to driver
2021-12-03 20:37:35,116 [dispatcher-event-loop-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 19.0 in stage 13.0 (TID 172, localhost, executor driver, partition 19, ANY, 7759 bytes)
2021-12-03 20:37:35,116 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 13.0 (TID 153) in 118 ms on localhost (executor driver) (8/22)
2021-12-03 20:37:35,116 [Executor task launch worker for task 172] INFO [org.apache.spark.executor.Executor] - Running task 19.0 in stage 13.0 (TID 172)
2021-12-03 20:37:35,118 [Executor task launch worker for task 157] INFO [org.apache.spark.executor.Executor] - Finished task 4.0 in stage 13.0 (TID 157). 1054 bytes result sent to driver
2021-12-03 20:37:35,119 [dispatcher-event-loop-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 20.0 in stage 13.0 (TID 173, localhost, executor driver, partition 20, ANY, 7759 bytes)
2021-12-03 20:37:35,119 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 4.0 in stage 13.0 (TID 157) in 120 ms on localhost (executor driver) (9/22)
2021-12-03 20:37:35,119 [Executor task launch worker for task 173] INFO [org.apache.spark.executor.Executor] - Running task 20.0 in stage 13.0 (TID 173)
2021-12-03 20:37:35,120 [Executor task launch worker for task 172] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 20:37:35,120 [Executor task launch worker for task 172] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 1 ms
2021-12-03 20:37:35,122 [Executor task launch worker for task 173] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 20:37:35,122 [Executor task launch worker for task 173] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 20:37:35,128 [Executor task launch worker for task 154] INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 13.0 (TID 154). 1097 bytes result sent to driver
2021-12-03 20:37:35,129 [dispatcher-event-loop-5] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 21.0 in stage 13.0 (TID 174, localhost, executor driver, partition 21, ANY, 7759 bytes)
2021-12-03 20:37:35,129 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 13.0 (TID 154) in 131 ms on localhost (executor driver) (10/22)
2021-12-03 20:37:35,129 [Executor task launch worker for task 174] INFO [org.apache.spark.executor.Executor] - Running task 21.0 in stage 13.0 (TID 174)
2021-12-03 20:37:35,132 [Executor task launch worker for task 174] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 20:37:35,132 [Executor task launch worker for task 174] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 20:37:35,143 [Executor task launch worker for task 160] INFO [org.apache.spark.executor.Executor] - Finished task 7.0 in stage 13.0 (TID 160). 1054 bytes result sent to driver
2021-12-03 20:37:35,145 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 7.0 in stage 13.0 (TID 160) in 146 ms on localhost (executor driver) (11/22)
2021-12-03 20:37:35,166 [Executor task launch worker for task 155] INFO [org.apache.spark.executor.Executor] - Finished task 2.0 in stage 13.0 (TID 155). 557212 bytes result sent to driver
2021-12-03 20:37:35,172 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 2.0 in stage 13.0 (TID 155) in 173 ms on localhost (executor driver) (12/22)
2021-12-03 20:37:35,173 [Executor task launch worker for task 167] INFO [org.apache.spark.executor.Executor] - Finished task 14.0 in stage 13.0 (TID 167). 1097 bytes result sent to driver
2021-12-03 20:37:35,173 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 14.0 in stage 13.0 (TID 167) in 79 ms on localhost (executor driver) (13/22)
2021-12-03 20:37:35,178 [Executor task launch worker for task 165] INFO [org.apache.spark.executor.Executor] - Finished task 12.0 in stage 13.0 (TID 165). 1054 bytes result sent to driver
2021-12-03 20:37:35,179 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 12.0 in stage 13.0 (TID 165) in 93 ms on localhost (executor driver) (14/22)
2021-12-03 20:37:35,182 [Executor task launch worker for task 169] INFO [org.apache.spark.executor.Executor] - Finished task 16.0 in stage 13.0 (TID 169). 1054 bytes result sent to driver
2021-12-03 20:37:35,182 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 16.0 in stage 13.0 (TID 169) in 83 ms on localhost (executor driver) (15/22)
2021-12-03 20:37:35,192 [Executor task launch worker for task 166] INFO [org.apache.spark.executor.Executor] - Finished task 13.0 in stage 13.0 (TID 166). 1054 bytes result sent to driver
2021-12-03 20:37:35,192 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 13.0 in stage 13.0 (TID 166) in 104 ms on localhost (executor driver) (16/22)
2021-12-03 20:37:35,193 [Executor task launch worker for task 168] INFO [org.apache.spark.executor.Executor] - Finished task 15.0 in stage 13.0 (TID 168). 1097 bytes result sent to driver
2021-12-03 20:37:35,194 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 15.0 in stage 13.0 (TID 168) in 100 ms on localhost (executor driver) (17/22)
2021-12-03 20:37:35,206 [Executor task launch worker for task 172] INFO [org.apache.spark.executor.Executor] - Finished task 19.0 in stage 13.0 (TID 172). 1054 bytes result sent to driver
2021-12-03 20:37:35,206 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 19.0 in stage 13.0 (TID 172) in 91 ms on localhost (executor driver) (18/22)
2021-12-03 20:37:35,206 [Executor task launch worker for task 173] INFO [org.apache.spark.executor.Executor] - Finished task 20.0 in stage 13.0 (TID 173). 1054 bytes result sent to driver
2021-12-03 20:37:35,206 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 20.0 in stage 13.0 (TID 173) in 87 ms on localhost (executor driver) (19/22)
2021-12-03 20:37:35,207 [Executor task launch worker for task 171] INFO [org.apache.spark.executor.Executor] - Finished task 18.0 in stage 13.0 (TID 171). 1054 bytes result sent to driver
2021-12-03 20:37:35,208 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 18.0 in stage 13.0 (TID 171) in 101 ms on localhost (executor driver) (20/22)
2021-12-03 20:37:35,211 [Executor task launch worker for task 170] INFO [org.apache.spark.executor.Executor] - Finished task 17.0 in stage 13.0 (TID 170). 1054 bytes result sent to driver
2021-12-03 20:37:35,211 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 17.0 in stage 13.0 (TID 170) in 111 ms on localhost (executor driver) (21/22)
2021-12-03 20:37:35,216 [Executor task launch worker for task 174] INFO [org.apache.spark.executor.Executor] - Finished task 21.0 in stage 13.0 (TID 174). 1054 bytes result sent to driver
2021-12-03 20:37:35,216 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 21.0 in stage 13.0 (TID 174) in 87 ms on localhost (executor driver) (22/22)
2021-12-03 20:37:35,216 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 13.0, whose tasks have all completed, from pool 
2021-12-03 20:37:35,216 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 13 (takeSample at PaidPromotionAdjustParameter.scala:77) finished in 0.221 s
2021-12-03 20:37:35,216 [main] INFO [org.apache.spark.scheduler.DAGScheduler] - Job 5 finished: takeSample at PaidPromotionAdjustParameter.scala:77, took 0.222862 s
2021-12-03 20:37:35,218 [main] INFO [PaidPromotion$] - 小数据集个数：littleDeviceSet16770
2021-12-03 20:37:35,231 [main] INFO [org.apache.spark.SparkContext] - Starting job: count at PaidPromotionAdjustParameter.scala:84
2021-12-03 20:37:35,231 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 6 (count at PaidPromotionAdjustParameter.scala:84) with 22 output partitions
2021-12-03 20:37:35,231 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 14 (count at PaidPromotionAdjustParameter.scala:84)
2021-12-03 20:37:35,231 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List()
2021-12-03 20:37:35,231 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2021-12-03 20:37:35,232 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 14 (MapPartitionsRDD[13] at map at PaidPromotionAdjustParameter.scala:82), which has no missing parents
2021-12-03 20:37:35,238 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_9 stored as values in memory (estimated size 576.9 KB, free 1989.9 MB)
2021-12-03 20:37:35,240 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_9_piece0 stored as bytes in memory (estimated size 198.7 KB, free 1989.7 MB)
2021-12-03 20:37:35,240 [dispatcher-event-loop-3] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_9_piece0 in memory on qb:53199 (size: 198.7 KB, free: 1990.6 MB)
2021-12-03 20:37:35,241 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 9 from broadcast at DAGScheduler.scala:1039
2021-12-03 20:37:35,241 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 22 missing tasks from ResultStage 14 (MapPartitionsRDD[13] at map at PaidPromotionAdjustParameter.scala:82) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14))
2021-12-03 20:37:35,241 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 14.0 with 22 tasks
2021-12-03 20:37:35,241 [dispatcher-event-loop-4] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 14.0 (TID 175, localhost, executor driver, partition 0, ANY, 7899 bytes)
2021-12-03 20:37:35,242 [dispatcher-event-loop-4] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 14.0 (TID 176, localhost, executor driver, partition 1, ANY, 7899 bytes)
2021-12-03 20:37:35,242 [dispatcher-event-loop-4] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 2.0 in stage 14.0 (TID 177, localhost, executor driver, partition 2, ANY, 7899 bytes)
2021-12-03 20:37:35,242 [dispatcher-event-loop-4] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 3.0 in stage 14.0 (TID 178, localhost, executor driver, partition 3, ANY, 7899 bytes)
2021-12-03 20:37:35,242 [dispatcher-event-loop-4] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 4.0 in stage 14.0 (TID 179, localhost, executor driver, partition 4, ANY, 7899 bytes)
2021-12-03 20:37:35,242 [dispatcher-event-loop-4] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 5.0 in stage 14.0 (TID 180, localhost, executor driver, partition 5, ANY, 7899 bytes)
2021-12-03 20:37:35,242 [dispatcher-event-loop-4] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 6.0 in stage 14.0 (TID 181, localhost, executor driver, partition 6, ANY, 7899 bytes)
2021-12-03 20:37:35,242 [dispatcher-event-loop-4] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 7.0 in stage 14.0 (TID 182, localhost, executor driver, partition 7, ANY, 7899 bytes)
2021-12-03 20:37:35,242 [dispatcher-event-loop-4] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 8.0 in stage 14.0 (TID 183, localhost, executor driver, partition 8, ANY, 7899 bytes)
2021-12-03 20:37:35,242 [dispatcher-event-loop-4] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 9.0 in stage 14.0 (TID 184, localhost, executor driver, partition 9, ANY, 7899 bytes)
2021-12-03 20:37:35,242 [dispatcher-event-loop-4] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 10.0 in stage 14.0 (TID 185, localhost, executor driver, partition 10, ANY, 7899 bytes)
2021-12-03 20:37:35,243 [dispatcher-event-loop-4] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 11.0 in stage 14.0 (TID 186, localhost, executor driver, partition 11, ANY, 7899 bytes)
2021-12-03 20:37:35,243 [Executor task launch worker for task 176] INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 14.0 (TID 176)
2021-12-03 20:37:35,243 [Executor task launch worker for task 183] INFO [org.apache.spark.executor.Executor] - Running task 8.0 in stage 14.0 (TID 183)
2021-12-03 20:37:35,243 [Executor task launch worker for task 177] INFO [org.apache.spark.executor.Executor] - Running task 2.0 in stage 14.0 (TID 177)
2021-12-03 20:37:35,243 [Executor task launch worker for task 182] INFO [org.apache.spark.executor.Executor] - Running task 7.0 in stage 14.0 (TID 182)
2021-12-03 20:37:35,243 [Executor task launch worker for task 178] INFO [org.apache.spark.executor.Executor] - Running task 3.0 in stage 14.0 (TID 178)
2021-12-03 20:37:35,243 [Executor task launch worker for task 181] INFO [org.apache.spark.executor.Executor] - Running task 6.0 in stage 14.0 (TID 181)
2021-12-03 20:37:35,243 [Executor task launch worker for task 180] INFO [org.apache.spark.executor.Executor] - Running task 5.0 in stage 14.0 (TID 180)
2021-12-03 20:37:35,243 [Executor task launch worker for task 179] INFO [org.apache.spark.executor.Executor] - Running task 4.0 in stage 14.0 (TID 179)
2021-12-03 20:37:35,243 [Executor task launch worker for task 175] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 14.0 (TID 175)
2021-12-03 20:37:35,243 [Executor task launch worker for task 186] INFO [org.apache.spark.executor.Executor] - Running task 11.0 in stage 14.0 (TID 186)
2021-12-03 20:37:35,243 [Executor task launch worker for task 185] INFO [org.apache.spark.executor.Executor] - Running task 10.0 in stage 14.0 (TID 185)
2021-12-03 20:37:35,243 [Executor task launch worker for task 184] INFO [org.apache.spark.executor.Executor] - Running task 9.0 in stage 14.0 (TID 184)
2021-12-03 20:37:35,271 [Executor task launch worker for task 183] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:1073741824+134217728
2021-12-03 20:37:35,271 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 188
2021-12-03 20:37:35,271 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 173
2021-12-03 20:37:35,271 [Executor task launch worker for task 184] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:1207959552+134217728
2021-12-03 20:37:35,271 [Executor task launch worker for task 186] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:1476395008+134217728
2021-12-03 20:37:35,272 [Executor task launch worker for task 176] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:134217728+134217728
2021-12-03 20:37:35,271 [Executor task launch worker for task 175] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:0+134217728
2021-12-03 20:37:35,272 [Executor task launch worker for task 177] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:268435456+134217728
2021-12-03 20:37:35,271 [Executor task launch worker for task 182] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:939524096+134217728
2021-12-03 20:37:35,272 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 178
2021-12-03 20:37:35,271 [Executor task launch worker for task 185] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:1342177280+134217728
2021-12-03 20:37:35,272 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 158
2021-12-03 20:37:35,272 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 172
2021-12-03 20:37:35,273 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 195
2021-12-03 20:37:35,273 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 152
2021-12-03 20:37:35,273 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 169
2021-12-03 20:37:35,273 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 183
2021-12-03 20:37:35,273 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 194
2021-12-03 20:37:35,273 [dispatcher-event-loop-10] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_7_piece0 on qb:53199 in memory (size: 2.4 KB, free: 1990.6 MB)
2021-12-03 20:37:35,273 [Executor task launch worker for task 180] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:671088640+134217728
2021-12-03 20:37:35,274 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 166
2021-12-03 20:37:35,274 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 193
2021-12-03 20:37:35,274 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 165
2021-12-03 20:37:35,274 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 191
2021-12-03 20:37:35,274 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 181
2021-12-03 20:37:35,274 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 175
2021-12-03 20:37:35,274 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 198
2021-12-03 20:37:35,274 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 182
2021-12-03 20:37:35,274 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 159
2021-12-03 20:37:35,274 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 180
2021-12-03 20:37:35,274 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 197
2021-12-03 20:37:35,274 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 196
2021-12-03 20:37:35,274 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 179
2021-12-03 20:37:35,274 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 189
2021-12-03 20:37:35,274 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 186
2021-12-03 20:37:35,274 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 163
2021-12-03 20:37:35,275 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 177
2021-12-03 20:37:35,275 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 176
2021-12-03 20:37:35,275 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 155
2021-12-03 20:37:35,275 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 160
2021-12-03 20:37:35,275 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 174
2021-12-03 20:37:35,275 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 157
2021-12-03 20:37:35,275 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 150
2021-12-03 20:37:35,275 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 168
2021-12-03 20:37:35,275 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 187
2021-12-03 20:37:35,275 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 185
2021-12-03 20:37:35,275 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 171
2021-12-03 20:37:35,275 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 151
2021-12-03 20:37:35,275 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 192
2021-12-03 20:37:35,275 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 161
2021-12-03 20:37:35,275 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 162
2021-12-03 20:37:35,275 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 170
2021-12-03 20:37:35,275 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 156
2021-12-03 20:37:35,275 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 153
2021-12-03 20:37:35,275 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 167
2021-12-03 20:37:35,275 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 199
2021-12-03 20:37:35,275 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 190
2021-12-03 20:37:35,275 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 164
2021-12-03 20:37:35,276 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 154
2021-12-03 20:37:35,276 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 184
2021-12-03 20:37:35,277 [dispatcher-event-loop-6] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_8_piece0 on qb:53199 in memory (size: 2.5 KB, free: 1990.6 MB)
2021-12-03 20:37:35,277 [Executor task launch worker for task 178] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:402653184+134217728
2021-12-03 20:37:35,278 [Executor task launch worker for task 179] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:536870912+134217728
2021-12-03 20:37:35,279 [Executor task launch worker for task 181] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:805306368+134217728
2021-12-03 20:41:44,116 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 136
2021-12-03 20:41:44,116 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 85
2021-12-03 20:41:44,116 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 29
2021-12-03 20:41:44,116 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 27
2021-12-03 20:41:44,116 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 122
2021-12-03 20:41:44,116 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 117
2021-12-03 20:41:44,116 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 138
2021-12-03 20:41:44,116 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 74
2021-12-03 20:41:44,116 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 119
2021-12-03 20:41:44,116 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 55
2021-12-03 20:41:44,116 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 98
2021-12-03 20:41:44,116 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 58
2021-12-03 20:41:44,116 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 81
2021-12-03 20:41:44,116 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 112
2021-12-03 20:41:44,116 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 75
2021-12-03 20:41:44,116 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 107
2021-12-03 20:41:44,116 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 28
2021-12-03 20:41:44,117 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 32
2021-12-03 20:41:44,117 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 50
2021-12-03 20:41:44,117 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 30
2021-12-03 20:41:44,117 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 116
2021-12-03 20:41:44,117 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 123
2021-12-03 20:41:44,117 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 46
2021-12-03 20:41:44,117 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 110
2021-12-03 20:41:44,117 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 77
2021-12-03 20:41:44,117 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 95
2021-12-03 20:41:44,117 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 115
2021-12-03 20:41:44,117 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 113
2021-12-03 20:41:44,117 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 83
2021-12-03 20:41:44,117 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 37
2021-12-03 20:41:44,117 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 141
2021-12-03 20:41:44,117 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 127
2021-12-03 20:41:44,117 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 71
2021-12-03 20:41:44,117 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 137
2021-12-03 20:41:44,117 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 86
2021-12-03 20:41:44,117 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 31
2021-12-03 20:41:44,117 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 38
2021-12-03 20:41:44,117 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 132
2021-12-03 20:41:44,117 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 43
2021-12-03 20:41:44,117 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 93
2021-12-03 20:41:44,117 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 73
2021-12-03 20:41:44,117 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 36
2021-12-03 20:41:44,117 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 129
2021-12-03 20:41:44,118 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 144
2021-12-03 20:41:44,118 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 125
2021-12-03 20:41:44,118 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 145
2021-12-03 20:41:44,118 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 26
2021-12-03 20:41:44,118 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 57
2021-12-03 20:41:44,118 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 88
2021-12-03 20:41:44,118 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 65
2021-12-03 20:41:44,118 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 78
2021-12-03 20:41:44,118 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 82
2021-12-03 20:41:44,118 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 89
2021-12-03 20:41:44,118 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 108
2021-12-03 20:41:44,118 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 39
2021-12-03 20:41:44,118 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 91
2021-12-03 20:41:44,118 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 76
2021-12-03 20:41:44,118 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 143
2021-12-03 20:41:44,118 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 102
2021-12-03 20:41:44,156 [dispatcher-event-loop-10] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_5_piece0 on qb:53199 in memory (size: 2.4 KB, free: 1990.6 MB)
2021-12-03 20:41:44,222 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 133
2021-12-03 20:41:44,222 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 40
2021-12-03 20:41:44,222 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 94
2021-12-03 20:41:44,222 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 118
2021-12-03 20:41:44,222 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 84
2021-12-03 20:41:44,222 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 70
2021-12-03 20:41:44,222 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 126
2021-12-03 20:41:44,222 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 139
2021-12-03 20:41:44,222 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 49
2021-12-03 20:41:44,222 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 54
2021-12-03 20:41:44,222 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 56
2021-12-03 20:41:44,222 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 41
2021-12-03 20:41:44,222 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 69
2021-12-03 20:41:44,222 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 120
2021-12-03 20:41:44,222 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 114
2021-12-03 20:41:44,222 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 109
2021-12-03 20:41:44,222 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 142
2021-12-03 20:41:44,222 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 52
2021-12-03 20:41:44,222 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 103
2021-12-03 20:41:44,222 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 135
2021-12-03 20:41:44,223 [dispatcher-event-loop-6] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_2_piece0 on qb:53199 in memory (size: 2.7 KB, free: 1990.6 MB)
2021-12-03 20:41:44,224 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 100
2021-12-03 20:41:44,224 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 62
2021-12-03 20:41:44,224 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 60
2021-12-03 20:41:44,224 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 105
2021-12-03 20:41:44,224 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 87
2021-12-03 20:41:44,224 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 53
2021-12-03 20:41:44,224 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 97
2021-12-03 20:41:44,224 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 128
2021-12-03 20:41:44,224 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 63
2021-12-03 20:41:44,224 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 149
2021-12-03 20:41:44,224 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 33
2021-12-03 20:41:44,224 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 92
2021-12-03 20:41:44,224 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 59
2021-12-03 20:41:44,224 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 104
2021-12-03 20:41:44,224 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 124
2021-12-03 20:41:44,224 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 42
2021-12-03 20:41:44,224 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 146
2021-12-03 20:41:44,224 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 35
2021-12-03 20:41:44,224 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 147
2021-12-03 20:41:44,224 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 121
2021-12-03 20:41:44,224 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 140
2021-12-03 20:41:44,224 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 48
2021-12-03 20:41:44,224 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 61
2021-12-03 20:41:44,224 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 47
2021-12-03 20:41:44,224 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 25
2021-12-03 20:41:44,224 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 148
2021-12-03 20:41:44,224 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 68
2021-12-03 20:41:44,224 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 64
2021-12-03 20:41:44,224 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 51
2021-12-03 20:41:44,224 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 96
2021-12-03 20:41:44,224 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 72
2021-12-03 20:41:44,224 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 106
2021-12-03 20:41:44,224 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 101
2021-12-03 20:41:44,224 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 131
2021-12-03 20:41:44,224 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 134
2021-12-03 20:41:44,224 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 66
2021-12-03 20:41:44,224 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 80
2021-12-03 20:41:44,224 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 44
2021-12-03 20:41:44,224 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 90
2021-12-03 20:41:44,224 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 99
2021-12-03 20:41:44,224 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 130
2021-12-03 20:41:44,224 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 34
2021-12-03 20:41:44,224 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 111
2021-12-03 20:41:44,224 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 67
2021-12-03 20:41:44,224 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 79
2021-12-03 20:41:44,224 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 45
2021-12-03 20:59:40,997 [Executor task launch worker for task 185] INFO [org.apache.spark.executor.Executor] - Finished task 10.0 in stage 14.0 (TID 185). 754 bytes result sent to driver
2021-12-03 20:59:40,999 [dispatcher-event-loop-5] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 12.0 in stage 14.0 (TID 187, localhost, executor driver, partition 12, ANY, 7899 bytes)
2021-12-03 20:59:40,999 [Executor task launch worker for task 187] INFO [org.apache.spark.executor.Executor] - Running task 12.0 in stage 14.0 (TID 187)
2021-12-03 20:59:41,000 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 10.0 in stage 14.0 (TID 185) in 1325758 ms on localhost (executor driver) (1/22)
2021-12-03 20:59:41,007 [Executor task launch worker for task 187] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:1610612736+134217728
2021-12-03 20:59:53,223 [Executor task launch worker for task 184] INFO [org.apache.spark.executor.Executor] - Finished task 9.0 in stage 14.0 (TID 184). 754 bytes result sent to driver
2021-12-03 20:59:53,224 [dispatcher-event-loop-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 13.0 in stage 14.0 (TID 188, localhost, executor driver, partition 13, ANY, 7899 bytes)
2021-12-03 20:59:53,224 [Executor task launch worker for task 188] INFO [org.apache.spark.executor.Executor] - Running task 13.0 in stage 14.0 (TID 188)
2021-12-03 20:59:53,224 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 9.0 in stage 14.0 (TID 184) in 1337982 ms on localhost (executor driver) (2/22)
2021-12-03 20:59:53,237 [Executor task launch worker for task 188] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:1744830464+134217728
2021-12-03 21:00:01,848 [Executor task launch worker for task 183] INFO [org.apache.spark.executor.Executor] - Finished task 8.0 in stage 14.0 (TID 183). 754 bytes result sent to driver
2021-12-03 21:00:01,850 [dispatcher-event-loop-9] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 14.0 in stage 14.0 (TID 189, localhost, executor driver, partition 14, ANY, 7899 bytes)
2021-12-03 21:00:01,850 [Executor task launch worker for task 189] INFO [org.apache.spark.executor.Executor] - Running task 14.0 in stage 14.0 (TID 189)
2021-12-03 21:00:01,850 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 8.0 in stage 14.0 (TID 183) in 1346608 ms on localhost (executor driver) (3/22)
2021-12-03 21:00:01,857 [Executor task launch worker for task 189] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:1879048192+134217728
2021-12-03 21:00:07,451 [Executor task launch worker for task 182] INFO [org.apache.spark.executor.Executor] - Finished task 7.0 in stage 14.0 (TID 182). 754 bytes result sent to driver
2021-12-03 21:00:07,451 [dispatcher-event-loop-4] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 15.0 in stage 14.0 (TID 190, localhost, executor driver, partition 15, ANY, 7899 bytes)
2021-12-03 21:00:07,451 [Executor task launch worker for task 190] INFO [org.apache.spark.executor.Executor] - Running task 15.0 in stage 14.0 (TID 190)
2021-12-03 21:00:07,457 [Executor task launch worker for task 190] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:2013265920+134217728
2021-12-03 21:00:07,458 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 7.0 in stage 14.0 (TID 182) in 1352216 ms on localhost (executor driver) (4/22)
2021-12-03 21:00:17,384 [Executor task launch worker for task 176] INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 14.0 (TID 176). 754 bytes result sent to driver
2021-12-03 21:00:17,388 [dispatcher-event-loop-11] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 16.0 in stage 14.0 (TID 191, localhost, executor driver, partition 16, ANY, 7899 bytes)
2021-12-03 21:00:17,388 [Executor task launch worker for task 191] INFO [org.apache.spark.executor.Executor] - Running task 16.0 in stage 14.0 (TID 191)
2021-12-03 21:00:17,391 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 14.0 (TID 176) in 1362150 ms on localhost (executor driver) (5/22)
2021-12-03 21:00:17,394 [Executor task launch worker for task 191] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:2147483648+134217728
2021-12-03 21:00:55,118 [Executor task launch worker for task 186] INFO [org.apache.spark.executor.Executor] - Finished task 11.0 in stage 14.0 (TID 186). 754 bytes result sent to driver
2021-12-03 21:00:55,118 [dispatcher-event-loop-8] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 17.0 in stage 14.0 (TID 192, localhost, executor driver, partition 17, ANY, 7899 bytes)
2021-12-03 21:00:55,119 [Executor task launch worker for task 192] INFO [org.apache.spark.executor.Executor] - Running task 17.0 in stage 14.0 (TID 192)
2021-12-03 21:00:55,124 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 11.0 in stage 14.0 (TID 186) in 1399881 ms on localhost (executor driver) (6/22)
2021-12-03 21:00:55,124 [Executor task launch worker for task 192] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:2281701376+134217728
2021-12-03 21:01:13,197 [Executor task launch worker for task 178] INFO [org.apache.spark.executor.Executor] - Finished task 3.0 in stage 14.0 (TID 178). 754 bytes result sent to driver
2021-12-03 21:01:13,197 [dispatcher-event-loop-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 18.0 in stage 14.0 (TID 193, localhost, executor driver, partition 18, ANY, 7899 bytes)
2021-12-03 21:01:13,198 [Executor task launch worker for task 193] INFO [org.apache.spark.executor.Executor] - Running task 18.0 in stage 14.0 (TID 193)
2021-12-03 21:01:13,198 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 3.0 in stage 14.0 (TID 178) in 1417956 ms on localhost (executor driver) (7/22)
2021-12-03 21:01:13,203 [Executor task launch worker for task 193] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:2415919104+134217728
2021-12-03 21:02:03,438 [Executor task launch worker for task 175] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 14.0 (TID 175). 754 bytes result sent to driver
2021-12-03 21:02:03,444 [dispatcher-event-loop-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 19.0 in stage 14.0 (TID 194, localhost, executor driver, partition 19, ANY, 7899 bytes)
2021-12-03 21:02:03,444 [Executor task launch worker for task 194] INFO [org.apache.spark.executor.Executor] - Running task 19.0 in stage 14.0 (TID 194)
2021-12-03 21:02:03,446 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 14.0 (TID 175) in 1468203 ms on localhost (executor driver) (8/22)
2021-12-03 21:02:03,450 [Executor task launch worker for task 194] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:2550136832+134217728
2021-12-03 21:06:01,352 [Executor task launch worker for task 180] INFO [org.apache.spark.executor.Executor] - Finished task 5.0 in stage 14.0 (TID 180). 754 bytes result sent to driver
2021-12-03 21:06:01,352 [dispatcher-event-loop-8] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 20.0 in stage 14.0 (TID 195, localhost, executor driver, partition 20, ANY, 7899 bytes)
2021-12-03 21:06:01,352 [Executor task launch worker for task 195] INFO [org.apache.spark.executor.Executor] - Running task 20.0 in stage 14.0 (TID 195)
2021-12-03 21:06:01,358 [Executor task launch worker for task 195] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:2684354560+134217728
2021-12-03 21:06:01,369 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 5.0 in stage 14.0 (TID 180) in 1706126 ms on localhost (executor driver) (9/22)
2021-12-03 21:06:27,696 [Executor task launch worker for task 179] INFO [org.apache.spark.executor.Executor] - Finished task 4.0 in stage 14.0 (TID 179). 754 bytes result sent to driver
2021-12-03 21:06:27,697 [dispatcher-event-loop-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 21.0 in stage 14.0 (TID 196, localhost, executor driver, partition 21, ANY, 7899 bytes)
2021-12-03 21:06:27,697 [Executor task launch worker for task 196] INFO [org.apache.spark.executor.Executor] - Running task 21.0 in stage 14.0 (TID 196)
2021-12-03 21:06:27,702 [Executor task launch worker for task 196] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:2818572288+147216171
2021-12-03 21:06:27,706 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 4.0 in stage 14.0 (TID 179) in 1732464 ms on localhost (executor driver) (10/22)
2021-12-03 21:06:30,704 [Executor task launch worker for task 177] INFO [org.apache.spark.executor.Executor] - Finished task 2.0 in stage 14.0 (TID 177). 754 bytes result sent to driver
2021-12-03 21:06:30,707 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 2.0 in stage 14.0 (TID 177) in 1735464 ms on localhost (executor driver) (11/22)
2021-12-03 21:07:52,377 [Executor task launch worker for task 181] INFO [org.apache.spark.executor.Executor] - Finished task 6.0 in stage 14.0 (TID 181). 754 bytes result sent to driver
2021-12-03 21:07:52,378 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 6.0 in stage 14.0 (TID 181) in 1817136 ms on localhost (executor driver) (12/22)
2021-12-03 21:20:59,476 [main] INFO [org.apache.spark.SparkContext] - Running Spark version 2.3.0
2021-12-03 21:20:59,779 [main] INFO [org.apache.spark.SparkContext] - Submitted application: PaidPromotion
2021-12-03 21:20:59,831 [main] INFO [org.apache.spark.SecurityManager] - Changing view acls to: ACER,root
2021-12-03 21:20:59,832 [main] INFO [org.apache.spark.SecurityManager] - Changing modify acls to: ACER,root
2021-12-03 21:20:59,832 [main] INFO [org.apache.spark.SecurityManager] - Changing view acls groups to: 
2021-12-03 21:20:59,832 [main] INFO [org.apache.spark.SecurityManager] - Changing modify acls groups to: 
2021-12-03 21:20:59,833 [main] INFO [org.apache.spark.SecurityManager] - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(ACER, root); groups with view permissions: Set(); users  with modify permissions: Set(ACER, root); groups with modify permissions: Set()
2021-12-03 21:21:00,499 [main] INFO [org.apache.spark.util.Utils] - Successfully started service 'sparkDriver' on port 61588.
2021-12-03 21:21:00,527 [main] INFO [org.apache.spark.SparkEnv] - Registering MapOutputTracker
2021-12-03 21:21:00,545 [main] INFO [org.apache.spark.SparkEnv] - Registering BlockManagerMaster
2021-12-03 21:21:00,548 [main] INFO [org.apache.spark.storage.BlockManagerMasterEndpoint] - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2021-12-03 21:21:00,548 [main] INFO [org.apache.spark.storage.BlockManagerMasterEndpoint] - BlockManagerMasterEndpoint up
2021-12-03 21:21:00,557 [main] INFO [org.apache.spark.storage.DiskBlockManager] - Created local directory at C:\Users\ACER\AppData\Local\Temp\blockmgr-880a3ee9-c6aa-4bde-b231-936a87a9a6d1
2021-12-03 21:21:00,574 [main] INFO [org.apache.spark.storage.memory.MemoryStore] - MemoryStore started with capacity 1990.8 MB
2021-12-03 21:21:00,588 [main] INFO [org.apache.spark.SparkEnv] - Registering OutputCommitCoordinator
2021-12-03 21:21:00,660 [main] INFO [org.spark_project.jetty.util.log] - Logging initialized @2253ms
2021-12-03 21:21:00,730 [main] INFO [org.spark_project.jetty.server.Server] - jetty-9.3.z-SNAPSHOT
2021-12-03 21:21:00,747 [main] INFO [org.spark_project.jetty.server.Server] - Started @2340ms
2021-12-03 21:21:00,790 [main] INFO [org.spark_project.jetty.server.AbstractConnector] - Started ServerConnector@3414a8c3{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2021-12-03 21:21:00,790 [main] INFO [org.apache.spark.util.Utils] - Successfully started service 'SparkUI' on port 4040.
2021-12-03 21:21:00,817 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@27b45ea{/jobs,null,AVAILABLE,@Spark}
2021-12-03 21:21:00,818 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@4fc142ec{/jobs/json,null,AVAILABLE,@Spark}
2021-12-03 21:21:00,819 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@702b06fb{/jobs/job,null,AVAILABLE,@Spark}
2021-12-03 21:21:00,821 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@2b22a1cc{/jobs/job/json,null,AVAILABLE,@Spark}
2021-12-03 21:21:00,823 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@7fd8c559{/stages,null,AVAILABLE,@Spark}
2021-12-03 21:21:00,824 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@55a88417{/stages/json,null,AVAILABLE,@Spark}
2021-12-03 21:21:00,825 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@19962194{/stages/stage,null,AVAILABLE,@Spark}
2021-12-03 21:21:00,828 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@3cbf1ba4{/stages/stage/json,null,AVAILABLE,@Spark}
2021-12-03 21:21:00,829 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@3dd818e8{/stages/pool,null,AVAILABLE,@Spark}
2021-12-03 21:21:00,830 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@47b67fcb{/stages/pool/json,null,AVAILABLE,@Spark}
2021-12-03 21:21:00,831 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@66420549{/storage,null,AVAILABLE,@Spark}
2021-12-03 21:21:00,832 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@42b28ff1{/storage/json,null,AVAILABLE,@Spark}
2021-12-03 21:21:00,833 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@706fe5c6{/storage/rdd,null,AVAILABLE,@Spark}
2021-12-03 21:21:00,835 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@6b3f6585{/storage/rdd/json,null,AVAILABLE,@Spark}
2021-12-03 21:21:00,837 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@64469d8{/environment,null,AVAILABLE,@Spark}
2021-12-03 21:21:00,838 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@1cec219f{/environment/json,null,AVAILABLE,@Spark}
2021-12-03 21:21:00,841 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@3cb8c8ce{/executors,null,AVAILABLE,@Spark}
2021-12-03 21:21:00,842 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@260a3a5e{/executors/json,null,AVAILABLE,@Spark}
2021-12-03 21:21:00,844 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@2e51d054{/executors/threadDump,null,AVAILABLE,@Spark}
2021-12-03 21:21:00,846 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@608bc8f8{/executors/threadDump/json,null,AVAILABLE,@Spark}
2021-12-03 21:21:00,852 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@381d7219{/static,null,AVAILABLE,@Spark}
2021-12-03 21:21:00,854 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@5f117b3d{/,null,AVAILABLE,@Spark}
2021-12-03 21:21:00,856 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@11f406f8{/api,null,AVAILABLE,@Spark}
2021-12-03 21:21:00,857 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@fb713e7{/jobs/job/kill,null,AVAILABLE,@Spark}
2021-12-03 21:21:00,859 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@35f639fa{/stages/stage/kill,null,AVAILABLE,@Spark}
2021-12-03 21:21:00,861 [main] INFO [org.apache.spark.ui.SparkUI] - Bound SparkUI to 0.0.0.0, and started at http://qb:4040
2021-12-03 21:21:00,983 [main] INFO [org.apache.spark.executor.Executor] - Starting executor ID driver on host localhost
2021-12-03 21:21:01,061 [main] INFO [org.apache.spark.util.Utils] - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 61634.
2021-12-03 21:21:01,062 [main] INFO [org.apache.spark.network.netty.NettyBlockTransferService] - Server created on qb:61634
2021-12-03 21:21:01,063 [main] INFO [org.apache.spark.storage.BlockManager] - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2021-12-03 21:21:01,064 [main] INFO [org.apache.spark.storage.BlockManagerMaster] - Registering BlockManager BlockManagerId(driver, qb, 61634, None)
2021-12-03 21:21:01,066 [dispatcher-event-loop-10] INFO [org.apache.spark.storage.BlockManagerMasterEndpoint] - Registering block manager qb:61634 with 1990.8 MB RAM, BlockManagerId(driver, qb, 61634, None)
2021-12-03 21:21:01,068 [main] INFO [org.apache.spark.storage.BlockManagerMaster] - Registered BlockManager BlockManagerId(driver, qb, 61634, None)
2021-12-03 21:21:01,068 [main] INFO [org.apache.spark.storage.BlockManager] - Initialized BlockManager: BlockManagerId(driver, qb, 61634, None)
2021-12-03 21:21:01,253 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@30893e08{/metrics/json,null,AVAILABLE,@Spark}
2021-12-03 21:21:01,825 [main] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_0 stored as values in memory (estimated size 312.7 KB, free 1990.5 MB)
2021-12-03 21:21:02,086 [main] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_0_piece0 stored as bytes in memory (estimated size 27.3 KB, free 1990.5 MB)
2021-12-03 21:21:02,089 [dispatcher-event-loop-0] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_0_piece0 in memory on qb:61634 (size: 27.3 KB, free: 1990.8 MB)
2021-12-03 21:21:02,092 [main] INFO [org.apache.spark.SparkContext] - Created broadcast 0 from textFile at PaidPromotionAdjustParameter.scala:57
2021-12-03 21:21:02,445 [main] WARN [org.apache.hadoop.hdfs.shortcircuit.DomainSocketFactory] - The short-circuit local reads feature cannot be used because UNIX Domain sockets are not available on Windows.
2021-12-03 21:21:02,518 [main] INFO [org.apache.hadoop.mapred.FileInputFormat] - Total input paths to process : 1
2021-12-03 21:21:02,552 [main] INFO [org.apache.hadoop.net.NetworkTopology] - Adding a new node: /default-rack/172.16.1.222:50010
2021-12-03 21:21:02,553 [main] INFO [org.apache.hadoop.net.NetworkTopology] - Adding a new node: /default-rack/192.168.1.33:50010
2021-12-03 21:21:02,553 [main] INFO [org.apache.hadoop.net.NetworkTopology] - Adding a new node: /default-rack/192.168.1.34:50010
2021-12-03 21:21:02,559 [main] INFO [org.apache.spark.SparkContext] - Starting job: count at PaidPromotionAdjustParameter.scala:59
2021-12-03 21:21:02,569 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 0 (count at PaidPromotionAdjustParameter.scala:59) with 22 output partitions
2021-12-03 21:21:02,569 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 0 (count at PaidPromotionAdjustParameter.scala:59)
2021-12-03 21:21:02,569 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List()
2021-12-03 21:21:02,570 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2021-12-03 21:21:02,576 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 0 (/sk/chongqing/data/behavior_data.bcp MapPartitionsRDD[1] at textFile at PaidPromotionAdjustParameter.scala:57), which has no missing parents
2021-12-03 21:21:02,607 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_1 stored as values in memory (estimated size 3.1 KB, free 1990.5 MB)
2021-12-03 21:21:02,613 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_1_piece0 stored as bytes in memory (estimated size 1903.0 B, free 1990.5 MB)
2021-12-03 21:21:02,613 [dispatcher-event-loop-1] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_1_piece0 in memory on qb:61634 (size: 1903.0 B, free: 1990.8 MB)
2021-12-03 21:21:02,614 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 1 from broadcast at DAGScheduler.scala:1039
2021-12-03 21:21:02,623 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 22 missing tasks from ResultStage 0 (/sk/chongqing/data/behavior_data.bcp MapPartitionsRDD[1] at textFile at PaidPromotionAdjustParameter.scala:57) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14))
2021-12-03 21:21:02,624 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 0.0 with 22 tasks
2021-12-03 21:21:02,657 [dispatcher-event-loop-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 0.0 (TID 0, localhost, executor driver, partition 0, ANY, 7899 bytes)
2021-12-03 21:21:02,659 [dispatcher-event-loop-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 0.0 (TID 1, localhost, executor driver, partition 1, ANY, 7899 bytes)
2021-12-03 21:21:02,659 [dispatcher-event-loop-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 2.0 in stage 0.0 (TID 2, localhost, executor driver, partition 2, ANY, 7899 bytes)
2021-12-03 21:21:02,660 [dispatcher-event-loop-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 3.0 in stage 0.0 (TID 3, localhost, executor driver, partition 3, ANY, 7899 bytes)
2021-12-03 21:21:02,660 [dispatcher-event-loop-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 4.0 in stage 0.0 (TID 4, localhost, executor driver, partition 4, ANY, 7899 bytes)
2021-12-03 21:21:02,661 [dispatcher-event-loop-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 5.0 in stage 0.0 (TID 5, localhost, executor driver, partition 5, ANY, 7899 bytes)
2021-12-03 21:21:02,661 [dispatcher-event-loop-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 6.0 in stage 0.0 (TID 6, localhost, executor driver, partition 6, ANY, 7899 bytes)
2021-12-03 21:21:02,661 [dispatcher-event-loop-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 7.0 in stage 0.0 (TID 7, localhost, executor driver, partition 7, ANY, 7899 bytes)
2021-12-03 21:21:02,662 [dispatcher-event-loop-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 8.0 in stage 0.0 (TID 8, localhost, executor driver, partition 8, ANY, 7899 bytes)
2021-12-03 21:21:02,662 [dispatcher-event-loop-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 9.0 in stage 0.0 (TID 9, localhost, executor driver, partition 9, ANY, 7899 bytes)
2021-12-03 21:21:02,663 [dispatcher-event-loop-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 10.0 in stage 0.0 (TID 10, localhost, executor driver, partition 10, ANY, 7899 bytes)
2021-12-03 21:21:02,663 [dispatcher-event-loop-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 11.0 in stage 0.0 (TID 11, localhost, executor driver, partition 11, ANY, 7899 bytes)
2021-12-03 21:21:02,668 [Executor task launch worker for task 10] INFO [org.apache.spark.executor.Executor] - Running task 10.0 in stage 0.0 (TID 10)
2021-12-03 21:21:02,668 [Executor task launch worker for task 7] INFO [org.apache.spark.executor.Executor] - Running task 7.0 in stage 0.0 (TID 7)
2021-12-03 21:21:02,668 [Executor task launch worker for task 4] INFO [org.apache.spark.executor.Executor] - Running task 4.0 in stage 0.0 (TID 4)
2021-12-03 21:21:02,668 [Executor task launch worker for task 6] INFO [org.apache.spark.executor.Executor] - Running task 6.0 in stage 0.0 (TID 6)
2021-12-03 21:21:02,668 [Executor task launch worker for task 8] INFO [org.apache.spark.executor.Executor] - Running task 8.0 in stage 0.0 (TID 8)
2021-12-03 21:21:02,668 [Executor task launch worker for task 5] INFO [org.apache.spark.executor.Executor] - Running task 5.0 in stage 0.0 (TID 5)
2021-12-03 21:21:02,668 [Executor task launch worker for task 3] INFO [org.apache.spark.executor.Executor] - Running task 3.0 in stage 0.0 (TID 3)
2021-12-03 21:21:02,668 [Executor task launch worker for task 11] INFO [org.apache.spark.executor.Executor] - Running task 11.0 in stage 0.0 (TID 11)
2021-12-03 21:21:02,668 [Executor task launch worker for task 1] INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 0.0 (TID 1)
2021-12-03 21:21:02,668 [Executor task launch worker for task 0] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 0.0 (TID 0)
2021-12-03 21:21:02,668 [Executor task launch worker for task 2] INFO [org.apache.spark.executor.Executor] - Running task 2.0 in stage 0.0 (TID 2)
2021-12-03 21:21:02,668 [Executor task launch worker for task 9] INFO [org.apache.spark.executor.Executor] - Running task 9.0 in stage 0.0 (TID 9)
2021-12-03 21:21:02,720 [Executor task launch worker for task 2] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:268435456+134217728
2021-12-03 21:21:02,720 [Executor task launch worker for task 1] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:134217728+134217728
2021-12-03 21:21:02,720 [Executor task launch worker for task 4] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:536870912+134217728
2021-12-03 21:21:02,720 [Executor task launch worker for task 8] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:1073741824+134217728
2021-12-03 21:21:02,720 [Executor task launch worker for task 10] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:1342177280+134217728
2021-12-03 21:21:02,720 [Executor task launch worker for task 5] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:671088640+134217728
2021-12-03 21:21:02,720 [Executor task launch worker for task 3] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:402653184+134217728
2021-12-03 21:21:02,720 [Executor task launch worker for task 11] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:1476395008+134217728
2021-12-03 21:21:02,720 [Executor task launch worker for task 6] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:805306368+134217728
2021-12-03 21:21:02,720 [Executor task launch worker for task 7] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:939524096+134217728
2021-12-03 21:21:02,720 [Executor task launch worker for task 0] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:0+134217728
2021-12-03 21:21:02,720 [Executor task launch worker for task 9] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:1207959552+134217728
2021-12-03 21:22:53,908 [Executor task launch worker for task 5] INFO [org.apache.spark.executor.Executor] - Finished task 5.0 in stage 0.0 (TID 5). 798 bytes result sent to driver
2021-12-03 21:22:53,910 [dispatcher-event-loop-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 12.0 in stage 0.0 (TID 12, localhost, executor driver, partition 12, ANY, 7899 bytes)
2021-12-03 21:22:53,910 [Executor task launch worker for task 12] INFO [org.apache.spark.executor.Executor] - Running task 12.0 in stage 0.0 (TID 12)
2021-12-03 21:22:53,912 [Executor task launch worker for task 12] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:1610612736+134217728
2021-12-03 21:22:53,919 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 5.0 in stage 0.0 (TID 5) in 111258 ms on localhost (executor driver) (1/22)
2021-12-03 21:23:09,424 [Executor task launch worker for task 8] INFO [org.apache.spark.executor.Executor] - Finished task 8.0 in stage 0.0 (TID 8). 798 bytes result sent to driver
2021-12-03 21:23:09,425 [dispatcher-event-loop-8] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 13.0 in stage 0.0 (TID 13, localhost, executor driver, partition 13, ANY, 7899 bytes)
2021-12-03 21:23:09,425 [Executor task launch worker for task 13] INFO [org.apache.spark.executor.Executor] - Running task 13.0 in stage 0.0 (TID 13)
2021-12-03 21:23:09,426 [Executor task launch worker for task 13] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:1744830464+134217728
2021-12-03 21:23:09,433 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 8.0 in stage 0.0 (TID 8) in 126771 ms on localhost (executor driver) (2/22)
2021-12-03 21:23:12,356 [Executor task launch worker for task 10] INFO [org.apache.spark.executor.Executor] - Finished task 10.0 in stage 0.0 (TID 10). 755 bytes result sent to driver
2021-12-03 21:23:12,360 [dispatcher-event-loop-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 14.0 in stage 0.0 (TID 14, localhost, executor driver, partition 14, ANY, 7899 bytes)
2021-12-03 21:23:12,361 [Executor task launch worker for task 14] INFO [org.apache.spark.executor.Executor] - Running task 14.0 in stage 0.0 (TID 14)
2021-12-03 21:23:12,362 [Executor task launch worker for task 14] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:1879048192+134217728
2021-12-03 21:23:12,363 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 10.0 in stage 0.0 (TID 10) in 129701 ms on localhost (executor driver) (3/22)
2021-12-03 21:23:14,509 [Executor task launch worker for task 2] INFO [org.apache.spark.executor.Executor] - Finished task 2.0 in stage 0.0 (TID 2). 755 bytes result sent to driver
2021-12-03 21:23:14,513 [dispatcher-event-loop-11] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 15.0 in stage 0.0 (TID 15, localhost, executor driver, partition 15, ANY, 7899 bytes)
2021-12-03 21:23:14,513 [Executor task launch worker for task 15] INFO [org.apache.spark.executor.Executor] - Running task 15.0 in stage 0.0 (TID 15)
2021-12-03 21:23:14,515 [Executor task launch worker for task 15] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:2013265920+134217728
2021-12-03 21:23:14,516 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 2.0 in stage 0.0 (TID 2) in 131857 ms on localhost (executor driver) (4/22)
2021-12-03 21:23:22,110 [Executor task launch worker for task 11] INFO [org.apache.spark.executor.Executor] - Finished task 11.0 in stage 0.0 (TID 11). 798 bytes result sent to driver
2021-12-03 21:23:22,110 [dispatcher-event-loop-5] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 16.0 in stage 0.0 (TID 16, localhost, executor driver, partition 16, ANY, 7899 bytes)
2021-12-03 21:23:22,110 [Executor task launch worker for task 16] INFO [org.apache.spark.executor.Executor] - Running task 16.0 in stage 0.0 (TID 16)
2021-12-03 21:23:22,110 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 11.0 in stage 0.0 (TID 11) in 139447 ms on localhost (executor driver) (5/22)
2021-12-03 21:23:22,115 [Executor task launch worker for task 16] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:2147483648+134217728
2021-12-03 21:23:25,704 [Executor task launch worker for task 0] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 0.0 (TID 0). 798 bytes result sent to driver
2021-12-03 21:23:25,704 [dispatcher-event-loop-7] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 17.0 in stage 0.0 (TID 17, localhost, executor driver, partition 17, ANY, 7899 bytes)
2021-12-03 21:23:25,704 [Executor task launch worker for task 17] INFO [org.apache.spark.executor.Executor] - Running task 17.0 in stage 0.0 (TID 17)
2021-12-03 21:23:25,704 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 0.0 (TID 0) in 143056 ms on localhost (executor driver) (6/22)
2021-12-03 21:23:25,705 [Executor task launch worker for task 17] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:2281701376+134217728
2021-12-03 21:23:27,540 [Executor task launch worker for task 4] INFO [org.apache.spark.executor.Executor] - Finished task 4.0 in stage 0.0 (TID 4). 798 bytes result sent to driver
2021-12-03 21:23:27,540 [dispatcher-event-loop-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 18.0 in stage 0.0 (TID 18, localhost, executor driver, partition 18, ANY, 7899 bytes)
2021-12-03 21:23:27,541 [Executor task launch worker for task 18] INFO [org.apache.spark.executor.Executor] - Running task 18.0 in stage 0.0 (TID 18)
2021-12-03 21:23:27,541 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 4.0 in stage 0.0 (TID 4) in 144881 ms on localhost (executor driver) (7/22)
2021-12-03 21:23:27,545 [Executor task launch worker for task 18] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:2415919104+134217728
2021-12-03 21:23:29,329 [Executor task launch worker for task 9] INFO [org.apache.spark.executor.Executor] - Finished task 9.0 in stage 0.0 (TID 9). 755 bytes result sent to driver
2021-12-03 21:23:29,329 [dispatcher-event-loop-11] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 19.0 in stage 0.0 (TID 19, localhost, executor driver, partition 19, ANY, 7899 bytes)
2021-12-03 21:23:29,330 [Executor task launch worker for task 19] INFO [org.apache.spark.executor.Executor] - Running task 19.0 in stage 0.0 (TID 19)
2021-12-03 21:23:29,330 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 9.0 in stage 0.0 (TID 9) in 146668 ms on localhost (executor driver) (8/22)
2021-12-03 21:23:29,330 [Executor task launch worker for task 19] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:2550136832+134217728
2021-12-03 21:23:33,076 [Executor task launch worker for task 3] INFO [org.apache.spark.executor.Executor] - Finished task 3.0 in stage 0.0 (TID 3). 755 bytes result sent to driver
2021-12-03 21:23:33,077 [dispatcher-event-loop-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 20.0 in stage 0.0 (TID 20, localhost, executor driver, partition 20, ANY, 7899 bytes)
2021-12-03 21:23:33,077 [Executor task launch worker for task 20] INFO [org.apache.spark.executor.Executor] - Running task 20.0 in stage 0.0 (TID 20)
2021-12-03 21:23:33,077 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 3.0 in stage 0.0 (TID 3) in 150418 ms on localhost (executor driver) (9/22)
2021-12-03 21:23:33,078 [Executor task launch worker for task 20] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:2684354560+134217728
2021-12-03 21:23:38,313 [Executor task launch worker for task 1] INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 0.0 (TID 1). 755 bytes result sent to driver
2021-12-03 21:23:38,314 [dispatcher-event-loop-7] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 21.0 in stage 0.0 (TID 21, localhost, executor driver, partition 21, ANY, 7899 bytes)
2021-12-03 21:23:38,314 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 0.0 (TID 1) in 155656 ms on localhost (executor driver) (10/22)
2021-12-03 21:23:38,314 [Executor task launch worker for task 21] INFO [org.apache.spark.executor.Executor] - Running task 21.0 in stage 0.0 (TID 21)
2021-12-03 21:23:38,315 [Executor task launch worker for task 21] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:2818572288+147216171
2021-12-03 21:23:38,646 [Executor task launch worker for task 6] INFO [org.apache.spark.executor.Executor] - Finished task 6.0 in stage 0.0 (TID 6). 755 bytes result sent to driver
2021-12-03 21:23:38,647 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 6.0 in stage 0.0 (TID 6) in 155986 ms on localhost (executor driver) (11/22)
2021-12-03 21:23:44,104 [Executor task launch worker for task 7] INFO [org.apache.spark.executor.Executor] - Finished task 7.0 in stage 0.0 (TID 7). 798 bytes result sent to driver
2021-12-03 21:23:44,105 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 7.0 in stage 0.0 (TID 7) in 161444 ms on localhost (executor driver) (12/22)
2021-12-03 21:24:35,825 [Executor task launch worker for task 12] INFO [org.apache.spark.executor.Executor] - Finished task 12.0 in stage 0.0 (TID 12). 755 bytes result sent to driver
2021-12-03 21:24:35,825 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 12.0 in stage 0.0 (TID 12) in 101916 ms on localhost (executor driver) (13/22)
2021-12-03 21:24:57,822 [Executor task launch worker for task 15] INFO [org.apache.spark.executor.Executor] - Finished task 15.0 in stage 0.0 (TID 15). 755 bytes result sent to driver
2021-12-03 21:24:57,822 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 15.0 in stage 0.0 (TID 15) in 103313 ms on localhost (executor driver) (14/22)
2021-12-03 21:25:02,839 [Executor task launch worker for task 13] INFO [org.apache.spark.executor.Executor] - Finished task 13.0 in stage 0.0 (TID 13). 712 bytes result sent to driver
2021-12-03 21:25:02,839 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 13.0 in stage 0.0 (TID 13) in 113414 ms on localhost (executor driver) (15/22)
2021-12-03 21:25:06,884 [Executor task launch worker for task 14] INFO [org.apache.spark.executor.Executor] - Finished task 14.0 in stage 0.0 (TID 14). 798 bytes result sent to driver
2021-12-03 21:25:06,887 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 14.0 in stage 0.0 (TID 14) in 114530 ms on localhost (executor driver) (16/22)
2021-12-03 21:25:09,127 [Executor task launch worker for task 19] INFO [org.apache.spark.executor.Executor] - Finished task 19.0 in stage 0.0 (TID 19). 712 bytes result sent to driver
2021-12-03 21:25:09,127 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 19.0 in stage 0.0 (TID 19) in 99798 ms on localhost (executor driver) (17/22)
2021-12-03 21:25:13,191 [Executor task launch worker for task 20] INFO [org.apache.spark.executor.Executor] - Finished task 20.0 in stage 0.0 (TID 20). 712 bytes result sent to driver
2021-12-03 21:25:13,191 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 20.0 in stage 0.0 (TID 20) in 100114 ms on localhost (executor driver) (18/22)
2021-12-03 21:25:13,878 [Executor task launch worker for task 16] INFO [org.apache.spark.executor.Executor] - Finished task 16.0 in stage 0.0 (TID 16). 798 bytes result sent to driver
2021-12-03 21:25:13,879 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 16.0 in stage 0.0 (TID 16) in 111769 ms on localhost (executor driver) (19/22)
2021-12-03 21:25:17,222 [Executor task launch worker for task 21] INFO [org.apache.spark.executor.Executor] - Finished task 21.0 in stage 0.0 (TID 21). 712 bytes result sent to driver
2021-12-03 21:25:17,223 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 21.0 in stage 0.0 (TID 21) in 98910 ms on localhost (executor driver) (20/22)
2021-12-03 21:25:18,140 [Executor task launch worker for task 17] INFO [org.apache.spark.executor.Executor] - Finished task 17.0 in stage 0.0 (TID 17). 798 bytes result sent to driver
2021-12-03 21:25:18,140 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 17.0 in stage 0.0 (TID 17) in 112436 ms on localhost (executor driver) (21/22)
2021-12-03 21:25:18,155 [Executor task launch worker for task 18] INFO [org.apache.spark.executor.Executor] - Finished task 18.0 in stage 0.0 (TID 18). 755 bytes result sent to driver
2021-12-03 21:25:18,156 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 18.0 in stage 0.0 (TID 18) in 110616 ms on localhost (executor driver) (22/22)
2021-12-03 21:25:18,163 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 0.0, whose tasks have all completed, from pool 
2021-12-03 21:25:18,163 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 0 (count at PaidPromotionAdjustParameter.scala:59) finished in 255.566 s
2021-12-03 21:25:18,167 [main] INFO [org.apache.spark.scheduler.DAGScheduler] - Job 0 finished: count at PaidPromotionAdjustParameter.scala:59, took 255.608815 s
2021-12-03 21:25:18,169 [main] INFO [PaidPromotion$] - 收视总数68489201
2021-12-03 21:25:18,347 [main] INFO [org.apache.spark.SparkContext] - Starting job: count at PaidPromotionAdjustParameter.scala:68
2021-12-03 21:25:18,356 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 3 (map at PaidPromotionAdjustParameter.scala:67)
2021-12-03 21:25:18,357 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 1 (count at PaidPromotionAdjustParameter.scala:68) with 22 output partitions
2021-12-03 21:25:18,357 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 2 (count at PaidPromotionAdjustParameter.scala:68)
2021-12-03 21:25:18,357 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 1)
2021-12-03 21:25:18,358 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List(ShuffleMapStage 1)
2021-12-03 21:25:18,359 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ShuffleMapStage 1 (MapPartitionsRDD[3] at map at PaidPromotionAdjustParameter.scala:67), which has no missing parents
2021-12-03 21:25:18,371 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_2 stored as values in memory (estimated size 4.7 KB, free 1990.5 MB)
2021-12-03 21:25:18,374 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_2_piece0 stored as bytes in memory (estimated size 2.7 KB, free 1990.5 MB)
2021-12-03 21:25:18,375 [dispatcher-event-loop-7] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_2_piece0 in memory on qb:61634 (size: 2.7 KB, free: 1990.8 MB)
2021-12-03 21:25:18,375 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 2 from broadcast at DAGScheduler.scala:1039
2021-12-03 21:25:18,377 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 22 missing tasks from ShuffleMapStage 1 (MapPartitionsRDD[3] at map at PaidPromotionAdjustParameter.scala:67) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14))
2021-12-03 21:25:18,377 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 1.0 with 22 tasks
2021-12-03 21:25:18,378 [dispatcher-event-loop-4] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 1.0 (TID 22, localhost, executor driver, partition 0, ANY, 7888 bytes)
2021-12-03 21:25:18,378 [dispatcher-event-loop-4] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 1.0 (TID 23, localhost, executor driver, partition 1, ANY, 7888 bytes)
2021-12-03 21:25:18,379 [dispatcher-event-loop-4] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 2.0 in stage 1.0 (TID 24, localhost, executor driver, partition 2, ANY, 7888 bytes)
2021-12-03 21:25:18,379 [dispatcher-event-loop-4] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 3.0 in stage 1.0 (TID 25, localhost, executor driver, partition 3, ANY, 7888 bytes)
2021-12-03 21:25:18,379 [dispatcher-event-loop-4] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 4.0 in stage 1.0 (TID 26, localhost, executor driver, partition 4, ANY, 7888 bytes)
2021-12-03 21:25:18,379 [dispatcher-event-loop-4] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 5.0 in stage 1.0 (TID 27, localhost, executor driver, partition 5, ANY, 7888 bytes)
2021-12-03 21:25:18,379 [dispatcher-event-loop-4] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 6.0 in stage 1.0 (TID 28, localhost, executor driver, partition 6, ANY, 7888 bytes)
2021-12-03 21:25:18,379 [dispatcher-event-loop-4] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 7.0 in stage 1.0 (TID 29, localhost, executor driver, partition 7, ANY, 7888 bytes)
2021-12-03 21:25:18,379 [dispatcher-event-loop-4] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 8.0 in stage 1.0 (TID 30, localhost, executor driver, partition 8, ANY, 7888 bytes)
2021-12-03 21:25:18,380 [dispatcher-event-loop-4] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 9.0 in stage 1.0 (TID 31, localhost, executor driver, partition 9, ANY, 7888 bytes)
2021-12-03 21:25:18,380 [dispatcher-event-loop-4] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 10.0 in stage 1.0 (TID 32, localhost, executor driver, partition 10, ANY, 7888 bytes)
2021-12-03 21:25:18,380 [dispatcher-event-loop-4] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 11.0 in stage 1.0 (TID 33, localhost, executor driver, partition 11, ANY, 7888 bytes)
2021-12-03 21:25:18,380 [Executor task launch worker for task 22] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 1.0 (TID 22)
2021-12-03 21:25:18,380 [Executor task launch worker for task 23] INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 1.0 (TID 23)
2021-12-03 21:25:18,380 [Executor task launch worker for task 29] INFO [org.apache.spark.executor.Executor] - Running task 7.0 in stage 1.0 (TID 29)
2021-12-03 21:25:18,380 [Executor task launch worker for task 31] INFO [org.apache.spark.executor.Executor] - Running task 9.0 in stage 1.0 (TID 31)
2021-12-03 21:25:18,380 [Executor task launch worker for task 30] INFO [org.apache.spark.executor.Executor] - Running task 8.0 in stage 1.0 (TID 30)
2021-12-03 21:25:18,380 [Executor task launch worker for task 27] INFO [org.apache.spark.executor.Executor] - Running task 5.0 in stage 1.0 (TID 27)
2021-12-03 21:25:18,380 [Executor task launch worker for task 28] INFO [org.apache.spark.executor.Executor] - Running task 6.0 in stage 1.0 (TID 28)
2021-12-03 21:25:18,380 [Executor task launch worker for task 24] INFO [org.apache.spark.executor.Executor] - Running task 2.0 in stage 1.0 (TID 24)
2021-12-03 21:25:18,380 [Executor task launch worker for task 25] INFO [org.apache.spark.executor.Executor] - Running task 3.0 in stage 1.0 (TID 25)
2021-12-03 21:25:18,380 [Executor task launch worker for task 26] INFO [org.apache.spark.executor.Executor] - Running task 4.0 in stage 1.0 (TID 26)
2021-12-03 21:25:18,381 [Executor task launch worker for task 33] INFO [org.apache.spark.executor.Executor] - Running task 11.0 in stage 1.0 (TID 33)
2021-12-03 21:25:18,382 [Executor task launch worker for task 32] INFO [org.apache.spark.executor.Executor] - Running task 10.0 in stage 1.0 (TID 32)
2021-12-03 21:25:18,385 [Executor task launch worker for task 25] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:402653184+134217728
2021-12-03 21:25:18,385 [Executor task launch worker for task 24] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:268435456+134217728
2021-12-03 21:25:18,385 [Executor task launch worker for task 22] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:0+134217728
2021-12-03 21:25:18,385 [Executor task launch worker for task 27] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:671088640+134217728
2021-12-03 21:25:18,385 [Executor task launch worker for task 26] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:536870912+134217728
2021-12-03 21:25:18,385 [Executor task launch worker for task 28] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:805306368+134217728
2021-12-03 21:25:18,385 [Executor task launch worker for task 23] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:134217728+134217728
2021-12-03 21:25:18,386 [Executor task launch worker for task 33] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:1476395008+134217728
2021-12-03 21:25:18,386 [Executor task launch worker for task 29] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:939524096+134217728
2021-12-03 21:25:18,385 [Executor task launch worker for task 31] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:1207959552+134217728
2021-12-03 21:25:18,386 [Executor task launch worker for task 32] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:1342177280+134217728
2021-12-03 21:25:18,386 [Executor task launch worker for task 30] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:1073741824+134217728
2021-12-03 21:26:56,737 [Executor task launch worker for task 31] INFO [org.apache.spark.executor.Executor] - Finished task 9.0 in stage 1.0 (TID 31). 1052 bytes result sent to driver
2021-12-03 21:26:56,738 [dispatcher-event-loop-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 12.0 in stage 1.0 (TID 34, localhost, executor driver, partition 12, ANY, 7888 bytes)
2021-12-03 21:26:56,738 [Executor task launch worker for task 34] INFO [org.apache.spark.executor.Executor] - Running task 12.0 in stage 1.0 (TID 34)
2021-12-03 21:26:56,739 [Executor task launch worker for task 34] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:1610612736+134217728
2021-12-03 21:26:56,756 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 9.0 in stage 1.0 (TID 31) in 98377 ms on localhost (executor driver) (1/22)
2021-12-03 21:27:16,575 [Executor task launch worker for task 30] INFO [org.apache.spark.executor.Executor] - Finished task 8.0 in stage 1.0 (TID 30). 1052 bytes result sent to driver
2021-12-03 21:27:16,575 [dispatcher-event-loop-10] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 13.0 in stage 1.0 (TID 35, localhost, executor driver, partition 13, ANY, 7888 bytes)
2021-12-03 21:27:16,576 [Executor task launch worker for task 35] INFO [org.apache.spark.executor.Executor] - Running task 13.0 in stage 1.0 (TID 35)
2021-12-03 21:27:16,576 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 8.0 in stage 1.0 (TID 30) in 118197 ms on localhost (executor driver) (2/22)
2021-12-03 21:27:16,577 [Executor task launch worker for task 35] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:1744830464+134217728
2021-12-03 21:27:21,349 [Executor task launch worker for task 28] INFO [org.apache.spark.executor.Executor] - Finished task 6.0 in stage 1.0 (TID 28). 1052 bytes result sent to driver
2021-12-03 21:27:21,350 [dispatcher-event-loop-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 14.0 in stage 1.0 (TID 36, localhost, executor driver, partition 14, ANY, 7888 bytes)
2021-12-03 21:27:21,350 [Executor task launch worker for task 36] INFO [org.apache.spark.executor.Executor] - Running task 14.0 in stage 1.0 (TID 36)
2021-12-03 21:27:21,350 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 6.0 in stage 1.0 (TID 28) in 122971 ms on localhost (executor driver) (3/22)
2021-12-03 21:27:21,351 [Executor task launch worker for task 36] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:1879048192+134217728
2021-12-03 21:27:28,308 [Executor task launch worker for task 23] INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 1.0 (TID 23). 1052 bytes result sent to driver
2021-12-03 21:27:28,309 [dispatcher-event-loop-8] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 15.0 in stage 1.0 (TID 37, localhost, executor driver, partition 15, ANY, 7888 bytes)
2021-12-03 21:27:28,309 [Executor task launch worker for task 37] INFO [org.apache.spark.executor.Executor] - Running task 15.0 in stage 1.0 (TID 37)
2021-12-03 21:27:28,309 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 1.0 (TID 23) in 129931 ms on localhost (executor driver) (4/22)
2021-12-03 21:27:28,313 [Executor task launch worker for task 37] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:2013265920+134217728
2021-12-03 21:27:28,476 [Executor task launch worker for task 29] INFO [org.apache.spark.executor.Executor] - Finished task 7.0 in stage 1.0 (TID 29). 1052 bytes result sent to driver
2021-12-03 21:27:28,476 [dispatcher-event-loop-9] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 16.0 in stage 1.0 (TID 38, localhost, executor driver, partition 16, ANY, 7888 bytes)
2021-12-03 21:27:28,476 [Executor task launch worker for task 38] INFO [org.apache.spark.executor.Executor] - Running task 16.0 in stage 1.0 (TID 38)
2021-12-03 21:27:28,476 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 7.0 in stage 1.0 (TID 29) in 130097 ms on localhost (executor driver) (5/22)
2021-12-03 21:27:28,477 [Executor task launch worker for task 38] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:2147483648+134217728
2021-12-03 21:27:33,313 [Executor task launch worker for task 25] INFO [org.apache.spark.executor.Executor] - Finished task 3.0 in stage 1.0 (TID 25). 1052 bytes result sent to driver
2021-12-03 21:27:33,313 [dispatcher-event-loop-10] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 17.0 in stage 1.0 (TID 39, localhost, executor driver, partition 17, ANY, 7888 bytes)
2021-12-03 21:27:33,314 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 3.0 in stage 1.0 (TID 25) in 134935 ms on localhost (executor driver) (6/22)
2021-12-03 21:27:33,314 [Executor task launch worker for task 39] INFO [org.apache.spark.executor.Executor] - Running task 17.0 in stage 1.0 (TID 39)
2021-12-03 21:27:33,314 [Executor task launch worker for task 39] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:2281701376+134217728
2021-12-03 21:27:40,513 [Executor task launch worker for task 32] INFO [org.apache.spark.executor.Executor] - Finished task 10.0 in stage 1.0 (TID 32). 1052 bytes result sent to driver
2021-12-03 21:27:40,513 [dispatcher-event-loop-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 18.0 in stage 1.0 (TID 40, localhost, executor driver, partition 18, ANY, 7888 bytes)
2021-12-03 21:27:40,513 [Executor task launch worker for task 40] INFO [org.apache.spark.executor.Executor] - Running task 18.0 in stage 1.0 (TID 40)
2021-12-03 21:27:40,513 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 10.0 in stage 1.0 (TID 32) in 142133 ms on localhost (executor driver) (7/22)
2021-12-03 21:27:40,514 [Executor task launch worker for task 40] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:2415919104+134217728
2021-12-03 21:27:47,849 [Executor task launch worker for task 24] INFO [org.apache.spark.executor.Executor] - Finished task 2.0 in stage 1.0 (TID 24). 1052 bytes result sent to driver
2021-12-03 21:27:47,849 [dispatcher-event-loop-8] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 19.0 in stage 1.0 (TID 41, localhost, executor driver, partition 19, ANY, 7888 bytes)
2021-12-03 21:27:47,849 [Executor task launch worker for task 41] INFO [org.apache.spark.executor.Executor] - Running task 19.0 in stage 1.0 (TID 41)
2021-12-03 21:27:47,849 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 2.0 in stage 1.0 (TID 24) in 149471 ms on localhost (executor driver) (8/22)
2021-12-03 21:27:47,850 [Executor task launch worker for task 41] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:2550136832+134217728
2021-12-03 21:27:58,048 [Executor task launch worker for task 22] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 1.0 (TID 22). 1052 bytes result sent to driver
2021-12-03 21:27:58,048 [dispatcher-event-loop-10] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 20.0 in stage 1.0 (TID 42, localhost, executor driver, partition 20, ANY, 7888 bytes)
2021-12-03 21:27:58,048 [Executor task launch worker for task 42] INFO [org.apache.spark.executor.Executor] - Running task 20.0 in stage 1.0 (TID 42)
2021-12-03 21:27:58,048 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 1.0 (TID 22) in 159671 ms on localhost (executor driver) (9/22)
2021-12-03 21:27:58,049 [Executor task launch worker for task 42] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:2684354560+134217728
2021-12-03 21:28:02,847 [Executor task launch worker for task 27] INFO [org.apache.spark.executor.Executor] - Finished task 5.0 in stage 1.0 (TID 27). 1052 bytes result sent to driver
2021-12-03 21:28:02,848 [dispatcher-event-loop-4] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 21.0 in stage 1.0 (TID 43, localhost, executor driver, partition 21, ANY, 7888 bytes)
2021-12-03 21:28:02,848 [Executor task launch worker for task 43] INFO [org.apache.spark.executor.Executor] - Running task 21.0 in stage 1.0 (TID 43)
2021-12-03 21:28:02,848 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 5.0 in stage 1.0 (TID 27) in 164469 ms on localhost (executor driver) (10/22)
2021-12-03 21:28:02,849 [Executor task launch worker for task 43] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:2818572288+147216171
2021-12-03 21:28:04,303 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 11
2021-12-03 21:28:04,304 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 20
2021-12-03 21:28:04,304 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 4
2021-12-03 21:28:04,304 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 7
2021-12-03 21:28:04,304 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 18
2021-12-03 21:28:04,304 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 15
2021-12-03 21:28:04,314 [dispatcher-event-loop-6] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_1_piece0 on qb:61634 in memory (size: 1903.0 B, free: 1990.8 MB)
2021-12-03 21:28:04,316 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1
2021-12-03 21:28:04,316 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 12
2021-12-03 21:28:04,316 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 14
2021-12-03 21:28:04,316 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 17
2021-12-03 21:28:04,316 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 0
2021-12-03 21:28:04,316 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 3
2021-12-03 21:28:04,316 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 21
2021-12-03 21:28:04,316 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 16
2021-12-03 21:28:04,316 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 13
2021-12-03 21:28:04,316 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 19
2021-12-03 21:28:04,316 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 24
2021-12-03 21:28:04,317 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 9
2021-12-03 21:28:04,317 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 6
2021-12-03 21:28:04,317 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 10
2021-12-03 21:28:04,317 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 5
2021-12-03 21:28:04,317 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 2
2021-12-03 21:28:04,317 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 8
2021-12-03 21:28:04,317 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 22
2021-12-03 21:28:04,317 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 23
2021-12-03 21:28:15,010 [Executor task launch worker for task 33] INFO [org.apache.spark.executor.Executor] - Finished task 11.0 in stage 1.0 (TID 33). 1052 bytes result sent to driver
2021-12-03 21:28:15,010 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 11.0 in stage 1.0 (TID 33) in 176630 ms on localhost (executor driver) (11/22)
2021-12-03 21:28:15,264 [Executor task launch worker for task 26] INFO [org.apache.spark.executor.Executor] - Finished task 4.0 in stage 1.0 (TID 26). 1052 bytes result sent to driver
2021-12-03 21:28:15,264 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 4.0 in stage 1.0 (TID 26) in 176885 ms on localhost (executor driver) (12/22)
2021-12-03 21:29:02,140 [Executor task launch worker for task 34] INFO [org.apache.spark.executor.Executor] - Finished task 12.0 in stage 1.0 (TID 34). 1009 bytes result sent to driver
2021-12-03 21:29:02,141 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 12.0 in stage 1.0 (TID 34) in 125403 ms on localhost (executor driver) (13/22)
2021-12-03 21:29:17,223 [Executor task launch worker for task 38] INFO [org.apache.spark.executor.Executor] - Finished task 16.0 in stage 1.0 (TID 38). 1052 bytes result sent to driver
2021-12-03 21:29:17,223 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 16.0 in stage 1.0 (TID 38) in 108747 ms on localhost (executor driver) (14/22)
2021-12-03 21:29:25,047 [Executor task launch worker for task 39] INFO [org.apache.spark.executor.Executor] - Finished task 17.0 in stage 1.0 (TID 39). 1009 bytes result sent to driver
2021-12-03 21:29:25,048 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 17.0 in stage 1.0 (TID 39) in 111735 ms on localhost (executor driver) (15/22)
2021-12-03 21:29:26,034 [Executor task launch worker for task 36] INFO [org.apache.spark.executor.Executor] - Finished task 14.0 in stage 1.0 (TID 36). 1052 bytes result sent to driver
2021-12-03 21:29:26,034 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 14.0 in stage 1.0 (TID 36) in 124684 ms on localhost (executor driver) (16/22)
2021-12-03 21:29:29,557 [Executor task launch worker for task 41] INFO [org.apache.spark.executor.Executor] - Finished task 19.0 in stage 1.0 (TID 41). 1052 bytes result sent to driver
2021-12-03 21:29:29,558 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 19.0 in stage 1.0 (TID 41) in 101708 ms on localhost (executor driver) (17/22)
2021-12-03 21:29:29,780 [Executor task launch worker for task 37] INFO [org.apache.spark.executor.Executor] - Finished task 15.0 in stage 1.0 (TID 37). 1052 bytes result sent to driver
2021-12-03 21:29:29,780 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 15.0 in stage 1.0 (TID 37) in 121471 ms on localhost (executor driver) (18/22)
2021-12-03 21:29:30,250 [Executor task launch worker for task 43] INFO [org.apache.spark.executor.Executor] - Finished task 21.0 in stage 1.0 (TID 43). 1095 bytes result sent to driver
2021-12-03 21:29:30,250 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 21.0 in stage 1.0 (TID 43) in 87402 ms on localhost (executor driver) (19/22)
2021-12-03 21:29:31,256 [Executor task launch worker for task 35] INFO [org.apache.spark.executor.Executor] - Finished task 13.0 in stage 1.0 (TID 35). 1052 bytes result sent to driver
2021-12-03 21:29:31,256 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 13.0 in stage 1.0 (TID 35) in 134681 ms on localhost (executor driver) (20/22)
2021-12-03 21:29:31,354 [Executor task launch worker for task 40] INFO [org.apache.spark.executor.Executor] - Finished task 18.0 in stage 1.0 (TID 40). 1052 bytes result sent to driver
2021-12-03 21:29:31,354 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 18.0 in stage 1.0 (TID 40) in 110841 ms on localhost (executor driver) (21/22)
2021-12-03 21:29:34,310 [Executor task launch worker for task 42] INFO [org.apache.spark.executor.Executor] - Finished task 20.0 in stage 1.0 (TID 42). 1095 bytes result sent to driver
2021-12-03 21:29:34,311 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 20.0 in stage 1.0 (TID 42) in 96263 ms on localhost (executor driver) (22/22)
2021-12-03 21:29:34,311 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 1.0, whose tasks have all completed, from pool 
2021-12-03 21:29:34,311 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ShuffleMapStage 1 (map at PaidPromotionAdjustParameter.scala:67) finished in 255.947 s
2021-12-03 21:29:34,315 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - looking for newly runnable stages
2021-12-03 21:29:34,315 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - running: Set()
2021-12-03 21:29:34,316 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - waiting: Set(ResultStage 2)
2021-12-03 21:29:34,316 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - failed: Set()
2021-12-03 21:29:34,318 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 2 (ShuffledRDD[4] at reduceByKey at PaidPromotionAdjustParameter.scala:67), which has no missing parents
2021-12-03 21:29:34,324 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_3 stored as values in memory (estimated size 3.0 KB, free 1990.5 MB)
2021-12-03 21:29:34,326 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_3_piece0 stored as bytes in memory (estimated size 1906.0 B, free 1990.5 MB)
2021-12-03 21:29:34,327 [dispatcher-event-loop-4] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_3_piece0 in memory on qb:61634 (size: 1906.0 B, free: 1990.8 MB)
2021-12-03 21:29:34,327 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 3 from broadcast at DAGScheduler.scala:1039
2021-12-03 21:29:34,327 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 22 missing tasks from ResultStage 2 (ShuffledRDD[4] at reduceByKey at PaidPromotionAdjustParameter.scala:67) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14))
2021-12-03 21:29:34,327 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 2.0 with 22 tasks
2021-12-03 21:29:34,329 [dispatcher-event-loop-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 2.0 (TID 44, localhost, executor driver, partition 0, ANY, 7649 bytes)
2021-12-03 21:29:34,329 [dispatcher-event-loop-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 2.0 (TID 45, localhost, executor driver, partition 1, ANY, 7649 bytes)
2021-12-03 21:29:34,329 [dispatcher-event-loop-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 2.0 in stage 2.0 (TID 46, localhost, executor driver, partition 2, ANY, 7649 bytes)
2021-12-03 21:29:34,329 [dispatcher-event-loop-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 3.0 in stage 2.0 (TID 47, localhost, executor driver, partition 3, ANY, 7649 bytes)
2021-12-03 21:29:34,329 [dispatcher-event-loop-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 4.0 in stage 2.0 (TID 48, localhost, executor driver, partition 4, ANY, 7649 bytes)
2021-12-03 21:29:34,329 [dispatcher-event-loop-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 5.0 in stage 2.0 (TID 49, localhost, executor driver, partition 5, ANY, 7649 bytes)
2021-12-03 21:29:34,330 [dispatcher-event-loop-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 6.0 in stage 2.0 (TID 50, localhost, executor driver, partition 6, ANY, 7649 bytes)
2021-12-03 21:29:34,330 [dispatcher-event-loop-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 7.0 in stage 2.0 (TID 51, localhost, executor driver, partition 7, ANY, 7649 bytes)
2021-12-03 21:29:34,330 [dispatcher-event-loop-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 8.0 in stage 2.0 (TID 52, localhost, executor driver, partition 8, ANY, 7649 bytes)
2021-12-03 21:29:34,330 [dispatcher-event-loop-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 9.0 in stage 2.0 (TID 53, localhost, executor driver, partition 9, ANY, 7649 bytes)
2021-12-03 21:29:34,330 [dispatcher-event-loop-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 10.0 in stage 2.0 (TID 54, localhost, executor driver, partition 10, ANY, 7649 bytes)
2021-12-03 21:29:34,330 [dispatcher-event-loop-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 11.0 in stage 2.0 (TID 55, localhost, executor driver, partition 11, ANY, 7649 bytes)
2021-12-03 21:29:34,330 [Executor task launch worker for task 44] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 2.0 (TID 44)
2021-12-03 21:29:34,330 [Executor task launch worker for task 45] INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 2.0 (TID 45)
2021-12-03 21:29:34,330 [Executor task launch worker for task 53] INFO [org.apache.spark.executor.Executor] - Running task 9.0 in stage 2.0 (TID 53)
2021-12-03 21:29:34,330 [Executor task launch worker for task 52] INFO [org.apache.spark.executor.Executor] - Running task 8.0 in stage 2.0 (TID 52)
2021-12-03 21:29:34,330 [Executor task launch worker for task 47] INFO [org.apache.spark.executor.Executor] - Running task 3.0 in stage 2.0 (TID 47)
2021-12-03 21:29:34,330 [Executor task launch worker for task 51] INFO [org.apache.spark.executor.Executor] - Running task 7.0 in stage 2.0 (TID 51)
2021-12-03 21:29:34,330 [Executor task launch worker for task 50] INFO [org.apache.spark.executor.Executor] - Running task 6.0 in stage 2.0 (TID 50)
2021-12-03 21:29:34,330 [Executor task launch worker for task 46] INFO [org.apache.spark.executor.Executor] - Running task 2.0 in stage 2.0 (TID 46)
2021-12-03 21:29:34,330 [Executor task launch worker for task 49] INFO [org.apache.spark.executor.Executor] - Running task 5.0 in stage 2.0 (TID 49)
2021-12-03 21:29:34,330 [Executor task launch worker for task 48] INFO [org.apache.spark.executor.Executor] - Running task 4.0 in stage 2.0 (TID 48)
2021-12-03 21:29:34,331 [Executor task launch worker for task 54] INFO [org.apache.spark.executor.Executor] - Running task 10.0 in stage 2.0 (TID 54)
2021-12-03 21:29:34,331 [Executor task launch worker for task 55] INFO [org.apache.spark.executor.Executor] - Running task 11.0 in stage 2.0 (TID 55)
2021-12-03 21:29:34,345 [Executor task launch worker for task 50] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 21:29:34,345 [Executor task launch worker for task 54] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 21:29:34,345 [Executor task launch worker for task 47] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 21:29:34,345 [Executor task launch worker for task 48] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 21:29:34,345 [Executor task launch worker for task 44] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 21:29:34,345 [Executor task launch worker for task 52] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 21:29:34,345 [Executor task launch worker for task 45] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 21:29:34,345 [Executor task launch worker for task 49] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 21:29:34,345 [Executor task launch worker for task 46] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 21:29:34,345 [Executor task launch worker for task 55] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 21:29:34,345 [Executor task launch worker for task 53] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 21:29:34,345 [Executor task launch worker for task 51] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 21:29:34,346 [Executor task launch worker for task 44] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 6 ms
2021-12-03 21:29:34,347 [Executor task launch worker for task 53] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 8 ms
2021-12-03 21:29:34,347 [Executor task launch worker for task 47] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 7 ms
2021-12-03 21:29:34,347 [Executor task launch worker for task 51] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 8 ms
2021-12-03 21:29:34,347 [Executor task launch worker for task 45] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 8 ms
2021-12-03 21:29:34,347 [Executor task launch worker for task 46] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 7 ms
2021-12-03 21:29:34,347 [Executor task launch worker for task 55] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 6 ms
2021-12-03 21:29:34,347 [Executor task launch worker for task 48] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 8 ms
2021-12-03 21:29:34,346 [Executor task launch worker for task 54] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 7 ms
2021-12-03 21:29:34,346 [Executor task launch worker for task 52] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 7 ms
2021-12-03 21:29:34,346 [Executor task launch worker for task 49] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 7 ms
2021-12-03 21:29:34,346 [Executor task launch worker for task 50] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 7 ms
2021-12-03 21:29:35,023 [Executor task launch worker for task 48] INFO [org.apache.spark.executor.Executor] - Finished task 4.0 in stage 2.0 (TID 48). 1098 bytes result sent to driver
2021-12-03 21:29:35,024 [dispatcher-event-loop-5] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 12.0 in stage 2.0 (TID 56, localhost, executor driver, partition 12, ANY, 7649 bytes)
2021-12-03 21:29:35,024 [Executor task launch worker for task 56] INFO [org.apache.spark.executor.Executor] - Running task 12.0 in stage 2.0 (TID 56)
2021-12-03 21:29:35,025 [Executor task launch worker for task 56] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 21:29:35,025 [Executor task launch worker for task 56] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 21:29:35,025 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 4.0 in stage 2.0 (TID 48) in 696 ms on localhost (executor driver) (1/22)
2021-12-03 21:29:35,030 [Executor task launch worker for task 46] INFO [org.apache.spark.executor.Executor] - Finished task 2.0 in stage 2.0 (TID 46). 1098 bytes result sent to driver
2021-12-03 21:29:35,031 [dispatcher-event-loop-8] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 13.0 in stage 2.0 (TID 57, localhost, executor driver, partition 13, ANY, 7649 bytes)
2021-12-03 21:29:35,032 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 2.0 in stage 2.0 (TID 46) in 703 ms on localhost (executor driver) (2/22)
2021-12-03 21:29:35,032 [Executor task launch worker for task 57] INFO [org.apache.spark.executor.Executor] - Running task 13.0 in stage 2.0 (TID 57)
2021-12-03 21:29:35,034 [Executor task launch worker for task 49] INFO [org.apache.spark.executor.Executor] - Finished task 5.0 in stage 2.0 (TID 49). 1098 bytes result sent to driver
2021-12-03 21:29:35,034 [Executor task launch worker for task 47] INFO [org.apache.spark.executor.Executor] - Finished task 3.0 in stage 2.0 (TID 47). 1098 bytes result sent to driver
2021-12-03 21:29:35,034 [Executor task launch worker for task 57] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 21:29:35,034 [Executor task launch worker for task 57] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 21:29:35,034 [dispatcher-event-loop-7] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 14.0 in stage 2.0 (TID 58, localhost, executor driver, partition 14, ANY, 7649 bytes)
2021-12-03 21:29:35,034 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 5.0 in stage 2.0 (TID 49) in 705 ms on localhost (executor driver) (3/22)
2021-12-03 21:29:35,034 [Executor task launch worker for task 58] INFO [org.apache.spark.executor.Executor] - Running task 14.0 in stage 2.0 (TID 58)
2021-12-03 21:29:35,035 [dispatcher-event-loop-7] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 15.0 in stage 2.0 (TID 59, localhost, executor driver, partition 15, ANY, 7649 bytes)
2021-12-03 21:29:35,035 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 3.0 in stage 2.0 (TID 47) in 706 ms on localhost (executor driver) (4/22)
2021-12-03 21:29:35,035 [Executor task launch worker for task 59] INFO [org.apache.spark.executor.Executor] - Running task 15.0 in stage 2.0 (TID 59)
2021-12-03 21:29:35,037 [Executor task launch worker for task 51] INFO [org.apache.spark.executor.Executor] - Finished task 7.0 in stage 2.0 (TID 51). 1098 bytes result sent to driver
2021-12-03 21:29:35,037 [Executor task launch worker for task 59] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 21:29:35,037 [Executor task launch worker for task 59] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 21:29:35,037 [Executor task launch worker for task 58] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 21:29:35,037 [Executor task launch worker for task 58] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 2 ms
2021-12-03 21:29:35,037 [dispatcher-event-loop-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 16.0 in stage 2.0 (TID 60, localhost, executor driver, partition 16, ANY, 7649 bytes)
2021-12-03 21:29:35,038 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 7.0 in stage 2.0 (TID 51) in 708 ms on localhost (executor driver) (5/22)
2021-12-03 21:29:35,038 [Executor task launch worker for task 55] INFO [org.apache.spark.executor.Executor] - Finished task 11.0 in stage 2.0 (TID 55). 1098 bytes result sent to driver
2021-12-03 21:29:35,039 [Executor task launch worker for task 53] INFO [org.apache.spark.executor.Executor] - Finished task 9.0 in stage 2.0 (TID 53). 1098 bytes result sent to driver
2021-12-03 21:29:35,040 [Executor task launch worker for task 44] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 2.0 (TID 44). 1098 bytes result sent to driver
2021-12-03 21:29:35,040 [dispatcher-event-loop-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 17.0 in stage 2.0 (TID 61, localhost, executor driver, partition 17, ANY, 7649 bytes)
2021-12-03 21:29:35,040 [Executor task launch worker for task 60] INFO [org.apache.spark.executor.Executor] - Running task 16.0 in stage 2.0 (TID 60)
2021-12-03 21:29:35,040 [dispatcher-event-loop-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 18.0 in stage 2.0 (TID 62, localhost, executor driver, partition 18, ANY, 7649 bytes)
2021-12-03 21:29:35,041 [Executor task launch worker for task 50] INFO [org.apache.spark.executor.Executor] - Finished task 6.0 in stage 2.0 (TID 50). 1098 bytes result sent to driver
2021-12-03 21:29:35,041 [dispatcher-event-loop-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 19.0 in stage 2.0 (TID 63, localhost, executor driver, partition 19, ANY, 7649 bytes)
2021-12-03 21:29:35,041 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 9.0 in stage 2.0 (TID 53) in 711 ms on localhost (executor driver) (6/22)
2021-12-03 21:29:35,041 [Executor task launch worker for task 61] INFO [org.apache.spark.executor.Executor] - Running task 17.0 in stage 2.0 (TID 61)
2021-12-03 21:29:35,041 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 11.0 in stage 2.0 (TID 55) in 711 ms on localhost (executor driver) (7/22)
2021-12-03 21:29:35,041 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 2.0 (TID 44) in 713 ms on localhost (executor driver) (8/22)
2021-12-03 21:29:35,041 [Executor task launch worker for task 62] INFO [org.apache.spark.executor.Executor] - Running task 18.0 in stage 2.0 (TID 62)
2021-12-03 21:29:35,041 [Executor task launch worker for task 63] INFO [org.apache.spark.executor.Executor] - Running task 19.0 in stage 2.0 (TID 63)
2021-12-03 21:29:35,041 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 6.0 in stage 2.0 (TID 50) in 712 ms on localhost (executor driver) (9/22)
2021-12-03 21:29:35,042 [Executor task launch worker for task 60] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 21:29:35,043 [Executor task launch worker for task 60] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 2 ms
2021-12-03 21:29:35,043 [Executor task launch worker for task 62] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 21:29:35,043 [Executor task launch worker for task 61] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 21:29:35,043 [Executor task launch worker for task 61] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 21:29:35,043 [Executor task launch worker for task 54] INFO [org.apache.spark.executor.Executor] - Finished task 10.0 in stage 2.0 (TID 54). 1055 bytes result sent to driver
2021-12-03 21:29:35,043 [Executor task launch worker for task 62] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 21:29:35,044 [Executor task launch worker for task 63] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 21:29:35,044 [Executor task launch worker for task 63] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 1 ms
2021-12-03 21:29:35,044 [dispatcher-event-loop-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 20.0 in stage 2.0 (TID 64, localhost, executor driver, partition 20, ANY, 7649 bytes)
2021-12-03 21:29:35,045 [Executor task launch worker for task 64] INFO [org.apache.spark.executor.Executor] - Running task 20.0 in stage 2.0 (TID 64)
2021-12-03 21:29:35,045 [Executor task launch worker for task 52] INFO [org.apache.spark.executor.Executor] - Finished task 8.0 in stage 2.0 (TID 52). 1098 bytes result sent to driver
2021-12-03 21:29:35,045 [dispatcher-event-loop-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 21.0 in stage 2.0 (TID 65, localhost, executor driver, partition 21, ANY, 7649 bytes)
2021-12-03 21:29:35,045 [Executor task launch worker for task 45] INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 2.0 (TID 45). 1098 bytes result sent to driver
2021-12-03 21:29:35,045 [Executor task launch worker for task 65] INFO [org.apache.spark.executor.Executor] - Running task 21.0 in stage 2.0 (TID 65)
2021-12-03 21:29:35,045 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 10.0 in stage 2.0 (TID 54) in 715 ms on localhost (executor driver) (10/22)
2021-12-03 21:29:35,046 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 8.0 in stage 2.0 (TID 52) in 716 ms on localhost (executor driver) (11/22)
2021-12-03 21:29:35,046 [Executor task launch worker for task 64] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 21:29:35,046 [Executor task launch worker for task 64] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 21:29:35,046 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 2.0 (TID 45) in 717 ms on localhost (executor driver) (12/22)
2021-12-03 21:29:35,046 [Executor task launch worker for task 65] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 21:29:35,046 [Executor task launch worker for task 65] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 21:29:35,142 [Executor task launch worker for task 56] INFO [org.apache.spark.executor.Executor] - Finished task 12.0 in stage 2.0 (TID 56). 1012 bytes result sent to driver
2021-12-03 21:29:35,144 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 12.0 in stage 2.0 (TID 56) in 121 ms on localhost (executor driver) (13/22)
2021-12-03 21:29:35,150 [Executor task launch worker for task 59] INFO [org.apache.spark.executor.Executor] - Finished task 15.0 in stage 2.0 (TID 59). 1012 bytes result sent to driver
2021-12-03 21:29:35,151 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 15.0 in stage 2.0 (TID 59) in 116 ms on localhost (executor driver) (14/22)
2021-12-03 21:29:35,155 [Executor task launch worker for task 57] INFO [org.apache.spark.executor.Executor] - Finished task 13.0 in stage 2.0 (TID 57). 1098 bytes result sent to driver
2021-12-03 21:29:35,156 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 13.0 in stage 2.0 (TID 57) in 125 ms on localhost (executor driver) (15/22)
2021-12-03 21:29:35,156 [Executor task launch worker for task 58] INFO [org.apache.spark.executor.Executor] - Finished task 14.0 in stage 2.0 (TID 58). 1055 bytes result sent to driver
2021-12-03 21:29:35,157 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 14.0 in stage 2.0 (TID 58) in 123 ms on localhost (executor driver) (16/22)
2021-12-03 21:29:35,158 [Executor task launch worker for task 61] INFO [org.apache.spark.executor.Executor] - Finished task 17.0 in stage 2.0 (TID 61). 1055 bytes result sent to driver
2021-12-03 21:29:35,158 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 17.0 in stage 2.0 (TID 61) in 118 ms on localhost (executor driver) (17/22)
2021-12-03 21:29:35,160 [Executor task launch worker for task 63] INFO [org.apache.spark.executor.Executor] - Finished task 19.0 in stage 2.0 (TID 63). 1055 bytes result sent to driver
2021-12-03 21:29:35,161 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 19.0 in stage 2.0 (TID 63) in 120 ms on localhost (executor driver) (18/22)
2021-12-03 21:29:35,163 [Executor task launch worker for task 64] INFO [org.apache.spark.executor.Executor] - Finished task 20.0 in stage 2.0 (TID 64). 1012 bytes result sent to driver
2021-12-03 21:29:35,163 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 20.0 in stage 2.0 (TID 64) in 119 ms on localhost (executor driver) (19/22)
2021-12-03 21:29:35,170 [Executor task launch worker for task 65] INFO [org.apache.spark.executor.Executor] - Finished task 21.0 in stage 2.0 (TID 65). 1055 bytes result sent to driver
2021-12-03 21:29:35,170 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 21.0 in stage 2.0 (TID 65) in 125 ms on localhost (executor driver) (20/22)
2021-12-03 21:29:35,170 [Executor task launch worker for task 60] INFO [org.apache.spark.executor.Executor] - Finished task 16.0 in stage 2.0 (TID 60). 1012 bytes result sent to driver
2021-12-03 21:29:35,170 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 16.0 in stage 2.0 (TID 60) in 133 ms on localhost (executor driver) (21/22)
2021-12-03 21:29:35,171 [Executor task launch worker for task 62] INFO [org.apache.spark.executor.Executor] - Finished task 18.0 in stage 2.0 (TID 62). 1055 bytes result sent to driver
2021-12-03 21:29:35,171 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 18.0 in stage 2.0 (TID 62) in 131 ms on localhost (executor driver) (22/22)
2021-12-03 21:29:35,171 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 2.0, whose tasks have all completed, from pool 
2021-12-03 21:29:35,171 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 2 (count at PaidPromotionAdjustParameter.scala:68) finished in 0.849 s
2021-12-03 21:29:35,171 [main] INFO [org.apache.spark.scheduler.DAGScheduler] - Job 1 finished: count at PaidPromotionAdjustParameter.scala:68, took 256.824172 s
2021-12-03 21:29:35,172 [main] INFO [PaidPromotion$] - 用户总数1207347
2021-12-03 21:29:35,210 [main] INFO [org.apache.spark.SparkContext] - Starting job: sortByKey at PaidPromotionAdjustParameter.scala:73
2021-12-03 21:29:35,211 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 2 (sortByKey at PaidPromotionAdjustParameter.scala:73) with 22 output partitions
2021-12-03 21:29:35,211 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 4 (sortByKey at PaidPromotionAdjustParameter.scala:73)
2021-12-03 21:29:35,211 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 3)
2021-12-03 21:29:35,211 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2021-12-03 21:29:35,211 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 4 (MapPartitionsRDD[7] at sortByKey at PaidPromotionAdjustParameter.scala:73), which has no missing parents
2021-12-03 21:29:35,215 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_4 stored as values in memory (estimated size 4.1 KB, free 1990.5 MB)
2021-12-03 21:29:35,217 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_4_piece0 stored as bytes in memory (estimated size 2.4 KB, free 1990.4 MB)
2021-12-03 21:29:35,217 [dispatcher-event-loop-4] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_4_piece0 in memory on qb:61634 (size: 2.4 KB, free: 1990.8 MB)
2021-12-03 21:29:35,217 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 4 from broadcast at DAGScheduler.scala:1039
2021-12-03 21:29:35,218 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 22 missing tasks from ResultStage 4 (MapPartitionsRDD[7] at sortByKey at PaidPromotionAdjustParameter.scala:73) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14))
2021-12-03 21:29:35,218 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 4.0 with 22 tasks
2021-12-03 21:29:35,218 [dispatcher-event-loop-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 4.0 (TID 66, localhost, executor driver, partition 0, ANY, 7649 bytes)
2021-12-03 21:29:35,218 [dispatcher-event-loop-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 4.0 (TID 67, localhost, executor driver, partition 1, ANY, 7649 bytes)
2021-12-03 21:29:35,219 [dispatcher-event-loop-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 2.0 in stage 4.0 (TID 68, localhost, executor driver, partition 2, ANY, 7649 bytes)
2021-12-03 21:29:35,219 [dispatcher-event-loop-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 3.0 in stage 4.0 (TID 69, localhost, executor driver, partition 3, ANY, 7649 bytes)
2021-12-03 21:29:35,219 [dispatcher-event-loop-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 4.0 in stage 4.0 (TID 70, localhost, executor driver, partition 4, ANY, 7649 bytes)
2021-12-03 21:29:35,219 [dispatcher-event-loop-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 5.0 in stage 4.0 (TID 71, localhost, executor driver, partition 5, ANY, 7649 bytes)
2021-12-03 21:29:35,219 [dispatcher-event-loop-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 6.0 in stage 4.0 (TID 72, localhost, executor driver, partition 6, ANY, 7649 bytes)
2021-12-03 21:29:35,219 [dispatcher-event-loop-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 7.0 in stage 4.0 (TID 73, localhost, executor driver, partition 7, ANY, 7649 bytes)
2021-12-03 21:29:35,219 [dispatcher-event-loop-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 8.0 in stage 4.0 (TID 74, localhost, executor driver, partition 8, ANY, 7649 bytes)
2021-12-03 21:29:35,219 [dispatcher-event-loop-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 9.0 in stage 4.0 (TID 75, localhost, executor driver, partition 9, ANY, 7649 bytes)
2021-12-03 21:29:35,219 [dispatcher-event-loop-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 10.0 in stage 4.0 (TID 76, localhost, executor driver, partition 10, ANY, 7649 bytes)
2021-12-03 21:29:35,219 [dispatcher-event-loop-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 11.0 in stage 4.0 (TID 77, localhost, executor driver, partition 11, ANY, 7649 bytes)
2021-12-03 21:29:35,220 [Executor task launch worker for task 66] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 4.0 (TID 66)
2021-12-03 21:29:35,220 [Executor task launch worker for task 69] INFO [org.apache.spark.executor.Executor] - Running task 3.0 in stage 4.0 (TID 69)
2021-12-03 21:29:35,220 [Executor task launch worker for task 75] INFO [org.apache.spark.executor.Executor] - Running task 9.0 in stage 4.0 (TID 75)
2021-12-03 21:29:35,220 [Executor task launch worker for task 74] INFO [org.apache.spark.executor.Executor] - Running task 8.0 in stage 4.0 (TID 74)
2021-12-03 21:29:35,220 [Executor task launch worker for task 67] INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 4.0 (TID 67)
2021-12-03 21:29:35,220 [Executor task launch worker for task 68] INFO [org.apache.spark.executor.Executor] - Running task 2.0 in stage 4.0 (TID 68)
2021-12-03 21:29:35,220 [Executor task launch worker for task 71] INFO [org.apache.spark.executor.Executor] - Running task 5.0 in stage 4.0 (TID 71)
2021-12-03 21:29:35,220 [Executor task launch worker for task 70] INFO [org.apache.spark.executor.Executor] - Running task 4.0 in stage 4.0 (TID 70)
2021-12-03 21:29:35,220 [Executor task launch worker for task 77] INFO [org.apache.spark.executor.Executor] - Running task 11.0 in stage 4.0 (TID 77)
2021-12-03 21:29:35,220 [Executor task launch worker for task 76] INFO [org.apache.spark.executor.Executor] - Running task 10.0 in stage 4.0 (TID 76)
2021-12-03 21:29:35,220 [Executor task launch worker for task 73] INFO [org.apache.spark.executor.Executor] - Running task 7.0 in stage 4.0 (TID 73)
2021-12-03 21:29:35,220 [Executor task launch worker for task 72] INFO [org.apache.spark.executor.Executor] - Running task 6.0 in stage 4.0 (TID 72)
2021-12-03 21:29:35,221 [Executor task launch worker for task 70] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 21:29:35,221 [Executor task launch worker for task 70] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 21:29:35,221 [Executor task launch worker for task 69] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 21:29:35,221 [Executor task launch worker for task 69] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 21:29:35,221 [Executor task launch worker for task 74] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 21:29:35,221 [Executor task launch worker for task 75] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 21:29:35,221 [Executor task launch worker for task 74] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 21:29:35,221 [Executor task launch worker for task 75] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 21:29:35,221 [Executor task launch worker for task 73] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 21:29:35,222 [Executor task launch worker for task 73] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 1 ms
2021-12-03 21:29:35,222 [Executor task launch worker for task 66] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 21:29:35,222 [Executor task launch worker for task 66] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 1 ms
2021-12-03 21:29:35,222 [Executor task launch worker for task 67] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 21:29:35,222 [Executor task launch worker for task 67] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 21:29:35,222 [Executor task launch worker for task 71] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 21:29:35,222 [Executor task launch worker for task 71] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 21:29:35,222 [Executor task launch worker for task 72] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 21:29:35,222 [Executor task launch worker for task 68] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 21:29:35,222 [Executor task launch worker for task 68] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 21:29:35,222 [Executor task launch worker for task 72] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 21:29:35,222 [Executor task launch worker for task 76] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 21:29:35,222 [Executor task launch worker for task 76] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 21:29:35,222 [Executor task launch worker for task 77] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 21:29:35,222 [Executor task launch worker for task 77] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 21:29:35,359 [Executor task launch worker for task 70] INFO [org.apache.spark.executor.Executor] - Finished task 4.0 in stage 4.0 (TID 70). 1230 bytes result sent to driver
2021-12-03 21:29:35,360 [dispatcher-event-loop-5] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 12.0 in stage 4.0 (TID 78, localhost, executor driver, partition 12, ANY, 7649 bytes)
2021-12-03 21:29:35,360 [Executor task launch worker for task 69] INFO [org.apache.spark.executor.Executor] - Finished task 3.0 in stage 4.0 (TID 69). 1184 bytes result sent to driver
2021-12-03 21:29:35,361 [dispatcher-event-loop-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 13.0 in stage 4.0 (TID 79, localhost, executor driver, partition 13, ANY, 7649 bytes)
2021-12-03 21:29:35,361 [Executor task launch worker for task 73] INFO [org.apache.spark.executor.Executor] - Finished task 7.0 in stage 4.0 (TID 73). 1143 bytes result sent to driver
2021-12-03 21:29:35,361 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 4.0 in stage 4.0 (TID 70) in 142 ms on localhost (executor driver) (1/22)
2021-12-03 21:29:35,362 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 3.0 in stage 4.0 (TID 69) in 143 ms on localhost (executor driver) (2/22)
2021-12-03 21:29:35,362 [Executor task launch worker for task 79] INFO [org.apache.spark.executor.Executor] - Running task 13.0 in stage 4.0 (TID 79)
2021-12-03 21:29:35,363 [Executor task launch worker for task 79] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 21:29:35,363 [Executor task launch worker for task 79] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 21:29:35,363 [Executor task launch worker for task 77] INFO [org.apache.spark.executor.Executor] - Finished task 11.0 in stage 4.0 (TID 77). 1271 bytes result sent to driver
2021-12-03 21:29:35,363 [dispatcher-event-loop-6] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 14.0 in stage 4.0 (TID 80, localhost, executor driver, partition 14, ANY, 7649 bytes)
2021-12-03 21:29:35,363 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 7.0 in stage 4.0 (TID 73) in 144 ms on localhost (executor driver) (3/22)
2021-12-03 21:29:35,363 [dispatcher-event-loop-6] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 15.0 in stage 4.0 (TID 81, localhost, executor driver, partition 15, ANY, 7649 bytes)
2021-12-03 21:29:35,364 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 11.0 in stage 4.0 (TID 77) in 145 ms on localhost (executor driver) (4/22)
2021-12-03 21:29:35,364 [Executor task launch worker for task 81] INFO [org.apache.spark.executor.Executor] - Running task 15.0 in stage 4.0 (TID 81)
2021-12-03 21:29:35,364 [Executor task launch worker for task 74] INFO [org.apache.spark.executor.Executor] - Finished task 8.0 in stage 4.0 (TID 74). 1187 bytes result sent to driver
2021-12-03 21:29:35,365 [Executor task launch worker for task 81] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 21:29:35,365 [Executor task launch worker for task 81] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 1 ms
2021-12-03 21:29:35,366 [Executor task launch worker for task 80] INFO [org.apache.spark.executor.Executor] - Running task 14.0 in stage 4.0 (TID 80)
2021-12-03 21:29:35,366 [dispatcher-event-loop-8] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 16.0 in stage 4.0 (TID 82, localhost, executor driver, partition 16, ANY, 7649 bytes)
2021-12-03 21:29:35,366 [Executor task launch worker for task 82] INFO [org.apache.spark.executor.Executor] - Running task 16.0 in stage 4.0 (TID 82)
2021-12-03 21:29:35,366 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 8.0 in stage 4.0 (TID 74) in 147 ms on localhost (executor driver) (5/22)
2021-12-03 21:29:35,367 [Executor task launch worker for task 82] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 21:29:35,367 [Executor task launch worker for task 82] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 21:29:35,367 [Executor task launch worker for task 75] INFO [org.apache.spark.executor.Executor] - Finished task 9.0 in stage 4.0 (TID 75). 1192 bytes result sent to driver
2021-12-03 21:29:35,367 [Executor task launch worker for task 80] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 21:29:35,367 [Executor task launch worker for task 80] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 21:29:35,367 [Executor task launch worker for task 76] INFO [org.apache.spark.executor.Executor] - Finished task 10.0 in stage 4.0 (TID 76). 1144 bytes result sent to driver
2021-12-03 21:29:35,368 [Executor task launch worker for task 67] INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 4.0 (TID 67). 1226 bytes result sent to driver
2021-12-03 21:29:35,368 [Executor task launch worker for task 78] INFO [org.apache.spark.executor.Executor] - Running task 12.0 in stage 4.0 (TID 78)
2021-12-03 21:29:35,369 [dispatcher-event-loop-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 17.0 in stage 4.0 (TID 83, localhost, executor driver, partition 17, ANY, 7649 bytes)
2021-12-03 21:29:35,369 [dispatcher-event-loop-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 18.0 in stage 4.0 (TID 84, localhost, executor driver, partition 18, ANY, 7649 bytes)
2021-12-03 21:29:35,369 [Executor task launch worker for task 71] INFO [org.apache.spark.executor.Executor] - Finished task 5.0 in stage 4.0 (TID 71). 1232 bytes result sent to driver
2021-12-03 21:29:35,369 [Executor task launch worker for task 83] INFO [org.apache.spark.executor.Executor] - Running task 17.0 in stage 4.0 (TID 83)
2021-12-03 21:29:35,369 [Executor task launch worker for task 78] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 21:29:35,369 [Executor task launch worker for task 78] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 21:29:35,369 [dispatcher-event-loop-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 19.0 in stage 4.0 (TID 85, localhost, executor driver, partition 19, ANY, 7649 bytes)
2021-12-03 21:29:35,370 [dispatcher-event-loop-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 20.0 in stage 4.0 (TID 86, localhost, executor driver, partition 20, ANY, 7649 bytes)
2021-12-03 21:29:35,370 [Executor task launch worker for task 84] INFO [org.apache.spark.executor.Executor] - Running task 18.0 in stage 4.0 (TID 84)
2021-12-03 21:29:35,370 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 10.0 in stage 4.0 (TID 76) in 151 ms on localhost (executor driver) (6/22)
2021-12-03 21:29:35,370 [Executor task launch worker for task 86] INFO [org.apache.spark.executor.Executor] - Running task 20.0 in stage 4.0 (TID 86)
2021-12-03 21:29:35,370 [Executor task launch worker for task 83] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 21:29:35,370 [Executor task launch worker for task 83] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 21:29:35,370 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 4.0 (TID 67) in 152 ms on localhost (executor driver) (7/22)
2021-12-03 21:29:35,370 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 9.0 in stage 4.0 (TID 75) in 151 ms on localhost (executor driver) (8/22)
2021-12-03 21:29:35,370 [Executor task launch worker for task 68] INFO [org.apache.spark.executor.Executor] - Finished task 2.0 in stage 4.0 (TID 68). 1189 bytes result sent to driver
2021-12-03 21:29:35,370 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 5.0 in stage 4.0 (TID 71) in 151 ms on localhost (executor driver) (9/22)
2021-12-03 21:29:35,371 [Executor task launch worker for task 84] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 21:29:35,371 [Executor task launch worker for task 84] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 21:29:35,371 [Executor task launch worker for task 86] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 21:29:35,371 [Executor task launch worker for task 86] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 21:29:35,371 [Executor task launch worker for task 85] INFO [org.apache.spark.executor.Executor] - Running task 19.0 in stage 4.0 (TID 85)
2021-12-03 21:29:35,371 [dispatcher-event-loop-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 21.0 in stage 4.0 (TID 87, localhost, executor driver, partition 21, ANY, 7649 bytes)
2021-12-03 21:29:35,371 [Executor task launch worker for task 87] INFO [org.apache.spark.executor.Executor] - Running task 21.0 in stage 4.0 (TID 87)
2021-12-03 21:29:35,371 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 2.0 in stage 4.0 (TID 68) in 153 ms on localhost (executor driver) (10/22)
2021-12-03 21:29:35,372 [Executor task launch worker for task 87] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 21:29:35,372 [Executor task launch worker for task 87] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 21:29:35,372 [Executor task launch worker for task 85] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 21:29:35,372 [Executor task launch worker for task 85] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 21:29:35,374 [Executor task launch worker for task 66] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 4.0 (TID 66). 1188 bytes result sent to driver
2021-12-03 21:29:35,375 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 4.0 (TID 66) in 157 ms on localhost (executor driver) (11/22)
2021-12-03 21:29:35,376 [Executor task launch worker for task 72] INFO [org.apache.spark.executor.Executor] - Finished task 6.0 in stage 4.0 (TID 72). 1138 bytes result sent to driver
2021-12-03 21:29:35,376 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 6.0 in stage 4.0 (TID 72) in 157 ms on localhost (executor driver) (12/22)
2021-12-03 21:29:35,485 [Executor task launch worker for task 79] INFO [org.apache.spark.executor.Executor] - Finished task 13.0 in stage 4.0 (TID 79). 1141 bytes result sent to driver
2021-12-03 21:29:35,486 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 13.0 in stage 4.0 (TID 79) in 126 ms on localhost (executor driver) (13/22)
2021-12-03 21:29:35,488 [Executor task launch worker for task 82] INFO [org.apache.spark.executor.Executor] - Finished task 16.0 in stage 4.0 (TID 82). 1143 bytes result sent to driver
2021-12-03 21:29:35,488 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 16.0 in stage 4.0 (TID 82) in 122 ms on localhost (executor driver) (14/22)
2021-12-03 21:29:35,490 [Executor task launch worker for task 81] INFO [org.apache.spark.executor.Executor] - Finished task 15.0 in stage 4.0 (TID 81). 1137 bytes result sent to driver
2021-12-03 21:29:35,491 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 15.0 in stage 4.0 (TID 81) in 128 ms on localhost (executor driver) (15/22)
2021-12-03 21:29:35,491 [Executor task launch worker for task 86] INFO [org.apache.spark.executor.Executor] - Finished task 20.0 in stage 4.0 (TID 86). 1189 bytes result sent to driver
2021-12-03 21:29:35,492 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 20.0 in stage 4.0 (TID 86) in 122 ms on localhost (executor driver) (16/22)
2021-12-03 21:29:35,492 [Executor task launch worker for task 78] INFO [org.apache.spark.executor.Executor] - Finished task 12.0 in stage 4.0 (TID 78). 1142 bytes result sent to driver
2021-12-03 21:29:35,492 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 12.0 in stage 4.0 (TID 78) in 133 ms on localhost (executor driver) (17/22)
2021-12-03 21:29:35,494 [Executor task launch worker for task 87] INFO [org.apache.spark.executor.Executor] - Finished task 21.0 in stage 4.0 (TID 87). 1187 bytes result sent to driver
2021-12-03 21:29:35,494 [Executor task launch worker for task 80] INFO [org.apache.spark.executor.Executor] - Finished task 14.0 in stage 4.0 (TID 80). 1228 bytes result sent to driver
2021-12-03 21:29:35,494 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 21.0 in stage 4.0 (TID 87) in 123 ms on localhost (executor driver) (18/22)
2021-12-03 21:29:35,494 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 14.0 in stage 4.0 (TID 80) in 131 ms on localhost (executor driver) (19/22)
2021-12-03 21:29:35,498 [Executor task launch worker for task 85] INFO [org.apache.spark.executor.Executor] - Finished task 19.0 in stage 4.0 (TID 85). 1189 bytes result sent to driver
2021-12-03 21:29:35,499 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 19.0 in stage 4.0 (TID 85) in 130 ms on localhost (executor driver) (20/22)
2021-12-03 21:29:35,499 [Executor task launch worker for task 84] INFO [org.apache.spark.executor.Executor] - Finished task 18.0 in stage 4.0 (TID 84). 1137 bytes result sent to driver
2021-12-03 21:29:35,499 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 18.0 in stage 4.0 (TID 84) in 130 ms on localhost (executor driver) (21/22)
2021-12-03 21:29:35,500 [Executor task launch worker for task 83] INFO [org.apache.spark.executor.Executor] - Finished task 17.0 in stage 4.0 (TID 83). 1142 bytes result sent to driver
2021-12-03 21:29:35,500 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 17.0 in stage 4.0 (TID 83) in 132 ms on localhost (executor driver) (22/22)
2021-12-03 21:29:35,500 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 4.0, whose tasks have all completed, from pool 
2021-12-03 21:29:35,500 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 4 (sortByKey at PaidPromotionAdjustParameter.scala:73) finished in 0.286 s
2021-12-03 21:29:35,500 [main] INFO [org.apache.spark.scheduler.DAGScheduler] - Job 2 finished: sortByKey at PaidPromotionAdjustParameter.scala:73, took 0.290320 s
2021-12-03 21:29:35,516 [main] INFO [org.apache.spark.SparkContext] - Starting job: zipWithIndex at PaidPromotionAdjustParameter.scala:74
2021-12-03 21:29:35,516 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 5 (map at PaidPromotionAdjustParameter.scala:72)
2021-12-03 21:29:35,516 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 3 (zipWithIndex at PaidPromotionAdjustParameter.scala:74) with 21 output partitions
2021-12-03 21:29:35,516 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 7 (zipWithIndex at PaidPromotionAdjustParameter.scala:74)
2021-12-03 21:29:35,516 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 6)
2021-12-03 21:29:35,517 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List(ShuffleMapStage 6)
2021-12-03 21:29:35,517 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ShuffleMapStage 6 (MapPartitionsRDD[5] at map at PaidPromotionAdjustParameter.scala:72), which has no missing parents
2021-12-03 21:29:35,524 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_5 stored as values in memory (estimated size 4.1 KB, free 1990.4 MB)
2021-12-03 21:29:35,526 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_5_piece0 stored as bytes in memory (estimated size 2.4 KB, free 1990.4 MB)
2021-12-03 21:29:35,526 [dispatcher-event-loop-11] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_5_piece0 in memory on qb:61634 (size: 2.4 KB, free: 1990.8 MB)
2021-12-03 21:29:35,526 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 5 from broadcast at DAGScheduler.scala:1039
2021-12-03 21:29:35,527 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 22 missing tasks from ShuffleMapStage 6 (MapPartitionsRDD[5] at map at PaidPromotionAdjustParameter.scala:72) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14))
2021-12-03 21:29:35,527 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 6.0 with 22 tasks
2021-12-03 21:29:35,527 [dispatcher-event-loop-4] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 6.0 (TID 88, localhost, executor driver, partition 0, ANY, 7638 bytes)
2021-12-03 21:29:35,527 [dispatcher-event-loop-4] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 6.0 (TID 89, localhost, executor driver, partition 1, ANY, 7638 bytes)
2021-12-03 21:29:35,527 [dispatcher-event-loop-4] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 2.0 in stage 6.0 (TID 90, localhost, executor driver, partition 2, ANY, 7638 bytes)
2021-12-03 21:29:35,527 [dispatcher-event-loop-4] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 3.0 in stage 6.0 (TID 91, localhost, executor driver, partition 3, ANY, 7638 bytes)
2021-12-03 21:29:35,528 [dispatcher-event-loop-4] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 4.0 in stage 6.0 (TID 92, localhost, executor driver, partition 4, ANY, 7638 bytes)
2021-12-03 21:29:35,528 [dispatcher-event-loop-4] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 5.0 in stage 6.0 (TID 93, localhost, executor driver, partition 5, ANY, 7638 bytes)
2021-12-03 21:29:35,528 [dispatcher-event-loop-4] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 6.0 in stage 6.0 (TID 94, localhost, executor driver, partition 6, ANY, 7638 bytes)
2021-12-03 21:29:35,528 [dispatcher-event-loop-4] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 7.0 in stage 6.0 (TID 95, localhost, executor driver, partition 7, ANY, 7638 bytes)
2021-12-03 21:29:35,528 [dispatcher-event-loop-4] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 8.0 in stage 6.0 (TID 96, localhost, executor driver, partition 8, ANY, 7638 bytes)
2021-12-03 21:29:35,528 [dispatcher-event-loop-4] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 9.0 in stage 6.0 (TID 97, localhost, executor driver, partition 9, ANY, 7638 bytes)
2021-12-03 21:29:35,528 [dispatcher-event-loop-4] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 10.0 in stage 6.0 (TID 98, localhost, executor driver, partition 10, ANY, 7638 bytes)
2021-12-03 21:29:35,528 [dispatcher-event-loop-4] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 11.0 in stage 6.0 (TID 99, localhost, executor driver, partition 11, ANY, 7638 bytes)
2021-12-03 21:29:35,528 [Executor task launch worker for task 89] INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 6.0 (TID 89)
2021-12-03 21:29:35,528 [Executor task launch worker for task 90] INFO [org.apache.spark.executor.Executor] - Running task 2.0 in stage 6.0 (TID 90)
2021-12-03 21:29:35,528 [Executor task launch worker for task 95] INFO [org.apache.spark.executor.Executor] - Running task 7.0 in stage 6.0 (TID 95)
2021-12-03 21:29:35,528 [Executor task launch worker for task 96] INFO [org.apache.spark.executor.Executor] - Running task 8.0 in stage 6.0 (TID 96)
2021-12-03 21:29:35,528 [Executor task launch worker for task 92] INFO [org.apache.spark.executor.Executor] - Running task 4.0 in stage 6.0 (TID 92)
2021-12-03 21:29:35,528 [Executor task launch worker for task 91] INFO [org.apache.spark.executor.Executor] - Running task 3.0 in stage 6.0 (TID 91)
2021-12-03 21:29:35,528 [Executor task launch worker for task 94] INFO [org.apache.spark.executor.Executor] - Running task 6.0 in stage 6.0 (TID 94)
2021-12-03 21:29:35,528 [Executor task launch worker for task 88] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 6.0 (TID 88)
2021-12-03 21:29:35,528 [Executor task launch worker for task 93] INFO [org.apache.spark.executor.Executor] - Running task 5.0 in stage 6.0 (TID 93)
2021-12-03 21:29:35,528 [Executor task launch worker for task 97] INFO [org.apache.spark.executor.Executor] - Running task 9.0 in stage 6.0 (TID 97)
2021-12-03 21:29:35,528 [Executor task launch worker for task 98] INFO [org.apache.spark.executor.Executor] - Running task 10.0 in stage 6.0 (TID 98)
2021-12-03 21:29:35,528 [Executor task launch worker for task 99] INFO [org.apache.spark.executor.Executor] - Running task 11.0 in stage 6.0 (TID 99)
2021-12-03 21:29:35,538 [Executor task launch worker for task 89] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 21:29:35,538 [Executor task launch worker for task 89] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 21:29:35,538 [Executor task launch worker for task 96] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 21:29:35,538 [Executor task launch worker for task 96] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 21:29:35,538 [Executor task launch worker for task 92] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 21:29:35,538 [Executor task launch worker for task 92] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 21:29:35,538 [Executor task launch worker for task 94] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 21:29:35,538 [Executor task launch worker for task 94] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 21:29:35,538 [Executor task launch worker for task 97] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 21:29:35,538 [Executor task launch worker for task 90] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 21:29:35,538 [Executor task launch worker for task 97] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 21:29:35,538 [Executor task launch worker for task 88] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 21:29:35,538 [Executor task launch worker for task 98] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 21:29:35,538 [Executor task launch worker for task 98] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 21:29:35,538 [Executor task launch worker for task 88] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 21:29:35,538 [Executor task launch worker for task 93] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 21:29:35,538 [Executor task launch worker for task 95] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 21:29:35,538 [Executor task launch worker for task 90] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 21:29:35,538 [Executor task launch worker for task 95] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 21:29:35,538 [Executor task launch worker for task 93] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 21:29:35,538 [Executor task launch worker for task 91] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 21:29:35,538 [Executor task launch worker for task 91] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 21:29:35,539 [Executor task launch worker for task 99] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 21:29:35,539 [Executor task launch worker for task 99] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 21:29:36,001 [Executor task launch worker for task 96] INFO [org.apache.spark.executor.Executor] - Finished task 8.0 in stage 6.0 (TID 96). 1224 bytes result sent to driver
2021-12-03 21:29:36,001 [dispatcher-event-loop-5] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 12.0 in stage 6.0 (TID 100, localhost, executor driver, partition 12, ANY, 7638 bytes)
2021-12-03 21:29:36,002 [Executor task launch worker for task 100] INFO [org.apache.spark.executor.Executor] - Running task 12.0 in stage 6.0 (TID 100)
2021-12-03 21:29:36,002 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 8.0 in stage 6.0 (TID 96) in 474 ms on localhost (executor driver) (1/22)
2021-12-03 21:29:36,006 [Executor task launch worker for task 100] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 21:29:36,006 [Executor task launch worker for task 100] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 21:29:36,008 [Executor task launch worker for task 97] INFO [org.apache.spark.executor.Executor] - Finished task 9.0 in stage 6.0 (TID 97). 1267 bytes result sent to driver
2021-12-03 21:29:36,008 [dispatcher-event-loop-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 13.0 in stage 6.0 (TID 101, localhost, executor driver, partition 13, ANY, 7638 bytes)
2021-12-03 21:29:36,008 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 9.0 in stage 6.0 (TID 97) in 480 ms on localhost (executor driver) (2/22)
2021-12-03 21:29:36,008 [Executor task launch worker for task 101] INFO [org.apache.spark.executor.Executor] - Running task 13.0 in stage 6.0 (TID 101)
2021-12-03 21:29:36,011 [Executor task launch worker for task 98] INFO [org.apache.spark.executor.Executor] - Finished task 10.0 in stage 6.0 (TID 98). 1267 bytes result sent to driver
2021-12-03 21:29:36,011 [dispatcher-event-loop-7] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 14.0 in stage 6.0 (TID 102, localhost, executor driver, partition 14, ANY, 7638 bytes)
2021-12-03 21:29:36,012 [Executor task launch worker for task 102] INFO [org.apache.spark.executor.Executor] - Running task 14.0 in stage 6.0 (TID 102)
2021-12-03 21:29:36,012 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 10.0 in stage 6.0 (TID 98) in 484 ms on localhost (executor driver) (3/22)
2021-12-03 21:29:36,012 [Executor task launch worker for task 101] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 21:29:36,012 [Executor task launch worker for task 101] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 21:29:36,016 [Executor task launch worker for task 102] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 21:29:36,016 [Executor task launch worker for task 102] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 21:29:36,033 [Executor task launch worker for task 92] INFO [org.apache.spark.executor.Executor] - Finished task 4.0 in stage 6.0 (TID 92). 1267 bytes result sent to driver
2021-12-03 21:29:36,034 [dispatcher-event-loop-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 15.0 in stage 6.0 (TID 103, localhost, executor driver, partition 15, ANY, 7638 bytes)
2021-12-03 21:29:36,034 [Executor task launch worker for task 103] INFO [org.apache.spark.executor.Executor] - Running task 15.0 in stage 6.0 (TID 103)
2021-12-03 21:29:36,034 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 4.0 in stage 6.0 (TID 92) in 506 ms on localhost (executor driver) (4/22)
2021-12-03 21:29:36,039 [Executor task launch worker for task 103] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 21:29:36,039 [Executor task launch worker for task 103] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 21:29:36,040 [Executor task launch worker for task 94] INFO [org.apache.spark.executor.Executor] - Finished task 6.0 in stage 6.0 (TID 94). 1224 bytes result sent to driver
2021-12-03 21:29:36,043 [dispatcher-event-loop-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 16.0 in stage 6.0 (TID 104, localhost, executor driver, partition 16, ANY, 7638 bytes)
2021-12-03 21:29:36,043 [Executor task launch worker for task 104] INFO [org.apache.spark.executor.Executor] - Running task 16.0 in stage 6.0 (TID 104)
2021-12-03 21:29:36,043 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 6.0 in stage 6.0 (TID 94) in 515 ms on localhost (executor driver) (5/22)
2021-12-03 21:29:36,047 [Executor task launch worker for task 104] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 21:29:36,047 [Executor task launch worker for task 104] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 21:29:36,059 [Executor task launch worker for task 91] INFO [org.apache.spark.executor.Executor] - Finished task 3.0 in stage 6.0 (TID 91). 1267 bytes result sent to driver
2021-12-03 21:29:36,060 [dispatcher-event-loop-11] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 17.0 in stage 6.0 (TID 105, localhost, executor driver, partition 17, ANY, 7638 bytes)
2021-12-03 21:29:36,060 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 3.0 in stage 6.0 (TID 91) in 533 ms on localhost (executor driver) (6/22)
2021-12-03 21:29:36,061 [Executor task launch worker for task 105] INFO [org.apache.spark.executor.Executor] - Running task 17.0 in stage 6.0 (TID 105)
2021-12-03 21:29:36,065 [Executor task launch worker for task 105] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 21:29:36,065 [Executor task launch worker for task 105] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 21:29:36,066 [Executor task launch worker for task 90] INFO [org.apache.spark.executor.Executor] - Finished task 2.0 in stage 6.0 (TID 90). 1267 bytes result sent to driver
2021-12-03 21:29:36,067 [dispatcher-event-loop-5] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 18.0 in stage 6.0 (TID 106, localhost, executor driver, partition 18, ANY, 7638 bytes)
2021-12-03 21:29:36,068 [Executor task launch worker for task 106] INFO [org.apache.spark.executor.Executor] - Running task 18.0 in stage 6.0 (TID 106)
2021-12-03 21:29:36,069 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 2.0 in stage 6.0 (TID 90) in 542 ms on localhost (executor driver) (7/22)
2021-12-03 21:29:36,072 [Executor task launch worker for task 106] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 21:29:36,072 [Executor task launch worker for task 106] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 21:29:36,085 [Executor task launch worker for task 95] INFO [org.apache.spark.executor.Executor] - Finished task 7.0 in stage 6.0 (TID 95). 1267 bytes result sent to driver
2021-12-03 21:29:36,088 [Executor task launch worker for task 93] INFO [org.apache.spark.executor.Executor] - Finished task 5.0 in stage 6.0 (TID 93). 1267 bytes result sent to driver
2021-12-03 21:29:36,096 [dispatcher-event-loop-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 19.0 in stage 6.0 (TID 107, localhost, executor driver, partition 19, ANY, 7638 bytes)
2021-12-03 21:29:36,096 [dispatcher-event-loop-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 20.0 in stage 6.0 (TID 108, localhost, executor driver, partition 20, ANY, 7638 bytes)
2021-12-03 21:29:36,096 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 7.0 in stage 6.0 (TID 95) in 568 ms on localhost (executor driver) (8/22)
2021-12-03 21:29:36,096 [Executor task launch worker for task 108] INFO [org.apache.spark.executor.Executor] - Running task 20.0 in stage 6.0 (TID 108)
2021-12-03 21:29:36,096 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 5.0 in stage 6.0 (TID 93) in 568 ms on localhost (executor driver) (9/22)
2021-12-03 21:29:36,099 [Executor task launch worker for task 107] INFO [org.apache.spark.executor.Executor] - Running task 19.0 in stage 6.0 (TID 107)
2021-12-03 21:29:36,100 [Executor task launch worker for task 108] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 21:29:36,100 [Executor task launch worker for task 108] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 21:29:36,134 [Executor task launch worker for task 107] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 21:29:36,134 [Executor task launch worker for task 107] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 21:29:36,135 [Executor task launch worker for task 89] INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 6.0 (TID 89). 1267 bytes result sent to driver
2021-12-03 21:29:36,148 [dispatcher-event-loop-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 21.0 in stage 6.0 (TID 109, localhost, executor driver, partition 21, ANY, 7638 bytes)
2021-12-03 21:29:36,148 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 6.0 (TID 89) in 621 ms on localhost (executor driver) (10/22)
2021-12-03 21:29:36,151 [Executor task launch worker for task 109] INFO [org.apache.spark.executor.Executor] - Running task 21.0 in stage 6.0 (TID 109)
2021-12-03 21:29:36,155 [Executor task launch worker for task 109] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 21:29:36,155 [Executor task launch worker for task 109] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 21:29:36,157 [Executor task launch worker for task 99] INFO [org.apache.spark.executor.Executor] - Finished task 11.0 in stage 6.0 (TID 99). 1267 bytes result sent to driver
2021-12-03 21:29:36,162 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 11.0 in stage 6.0 (TID 99) in 634 ms on localhost (executor driver) (11/22)
2021-12-03 21:29:36,173 [Executor task launch worker for task 88] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 6.0 (TID 88). 1267 bytes result sent to driver
2021-12-03 21:29:36,174 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 6.0 (TID 88) in 647 ms on localhost (executor driver) (12/22)
2021-12-03 21:29:36,413 [Executor task launch worker for task 100] INFO [org.apache.spark.executor.Executor] - Finished task 12.0 in stage 6.0 (TID 100). 1267 bytes result sent to driver
2021-12-03 21:29:36,414 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 12.0 in stage 6.0 (TID 100) in 413 ms on localhost (executor driver) (13/22)
2021-12-03 21:29:36,430 [Executor task launch worker for task 104] INFO [org.apache.spark.executor.Executor] - Finished task 16.0 in stage 6.0 (TID 104). 1310 bytes result sent to driver
2021-12-03 21:29:36,430 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 16.0 in stage 6.0 (TID 104) in 388 ms on localhost (executor driver) (14/22)
2021-12-03 21:29:36,506 [Executor task launch worker for task 101] INFO [org.apache.spark.executor.Executor] - Finished task 13.0 in stage 6.0 (TID 101). 1267 bytes result sent to driver
2021-12-03 21:29:36,507 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 13.0 in stage 6.0 (TID 101) in 499 ms on localhost (executor driver) (15/22)
2021-12-03 21:29:36,510 [Executor task launch worker for task 103] INFO [org.apache.spark.executor.Executor] - Finished task 15.0 in stage 6.0 (TID 103). 1267 bytes result sent to driver
2021-12-03 21:29:36,511 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 15.0 in stage 6.0 (TID 103) in 478 ms on localhost (executor driver) (16/22)
2021-12-03 21:29:36,524 [Executor task launch worker for task 102] INFO [org.apache.spark.executor.Executor] - Finished task 14.0 in stage 6.0 (TID 102). 1267 bytes result sent to driver
2021-12-03 21:29:36,524 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 14.0 in stage 6.0 (TID 102) in 513 ms on localhost (executor driver) (17/22)
2021-12-03 21:29:36,551 [Executor task launch worker for task 106] INFO [org.apache.spark.executor.Executor] - Finished task 18.0 in stage 6.0 (TID 106). 1267 bytes result sent to driver
2021-12-03 21:29:36,551 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 18.0 in stage 6.0 (TID 106) in 484 ms on localhost (executor driver) (18/22)
2021-12-03 21:29:36,552 [Executor task launch worker for task 108] INFO [org.apache.spark.executor.Executor] - Finished task 20.0 in stage 6.0 (TID 108). 1267 bytes result sent to driver
2021-12-03 21:29:36,552 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 20.0 in stage 6.0 (TID 108) in 456 ms on localhost (executor driver) (19/22)
2021-12-03 21:29:36,557 [Executor task launch worker for task 105] INFO [org.apache.spark.executor.Executor] - Finished task 17.0 in stage 6.0 (TID 105). 1310 bytes result sent to driver
2021-12-03 21:29:36,557 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 17.0 in stage 6.0 (TID 105) in 497 ms on localhost (executor driver) (20/22)
2021-12-03 21:29:36,580 [Executor task launch worker for task 109] INFO [org.apache.spark.executor.Executor] - Finished task 21.0 in stage 6.0 (TID 109). 1224 bytes result sent to driver
2021-12-03 21:29:36,581 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 21.0 in stage 6.0 (TID 109) in 432 ms on localhost (executor driver) (21/22)
2021-12-03 21:29:36,585 [Executor task launch worker for task 107] INFO [org.apache.spark.executor.Executor] - Finished task 19.0 in stage 6.0 (TID 107). 1310 bytes result sent to driver
2021-12-03 21:29:36,585 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 19.0 in stage 6.0 (TID 107) in 490 ms on localhost (executor driver) (22/22)
2021-12-03 21:29:36,585 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 6.0, whose tasks have all completed, from pool 
2021-12-03 21:29:36,585 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ShuffleMapStage 6 (map at PaidPromotionAdjustParameter.scala:72) finished in 1.066 s
2021-12-03 21:29:36,585 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - looking for newly runnable stages
2021-12-03 21:29:36,585 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - running: Set()
2021-12-03 21:29:36,585 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - waiting: Set(ResultStage 7)
2021-12-03 21:29:36,585 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - failed: Set()
2021-12-03 21:29:36,585 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 7 (ShuffledRDD[8] at sortByKey at PaidPromotionAdjustParameter.scala:73), which has no missing parents
2021-12-03 21:29:36,588 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_6 stored as values in memory (estimated size 3.4 KB, free 1990.4 MB)
2021-12-03 21:29:36,589 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_6_piece0 stored as bytes in memory (estimated size 2.0 KB, free 1990.4 MB)
2021-12-03 21:29:36,589 [dispatcher-event-loop-3] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_6_piece0 in memory on qb:61634 (size: 2.0 KB, free: 1990.8 MB)
2021-12-03 21:29:36,590 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 6 from broadcast at DAGScheduler.scala:1039
2021-12-03 21:29:36,590 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 21 missing tasks from ResultStage 7 (ShuffledRDD[8] at sortByKey at PaidPromotionAdjustParameter.scala:73) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14))
2021-12-03 21:29:36,590 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 7.0 with 21 tasks
2021-12-03 21:29:36,590 [dispatcher-event-loop-10] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 7.0 (TID 110, localhost, executor driver, partition 0, ANY, 7649 bytes)
2021-12-03 21:29:36,590 [dispatcher-event-loop-10] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 7.0 (TID 111, localhost, executor driver, partition 1, ANY, 7649 bytes)
2021-12-03 21:29:36,590 [dispatcher-event-loop-10] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 2.0 in stage 7.0 (TID 112, localhost, executor driver, partition 2, ANY, 7649 bytes)
2021-12-03 21:29:36,591 [dispatcher-event-loop-10] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 3.0 in stage 7.0 (TID 113, localhost, executor driver, partition 3, ANY, 7649 bytes)
2021-12-03 21:29:36,591 [dispatcher-event-loop-10] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 4.0 in stage 7.0 (TID 114, localhost, executor driver, partition 4, ANY, 7649 bytes)
2021-12-03 21:29:36,591 [dispatcher-event-loop-10] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 5.0 in stage 7.0 (TID 115, localhost, executor driver, partition 5, ANY, 7649 bytes)
2021-12-03 21:29:36,591 [dispatcher-event-loop-10] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 6.0 in stage 7.0 (TID 116, localhost, executor driver, partition 6, ANY, 7649 bytes)
2021-12-03 21:29:36,591 [dispatcher-event-loop-10] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 7.0 in stage 7.0 (TID 117, localhost, executor driver, partition 7, ANY, 7649 bytes)
2021-12-03 21:29:36,591 [dispatcher-event-loop-10] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 8.0 in stage 7.0 (TID 118, localhost, executor driver, partition 8, ANY, 7649 bytes)
2021-12-03 21:29:36,591 [dispatcher-event-loop-10] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 9.0 in stage 7.0 (TID 119, localhost, executor driver, partition 9, ANY, 7649 bytes)
2021-12-03 21:29:36,591 [dispatcher-event-loop-10] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 10.0 in stage 7.0 (TID 120, localhost, executor driver, partition 10, ANY, 7649 bytes)
2021-12-03 21:29:36,591 [dispatcher-event-loop-10] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 11.0 in stage 7.0 (TID 121, localhost, executor driver, partition 11, ANY, 7649 bytes)
2021-12-03 21:29:36,591 [Executor task launch worker for task 112] INFO [org.apache.spark.executor.Executor] - Running task 2.0 in stage 7.0 (TID 112)
2021-12-03 21:29:36,591 [Executor task launch worker for task 118] INFO [org.apache.spark.executor.Executor] - Running task 8.0 in stage 7.0 (TID 118)
2021-12-03 21:29:36,591 [Executor task launch worker for task 117] INFO [org.apache.spark.executor.Executor] - Running task 7.0 in stage 7.0 (TID 117)
2021-12-03 21:29:36,591 [Executor task launch worker for task 116] INFO [org.apache.spark.executor.Executor] - Running task 6.0 in stage 7.0 (TID 116)
2021-12-03 21:29:36,591 [Executor task launch worker for task 114] INFO [org.apache.spark.executor.Executor] - Running task 4.0 in stage 7.0 (TID 114)
2021-12-03 21:29:36,591 [Executor task launch worker for task 113] INFO [org.apache.spark.executor.Executor] - Running task 3.0 in stage 7.0 (TID 113)
2021-12-03 21:29:36,591 [Executor task launch worker for task 111] INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 7.0 (TID 111)
2021-12-03 21:29:36,591 [Executor task launch worker for task 110] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 7.0 (TID 110)
2021-12-03 21:29:36,591 [Executor task launch worker for task 115] INFO [org.apache.spark.executor.Executor] - Running task 5.0 in stage 7.0 (TID 115)
2021-12-03 21:29:36,591 [Executor task launch worker for task 120] INFO [org.apache.spark.executor.Executor] - Running task 10.0 in stage 7.0 (TID 120)
2021-12-03 21:29:36,591 [Executor task launch worker for task 121] INFO [org.apache.spark.executor.Executor] - Running task 11.0 in stage 7.0 (TID 121)
2021-12-03 21:29:36,591 [Executor task launch worker for task 119] INFO [org.apache.spark.executor.Executor] - Running task 9.0 in stage 7.0 (TID 119)
2021-12-03 21:29:36,595 [Executor task launch worker for task 115] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 21:29:36,595 [Executor task launch worker for task 115] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 21:29:36,595 [Executor task launch worker for task 120] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 21:29:36,595 [Executor task launch worker for task 120] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 21:29:36,596 [Executor task launch worker for task 117] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 21:29:36,596 [Executor task launch worker for task 117] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 21:29:36,596 [Executor task launch worker for task 114] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 21:29:36,596 [Executor task launch worker for task 114] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 21:29:36,597 [Executor task launch worker for task 121] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 21:29:36,597 [Executor task launch worker for task 110] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 21:29:36,597 [Executor task launch worker for task 121] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 21:29:36,597 [Executor task launch worker for task 110] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 21:29:36,598 [Executor task launch worker for task 113] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 21:29:36,598 [Executor task launch worker for task 113] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 21:29:36,599 [Executor task launch worker for task 118] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 21:29:36,599 [Executor task launch worker for task 118] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 21:29:36,599 [Executor task launch worker for task 111] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 21:29:36,599 [Executor task launch worker for task 111] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 21:29:36,600 [Executor task launch worker for task 116] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 21:29:36,600 [Executor task launch worker for task 116] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 21:29:36,600 [Executor task launch worker for task 112] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 21:29:36,601 [Executor task launch worker for task 112] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 1 ms
2021-12-03 21:29:36,601 [Executor task launch worker for task 119] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 21:29:36,601 [Executor task launch worker for task 119] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 21:29:36,866 [Executor task launch worker for task 119] INFO [org.apache.spark.executor.Executor] - Finished task 9.0 in stage 7.0 (TID 119). 1055 bytes result sent to driver
2021-12-03 21:29:36,866 [dispatcher-event-loop-11] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 12.0 in stage 7.0 (TID 122, localhost, executor driver, partition 12, ANY, 7649 bytes)
2021-12-03 21:29:36,866 [Executor task launch worker for task 122] INFO [org.apache.spark.executor.Executor] - Running task 12.0 in stage 7.0 (TID 122)
2021-12-03 21:29:36,868 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 9.0 in stage 7.0 (TID 119) in 277 ms on localhost (executor driver) (1/21)
2021-12-03 21:29:36,870 [Executor task launch worker for task 122] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 21:29:36,870 [Executor task launch worker for task 122] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 21:29:36,870 [Executor task launch worker for task 115] INFO [org.apache.spark.executor.Executor] - Finished task 5.0 in stage 7.0 (TID 115). 1055 bytes result sent to driver
2021-12-03 21:29:36,870 [dispatcher-event-loop-5] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 13.0 in stage 7.0 (TID 123, localhost, executor driver, partition 13, ANY, 7649 bytes)
2021-12-03 21:29:36,870 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 5.0 in stage 7.0 (TID 115) in 279 ms on localhost (executor driver) (2/21)
2021-12-03 21:29:36,870 [Executor task launch worker for task 123] INFO [org.apache.spark.executor.Executor] - Running task 13.0 in stage 7.0 (TID 123)
2021-12-03 21:29:36,871 [Executor task launch worker for task 118] INFO [org.apache.spark.executor.Executor] - Finished task 8.0 in stage 7.0 (TID 118). 1055 bytes result sent to driver
2021-12-03 21:29:36,871 [dispatcher-event-loop-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 14.0 in stage 7.0 (TID 124, localhost, executor driver, partition 14, ANY, 7649 bytes)
2021-12-03 21:29:36,871 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 8.0 in stage 7.0 (TID 118) in 280 ms on localhost (executor driver) (3/21)
2021-12-03 21:29:36,871 [Executor task launch worker for task 124] INFO [org.apache.spark.executor.Executor] - Running task 14.0 in stage 7.0 (TID 124)
2021-12-03 21:29:36,874 [Executor task launch worker for task 123] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 21:29:36,874 [Executor task launch worker for task 123] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 21:29:36,875 [Executor task launch worker for task 124] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 21:29:36,875 [Executor task launch worker for task 124] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 1 ms
2021-12-03 21:29:36,875 [Executor task launch worker for task 121] INFO [org.apache.spark.executor.Executor] - Finished task 11.0 in stage 7.0 (TID 121). 1098 bytes result sent to driver
2021-12-03 21:29:36,878 [dispatcher-event-loop-7] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 15.0 in stage 7.0 (TID 125, localhost, executor driver, partition 15, ANY, 7649 bytes)
2021-12-03 21:29:36,878 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 11.0 in stage 7.0 (TID 121) in 287 ms on localhost (executor driver) (4/21)
2021-12-03 21:29:36,878 [Executor task launch worker for task 125] INFO [org.apache.spark.executor.Executor] - Running task 15.0 in stage 7.0 (TID 125)
2021-12-03 21:29:36,881 [Executor task launch worker for task 113] INFO [org.apache.spark.executor.Executor] - Finished task 3.0 in stage 7.0 (TID 113). 1055 bytes result sent to driver
2021-12-03 21:29:36,881 [Executor task launch worker for task 116] INFO [org.apache.spark.executor.Executor] - Finished task 6.0 in stage 7.0 (TID 116). 1055 bytes result sent to driver
2021-12-03 21:29:36,881 [Executor task launch worker for task 110] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 7.0 (TID 110). 1055 bytes result sent to driver
2021-12-03 21:29:36,881 [Executor task launch worker for task 117] INFO [org.apache.spark.executor.Executor] - Finished task 7.0 in stage 7.0 (TID 117). 1098 bytes result sent to driver
2021-12-03 21:29:36,881 [dispatcher-event-loop-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 16.0 in stage 7.0 (TID 126, localhost, executor driver, partition 16, ANY, 7649 bytes)
2021-12-03 21:29:36,882 [Executor task launch worker for task 126] INFO [org.apache.spark.executor.Executor] - Running task 16.0 in stage 7.0 (TID 126)
2021-12-03 21:29:36,882 [dispatcher-event-loop-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 17.0 in stage 7.0 (TID 127, localhost, executor driver, partition 17, ANY, 7649 bytes)
2021-12-03 21:29:36,883 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 3.0 in stage 7.0 (TID 113) in 293 ms on localhost (executor driver) (5/21)
2021-12-03 21:29:36,883 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 6.0 in stage 7.0 (TID 116) in 292 ms on localhost (executor driver) (6/21)
2021-12-03 21:29:36,883 [Executor task launch worker for task 125] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 21:29:36,883 [Executor task launch worker for task 125] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 21:29:36,883 [dispatcher-event-loop-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 18.0 in stage 7.0 (TID 128, localhost, executor driver, partition 18, ANY, 7649 bytes)
2021-12-03 21:29:36,883 [Executor task launch worker for task 127] INFO [org.apache.spark.executor.Executor] - Running task 17.0 in stage 7.0 (TID 127)
2021-12-03 21:29:36,883 [Executor task launch worker for task 128] INFO [org.apache.spark.executor.Executor] - Running task 18.0 in stage 7.0 (TID 128)
2021-12-03 21:29:36,883 [Executor task launch worker for task 120] INFO [org.apache.spark.executor.Executor] - Finished task 10.0 in stage 7.0 (TID 120). 1055 bytes result sent to driver
2021-12-03 21:29:36,883 [dispatcher-event-loop-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 19.0 in stage 7.0 (TID 129, localhost, executor driver, partition 19, ANY, 7649 bytes)
2021-12-03 21:29:36,884 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 7.0 in stage 7.0 (TID 117) in 292 ms on localhost (executor driver) (7/21)
2021-12-03 21:29:36,884 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 7.0 (TID 110) in 294 ms on localhost (executor driver) (8/21)
2021-12-03 21:29:36,884 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 10.0 in stage 7.0 (TID 120) in 293 ms on localhost (executor driver) (9/21)
2021-12-03 21:29:36,884 [Executor task launch worker for task 129] INFO [org.apache.spark.executor.Executor] - Running task 19.0 in stage 7.0 (TID 129)
2021-12-03 21:29:36,884 [dispatcher-event-loop-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 20.0 in stage 7.0 (TID 130, localhost, executor driver, partition 20, ANY, 7649 bytes)
2021-12-03 21:29:36,884 [Executor task launch worker for task 130] INFO [org.apache.spark.executor.Executor] - Running task 20.0 in stage 7.0 (TID 130)
2021-12-03 21:29:36,885 [Executor task launch worker for task 126] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 21:29:36,885 [Executor task launch worker for task 126] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 21:29:36,887 [Executor task launch worker for task 111] INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 7.0 (TID 111). 1055 bytes result sent to driver
2021-12-03 21:29:36,887 [Executor task launch worker for task 114] INFO [org.apache.spark.executor.Executor] - Finished task 4.0 in stage 7.0 (TID 114). 1098 bytes result sent to driver
2021-12-03 21:29:36,888 [Executor task launch worker for task 127] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 21:29:36,888 [Executor task launch worker for task 127] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 21:29:36,888 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 7.0 (TID 111) in 298 ms on localhost (executor driver) (10/21)
2021-12-03 21:29:36,888 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 4.0 in stage 7.0 (TID 114) in 297 ms on localhost (executor driver) (11/21)
2021-12-03 21:29:36,888 [Executor task launch worker for task 129] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 21:29:36,888 [Executor task launch worker for task 129] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 21:29:36,889 [Executor task launch worker for task 130] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 21:29:36,890 [Executor task launch worker for task 130] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 1 ms
2021-12-03 21:29:36,890 [Executor task launch worker for task 128] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 21:29:36,890 [Executor task launch worker for task 128] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 21:29:36,891 [Executor task launch worker for task 112] INFO [org.apache.spark.executor.Executor] - Finished task 2.0 in stage 7.0 (TID 112). 1055 bytes result sent to driver
2021-12-03 21:29:36,902 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 2.0 in stage 7.0 (TID 112) in 312 ms on localhost (executor driver) (12/21)
2021-12-03 21:29:36,914 [dispatcher-event-loop-11] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_5_piece0 on qb:61634 in memory (size: 2.4 KB, free: 1990.8 MB)
2021-12-03 21:29:36,959 [Executor task launch worker for task 124] INFO [org.apache.spark.executor.Executor] - Finished task 14.0 in stage 7.0 (TID 124). 1098 bytes result sent to driver
2021-12-03 21:29:36,959 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 14.0 in stage 7.0 (TID 124) in 88 ms on localhost (executor driver) (13/21)
2021-12-03 21:29:36,970 [Executor task launch worker for task 126] INFO [org.apache.spark.executor.Executor] - Finished task 16.0 in stage 7.0 (TID 126). 1098 bytes result sent to driver
2021-12-03 21:29:36,971 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 16.0 in stage 7.0 (TID 126) in 90 ms on localhost (executor driver) (14/21)
2021-12-03 21:29:36,980 [Executor task launch worker for task 130] INFO [org.apache.spark.executor.Executor] - Finished task 20.0 in stage 7.0 (TID 130). 1098 bytes result sent to driver
2021-12-03 21:29:36,980 [Executor task launch worker for task 123] INFO [org.apache.spark.executor.Executor] - Finished task 13.0 in stage 7.0 (TID 123). 1098 bytes result sent to driver
2021-12-03 21:29:36,980 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 20.0 in stage 7.0 (TID 130) in 96 ms on localhost (executor driver) (15/21)
2021-12-03 21:29:36,980 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 13.0 in stage 7.0 (TID 123) in 110 ms on localhost (executor driver) (16/21)
2021-12-03 21:29:36,982 [Executor task launch worker for task 125] INFO [org.apache.spark.executor.Executor] - Finished task 15.0 in stage 7.0 (TID 125). 1098 bytes result sent to driver
2021-12-03 21:29:36,982 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 15.0 in stage 7.0 (TID 125) in 104 ms on localhost (executor driver) (17/21)
2021-12-03 21:29:36,983 [Executor task launch worker for task 128] INFO [org.apache.spark.executor.Executor] - Finished task 18.0 in stage 7.0 (TID 128). 1098 bytes result sent to driver
2021-12-03 21:29:36,983 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 18.0 in stage 7.0 (TID 128) in 100 ms on localhost (executor driver) (18/21)
2021-12-03 21:29:36,983 [Executor task launch worker for task 122] INFO [org.apache.spark.executor.Executor] - Finished task 12.0 in stage 7.0 (TID 122). 1098 bytes result sent to driver
2021-12-03 21:29:36,983 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 12.0 in stage 7.0 (TID 122) in 117 ms on localhost (executor driver) (19/21)
2021-12-03 21:29:36,985 [Executor task launch worker for task 129] INFO [org.apache.spark.executor.Executor] - Finished task 19.0 in stage 7.0 (TID 129). 1098 bytes result sent to driver
2021-12-03 21:29:36,986 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 19.0 in stage 7.0 (TID 129) in 103 ms on localhost (executor driver) (20/21)
2021-12-03 21:29:36,993 [Executor task launch worker for task 127] INFO [org.apache.spark.executor.Executor] - Finished task 17.0 in stage 7.0 (TID 127). 1098 bytes result sent to driver
2021-12-03 21:29:36,993 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 17.0 in stage 7.0 (TID 127) in 111 ms on localhost (executor driver) (21/21)
2021-12-03 21:29:36,993 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 7.0, whose tasks have all completed, from pool 
2021-12-03 21:29:36,993 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 7 (zipWithIndex at PaidPromotionAdjustParameter.scala:74) finished in 0.407 s
2021-12-03 21:29:36,994 [main] INFO [org.apache.spark.scheduler.DAGScheduler] - Job 3 finished: zipWithIndex at PaidPromotionAdjustParameter.scala:74, took 1.477250 s
2021-12-03 21:29:37,029 [main] INFO [org.apache.spark.SparkContext] - Starting job: count at PaidPromotionAdjustParameter.scala:79
2021-12-03 21:29:37,030 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 4 (count at PaidPromotionAdjustParameter.scala:79) with 22 output partitions
2021-12-03 21:29:37,030 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 10 (count at PaidPromotionAdjustParameter.scala:79)
2021-12-03 21:29:37,030 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 9)
2021-12-03 21:29:37,030 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2021-12-03 21:29:37,030 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 10 (MapPartitionsRDD[11] at map at PaidPromotionAdjustParameter.scala:76), which has no missing parents
2021-12-03 21:29:37,035 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_7 stored as values in memory (estimated size 4.2 KB, free 1990.4 MB)
2021-12-03 21:29:37,036 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_7_piece0 stored as bytes in memory (estimated size 2.4 KB, free 1990.4 MB)
2021-12-03 21:29:37,037 [dispatcher-event-loop-10] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_7_piece0 in memory on qb:61634 (size: 2.4 KB, free: 1990.8 MB)
2021-12-03 21:29:37,037 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 7 from broadcast at DAGScheduler.scala:1039
2021-12-03 21:29:37,037 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 22 missing tasks from ResultStage 10 (MapPartitionsRDD[11] at map at PaidPromotionAdjustParameter.scala:76) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14))
2021-12-03 21:29:37,037 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 10.0 with 22 tasks
2021-12-03 21:29:37,038 [dispatcher-event-loop-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 10.0 (TID 131, localhost, executor driver, partition 0, ANY, 7759 bytes)
2021-12-03 21:29:37,038 [dispatcher-event-loop-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 10.0 (TID 132, localhost, executor driver, partition 1, ANY, 7759 bytes)
2021-12-03 21:29:37,038 [dispatcher-event-loop-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 2.0 in stage 10.0 (TID 133, localhost, executor driver, partition 2, ANY, 7759 bytes)
2021-12-03 21:29:37,038 [dispatcher-event-loop-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 3.0 in stage 10.0 (TID 134, localhost, executor driver, partition 3, ANY, 7759 bytes)
2021-12-03 21:29:37,039 [dispatcher-event-loop-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 4.0 in stage 10.0 (TID 135, localhost, executor driver, partition 4, ANY, 7759 bytes)
2021-12-03 21:29:37,039 [dispatcher-event-loop-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 5.0 in stage 10.0 (TID 136, localhost, executor driver, partition 5, ANY, 7759 bytes)
2021-12-03 21:29:37,039 [dispatcher-event-loop-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 6.0 in stage 10.0 (TID 137, localhost, executor driver, partition 6, ANY, 7759 bytes)
2021-12-03 21:29:37,039 [dispatcher-event-loop-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 7.0 in stage 10.0 (TID 138, localhost, executor driver, partition 7, ANY, 7759 bytes)
2021-12-03 21:29:37,039 [dispatcher-event-loop-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 8.0 in stage 10.0 (TID 139, localhost, executor driver, partition 8, ANY, 7759 bytes)
2021-12-03 21:29:37,039 [dispatcher-event-loop-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 9.0 in stage 10.0 (TID 140, localhost, executor driver, partition 9, ANY, 7759 bytes)
2021-12-03 21:29:37,039 [dispatcher-event-loop-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 10.0 in stage 10.0 (TID 141, localhost, executor driver, partition 10, ANY, 7759 bytes)
2021-12-03 21:29:37,039 [dispatcher-event-loop-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 11.0 in stage 10.0 (TID 142, localhost, executor driver, partition 11, ANY, 7759 bytes)
2021-12-03 21:29:37,039 [Executor task launch worker for task 131] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 10.0 (TID 131)
2021-12-03 21:29:37,039 [Executor task launch worker for task 139] INFO [org.apache.spark.executor.Executor] - Running task 8.0 in stage 10.0 (TID 139)
2021-12-03 21:29:37,039 [Executor task launch worker for task 142] INFO [org.apache.spark.executor.Executor] - Running task 11.0 in stage 10.0 (TID 142)
2021-12-03 21:29:37,039 [Executor task launch worker for task 141] INFO [org.apache.spark.executor.Executor] - Running task 10.0 in stage 10.0 (TID 141)
2021-12-03 21:29:37,039 [Executor task launch worker for task 140] INFO [org.apache.spark.executor.Executor] - Running task 9.0 in stage 10.0 (TID 140)
2021-12-03 21:29:37,039 [Executor task launch worker for task 132] INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 10.0 (TID 132)
2021-12-03 21:29:37,039 [Executor task launch worker for task 134] INFO [org.apache.spark.executor.Executor] - Running task 3.0 in stage 10.0 (TID 134)
2021-12-03 21:29:37,039 [Executor task launch worker for task 135] INFO [org.apache.spark.executor.Executor] - Running task 4.0 in stage 10.0 (TID 135)
2021-12-03 21:29:37,039 [Executor task launch worker for task 136] INFO [org.apache.spark.executor.Executor] - Running task 5.0 in stage 10.0 (TID 136)
2021-12-03 21:29:37,039 [Executor task launch worker for task 137] INFO [org.apache.spark.executor.Executor] - Running task 6.0 in stage 10.0 (TID 137)
2021-12-03 21:29:37,039 [Executor task launch worker for task 133] INFO [org.apache.spark.executor.Executor] - Running task 2.0 in stage 10.0 (TID 133)
2021-12-03 21:29:37,039 [Executor task launch worker for task 138] INFO [org.apache.spark.executor.Executor] - Running task 7.0 in stage 10.0 (TID 138)
2021-12-03 21:29:37,044 [Executor task launch worker for task 142] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 21:29:37,044 [Executor task launch worker for task 142] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 21:29:37,044 [Executor task launch worker for task 133] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 21:29:37,044 [Executor task launch worker for task 133] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 21:29:37,044 [Executor task launch worker for task 135] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 21:29:37,044 [Executor task launch worker for task 135] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 21:29:37,045 [Executor task launch worker for task 137] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 21:29:37,045 [Executor task launch worker for task 137] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 21:29:37,045 [Executor task launch worker for task 132] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 21:29:37,045 [Executor task launch worker for task 132] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 21:29:37,046 [Executor task launch worker for task 139] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 21:29:37,046 [Executor task launch worker for task 139] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 21:29:37,047 [Executor task launch worker for task 141] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 21:29:37,047 [Executor task launch worker for task 141] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 21:29:37,048 [Executor task launch worker for task 136] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 21:29:37,048 [Executor task launch worker for task 136] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 21:29:37,048 [Executor task launch worker for task 134] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 21:29:37,048 [Executor task launch worker for task 134] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 21:29:37,049 [Executor task launch worker for task 140] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 21:29:37,049 [Executor task launch worker for task 140] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 21:29:37,050 [Executor task launch worker for task 138] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 21:29:37,050 [Executor task launch worker for task 138] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 21:29:37,050 [Executor task launch worker for task 131] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 21:29:37,051 [Executor task launch worker for task 131] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 1 ms
2021-12-03 21:29:37,176 [Executor task launch worker for task 142] INFO [org.apache.spark.executor.Executor] - Finished task 11.0 in stage 10.0 (TID 142). 1053 bytes result sent to driver
2021-12-03 21:29:37,177 [dispatcher-event-loop-5] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 12.0 in stage 10.0 (TID 143, localhost, executor driver, partition 12, ANY, 7759 bytes)
2021-12-03 21:29:37,177 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 11.0 in stage 10.0 (TID 142) in 138 ms on localhost (executor driver) (1/22)
2021-12-03 21:29:37,180 [Executor task launch worker for task 143] INFO [org.apache.spark.executor.Executor] - Running task 12.0 in stage 10.0 (TID 143)
2021-12-03 21:29:37,180 [Executor task launch worker for task 136] INFO [org.apache.spark.executor.Executor] - Finished task 5.0 in stage 10.0 (TID 136). 1053 bytes result sent to driver
2021-12-03 21:29:37,181 [dispatcher-event-loop-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 13.0 in stage 10.0 (TID 144, localhost, executor driver, partition 13, ANY, 7759 bytes)
2021-12-03 21:29:37,181 [Executor task launch worker for task 144] INFO [org.apache.spark.executor.Executor] - Running task 13.0 in stage 10.0 (TID 144)
2021-12-03 21:29:37,181 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 5.0 in stage 10.0 (TID 136) in 142 ms on localhost (executor driver) (2/22)
2021-12-03 21:29:37,214 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 129
2021-12-03 21:29:37,214 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 142
2021-12-03 21:29:37,214 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 148
2021-12-03 21:29:37,214 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 108
2021-12-03 21:29:37,214 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 139
2021-12-03 21:29:37,214 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 124
2021-12-03 21:29:37,214 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 140
2021-12-03 21:29:37,214 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 102
2021-12-03 21:29:37,214 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 145
2021-12-03 21:29:37,214 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 126
2021-12-03 21:29:37,214 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 143
2021-12-03 21:29:37,214 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 130
2021-12-03 21:29:37,214 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 116
2021-12-03 21:29:37,214 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 135
2021-12-03 21:29:37,214 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 107
2021-12-03 21:29:37,214 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 146
2021-12-03 21:29:37,214 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 101
2021-12-03 21:29:37,214 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 110
2021-12-03 21:29:37,214 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 147
2021-12-03 21:29:37,215 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 109
2021-12-03 21:29:37,215 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 120
2021-12-03 21:29:37,215 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 131
2021-12-03 21:29:37,215 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 133
2021-12-03 21:29:37,215 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 114
2021-12-03 21:29:37,215 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 118
2021-12-03 21:29:37,215 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 104
2021-12-03 21:29:37,215 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 137
2021-12-03 21:29:37,215 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 113
2021-12-03 21:29:37,215 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 122
2021-12-03 21:29:37,215 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 117
2021-12-03 21:29:37,215 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 134
2021-12-03 21:29:37,215 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 106
2021-12-03 21:29:37,215 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 105
2021-12-03 21:29:37,215 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 115
2021-12-03 21:29:37,215 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 112
2021-12-03 21:29:37,215 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 121
2021-12-03 21:29:37,215 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 138
2021-12-03 21:29:37,215 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 119
2021-12-03 21:29:37,216 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 111
2021-12-03 21:29:37,216 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 141
2021-12-03 21:29:37,216 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 100
2021-12-03 21:29:37,216 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 123
2021-12-03 21:29:37,216 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 149
2021-12-03 21:29:37,216 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 125
2021-12-03 21:29:37,216 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 132
2021-12-03 21:29:37,216 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 144
2021-12-03 21:29:37,217 [Executor task launch worker for task 141] INFO [org.apache.spark.executor.Executor] - Finished task 10.0 in stage 10.0 (TID 141). 1096 bytes result sent to driver
2021-12-03 21:29:37,218 [Executor task launch worker for task 139] INFO [org.apache.spark.executor.Executor] - Finished task 8.0 in stage 10.0 (TID 139). 1096 bytes result sent to driver
2021-12-03 21:29:37,218 [dispatcher-event-loop-8] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 14.0 in stage 10.0 (TID 145, localhost, executor driver, partition 14, ANY, 7759 bytes)
2021-12-03 21:29:37,218 [dispatcher-event-loop-9] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_6_piece0 on qb:61634 in memory (size: 2.0 KB, free: 1990.8 MB)
2021-12-03 21:29:37,219 [Executor task launch worker for task 145] INFO [org.apache.spark.executor.Executor] - Running task 14.0 in stage 10.0 (TID 145)
2021-12-03 21:29:37,219 [Executor task launch worker for task 135] INFO [org.apache.spark.executor.Executor] - Finished task 4.0 in stage 10.0 (TID 135). 1096 bytes result sent to driver
2021-12-03 21:29:37,220 [Executor task launch worker for task 137] INFO [org.apache.spark.executor.Executor] - Finished task 6.0 in stage 10.0 (TID 137). 1096 bytes result sent to driver
2021-12-03 21:29:37,219 [dispatcher-event-loop-8] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 15.0 in stage 10.0 (TID 146, localhost, executor driver, partition 15, ANY, 7759 bytes)
2021-12-03 21:29:37,221 [Executor task launch worker for task 132] INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 10.0 (TID 132). 1096 bytes result sent to driver
2021-12-03 21:29:37,221 [Executor task launch worker for task 146] INFO [org.apache.spark.executor.Executor] - Running task 15.0 in stage 10.0 (TID 146)
2021-12-03 21:29:37,221 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 8.0 in stage 10.0 (TID 139) in 182 ms on localhost (executor driver) (3/22)
2021-12-03 21:29:37,221 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 10.0 in stage 10.0 (TID 141) in 182 ms on localhost (executor driver) (4/22)
2021-12-03 21:29:37,221 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 4.0 in stage 10.0 (TID 135) in 182 ms on localhost (executor driver) (5/22)
2021-12-03 21:29:37,224 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 136
2021-12-03 21:29:37,224 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 103
2021-12-03 21:29:37,224 [dispatcher-event-loop-8] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 16.0 in stage 10.0 (TID 147, localhost, executor driver, partition 16, ANY, 7759 bytes)
2021-12-03 21:29:37,224 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 127
2021-12-03 21:29:37,224 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 128
2021-12-03 21:29:37,224 [dispatcher-event-loop-8] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 17.0 in stage 10.0 (TID 148, localhost, executor driver, partition 17, ANY, 7759 bytes)
2021-12-03 21:29:37,224 [dispatcher-event-loop-8] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 18.0 in stage 10.0 (TID 149, localhost, executor driver, partition 18, ANY, 7759 bytes)
2021-12-03 21:29:37,224 [Executor task launch worker for task 140] INFO [org.apache.spark.executor.Executor] - Finished task 9.0 in stage 10.0 (TID 140). 1096 bytes result sent to driver
2021-12-03 21:29:37,224 [Executor task launch worker for task 147] INFO [org.apache.spark.executor.Executor] - Running task 16.0 in stage 10.0 (TID 147)
2021-12-03 21:29:37,224 [dispatcher-event-loop-8] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 19.0 in stage 10.0 (TID 150, localhost, executor driver, partition 19, ANY, 7759 bytes)
2021-12-03 21:29:37,225 [Executor task launch worker for task 148] INFO [org.apache.spark.executor.Executor] - Running task 17.0 in stage 10.0 (TID 148)
2021-12-03 21:29:37,225 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 6.0 in stage 10.0 (TID 137) in 186 ms on localhost (executor driver) (6/22)
2021-12-03 21:29:37,225 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 9.0 in stage 10.0 (TID 140) in 186 ms on localhost (executor driver) (7/22)
2021-12-03 21:29:37,225 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 10.0 (TID 132) in 187 ms on localhost (executor driver) (8/22)
2021-12-03 21:29:37,225 [Executor task launch worker for task 149] INFO [org.apache.spark.executor.Executor] - Running task 18.0 in stage 10.0 (TID 149)
2021-12-03 21:29:37,225 [Executor task launch worker for task 150] INFO [org.apache.spark.executor.Executor] - Running task 19.0 in stage 10.0 (TID 150)
2021-12-03 21:29:37,226 [Executor task launch worker for task 145] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 21:29:37,226 [Executor task launch worker for task 145] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 21:29:37,226 [Executor task launch worker for task 146] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 21:29:37,226 [Executor task launch worker for task 144] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 21:29:37,226 [Executor task launch worker for task 144] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 21:29:37,226 [Executor task launch worker for task 143] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 21:29:37,227 [Executor task launch worker for task 143] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 1 ms
2021-12-03 21:29:37,226 [Executor task launch worker for task 146] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 21:29:37,228 [Executor task launch worker for task 138] INFO [org.apache.spark.executor.Executor] - Finished task 7.0 in stage 10.0 (TID 138). 1139 bytes result sent to driver
2021-12-03 21:29:37,229 [Executor task launch worker for task 148] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 21:29:37,229 [Executor task launch worker for task 148] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 21:29:37,229 [dispatcher-event-loop-10] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 20.0 in stage 10.0 (TID 151, localhost, executor driver, partition 20, ANY, 7759 bytes)
2021-12-03 21:29:37,229 [Executor task launch worker for task 151] INFO [org.apache.spark.executor.Executor] - Running task 20.0 in stage 10.0 (TID 151)
2021-12-03 21:29:37,229 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 7.0 in stage 10.0 (TID 138) in 190 ms on localhost (executor driver) (9/22)
2021-12-03 21:29:37,229 [Executor task launch worker for task 149] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 21:29:37,229 [Executor task launch worker for task 149] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 1 ms
2021-12-03 21:29:37,231 [Executor task launch worker for task 147] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 21:29:37,231 [Executor task launch worker for task 147] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 21:29:37,231 [Executor task launch worker for task 131] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 10.0 (TID 131). 1139 bytes result sent to driver
2021-12-03 21:29:37,231 [Executor task launch worker for task 134] INFO [org.apache.spark.executor.Executor] - Finished task 3.0 in stage 10.0 (TID 134). 1096 bytes result sent to driver
2021-12-03 21:29:37,232 [Executor task launch worker for task 150] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 21:29:37,232 [Executor task launch worker for task 150] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 21:29:37,232 [dispatcher-event-loop-4] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 21.0 in stage 10.0 (TID 152, localhost, executor driver, partition 21, ANY, 7759 bytes)
2021-12-03 21:29:37,232 [Executor task launch worker for task 152] INFO [org.apache.spark.executor.Executor] - Running task 21.0 in stage 10.0 (TID 152)
2021-12-03 21:29:37,232 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 10.0 (TID 131) in 194 ms on localhost (executor driver) (10/22)
2021-12-03 21:29:37,232 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 3.0 in stage 10.0 (TID 134) in 194 ms on localhost (executor driver) (11/22)
2021-12-03 21:29:37,233 [Executor task launch worker for task 151] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 21:29:37,233 [Executor task launch worker for task 151] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 21:29:37,236 [Executor task launch worker for task 152] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 21:29:37,236 [Executor task launch worker for task 152] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 21:29:37,237 [Executor task launch worker for task 133] INFO [org.apache.spark.executor.Executor] - Finished task 2.0 in stage 10.0 (TID 133). 1098 bytes result sent to driver
2021-12-03 21:29:37,238 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 2.0 in stage 10.0 (TID 133) in 200 ms on localhost (executor driver) (12/22)
2021-12-03 21:29:37,305 [Executor task launch worker for task 145] INFO [org.apache.spark.executor.Executor] - Finished task 14.0 in stage 10.0 (TID 145). 1053 bytes result sent to driver
2021-12-03 21:29:37,305 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 14.0 in stage 10.0 (TID 145) in 87 ms on localhost (executor driver) (13/22)
2021-12-03 21:29:37,318 [Executor task launch worker for task 147] INFO [org.apache.spark.executor.Executor] - Finished task 16.0 in stage 10.0 (TID 147). 1053 bytes result sent to driver
2021-12-03 21:29:37,318 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 16.0 in stage 10.0 (TID 147) in 95 ms on localhost (executor driver) (14/22)
2021-12-03 21:29:37,324 [Executor task launch worker for task 149] INFO [org.apache.spark.executor.Executor] - Finished task 18.0 in stage 10.0 (TID 149). 1053 bytes result sent to driver
2021-12-03 21:29:37,324 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 18.0 in stage 10.0 (TID 149) in 100 ms on localhost (executor driver) (15/22)
2021-12-03 21:29:37,325 [Executor task launch worker for task 150] INFO [org.apache.spark.executor.Executor] - Finished task 19.0 in stage 10.0 (TID 150). 1053 bytes result sent to driver
2021-12-03 21:29:37,326 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 19.0 in stage 10.0 (TID 150) in 102 ms on localhost (executor driver) (16/22)
2021-12-03 21:29:37,327 [Executor task launch worker for task 144] INFO [org.apache.spark.executor.Executor] - Finished task 13.0 in stage 10.0 (TID 144). 1139 bytes result sent to driver
2021-12-03 21:29:37,327 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 13.0 in stage 10.0 (TID 144) in 146 ms on localhost (executor driver) (17/22)
2021-12-03 21:29:37,327 [Executor task launch worker for task 146] INFO [org.apache.spark.executor.Executor] - Finished task 15.0 in stage 10.0 (TID 146). 1053 bytes result sent to driver
2021-12-03 21:29:37,328 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 15.0 in stage 10.0 (TID 146) in 110 ms on localhost (executor driver) (18/22)
2021-12-03 21:29:37,335 [Executor task launch worker for task 148] INFO [org.apache.spark.executor.Executor] - Finished task 17.0 in stage 10.0 (TID 148). 1053 bytes result sent to driver
2021-12-03 21:29:37,336 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 17.0 in stage 10.0 (TID 148) in 112 ms on localhost (executor driver) (19/22)
2021-12-03 21:29:37,336 [Executor task launch worker for task 143] INFO [org.apache.spark.executor.Executor] - Finished task 12.0 in stage 10.0 (TID 143). 1139 bytes result sent to driver
2021-12-03 21:29:37,336 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 12.0 in stage 10.0 (TID 143) in 159 ms on localhost (executor driver) (20/22)
2021-12-03 21:29:37,338 [Executor task launch worker for task 151] INFO [org.apache.spark.executor.Executor] - Finished task 20.0 in stage 10.0 (TID 151). 1053 bytes result sent to driver
2021-12-03 21:29:37,339 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 20.0 in stage 10.0 (TID 151) in 110 ms on localhost (executor driver) (21/22)
2021-12-03 21:29:37,339 [Executor task launch worker for task 152] INFO [org.apache.spark.executor.Executor] - Finished task 21.0 in stage 10.0 (TID 152). 1053 bytes result sent to driver
2021-12-03 21:29:37,339 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 21.0 in stage 10.0 (TID 152) in 107 ms on localhost (executor driver) (22/22)
2021-12-03 21:29:37,339 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 10.0, whose tasks have all completed, from pool 
2021-12-03 21:29:37,339 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 10 (count at PaidPromotionAdjustParameter.scala:79) finished in 0.307 s
2021-12-03 21:29:37,339 [main] INFO [org.apache.spark.scheduler.DAGScheduler] - Job 4 finished: count at PaidPromotionAdjustParameter.scala:79, took 0.310271 s
2021-12-03 21:29:37,340 [main] INFO [PaidPromotion$] - 小数据集个数：16770
2021-12-03 21:29:37,357 [main] INFO [org.apache.spark.SparkContext] - Starting job: count at PaidPromotionAdjustParameter.scala:85
2021-12-03 21:29:37,358 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 5 (count at PaidPromotionAdjustParameter.scala:85) with 22 output partitions
2021-12-03 21:29:37,358 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 11 (count at PaidPromotionAdjustParameter.scala:85)
2021-12-03 21:29:37,358 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List()
2021-12-03 21:29:37,358 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2021-12-03 21:29:37,358 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 11 (MapPartitionsRDD[12] at map at PaidPromotionAdjustParameter.scala:83), which has no missing parents
2021-12-03 21:29:37,361 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_8 stored as values in memory (estimated size 3.4 KB, free 1990.4 MB)
2021-12-03 21:29:37,363 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_8_piece0 stored as bytes in memory (estimated size 2022.0 B, free 1990.4 MB)
2021-12-03 21:29:37,363 [dispatcher-event-loop-5] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_8_piece0 in memory on qb:61634 (size: 2022.0 B, free: 1990.8 MB)
2021-12-03 21:29:37,363 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 8 from broadcast at DAGScheduler.scala:1039
2021-12-03 21:29:37,363 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 22 missing tasks from ResultStage 11 (MapPartitionsRDD[12] at map at PaidPromotionAdjustParameter.scala:83) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14))
2021-12-03 21:29:37,363 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 11.0 with 22 tasks
2021-12-03 21:29:37,364 [dispatcher-event-loop-6] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 11.0 (TID 153, localhost, executor driver, partition 0, ANY, 7899 bytes)
2021-12-03 21:29:37,364 [dispatcher-event-loop-6] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 11.0 (TID 154, localhost, executor driver, partition 1, ANY, 7899 bytes)
2021-12-03 21:29:37,364 [dispatcher-event-loop-6] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 2.0 in stage 11.0 (TID 155, localhost, executor driver, partition 2, ANY, 7899 bytes)
2021-12-03 21:29:37,364 [dispatcher-event-loop-6] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 3.0 in stage 11.0 (TID 156, localhost, executor driver, partition 3, ANY, 7899 bytes)
2021-12-03 21:29:37,364 [dispatcher-event-loop-6] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 4.0 in stage 11.0 (TID 157, localhost, executor driver, partition 4, ANY, 7899 bytes)
2021-12-03 21:29:37,365 [dispatcher-event-loop-6] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 5.0 in stage 11.0 (TID 158, localhost, executor driver, partition 5, ANY, 7899 bytes)
2021-12-03 21:29:37,365 [dispatcher-event-loop-6] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 6.0 in stage 11.0 (TID 159, localhost, executor driver, partition 6, ANY, 7899 bytes)
2021-12-03 21:29:37,365 [dispatcher-event-loop-6] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 7.0 in stage 11.0 (TID 160, localhost, executor driver, partition 7, ANY, 7899 bytes)
2021-12-03 21:29:37,365 [dispatcher-event-loop-6] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 8.0 in stage 11.0 (TID 161, localhost, executor driver, partition 8, ANY, 7899 bytes)
2021-12-03 21:29:37,365 [dispatcher-event-loop-6] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 9.0 in stage 11.0 (TID 162, localhost, executor driver, partition 9, ANY, 7899 bytes)
2021-12-03 21:29:37,365 [dispatcher-event-loop-6] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 10.0 in stage 11.0 (TID 163, localhost, executor driver, partition 10, ANY, 7899 bytes)
2021-12-03 21:29:37,365 [dispatcher-event-loop-6] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 11.0 in stage 11.0 (TID 164, localhost, executor driver, partition 11, ANY, 7899 bytes)
2021-12-03 21:29:37,365 [Executor task launch worker for task 154] INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 11.0 (TID 154)
2021-12-03 21:29:37,365 [Executor task launch worker for task 158] INFO [org.apache.spark.executor.Executor] - Running task 5.0 in stage 11.0 (TID 158)
2021-12-03 21:29:37,365 [Executor task launch worker for task 164] INFO [org.apache.spark.executor.Executor] - Running task 11.0 in stage 11.0 (TID 164)
2021-12-03 21:29:37,365 [Executor task launch worker for task 157] INFO [org.apache.spark.executor.Executor] - Running task 4.0 in stage 11.0 (TID 157)
2021-12-03 21:29:37,365 [Executor task launch worker for task 156] INFO [org.apache.spark.executor.Executor] - Running task 3.0 in stage 11.0 (TID 156)
2021-12-03 21:29:37,365 [Executor task launch worker for task 155] INFO [org.apache.spark.executor.Executor] - Running task 2.0 in stage 11.0 (TID 155)
2021-12-03 21:29:37,365 [Executor task launch worker for task 153] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 11.0 (TID 153)
2021-12-03 21:29:37,365 [Executor task launch worker for task 162] INFO [org.apache.spark.executor.Executor] - Running task 9.0 in stage 11.0 (TID 162)
2021-12-03 21:29:37,365 [Executor task launch worker for task 163] INFO [org.apache.spark.executor.Executor] - Running task 10.0 in stage 11.0 (TID 163)
2021-12-03 21:29:37,365 [Executor task launch worker for task 160] INFO [org.apache.spark.executor.Executor] - Running task 7.0 in stage 11.0 (TID 160)
2021-12-03 21:29:37,365 [Executor task launch worker for task 161] INFO [org.apache.spark.executor.Executor] - Running task 8.0 in stage 11.0 (TID 161)
2021-12-03 21:29:37,365 [Executor task launch worker for task 159] INFO [org.apache.spark.executor.Executor] - Running task 6.0 in stage 11.0 (TID 159)
2021-12-03 21:29:37,366 [Executor task launch worker for task 162] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:1207959552+134217728
2021-12-03 21:29:37,366 [Executor task launch worker for task 153] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:0+134217728
2021-12-03 21:29:37,366 [Executor task launch worker for task 160] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:939524096+134217728
2021-12-03 21:29:37,366 [Executor task launch worker for task 164] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:1476395008+134217728
2021-12-03 21:29:37,366 [Executor task launch worker for task 158] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:671088640+134217728
2021-12-03 21:29:37,366 [Executor task launch worker for task 163] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:1342177280+134217728
2021-12-03 21:29:37,366 [Executor task launch worker for task 159] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:805306368+134217728
2021-12-03 21:29:37,366 [Executor task launch worker for task 155] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:268435456+134217728
2021-12-03 21:29:37,366 [Executor task launch worker for task 154] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:134217728+134217728
2021-12-03 21:29:37,366 [Executor task launch worker for task 156] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:402653184+134217728
2021-12-03 21:29:37,366 [Executor task launch worker for task 161] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:1073741824+134217728
2021-12-03 21:29:37,366 [Executor task launch worker for task 157] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:536870912+134217728
2021-12-03 21:29:38,646 [dispatcher-event-loop-2] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_7_piece0 on qb:61634 in memory (size: 2.4 KB, free: 1990.8 MB)
2021-12-03 21:31:12,224 [Executor task launch worker for task 158] INFO [org.apache.spark.executor.Executor] - Finished task 5.0 in stage 11.0 (TID 158). 755 bytes result sent to driver
2021-12-03 21:31:12,225 [dispatcher-event-loop-6] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 12.0 in stage 11.0 (TID 165, localhost, executor driver, partition 12, ANY, 7899 bytes)
2021-12-03 21:31:12,225 [Executor task launch worker for task 165] INFO [org.apache.spark.executor.Executor] - Running task 12.0 in stage 11.0 (TID 165)
2021-12-03 21:31:12,225 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 5.0 in stage 11.0 (TID 158) in 94861 ms on localhost (executor driver) (1/22)
2021-12-03 21:31:12,225 [Executor task launch worker for task 165] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:1610612736+134217728
2021-12-03 21:31:40,924 [Executor task launch worker for task 160] INFO [org.apache.spark.executor.Executor] - Finished task 7.0 in stage 11.0 (TID 160). 755 bytes result sent to driver
2021-12-03 21:31:40,924 [dispatcher-event-loop-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 13.0 in stage 11.0 (TID 166, localhost, executor driver, partition 13, ANY, 7899 bytes)
2021-12-03 21:31:40,924 [Executor task launch worker for task 166] INFO [org.apache.spark.executor.Executor] - Running task 13.0 in stage 11.0 (TID 166)
2021-12-03 21:31:40,924 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 7.0 in stage 11.0 (TID 160) in 123559 ms on localhost (executor driver) (2/22)
2021-12-03 21:31:40,925 [Executor task launch worker for task 166] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:1744830464+134217728
2021-12-03 21:31:48,688 [Executor task launch worker for task 155] INFO [org.apache.spark.executor.Executor] - Finished task 2.0 in stage 11.0 (TID 155). 755 bytes result sent to driver
2021-12-03 21:31:48,689 [dispatcher-event-loop-6] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 14.0 in stage 11.0 (TID 167, localhost, executor driver, partition 14, ANY, 7899 bytes)
2021-12-03 21:31:48,689 [Executor task launch worker for task 167] INFO [org.apache.spark.executor.Executor] - Running task 14.0 in stage 11.0 (TID 167)
2021-12-03 21:31:48,689 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 2.0 in stage 11.0 (TID 155) in 131325 ms on localhost (executor driver) (3/22)
2021-12-03 21:31:48,690 [Executor task launch worker for task 167] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:1879048192+134217728
2021-12-03 21:31:49,344 [Executor task launch worker for task 153] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 11.0 (TID 153). 755 bytes result sent to driver
2021-12-03 21:31:49,344 [dispatcher-event-loop-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 15.0 in stage 11.0 (TID 168, localhost, executor driver, partition 15, ANY, 7899 bytes)
2021-12-03 21:31:49,345 [Executor task launch worker for task 168] INFO [org.apache.spark.executor.Executor] - Running task 15.0 in stage 11.0 (TID 168)
2021-12-03 21:31:49,345 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 11.0 (TID 153) in 131981 ms on localhost (executor driver) (4/22)
2021-12-03 21:31:49,345 [Executor task launch worker for task 168] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:2013265920+134217728
2021-12-03 21:31:55,932 [Executor task launch worker for task 159] INFO [org.apache.spark.executor.Executor] - Finished task 6.0 in stage 11.0 (TID 159). 755 bytes result sent to driver
2021-12-03 21:31:55,933 [dispatcher-event-loop-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 16.0 in stage 11.0 (TID 169, localhost, executor driver, partition 16, ANY, 7899 bytes)
2021-12-03 21:31:55,933 [Executor task launch worker for task 169] INFO [org.apache.spark.executor.Executor] - Running task 16.0 in stage 11.0 (TID 169)
2021-12-03 21:31:55,933 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 6.0 in stage 11.0 (TID 159) in 138568 ms on localhost (executor driver) (5/22)
2021-12-03 21:31:55,934 [Executor task launch worker for task 169] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:2147483648+134217728
2021-12-03 21:31:59,408 [Executor task launch worker for task 162] INFO [org.apache.spark.executor.Executor] - Finished task 9.0 in stage 11.0 (TID 162). 755 bytes result sent to driver
2021-12-03 21:31:59,408 [dispatcher-event-loop-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 17.0 in stage 11.0 (TID 170, localhost, executor driver, partition 17, ANY, 7899 bytes)
2021-12-03 21:31:59,408 [Executor task launch worker for task 170] INFO [org.apache.spark.executor.Executor] - Running task 17.0 in stage 11.0 (TID 170)
2021-12-03 21:31:59,408 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 9.0 in stage 11.0 (TID 162) in 142043 ms on localhost (executor driver) (6/22)
2021-12-03 21:31:59,409 [Executor task launch worker for task 170] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:2281701376+134217728
2021-12-03 21:32:00,776 [Executor task launch worker for task 164] INFO [org.apache.spark.executor.Executor] - Finished task 11.0 in stage 11.0 (TID 164). 755 bytes result sent to driver
2021-12-03 21:32:00,776 [dispatcher-event-loop-4] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 18.0 in stage 11.0 (TID 171, localhost, executor driver, partition 18, ANY, 7899 bytes)
2021-12-03 21:32:00,776 [Executor task launch worker for task 171] INFO [org.apache.spark.executor.Executor] - Running task 18.0 in stage 11.0 (TID 171)
2021-12-03 21:32:00,776 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 11.0 in stage 11.0 (TID 164) in 143411 ms on localhost (executor driver) (7/22)
2021-12-03 21:32:00,777 [Executor task launch worker for task 171] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:2415919104+134217728
2021-12-03 21:32:01,798 [Executor task launch worker for task 156] INFO [org.apache.spark.executor.Executor] - Finished task 3.0 in stage 11.0 (TID 156). 755 bytes result sent to driver
2021-12-03 21:32:01,798 [dispatcher-event-loop-8] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 19.0 in stage 11.0 (TID 172, localhost, executor driver, partition 19, ANY, 7899 bytes)
2021-12-03 21:32:01,798 [Executor task launch worker for task 172] INFO [org.apache.spark.executor.Executor] - Running task 19.0 in stage 11.0 (TID 172)
2021-12-03 21:32:01,798 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 3.0 in stage 11.0 (TID 156) in 144434 ms on localhost (executor driver) (8/22)
2021-12-03 21:32:01,799 [Executor task launch worker for task 172] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:2550136832+134217728
2021-12-03 21:32:03,260 [Executor task launch worker for task 161] INFO [org.apache.spark.executor.Executor] - Finished task 8.0 in stage 11.0 (TID 161). 755 bytes result sent to driver
2021-12-03 21:32:03,260 [dispatcher-event-loop-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 20.0 in stage 11.0 (TID 173, localhost, executor driver, partition 20, ANY, 7899 bytes)
2021-12-03 21:32:03,261 [Executor task launch worker for task 173] INFO [org.apache.spark.executor.Executor] - Running task 20.0 in stage 11.0 (TID 173)
2021-12-03 21:32:03,261 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 8.0 in stage 11.0 (TID 161) in 145896 ms on localhost (executor driver) (9/22)
2021-12-03 21:32:03,261 [Executor task launch worker for task 173] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:2684354560+134217728
2021-12-03 21:32:05,195 [Executor task launch worker for task 163] INFO [org.apache.spark.executor.Executor] - Finished task 10.0 in stage 11.0 (TID 163). 755 bytes result sent to driver
2021-12-03 21:32:05,195 [dispatcher-event-loop-7] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 21.0 in stage 11.0 (TID 174, localhost, executor driver, partition 21, ANY, 7899 bytes)
2021-12-03 21:32:05,195 [Executor task launch worker for task 174] INFO [org.apache.spark.executor.Executor] - Running task 21.0 in stage 11.0 (TID 174)
2021-12-03 21:32:05,195 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 10.0 in stage 11.0 (TID 163) in 147830 ms on localhost (executor driver) (10/22)
2021-12-03 21:32:05,196 [Executor task launch worker for task 174] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:2818572288+147216171
2021-12-03 21:32:18,026 [Executor task launch worker for task 154] INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 11.0 (TID 154). 755 bytes result sent to driver
2021-12-03 21:32:18,026 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 11.0 (TID 154) in 160662 ms on localhost (executor driver) (11/22)
2021-12-03 21:32:18,591 [Executor task launch worker for task 157] INFO [org.apache.spark.executor.Executor] - Finished task 4.0 in stage 11.0 (TID 157). 755 bytes result sent to driver
2021-12-03 21:32:18,592 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 4.0 in stage 11.0 (TID 157) in 161228 ms on localhost (executor driver) (12/22)
2021-12-03 21:33:35,942 [Executor task launch worker for task 170] INFO [org.apache.spark.executor.Executor] - Finished task 17.0 in stage 11.0 (TID 170). 712 bytes result sent to driver
2021-12-03 21:33:35,942 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 17.0 in stage 11.0 (TID 170) in 96534 ms on localhost (executor driver) (13/22)
2021-12-03 21:33:39,948 [Executor task launch worker for task 165] INFO [org.apache.spark.executor.Executor] - Finished task 12.0 in stage 11.0 (TID 165). 712 bytes result sent to driver
2021-12-03 21:33:39,948 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 12.0 in stage 11.0 (TID 165) in 147724 ms on localhost (executor driver) (14/22)
2021-12-03 21:33:40,353 [Executor task launch worker for task 168] INFO [org.apache.spark.executor.Executor] - Finished task 15.0 in stage 11.0 (TID 168). 712 bytes result sent to driver
2021-12-03 21:33:40,353 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 15.0 in stage 11.0 (TID 168) in 111009 ms on localhost (executor driver) (15/22)
2021-12-03 21:33:44,275 [Executor task launch worker for task 172] INFO [org.apache.spark.executor.Executor] - Finished task 19.0 in stage 11.0 (TID 172). 712 bytes result sent to driver
2021-12-03 21:33:44,276 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 19.0 in stage 11.0 (TID 172) in 102478 ms on localhost (executor driver) (16/22)
2021-12-03 21:33:46,809 [Executor task launch worker for task 171] INFO [org.apache.spark.executor.Executor] - Finished task 18.0 in stage 11.0 (TID 171). 755 bytes result sent to driver
2021-12-03 21:33:46,809 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 18.0 in stage 11.0 (TID 171) in 106033 ms on localhost (executor driver) (17/22)
2021-12-03 21:33:47,316 [Executor task launch worker for task 166] INFO [org.apache.spark.executor.Executor] - Finished task 13.0 in stage 11.0 (TID 166). 712 bytes result sent to driver
2021-12-03 21:33:47,316 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 13.0 in stage 11.0 (TID 166) in 126392 ms on localhost (executor driver) (18/22)
2021-12-03 21:33:47,708 [Executor task launch worker for task 173] INFO [org.apache.spark.executor.Executor] - Finished task 20.0 in stage 11.0 (TID 173). 712 bytes result sent to driver
2021-12-03 21:33:47,709 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 20.0 in stage 11.0 (TID 173) in 104449 ms on localhost (executor driver) (19/22)
2021-12-03 21:33:49,103 [Executor task launch worker for task 167] INFO [org.apache.spark.executor.Executor] - Finished task 14.0 in stage 11.0 (TID 167). 755 bytes result sent to driver
2021-12-03 21:33:49,103 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 14.0 in stage 11.0 (TID 167) in 120414 ms on localhost (executor driver) (20/22)
2021-12-03 21:33:50,447 [Executor task launch worker for task 169] INFO [org.apache.spark.executor.Executor] - Finished task 16.0 in stage 11.0 (TID 169). 712 bytes result sent to driver
2021-12-03 21:33:50,448 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 16.0 in stage 11.0 (TID 169) in 114515 ms on localhost (executor driver) (21/22)
2021-12-03 21:33:52,788 [Executor task launch worker for task 174] INFO [org.apache.spark.executor.Executor] - Finished task 21.0 in stage 11.0 (TID 174). 755 bytes result sent to driver
2021-12-03 21:33:52,788 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 21.0 in stage 11.0 (TID 174) in 107593 ms on localhost (executor driver) (22/22)
2021-12-03 21:33:52,788 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 11.0, whose tasks have all completed, from pool 
2021-12-03 21:33:52,788 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 11 (count at PaidPromotionAdjustParameter.scala:85) finished in 255.428 s
2021-12-03 21:33:52,788 [main] INFO [org.apache.spark.scheduler.DAGScheduler] - Job 5 finished: count at PaidPromotionAdjustParameter.scala:85, took 255.430913 s
2021-12-03 21:33:52,788 [main] INFO [PaidPromotion$] - 抽样总数：68489201
2021-12-03 21:40:30,865 [dispatcher-event-loop-9] WARN [org.apache.spark.HeartbeatReceiver] - Removing executor driver with no recent heartbeats: 403772 ms exceeds timeout 120000 ms
2021-12-03 21:40:30,867 [dispatcher-event-loop-9] ERROR [org.apache.spark.scheduler.TaskSchedulerImpl] - Lost executor driver on localhost: Executor heartbeat timed out after 403772 ms
2021-12-03 21:40:30,871 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Executor lost: driver (epoch 2)
2021-12-03 21:40:30,871 [dispatcher-event-loop-2] INFO [org.apache.spark.storage.BlockManagerMasterEndpoint] - Trying to remove executor driver from BlockManagerMaster.
2021-12-03 21:40:30,871 [driver-heartbeater] INFO [org.apache.spark.executor.Executor] - Told to re-register on heartbeat
2021-12-03 21:40:30,872 [kill-executor-thread] WARN [org.apache.spark.SparkContext] - Killing executors is not supported by current scheduler.
2021-12-03 21:40:30,872 [driver-heartbeater] INFO [org.apache.spark.storage.BlockManager] - BlockManager BlockManagerId(driver, qb, 61634, None) re-registering with master
2021-12-03 21:40:30,872 [driver-heartbeater] INFO [org.apache.spark.storage.BlockManagerMaster] - Registering BlockManager BlockManagerId(driver, qb, 61634, None)
2021-12-03 21:40:30,872 [dispatcher-event-loop-2] WARN [org.apache.spark.storage.BlockManagerMasterEndpoint] - No more replicas available for broadcast_0_piece0 !
2021-12-03 21:40:30,872 [dispatcher-event-loop-2] WARN [org.apache.spark.storage.BlockManagerMasterEndpoint] - No more replicas available for broadcast_4_piece0 !
2021-12-03 21:40:30,872 [dispatcher-event-loop-2] WARN [org.apache.spark.storage.BlockManagerMasterEndpoint] - No more replicas available for broadcast_2_piece0 !
2021-12-03 21:40:30,872 [dispatcher-event-loop-2] WARN [org.apache.spark.storage.BlockManagerMasterEndpoint] - No more replicas available for broadcast_8_piece0 !
2021-12-03 21:40:30,872 [dispatcher-event-loop-2] WARN [org.apache.spark.storage.BlockManagerMasterEndpoint] - No more replicas available for broadcast_3_piece0 !
2021-12-03 21:40:30,873 [dispatcher-event-loop-2] INFO [org.apache.spark.storage.BlockManagerMasterEndpoint] - Removing block manager BlockManagerId(driver, qb, 61634, None)
2021-12-03 21:40:30,873 [dispatcher-event-loop-2] INFO [org.apache.spark.storage.BlockManagerMasterEndpoint] - Registering block manager qb:61634 with 1990.8 MB RAM, BlockManagerId(driver, qb, 61634, None)
2021-12-03 21:40:30,873 [driver-heartbeater] INFO [org.apache.spark.storage.BlockManagerMaster] - Registered BlockManager BlockManagerId(driver, qb, 61634, None)
2021-12-03 21:40:30,873 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.BlockManagerMaster] - Removed driver successfully in removeExecutor
2021-12-03 21:40:30,874 [driver-heartbeater] INFO [org.apache.spark.storage.BlockManager] - Reporting 10 blocks to the master.
2021-12-03 21:40:30,874 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Shuffle files lost for executor: driver (epoch 2)
2021-12-03 21:40:30,875 [dispatcher-event-loop-7] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_3_piece0 in memory on qb:61634 (size: 1906.0 B, free: 1990.8 MB)
2021-12-03 21:40:30,876 [dispatcher-event-loop-10] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_4_piece0 in memory on qb:61634 (size: 2.4 KB, free: 1990.8 MB)
2021-12-03 21:40:30,876 [dispatcher-event-loop-3] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_0_piece0 in memory on qb:61634 (size: 27.3 KB, free: 1990.8 MB)
2021-12-03 21:40:30,876 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Host added was in lost list earlier: localhost
2021-12-03 21:40:30,877 [dispatcher-event-loop-11] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_2_piece0 in memory on qb:61634 (size: 2.7 KB, free: 1990.8 MB)
2021-12-03 21:40:30,878 [dispatcher-event-loop-4] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_8_piece0 in memory on qb:61634 (size: 2022.0 B, free: 1990.8 MB)
2021-12-03 21:40:30,878 [driver-heartbeater] INFO [org.apache.spark.executor.Executor] - Told to re-register on heartbeat
2021-12-03 21:40:30,878 [driver-heartbeater] INFO [org.apache.spark.storage.BlockManager] - BlockManager BlockManagerId(driver, qb, 61634, None) re-registering with master
2021-12-03 21:40:30,879 [driver-heartbeater] INFO [org.apache.spark.storage.BlockManagerMaster] - Registering BlockManager BlockManagerId(driver, qb, 61634, None)
2021-12-03 21:40:30,879 [driver-heartbeater] INFO [org.apache.spark.storage.BlockManagerMaster] - Registered BlockManager BlockManagerId(driver, qb, 61634, None)
2021-12-03 21:40:30,879 [driver-heartbeater] INFO [org.apache.spark.storage.BlockManager] - Reporting 10 blocks to the master.
2021-12-03 21:40:30,879 [dispatcher-event-loop-8] INFO [org.apache.spark.storage.BlockManagerInfo] - Updated broadcast_3_piece0 in memory on qb:61634 (current size: 1906.0 B, original size: 1906.0 B, free: 1990.8 MB)
2021-12-03 21:40:30,880 [dispatcher-event-loop-1] INFO [org.apache.spark.storage.BlockManagerInfo] - Updated broadcast_4_piece0 in memory on qb:61634 (current size: 2.4 KB, original size: 2.4 KB, free: 1990.8 MB)
2021-12-03 21:40:30,880 [dispatcher-event-loop-9] INFO [org.apache.spark.storage.BlockManagerInfo] - Updated broadcast_0_piece0 in memory on qb:61634 (current size: 27.3 KB, original size: 27.3 KB, free: 1990.8 MB)
2021-12-03 21:40:30,880 [dispatcher-event-loop-0] INFO [org.apache.spark.storage.BlockManagerInfo] - Updated broadcast_2_piece0 in memory on qb:61634 (current size: 2.7 KB, original size: 2.7 KB, free: 1990.8 MB)
2021-12-03 21:40:30,881 [dispatcher-event-loop-2] INFO [org.apache.spark.storage.BlockManagerInfo] - Updated broadcast_8_piece0 in memory on qb:61634 (current size: 2022.0 B, original size: 2022.0 B, free: 1990.8 MB)
2021-12-03 21:40:30,881 [driver-heartbeater] INFO [org.apache.spark.executor.Executor] - Told to re-register on heartbeat
2021-12-03 21:40:30,881 [driver-heartbeater] INFO [org.apache.spark.storage.BlockManager] - BlockManager BlockManagerId(driver, qb, 61634, None) re-registering with master
2021-12-03 21:40:30,881 [driver-heartbeater] INFO [org.apache.spark.storage.BlockManagerMaster] - Registering BlockManager BlockManagerId(driver, qb, 61634, None)
2021-12-03 21:40:30,881 [driver-heartbeater] INFO [org.apache.spark.storage.BlockManagerMaster] - Registered BlockManager BlockManagerId(driver, qb, 61634, None)
2021-12-03 21:40:30,881 [driver-heartbeater] INFO [org.apache.spark.storage.BlockManager] - Reporting 10 blocks to the master.
2021-12-03 21:40:30,882 [dispatcher-event-loop-3] INFO [org.apache.spark.storage.BlockManagerInfo] - Updated broadcast_3_piece0 in memory on qb:61634 (current size: 1906.0 B, original size: 1906.0 B, free: 1990.8 MB)
2021-12-03 21:40:30,882 [dispatcher-event-loop-11] INFO [org.apache.spark.storage.BlockManagerInfo] - Updated broadcast_4_piece0 in memory on qb:61634 (current size: 2.4 KB, original size: 2.4 KB, free: 1990.8 MB)
2021-12-03 21:40:30,882 [dispatcher-event-loop-4] INFO [org.apache.spark.storage.BlockManagerInfo] - Updated broadcast_0_piece0 in memory on qb:61634 (current size: 27.3 KB, original size: 27.3 KB, free: 1990.8 MB)
2021-12-03 21:40:30,883 [dispatcher-event-loop-5] INFO [org.apache.spark.storage.BlockManagerInfo] - Updated broadcast_2_piece0 in memory on qb:61634 (current size: 2.7 KB, original size: 2.7 KB, free: 1990.8 MB)
2021-12-03 21:40:30,883 [dispatcher-event-loop-6] INFO [org.apache.spark.storage.BlockManagerInfo] - Updated broadcast_8_piece0 in memory on qb:61634 (current size: 2022.0 B, original size: 2022.0 B, free: 1990.8 MB)
2021-12-03 21:40:30,884 [driver-heartbeater] INFO [org.apache.spark.executor.Executor] - Told to re-register on heartbeat
2021-12-03 21:40:30,884 [driver-heartbeater] INFO [org.apache.spark.storage.BlockManager] - BlockManager BlockManagerId(driver, qb, 61634, None) re-registering with master
2021-12-03 21:40:30,884 [driver-heartbeater] INFO [org.apache.spark.storage.BlockManagerMaster] - Registering BlockManager BlockManagerId(driver, qb, 61634, None)
2021-12-03 21:40:30,884 [driver-heartbeater] INFO [org.apache.spark.storage.BlockManagerMaster] - Registered BlockManager BlockManagerId(driver, qb, 61634, None)
2021-12-03 21:40:30,884 [driver-heartbeater] INFO [org.apache.spark.storage.BlockManager] - Reporting 10 blocks to the master.
2021-12-03 21:40:30,884 [dispatcher-event-loop-9] INFO [org.apache.spark.storage.BlockManagerInfo] - Updated broadcast_3_piece0 in memory on qb:61634 (current size: 1906.0 B, original size: 1906.0 B, free: 1990.8 MB)
2021-12-03 21:40:30,885 [dispatcher-event-loop-0] INFO [org.apache.spark.storage.BlockManagerInfo] - Updated broadcast_4_piece0 in memory on qb:61634 (current size: 2.4 KB, original size: 2.4 KB, free: 1990.8 MB)
2021-12-03 21:40:30,885 [dispatcher-event-loop-2] INFO [org.apache.spark.storage.BlockManagerInfo] - Updated broadcast_0_piece0 in memory on qb:61634 (current size: 27.3 KB, original size: 27.3 KB, free: 1990.8 MB)
2021-12-03 21:40:30,886 [dispatcher-event-loop-7] INFO [org.apache.spark.storage.BlockManagerInfo] - Updated broadcast_2_piece0 in memory on qb:61634 (current size: 2.7 KB, original size: 2.7 KB, free: 1990.8 MB)
2021-12-03 21:40:30,886 [dispatcher-event-loop-10] INFO [org.apache.spark.storage.BlockManagerInfo] - Updated broadcast_8_piece0 in memory on qb:61634 (current size: 2022.0 B, original size: 2022.0 B, free: 1990.8 MB)
2021-12-03 21:40:30,887 [driver-heartbeater] INFO [org.apache.spark.executor.Executor] - Told to re-register on heartbeat
2021-12-03 21:40:30,887 [driver-heartbeater] INFO [org.apache.spark.storage.BlockManager] - BlockManager BlockManagerId(driver, qb, 61634, None) re-registering with master
2021-12-03 21:40:30,887 [driver-heartbeater] INFO [org.apache.spark.storage.BlockManagerMaster] - Registering BlockManager BlockManagerId(driver, qb, 61634, None)
2021-12-03 21:40:30,887 [driver-heartbeater] INFO [org.apache.spark.storage.BlockManagerMaster] - Registered BlockManager BlockManagerId(driver, qb, 61634, None)
2021-12-03 21:40:30,887 [driver-heartbeater] INFO [org.apache.spark.storage.BlockManager] - Reporting 10 blocks to the master.
2021-12-03 21:40:30,887 [dispatcher-event-loop-4] INFO [org.apache.spark.storage.BlockManagerInfo] - Updated broadcast_3_piece0 in memory on qb:61634 (current size: 1906.0 B, original size: 1906.0 B, free: 1990.8 MB)
2021-12-03 21:40:30,888 [dispatcher-event-loop-5] INFO [org.apache.spark.storage.BlockManagerInfo] - Updated broadcast_4_piece0 in memory on qb:61634 (current size: 2.4 KB, original size: 2.4 KB, free: 1990.8 MB)
2021-12-03 21:40:30,888 [dispatcher-event-loop-6] INFO [org.apache.spark.storage.BlockManagerInfo] - Updated broadcast_0_piece0 in memory on qb:61634 (current size: 27.3 KB, original size: 27.3 KB, free: 1990.8 MB)
2021-12-03 21:40:30,889 [dispatcher-event-loop-8] INFO [org.apache.spark.storage.BlockManagerInfo] - Updated broadcast_2_piece0 in memory on qb:61634 (current size: 2.7 KB, original size: 2.7 KB, free: 1990.8 MB)
2021-12-03 21:40:30,889 [main] INFO [org.apache.hadoop.conf.Configuration.deprecation] - mapred.output.dir is deprecated. Instead, use mapreduce.output.fileoutputformat.outputdir
2021-12-03 21:40:30,889 [dispatcher-event-loop-1] INFO [org.apache.spark.storage.BlockManagerInfo] - Updated broadcast_8_piece0 in memory on qb:61634 (current size: 2022.0 B, original size: 2022.0 B, free: 1990.8 MB)
2021-12-03 21:40:30,889 [driver-heartbeater] INFO [org.apache.spark.executor.Executor] - Told to re-register on heartbeat
2021-12-03 21:40:30,889 [driver-heartbeater] INFO [org.apache.spark.storage.BlockManager] - BlockManager BlockManagerId(driver, qb, 61634, None) re-registering with master
2021-12-03 21:40:30,889 [driver-heartbeater] INFO [org.apache.spark.storage.BlockManagerMaster] - Registering BlockManager BlockManagerId(driver, qb, 61634, None)
2021-12-03 21:40:30,889 [driver-heartbeater] INFO [org.apache.spark.storage.BlockManagerMaster] - Registered BlockManager BlockManagerId(driver, qb, 61634, None)
2021-12-03 21:40:30,889 [driver-heartbeater] INFO [org.apache.spark.storage.BlockManager] - Reporting 10 blocks to the master.
2021-12-03 21:40:30,890 [dispatcher-event-loop-2] INFO [org.apache.spark.storage.BlockManagerInfo] - Updated broadcast_3_piece0 in memory on qb:61634 (current size: 1906.0 B, original size: 1906.0 B, free: 1990.8 MB)
2021-12-03 21:40:30,890 [dispatcher-event-loop-7] INFO [org.apache.spark.storage.BlockManagerInfo] - Updated broadcast_4_piece0 in memory on qb:61634 (current size: 2.4 KB, original size: 2.4 KB, free: 1990.8 MB)
2021-12-03 21:40:30,890 [dispatcher-event-loop-10] INFO [org.apache.spark.storage.BlockManagerInfo] - Updated broadcast_0_piece0 in memory on qb:61634 (current size: 27.3 KB, original size: 27.3 KB, free: 1990.8 MB)
2021-12-03 21:40:30,891 [dispatcher-event-loop-3] INFO [org.apache.spark.storage.BlockManagerInfo] - Updated broadcast_2_piece0 in memory on qb:61634 (current size: 2.7 KB, original size: 2.7 KB, free: 1990.8 MB)
2021-12-03 21:40:30,891 [dispatcher-event-loop-11] INFO [org.apache.spark.storage.BlockManagerInfo] - Updated broadcast_8_piece0 in memory on qb:61634 (current size: 2022.0 B, original size: 2022.0 B, free: 1990.8 MB)
2021-12-03 21:40:30,891 [driver-heartbeater] INFO [org.apache.spark.executor.Executor] - Told to re-register on heartbeat
2021-12-03 21:40:30,891 [driver-heartbeater] INFO [org.apache.spark.storage.BlockManager] - BlockManager BlockManagerId(driver, qb, 61634, None) re-registering with master
2021-12-03 21:40:30,891 [driver-heartbeater] INFO [org.apache.spark.storage.BlockManagerMaster] - Registering BlockManager BlockManagerId(driver, qb, 61634, None)
2021-12-03 21:40:30,892 [driver-heartbeater] INFO [org.apache.spark.storage.BlockManagerMaster] - Registered BlockManager BlockManagerId(driver, qb, 61634, None)
2021-12-03 21:40:30,892 [driver-heartbeater] INFO [org.apache.spark.storage.BlockManager] - Reporting 10 blocks to the master.
2021-12-03 21:40:30,892 [dispatcher-event-loop-6] INFO [org.apache.spark.storage.BlockManagerInfo] - Updated broadcast_3_piece0 in memory on qb:61634 (current size: 1906.0 B, original size: 1906.0 B, free: 1990.8 MB)
2021-12-03 21:40:30,892 [main] INFO [org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter] - File Output Committer Algorithm version is 1
2021-12-03 21:40:30,892 [dispatcher-event-loop-8] INFO [org.apache.spark.storage.BlockManagerInfo] - Updated broadcast_4_piece0 in memory on qb:61634 (current size: 2.4 KB, original size: 2.4 KB, free: 1990.8 MB)
2021-12-03 21:40:30,893 [dispatcher-event-loop-1] INFO [org.apache.spark.storage.BlockManagerInfo] - Updated broadcast_0_piece0 in memory on qb:61634 (current size: 27.3 KB, original size: 27.3 KB, free: 1990.8 MB)
2021-12-03 21:40:30,893 [dispatcher-event-loop-9] INFO [org.apache.spark.storage.BlockManagerInfo] - Updated broadcast_2_piece0 in memory on qb:61634 (current size: 2.7 KB, original size: 2.7 KB, free: 1990.8 MB)
2021-12-03 21:40:30,893 [dispatcher-event-loop-0] INFO [org.apache.spark.storage.BlockManagerInfo] - Updated broadcast_8_piece0 in memory on qb:61634 (current size: 2022.0 B, original size: 2022.0 B, free: 1990.8 MB)
2021-12-03 21:40:30,894 [driver-heartbeater] INFO [org.apache.spark.executor.Executor] - Told to re-register on heartbeat
2021-12-03 21:40:30,894 [driver-heartbeater] INFO [org.apache.spark.storage.BlockManager] - BlockManager BlockManagerId(driver, qb, 61634, None) re-registering with master
2021-12-03 21:40:30,894 [driver-heartbeater] INFO [org.apache.spark.storage.BlockManagerMaster] - Registering BlockManager BlockManagerId(driver, qb, 61634, None)
2021-12-03 21:40:30,894 [driver-heartbeater] INFO [org.apache.spark.storage.BlockManagerMaster] - Registered BlockManager BlockManagerId(driver, qb, 61634, None)
2021-12-03 21:40:30,894 [driver-heartbeater] INFO [org.apache.spark.storage.BlockManager] - Reporting 10 blocks to the master.
2021-12-03 21:40:30,894 [dispatcher-event-loop-10] INFO [org.apache.spark.storage.BlockManagerInfo] - Updated broadcast_3_piece0 in memory on qb:61634 (current size: 1906.0 B, original size: 1906.0 B, free: 1990.8 MB)
2021-12-03 21:40:30,895 [dispatcher-event-loop-3] INFO [org.apache.spark.storage.BlockManagerInfo] - Updated broadcast_4_piece0 in memory on qb:61634 (current size: 2.4 KB, original size: 2.4 KB, free: 1990.8 MB)
2021-12-03 21:40:30,895 [dispatcher-event-loop-11] INFO [org.apache.spark.storage.BlockManagerInfo] - Updated broadcast_0_piece0 in memory on qb:61634 (current size: 27.3 KB, original size: 27.3 KB, free: 1990.8 MB)
2021-12-03 21:40:30,895 [dispatcher-event-loop-4] INFO [org.apache.spark.storage.BlockManagerInfo] - Updated broadcast_2_piece0 in memory on qb:61634 (current size: 2.7 KB, original size: 2.7 KB, free: 1990.8 MB)
2021-12-03 21:40:30,896 [dispatcher-event-loop-5] INFO [org.apache.spark.storage.BlockManagerInfo] - Updated broadcast_8_piece0 in memory on qb:61634 (current size: 2022.0 B, original size: 2022.0 B, free: 1990.8 MB)
2021-12-03 21:40:30,896 [driver-heartbeater] INFO [org.apache.spark.executor.Executor] - Told to re-register on heartbeat
2021-12-03 21:40:30,896 [driver-heartbeater] INFO [org.apache.spark.storage.BlockManager] - BlockManager BlockManagerId(driver, qb, 61634, None) re-registering with master
2021-12-03 21:40:30,896 [driver-heartbeater] INFO [org.apache.spark.storage.BlockManagerMaster] - Registering BlockManager BlockManagerId(driver, qb, 61634, None)
2021-12-03 21:40:30,896 [driver-heartbeater] INFO [org.apache.spark.storage.BlockManagerMaster] - Registered BlockManager BlockManagerId(driver, qb, 61634, None)
2021-12-03 21:40:30,896 [driver-heartbeater] INFO [org.apache.spark.storage.BlockManager] - Reporting 10 blocks to the master.
2021-12-03 21:40:30,897 [dispatcher-event-loop-1] INFO [org.apache.spark.storage.BlockManagerInfo] - Updated broadcast_3_piece0 in memory on qb:61634 (current size: 1906.0 B, original size: 1906.0 B, free: 1990.8 MB)
2021-12-03 21:40:30,897 [dispatcher-event-loop-9] INFO [org.apache.spark.storage.BlockManagerInfo] - Updated broadcast_4_piece0 in memory on qb:61634 (current size: 2.4 KB, original size: 2.4 KB, free: 1990.8 MB)
2021-12-03 21:40:30,898 [dispatcher-event-loop-0] INFO [org.apache.spark.storage.BlockManagerInfo] - Updated broadcast_0_piece0 in memory on qb:61634 (current size: 27.3 KB, original size: 27.3 KB, free: 1990.8 MB)
2021-12-03 21:40:30,898 [dispatcher-event-loop-2] INFO [org.apache.spark.storage.BlockManagerInfo] - Updated broadcast_2_piece0 in memory on qb:61634 (current size: 2.7 KB, original size: 2.7 KB, free: 1990.8 MB)
2021-12-03 21:40:30,899 [dispatcher-event-loop-7] INFO [org.apache.spark.storage.BlockManagerInfo] - Updated broadcast_8_piece0 in memory on qb:61634 (current size: 2022.0 B, original size: 2022.0 B, free: 1990.8 MB)
2021-12-03 21:40:30,899 [driver-heartbeater] INFO [org.apache.spark.executor.Executor] - Told to re-register on heartbeat
2021-12-03 21:40:30,899 [driver-heartbeater] INFO [org.apache.spark.storage.BlockManager] - BlockManager BlockManagerId(driver, qb, 61634, None) re-registering with master
2021-12-03 21:40:30,899 [driver-heartbeater] INFO [org.apache.spark.storage.BlockManagerMaster] - Registering BlockManager BlockManagerId(driver, qb, 61634, None)
2021-12-03 21:40:30,899 [driver-heartbeater] INFO [org.apache.spark.storage.BlockManagerMaster] - Registered BlockManager BlockManagerId(driver, qb, 61634, None)
2021-12-03 21:40:30,899 [driver-heartbeater] INFO [org.apache.spark.storage.BlockManager] - Reporting 10 blocks to the master.
2021-12-03 21:40:30,900 [dispatcher-event-loop-11] INFO [org.apache.spark.storage.BlockManagerInfo] - Updated broadcast_3_piece0 in memory on qb:61634 (current size: 1906.0 B, original size: 1906.0 B, free: 1990.8 MB)
2021-12-03 21:40:30,900 [dispatcher-event-loop-4] INFO [org.apache.spark.storage.BlockManagerInfo] - Updated broadcast_4_piece0 in memory on qb:61634 (current size: 2.4 KB, original size: 2.4 KB, free: 1990.8 MB)
2021-12-03 21:40:30,900 [dispatcher-event-loop-5] INFO [org.apache.spark.storage.BlockManagerInfo] - Updated broadcast_0_piece0 in memory on qb:61634 (current size: 27.3 KB, original size: 27.3 KB, free: 1990.8 MB)
2021-12-03 21:40:30,901 [dispatcher-event-loop-6] INFO [org.apache.spark.storage.BlockManagerInfo] - Updated broadcast_2_piece0 in memory on qb:61634 (current size: 2.7 KB, original size: 2.7 KB, free: 1990.8 MB)
2021-12-03 21:40:30,901 [dispatcher-event-loop-8] INFO [org.apache.spark.storage.BlockManagerInfo] - Updated broadcast_8_piece0 in memory on qb:61634 (current size: 2022.0 B, original size: 2022.0 B, free: 1990.8 MB)
2021-12-03 21:40:30,901 [driver-heartbeater] INFO [org.apache.spark.executor.Executor] - Told to re-register on heartbeat
2021-12-03 21:40:30,901 [driver-heartbeater] INFO [org.apache.spark.storage.BlockManager] - BlockManager BlockManagerId(driver, qb, 61634, None) re-registering with master
2021-12-03 21:40:30,901 [driver-heartbeater] INFO [org.apache.spark.storage.BlockManagerMaster] - Registering BlockManager BlockManagerId(driver, qb, 61634, None)
2021-12-03 21:40:30,901 [driver-heartbeater] INFO [org.apache.spark.storage.BlockManagerMaster] - Registered BlockManager BlockManagerId(driver, qb, 61634, None)
2021-12-03 21:40:30,901 [driver-heartbeater] INFO [org.apache.spark.storage.BlockManager] - Reporting 10 blocks to the master.
2021-12-03 21:40:30,902 [dispatcher-event-loop-0] INFO [org.apache.spark.storage.BlockManagerInfo] - Updated broadcast_3_piece0 in memory on qb:61634 (current size: 1906.0 B, original size: 1906.0 B, free: 1990.8 MB)
2021-12-03 21:40:30,902 [dispatcher-event-loop-2] INFO [org.apache.spark.storage.BlockManagerInfo] - Updated broadcast_4_piece0 in memory on qb:61634 (current size: 2.4 KB, original size: 2.4 KB, free: 1990.8 MB)
2021-12-03 21:40:30,902 [dispatcher-event-loop-7] INFO [org.apache.spark.storage.BlockManagerInfo] - Updated broadcast_0_piece0 in memory on qb:61634 (current size: 27.3 KB, original size: 27.3 KB, free: 1990.8 MB)
2021-12-03 21:40:30,903 [dispatcher-event-loop-10] INFO [org.apache.spark.storage.BlockManagerInfo] - Updated broadcast_2_piece0 in memory on qb:61634 (current size: 2.7 KB, original size: 2.7 KB, free: 1990.8 MB)
2021-12-03 21:40:30,903 [dispatcher-event-loop-3] INFO [org.apache.spark.storage.BlockManagerInfo] - Updated broadcast_8_piece0 in memory on qb:61634 (current size: 2022.0 B, original size: 2022.0 B, free: 1990.8 MB)
2021-12-03 21:40:30,903 [driver-heartbeater] INFO [org.apache.spark.executor.Executor] - Told to re-register on heartbeat
2021-12-03 21:40:30,903 [driver-heartbeater] INFO [org.apache.spark.storage.BlockManager] - BlockManager BlockManagerId(driver, qb, 61634, None) re-registering with master
2021-12-03 21:40:30,903 [driver-heartbeater] INFO [org.apache.spark.storage.BlockManagerMaster] - Registering BlockManager BlockManagerId(driver, qb, 61634, None)
2021-12-03 21:40:30,903 [driver-heartbeater] INFO [org.apache.spark.storage.BlockManagerMaster] - Registered BlockManager BlockManagerId(driver, qb, 61634, None)
2021-12-03 21:40:30,903 [driver-heartbeater] INFO [org.apache.spark.storage.BlockManager] - Reporting 10 blocks to the master.
2021-12-03 21:40:30,903 [dispatcher-event-loop-5] INFO [org.apache.spark.storage.BlockManagerInfo] - Updated broadcast_3_piece0 in memory on qb:61634 (current size: 1906.0 B, original size: 1906.0 B, free: 1990.8 MB)
2021-12-03 21:40:30,904 [dispatcher-event-loop-6] INFO [org.apache.spark.storage.BlockManagerInfo] - Updated broadcast_4_piece0 in memory on qb:61634 (current size: 2.4 KB, original size: 2.4 KB, free: 1990.8 MB)
2021-12-03 21:40:30,904 [dispatcher-event-loop-8] INFO [org.apache.spark.storage.BlockManagerInfo] - Updated broadcast_0_piece0 in memory on qb:61634 (current size: 27.3 KB, original size: 27.3 KB, free: 1990.8 MB)
2021-12-03 21:40:30,904 [dispatcher-event-loop-1] INFO [org.apache.spark.storage.BlockManagerInfo] - Updated broadcast_2_piece0 in memory on qb:61634 (current size: 2.7 KB, original size: 2.7 KB, free: 1990.8 MB)
2021-12-03 21:40:30,904 [dispatcher-event-loop-9] INFO [org.apache.spark.storage.BlockManagerInfo] - Updated broadcast_8_piece0 in memory on qb:61634 (current size: 2022.0 B, original size: 2022.0 B, free: 1990.8 MB)
2021-12-03 21:40:30,905 [driver-heartbeater] INFO [org.apache.spark.executor.Executor] - Told to re-register on heartbeat
2021-12-03 21:40:30,905 [driver-heartbeater] INFO [org.apache.spark.storage.BlockManager] - BlockManager BlockManagerId(driver, qb, 61634, None) re-registering with master
2021-12-03 21:40:30,905 [driver-heartbeater] INFO [org.apache.spark.storage.BlockManagerMaster] - Registering BlockManager BlockManagerId(driver, qb, 61634, None)
2021-12-03 21:40:30,905 [driver-heartbeater] INFO [org.apache.spark.storage.BlockManagerMaster] - Registered BlockManager BlockManagerId(driver, qb, 61634, None)
2021-12-03 21:40:30,905 [driver-heartbeater] INFO [org.apache.spark.storage.BlockManager] - Reporting 10 blocks to the master.
2021-12-03 21:40:30,905 [dispatcher-event-loop-7] INFO [org.apache.spark.storage.BlockManagerInfo] - Updated broadcast_3_piece0 in memory on qb:61634 (current size: 1906.0 B, original size: 1906.0 B, free: 1990.8 MB)
2021-12-03 21:40:30,905 [dispatcher-event-loop-10] INFO [org.apache.spark.storage.BlockManagerInfo] - Updated broadcast_4_piece0 in memory on qb:61634 (current size: 2.4 KB, original size: 2.4 KB, free: 1990.8 MB)
2021-12-03 21:40:30,905 [dispatcher-event-loop-3] INFO [org.apache.spark.storage.BlockManagerInfo] - Updated broadcast_0_piece0 in memory on qb:61634 (current size: 27.3 KB, original size: 27.3 KB, free: 1990.8 MB)
2021-12-03 21:40:30,906 [dispatcher-event-loop-11] INFO [org.apache.spark.storage.BlockManagerInfo] - Updated broadcast_2_piece0 in memory on qb:61634 (current size: 2.7 KB, original size: 2.7 KB, free: 1990.8 MB)
2021-12-03 21:40:30,906 [dispatcher-event-loop-4] INFO [org.apache.spark.storage.BlockManagerInfo] - Updated broadcast_8_piece0 in memory on qb:61634 (current size: 2022.0 B, original size: 2022.0 B, free: 1990.8 MB)
2021-12-03 21:40:30,906 [driver-heartbeater] INFO [org.apache.spark.executor.Executor] - Told to re-register on heartbeat
2021-12-03 21:40:30,906 [driver-heartbeater] INFO [org.apache.spark.storage.BlockManager] - BlockManager BlockManagerId(driver, qb, 61634, None) re-registering with master
2021-12-03 21:40:30,907 [driver-heartbeater] INFO [org.apache.spark.storage.BlockManagerMaster] - Registering BlockManager BlockManagerId(driver, qb, 61634, None)
2021-12-03 21:40:30,907 [driver-heartbeater] INFO [org.apache.spark.storage.BlockManagerMaster] - Registered BlockManager BlockManagerId(driver, qb, 61634, None)
2021-12-03 21:40:30,907 [driver-heartbeater] INFO [org.apache.spark.storage.BlockManager] - Reporting 10 blocks to the master.
2021-12-03 21:40:30,907 [dispatcher-event-loop-8] INFO [org.apache.spark.storage.BlockManagerInfo] - Updated broadcast_3_piece0 in memory on qb:61634 (current size: 1906.0 B, original size: 1906.0 B, free: 1990.8 MB)
2021-12-03 21:40:30,907 [dispatcher-event-loop-1] INFO [org.apache.spark.storage.BlockManagerInfo] - Updated broadcast_4_piece0 in memory on qb:61634 (current size: 2.4 KB, original size: 2.4 KB, free: 1990.8 MB)
2021-12-03 21:40:30,907 [dispatcher-event-loop-9] INFO [org.apache.spark.storage.BlockManagerInfo] - Updated broadcast_0_piece0 in memory on qb:61634 (current size: 27.3 KB, original size: 27.3 KB, free: 1990.8 MB)
2021-12-03 21:40:30,908 [dispatcher-event-loop-0] INFO [org.apache.spark.storage.BlockManagerInfo] - Updated broadcast_2_piece0 in memory on qb:61634 (current size: 2.7 KB, original size: 2.7 KB, free: 1990.8 MB)
2021-12-03 21:40:30,908 [dispatcher-event-loop-2] INFO [org.apache.spark.storage.BlockManagerInfo] - Updated broadcast_8_piece0 in memory on qb:61634 (current size: 2022.0 B, original size: 2022.0 B, free: 1990.8 MB)
2021-12-03 21:40:30,908 [driver-heartbeater] INFO [org.apache.spark.executor.Executor] - Told to re-register on heartbeat
2021-12-03 21:40:30,908 [driver-heartbeater] INFO [org.apache.spark.storage.BlockManager] - BlockManager BlockManagerId(driver, qb, 61634, None) re-registering with master
2021-12-03 21:40:30,908 [driver-heartbeater] INFO [org.apache.spark.storage.BlockManagerMaster] - Registering BlockManager BlockManagerId(driver, qb, 61634, None)
2021-12-03 21:40:30,908 [driver-heartbeater] INFO [org.apache.spark.storage.BlockManagerMaster] - Registered BlockManager BlockManagerId(driver, qb, 61634, None)
2021-12-03 21:40:30,908 [driver-heartbeater] INFO [org.apache.spark.storage.BlockManager] - Reporting 10 blocks to the master.
2021-12-03 21:40:30,909 [dispatcher-event-loop-3] INFO [org.apache.spark.storage.BlockManagerInfo] - Updated broadcast_3_piece0 in memory on qb:61634 (current size: 1906.0 B, original size: 1906.0 B, free: 1990.8 MB)
2021-12-03 21:40:30,909 [dispatcher-event-loop-11] INFO [org.apache.spark.storage.BlockManagerInfo] - Updated broadcast_4_piece0 in memory on qb:61634 (current size: 2.4 KB, original size: 2.4 KB, free: 1990.8 MB)
2021-12-03 21:40:30,909 [dispatcher-event-loop-4] INFO [org.apache.spark.storage.BlockManagerInfo] - Updated broadcast_0_piece0 in memory on qb:61634 (current size: 27.3 KB, original size: 27.3 KB, free: 1990.8 MB)
2021-12-03 21:40:30,909 [dispatcher-event-loop-5] INFO [org.apache.spark.storage.BlockManagerInfo] - Updated broadcast_2_piece0 in memory on qb:61634 (current size: 2.7 KB, original size: 2.7 KB, free: 1990.8 MB)
2021-12-03 21:40:30,910 [dispatcher-event-loop-6] INFO [org.apache.spark.storage.BlockManagerInfo] - Updated broadcast_8_piece0 in memory on qb:61634 (current size: 2022.0 B, original size: 2022.0 B, free: 1990.8 MB)
2021-12-03 21:40:30,910 [driver-heartbeater] INFO [org.apache.spark.executor.Executor] - Told to re-register on heartbeat
2021-12-03 21:40:30,910 [driver-heartbeater] INFO [org.apache.spark.storage.BlockManager] - BlockManager BlockManagerId(driver, qb, 61634, None) re-registering with master
2021-12-03 21:40:30,910 [driver-heartbeater] INFO [org.apache.spark.storage.BlockManagerMaster] - Registering BlockManager BlockManagerId(driver, qb, 61634, None)
2021-12-03 21:40:30,910 [driver-heartbeater] INFO [org.apache.spark.storage.BlockManagerMaster] - Registered BlockManager BlockManagerId(driver, qb, 61634, None)
2021-12-03 21:40:30,910 [driver-heartbeater] INFO [org.apache.spark.storage.BlockManager] - Reporting 10 blocks to the master.
2021-12-03 21:40:30,911 [dispatcher-event-loop-9] INFO [org.apache.spark.storage.BlockManagerInfo] - Updated broadcast_3_piece0 in memory on qb:61634 (current size: 1906.0 B, original size: 1906.0 B, free: 1990.8 MB)
2021-12-03 21:40:30,911 [dispatcher-event-loop-0] INFO [org.apache.spark.storage.BlockManagerInfo] - Updated broadcast_4_piece0 in memory on qb:61634 (current size: 2.4 KB, original size: 2.4 KB, free: 1990.8 MB)
2021-12-03 21:40:30,911 [dispatcher-event-loop-2] INFO [org.apache.spark.storage.BlockManagerInfo] - Updated broadcast_0_piece0 in memory on qb:61634 (current size: 27.3 KB, original size: 27.3 KB, free: 1990.8 MB)
2021-12-03 21:40:30,911 [dispatcher-event-loop-7] INFO [org.apache.spark.storage.BlockManagerInfo] - Updated broadcast_2_piece0 in memory on qb:61634 (current size: 2.7 KB, original size: 2.7 KB, free: 1990.8 MB)
2021-12-03 21:40:30,912 [dispatcher-event-loop-10] INFO [org.apache.spark.storage.BlockManagerInfo] - Updated broadcast_8_piece0 in memory on qb:61634 (current size: 2022.0 B, original size: 2022.0 B, free: 1990.8 MB)
2021-12-03 21:40:30,912 [driver-heartbeater] INFO [org.apache.spark.executor.Executor] - Told to re-register on heartbeat
2021-12-03 21:40:30,912 [driver-heartbeater] INFO [org.apache.spark.storage.BlockManager] - BlockManager BlockManagerId(driver, qb, 61634, None) re-registering with master
2021-12-03 21:40:30,912 [driver-heartbeater] INFO [org.apache.spark.storage.BlockManagerMaster] - Registering BlockManager BlockManagerId(driver, qb, 61634, None)
2021-12-03 21:40:30,912 [driver-heartbeater] INFO [org.apache.spark.storage.BlockManagerMaster] - Registered BlockManager BlockManagerId(driver, qb, 61634, None)
2021-12-03 21:40:30,912 [driver-heartbeater] INFO [org.apache.spark.storage.BlockManager] - Reporting 10 blocks to the master.
2021-12-03 21:40:30,912 [dispatcher-event-loop-4] INFO [org.apache.spark.storage.BlockManagerInfo] - Updated broadcast_3_piece0 in memory on qb:61634 (current size: 1906.0 B, original size: 1906.0 B, free: 1990.8 MB)
2021-12-03 21:40:30,913 [dispatcher-event-loop-5] INFO [org.apache.spark.storage.BlockManagerInfo] - Updated broadcast_4_piece0 in memory on qb:61634 (current size: 2.4 KB, original size: 2.4 KB, free: 1990.8 MB)
2021-12-03 21:40:30,913 [dispatcher-event-loop-6] INFO [org.apache.spark.storage.BlockManagerInfo] - Updated broadcast_0_piece0 in memory on qb:61634 (current size: 27.3 KB, original size: 27.3 KB, free: 1990.8 MB)
2021-12-03 21:40:30,913 [dispatcher-event-loop-8] INFO [org.apache.spark.storage.BlockManagerInfo] - Updated broadcast_2_piece0 in memory on qb:61634 (current size: 2.7 KB, original size: 2.7 KB, free: 1990.8 MB)
2021-12-03 21:40:30,913 [dispatcher-event-loop-1] INFO [org.apache.spark.storage.BlockManagerInfo] - Updated broadcast_8_piece0 in memory on qb:61634 (current size: 2022.0 B, original size: 2022.0 B, free: 1990.8 MB)
2021-12-03 21:40:30,914 [driver-heartbeater] INFO [org.apache.spark.executor.Executor] - Told to re-register on heartbeat
2021-12-03 21:40:30,914 [driver-heartbeater] INFO [org.apache.spark.storage.BlockManager] - BlockManager BlockManagerId(driver, qb, 61634, None) re-registering with master
2021-12-03 21:40:30,914 [driver-heartbeater] INFO [org.apache.spark.storage.BlockManagerMaster] - Registering BlockManager BlockManagerId(driver, qb, 61634, None)
2021-12-03 21:40:30,914 [driver-heartbeater] INFO [org.apache.spark.storage.BlockManagerMaster] - Registered BlockManager BlockManagerId(driver, qb, 61634, None)
2021-12-03 21:40:30,914 [driver-heartbeater] INFO [org.apache.spark.storage.BlockManager] - Reporting 10 blocks to the master.
2021-12-03 21:40:30,914 [dispatcher-event-loop-2] INFO [org.apache.spark.storage.BlockManagerInfo] - Updated broadcast_3_piece0 in memory on qb:61634 (current size: 1906.0 B, original size: 1906.0 B, free: 1990.8 MB)
2021-12-03 21:40:30,914 [dispatcher-event-loop-7] INFO [org.apache.spark.storage.BlockManagerInfo] - Updated broadcast_4_piece0 in memory on qb:61634 (current size: 2.4 KB, original size: 2.4 KB, free: 1990.8 MB)
2021-12-03 21:40:30,915 [dispatcher-event-loop-10] INFO [org.apache.spark.storage.BlockManagerInfo] - Updated broadcast_0_piece0 in memory on qb:61634 (current size: 27.3 KB, original size: 27.3 KB, free: 1990.8 MB)
2021-12-03 21:40:30,915 [dispatcher-event-loop-3] INFO [org.apache.spark.storage.BlockManagerInfo] - Updated broadcast_2_piece0 in memory on qb:61634 (current size: 2.7 KB, original size: 2.7 KB, free: 1990.8 MB)
2021-12-03 21:40:30,916 [dispatcher-event-loop-11] INFO [org.apache.spark.storage.BlockManagerInfo] - Updated broadcast_8_piece0 in memory on qb:61634 (current size: 2022.0 B, original size: 2022.0 B, free: 1990.8 MB)
2021-12-03 21:40:30,916 [driver-heartbeater] INFO [org.apache.spark.executor.Executor] - Told to re-register on heartbeat
2021-12-03 21:40:30,916 [driver-heartbeater] INFO [org.apache.spark.storage.BlockManager] - BlockManager BlockManagerId(driver, qb, 61634, None) re-registering with master
2021-12-03 21:40:30,916 [driver-heartbeater] INFO [org.apache.spark.storage.BlockManagerMaster] - Registering BlockManager BlockManagerId(driver, qb, 61634, None)
2021-12-03 21:40:30,916 [driver-heartbeater] INFO [org.apache.spark.storage.BlockManagerMaster] - Registered BlockManager BlockManagerId(driver, qb, 61634, None)
2021-12-03 21:40:30,916 [driver-heartbeater] INFO [org.apache.spark.storage.BlockManager] - Reporting 10 blocks to the master.
2021-12-03 21:40:30,917 [dispatcher-event-loop-6] INFO [org.apache.spark.storage.BlockManagerInfo] - Updated broadcast_3_piece0 in memory on qb:61634 (current size: 1906.0 B, original size: 1906.0 B, free: 1990.8 MB)
2021-12-03 21:40:30,917 [dispatcher-event-loop-8] INFO [org.apache.spark.storage.BlockManagerInfo] - Updated broadcast_4_piece0 in memory on qb:61634 (current size: 2.4 KB, original size: 2.4 KB, free: 1990.8 MB)
2021-12-03 21:40:30,917 [dispatcher-event-loop-1] INFO [org.apache.spark.storage.BlockManagerInfo] - Updated broadcast_0_piece0 in memory on qb:61634 (current size: 27.3 KB, original size: 27.3 KB, free: 1990.8 MB)
2021-12-03 21:40:30,917 [dispatcher-event-loop-9] INFO [org.apache.spark.storage.BlockManagerInfo] - Updated broadcast_2_piece0 in memory on qb:61634 (current size: 2.7 KB, original size: 2.7 KB, free: 1990.8 MB)
2021-12-03 21:40:30,918 [dispatcher-event-loop-0] INFO [org.apache.spark.storage.BlockManagerInfo] - Updated broadcast_8_piece0 in memory on qb:61634 (current size: 2022.0 B, original size: 2022.0 B, free: 1990.8 MB)
2021-12-03 21:40:30,918 [driver-heartbeater] INFO [org.apache.spark.executor.Executor] - Told to re-register on heartbeat
2021-12-03 21:40:30,918 [driver-heartbeater] INFO [org.apache.spark.storage.BlockManager] - BlockManager BlockManagerId(driver, qb, 61634, None) re-registering with master
2021-12-03 21:40:30,918 [driver-heartbeater] INFO [org.apache.spark.storage.BlockManagerMaster] - Registering BlockManager BlockManagerId(driver, qb, 61634, None)
2021-12-03 21:40:30,918 [driver-heartbeater] INFO [org.apache.spark.storage.BlockManagerMaster] - Registered BlockManager BlockManagerId(driver, qb, 61634, None)
2021-12-03 21:40:30,918 [driver-heartbeater] INFO [org.apache.spark.storage.BlockManager] - Reporting 10 blocks to the master.
2021-12-03 21:40:30,918 [dispatcher-event-loop-10] INFO [org.apache.spark.storage.BlockManagerInfo] - Updated broadcast_3_piece0 in memory on qb:61634 (current size: 1906.0 B, original size: 1906.0 B, free: 1990.8 MB)
2021-12-03 21:40:30,919 [dispatcher-event-loop-3] INFO [org.apache.spark.storage.BlockManagerInfo] - Updated broadcast_4_piece0 in memory on qb:61634 (current size: 2.4 KB, original size: 2.4 KB, free: 1990.8 MB)
2021-12-03 21:40:30,919 [dispatcher-event-loop-11] INFO [org.apache.spark.storage.BlockManagerInfo] - Updated broadcast_0_piece0 in memory on qb:61634 (current size: 27.3 KB, original size: 27.3 KB, free: 1990.8 MB)
2021-12-03 21:40:30,919 [dispatcher-event-loop-4] INFO [org.apache.spark.storage.BlockManagerInfo] - Updated broadcast_2_piece0 in memory on qb:61634 (current size: 2.7 KB, original size: 2.7 KB, free: 1990.8 MB)
2021-12-03 21:40:30,919 [dispatcher-event-loop-5] INFO [org.apache.spark.storage.BlockManagerInfo] - Updated broadcast_8_piece0 in memory on qb:61634 (current size: 2022.0 B, original size: 2022.0 B, free: 1990.8 MB)
2021-12-03 21:40:30,920 [driver-heartbeater] INFO [org.apache.spark.executor.Executor] - Told to re-register on heartbeat
2021-12-03 21:40:30,920 [driver-heartbeater] INFO [org.apache.spark.storage.BlockManager] - BlockManager BlockManagerId(driver, qb, 61634, None) re-registering with master
2021-12-03 21:40:30,920 [driver-heartbeater] INFO [org.apache.spark.storage.BlockManagerMaster] - Registering BlockManager BlockManagerId(driver, qb, 61634, None)
2021-12-03 21:40:30,920 [driver-heartbeater] INFO [org.apache.spark.storage.BlockManagerMaster] - Registered BlockManager BlockManagerId(driver, qb, 61634, None)
2021-12-03 21:40:30,920 [driver-heartbeater] INFO [org.apache.spark.storage.BlockManager] - Reporting 10 blocks to the master.
2021-12-03 21:40:30,920 [dispatcher-event-loop-1] INFO [org.apache.spark.storage.BlockManagerInfo] - Updated broadcast_3_piece0 in memory on qb:61634 (current size: 1906.0 B, original size: 1906.0 B, free: 1990.8 MB)
2021-12-03 21:40:30,920 [dispatcher-event-loop-9] INFO [org.apache.spark.storage.BlockManagerInfo] - Updated broadcast_4_piece0 in memory on qb:61634 (current size: 2.4 KB, original size: 2.4 KB, free: 1990.8 MB)
2021-12-03 21:40:30,920 [dispatcher-event-loop-0] INFO [org.apache.spark.storage.BlockManagerInfo] - Updated broadcast_0_piece0 in memory on qb:61634 (current size: 27.3 KB, original size: 27.3 KB, free: 1990.8 MB)
2021-12-03 21:40:30,921 [dispatcher-event-loop-2] INFO [org.apache.spark.storage.BlockManagerInfo] - Updated broadcast_2_piece0 in memory on qb:61634 (current size: 2.7 KB, original size: 2.7 KB, free: 1990.8 MB)
2021-12-03 21:40:30,921 [dispatcher-event-loop-7] INFO [org.apache.spark.storage.BlockManagerInfo] - Updated broadcast_8_piece0 in memory on qb:61634 (current size: 2022.0 B, original size: 2022.0 B, free: 1990.8 MB)
2021-12-03 21:40:30,921 [driver-heartbeater] INFO [org.apache.spark.executor.Executor] - Told to re-register on heartbeat
2021-12-03 21:40:30,921 [driver-heartbeater] INFO [org.apache.spark.storage.BlockManager] - BlockManager BlockManagerId(driver, qb, 61634, None) re-registering with master
2021-12-03 21:40:30,921 [driver-heartbeater] INFO [org.apache.spark.storage.BlockManagerMaster] - Registering BlockManager BlockManagerId(driver, qb, 61634, None)
2021-12-03 21:40:30,921 [driver-heartbeater] INFO [org.apache.spark.storage.BlockManagerMaster] - Registered BlockManager BlockManagerId(driver, qb, 61634, None)
2021-12-03 21:40:30,921 [driver-heartbeater] INFO [org.apache.spark.storage.BlockManager] - Reporting 10 blocks to the master.
2021-12-03 21:40:30,921 [dispatcher-event-loop-11] INFO [org.apache.spark.storage.BlockManagerInfo] - Updated broadcast_3_piece0 in memory on qb:61634 (current size: 1906.0 B, original size: 1906.0 B, free: 1990.8 MB)
2021-12-03 21:40:30,922 [dispatcher-event-loop-4] INFO [org.apache.spark.storage.BlockManagerInfo] - Updated broadcast_4_piece0 in memory on qb:61634 (current size: 2.4 KB, original size: 2.4 KB, free: 1990.8 MB)
2021-12-03 21:40:30,922 [dispatcher-event-loop-5] INFO [org.apache.spark.storage.BlockManagerInfo] - Updated broadcast_0_piece0 in memory on qb:61634 (current size: 27.3 KB, original size: 27.3 KB, free: 1990.8 MB)
2021-12-03 21:40:30,922 [dispatcher-event-loop-6] INFO [org.apache.spark.storage.BlockManagerInfo] - Updated broadcast_2_piece0 in memory on qb:61634 (current size: 2.7 KB, original size: 2.7 KB, free: 1990.8 MB)
2021-12-03 21:40:30,922 [dispatcher-event-loop-8] INFO [org.apache.spark.storage.BlockManagerInfo] - Updated broadcast_8_piece0 in memory on qb:61634 (current size: 2022.0 B, original size: 2022.0 B, free: 1990.8 MB)
2021-12-03 21:40:30,923 [driver-heartbeater] INFO [org.apache.spark.executor.Executor] - Told to re-register on heartbeat
2021-12-03 21:40:30,923 [driver-heartbeater] INFO [org.apache.spark.storage.BlockManager] - BlockManager BlockManagerId(driver, qb, 61634, None) re-registering with master
2021-12-03 21:40:30,923 [driver-heartbeater] INFO [org.apache.spark.storage.BlockManagerMaster] - Registering BlockManager BlockManagerId(driver, qb, 61634, None)
2021-12-03 21:40:30,923 [driver-heartbeater] INFO [org.apache.spark.storage.BlockManagerMaster] - Registered BlockManager BlockManagerId(driver, qb, 61634, None)
2021-12-03 21:40:30,923 [driver-heartbeater] INFO [org.apache.spark.storage.BlockManager] - Reporting 10 blocks to the master.
2021-12-03 21:40:30,923 [dispatcher-event-loop-0] INFO [org.apache.spark.storage.BlockManagerInfo] - Updated broadcast_3_piece0 in memory on qb:61634 (current size: 1906.0 B, original size: 1906.0 B, free: 1990.8 MB)
2021-12-03 21:40:30,923 [dispatcher-event-loop-2] INFO [org.apache.spark.storage.BlockManagerInfo] - Updated broadcast_4_piece0 in memory on qb:61634 (current size: 2.4 KB, original size: 2.4 KB, free: 1990.8 MB)
2021-12-03 21:40:30,923 [dispatcher-event-loop-7] INFO [org.apache.spark.storage.BlockManagerInfo] - Updated broadcast_0_piece0 in memory on qb:61634 (current size: 27.3 KB, original size: 27.3 KB, free: 1990.8 MB)
2021-12-03 21:40:30,924 [dispatcher-event-loop-10] INFO [org.apache.spark.storage.BlockManagerInfo] - Updated broadcast_2_piece0 in memory on qb:61634 (current size: 2.7 KB, original size: 2.7 KB, free: 1990.8 MB)
2021-12-03 21:40:30,924 [dispatcher-event-loop-3] INFO [org.apache.spark.storage.BlockManagerInfo] - Updated broadcast_8_piece0 in memory on qb:61634 (current size: 2022.0 B, original size: 2022.0 B, free: 1990.8 MB)
2021-12-03 21:40:30,924 [driver-heartbeater] INFO [org.apache.spark.executor.Executor] - Told to re-register on heartbeat
2021-12-03 21:40:30,924 [driver-heartbeater] INFO [org.apache.spark.storage.BlockManager] - BlockManager BlockManagerId(driver, qb, 61634, None) re-registering with master
2021-12-03 21:40:30,924 [driver-heartbeater] INFO [org.apache.spark.storage.BlockManagerMaster] - Registering BlockManager BlockManagerId(driver, qb, 61634, None)
2021-12-03 21:40:30,924 [driver-heartbeater] INFO [org.apache.spark.storage.BlockManagerMaster] - Registered BlockManager BlockManagerId(driver, qb, 61634, None)
2021-12-03 21:40:30,924 [driver-heartbeater] INFO [org.apache.spark.storage.BlockManager] - Reporting 10 blocks to the master.
2021-12-03 21:40:30,925 [dispatcher-event-loop-5] INFO [org.apache.spark.storage.BlockManagerInfo] - Updated broadcast_3_piece0 in memory on qb:61634 (current size: 1906.0 B, original size: 1906.0 B, free: 1990.8 MB)
2021-12-03 21:40:30,925 [dispatcher-event-loop-6] INFO [org.apache.spark.storage.BlockManagerInfo] - Updated broadcast_4_piece0 in memory on qb:61634 (current size: 2.4 KB, original size: 2.4 KB, free: 1990.8 MB)
2021-12-03 21:40:30,925 [dispatcher-event-loop-8] INFO [org.apache.spark.storage.BlockManagerInfo] - Updated broadcast_0_piece0 in memory on qb:61634 (current size: 27.3 KB, original size: 27.3 KB, free: 1990.8 MB)
2021-12-03 21:40:30,925 [dispatcher-event-loop-1] INFO [org.apache.spark.storage.BlockManagerInfo] - Updated broadcast_2_piece0 in memory on qb:61634 (current size: 2.7 KB, original size: 2.7 KB, free: 1990.8 MB)
2021-12-03 21:40:30,925 [dispatcher-event-loop-9] INFO [org.apache.spark.storage.BlockManagerInfo] - Updated broadcast_8_piece0 in memory on qb:61634 (current size: 2022.0 B, original size: 2022.0 B, free: 1990.8 MB)
2021-12-03 21:40:30,926 [driver-heartbeater] INFO [org.apache.spark.executor.Executor] - Told to re-register on heartbeat
2021-12-03 21:40:30,926 [driver-heartbeater] INFO [org.apache.spark.storage.BlockManager] - BlockManager BlockManagerId(driver, qb, 61634, None) re-registering with master
2021-12-03 21:40:30,926 [driver-heartbeater] INFO [org.apache.spark.storage.BlockManagerMaster] - Registering BlockManager BlockManagerId(driver, qb, 61634, None)
2021-12-03 21:40:30,926 [driver-heartbeater] INFO [org.apache.spark.storage.BlockManagerMaster] - Registered BlockManager BlockManagerId(driver, qb, 61634, None)
2021-12-03 21:40:30,926 [driver-heartbeater] INFO [org.apache.spark.storage.BlockManager] - Reporting 10 blocks to the master.
2021-12-03 21:40:30,926 [dispatcher-event-loop-7] INFO [org.apache.spark.storage.BlockManagerInfo] - Updated broadcast_3_piece0 in memory on qb:61634 (current size: 1906.0 B, original size: 1906.0 B, free: 1990.8 MB)
2021-12-03 21:40:30,926 [dispatcher-event-loop-10] INFO [org.apache.spark.storage.BlockManagerInfo] - Updated broadcast_4_piece0 in memory on qb:61634 (current size: 2.4 KB, original size: 2.4 KB, free: 1990.8 MB)
2021-12-03 21:40:30,926 [dispatcher-event-loop-3] INFO [org.apache.spark.storage.BlockManagerInfo] - Updated broadcast_0_piece0 in memory on qb:61634 (current size: 27.3 KB, original size: 27.3 KB, free: 1990.8 MB)
2021-12-03 21:40:30,927 [dispatcher-event-loop-11] INFO [org.apache.spark.storage.BlockManagerInfo] - Updated broadcast_2_piece0 in memory on qb:61634 (current size: 2.7 KB, original size: 2.7 KB, free: 1990.8 MB)
2021-12-03 21:40:30,927 [dispatcher-event-loop-4] INFO [org.apache.spark.storage.BlockManagerInfo] - Updated broadcast_8_piece0 in memory on qb:61634 (current size: 2022.0 B, original size: 2022.0 B, free: 1990.8 MB)
2021-12-03 21:40:30,927 [driver-heartbeater] INFO [org.apache.spark.executor.Executor] - Told to re-register on heartbeat
2021-12-03 21:40:30,927 [driver-heartbeater] INFO [org.apache.spark.storage.BlockManager] - BlockManager BlockManagerId(driver, qb, 61634, None) re-registering with master
2021-12-03 21:40:30,927 [driver-heartbeater] INFO [org.apache.spark.storage.BlockManagerMaster] - Registering BlockManager BlockManagerId(driver, qb, 61634, None)
2021-12-03 21:40:30,927 [driver-heartbeater] INFO [org.apache.spark.storage.BlockManagerMaster] - Registered BlockManager BlockManagerId(driver, qb, 61634, None)
2021-12-03 21:40:30,927 [driver-heartbeater] INFO [org.apache.spark.storage.BlockManager] - Reporting 10 blocks to the master.
2021-12-03 21:40:30,927 [dispatcher-event-loop-8] INFO [org.apache.spark.storage.BlockManagerInfo] - Updated broadcast_3_piece0 in memory on qb:61634 (current size: 1906.0 B, original size: 1906.0 B, free: 1990.8 MB)
2021-12-03 21:40:30,928 [dispatcher-event-loop-1] INFO [org.apache.spark.storage.BlockManagerInfo] - Updated broadcast_4_piece0 in memory on qb:61634 (current size: 2.4 KB, original size: 2.4 KB, free: 1990.8 MB)
2021-12-03 21:40:30,928 [dispatcher-event-loop-9] INFO [org.apache.spark.storage.BlockManagerInfo] - Updated broadcast_0_piece0 in memory on qb:61634 (current size: 27.3 KB, original size: 27.3 KB, free: 1990.8 MB)
2021-12-03 21:40:30,928 [dispatcher-event-loop-0] INFO [org.apache.spark.storage.BlockManagerInfo] - Updated broadcast_2_piece0 in memory on qb:61634 (current size: 2.7 KB, original size: 2.7 KB, free: 1990.8 MB)
2021-12-03 21:40:30,928 [dispatcher-event-loop-2] INFO [org.apache.spark.storage.BlockManagerInfo] - Updated broadcast_8_piece0 in memory on qb:61634 (current size: 2022.0 B, original size: 2022.0 B, free: 1990.8 MB)
2021-12-03 21:40:30,928 [driver-heartbeater] INFO [org.apache.spark.executor.Executor] - Told to re-register on heartbeat
2021-12-03 21:40:30,929 [driver-heartbeater] INFO [org.apache.spark.storage.BlockManager] - BlockManager BlockManagerId(driver, qb, 61634, None) re-registering with master
2021-12-03 21:40:30,929 [driver-heartbeater] INFO [org.apache.spark.storage.BlockManagerMaster] - Registering BlockManager BlockManagerId(driver, qb, 61634, None)
2021-12-03 21:40:30,929 [driver-heartbeater] INFO [org.apache.spark.storage.BlockManagerMaster] - Registered BlockManager BlockManagerId(driver, qb, 61634, None)
2021-12-03 21:40:30,929 [driver-heartbeater] INFO [org.apache.spark.storage.BlockManager] - Reporting 10 blocks to the master.
2021-12-03 21:40:30,929 [dispatcher-event-loop-3] INFO [org.apache.spark.storage.BlockManagerInfo] - Updated broadcast_3_piece0 in memory on qb:61634 (current size: 1906.0 B, original size: 1906.0 B, free: 1990.8 MB)
2021-12-03 21:40:30,929 [dispatcher-event-loop-11] INFO [org.apache.spark.storage.BlockManagerInfo] - Updated broadcast_4_piece0 in memory on qb:61634 (current size: 2.4 KB, original size: 2.4 KB, free: 1990.8 MB)
2021-12-03 21:40:30,929 [dispatcher-event-loop-4] INFO [org.apache.spark.storage.BlockManagerInfo] - Updated broadcast_0_piece0 in memory on qb:61634 (current size: 27.3 KB, original size: 27.3 KB, free: 1990.8 MB)
2021-12-03 21:40:30,929 [dispatcher-event-loop-5] INFO [org.apache.spark.storage.BlockManagerInfo] - Updated broadcast_2_piece0 in memory on qb:61634 (current size: 2.7 KB, original size: 2.7 KB, free: 1990.8 MB)
2021-12-03 21:40:30,930 [dispatcher-event-loop-6] INFO [org.apache.spark.storage.BlockManagerInfo] - Updated broadcast_8_piece0 in memory on qb:61634 (current size: 2022.0 B, original size: 2022.0 B, free: 1990.8 MB)
2021-12-03 21:40:30,930 [driver-heartbeater] INFO [org.apache.spark.executor.Executor] - Told to re-register on heartbeat
2021-12-03 21:40:30,930 [driver-heartbeater] INFO [org.apache.spark.storage.BlockManager] - BlockManager BlockManagerId(driver, qb, 61634, None) re-registering with master
2021-12-03 21:40:30,930 [driver-heartbeater] INFO [org.apache.spark.storage.BlockManagerMaster] - Registering BlockManager BlockManagerId(driver, qb, 61634, None)
2021-12-03 21:40:30,930 [driver-heartbeater] INFO [org.apache.spark.storage.BlockManagerMaster] - Registered BlockManager BlockManagerId(driver, qb, 61634, None)
2021-12-03 21:40:30,930 [driver-heartbeater] INFO [org.apache.spark.storage.BlockManager] - Reporting 10 blocks to the master.
2021-12-03 21:40:30,930 [dispatcher-event-loop-9] INFO [org.apache.spark.storage.BlockManagerInfo] - Updated broadcast_3_piece0 in memory on qb:61634 (current size: 1906.0 B, original size: 1906.0 B, free: 1990.8 MB)
2021-12-03 21:40:30,931 [dispatcher-event-loop-0] INFO [org.apache.spark.storage.BlockManagerInfo] - Updated broadcast_4_piece0 in memory on qb:61634 (current size: 2.4 KB, original size: 2.4 KB, free: 1990.8 MB)
2021-12-03 21:40:30,931 [dispatcher-event-loop-2] INFO [org.apache.spark.storage.BlockManagerInfo] - Updated broadcast_0_piece0 in memory on qb:61634 (current size: 27.3 KB, original size: 27.3 KB, free: 1990.8 MB)
2021-12-03 21:40:30,931 [dispatcher-event-loop-7] INFO [org.apache.spark.storage.BlockManagerInfo] - Updated broadcast_2_piece0 in memory on qb:61634 (current size: 2.7 KB, original size: 2.7 KB, free: 1990.8 MB)
2021-12-03 21:40:30,931 [dispatcher-event-loop-10] INFO [org.apache.spark.storage.BlockManagerInfo] - Updated broadcast_8_piece0 in memory on qb:61634 (current size: 2022.0 B, original size: 2022.0 B, free: 1990.8 MB)
2021-12-03 21:40:30,932 [driver-heartbeater] INFO [org.apache.spark.executor.Executor] - Told to re-register on heartbeat
2021-12-03 21:40:30,932 [driver-heartbeater] INFO [org.apache.spark.storage.BlockManager] - BlockManager BlockManagerId(driver, qb, 61634, None) re-registering with master
2021-12-03 21:40:30,932 [driver-heartbeater] INFO [org.apache.spark.storage.BlockManagerMaster] - Registering BlockManager BlockManagerId(driver, qb, 61634, None)
2021-12-03 21:40:30,932 [driver-heartbeater] INFO [org.apache.spark.storage.BlockManagerMaster] - Registered BlockManager BlockManagerId(driver, qb, 61634, None)
2021-12-03 21:40:30,932 [driver-heartbeater] INFO [org.apache.spark.storage.BlockManager] - Reporting 10 blocks to the master.
2021-12-03 21:40:30,932 [dispatcher-event-loop-4] INFO [org.apache.spark.storage.BlockManagerInfo] - Updated broadcast_3_piece0 in memory on qb:61634 (current size: 1906.0 B, original size: 1906.0 B, free: 1990.8 MB)
2021-12-03 21:40:30,932 [dispatcher-event-loop-5] INFO [org.apache.spark.storage.BlockManagerInfo] - Updated broadcast_4_piece0 in memory on qb:61634 (current size: 2.4 KB, original size: 2.4 KB, free: 1990.8 MB)
2021-12-03 21:40:30,932 [dispatcher-event-loop-6] INFO [org.apache.spark.storage.BlockManagerInfo] - Updated broadcast_0_piece0 in memory on qb:61634 (current size: 27.3 KB, original size: 27.3 KB, free: 1990.8 MB)
2021-12-03 21:40:30,933 [dispatcher-event-loop-8] INFO [org.apache.spark.storage.BlockManagerInfo] - Updated broadcast_2_piece0 in memory on qb:61634 (current size: 2.7 KB, original size: 2.7 KB, free: 1990.8 MB)
2021-12-03 21:40:30,933 [dispatcher-event-loop-1] INFO [org.apache.spark.storage.BlockManagerInfo] - Updated broadcast_8_piece0 in memory on qb:61634 (current size: 2022.0 B, original size: 2022.0 B, free: 1990.8 MB)
2021-12-03 21:40:30,933 [driver-heartbeater] INFO [org.apache.spark.executor.Executor] - Told to re-register on heartbeat
2021-12-03 21:40:30,933 [driver-heartbeater] INFO [org.apache.spark.storage.BlockManager] - BlockManager BlockManagerId(driver, qb, 61634, None) re-registering with master
2021-12-03 21:40:30,933 [driver-heartbeater] INFO [org.apache.spark.storage.BlockManagerMaster] - Registering BlockManager BlockManagerId(driver, qb, 61634, None)
2021-12-03 21:40:30,933 [driver-heartbeater] INFO [org.apache.spark.storage.BlockManagerMaster] - Registered BlockManager BlockManagerId(driver, qb, 61634, None)
2021-12-03 21:40:30,933 [driver-heartbeater] INFO [org.apache.spark.storage.BlockManager] - Reporting 10 blocks to the master.
2021-12-03 21:40:30,934 [dispatcher-event-loop-2] INFO [org.apache.spark.storage.BlockManagerInfo] - Updated broadcast_3_piece0 in memory on qb:61634 (current size: 1906.0 B, original size: 1906.0 B, free: 1990.8 MB)
2021-12-03 21:40:30,934 [dispatcher-event-loop-7] INFO [org.apache.spark.storage.BlockManagerInfo] - Updated broadcast_4_piece0 in memory on qb:61634 (current size: 2.4 KB, original size: 2.4 KB, free: 1990.8 MB)
2021-12-03 21:40:30,934 [dispatcher-event-loop-10] INFO [org.apache.spark.storage.BlockManagerInfo] - Updated broadcast_0_piece0 in memory on qb:61634 (current size: 27.3 KB, original size: 27.3 KB, free: 1990.8 MB)
2021-12-03 21:40:30,934 [dispatcher-event-loop-3] INFO [org.apache.spark.storage.BlockManagerInfo] - Updated broadcast_2_piece0 in memory on qb:61634 (current size: 2.7 KB, original size: 2.7 KB, free: 1990.8 MB)
2021-12-03 21:40:30,934 [dispatcher-event-loop-11] INFO [org.apache.spark.storage.BlockManagerInfo] - Updated broadcast_8_piece0 in memory on qb:61634 (current size: 2022.0 B, original size: 2022.0 B, free: 1990.8 MB)
2021-12-03 21:40:30,935 [driver-heartbeater] INFO [org.apache.spark.executor.Executor] - Told to re-register on heartbeat
2021-12-03 21:40:30,935 [driver-heartbeater] INFO [org.apache.spark.storage.BlockManager] - BlockManager BlockManagerId(driver, qb, 61634, None) re-registering with master
2021-12-03 21:40:30,935 [driver-heartbeater] INFO [org.apache.spark.storage.BlockManagerMaster] - Registering BlockManager BlockManagerId(driver, qb, 61634, None)
2021-12-03 21:40:30,935 [driver-heartbeater] INFO [org.apache.spark.storage.BlockManagerMaster] - Registered BlockManager BlockManagerId(driver, qb, 61634, None)
2021-12-03 21:40:30,935 [driver-heartbeater] INFO [org.apache.spark.storage.BlockManager] - Reporting 10 blocks to the master.
2021-12-03 21:40:30,935 [dispatcher-event-loop-6] INFO [org.apache.spark.storage.BlockManagerInfo] - Updated broadcast_3_piece0 in memory on qb:61634 (current size: 1906.0 B, original size: 1906.0 B, free: 1990.8 MB)
2021-12-03 21:40:30,935 [dispatcher-event-loop-8] INFO [org.apache.spark.storage.BlockManagerInfo] - Updated broadcast_4_piece0 in memory on qb:61634 (current size: 2.4 KB, original size: 2.4 KB, free: 1990.8 MB)
2021-12-03 21:40:30,935 [dispatcher-event-loop-1] INFO [org.apache.spark.storage.BlockManagerInfo] - Updated broadcast_0_piece0 in memory on qb:61634 (current size: 27.3 KB, original size: 27.3 KB, free: 1990.8 MB)
2021-12-03 21:40:30,936 [dispatcher-event-loop-9] INFO [org.apache.spark.storage.BlockManagerInfo] - Updated broadcast_2_piece0 in memory on qb:61634 (current size: 2.7 KB, original size: 2.7 KB, free: 1990.8 MB)
2021-12-03 21:40:30,936 [dispatcher-event-loop-0] INFO [org.apache.spark.storage.BlockManagerInfo] - Updated broadcast_8_piece0 in memory on qb:61634 (current size: 2022.0 B, original size: 2022.0 B, free: 1990.8 MB)
2021-12-03 21:40:30,936 [driver-heartbeater] INFO [org.apache.spark.executor.Executor] - Told to re-register on heartbeat
2021-12-03 21:40:30,936 [driver-heartbeater] INFO [org.apache.spark.storage.BlockManager] - BlockManager BlockManagerId(driver, qb, 61634, None) re-registering with master
2021-12-03 21:40:30,936 [driver-heartbeater] INFO [org.apache.spark.storage.BlockManagerMaster] - Registering BlockManager BlockManagerId(driver, qb, 61634, None)
2021-12-03 21:40:30,936 [driver-heartbeater] INFO [org.apache.spark.storage.BlockManagerMaster] - Registered BlockManager BlockManagerId(driver, qb, 61634, None)
2021-12-03 21:40:30,936 [driver-heartbeater] INFO [org.apache.spark.storage.BlockManager] - Reporting 10 blocks to the master.
2021-12-03 21:40:30,937 [dispatcher-event-loop-10] INFO [org.apache.spark.storage.BlockManagerInfo] - Updated broadcast_3_piece0 in memory on qb:61634 (current size: 1906.0 B, original size: 1906.0 B, free: 1990.8 MB)
2021-12-03 21:40:30,937 [dispatcher-event-loop-3] INFO [org.apache.spark.storage.BlockManagerInfo] - Updated broadcast_4_piece0 in memory on qb:61634 (current size: 2.4 KB, original size: 2.4 KB, free: 1990.8 MB)
2021-12-03 21:40:30,937 [dispatcher-event-loop-11] INFO [org.apache.spark.storage.BlockManagerInfo] - Updated broadcast_0_piece0 in memory on qb:61634 (current size: 27.3 KB, original size: 27.3 KB, free: 1990.8 MB)
2021-12-03 21:40:30,937 [dispatcher-event-loop-4] INFO [org.apache.spark.storage.BlockManagerInfo] - Updated broadcast_2_piece0 in memory on qb:61634 (current size: 2.7 KB, original size: 2.7 KB, free: 1990.8 MB)
2021-12-03 21:40:30,937 [dispatcher-event-loop-5] INFO [org.apache.spark.storage.BlockManagerInfo] - Updated broadcast_8_piece0 in memory on qb:61634 (current size: 2022.0 B, original size: 2022.0 B, free: 1990.8 MB)
2021-12-03 21:40:30,937 [driver-heartbeater] INFO [org.apache.spark.executor.Executor] - Told to re-register on heartbeat
2021-12-03 21:40:30,938 [driver-heartbeater] INFO [org.apache.spark.storage.BlockManager] - BlockManager BlockManagerId(driver, qb, 61634, None) re-registering with master
2021-12-03 21:40:30,938 [driver-heartbeater] INFO [org.apache.spark.storage.BlockManagerMaster] - Registering BlockManager BlockManagerId(driver, qb, 61634, None)
2021-12-03 21:40:30,938 [driver-heartbeater] INFO [org.apache.spark.storage.BlockManagerMaster] - Registered BlockManager BlockManagerId(driver, qb, 61634, None)
2021-12-03 21:40:30,938 [driver-heartbeater] INFO [org.apache.spark.storage.BlockManager] - Reporting 10 blocks to the master.
2021-12-03 21:40:30,938 [dispatcher-event-loop-1] INFO [org.apache.spark.storage.BlockManagerInfo] - Updated broadcast_3_piece0 in memory on qb:61634 (current size: 1906.0 B, original size: 1906.0 B, free: 1990.8 MB)
2021-12-03 21:40:30,938 [dispatcher-event-loop-9] INFO [org.apache.spark.storage.BlockManagerInfo] - Updated broadcast_4_piece0 in memory on qb:61634 (current size: 2.4 KB, original size: 2.4 KB, free: 1990.8 MB)
2021-12-03 21:40:30,938 [dispatcher-event-loop-0] INFO [org.apache.spark.storage.BlockManagerInfo] - Updated broadcast_0_piece0 in memory on qb:61634 (current size: 27.3 KB, original size: 27.3 KB, free: 1990.8 MB)
2021-12-03 21:40:30,938 [dispatcher-event-loop-2] INFO [org.apache.spark.storage.BlockManagerInfo] - Updated broadcast_2_piece0 in memory on qb:61634 (current size: 2.7 KB, original size: 2.7 KB, free: 1990.8 MB)
2021-12-03 21:40:30,939 [dispatcher-event-loop-7] INFO [org.apache.spark.storage.BlockManagerInfo] - Updated broadcast_8_piece0 in memory on qb:61634 (current size: 2022.0 B, original size: 2022.0 B, free: 1990.8 MB)
2021-12-03 21:40:30,939 [driver-heartbeater] INFO [org.apache.spark.executor.Executor] - Told to re-register on heartbeat
2021-12-03 21:40:30,939 [driver-heartbeater] INFO [org.apache.spark.storage.BlockManager] - BlockManager BlockManagerId(driver, qb, 61634, None) re-registering with master
2021-12-03 21:40:30,939 [driver-heartbeater] INFO [org.apache.spark.storage.BlockManagerMaster] - Registering BlockManager BlockManagerId(driver, qb, 61634, None)
2021-12-03 21:40:30,939 [driver-heartbeater] INFO [org.apache.spark.storage.BlockManagerMaster] - Registered BlockManager BlockManagerId(driver, qb, 61634, None)
2021-12-03 21:40:30,939 [driver-heartbeater] INFO [org.apache.spark.storage.BlockManager] - Reporting 10 blocks to the master.
2021-12-03 21:40:30,939 [dispatcher-event-loop-11] INFO [org.apache.spark.storage.BlockManagerInfo] - Updated broadcast_3_piece0 in memory on qb:61634 (current size: 1906.0 B, original size: 1906.0 B, free: 1990.8 MB)
2021-12-03 21:40:30,939 [dispatcher-event-loop-4] INFO [org.apache.spark.storage.BlockManagerInfo] - Updated broadcast_4_piece0 in memory on qb:61634 (current size: 2.4 KB, original size: 2.4 KB, free: 1990.8 MB)
2021-12-03 21:40:30,939 [dispatcher-event-loop-5] INFO [org.apache.spark.storage.BlockManagerInfo] - Updated broadcast_0_piece0 in memory on qb:61634 (current size: 27.3 KB, original size: 27.3 KB, free: 1990.8 MB)
2021-12-03 21:40:30,940 [dispatcher-event-loop-6] INFO [org.apache.spark.storage.BlockManagerInfo] - Updated broadcast_2_piece0 in memory on qb:61634 (current size: 2.7 KB, original size: 2.7 KB, free: 1990.8 MB)
2021-12-03 21:40:30,940 [dispatcher-event-loop-8] INFO [org.apache.spark.storage.BlockManagerInfo] - Updated broadcast_8_piece0 in memory on qb:61634 (current size: 2022.0 B, original size: 2022.0 B, free: 1990.8 MB)
2021-12-03 21:40:30,940 [driver-heartbeater] INFO [org.apache.spark.executor.Executor] - Told to re-register on heartbeat
2021-12-03 21:40:30,940 [driver-heartbeater] INFO [org.apache.spark.storage.BlockManager] - BlockManager BlockManagerId(driver, qb, 61634, None) re-registering with master
2021-12-03 21:40:30,940 [driver-heartbeater] INFO [org.apache.spark.storage.BlockManagerMaster] - Registering BlockManager BlockManagerId(driver, qb, 61634, None)
2021-12-03 21:40:30,940 [driver-heartbeater] INFO [org.apache.spark.storage.BlockManagerMaster] - Registered BlockManager BlockManagerId(driver, qb, 61634, None)
2021-12-03 21:40:30,940 [driver-heartbeater] INFO [org.apache.spark.storage.BlockManager] - Reporting 10 blocks to the master.
2021-12-03 21:40:30,940 [dispatcher-event-loop-0] INFO [org.apache.spark.storage.BlockManagerInfo] - Updated broadcast_3_piece0 in memory on qb:61634 (current size: 1906.0 B, original size: 1906.0 B, free: 1990.8 MB)
2021-12-03 21:40:30,941 [dispatcher-event-loop-2] INFO [org.apache.spark.storage.BlockManagerInfo] - Updated broadcast_4_piece0 in memory on qb:61634 (current size: 2.4 KB, original size: 2.4 KB, free: 1990.8 MB)
2021-12-03 21:40:30,941 [dispatcher-event-loop-7] INFO [org.apache.spark.storage.BlockManagerInfo] - Updated broadcast_0_piece0 in memory on qb:61634 (current size: 27.3 KB, original size: 27.3 KB, free: 1990.8 MB)
2021-12-03 21:40:30,941 [dispatcher-event-loop-10] INFO [org.apache.spark.storage.BlockManagerInfo] - Updated broadcast_2_piece0 in memory on qb:61634 (current size: 2.7 KB, original size: 2.7 KB, free: 1990.8 MB)
2021-12-03 21:40:30,941 [dispatcher-event-loop-3] INFO [org.apache.spark.storage.BlockManagerInfo] - Updated broadcast_8_piece0 in memory on qb:61634 (current size: 2022.0 B, original size: 2022.0 B, free: 1990.8 MB)
2021-12-03 21:40:30,941 [driver-heartbeater] INFO [org.apache.spark.executor.Executor] - Told to re-register on heartbeat
2021-12-03 21:40:30,941 [driver-heartbeater] INFO [org.apache.spark.storage.BlockManager] - BlockManager BlockManagerId(driver, qb, 61634, None) re-registering with master
2021-12-03 21:40:30,941 [driver-heartbeater] INFO [org.apache.spark.storage.BlockManagerMaster] - Registering BlockManager BlockManagerId(driver, qb, 61634, None)
2021-12-03 21:40:30,942 [driver-heartbeater] INFO [org.apache.spark.storage.BlockManagerMaster] - Registered BlockManager BlockManagerId(driver, qb, 61634, None)
2021-12-03 21:40:30,942 [driver-heartbeater] INFO [org.apache.spark.storage.BlockManager] - Reporting 10 blocks to the master.
2021-12-03 21:40:30,942 [dispatcher-event-loop-5] INFO [org.apache.spark.storage.BlockManagerInfo] - Updated broadcast_3_piece0 in memory on qb:61634 (current size: 1906.0 B, original size: 1906.0 B, free: 1990.8 MB)
2021-12-03 21:40:30,942 [dispatcher-event-loop-6] INFO [org.apache.spark.storage.BlockManagerInfo] - Updated broadcast_4_piece0 in memory on qb:61634 (current size: 2.4 KB, original size: 2.4 KB, free: 1990.8 MB)
2021-12-03 21:40:30,942 [dispatcher-event-loop-8] INFO [org.apache.spark.storage.BlockManagerInfo] - Updated broadcast_0_piece0 in memory on qb:61634 (current size: 27.3 KB, original size: 27.3 KB, free: 1990.8 MB)
2021-12-03 21:40:30,942 [dispatcher-event-loop-1] INFO [org.apache.spark.storage.BlockManagerInfo] - Updated broadcast_2_piece0 in memory on qb:61634 (current size: 2.7 KB, original size: 2.7 KB, free: 1990.8 MB)
2021-12-03 21:40:30,943 [dispatcher-event-loop-9] INFO [org.apache.spark.storage.BlockManagerInfo] - Updated broadcast_8_piece0 in memory on qb:61634 (current size: 2022.0 B, original size: 2022.0 B, free: 1990.8 MB)
2021-12-03 21:40:30,943 [driver-heartbeater] INFO [org.apache.spark.executor.Executor] - Told to re-register on heartbeat
2021-12-03 21:40:30,943 [driver-heartbeater] INFO [org.apache.spark.storage.BlockManager] - BlockManager BlockManagerId(driver, qb, 61634, None) re-registering with master
2021-12-03 21:40:30,943 [driver-heartbeater] INFO [org.apache.spark.storage.BlockManagerMaster] - Registering BlockManager BlockManagerId(driver, qb, 61634, None)
2021-12-03 21:40:30,943 [driver-heartbeater] INFO [org.apache.spark.storage.BlockManagerMaster] - Registered BlockManager BlockManagerId(driver, qb, 61634, None)
2021-12-03 21:40:30,943 [driver-heartbeater] INFO [org.apache.spark.storage.BlockManager] - Reporting 10 blocks to the master.
2021-12-03 21:40:30,943 [dispatcher-event-loop-7] INFO [org.apache.spark.storage.BlockManagerInfo] - Updated broadcast_3_piece0 in memory on qb:61634 (current size: 1906.0 B, original size: 1906.0 B, free: 1990.8 MB)
2021-12-03 21:40:30,943 [dispatcher-event-loop-10] INFO [org.apache.spark.storage.BlockManagerInfo] - Updated broadcast_4_piece0 in memory on qb:61634 (current size: 2.4 KB, original size: 2.4 KB, free: 1990.8 MB)
2021-12-03 21:40:30,944 [dispatcher-event-loop-3] INFO [org.apache.spark.storage.BlockManagerInfo] - Updated broadcast_0_piece0 in memory on qb:61634 (current size: 27.3 KB, original size: 27.3 KB, free: 1990.8 MB)
2021-12-03 21:40:30,944 [dispatcher-event-loop-11] INFO [org.apache.spark.storage.BlockManagerInfo] - Updated broadcast_2_piece0 in memory on qb:61634 (current size: 2.7 KB, original size: 2.7 KB, free: 1990.8 MB)
2021-12-03 21:40:30,944 [dispatcher-event-loop-4] INFO [org.apache.spark.storage.BlockManagerInfo] - Updated broadcast_8_piece0 in memory on qb:61634 (current size: 2022.0 B, original size: 2022.0 B, free: 1990.8 MB)
2021-12-03 21:40:30,944 [driver-heartbeater] INFO [org.apache.spark.executor.Executor] - Told to re-register on heartbeat
2021-12-03 21:40:30,944 [driver-heartbeater] INFO [org.apache.spark.storage.BlockManager] - BlockManager BlockManagerId(driver, qb, 61634, None) re-registering with master
2021-12-03 21:40:30,944 [driver-heartbeater] INFO [org.apache.spark.storage.BlockManagerMaster] - Registering BlockManager BlockManagerId(driver, qb, 61634, None)
2021-12-03 21:40:30,945 [driver-heartbeater] INFO [org.apache.spark.storage.BlockManagerMaster] - Registered BlockManager BlockManagerId(driver, qb, 61634, None)
2021-12-03 21:40:30,945 [driver-heartbeater] INFO [org.apache.spark.storage.BlockManager] - Reporting 10 blocks to the master.
2021-12-03 21:40:30,945 [dispatcher-event-loop-8] INFO [org.apache.spark.storage.BlockManagerInfo] - Updated broadcast_3_piece0 in memory on qb:61634 (current size: 1906.0 B, original size: 1906.0 B, free: 1990.8 MB)
2021-12-03 21:40:30,945 [dispatcher-event-loop-1] INFO [org.apache.spark.storage.BlockManagerInfo] - Updated broadcast_4_piece0 in memory on qb:61634 (current size: 2.4 KB, original size: 2.4 KB, free: 1990.8 MB)
2021-12-03 21:40:30,945 [dispatcher-event-loop-9] INFO [org.apache.spark.storage.BlockManagerInfo] - Updated broadcast_0_piece0 in memory on qb:61634 (current size: 27.3 KB, original size: 27.3 KB, free: 1990.8 MB)
2021-12-03 21:40:30,946 [dispatcher-event-loop-0] INFO [org.apache.spark.storage.BlockManagerInfo] - Updated broadcast_2_piece0 in memory on qb:61634 (current size: 2.7 KB, original size: 2.7 KB, free: 1990.8 MB)
2021-12-03 21:40:30,946 [dispatcher-event-loop-2] INFO [org.apache.spark.storage.BlockManagerInfo] - Updated broadcast_8_piece0 in memory on qb:61634 (current size: 2022.0 B, original size: 2022.0 B, free: 1990.8 MB)
2021-12-03 21:40:30,946 [driver-heartbeater] INFO [org.apache.spark.executor.Executor] - Told to re-register on heartbeat
2021-12-03 21:40:30,946 [driver-heartbeater] INFO [org.apache.spark.storage.BlockManager] - BlockManager BlockManagerId(driver, qb, 61634, None) re-registering with master
2021-12-03 21:40:30,946 [driver-heartbeater] INFO [org.apache.spark.storage.BlockManagerMaster] - Registering BlockManager BlockManagerId(driver, qb, 61634, None)
2021-12-03 21:40:30,946 [driver-heartbeater] INFO [org.apache.spark.storage.BlockManagerMaster] - Registered BlockManager BlockManagerId(driver, qb, 61634, None)
2021-12-03 21:40:30,946 [driver-heartbeater] INFO [org.apache.spark.storage.BlockManager] - Reporting 10 blocks to the master.
2021-12-03 21:40:30,947 [dispatcher-event-loop-3] INFO [org.apache.spark.storage.BlockManagerInfo] - Updated broadcast_3_piece0 in memory on qb:61634 (current size: 1906.0 B, original size: 1906.0 B, free: 1990.8 MB)
2021-12-03 21:40:30,947 [dispatcher-event-loop-11] INFO [org.apache.spark.storage.BlockManagerInfo] - Updated broadcast_4_piece0 in memory on qb:61634 (current size: 2.4 KB, original size: 2.4 KB, free: 1990.8 MB)
2021-12-03 21:40:30,947 [dispatcher-event-loop-4] INFO [org.apache.spark.storage.BlockManagerInfo] - Updated broadcast_0_piece0 in memory on qb:61634 (current size: 27.3 KB, original size: 27.3 KB, free: 1990.8 MB)
2021-12-03 21:40:30,947 [dispatcher-event-loop-5] INFO [org.apache.spark.storage.BlockManagerInfo] - Updated broadcast_2_piece0 in memory on qb:61634 (current size: 2.7 KB, original size: 2.7 KB, free: 1990.8 MB)
2021-12-03 21:40:30,948 [dispatcher-event-loop-6] INFO [org.apache.spark.storage.BlockManagerInfo] - Updated broadcast_8_piece0 in memory on qb:61634 (current size: 2022.0 B, original size: 2022.0 B, free: 1990.8 MB)
2021-12-03 21:40:30,948 [driver-heartbeater] INFO [org.apache.spark.executor.Executor] - Told to re-register on heartbeat
2021-12-03 21:40:30,948 [driver-heartbeater] INFO [org.apache.spark.storage.BlockManager] - BlockManager BlockManagerId(driver, qb, 61634, None) re-registering with master
2021-12-03 21:40:30,948 [driver-heartbeater] INFO [org.apache.spark.storage.BlockManagerMaster] - Registering BlockManager BlockManagerId(driver, qb, 61634, None)
2021-12-03 21:40:30,948 [driver-heartbeater] INFO [org.apache.spark.storage.BlockManagerMaster] - Registered BlockManager BlockManagerId(driver, qb, 61634, None)
2021-12-03 21:40:30,948 [driver-heartbeater] INFO [org.apache.spark.storage.BlockManager] - Reporting 10 blocks to the master.
2021-12-03 21:40:30,949 [dispatcher-event-loop-9] INFO [org.apache.spark.storage.BlockManagerInfo] - Updated broadcast_3_piece0 in memory on qb:61634 (current size: 1906.0 B, original size: 1906.0 B, free: 1990.8 MB)
2021-12-03 21:40:30,949 [dispatcher-event-loop-0] INFO [org.apache.spark.storage.BlockManagerInfo] - Updated broadcast_4_piece0 in memory on qb:61634 (current size: 2.4 KB, original size: 2.4 KB, free: 1990.8 MB)
2021-12-03 21:40:30,949 [dispatcher-event-loop-2] INFO [org.apache.spark.storage.BlockManagerInfo] - Updated broadcast_0_piece0 in memory on qb:61634 (current size: 27.3 KB, original size: 27.3 KB, free: 1990.8 MB)
2021-12-03 21:40:30,949 [dispatcher-event-loop-7] INFO [org.apache.spark.storage.BlockManagerInfo] - Updated broadcast_2_piece0 in memory on qb:61634 (current size: 2.7 KB, original size: 2.7 KB, free: 1990.8 MB)
2021-12-03 21:40:30,950 [dispatcher-event-loop-10] INFO [org.apache.spark.storage.BlockManagerInfo] - Updated broadcast_8_piece0 in memory on qb:61634 (current size: 2022.0 B, original size: 2022.0 B, free: 1990.8 MB)
2021-12-03 21:40:30,986 [main] INFO [org.apache.spark.SparkContext] - Starting job: runJob at SparkHadoopWriter.scala:78
2021-12-03 21:40:30,987 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 6 (runJob at SparkHadoopWriter.scala:78) with 1 output partitions
2021-12-03 21:40:30,987 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 12 (runJob at SparkHadoopWriter.scala:78)
2021-12-03 21:40:30,987 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List()
2021-12-03 21:40:30,987 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2021-12-03 21:40:30,987 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 12 (MapPartitionsRDD[14] at saveAsTextFile at PaidPromotionAdjustParameter.scala:87), which has no missing parents
2021-12-03 21:40:30,996 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_9 stored as values in memory (estimated size 79.9 KB, free 1990.4 MB)
2021-12-03 21:40:30,998 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_9_piece0 stored as bytes in memory (estimated size 30.5 KB, free 1990.3 MB)
2021-12-03 21:40:30,999 [dispatcher-event-loop-3] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_9_piece0 in memory on qb:61634 (size: 30.5 KB, free: 1990.7 MB)
2021-12-03 21:40:30,999 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 9 from broadcast at DAGScheduler.scala:1039
2021-12-03 21:40:31,000 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 12 (MapPartitionsRDD[14] at saveAsTextFile at PaidPromotionAdjustParameter.scala:87) (first 15 tasks are for partitions Vector(0))
2021-12-03 21:40:31,000 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 12.0 with 1 tasks
2021-12-03 21:40:31,007 [dispatcher-event-loop-11] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 12.0 (TID 175, localhost, executor driver, partition 0, ANY, 11703 bytes)
2021-12-03 21:40:31,008 [Executor task launch worker for task 175] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 12.0 (TID 175)
2021-12-03 21:40:31,027 [Executor task launch worker for task 175] INFO [org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter] - File Output Committer Algorithm version is 1
2021-12-03 21:40:31,052 [Executor task launch worker for task 175] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:0+134217728
2021-12-03 21:40:31,903 [Thread-1] INFO [org.apache.spark.SparkContext] - Invoking stop() from shutdown hook
2021-12-03 21:40:31,908 [Thread-1] INFO [org.spark_project.jetty.server.AbstractConnector] - Stopped Spark@3414a8c3{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2021-12-03 21:40:31,910 [Thread-1] INFO [org.apache.spark.ui.SparkUI] - Stopped Spark web UI at http://qb:4040
2021-12-03 21:40:31,915 [main] INFO [org.apache.spark.scheduler.DAGScheduler] - Job 6 failed: runJob at SparkHadoopWriter.scala:78, took 0.928558 s
2021-12-03 21:40:31,915 [Thread-1] INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 12 (runJob at SparkHadoopWriter.scala:78) failed in 0.928 s due to Stage cancelled because SparkContext was shut down
2021-12-03 21:40:31,916 [main] ERROR [org.apache.spark.internal.io.SparkHadoopWriter] - Aborting job job_20211203214030_0014.
org.apache.spark.SparkException: Job 6 cancelled because SparkContext was shut down
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$cleanUpAfterSchedulerStop$1.apply(DAGScheduler.scala:837)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$cleanUpAfterSchedulerStop$1.apply(DAGScheduler.scala:835)
	at scala.collection.mutable.HashSet.foreach(HashSet.scala:78)
	at org.apache.spark.scheduler.DAGScheduler.cleanUpAfterSchedulerStop(DAGScheduler.scala:835)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onStop(DAGScheduler.scala:1838)
	at org.apache.spark.util.EventLoop.stop(EventLoop.scala:83)
	at org.apache.spark.scheduler.DAGScheduler.stop(DAGScheduler.scala:1751)
	at org.apache.spark.SparkContext$$anonfun$stop$8.apply$mcV$sp(SparkContext.scala:1924)
	at org.apache.spark.util.Utils$.tryLogNonFatalError(Utils.scala:1357)
	at org.apache.spark.SparkContext.stop(SparkContext.scala:1923)
	at org.apache.spark.SparkContext$$anonfun$2.apply$mcV$sp(SparkContext.scala:572)
	at org.apache.spark.util.SparkShutdownHook.run(ShutdownHookManager.scala:216)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply$mcV$sp(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1988)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply$mcV$sp(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply(ShutdownHookManager.scala:188)
	at scala.util.Try$.apply(Try.scala:192)
	at org.apache.spark.util.SparkShutdownHookManager.runAll(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anon$2.run(ShutdownHookManager.scala:178)
	at org.apache.hadoop.util.ShutdownHookManager$1.run(ShutdownHookManager.java:54)
	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:642)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2027)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2048)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2080)
	at org.apache.spark.internal.io.SparkHadoopWriter$.write(SparkHadoopWriter.scala:78)
	at org.apache.spark.rdd.PairRDDFunctions$$anonfun$saveAsHadoopDataset$1.apply$mcV$sp(PairRDDFunctions.scala:1096)
	at org.apache.spark.rdd.PairRDDFunctions$$anonfun$saveAsHadoopDataset$1.apply(PairRDDFunctions.scala:1094)
	at org.apache.spark.rdd.PairRDDFunctions$$anonfun$saveAsHadoopDataset$1.apply(PairRDDFunctions.scala:1094)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)
	at org.apache.spark.rdd.RDD.withScope(RDD.scala:363)
	at org.apache.spark.rdd.PairRDDFunctions.saveAsHadoopDataset(PairRDDFunctions.scala:1094)
	at org.apache.spark.rdd.PairRDDFunctions$$anonfun$saveAsHadoopFile$4.apply$mcV$sp(PairRDDFunctions.scala:1067)
	at org.apache.spark.rdd.PairRDDFunctions$$anonfun$saveAsHadoopFile$4.apply(PairRDDFunctions.scala:1032)
	at org.apache.spark.rdd.PairRDDFunctions$$anonfun$saveAsHadoopFile$4.apply(PairRDDFunctions.scala:1032)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)
	at org.apache.spark.rdd.RDD.withScope(RDD.scala:363)
	at org.apache.spark.rdd.PairRDDFunctions.saveAsHadoopFile(PairRDDFunctions.scala:1032)
	at org.apache.spark.rdd.PairRDDFunctions$$anonfun$saveAsHadoopFile$1.apply$mcV$sp(PairRDDFunctions.scala:958)
	at org.apache.spark.rdd.PairRDDFunctions$$anonfun$saveAsHadoopFile$1.apply(PairRDDFunctions.scala:958)
	at org.apache.spark.rdd.PairRDDFunctions$$anonfun$saveAsHadoopFile$1.apply(PairRDDFunctions.scala:958)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)
	at org.apache.spark.rdd.RDD.withScope(RDD.scala:363)
	at org.apache.spark.rdd.PairRDDFunctions.saveAsHadoopFile(PairRDDFunctions.scala:957)
	at org.apache.spark.rdd.RDD$$anonfun$saveAsTextFile$1.apply$mcV$sp(RDD.scala:1493)
	at org.apache.spark.rdd.RDD$$anonfun$saveAsTextFile$1.apply(RDD.scala:1472)
	at org.apache.spark.rdd.RDD$$anonfun$saveAsTextFile$1.apply(RDD.scala:1472)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)
	at org.apache.spark.rdd.RDD.withScope(RDD.scala:363)
	at org.apache.spark.rdd.RDD.saveAsTextFile(RDD.scala:1472)
	at PaidPromotionAdjustParameter$.handleVideoData(PaidPromotionAdjustParameter.scala:87)
	at PaidPromotionAdjustParameter$.main(PaidPromotionAdjustParameter.scala:40)
	at PaidPromotionAdjustParameter.main(PaidPromotionAdjustParameter.scala)
2021-12-03 21:40:31,921 [dispatcher-event-loop-8] INFO [org.apache.spark.MapOutputTrackerMasterEndpoint] - MapOutputTrackerMasterEndpoint stopped!
2021-12-03 21:40:32,002 [Thread-1] INFO [org.apache.spark.storage.memory.MemoryStore] - MemoryStore cleared
2021-12-03 21:40:32,003 [Thread-1] INFO [org.apache.spark.storage.BlockManager] - BlockManager stopped
2021-12-03 21:40:32,003 [Thread-1] INFO [org.apache.spark.storage.BlockManagerMaster] - BlockManagerMaster stopped
2021-12-03 21:40:32,005 [dispatcher-event-loop-7] INFO [org.apache.spark.scheduler.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint] - OutputCommitCoordinator stopped!
2021-12-03 21:40:32,008 [Thread-1] INFO [org.apache.spark.SparkContext] - Successfully stopped SparkContext
2021-12-03 21:40:32,008 [Thread-1] INFO [org.apache.spark.util.ShutdownHookManager] - Shutdown hook called
2021-12-03 21:40:32,009 [Thread-1] INFO [org.apache.spark.util.ShutdownHookManager] - Deleting directory C:\Users\ACER\AppData\Local\Temp\spark-a0be8923-dfa1-446e-b670-fd3b7953e974
2021-12-03 21:40:50,138 [ResponseProcessor for block BP-1090623929-172.16.1.222-1605776978734:blk_1074049154_309056] WARN [org.apache.hadoop.hdfs.DFSClient] - DFSOutputStream ResponseProcessor exception  for block BP-1090623929-172.16.1.222-1605776978734:blk_1074049154_309056
java.io.IOException: 你的主机中的软件中止了一个已建立的连接。
	at sun.nio.ch.SocketDispatcher.read0(Native Method)
	at sun.nio.ch.SocketDispatcher.read(SocketDispatcher.java:43)
	at sun.nio.ch.IOUtil.readIntoNativeBuffer(IOUtil.java:223)
	at sun.nio.ch.IOUtil.read(IOUtil.java:197)
	at sun.nio.ch.SocketChannelImpl.read(SocketChannelImpl.java:380)
	at org.apache.hadoop.net.SocketInputStream$Reader.performIO(SocketInputStream.java:57)
	at org.apache.hadoop.net.SocketIOWithTimeout.doIO(SocketIOWithTimeout.java:142)
	at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:161)
	at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:131)
	at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:118)
	at java.io.FilterInputStream.read(FilterInputStream.java:83)
	at java.io.FilterInputStream.read(FilterInputStream.java:83)
	at org.apache.hadoop.hdfs.protocolPB.PBHelper.vintPrefixed(PBHelper.java:2280)
	at org.apache.hadoop.hdfs.protocol.datatransfer.PipelineAck.readFields(PipelineAck.java:244)
	at org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer$ResponseProcessor.run(DFSOutputStream.java:733)
2021-12-03 21:40:50,138 [DataStreamer for file /sk/chongqing/sample_data/filter-sample-device-video-data.bcp/_temporary/0/_temporary/attempt_20211203214030_0014_m_000000_0/part-00000 block BP-1090623929-172.16.1.222-1605776978734:blk_1074049154_309056] WARN [org.apache.hadoop.hdfs.DFSClient] - DataStreamer Exception
java.io.IOException: 你的主机中的软件中止了一个已建立的连接。
	at sun.nio.ch.SocketDispatcher.write0(Native Method)
	at sun.nio.ch.SocketDispatcher.write(SocketDispatcher.java:51)
	at sun.nio.ch.IOUtil.writeFromNativeBuffer(IOUtil.java:93)
	at sun.nio.ch.IOUtil.write(IOUtil.java:65)
	at sun.nio.ch.SocketChannelImpl.write(SocketChannelImpl.java:471)
	at org.apache.hadoop.net.SocketOutputStream$Writer.performIO(SocketOutputStream.java:63)
	at org.apache.hadoop.net.SocketIOWithTimeout.doIO(SocketIOWithTimeout.java:142)
	at org.apache.hadoop.net.SocketOutputStream.write(SocketOutputStream.java:159)
	at org.apache.hadoop.net.SocketOutputStream.write(SocketOutputStream.java:117)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.hdfs.DFSPacket.writeTo(DFSPacket.java:176)
	at org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.run(DFSOutputStream.java:507)
2021-12-03 21:40:50,139 [DataStreamer for file /sk/chongqing/sample_data/filter-sample-device-video-data.bcp/_temporary/0/_temporary/attempt_20211203214030_0014_m_000000_0/part-00000 block BP-1090623929-172.16.1.222-1605776978734:blk_1074049154_309056] WARN [org.apache.hadoop.hdfs.DFSClient] - Error Recovery for block BP-1090623929-172.16.1.222-1605776978734:blk_1074049154_309056 in pipeline DatanodeInfoWithStorage[192.168.1.33:50010,DS-bb6416c8-94bb-4d0d-9363-04fd80832ae1,DISK], DatanodeInfoWithStorage[192.168.1.34:50010,DS-10101268-726d-4b76-ac53-35b16d66b0f6,DISK], DatanodeInfoWithStorage[172.16.1.220:50010,DS-aa570649-442f-453e-80e8-57a042e5dfcb,DISK]: bad datanode DatanodeInfoWithStorage[192.168.1.33:50010,DS-bb6416c8-94bb-4d0d-9363-04fd80832ae1,DISK]
2021-12-03 21:40:50,871 [DataStreamer for file /sk/chongqing/sample_data/filter-sample-device-video-data.bcp/_temporary/0/_temporary/attempt_20211203214030_0014_m_000000_0/part-00000 block BP-1090623929-172.16.1.222-1605776978734:blk_1074049154_309056] WARN [org.apache.hadoop.hdfs.DFSClient] - DataStreamer Exception
java.io.IOException: Failed on local exception: java.io.IOException: 你的主机中的软件中止了一个已建立的连接。; Host Details : local host is: "qb/192.168.2.180"; destination host is: "hdp1":8020; 
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:776)
	at org.apache.hadoop.ipc.Client.call(Client.java:1479)
	at org.apache.hadoop.ipc.Client.call(Client.java:1412)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:229)
	at com.sun.proxy.$Proxy24.updateBlockForPipeline(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.updateBlockForPipeline(ClientNamenodeProtocolTranslatorPB.java:902)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:191)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy25.updateBlockForPipeline(Unknown Source)
	at org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.setupPipelineForAppendOrRecovery(DFSOutputStream.java:1169)
	at org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.processDatanodeError(DFSOutputStream.java:871)
	at org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.run(DFSOutputStream.java:401)
Caused by: java.io.IOException: 你的主机中的软件中止了一个已建立的连接。
	at sun.nio.ch.SocketDispatcher.read0(Native Method)
	at sun.nio.ch.SocketDispatcher.read(SocketDispatcher.java:43)
	at sun.nio.ch.IOUtil.readIntoNativeBuffer(IOUtil.java:223)
	at sun.nio.ch.IOUtil.read(IOUtil.java:197)
	at sun.nio.ch.SocketChannelImpl.read(SocketChannelImpl.java:380)
	at org.apache.hadoop.net.SocketInputStream$Reader.performIO(SocketInputStream.java:57)
	at org.apache.hadoop.net.SocketIOWithTimeout.doIO(SocketIOWithTimeout.java:142)
	at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:161)
	at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:131)
	at java.io.FilterInputStream.read(FilterInputStream.java:133)
	at java.io.FilterInputStream.read(FilterInputStream.java:133)
	at org.apache.hadoop.ipc.Client$Connection$PingInputStream.read(Client.java:520)
	at java.io.BufferedInputStream.fill(BufferedInputStream.java:246)
	at java.io.BufferedInputStream.read(BufferedInputStream.java:265)
	at java.io.DataInputStream.readInt(DataInputStream.java:387)
	at org.apache.hadoop.ipc.Client$Connection.receiveRpcResponse(Client.java:1084)
	at org.apache.hadoop.ipc.Client$Connection.run(Client.java:979)
2021-12-03 21:40:50,873 [Thread-1] ERROR [org.apache.hadoop.hdfs.DFSClient] - Failed to close inode 4426304
java.io.IOException: Failed on local exception: java.io.IOException: 你的主机中的软件中止了一个已建立的连接。; Host Details : local host is: "qb/192.168.2.180"; destination host is: "hdp1":8020; 
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:776)
	at org.apache.hadoop.ipc.Client.call(Client.java:1479)
	at org.apache.hadoop.ipc.Client.call(Client.java:1412)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:229)
	at com.sun.proxy.$Proxy24.updateBlockForPipeline(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.updateBlockForPipeline(ClientNamenodeProtocolTranslatorPB.java:902)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:191)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy25.updateBlockForPipeline(Unknown Source)
	at org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.setupPipelineForAppendOrRecovery(DFSOutputStream.java:1169)
	at org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.processDatanodeError(DFSOutputStream.java:871)
	at org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.run(DFSOutputStream.java:401)
Caused by: java.io.IOException: 你的主机中的软件中止了一个已建立的连接。
	at sun.nio.ch.SocketDispatcher.read0(Native Method)
	at sun.nio.ch.SocketDispatcher.read(SocketDispatcher.java:43)
	at sun.nio.ch.IOUtil.readIntoNativeBuffer(IOUtil.java:223)
	at sun.nio.ch.IOUtil.read(IOUtil.java:197)
	at sun.nio.ch.SocketChannelImpl.read(SocketChannelImpl.java:380)
	at org.apache.hadoop.net.SocketInputStream$Reader.performIO(SocketInputStream.java:57)
	at org.apache.hadoop.net.SocketIOWithTimeout.doIO(SocketIOWithTimeout.java:142)
	at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:161)
	at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:131)
	at java.io.FilterInputStream.read(FilterInputStream.java:133)
	at java.io.FilterInputStream.read(FilterInputStream.java:133)
	at org.apache.hadoop.ipc.Client$Connection$PingInputStream.read(Client.java:520)
	at java.io.BufferedInputStream.fill(BufferedInputStream.java:246)
	at java.io.BufferedInputStream.read(BufferedInputStream.java:265)
	at java.io.DataInputStream.readInt(DataInputStream.java:387)
	at org.apache.hadoop.ipc.Client$Connection.receiveRpcResponse(Client.java:1084)
	at org.apache.hadoop.ipc.Client$Connection.run(Client.java:979)
2021-12-03 21:41:01,679 [main] INFO [org.apache.spark.SparkContext] - Running Spark version 2.3.0
2021-12-03 21:41:01,993 [main] INFO [org.apache.spark.SparkContext] - Submitted application: PaidPromotion
2021-12-03 21:41:02,054 [main] INFO [org.apache.spark.SecurityManager] - Changing view acls to: ACER,root
2021-12-03 21:41:02,054 [main] INFO [org.apache.spark.SecurityManager] - Changing modify acls to: ACER,root
2021-12-03 21:41:02,055 [main] INFO [org.apache.spark.SecurityManager] - Changing view acls groups to: 
2021-12-03 21:41:02,055 [main] INFO [org.apache.spark.SecurityManager] - Changing modify acls groups to: 
2021-12-03 21:41:02,056 [main] INFO [org.apache.spark.SecurityManager] - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(ACER, root); groups with view permissions: Set(); users  with modify permissions: Set(ACER, root); groups with modify permissions: Set()
2021-12-03 21:41:02,707 [main] INFO [org.apache.spark.util.Utils] - Successfully started service 'sparkDriver' on port 60034.
2021-12-03 21:41:02,728 [main] INFO [org.apache.spark.SparkEnv] - Registering MapOutputTracker
2021-12-03 21:41:02,747 [main] INFO [org.apache.spark.SparkEnv] - Registering BlockManagerMaster
2021-12-03 21:41:02,750 [main] INFO [org.apache.spark.storage.BlockManagerMasterEndpoint] - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2021-12-03 21:41:02,750 [main] INFO [org.apache.spark.storage.BlockManagerMasterEndpoint] - BlockManagerMasterEndpoint up
2021-12-03 21:41:02,758 [main] INFO [org.apache.spark.storage.DiskBlockManager] - Created local directory at C:\Users\ACER\AppData\Local\Temp\blockmgr-4337818b-5092-440e-81d5-fd308d5cbc52
2021-12-03 21:41:02,774 [main] INFO [org.apache.spark.storage.memory.MemoryStore] - MemoryStore started with capacity 1990.8 MB
2021-12-03 21:41:02,784 [main] INFO [org.apache.spark.SparkEnv] - Registering OutputCommitCoordinator
2021-12-03 21:41:02,840 [main] INFO [org.spark_project.jetty.util.log] - Logging initialized @3529ms
2021-12-03 21:41:02,892 [main] INFO [org.spark_project.jetty.server.Server] - jetty-9.3.z-SNAPSHOT
2021-12-03 21:41:02,904 [main] INFO [org.spark_project.jetty.server.Server] - Started @3593ms
2021-12-03 21:41:02,931 [main] INFO [org.spark_project.jetty.server.AbstractConnector] - Started ServerConnector@3414a8c3{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2021-12-03 21:41:02,931 [main] INFO [org.apache.spark.util.Utils] - Successfully started service 'SparkUI' on port 4040.
2021-12-03 21:41:02,954 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@27b45ea{/jobs,null,AVAILABLE,@Spark}
2021-12-03 21:41:02,955 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@4fc142ec{/jobs/json,null,AVAILABLE,@Spark}
2021-12-03 21:41:02,956 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@702b06fb{/jobs/job,null,AVAILABLE,@Spark}
2021-12-03 21:41:02,957 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@2b22a1cc{/jobs/job/json,null,AVAILABLE,@Spark}
2021-12-03 21:41:02,958 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@7fd8c559{/stages,null,AVAILABLE,@Spark}
2021-12-03 21:41:02,959 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@55a88417{/stages/json,null,AVAILABLE,@Spark}
2021-12-03 21:41:02,960 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@19962194{/stages/stage,null,AVAILABLE,@Spark}
2021-12-03 21:41:02,961 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@3cbf1ba4{/stages/stage/json,null,AVAILABLE,@Spark}
2021-12-03 21:41:02,962 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@3dd818e8{/stages/pool,null,AVAILABLE,@Spark}
2021-12-03 21:41:02,963 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@47b67fcb{/stages/pool/json,null,AVAILABLE,@Spark}
2021-12-03 21:41:02,964 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@66420549{/storage,null,AVAILABLE,@Spark}
2021-12-03 21:41:02,965 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@42b28ff1{/storage/json,null,AVAILABLE,@Spark}
2021-12-03 21:41:02,966 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@706fe5c6{/storage/rdd,null,AVAILABLE,@Spark}
2021-12-03 21:41:02,967 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@6b3f6585{/storage/rdd/json,null,AVAILABLE,@Spark}
2021-12-03 21:41:02,969 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@64469d8{/environment,null,AVAILABLE,@Spark}
2021-12-03 21:41:02,970 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@1cec219f{/environment/json,null,AVAILABLE,@Spark}
2021-12-03 21:41:02,971 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@3cb8c8ce{/executors,null,AVAILABLE,@Spark}
2021-12-03 21:41:02,973 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@260a3a5e{/executors/json,null,AVAILABLE,@Spark}
2021-12-03 21:41:02,974 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@2e51d054{/executors/threadDump,null,AVAILABLE,@Spark}
2021-12-03 21:41:02,975 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@608bc8f8{/executors/threadDump/json,null,AVAILABLE,@Spark}
2021-12-03 21:41:02,984 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@381d7219{/static,null,AVAILABLE,@Spark}
2021-12-03 21:41:02,985 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@5f117b3d{/,null,AVAILABLE,@Spark}
2021-12-03 21:41:02,986 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@11f406f8{/api,null,AVAILABLE,@Spark}
2021-12-03 21:41:02,987 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@fb713e7{/jobs/job/kill,null,AVAILABLE,@Spark}
2021-12-03 21:41:02,988 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@35f639fa{/stages/stage/kill,null,AVAILABLE,@Spark}
2021-12-03 21:41:02,990 [main] INFO [org.apache.spark.ui.SparkUI] - Bound SparkUI to 0.0.0.0, and started at http://qb:4040
2021-12-03 21:41:03,077 [main] INFO [org.apache.spark.executor.Executor] - Starting executor ID driver on host localhost
2021-12-03 21:41:03,126 [main] INFO [org.apache.spark.util.Utils] - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 60076.
2021-12-03 21:41:03,126 [main] INFO [org.apache.spark.network.netty.NettyBlockTransferService] - Server created on qb:60076
2021-12-03 21:41:03,127 [main] INFO [org.apache.spark.storage.BlockManager] - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2021-12-03 21:41:03,129 [main] INFO [org.apache.spark.storage.BlockManagerMaster] - Registering BlockManager BlockManagerId(driver, qb, 60076, None)
2021-12-03 21:41:03,131 [dispatcher-event-loop-10] INFO [org.apache.spark.storage.BlockManagerMasterEndpoint] - Registering block manager qb:60076 with 1990.8 MB RAM, BlockManagerId(driver, qb, 60076, None)
2021-12-03 21:41:03,133 [main] INFO [org.apache.spark.storage.BlockManagerMaster] - Registered BlockManager BlockManagerId(driver, qb, 60076, None)
2021-12-03 21:41:03,133 [main] INFO [org.apache.spark.storage.BlockManager] - Initialized BlockManager: BlockManagerId(driver, qb, 60076, None)
2021-12-03 21:41:03,263 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@59bbb974{/metrics/json,null,AVAILABLE,@Spark}
2021-12-03 21:41:03,745 [main] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_0 stored as values in memory (estimated size 312.7 KB, free 1990.5 MB)
2021-12-03 21:41:03,965 [main] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_0_piece0 stored as bytes in memory (estimated size 27.3 KB, free 1990.5 MB)
2021-12-03 21:41:03,967 [dispatcher-event-loop-0] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_0_piece0 in memory on qb:60076 (size: 27.3 KB, free: 1990.8 MB)
2021-12-03 21:41:03,971 [main] INFO [org.apache.spark.SparkContext] - Created broadcast 0 from textFile at PaidPromotionAdjustParameter.scala:57
2021-12-03 21:41:04,322 [main] WARN [org.apache.hadoop.hdfs.shortcircuit.DomainSocketFactory] - The short-circuit local reads feature cannot be used because UNIX Domain sockets are not available on Windows.
2021-12-03 21:41:24,359 [main] INFO [org.apache.hadoop.ipc.Client] - Retrying connect to server: hdp1/172.16.1.222:8020. Already tried 0 time(s); maxRetries=45
2021-12-03 21:41:44,375 [main] INFO [org.apache.hadoop.ipc.Client] - Retrying connect to server: hdp1/172.16.1.222:8020. Already tried 1 time(s); maxRetries=45
2021-12-03 21:42:04,385 [main] INFO [org.apache.hadoop.ipc.Client] - Retrying connect to server: hdp1/172.16.1.222:8020. Already tried 2 time(s); maxRetries=45
2021-12-03 21:42:24,391 [main] INFO [org.apache.hadoop.ipc.Client] - Retrying connect to server: hdp1/172.16.1.222:8020. Already tried 3 time(s); maxRetries=45
2021-12-03 21:42:44,401 [main] INFO [org.apache.hadoop.ipc.Client] - Retrying connect to server: hdp1/172.16.1.222:8020. Already tried 4 time(s); maxRetries=45
2021-12-03 21:43:04,413 [main] INFO [org.apache.hadoop.ipc.Client] - Retrying connect to server: hdp1/172.16.1.222:8020. Already tried 5 time(s); maxRetries=45
2021-12-03 21:43:24,418 [main] INFO [org.apache.hadoop.ipc.Client] - Retrying connect to server: hdp1/172.16.1.222:8020. Already tried 6 time(s); maxRetries=45
2021-12-03 21:43:44,429 [main] INFO [org.apache.hadoop.ipc.Client] - Retrying connect to server: hdp1/172.16.1.222:8020. Already tried 7 time(s); maxRetries=45
2021-12-03 21:44:04,438 [main] INFO [org.apache.hadoop.ipc.Client] - Retrying connect to server: hdp1/172.16.1.222:8020. Already tried 8 time(s); maxRetries=45
2021-12-03 21:44:24,438 [main] INFO [org.apache.hadoop.ipc.Client] - Retrying connect to server: hdp1/172.16.1.222:8020. Already tried 9 time(s); maxRetries=45
2021-12-03 21:44:44,443 [main] INFO [org.apache.hadoop.ipc.Client] - Retrying connect to server: hdp1/172.16.1.222:8020. Already tried 10 time(s); maxRetries=45
2021-12-03 22:20:59,739 [main] INFO [org.apache.spark.SparkContext] - Running Spark version 2.3.0
2021-12-03 22:21:00,152 [main] INFO [org.apache.spark.SparkContext] - Submitted application: PaidPromotion
2021-12-03 22:21:00,233 [main] INFO [org.apache.spark.SecurityManager] - Changing view acls to: ACER,root
2021-12-03 22:21:00,234 [main] INFO [org.apache.spark.SecurityManager] - Changing modify acls to: ACER,root
2021-12-03 22:21:00,235 [main] INFO [org.apache.spark.SecurityManager] - Changing view acls groups to: 
2021-12-03 22:21:00,235 [main] INFO [org.apache.spark.SecurityManager] - Changing modify acls groups to: 
2021-12-03 22:21:00,236 [main] INFO [org.apache.spark.SecurityManager] - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(ACER, root); groups with view permissions: Set(); users  with modify permissions: Set(ACER, root); groups with modify permissions: Set()
2021-12-03 22:21:01,035 [main] INFO [org.apache.spark.util.Utils] - Successfully started service 'sparkDriver' on port 51705.
2021-12-03 22:21:01,076 [main] INFO [org.apache.spark.SparkEnv] - Registering MapOutputTracker
2021-12-03 22:21:01,107 [main] INFO [org.apache.spark.SparkEnv] - Registering BlockManagerMaster
2021-12-03 22:21:01,113 [main] INFO [org.apache.spark.storage.BlockManagerMasterEndpoint] - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2021-12-03 22:21:01,114 [main] INFO [org.apache.spark.storage.BlockManagerMasterEndpoint] - BlockManagerMasterEndpoint up
2021-12-03 22:21:01,132 [main] INFO [org.apache.spark.storage.DiskBlockManager] - Created local directory at C:\Users\ACER\AppData\Local\Temp\blockmgr-c5af7e0c-23df-440e-a1c7-9c42732f78ed
2021-12-03 22:21:01,165 [main] INFO [org.apache.spark.storage.memory.MemoryStore] - MemoryStore started with capacity 1990.8 MB
2021-12-03 22:21:01,186 [main] INFO [org.apache.spark.SparkEnv] - Registering OutputCommitCoordinator
2021-12-03 22:21:01,297 [main] INFO [org.spark_project.jetty.util.log] - Logging initialized @2988ms
2021-12-03 22:21:01,399 [main] INFO [org.spark_project.jetty.server.Server] - jetty-9.3.z-SNAPSHOT
2021-12-03 22:21:01,417 [main] INFO [org.spark_project.jetty.server.Server] - Started @3108ms
2021-12-03 22:21:01,450 [main] INFO [org.spark_project.jetty.server.AbstractConnector] - Started ServerConnector@3414a8c3{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2021-12-03 22:21:01,450 [main] INFO [org.apache.spark.util.Utils] - Successfully started service 'SparkUI' on port 4040.
2021-12-03 22:21:01,477 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@27b45ea{/jobs,null,AVAILABLE,@Spark}
2021-12-03 22:21:01,478 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@4fc142ec{/jobs/json,null,AVAILABLE,@Spark}
2021-12-03 22:21:01,479 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@702b06fb{/jobs/job,null,AVAILABLE,@Spark}
2021-12-03 22:21:01,480 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@2b22a1cc{/jobs/job/json,null,AVAILABLE,@Spark}
2021-12-03 22:21:01,481 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@7fd8c559{/stages,null,AVAILABLE,@Spark}
2021-12-03 22:21:01,482 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@55a88417{/stages/json,null,AVAILABLE,@Spark}
2021-12-03 22:21:01,483 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@19962194{/stages/stage,null,AVAILABLE,@Spark}
2021-12-03 22:21:01,484 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@3cbf1ba4{/stages/stage/json,null,AVAILABLE,@Spark}
2021-12-03 22:21:01,485 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@3dd818e8{/stages/pool,null,AVAILABLE,@Spark}
2021-12-03 22:21:01,487 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@47b67fcb{/stages/pool/json,null,AVAILABLE,@Spark}
2021-12-03 22:21:01,489 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@66420549{/storage,null,AVAILABLE,@Spark}
2021-12-03 22:21:01,491 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@42b28ff1{/storage/json,null,AVAILABLE,@Spark}
2021-12-03 22:21:01,492 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@706fe5c6{/storage/rdd,null,AVAILABLE,@Spark}
2021-12-03 22:21:01,493 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@6b3f6585{/storage/rdd/json,null,AVAILABLE,@Spark}
2021-12-03 22:21:01,494 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@64469d8{/environment,null,AVAILABLE,@Spark}
2021-12-03 22:21:01,495 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@1cec219f{/environment/json,null,AVAILABLE,@Spark}
2021-12-03 22:21:01,496 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@3cb8c8ce{/executors,null,AVAILABLE,@Spark}
2021-12-03 22:21:01,497 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@260a3a5e{/executors/json,null,AVAILABLE,@Spark}
2021-12-03 22:21:01,498 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@2e51d054{/executors/threadDump,null,AVAILABLE,@Spark}
2021-12-03 22:21:01,499 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@608bc8f8{/executors/threadDump/json,null,AVAILABLE,@Spark}
2021-12-03 22:21:01,510 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@381d7219{/static,null,AVAILABLE,@Spark}
2021-12-03 22:21:01,511 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@5f117b3d{/,null,AVAILABLE,@Spark}
2021-12-03 22:21:01,513 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@11f406f8{/api,null,AVAILABLE,@Spark}
2021-12-03 22:21:01,514 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@fb713e7{/jobs/job/kill,null,AVAILABLE,@Spark}
2021-12-03 22:21:01,515 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@35f639fa{/stages/stage/kill,null,AVAILABLE,@Spark}
2021-12-03 22:21:01,517 [main] INFO [org.apache.spark.ui.SparkUI] - Bound SparkUI to 0.0.0.0, and started at http://qb:4040
2021-12-03 22:21:01,642 [main] INFO [org.apache.spark.executor.Executor] - Starting executor ID driver on host localhost
2021-12-03 22:21:01,682 [main] INFO [org.apache.spark.util.Utils] - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 51746.
2021-12-03 22:21:01,683 [main] INFO [org.apache.spark.network.netty.NettyBlockTransferService] - Server created on qb:51746
2021-12-03 22:21:01,685 [main] INFO [org.apache.spark.storage.BlockManager] - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2021-12-03 22:21:01,688 [main] INFO [org.apache.spark.storage.BlockManagerMaster] - Registering BlockManager BlockManagerId(driver, qb, 51746, None)
2021-12-03 22:21:01,692 [dispatcher-event-loop-10] INFO [org.apache.spark.storage.BlockManagerMasterEndpoint] - Registering block manager qb:51746 with 1990.8 MB RAM, BlockManagerId(driver, qb, 51746, None)
2021-12-03 22:21:01,694 [main] INFO [org.apache.spark.storage.BlockManagerMaster] - Registered BlockManager BlockManagerId(driver, qb, 51746, None)
2021-12-03 22:21:01,695 [main] INFO [org.apache.spark.storage.BlockManager] - Initialized BlockManager: BlockManagerId(driver, qb, 51746, None)
2021-12-03 22:21:01,877 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@30893e08{/metrics/json,null,AVAILABLE,@Spark}
2021-12-03 22:21:02,443 [main] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_0 stored as values in memory (estimated size 312.7 KB, free 1990.5 MB)
2021-12-03 22:21:02,657 [main] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_0_piece0 stored as bytes in memory (estimated size 27.3 KB, free 1990.5 MB)
2021-12-03 22:21:02,659 [dispatcher-event-loop-0] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_0_piece0 in memory on qb:51746 (size: 27.3 KB, free: 1990.8 MB)
2021-12-03 22:21:02,672 [main] INFO [org.apache.spark.SparkContext] - Created broadcast 0 from textFile at PaidPromotionAdjustParameter.scala:57
2021-12-03 22:21:03,088 [main] WARN [org.apache.hadoop.hdfs.shortcircuit.DomainSocketFactory] - The short-circuit local reads feature cannot be used because UNIX Domain sockets are not available on Windows.
2021-12-03 22:21:03,171 [main] INFO [org.apache.hadoop.mapred.FileInputFormat] - Total input paths to process : 1
2021-12-03 22:21:03,212 [main] INFO [org.apache.hadoop.net.NetworkTopology] - Adding a new node: /default-rack/192.168.1.33:50010
2021-12-03 22:21:03,212 [main] INFO [org.apache.hadoop.net.NetworkTopology] - Adding a new node: /default-rack/172.16.1.220:50010
2021-12-03 22:21:03,212 [main] INFO [org.apache.hadoop.net.NetworkTopology] - Adding a new node: /default-rack/192.168.1.34:50010
2021-12-03 22:21:03,219 [main] INFO [org.apache.spark.SparkContext] - Starting job: count at PaidPromotionAdjustParameter.scala:59
2021-12-03 22:21:03,232 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 0 (count at PaidPromotionAdjustParameter.scala:59) with 22 output partitions
2021-12-03 22:21:03,232 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 0 (count at PaidPromotionAdjustParameter.scala:59)
2021-12-03 22:21:03,232 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List()
2021-12-03 22:21:03,233 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2021-12-03 22:21:03,240 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 0 (/sk/chongqing/data/behavior_data.bcp MapPartitionsRDD[1] at textFile at PaidPromotionAdjustParameter.scala:57), which has no missing parents
2021-12-03 22:21:03,281 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_1 stored as values in memory (estimated size 3.1 KB, free 1990.5 MB)
2021-12-03 22:21:03,286 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_1_piece0 stored as bytes in memory (estimated size 1903.0 B, free 1990.5 MB)
2021-12-03 22:21:03,287 [dispatcher-event-loop-1] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_1_piece0 in memory on qb:51746 (size: 1903.0 B, free: 1990.8 MB)
2021-12-03 22:21:03,287 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 1 from broadcast at DAGScheduler.scala:1039
2021-12-03 22:21:03,299 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 22 missing tasks from ResultStage 0 (/sk/chongqing/data/behavior_data.bcp MapPartitionsRDD[1] at textFile at PaidPromotionAdjustParameter.scala:57) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14))
2021-12-03 22:21:03,300 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 0.0 with 22 tasks
2021-12-03 22:21:03,343 [dispatcher-event-loop-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 0.0 (TID 0, localhost, executor driver, partition 0, ANY, 7899 bytes)
2021-12-03 22:21:03,345 [dispatcher-event-loop-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 0.0 (TID 1, localhost, executor driver, partition 1, ANY, 7899 bytes)
2021-12-03 22:21:03,346 [dispatcher-event-loop-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 2.0 in stage 0.0 (TID 2, localhost, executor driver, partition 2, ANY, 7899 bytes)
2021-12-03 22:21:03,346 [dispatcher-event-loop-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 3.0 in stage 0.0 (TID 3, localhost, executor driver, partition 3, ANY, 7899 bytes)
2021-12-03 22:21:03,346 [dispatcher-event-loop-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 4.0 in stage 0.0 (TID 4, localhost, executor driver, partition 4, ANY, 7899 bytes)
2021-12-03 22:21:03,347 [dispatcher-event-loop-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 5.0 in stage 0.0 (TID 5, localhost, executor driver, partition 5, ANY, 7899 bytes)
2021-12-03 22:21:03,347 [dispatcher-event-loop-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 6.0 in stage 0.0 (TID 6, localhost, executor driver, partition 6, ANY, 7899 bytes)
2021-12-03 22:21:03,347 [dispatcher-event-loop-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 7.0 in stage 0.0 (TID 7, localhost, executor driver, partition 7, ANY, 7899 bytes)
2021-12-03 22:21:03,348 [dispatcher-event-loop-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 8.0 in stage 0.0 (TID 8, localhost, executor driver, partition 8, ANY, 7899 bytes)
2021-12-03 22:21:03,348 [dispatcher-event-loop-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 9.0 in stage 0.0 (TID 9, localhost, executor driver, partition 9, ANY, 7899 bytes)
2021-12-03 22:21:03,348 [dispatcher-event-loop-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 10.0 in stage 0.0 (TID 10, localhost, executor driver, partition 10, ANY, 7899 bytes)
2021-12-03 22:21:03,349 [dispatcher-event-loop-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 11.0 in stage 0.0 (TID 11, localhost, executor driver, partition 11, ANY, 7899 bytes)
2021-12-03 22:21:03,359 [Executor task launch worker for task 5] INFO [org.apache.spark.executor.Executor] - Running task 5.0 in stage 0.0 (TID 5)
2021-12-03 22:21:03,359 [Executor task launch worker for task 9] INFO [org.apache.spark.executor.Executor] - Running task 9.0 in stage 0.0 (TID 9)
2021-12-03 22:21:03,359 [Executor task launch worker for task 10] INFO [org.apache.spark.executor.Executor] - Running task 10.0 in stage 0.0 (TID 10)
2021-12-03 22:21:03,359 [Executor task launch worker for task 8] INFO [org.apache.spark.executor.Executor] - Running task 8.0 in stage 0.0 (TID 8)
2021-12-03 22:21:03,359 [Executor task launch worker for task 11] INFO [org.apache.spark.executor.Executor] - Running task 11.0 in stage 0.0 (TID 11)
2021-12-03 22:21:03,359 [Executor task launch worker for task 7] INFO [org.apache.spark.executor.Executor] - Running task 7.0 in stage 0.0 (TID 7)
2021-12-03 22:21:03,359 [Executor task launch worker for task 4] INFO [org.apache.spark.executor.Executor] - Running task 4.0 in stage 0.0 (TID 4)
2021-12-03 22:21:03,359 [Executor task launch worker for task 2] INFO [org.apache.spark.executor.Executor] - Running task 2.0 in stage 0.0 (TID 2)
2021-12-03 22:21:03,359 [Executor task launch worker for task 0] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 0.0 (TID 0)
2021-12-03 22:21:03,359 [Executor task launch worker for task 6] INFO [org.apache.spark.executor.Executor] - Running task 6.0 in stage 0.0 (TID 6)
2021-12-03 22:21:03,359 [Executor task launch worker for task 3] INFO [org.apache.spark.executor.Executor] - Running task 3.0 in stage 0.0 (TID 3)
2021-12-03 22:21:03,359 [Executor task launch worker for task 1] INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 0.0 (TID 1)
2021-12-03 22:21:03,416 [Executor task launch worker for task 8] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:1073741824+134217728
2021-12-03 22:21:03,416 [Executor task launch worker for task 9] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:1207959552+134217728
2021-12-03 22:21:03,416 [Executor task launch worker for task 11] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:1476395008+134217728
2021-12-03 22:21:03,416 [Executor task launch worker for task 5] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:671088640+134217728
2021-12-03 22:21:03,416 [Executor task launch worker for task 4] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:536870912+134217728
2021-12-03 22:21:03,416 [Executor task launch worker for task 10] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:1342177280+134217728
2021-12-03 22:21:03,416 [Executor task launch worker for task 7] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:939524096+134217728
2021-12-03 22:21:03,416 [Executor task launch worker for task 2] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:268435456+134217728
2021-12-03 22:21:03,416 [Executor task launch worker for task 1] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:134217728+134217728
2021-12-03 22:21:03,416 [Executor task launch worker for task 3] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:402653184+134217728
2021-12-03 22:21:03,416 [Executor task launch worker for task 0] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:0+134217728
2021-12-03 22:21:03,416 [Executor task launch worker for task 6] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:805306368+134217728
2021-12-03 22:22:49,249 [Executor task launch worker for task 11] INFO [org.apache.spark.executor.Executor] - Finished task 11.0 in stage 0.0 (TID 11). 755 bytes result sent to driver
2021-12-03 22:22:49,252 [dispatcher-event-loop-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 12.0 in stage 0.0 (TID 12, localhost, executor driver, partition 12, ANY, 7899 bytes)
2021-12-03 22:22:49,252 [Executor task launch worker for task 12] INFO [org.apache.spark.executor.Executor] - Running task 12.0 in stage 0.0 (TID 12)
2021-12-03 22:22:49,253 [Executor task launch worker for task 12] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:1610612736+134217728
2021-12-03 22:22:49,260 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 11.0 in stage 0.0 (TID 11) in 105911 ms on localhost (executor driver) (1/22)
2021-12-03 22:22:54,720 [Executor task launch worker for task 10] INFO [org.apache.spark.executor.Executor] - Finished task 10.0 in stage 0.0 (TID 10). 755 bytes result sent to driver
2021-12-03 22:22:54,721 [dispatcher-event-loop-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 13.0 in stage 0.0 (TID 13, localhost, executor driver, partition 13, ANY, 7899 bytes)
2021-12-03 22:22:54,721 [Executor task launch worker for task 13] INFO [org.apache.spark.executor.Executor] - Running task 13.0 in stage 0.0 (TID 13)
2021-12-03 22:22:54,723 [Executor task launch worker for task 13] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:1744830464+134217728
2021-12-03 22:22:54,728 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 10.0 in stage 0.0 (TID 10) in 111380 ms on localhost (executor driver) (2/22)
2021-12-03 22:22:56,633 [Executor task launch worker for task 2] INFO [org.apache.spark.executor.Executor] - Finished task 2.0 in stage 0.0 (TID 2). 755 bytes result sent to driver
2021-12-03 22:22:56,637 [dispatcher-event-loop-8] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 14.0 in stage 0.0 (TID 14, localhost, executor driver, partition 14, ANY, 7899 bytes)
2021-12-03 22:22:56,637 [Executor task launch worker for task 14] INFO [org.apache.spark.executor.Executor] - Running task 14.0 in stage 0.0 (TID 14)
2021-12-03 22:22:56,638 [Executor task launch worker for task 14] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:1879048192+134217728
2021-12-03 22:22:56,639 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 2.0 in stage 0.0 (TID 2) in 113294 ms on localhost (executor driver) (3/22)
2021-12-03 22:22:57,587 [Executor task launch worker for task 7] INFO [org.apache.spark.executor.Executor] - Finished task 7.0 in stage 0.0 (TID 7). 755 bytes result sent to driver
2021-12-03 22:22:57,591 [dispatcher-event-loop-9] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 15.0 in stage 0.0 (TID 15, localhost, executor driver, partition 15, ANY, 7899 bytes)
2021-12-03 22:22:57,591 [Executor task launch worker for task 15] INFO [org.apache.spark.executor.Executor] - Running task 15.0 in stage 0.0 (TID 15)
2021-12-03 22:22:57,593 [Executor task launch worker for task 15] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:2013265920+134217728
2021-12-03 22:22:57,593 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 7.0 in stage 0.0 (TID 7) in 114246 ms on localhost (executor driver) (4/22)
2021-12-03 22:22:58,460 [Executor task launch worker for task 5] INFO [org.apache.spark.executor.Executor] - Finished task 5.0 in stage 0.0 (TID 5). 755 bytes result sent to driver
2021-12-03 22:22:58,460 [dispatcher-event-loop-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 16.0 in stage 0.0 (TID 16, localhost, executor driver, partition 16, ANY, 7899 bytes)
2021-12-03 22:22:58,461 [Executor task launch worker for task 16] INFO [org.apache.spark.executor.Executor] - Running task 16.0 in stage 0.0 (TID 16)
2021-12-03 22:22:58,461 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 5.0 in stage 0.0 (TID 5) in 115115 ms on localhost (executor driver) (5/22)
2021-12-03 22:22:58,471 [Executor task launch worker for task 16] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:2147483648+134217728
2021-12-03 22:23:00,823 [Executor task launch worker for task 0] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 0.0 (TID 0). 755 bytes result sent to driver
2021-12-03 22:23:00,824 [dispatcher-event-loop-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 17.0 in stage 0.0 (TID 17, localhost, executor driver, partition 17, ANY, 7899 bytes)
2021-12-03 22:23:00,824 [Executor task launch worker for task 17] INFO [org.apache.spark.executor.Executor] - Running task 17.0 in stage 0.0 (TID 17)
2021-12-03 22:23:00,824 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 0.0 (TID 0) in 117495 ms on localhost (executor driver) (6/22)
2021-12-03 22:23:00,830 [Executor task launch worker for task 17] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:2281701376+134217728
2021-12-03 22:23:11,086 [Executor task launch worker for task 4] INFO [org.apache.spark.executor.Executor] - Finished task 4.0 in stage 0.0 (TID 4). 755 bytes result sent to driver
2021-12-03 22:23:11,086 [dispatcher-event-loop-7] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 18.0 in stage 0.0 (TID 18, localhost, executor driver, partition 18, ANY, 7899 bytes)
2021-12-03 22:23:11,086 [Executor task launch worker for task 18] INFO [org.apache.spark.executor.Executor] - Running task 18.0 in stage 0.0 (TID 18)
2021-12-03 22:23:11,086 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 4.0 in stage 0.0 (TID 4) in 127740 ms on localhost (executor driver) (7/22)
2021-12-03 22:23:11,087 [Executor task launch worker for task 18] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:2415919104+134217728
2021-12-03 22:23:32,355 [Executor task launch worker for task 6] INFO [org.apache.spark.executor.Executor] - Finished task 6.0 in stage 0.0 (TID 6). 755 bytes result sent to driver
2021-12-03 22:23:32,356 [dispatcher-event-loop-11] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 19.0 in stage 0.0 (TID 19, localhost, executor driver, partition 19, ANY, 7899 bytes)
2021-12-03 22:23:32,356 [Executor task launch worker for task 19] INFO [org.apache.spark.executor.Executor] - Running task 19.0 in stage 0.0 (TID 19)
2021-12-03 22:23:32,356 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 6.0 in stage 0.0 (TID 6) in 149009 ms on localhost (executor driver) (8/22)
2021-12-03 22:23:32,360 [Executor task launch worker for task 19] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:2550136832+134217728
2021-12-03 22:23:57,970 [Executor task launch worker for task 17] INFO [org.apache.spark.executor.Executor] - Finished task 17.0 in stage 0.0 (TID 17). 798 bytes result sent to driver
2021-12-03 22:23:57,971 [dispatcher-event-loop-5] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 20.0 in stage 0.0 (TID 20, localhost, executor driver, partition 20, ANY, 7899 bytes)
2021-12-03 22:23:57,971 [Executor task launch worker for task 20] INFO [org.apache.spark.executor.Executor] - Running task 20.0 in stage 0.0 (TID 20)
2021-12-03 22:23:57,971 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 17.0 in stage 0.0 (TID 17) in 57148 ms on localhost (executor driver) (9/22)
2021-12-03 22:23:57,972 [Executor task launch worker for task 20] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:2684354560+134217728
2021-12-03 22:24:15,021 [Executor task launch worker for task 8] INFO [org.apache.spark.executor.Executor] - Finished task 8.0 in stage 0.0 (TID 8). 755 bytes result sent to driver
2021-12-03 22:24:15,022 [dispatcher-event-loop-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 21.0 in stage 0.0 (TID 21, localhost, executor driver, partition 21, ANY, 7899 bytes)
2021-12-03 22:24:15,022 [Executor task launch worker for task 21] INFO [org.apache.spark.executor.Executor] - Running task 21.0 in stage 0.0 (TID 21)
2021-12-03 22:24:15,022 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 8.0 in stage 0.0 (TID 8) in 191675 ms on localhost (executor driver) (10/22)
2021-12-03 22:24:15,023 [Executor task launch worker for task 21] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:2818572288+147216171
2021-12-03 22:24:17,195 [Executor task launch worker for task 1] INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 0.0 (TID 1). 755 bytes result sent to driver
2021-12-03 22:24:17,200 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 0.0 (TID 1) in 193855 ms on localhost (executor driver) (11/22)
2021-12-03 22:24:21,502 [Executor task launch worker for task 9] INFO [org.apache.spark.executor.Executor] - Finished task 9.0 in stage 0.0 (TID 9). 755 bytes result sent to driver
2021-12-03 22:24:21,502 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 9.0 in stage 0.0 (TID 9) in 198154 ms on localhost (executor driver) (12/22)
2021-12-03 22:24:23,078 [Executor task launch worker for task 18] INFO [org.apache.spark.executor.Executor] - Finished task 18.0 in stage 0.0 (TID 18). 755 bytes result sent to driver
2021-12-03 22:24:23,078 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 18.0 in stage 0.0 (TID 18) in 71992 ms on localhost (executor driver) (13/22)
2021-12-03 22:24:34,402 [Executor task launch worker for task 13] INFO [org.apache.spark.executor.Executor] - Finished task 13.0 in stage 0.0 (TID 13). 755 bytes result sent to driver
2021-12-03 22:24:34,402 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 13.0 in stage 0.0 (TID 13) in 99681 ms on localhost (executor driver) (14/22)
2021-12-03 22:24:36,408 [Executor task launch worker for task 3] INFO [org.apache.spark.executor.Executor] - Finished task 3.0 in stage 0.0 (TID 3). 755 bytes result sent to driver
2021-12-03 22:24:36,408 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 3.0 in stage 0.0 (TID 3) in 213062 ms on localhost (executor driver) (15/22)
2021-12-03 22:24:54,031 [Executor task launch worker for task 14] INFO [org.apache.spark.executor.Executor] - Finished task 14.0 in stage 0.0 (TID 14). 755 bytes result sent to driver
2021-12-03 22:24:54,037 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 14.0 in stage 0.0 (TID 14) in 117404 ms on localhost (executor driver) (16/22)
2021-12-03 22:25:04,811 [Executor task launch worker for task 15] INFO [org.apache.spark.executor.Executor] - Finished task 15.0 in stage 0.0 (TID 15). 798 bytes result sent to driver
2021-12-03 22:25:04,811 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 15.0 in stage 0.0 (TID 15) in 127223 ms on localhost (executor driver) (17/22)
2021-12-03 22:25:05,164 [Executor task launch worker for task 12] INFO [org.apache.spark.executor.Executor] - Finished task 12.0 in stage 0.0 (TID 12). 712 bytes result sent to driver
2021-12-03 22:25:05,164 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 12.0 in stage 0.0 (TID 12) in 135913 ms on localhost (executor driver) (18/22)
2021-12-03 22:25:14,549 [Executor task launch worker for task 19] INFO [org.apache.spark.executor.Executor] - Finished task 19.0 in stage 0.0 (TID 19). 798 bytes result sent to driver
2021-12-03 22:25:14,550 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 19.0 in stage 0.0 (TID 19) in 102194 ms on localhost (executor driver) (19/22)
2021-12-03 22:25:15,934 [Executor task launch worker for task 21] INFO [org.apache.spark.executor.Executor] - Finished task 21.0 in stage 0.0 (TID 21). 755 bytes result sent to driver
2021-12-03 22:25:15,937 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 21.0 in stage 0.0 (TID 21) in 60916 ms on localhost (executor driver) (20/22)
2021-12-03 22:25:18,722 [Executor task launch worker for task 16] INFO [org.apache.spark.executor.Executor] - Finished task 16.0 in stage 0.0 (TID 16). 755 bytes result sent to driver
2021-12-03 22:25:18,723 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 16.0 in stage 0.0 (TID 16) in 140263 ms on localhost (executor driver) (21/22)
2021-12-03 22:25:18,738 [Executor task launch worker for task 20] INFO [org.apache.spark.executor.Executor] - Finished task 20.0 in stage 0.0 (TID 20). 712 bytes result sent to driver
2021-12-03 22:25:18,739 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 20.0 in stage 0.0 (TID 20) in 80769 ms on localhost (executor driver) (22/22)
2021-12-03 22:25:18,747 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 0.0, whose tasks have all completed, from pool 
2021-12-03 22:25:18,747 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 0 (count at PaidPromotionAdjustParameter.scala:59) finished in 255.480 s
2021-12-03 22:25:18,753 [main] INFO [org.apache.spark.scheduler.DAGScheduler] - Job 0 finished: count at PaidPromotionAdjustParameter.scala:59, took 255.533158 s
2021-12-03 22:25:18,755 [main] INFO [PaidPromotion$] - 收视总数68489201
2021-12-03 22:25:18,758 [Thread-1] INFO [org.apache.spark.SparkContext] - Invoking stop() from shutdown hook
2021-12-03 22:25:18,764 [Thread-1] INFO [org.spark_project.jetty.server.AbstractConnector] - Stopped Spark@3414a8c3{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2021-12-03 22:25:18,766 [Thread-1] INFO [org.apache.spark.ui.SparkUI] - Stopped Spark web UI at http://qb:4040
2021-12-03 22:25:18,777 [dispatcher-event-loop-5] INFO [org.apache.spark.MapOutputTrackerMasterEndpoint] - MapOutputTrackerMasterEndpoint stopped!
2021-12-03 22:25:18,798 [Thread-1] INFO [org.apache.spark.storage.memory.MemoryStore] - MemoryStore cleared
2021-12-03 22:25:18,798 [Thread-1] INFO [org.apache.spark.storage.BlockManager] - BlockManager stopped
2021-12-03 22:25:18,799 [Thread-1] INFO [org.apache.spark.storage.BlockManagerMaster] - BlockManagerMaster stopped
2021-12-03 22:25:18,800 [dispatcher-event-loop-0] INFO [org.apache.spark.scheduler.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint] - OutputCommitCoordinator stopped!
2021-12-03 22:25:18,804 [Thread-1] INFO [org.apache.spark.SparkContext] - Successfully stopped SparkContext
2021-12-03 22:25:18,805 [Thread-1] INFO [org.apache.spark.util.ShutdownHookManager] - Shutdown hook called
2021-12-03 22:25:18,806 [Thread-1] INFO [org.apache.spark.util.ShutdownHookManager] - Deleting directory C:\Users\ACER\AppData\Local\Temp\spark-89523ca1-dd7b-4cca-b6c8-c643597d0dbc
2021-12-03 22:28:14,712 [main] INFO [org.apache.spark.SparkContext] - Running Spark version 2.3.0
2021-12-03 22:28:14,995 [main] INFO [org.apache.spark.SparkContext] - Submitted application: PaidPromotion
2021-12-03 22:28:15,049 [main] INFO [org.apache.spark.SecurityManager] - Changing view acls to: ACER,root
2021-12-03 22:28:15,049 [main] INFO [org.apache.spark.SecurityManager] - Changing modify acls to: ACER,root
2021-12-03 22:28:15,049 [main] INFO [org.apache.spark.SecurityManager] - Changing view acls groups to: 
2021-12-03 22:28:15,050 [main] INFO [org.apache.spark.SecurityManager] - Changing modify acls groups to: 
2021-12-03 22:28:15,050 [main] INFO [org.apache.spark.SecurityManager] - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(ACER, root); groups with view permissions: Set(); users  with modify permissions: Set(ACER, root); groups with modify permissions: Set()
2021-12-03 22:28:15,644 [main] INFO [org.apache.spark.util.Utils] - Successfully started service 'sparkDriver' on port 59920.
2021-12-03 22:28:15,664 [main] INFO [org.apache.spark.SparkEnv] - Registering MapOutputTracker
2021-12-03 22:28:15,679 [main] INFO [org.apache.spark.SparkEnv] - Registering BlockManagerMaster
2021-12-03 22:28:15,682 [main] INFO [org.apache.spark.storage.BlockManagerMasterEndpoint] - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2021-12-03 22:28:15,682 [main] INFO [org.apache.spark.storage.BlockManagerMasterEndpoint] - BlockManagerMasterEndpoint up
2021-12-03 22:28:15,689 [main] INFO [org.apache.spark.storage.DiskBlockManager] - Created local directory at C:\Users\ACER\AppData\Local\Temp\blockmgr-48866eeb-401e-4f2b-a8bf-6ffeb988aff2
2021-12-03 22:28:15,704 [main] INFO [org.apache.spark.storage.memory.MemoryStore] - MemoryStore started with capacity 1990.8 MB
2021-12-03 22:28:15,714 [main] INFO [org.apache.spark.SparkEnv] - Registering OutputCommitCoordinator
2021-12-03 22:28:15,768 [main] INFO [org.spark_project.jetty.util.log] - Logging initialized @2945ms
2021-12-03 22:28:15,817 [main] INFO [org.spark_project.jetty.server.Server] - jetty-9.3.z-SNAPSHOT
2021-12-03 22:28:15,828 [main] INFO [org.spark_project.jetty.server.Server] - Started @3005ms
2021-12-03 22:28:15,852 [main] INFO [org.spark_project.jetty.server.AbstractConnector] - Started ServerConnector@3414a8c3{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2021-12-03 22:28:15,852 [main] INFO [org.apache.spark.util.Utils] - Successfully started service 'SparkUI' on port 4040.
2021-12-03 22:28:15,873 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@27b45ea{/jobs,null,AVAILABLE,@Spark}
2021-12-03 22:28:15,874 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@4fc142ec{/jobs/json,null,AVAILABLE,@Spark}
2021-12-03 22:28:15,874 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@702b06fb{/jobs/job,null,AVAILABLE,@Spark}
2021-12-03 22:28:15,876 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@2b22a1cc{/jobs/job/json,null,AVAILABLE,@Spark}
2021-12-03 22:28:15,876 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@7fd8c559{/stages,null,AVAILABLE,@Spark}
2021-12-03 22:28:15,877 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@55a88417{/stages/json,null,AVAILABLE,@Spark}
2021-12-03 22:28:15,878 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@19962194{/stages/stage,null,AVAILABLE,@Spark}
2021-12-03 22:28:15,880 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@3cbf1ba4{/stages/stage/json,null,AVAILABLE,@Spark}
2021-12-03 22:28:15,881 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@3dd818e8{/stages/pool,null,AVAILABLE,@Spark}
2021-12-03 22:28:15,882 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@47b67fcb{/stages/pool/json,null,AVAILABLE,@Spark}
2021-12-03 22:28:15,883 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@66420549{/storage,null,AVAILABLE,@Spark}
2021-12-03 22:28:15,885 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@42b28ff1{/storage/json,null,AVAILABLE,@Spark}
2021-12-03 22:28:15,886 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@706fe5c6{/storage/rdd,null,AVAILABLE,@Spark}
2021-12-03 22:28:15,887 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@6b3f6585{/storage/rdd/json,null,AVAILABLE,@Spark}
2021-12-03 22:28:15,889 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@64469d8{/environment,null,AVAILABLE,@Spark}
2021-12-03 22:28:15,890 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@1cec219f{/environment/json,null,AVAILABLE,@Spark}
2021-12-03 22:28:15,891 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@3cb8c8ce{/executors,null,AVAILABLE,@Spark}
2021-12-03 22:28:15,892 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@260a3a5e{/executors/json,null,AVAILABLE,@Spark}
2021-12-03 22:28:15,893 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@2e51d054{/executors/threadDump,null,AVAILABLE,@Spark}
2021-12-03 22:28:15,894 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@608bc8f8{/executors/threadDump/json,null,AVAILABLE,@Spark}
2021-12-03 22:28:15,900 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@381d7219{/static,null,AVAILABLE,@Spark}
2021-12-03 22:28:15,901 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@5f117b3d{/,null,AVAILABLE,@Spark}
2021-12-03 22:28:15,902 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@11f406f8{/api,null,AVAILABLE,@Spark}
2021-12-03 22:28:15,903 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@fb713e7{/jobs/job/kill,null,AVAILABLE,@Spark}
2021-12-03 22:28:15,904 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@35f639fa{/stages/stage/kill,null,AVAILABLE,@Spark}
2021-12-03 22:28:15,906 [main] INFO [org.apache.spark.ui.SparkUI] - Bound SparkUI to 0.0.0.0, and started at http://qb:4040
2021-12-03 22:28:15,984 [main] INFO [org.apache.spark.executor.Executor] - Starting executor ID driver on host localhost
2021-12-03 22:28:16,024 [main] INFO [org.apache.spark.util.Utils] - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 59961.
2021-12-03 22:28:16,025 [main] INFO [org.apache.spark.network.netty.NettyBlockTransferService] - Server created on qb:59961
2021-12-03 22:28:16,026 [main] INFO [org.apache.spark.storage.BlockManager] - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2021-12-03 22:28:16,028 [main] INFO [org.apache.spark.storage.BlockManagerMaster] - Registering BlockManager BlockManagerId(driver, qb, 59961, None)
2021-12-03 22:28:16,030 [dispatcher-event-loop-10] INFO [org.apache.spark.storage.BlockManagerMasterEndpoint] - Registering block manager qb:59961 with 1990.8 MB RAM, BlockManagerId(driver, qb, 59961, None)
2021-12-03 22:28:16,031 [main] INFO [org.apache.spark.storage.BlockManagerMaster] - Registered BlockManager BlockManagerId(driver, qb, 59961, None)
2021-12-03 22:28:16,032 [main] INFO [org.apache.spark.storage.BlockManager] - Initialized BlockManager: BlockManagerId(driver, qb, 59961, None)
2021-12-03 22:28:16,161 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@575b5f7d{/metrics/json,null,AVAILABLE,@Spark}
2021-12-03 22:28:16,645 [main] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_0 stored as values in memory (estimated size 312.7 KB, free 1990.5 MB)
2021-12-03 22:28:16,851 [main] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_0_piece0 stored as bytes in memory (estimated size 27.3 KB, free 1990.5 MB)
2021-12-03 22:28:16,853 [dispatcher-event-loop-0] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_0_piece0 in memory on qb:59961 (size: 27.3 KB, free: 1990.8 MB)
2021-12-03 22:28:16,857 [main] INFO [org.apache.spark.SparkContext] - Created broadcast 0 from textFile at PaidPromotionAdjustParameter.scala:57
2021-12-03 22:28:17,188 [main] WARN [org.apache.hadoop.hdfs.shortcircuit.DomainSocketFactory] - The short-circuit local reads feature cannot be used because UNIX Domain sockets are not available on Windows.
2021-12-03 22:28:17,257 [main] INFO [org.apache.hadoop.mapred.FileInputFormat] - Total input paths to process : 1
2021-12-03 22:28:17,291 [main] INFO [org.apache.hadoop.net.NetworkTopology] - Adding a new node: /default-rack/192.168.1.34:50010
2021-12-03 22:28:17,291 [main] INFO [org.apache.hadoop.net.NetworkTopology] - Adding a new node: /default-rack/192.168.1.33:50010
2021-12-03 22:28:17,291 [main] INFO [org.apache.hadoop.net.NetworkTopology] - Adding a new node: /default-rack/172.16.1.220:50010
2021-12-03 22:28:17,297 [main] INFO [org.apache.spark.SparkContext] - Starting job: count at PaidPromotionAdjustParameter.scala:59
2021-12-03 22:28:17,307 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 0 (count at PaidPromotionAdjustParameter.scala:59) with 22 output partitions
2021-12-03 22:28:17,307 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 0 (count at PaidPromotionAdjustParameter.scala:59)
2021-12-03 22:28:17,308 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List()
2021-12-03 22:28:17,309 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2021-12-03 22:28:17,314 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 0 (/sk/chongqing/data/behavior_data.bcp MapPartitionsRDD[1] at textFile at PaidPromotionAdjustParameter.scala:57), which has no missing parents
2021-12-03 22:28:17,347 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_1 stored as values in memory (estimated size 3.1 KB, free 1990.5 MB)
2021-12-03 22:28:17,353 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_1_piece0 stored as bytes in memory (estimated size 1903.0 B, free 1990.5 MB)
2021-12-03 22:28:17,353 [dispatcher-event-loop-1] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_1_piece0 in memory on qb:59961 (size: 1903.0 B, free: 1990.8 MB)
2021-12-03 22:28:17,354 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 1 from broadcast at DAGScheduler.scala:1039
2021-12-03 22:28:17,365 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 22 missing tasks from ResultStage 0 (/sk/chongqing/data/behavior_data.bcp MapPartitionsRDD[1] at textFile at PaidPromotionAdjustParameter.scala:57) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14))
2021-12-03 22:28:17,365 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 0.0 with 22 tasks
2021-12-03 22:28:17,399 [dispatcher-event-loop-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 0.0 (TID 0, localhost, executor driver, partition 0, ANY, 7899 bytes)
2021-12-03 22:28:17,400 [dispatcher-event-loop-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 0.0 (TID 1, localhost, executor driver, partition 1, ANY, 7899 bytes)
2021-12-03 22:28:17,401 [dispatcher-event-loop-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 2.0 in stage 0.0 (TID 2, localhost, executor driver, partition 2, ANY, 7899 bytes)
2021-12-03 22:28:17,401 [dispatcher-event-loop-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 3.0 in stage 0.0 (TID 3, localhost, executor driver, partition 3, ANY, 7899 bytes)
2021-12-03 22:28:17,402 [dispatcher-event-loop-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 4.0 in stage 0.0 (TID 4, localhost, executor driver, partition 4, ANY, 7899 bytes)
2021-12-03 22:28:17,402 [dispatcher-event-loop-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 5.0 in stage 0.0 (TID 5, localhost, executor driver, partition 5, ANY, 7899 bytes)
2021-12-03 22:28:17,402 [dispatcher-event-loop-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 6.0 in stage 0.0 (TID 6, localhost, executor driver, partition 6, ANY, 7899 bytes)
2021-12-03 22:28:17,403 [dispatcher-event-loop-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 7.0 in stage 0.0 (TID 7, localhost, executor driver, partition 7, ANY, 7899 bytes)
2021-12-03 22:28:17,403 [dispatcher-event-loop-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 8.0 in stage 0.0 (TID 8, localhost, executor driver, partition 8, ANY, 7899 bytes)
2021-12-03 22:28:17,404 [dispatcher-event-loop-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 9.0 in stage 0.0 (TID 9, localhost, executor driver, partition 9, ANY, 7899 bytes)
2021-12-03 22:28:17,404 [dispatcher-event-loop-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 10.0 in stage 0.0 (TID 10, localhost, executor driver, partition 10, ANY, 7899 bytes)
2021-12-03 22:28:17,405 [dispatcher-event-loop-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 11.0 in stage 0.0 (TID 11, localhost, executor driver, partition 11, ANY, 7899 bytes)
2021-12-03 22:28:17,412 [Executor task launch worker for task 4] INFO [org.apache.spark.executor.Executor] - Running task 4.0 in stage 0.0 (TID 4)
2021-12-03 22:28:17,412 [Executor task launch worker for task 2] INFO [org.apache.spark.executor.Executor] - Running task 2.0 in stage 0.0 (TID 2)
2021-12-03 22:28:17,412 [Executor task launch worker for task 10] INFO [org.apache.spark.executor.Executor] - Running task 10.0 in stage 0.0 (TID 10)
2021-12-03 22:28:17,412 [Executor task launch worker for task 3] INFO [org.apache.spark.executor.Executor] - Running task 3.0 in stage 0.0 (TID 3)
2021-12-03 22:28:17,412 [Executor task launch worker for task 0] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 0.0 (TID 0)
2021-12-03 22:28:17,412 [Executor task launch worker for task 8] INFO [org.apache.spark.executor.Executor] - Running task 8.0 in stage 0.0 (TID 8)
2021-12-03 22:28:17,412 [Executor task launch worker for task 11] INFO [org.apache.spark.executor.Executor] - Running task 11.0 in stage 0.0 (TID 11)
2021-12-03 22:28:17,412 [Executor task launch worker for task 6] INFO [org.apache.spark.executor.Executor] - Running task 6.0 in stage 0.0 (TID 6)
2021-12-03 22:28:17,412 [Executor task launch worker for task 5] INFO [org.apache.spark.executor.Executor] - Running task 5.0 in stage 0.0 (TID 5)
2021-12-03 22:28:17,412 [Executor task launch worker for task 1] INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 0.0 (TID 1)
2021-12-03 22:28:17,412 [Executor task launch worker for task 7] INFO [org.apache.spark.executor.Executor] - Running task 7.0 in stage 0.0 (TID 7)
2021-12-03 22:28:17,412 [Executor task launch worker for task 9] INFO [org.apache.spark.executor.Executor] - Running task 9.0 in stage 0.0 (TID 9)
2021-12-03 22:28:17,461 [Executor task launch worker for task 3] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:402653184+134217728
2021-12-03 22:28:17,462 [Executor task launch worker for task 2] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:268435456+134217728
2021-12-03 22:28:17,461 [Executor task launch worker for task 4] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:536870912+134217728
2021-12-03 22:28:17,462 [Executor task launch worker for task 9] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:1207959552+134217728
2021-12-03 22:28:17,462 [Executor task launch worker for task 11] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:1476395008+134217728
2021-12-03 22:28:17,462 [Executor task launch worker for task 5] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:671088640+134217728
2021-12-03 22:28:17,462 [Executor task launch worker for task 6] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:805306368+134217728
2021-12-03 22:28:17,461 [Executor task launch worker for task 10] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:1342177280+134217728
2021-12-03 22:28:17,461 [Executor task launch worker for task 0] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:0+134217728
2021-12-03 22:28:17,461 [Executor task launch worker for task 8] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:1073741824+134217728
2021-12-03 22:28:17,461 [Executor task launch worker for task 1] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:134217728+134217728
2021-12-03 22:28:17,461 [Executor task launch worker for task 7] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:939524096+134217728
2021-12-03 22:30:02,874 [Executor task launch worker for task 8] INFO [org.apache.spark.executor.Executor] - Finished task 8.0 in stage 0.0 (TID 8). 798 bytes result sent to driver
2021-12-03 22:30:02,876 [dispatcher-event-loop-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 12.0 in stage 0.0 (TID 12, localhost, executor driver, partition 12, ANY, 7899 bytes)
2021-12-03 22:30:02,876 [Executor task launch worker for task 12] INFO [org.apache.spark.executor.Executor] - Running task 12.0 in stage 0.0 (TID 12)
2021-12-03 22:30:02,878 [Executor task launch worker for task 12] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:1610612736+134217728
2021-12-03 22:30:02,885 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 8.0 in stage 0.0 (TID 8) in 105481 ms on localhost (executor driver) (1/22)
2021-12-03 22:30:20,603 [Executor task launch worker for task 4] INFO [org.apache.spark.executor.Executor] - Finished task 4.0 in stage 0.0 (TID 4). 755 bytes result sent to driver
2021-12-03 22:30:20,604 [dispatcher-event-loop-10] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 13.0 in stage 0.0 (TID 13, localhost, executor driver, partition 13, ANY, 7899 bytes)
2021-12-03 22:30:20,604 [Executor task launch worker for task 13] INFO [org.apache.spark.executor.Executor] - Running task 13.0 in stage 0.0 (TID 13)
2021-12-03 22:30:20,606 [Executor task launch worker for task 13] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:1744830464+134217728
2021-12-03 22:30:20,611 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 4.0 in stage 0.0 (TID 4) in 123210 ms on localhost (executor driver) (2/22)
2021-12-03 22:30:27,963 [Executor task launch worker for task 2] INFO [org.apache.spark.executor.Executor] - Finished task 2.0 in stage 0.0 (TID 2). 798 bytes result sent to driver
2021-12-03 22:30:27,967 [dispatcher-event-loop-6] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 14.0 in stage 0.0 (TID 14, localhost, executor driver, partition 14, ANY, 7899 bytes)
2021-12-03 22:30:27,968 [Executor task launch worker for task 14] INFO [org.apache.spark.executor.Executor] - Running task 14.0 in stage 0.0 (TID 14)
2021-12-03 22:30:27,970 [Executor task launch worker for task 14] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:1879048192+134217728
2021-12-03 22:30:27,972 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 2.0 in stage 0.0 (TID 2) in 130572 ms on localhost (executor driver) (3/22)
2021-12-03 22:30:34,159 [Executor task launch worker for task 6] INFO [org.apache.spark.executor.Executor] - Finished task 6.0 in stage 0.0 (TID 6). 798 bytes result sent to driver
2021-12-03 22:30:34,163 [dispatcher-event-loop-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 15.0 in stage 0.0 (TID 15, localhost, executor driver, partition 15, ANY, 7899 bytes)
2021-12-03 22:30:34,163 [Executor task launch worker for task 15] INFO [org.apache.spark.executor.Executor] - Running task 15.0 in stage 0.0 (TID 15)
2021-12-03 22:30:34,166 [Executor task launch worker for task 15] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:2013265920+134217728
2021-12-03 22:30:34,166 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 6.0 in stage 0.0 (TID 6) in 136764 ms on localhost (executor driver) (4/22)
2021-12-03 22:30:45,950 [Executor task launch worker for task 7] INFO [org.apache.spark.executor.Executor] - Finished task 7.0 in stage 0.0 (TID 7). 798 bytes result sent to driver
2021-12-03 22:30:45,950 [dispatcher-event-loop-4] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 16.0 in stage 0.0 (TID 16, localhost, executor driver, partition 16, ANY, 7899 bytes)
2021-12-03 22:30:45,951 [Executor task launch worker for task 16] INFO [org.apache.spark.executor.Executor] - Running task 16.0 in stage 0.0 (TID 16)
2021-12-03 22:30:45,951 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 7.0 in stage 0.0 (TID 7) in 148548 ms on localhost (executor driver) (5/22)
2021-12-03 22:30:45,955 [Executor task launch worker for task 16] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:2147483648+134217728
2021-12-03 22:30:46,493 [Executor task launch worker for task 10] INFO [org.apache.spark.executor.Executor] - Finished task 10.0 in stage 0.0 (TID 10). 798 bytes result sent to driver
2021-12-03 22:30:46,494 [dispatcher-event-loop-10] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 17.0 in stage 0.0 (TID 17, localhost, executor driver, partition 17, ANY, 7899 bytes)
2021-12-03 22:30:46,494 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 10.0 in stage 0.0 (TID 10) in 149090 ms on localhost (executor driver) (6/22)
2021-12-03 22:30:46,494 [Executor task launch worker for task 17] INFO [org.apache.spark.executor.Executor] - Running task 17.0 in stage 0.0 (TID 17)
2021-12-03 22:30:46,498 [Executor task launch worker for task 17] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:2281701376+134217728
2021-12-03 22:30:46,604 [Executor task launch worker for task 3] INFO [org.apache.spark.executor.Executor] - Finished task 3.0 in stage 0.0 (TID 3). 798 bytes result sent to driver
2021-12-03 22:30:46,605 [dispatcher-event-loop-6] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 18.0 in stage 0.0 (TID 18, localhost, executor driver, partition 18, ANY, 7899 bytes)
2021-12-03 22:30:46,605 [Executor task launch worker for task 18] INFO [org.apache.spark.executor.Executor] - Running task 18.0 in stage 0.0 (TID 18)
2021-12-03 22:30:46,605 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 3.0 in stage 0.0 (TID 3) in 149204 ms on localhost (executor driver) (7/22)
2021-12-03 22:30:46,606 [Executor task launch worker for task 18] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:2415919104+134217728
2021-12-03 22:30:46,646 [Executor task launch worker for task 11] INFO [org.apache.spark.executor.Executor] - Finished task 11.0 in stage 0.0 (TID 11). 798 bytes result sent to driver
2021-12-03 22:30:46,647 [dispatcher-event-loop-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 19.0 in stage 0.0 (TID 19, localhost, executor driver, partition 19, ANY, 7899 bytes)
2021-12-03 22:30:46,647 [Executor task launch worker for task 19] INFO [org.apache.spark.executor.Executor] - Running task 19.0 in stage 0.0 (TID 19)
2021-12-03 22:30:46,647 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 11.0 in stage 0.0 (TID 11) in 149243 ms on localhost (executor driver) (8/22)
2021-12-03 22:30:46,648 [Executor task launch worker for task 19] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:2550136832+134217728
2021-12-03 22:30:47,645 [Executor task launch worker for task 1] INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 0.0 (TID 1). 798 bytes result sent to driver
2021-12-03 22:30:47,645 [dispatcher-event-loop-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 20.0 in stage 0.0 (TID 20, localhost, executor driver, partition 20, ANY, 7899 bytes)
2021-12-03 22:30:47,645 [Executor task launch worker for task 20] INFO [org.apache.spark.executor.Executor] - Running task 20.0 in stage 0.0 (TID 20)
2021-12-03 22:30:47,645 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 0.0 (TID 1) in 150245 ms on localhost (executor driver) (9/22)
2021-12-03 22:30:47,646 [Executor task launch worker for task 20] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:2684354560+134217728
2021-12-03 22:30:53,895 [Executor task launch worker for task 0] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 0.0 (TID 0). 798 bytes result sent to driver
2021-12-03 22:30:53,895 [dispatcher-event-loop-4] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 21.0 in stage 0.0 (TID 21, localhost, executor driver, partition 21, ANY, 7899 bytes)
2021-12-03 22:30:53,895 [Executor task launch worker for task 21] INFO [org.apache.spark.executor.Executor] - Running task 21.0 in stage 0.0 (TID 21)
2021-12-03 22:30:53,895 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 0.0 (TID 0) in 156507 ms on localhost (executor driver) (10/22)
2021-12-03 22:30:53,896 [Executor task launch worker for task 21] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:2818572288+147216171
2021-12-03 22:30:57,897 [Executor task launch worker for task 5] INFO [org.apache.spark.executor.Executor] - Finished task 5.0 in stage 0.0 (TID 5). 755 bytes result sent to driver
2021-12-03 22:30:57,902 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 5.0 in stage 0.0 (TID 5) in 160500 ms on localhost (executor driver) (11/22)
2021-12-03 22:30:59,141 [Executor task launch worker for task 9] INFO [org.apache.spark.executor.Executor] - Finished task 9.0 in stage 0.0 (TID 9). 798 bytes result sent to driver
2021-12-03 22:30:59,141 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 9.0 in stage 0.0 (TID 9) in 161738 ms on localhost (executor driver) (12/22)
2021-12-03 22:31:53,187 [Executor task launch worker for task 15] INFO [org.apache.spark.executor.Executor] - Finished task 15.0 in stage 0.0 (TID 15). 755 bytes result sent to driver
2021-12-03 22:31:53,187 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 15.0 in stage 0.0 (TID 15) in 79027 ms on localhost (executor driver) (13/22)
2021-12-03 22:32:06,327 [Executor task launch worker for task 14] INFO [org.apache.spark.executor.Executor] - Finished task 14.0 in stage 0.0 (TID 14). 755 bytes result sent to driver
2021-12-03 22:32:06,327 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 14.0 in stage 0.0 (TID 14) in 98363 ms on localhost (executor driver) (14/22)
2021-12-03 22:32:06,551 [Executor task launch worker for task 13] INFO [org.apache.spark.executor.Executor] - Finished task 13.0 in stage 0.0 (TID 13). 755 bytes result sent to driver
2021-12-03 22:32:06,552 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 13.0 in stage 0.0 (TID 13) in 105948 ms on localhost (executor driver) (15/22)
2021-12-03 22:32:16,258 [Executor task launch worker for task 12] INFO [org.apache.spark.executor.Executor] - Finished task 12.0 in stage 0.0 (TID 12). 755 bytes result sent to driver
2021-12-03 22:32:16,262 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 12.0 in stage 0.0 (TID 12) in 133387 ms on localhost (executor driver) (16/22)
2021-12-03 22:32:20,497 [Executor task launch worker for task 20] INFO [org.apache.spark.executor.Executor] - Finished task 20.0 in stage 0.0 (TID 20). 755 bytes result sent to driver
2021-12-03 22:32:20,497 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 20.0 in stage 0.0 (TID 20) in 92852 ms on localhost (executor driver) (17/22)
2021-12-03 22:32:22,100 [Executor task launch worker for task 21] INFO [org.apache.spark.executor.Executor] - Finished task 21.0 in stage 0.0 (TID 21). 755 bytes result sent to driver
2021-12-03 22:32:22,100 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 21.0 in stage 0.0 (TID 21) in 88205 ms on localhost (executor driver) (18/22)
2021-12-03 22:32:30,654 [Executor task launch worker for task 19] INFO [org.apache.spark.executor.Executor] - Finished task 19.0 in stage 0.0 (TID 19). 755 bytes result sent to driver
2021-12-03 22:32:30,654 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 19.0 in stage 0.0 (TID 19) in 104008 ms on localhost (executor driver) (19/22)
2021-12-03 22:32:31,836 [Executor task launch worker for task 17] INFO [org.apache.spark.executor.Executor] - Finished task 17.0 in stage 0.0 (TID 17). 798 bytes result sent to driver
2021-12-03 22:32:31,837 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 17.0 in stage 0.0 (TID 17) in 105344 ms on localhost (executor driver) (20/22)
2021-12-03 22:32:32,973 [Executor task launch worker for task 18] INFO [org.apache.spark.executor.Executor] - Finished task 18.0 in stage 0.0 (TID 18). 712 bytes result sent to driver
2021-12-03 22:32:32,973 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 18.0 in stage 0.0 (TID 18) in 106368 ms on localhost (executor driver) (21/22)
2021-12-03 22:32:33,337 [Executor task launch worker for task 16] INFO [org.apache.spark.executor.Executor] - Finished task 16.0 in stage 0.0 (TID 16). 712 bytes result sent to driver
2021-12-03 22:32:33,338 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 16.0 in stage 0.0 (TID 16) in 107388 ms on localhost (executor driver) (22/22)
2021-12-03 22:32:33,344 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 0.0, whose tasks have all completed, from pool 
2021-12-03 22:32:33,344 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 0 (count at PaidPromotionAdjustParameter.scala:59) finished in 256.009 s
2021-12-03 22:32:33,349 [main] INFO [org.apache.spark.scheduler.DAGScheduler] - Job 0 finished: count at PaidPromotionAdjustParameter.scala:59, took 256.051172 s
2021-12-03 22:32:33,350 [main] INFO [PaidPromotion$] - 收视总数68489201
2021-12-03 22:32:33,521 [main] INFO [org.apache.spark.SparkContext] - Starting job: count at PaidPromotionAdjustParameter.scala:68
2021-12-03 22:32:33,529 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 3 (map at PaidPromotionAdjustParameter.scala:67)
2021-12-03 22:32:33,529 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 1 (count at PaidPromotionAdjustParameter.scala:68) with 22 output partitions
2021-12-03 22:32:33,529 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 2 (count at PaidPromotionAdjustParameter.scala:68)
2021-12-03 22:32:33,530 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 1)
2021-12-03 22:32:33,530 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List(ShuffleMapStage 1)
2021-12-03 22:32:33,531 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ShuffleMapStage 1 (MapPartitionsRDD[3] at map at PaidPromotionAdjustParameter.scala:67), which has no missing parents
2021-12-03 22:32:33,543 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_2 stored as values in memory (estimated size 4.7 KB, free 1990.5 MB)
2021-12-03 22:32:33,545 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_2_piece0 stored as bytes in memory (estimated size 2.7 KB, free 1990.5 MB)
2021-12-03 22:32:33,546 [dispatcher-event-loop-4] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_2_piece0 in memory on qb:59961 (size: 2.7 KB, free: 1990.8 MB)
2021-12-03 22:32:33,546 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 2 from broadcast at DAGScheduler.scala:1039
2021-12-03 22:32:33,548 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 22 missing tasks from ShuffleMapStage 1 (MapPartitionsRDD[3] at map at PaidPromotionAdjustParameter.scala:67) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14))
2021-12-03 22:32:33,548 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 1.0 with 22 tasks
2021-12-03 22:32:33,550 [dispatcher-event-loop-9] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 1.0 (TID 22, localhost, executor driver, partition 0, ANY, 7888 bytes)
2021-12-03 22:32:33,550 [dispatcher-event-loop-9] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 1.0 (TID 23, localhost, executor driver, partition 1, ANY, 7888 bytes)
2021-12-03 22:32:33,550 [dispatcher-event-loop-9] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 2.0 in stage 1.0 (TID 24, localhost, executor driver, partition 2, ANY, 7888 bytes)
2021-12-03 22:32:33,550 [dispatcher-event-loop-9] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 3.0 in stage 1.0 (TID 25, localhost, executor driver, partition 3, ANY, 7888 bytes)
2021-12-03 22:32:33,551 [dispatcher-event-loop-9] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 4.0 in stage 1.0 (TID 26, localhost, executor driver, partition 4, ANY, 7888 bytes)
2021-12-03 22:32:33,551 [dispatcher-event-loop-9] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 5.0 in stage 1.0 (TID 27, localhost, executor driver, partition 5, ANY, 7888 bytes)
2021-12-03 22:32:33,551 [dispatcher-event-loop-9] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 6.0 in stage 1.0 (TID 28, localhost, executor driver, partition 6, ANY, 7888 bytes)
2021-12-03 22:32:33,551 [dispatcher-event-loop-9] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 7.0 in stage 1.0 (TID 29, localhost, executor driver, partition 7, ANY, 7888 bytes)
2021-12-03 22:32:33,551 [dispatcher-event-loop-9] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 8.0 in stage 1.0 (TID 30, localhost, executor driver, partition 8, ANY, 7888 bytes)
2021-12-03 22:32:33,552 [dispatcher-event-loop-9] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 9.0 in stage 1.0 (TID 31, localhost, executor driver, partition 9, ANY, 7888 bytes)
2021-12-03 22:32:33,552 [dispatcher-event-loop-9] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 10.0 in stage 1.0 (TID 32, localhost, executor driver, partition 10, ANY, 7888 bytes)
2021-12-03 22:32:33,552 [dispatcher-event-loop-9] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 11.0 in stage 1.0 (TID 33, localhost, executor driver, partition 11, ANY, 7888 bytes)
2021-12-03 22:32:33,552 [Executor task launch worker for task 22] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 1.0 (TID 22)
2021-12-03 22:32:33,552 [Executor task launch worker for task 27] INFO [org.apache.spark.executor.Executor] - Running task 5.0 in stage 1.0 (TID 27)
2021-12-03 22:32:33,552 [Executor task launch worker for task 31] INFO [org.apache.spark.executor.Executor] - Running task 9.0 in stage 1.0 (TID 31)
2021-12-03 22:32:33,552 [Executor task launch worker for task 30] INFO [org.apache.spark.executor.Executor] - Running task 8.0 in stage 1.0 (TID 30)
2021-12-03 22:32:33,552 [Executor task launch worker for task 26] INFO [org.apache.spark.executor.Executor] - Running task 4.0 in stage 1.0 (TID 26)
2021-12-03 22:32:33,552 [Executor task launch worker for task 24] INFO [org.apache.spark.executor.Executor] - Running task 2.0 in stage 1.0 (TID 24)
2021-12-03 22:32:33,552 [Executor task launch worker for task 28] INFO [org.apache.spark.executor.Executor] - Running task 6.0 in stage 1.0 (TID 28)
2021-12-03 22:32:33,552 [Executor task launch worker for task 25] INFO [org.apache.spark.executor.Executor] - Running task 3.0 in stage 1.0 (TID 25)
2021-12-03 22:32:33,552 [Executor task launch worker for task 23] INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 1.0 (TID 23)
2021-12-03 22:32:33,552 [Executor task launch worker for task 29] INFO [org.apache.spark.executor.Executor] - Running task 7.0 in stage 1.0 (TID 29)
2021-12-03 22:32:33,556 [Executor task launch worker for task 32] INFO [org.apache.spark.executor.Executor] - Running task 10.0 in stage 1.0 (TID 32)
2021-12-03 22:32:33,557 [Executor task launch worker for task 33] INFO [org.apache.spark.executor.Executor] - Running task 11.0 in stage 1.0 (TID 33)
2021-12-03 22:32:33,557 [Executor task launch worker for task 23] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:134217728+134217728
2021-12-03 22:32:33,557 [Executor task launch worker for task 29] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:939524096+134217728
2021-12-03 22:32:33,557 [Executor task launch worker for task 30] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:1073741824+134217728
2021-12-03 22:32:33,557 [Executor task launch worker for task 25] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:402653184+134217728
2021-12-03 22:32:33,557 [Executor task launch worker for task 27] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:671088640+134217728
2021-12-03 22:32:33,557 [Executor task launch worker for task 31] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:1207959552+134217728
2021-12-03 22:32:33,557 [Executor task launch worker for task 22] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:0+134217728
2021-12-03 22:32:33,557 [Executor task launch worker for task 28] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:805306368+134217728
2021-12-03 22:32:33,557 [Executor task launch worker for task 24] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:268435456+134217728
2021-12-03 22:32:33,557 [Executor task launch worker for task 26] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:536870912+134217728
2021-12-03 22:32:33,558 [Executor task launch worker for task 33] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:1476395008+134217728
2021-12-03 22:32:33,558 [Executor task launch worker for task 32] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:1342177280+134217728
2021-12-03 22:34:32,647 [Executor task launch worker for task 27] INFO [org.apache.spark.executor.Executor] - Finished task 5.0 in stage 1.0 (TID 27). 1052 bytes result sent to driver
2021-12-03 22:34:32,647 [dispatcher-event-loop-11] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 12.0 in stage 1.0 (TID 34, localhost, executor driver, partition 12, ANY, 7888 bytes)
2021-12-03 22:34:32,648 [Executor task launch worker for task 34] INFO [org.apache.spark.executor.Executor] - Running task 12.0 in stage 1.0 (TID 34)
2021-12-03 22:34:32,649 [Executor task launch worker for task 34] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:1610612736+134217728
2021-12-03 22:34:32,663 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 5.0 in stage 1.0 (TID 27) in 119112 ms on localhost (executor driver) (1/22)
2021-12-03 22:34:34,867 [Executor task launch worker for task 31] INFO [org.apache.spark.executor.Executor] - Finished task 9.0 in stage 1.0 (TID 31). 1052 bytes result sent to driver
2021-12-03 22:34:34,868 [dispatcher-event-loop-9] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 13.0 in stage 1.0 (TID 35, localhost, executor driver, partition 13, ANY, 7888 bytes)
2021-12-03 22:34:34,868 [Executor task launch worker for task 35] INFO [org.apache.spark.executor.Executor] - Running task 13.0 in stage 1.0 (TID 35)
2021-12-03 22:34:34,868 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 9.0 in stage 1.0 (TID 31) in 121317 ms on localhost (executor driver) (2/22)
2021-12-03 22:34:34,869 [Executor task launch worker for task 35] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:1744830464+134217728
2021-12-03 22:34:38,847 [Executor task launch worker for task 33] INFO [org.apache.spark.executor.Executor] - Finished task 11.0 in stage 1.0 (TID 33). 1009 bytes result sent to driver
2021-12-03 22:34:38,847 [dispatcher-event-loop-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 14.0 in stage 1.0 (TID 36, localhost, executor driver, partition 14, ANY, 7888 bytes)
2021-12-03 22:34:38,847 [Executor task launch worker for task 36] INFO [org.apache.spark.executor.Executor] - Running task 14.0 in stage 1.0 (TID 36)
2021-12-03 22:34:38,848 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 11.0 in stage 1.0 (TID 33) in 125296 ms on localhost (executor driver) (3/22)
2021-12-03 22:34:38,848 [Executor task launch worker for task 36] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:1879048192+134217728
2021-12-03 22:34:41,927 [Executor task launch worker for task 23] INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 1.0 (TID 23). 1052 bytes result sent to driver
2021-12-03 22:34:41,928 [dispatcher-event-loop-10] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 15.0 in stage 1.0 (TID 37, localhost, executor driver, partition 15, ANY, 7888 bytes)
2021-12-03 22:34:41,928 [Executor task launch worker for task 37] INFO [org.apache.spark.executor.Executor] - Running task 15.0 in stage 1.0 (TID 37)
2021-12-03 22:34:41,928 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 1.0 (TID 23) in 128378 ms on localhost (executor driver) (4/22)
2021-12-03 22:34:41,933 [Executor task launch worker for task 37] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:2013265920+134217728
2021-12-03 22:34:52,227 [Executor task launch worker for task 22] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 1.0 (TID 22). 1052 bytes result sent to driver
2021-12-03 22:34:52,228 [dispatcher-event-loop-11] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 16.0 in stage 1.0 (TID 38, localhost, executor driver, partition 16, ANY, 7888 bytes)
2021-12-03 22:34:52,228 [Executor task launch worker for task 38] INFO [org.apache.spark.executor.Executor] - Running task 16.0 in stage 1.0 (TID 38)
2021-12-03 22:34:52,228 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 1.0 (TID 22) in 138679 ms on localhost (executor driver) (5/22)
2021-12-03 22:34:52,229 [Executor task launch worker for task 38] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:2147483648+134217728
2021-12-03 22:34:54,365 [Executor task launch worker for task 32] INFO [org.apache.spark.executor.Executor] - Finished task 10.0 in stage 1.0 (TID 32). 1052 bytes result sent to driver
2021-12-03 22:34:54,366 [dispatcher-event-loop-9] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 17.0 in stage 1.0 (TID 39, localhost, executor driver, partition 17, ANY, 7888 bytes)
2021-12-03 22:34:54,366 [Executor task launch worker for task 39] INFO [org.apache.spark.executor.Executor] - Running task 17.0 in stage 1.0 (TID 39)
2021-12-03 22:34:54,366 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 10.0 in stage 1.0 (TID 32) in 140814 ms on localhost (executor driver) (6/22)
2021-12-03 22:34:54,367 [Executor task launch worker for task 39] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:2281701376+134217728
2021-12-03 22:34:56,526 [Executor task launch worker for task 30] INFO [org.apache.spark.executor.Executor] - Finished task 8.0 in stage 1.0 (TID 30). 1052 bytes result sent to driver
2021-12-03 22:34:56,526 [dispatcher-event-loop-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 18.0 in stage 1.0 (TID 40, localhost, executor driver, partition 18, ANY, 7888 bytes)
2021-12-03 22:34:56,526 [Executor task launch worker for task 40] INFO [org.apache.spark.executor.Executor] - Running task 18.0 in stage 1.0 (TID 40)
2021-12-03 22:34:56,527 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 8.0 in stage 1.0 (TID 30) in 142975 ms on localhost (executor driver) (7/22)
2021-12-03 22:34:56,527 [Executor task launch worker for task 40] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:2415919104+134217728
2021-12-03 22:34:59,237 [Executor task launch worker for task 24] INFO [org.apache.spark.executor.Executor] - Finished task 2.0 in stage 1.0 (TID 24). 1052 bytes result sent to driver
2021-12-03 22:34:59,237 [dispatcher-event-loop-7] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 19.0 in stage 1.0 (TID 41, localhost, executor driver, partition 19, ANY, 7888 bytes)
2021-12-03 22:34:59,237 [Executor task launch worker for task 41] INFO [org.apache.spark.executor.Executor] - Running task 19.0 in stage 1.0 (TID 41)
2021-12-03 22:34:59,237 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 2.0 in stage 1.0 (TID 24) in 145687 ms on localhost (executor driver) (8/22)
2021-12-03 22:34:59,238 [Executor task launch worker for task 41] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:2550136832+134217728
2021-12-03 22:35:03,627 [Executor task launch worker for task 26] INFO [org.apache.spark.executor.Executor] - Finished task 4.0 in stage 1.0 (TID 26). 1052 bytes result sent to driver
2021-12-03 22:35:03,628 [dispatcher-event-loop-5] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 20.0 in stage 1.0 (TID 42, localhost, executor driver, partition 20, ANY, 7888 bytes)
2021-12-03 22:35:03,628 [Executor task launch worker for task 42] INFO [org.apache.spark.executor.Executor] - Running task 20.0 in stage 1.0 (TID 42)
2021-12-03 22:35:03,628 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 4.0 in stage 1.0 (TID 26) in 150078 ms on localhost (executor driver) (9/22)
2021-12-03 22:35:03,629 [Executor task launch worker for task 42] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:2684354560+134217728
2021-12-03 22:35:10,056 [Executor task launch worker for task 25] INFO [org.apache.spark.executor.Executor] - Finished task 3.0 in stage 1.0 (TID 25). 1052 bytes result sent to driver
2021-12-03 22:35:10,056 [dispatcher-event-loop-11] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 21.0 in stage 1.0 (TID 43, localhost, executor driver, partition 21, ANY, 7888 bytes)
2021-12-03 22:35:10,057 [Executor task launch worker for task 43] INFO [org.apache.spark.executor.Executor] - Running task 21.0 in stage 1.0 (TID 43)
2021-12-03 22:35:10,057 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 3.0 in stage 1.0 (TID 25) in 156507 ms on localhost (executor driver) (10/22)
2021-12-03 22:35:10,058 [Executor task launch worker for task 43] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:2818572288+147216171
2021-12-03 22:35:13,046 [Executor task launch worker for task 28] INFO [org.apache.spark.executor.Executor] - Finished task 6.0 in stage 1.0 (TID 28). 1052 bytes result sent to driver
2021-12-03 22:35:13,047 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 6.0 in stage 1.0 (TID 28) in 159496 ms on localhost (executor driver) (11/22)
2021-12-03 22:35:15,277 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 19
2021-12-03 22:35:15,277 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 23
2021-12-03 22:35:15,277 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 0
2021-12-03 22:35:15,277 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 11
2021-12-03 22:35:15,277 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1
2021-12-03 22:35:15,288 [dispatcher-event-loop-8] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_1_piece0 on qb:59961 in memory (size: 1903.0 B, free: 1990.8 MB)
2021-12-03 22:35:15,290 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 7
2021-12-03 22:35:15,290 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 20
2021-12-03 22:35:15,290 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 2
2021-12-03 22:35:15,290 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 21
2021-12-03 22:35:15,290 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 4
2021-12-03 22:35:15,290 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 13
2021-12-03 22:35:15,290 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 14
2021-12-03 22:35:15,290 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 16
2021-12-03 22:35:15,290 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 18
2021-12-03 22:35:15,290 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 3
2021-12-03 22:35:15,290 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 22
2021-12-03 22:35:15,290 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 9
2021-12-03 22:35:15,290 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 6
2021-12-03 22:35:15,290 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 17
2021-12-03 22:35:15,290 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 24
2021-12-03 22:35:15,290 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 5
2021-12-03 22:35:15,290 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 8
2021-12-03 22:35:15,290 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 15
2021-12-03 22:35:15,290 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 10
2021-12-03 22:35:15,290 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 12
2021-12-03 22:35:28,285 [Executor task launch worker for task 29] INFO [org.apache.spark.executor.Executor] - Finished task 7.0 in stage 1.0 (TID 29). 1052 bytes result sent to driver
2021-12-03 22:35:28,286 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 7.0 in stage 1.0 (TID 29) in 174735 ms on localhost (executor driver) (12/22)
2021-12-03 22:36:23,989 [Executor task launch worker for task 39] INFO [org.apache.spark.executor.Executor] - Finished task 17.0 in stage 1.0 (TID 39). 1052 bytes result sent to driver
2021-12-03 22:36:23,989 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 17.0 in stage 1.0 (TID 39) in 89623 ms on localhost (executor driver) (13/22)
2021-12-03 22:36:35,969 [Executor task launch worker for task 36] INFO [org.apache.spark.executor.Executor] - Finished task 14.0 in stage 1.0 (TID 36). 1052 bytes result sent to driver
2021-12-03 22:36:35,969 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 14.0 in stage 1.0 (TID 36) in 117122 ms on localhost (executor driver) (14/22)
2021-12-03 22:36:37,565 [Executor task launch worker for task 40] INFO [org.apache.spark.executor.Executor] - Finished task 18.0 in stage 1.0 (TID 40). 1052 bytes result sent to driver
2021-12-03 22:36:37,566 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 18.0 in stage 1.0 (TID 40) in 101040 ms on localhost (executor driver) (15/22)
2021-12-03 22:36:38,147 [Executor task launch worker for task 37] INFO [org.apache.spark.executor.Executor] - Finished task 15.0 in stage 1.0 (TID 37). 1052 bytes result sent to driver
2021-12-03 22:36:38,147 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 15.0 in stage 1.0 (TID 37) in 116219 ms on localhost (executor driver) (16/22)
2021-12-03 22:36:43,081 [Executor task launch worker for task 38] INFO [org.apache.spark.executor.Executor] - Finished task 16.0 in stage 1.0 (TID 38). 1052 bytes result sent to driver
2021-12-03 22:36:43,081 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 16.0 in stage 1.0 (TID 38) in 110853 ms on localhost (executor driver) (17/22)
2021-12-03 22:36:46,427 [Executor task launch worker for task 41] INFO [org.apache.spark.executor.Executor] - Finished task 19.0 in stage 1.0 (TID 41). 1052 bytes result sent to driver
2021-12-03 22:36:46,427 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 19.0 in stage 1.0 (TID 41) in 107190 ms on localhost (executor driver) (18/22)
2021-12-03 22:36:46,843 [Executor task launch worker for task 42] INFO [org.apache.spark.executor.Executor] - Finished task 20.0 in stage 1.0 (TID 42). 1052 bytes result sent to driver
2021-12-03 22:36:46,843 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 20.0 in stage 1.0 (TID 42) in 103215 ms on localhost (executor driver) (19/22)
2021-12-03 22:36:48,800 [Executor task launch worker for task 34] INFO [org.apache.spark.executor.Executor] - Finished task 12.0 in stage 1.0 (TID 34). 1052 bytes result sent to driver
2021-12-03 22:36:48,801 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 12.0 in stage 1.0 (TID 34) in 136154 ms on localhost (executor driver) (20/22)
2021-12-03 22:36:49,859 [Executor task launch worker for task 35] INFO [org.apache.spark.executor.Executor] - Finished task 13.0 in stage 1.0 (TID 35). 1052 bytes result sent to driver
2021-12-03 22:36:49,860 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 13.0 in stage 1.0 (TID 35) in 134991 ms on localhost (executor driver) (21/22)
2021-12-03 22:36:49,929 [Executor task launch worker for task 43] INFO [org.apache.spark.executor.Executor] - Finished task 21.0 in stage 1.0 (TID 43). 1009 bytes result sent to driver
2021-12-03 22:36:49,929 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 21.0 in stage 1.0 (TID 43) in 99873 ms on localhost (executor driver) (22/22)
2021-12-03 22:36:49,929 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 1.0, whose tasks have all completed, from pool 
2021-12-03 22:36:49,929 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ShuffleMapStage 1 (map at PaidPromotionAdjustParameter.scala:67) finished in 256.393 s
2021-12-03 22:36:49,933 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - looking for newly runnable stages
2021-12-03 22:36:49,933 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - running: Set()
2021-12-03 22:36:49,934 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - waiting: Set(ResultStage 2)
2021-12-03 22:36:49,934 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - failed: Set()
2021-12-03 22:36:49,936 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 2 (ShuffledRDD[4] at reduceByKey at PaidPromotionAdjustParameter.scala:67), which has no missing parents
2021-12-03 22:36:49,942 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_3 stored as values in memory (estimated size 3.0 KB, free 1990.5 MB)
2021-12-03 22:36:49,943 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_3_piece0 stored as bytes in memory (estimated size 1906.0 B, free 1990.5 MB)
2021-12-03 22:36:49,943 [dispatcher-event-loop-1] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_3_piece0 in memory on qb:59961 (size: 1906.0 B, free: 1990.8 MB)
2021-12-03 22:36:49,944 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 3 from broadcast at DAGScheduler.scala:1039
2021-12-03 22:36:49,944 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 22 missing tasks from ResultStage 2 (ShuffledRDD[4] at reduceByKey at PaidPromotionAdjustParameter.scala:67) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14))
2021-12-03 22:36:49,944 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 2.0 with 22 tasks
2021-12-03 22:36:49,945 [dispatcher-event-loop-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 2.0 (TID 44, localhost, executor driver, partition 0, ANY, 7649 bytes)
2021-12-03 22:36:49,945 [dispatcher-event-loop-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 2.0 (TID 45, localhost, executor driver, partition 1, ANY, 7649 bytes)
2021-12-03 22:36:49,945 [dispatcher-event-loop-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 2.0 in stage 2.0 (TID 46, localhost, executor driver, partition 2, ANY, 7649 bytes)
2021-12-03 22:36:49,945 [dispatcher-event-loop-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 3.0 in stage 2.0 (TID 47, localhost, executor driver, partition 3, ANY, 7649 bytes)
2021-12-03 22:36:49,945 [dispatcher-event-loop-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 4.0 in stage 2.0 (TID 48, localhost, executor driver, partition 4, ANY, 7649 bytes)
2021-12-03 22:36:49,946 [dispatcher-event-loop-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 5.0 in stage 2.0 (TID 49, localhost, executor driver, partition 5, ANY, 7649 bytes)
2021-12-03 22:36:49,946 [dispatcher-event-loop-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 6.0 in stage 2.0 (TID 50, localhost, executor driver, partition 6, ANY, 7649 bytes)
2021-12-03 22:36:49,946 [dispatcher-event-loop-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 7.0 in stage 2.0 (TID 51, localhost, executor driver, partition 7, ANY, 7649 bytes)
2021-12-03 22:36:49,946 [dispatcher-event-loop-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 8.0 in stage 2.0 (TID 52, localhost, executor driver, partition 8, ANY, 7649 bytes)
2021-12-03 22:36:49,946 [dispatcher-event-loop-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 9.0 in stage 2.0 (TID 53, localhost, executor driver, partition 9, ANY, 7649 bytes)
2021-12-03 22:36:49,946 [dispatcher-event-loop-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 10.0 in stage 2.0 (TID 54, localhost, executor driver, partition 10, ANY, 7649 bytes)
2021-12-03 22:36:49,946 [dispatcher-event-loop-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 11.0 in stage 2.0 (TID 55, localhost, executor driver, partition 11, ANY, 7649 bytes)
2021-12-03 22:36:49,946 [Executor task launch worker for task 46] INFO [org.apache.spark.executor.Executor] - Running task 2.0 in stage 2.0 (TID 46)
2021-12-03 22:36:49,946 [Executor task launch worker for task 51] INFO [org.apache.spark.executor.Executor] - Running task 7.0 in stage 2.0 (TID 51)
2021-12-03 22:36:49,946 [Executor task launch worker for task 53] INFO [org.apache.spark.executor.Executor] - Running task 9.0 in stage 2.0 (TID 53)
2021-12-03 22:36:49,946 [Executor task launch worker for task 49] INFO [org.apache.spark.executor.Executor] - Running task 5.0 in stage 2.0 (TID 49)
2021-12-03 22:36:49,946 [Executor task launch worker for task 45] INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 2.0 (TID 45)
2021-12-03 22:36:49,946 [Executor task launch worker for task 44] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 2.0 (TID 44)
2021-12-03 22:36:49,946 [Executor task launch worker for task 50] INFO [org.apache.spark.executor.Executor] - Running task 6.0 in stage 2.0 (TID 50)
2021-12-03 22:36:49,946 [Executor task launch worker for task 48] INFO [org.apache.spark.executor.Executor] - Running task 4.0 in stage 2.0 (TID 48)
2021-12-03 22:36:49,946 [Executor task launch worker for task 52] INFO [org.apache.spark.executor.Executor] - Running task 8.0 in stage 2.0 (TID 52)
2021-12-03 22:36:49,946 [Executor task launch worker for task 47] INFO [org.apache.spark.executor.Executor] - Running task 3.0 in stage 2.0 (TID 47)
2021-12-03 22:36:49,947 [Executor task launch worker for task 54] INFO [org.apache.spark.executor.Executor] - Running task 10.0 in stage 2.0 (TID 54)
2021-12-03 22:36:49,947 [Executor task launch worker for task 55] INFO [org.apache.spark.executor.Executor] - Running task 11.0 in stage 2.0 (TID 55)
2021-12-03 22:36:49,959 [Executor task launch worker for task 55] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 22:36:49,959 [Executor task launch worker for task 53] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 22:36:49,959 [Executor task launch worker for task 50] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 22:36:49,959 [Executor task launch worker for task 52] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 22:36:49,959 [Executor task launch worker for task 51] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 22:36:49,959 [Executor task launch worker for task 49] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 22:36:49,959 [Executor task launch worker for task 44] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 22:36:49,959 [Executor task launch worker for task 54] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 22:36:49,959 [Executor task launch worker for task 46] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 22:36:49,959 [Executor task launch worker for task 47] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 22:36:49,959 [Executor task launch worker for task 48] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 22:36:49,959 [Executor task launch worker for task 45] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 22:36:49,960 [Executor task launch worker for task 44] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 5 ms
2021-12-03 22:36:49,960 [Executor task launch worker for task 49] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 5 ms
2021-12-03 22:36:49,960 [Executor task launch worker for task 48] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 5 ms
2021-12-03 22:36:49,960 [Executor task launch worker for task 52] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 5 ms
2021-12-03 22:36:49,960 [Executor task launch worker for task 54] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 5 ms
2021-12-03 22:36:49,960 [Executor task launch worker for task 51] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 5 ms
2021-12-03 22:36:49,960 [Executor task launch worker for task 50] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 5 ms
2021-12-03 22:36:49,960 [Executor task launch worker for task 53] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 5 ms
2021-12-03 22:36:49,960 [Executor task launch worker for task 55] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 5 ms
2021-12-03 22:36:49,960 [Executor task launch worker for task 45] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 5 ms
2021-12-03 22:36:49,960 [Executor task launch worker for task 47] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 5 ms
2021-12-03 22:36:49,960 [Executor task launch worker for task 46] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 5 ms
2021-12-03 22:36:50,341 [Executor task launch worker for task 45] INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 2.0 (TID 45). 1055 bytes result sent to driver
2021-12-03 22:36:50,342 [Executor task launch worker for task 53] INFO [org.apache.spark.executor.Executor] - Finished task 9.0 in stage 2.0 (TID 53). 1055 bytes result sent to driver
2021-12-03 22:36:50,342 [dispatcher-event-loop-7] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 12.0 in stage 2.0 (TID 56, localhost, executor driver, partition 12, ANY, 7649 bytes)
2021-12-03 22:36:50,342 [dispatcher-event-loop-7] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 13.0 in stage 2.0 (TID 57, localhost, executor driver, partition 13, ANY, 7649 bytes)
2021-12-03 22:36:50,343 [Executor task launch worker for task 56] INFO [org.apache.spark.executor.Executor] - Running task 12.0 in stage 2.0 (TID 56)
2021-12-03 22:36:50,344 [Executor task launch worker for task 56] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 22:36:50,344 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 9.0 in stage 2.0 (TID 53) in 398 ms on localhost (executor driver) (1/22)
2021-12-03 22:36:50,344 [Executor task launch worker for task 56] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 1 ms
2021-12-03 22:36:50,344 [Executor task launch worker for task 57] INFO [org.apache.spark.executor.Executor] - Running task 13.0 in stage 2.0 (TID 57)
2021-12-03 22:36:50,344 [Executor task launch worker for task 51] INFO [org.apache.spark.executor.Executor] - Finished task 7.0 in stage 2.0 (TID 51). 1055 bytes result sent to driver
2021-12-03 22:36:50,345 [Executor task launch worker for task 57] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 22:36:50,345 [Executor task launch worker for task 57] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 22:36:50,346 [dispatcher-event-loop-4] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 14.0 in stage 2.0 (TID 58, localhost, executor driver, partition 14, ANY, 7649 bytes)
2021-12-03 22:36:50,347 [Executor task launch worker for task 58] INFO [org.apache.spark.executor.Executor] - Running task 14.0 in stage 2.0 (TID 58)
2021-12-03 22:36:50,347 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 2.0 (TID 45) in 402 ms on localhost (executor driver) (2/22)
2021-12-03 22:36:50,348 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 7.0 in stage 2.0 (TID 51) in 402 ms on localhost (executor driver) (3/22)
2021-12-03 22:36:50,348 [Executor task launch worker for task 58] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 22:36:50,348 [Executor task launch worker for task 58] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 22:36:50,350 [Executor task launch worker for task 48] INFO [org.apache.spark.executor.Executor] - Finished task 4.0 in stage 2.0 (TID 48). 1055 bytes result sent to driver
2021-12-03 22:36:50,351 [dispatcher-event-loop-6] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 15.0 in stage 2.0 (TID 59, localhost, executor driver, partition 15, ANY, 7649 bytes)
2021-12-03 22:36:50,352 [Executor task launch worker for task 52] INFO [org.apache.spark.executor.Executor] - Finished task 8.0 in stage 2.0 (TID 52). 1055 bytes result sent to driver
2021-12-03 22:36:50,352 [dispatcher-event-loop-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 16.0 in stage 2.0 (TID 60, localhost, executor driver, partition 16, ANY, 7649 bytes)
2021-12-03 22:36:50,352 [Executor task launch worker for task 59] INFO [org.apache.spark.executor.Executor] - Running task 15.0 in stage 2.0 (TID 59)
2021-12-03 22:36:50,352 [Executor task launch worker for task 50] INFO [org.apache.spark.executor.Executor] - Finished task 6.0 in stage 2.0 (TID 50). 1055 bytes result sent to driver
2021-12-03 22:36:50,353 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 4.0 in stage 2.0 (TID 48) in 408 ms on localhost (executor driver) (4/22)
2021-12-03 22:36:50,353 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 8.0 in stage 2.0 (TID 52) in 407 ms on localhost (executor driver) (5/22)
2021-12-03 22:36:50,353 [Executor task launch worker for task 44] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 2.0 (TID 44). 1055 bytes result sent to driver
2021-12-03 22:36:50,353 [Executor task launch worker for task 60] INFO [org.apache.spark.executor.Executor] - Running task 16.0 in stage 2.0 (TID 60)
2021-12-03 22:36:50,354 [dispatcher-event-loop-9] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 17.0 in stage 2.0 (TID 61, localhost, executor driver, partition 17, ANY, 7649 bytes)
2021-12-03 22:36:50,355 [dispatcher-event-loop-9] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 18.0 in stage 2.0 (TID 62, localhost, executor driver, partition 18, ANY, 7649 bytes)
2021-12-03 22:36:50,355 [Executor task launch worker for task 62] INFO [org.apache.spark.executor.Executor] - Running task 18.0 in stage 2.0 (TID 62)
2021-12-03 22:36:50,355 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 6.0 in stage 2.0 (TID 50) in 409 ms on localhost (executor driver) (6/22)
2021-12-03 22:36:50,355 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 2.0 (TID 44) in 411 ms on localhost (executor driver) (7/22)
2021-12-03 22:36:50,356 [Executor task launch worker for task 54] INFO [org.apache.spark.executor.Executor] - Finished task 10.0 in stage 2.0 (TID 54). 1055 bytes result sent to driver
2021-12-03 22:36:50,356 [Executor task launch worker for task 47] INFO [org.apache.spark.executor.Executor] - Finished task 3.0 in stage 2.0 (TID 47). 1055 bytes result sent to driver
2021-12-03 22:36:50,356 [Executor task launch worker for task 62] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 22:36:50,356 [Executor task launch worker for task 62] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 22:36:50,356 [Executor task launch worker for task 55] INFO [org.apache.spark.executor.Executor] - Finished task 11.0 in stage 2.0 (TID 55). 1055 bytes result sent to driver
2021-12-03 22:36:50,356 [Executor task launch worker for task 61] INFO [org.apache.spark.executor.Executor] - Running task 17.0 in stage 2.0 (TID 61)
2021-12-03 22:36:50,356 [Executor task launch worker for task 60] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 22:36:50,356 [Executor task launch worker for task 60] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 1 ms
2021-12-03 22:36:50,357 [Executor task launch worker for task 59] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 22:36:50,357 [Executor task launch worker for task 59] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 1 ms
2021-12-03 22:36:50,357 [dispatcher-event-loop-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 19.0 in stage 2.0 (TID 63, localhost, executor driver, partition 19, ANY, 7649 bytes)
2021-12-03 22:36:50,357 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 10.0 in stage 2.0 (TID 54) in 411 ms on localhost (executor driver) (8/22)
2021-12-03 22:36:50,357 [Executor task launch worker for task 63] INFO [org.apache.spark.executor.Executor] - Running task 19.0 in stage 2.0 (TID 63)
2021-12-03 22:36:50,357 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 3.0 in stage 2.0 (TID 47) in 412 ms on localhost (executor driver) (9/22)
2021-12-03 22:36:50,358 [dispatcher-event-loop-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 20.0 in stage 2.0 (TID 64, localhost, executor driver, partition 20, ANY, 7649 bytes)
2021-12-03 22:36:50,358 [Executor task launch worker for task 64] INFO [org.apache.spark.executor.Executor] - Running task 20.0 in stage 2.0 (TID 64)
2021-12-03 22:36:50,358 [dispatcher-event-loop-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 21.0 in stage 2.0 (TID 65, localhost, executor driver, partition 21, ANY, 7649 bytes)
2021-12-03 22:36:50,358 [Executor task launch worker for task 65] INFO [org.apache.spark.executor.Executor] - Running task 21.0 in stage 2.0 (TID 65)
2021-12-03 22:36:50,358 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 11.0 in stage 2.0 (TID 55) in 412 ms on localhost (executor driver) (10/22)
2021-12-03 22:36:50,359 [Executor task launch worker for task 63] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 22:36:50,359 [Executor task launch worker for task 63] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 22:36:50,359 [Executor task launch worker for task 64] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 22:36:50,359 [Executor task launch worker for task 64] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 22:36:50,360 [Executor task launch worker for task 65] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 22:36:50,360 [Executor task launch worker for task 65] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 22:36:50,360 [Executor task launch worker for task 61] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 22:36:50,360 [Executor task launch worker for task 61] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 22:36:50,362 [Executor task launch worker for task 46] INFO [org.apache.spark.executor.Executor] - Finished task 2.0 in stage 2.0 (TID 46). 1055 bytes result sent to driver
2021-12-03 22:36:50,362 [Executor task launch worker for task 49] INFO [org.apache.spark.executor.Executor] - Finished task 5.0 in stage 2.0 (TID 49). 1055 bytes result sent to driver
2021-12-03 22:36:50,362 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 2.0 in stage 2.0 (TID 46) in 417 ms on localhost (executor driver) (11/22)
2021-12-03 22:36:50,362 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 5.0 in stage 2.0 (TID 49) in 417 ms on localhost (executor driver) (12/22)
2021-12-03 22:36:50,518 [Executor task launch worker for task 57] INFO [org.apache.spark.executor.Executor] - Finished task 13.0 in stage 2.0 (TID 57). 1098 bytes result sent to driver
2021-12-03 22:36:50,518 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 13.0 in stage 2.0 (TID 57) in 176 ms on localhost (executor driver) (13/22)
2021-12-03 22:36:50,518 [Executor task launch worker for task 59] INFO [org.apache.spark.executor.Executor] - Finished task 15.0 in stage 2.0 (TID 59). 1098 bytes result sent to driver
2021-12-03 22:36:50,520 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 15.0 in stage 2.0 (TID 59) in 169 ms on localhost (executor driver) (14/22)
2021-12-03 22:36:50,520 [Executor task launch worker for task 56] INFO [org.apache.spark.executor.Executor] - Finished task 12.0 in stage 2.0 (TID 56). 1055 bytes result sent to driver
2021-12-03 22:36:50,521 [Executor task launch worker for task 64] INFO [org.apache.spark.executor.Executor] - Finished task 20.0 in stage 2.0 (TID 64). 1098 bytes result sent to driver
2021-12-03 22:36:50,522 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 12.0 in stage 2.0 (TID 56) in 180 ms on localhost (executor driver) (15/22)
2021-12-03 22:36:50,522 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 20.0 in stage 2.0 (TID 64) in 164 ms on localhost (executor driver) (16/22)
2021-12-03 22:36:50,535 [Executor task launch worker for task 65] INFO [org.apache.spark.executor.Executor] - Finished task 21.0 in stage 2.0 (TID 65). 1055 bytes result sent to driver
2021-12-03 22:36:50,535 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 21.0 in stage 2.0 (TID 65) in 177 ms on localhost (executor driver) (17/22)
2021-12-03 22:36:50,543 [Executor task launch worker for task 58] INFO [org.apache.spark.executor.Executor] - Finished task 14.0 in stage 2.0 (TID 58). 1098 bytes result sent to driver
2021-12-03 22:36:50,543 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 14.0 in stage 2.0 (TID 58) in 197 ms on localhost (executor driver) (18/22)
2021-12-03 22:36:50,544 [Executor task launch worker for task 63] INFO [org.apache.spark.executor.Executor] - Finished task 19.0 in stage 2.0 (TID 63). 1055 bytes result sent to driver
2021-12-03 22:36:50,544 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 19.0 in stage 2.0 (TID 63) in 187 ms on localhost (executor driver) (19/22)
2021-12-03 22:36:50,545 [Executor task launch worker for task 62] INFO [org.apache.spark.executor.Executor] - Finished task 18.0 in stage 2.0 (TID 62). 1098 bytes result sent to driver
2021-12-03 22:36:50,545 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 18.0 in stage 2.0 (TID 62) in 191 ms on localhost (executor driver) (20/22)
2021-12-03 22:36:50,546 [Executor task launch worker for task 61] INFO [org.apache.spark.executor.Executor] - Finished task 17.0 in stage 2.0 (TID 61). 1098 bytes result sent to driver
2021-12-03 22:36:50,546 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 17.0 in stage 2.0 (TID 61) in 192 ms on localhost (executor driver) (21/22)
2021-12-03 22:36:50,549 [Executor task launch worker for task 60] INFO [org.apache.spark.executor.Executor] - Finished task 16.0 in stage 2.0 (TID 60). 1098 bytes result sent to driver
2021-12-03 22:36:50,549 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 16.0 in stage 2.0 (TID 60) in 197 ms on localhost (executor driver) (22/22)
2021-12-03 22:36:50,549 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 2.0, whose tasks have all completed, from pool 
2021-12-03 22:36:50,549 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 2 (count at PaidPromotionAdjustParameter.scala:68) finished in 0.609 s
2021-12-03 22:36:50,550 [main] INFO [org.apache.spark.scheduler.DAGScheduler] - Job 1 finished: count at PaidPromotionAdjustParameter.scala:68, took 257.028212 s
2021-12-03 22:36:50,550 [main] INFO [PaidPromotion$] - 用户总数1207347
2021-12-03 22:36:50,588 [main] INFO [org.apache.spark.SparkContext] - Starting job: sortByKey at PaidPromotionAdjustParameter.scala:73
2021-12-03 22:36:50,588 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 2 (sortByKey at PaidPromotionAdjustParameter.scala:73) with 22 output partitions
2021-12-03 22:36:50,589 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 4 (sortByKey at PaidPromotionAdjustParameter.scala:73)
2021-12-03 22:36:50,589 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 3)
2021-12-03 22:36:50,589 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2021-12-03 22:36:50,589 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 4 (MapPartitionsRDD[7] at sortByKey at PaidPromotionAdjustParameter.scala:73), which has no missing parents
2021-12-03 22:36:50,593 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_4 stored as values in memory (estimated size 4.1 KB, free 1990.5 MB)
2021-12-03 22:36:50,595 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_4_piece0 stored as bytes in memory (estimated size 2.4 KB, free 1990.4 MB)
2021-12-03 22:36:50,596 [dispatcher-event-loop-9] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_4_piece0 in memory on qb:59961 (size: 2.4 KB, free: 1990.8 MB)
2021-12-03 22:36:50,596 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 4 from broadcast at DAGScheduler.scala:1039
2021-12-03 22:36:50,597 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 22 missing tasks from ResultStage 4 (MapPartitionsRDD[7] at sortByKey at PaidPromotionAdjustParameter.scala:73) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14))
2021-12-03 22:36:50,597 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 4.0 with 22 tasks
2021-12-03 22:36:50,598 [dispatcher-event-loop-7] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 4.0 (TID 66, localhost, executor driver, partition 0, ANY, 7649 bytes)
2021-12-03 22:36:50,599 [dispatcher-event-loop-7] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 4.0 (TID 67, localhost, executor driver, partition 1, ANY, 7649 bytes)
2021-12-03 22:36:50,599 [dispatcher-event-loop-7] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 2.0 in stage 4.0 (TID 68, localhost, executor driver, partition 2, ANY, 7649 bytes)
2021-12-03 22:36:50,599 [dispatcher-event-loop-7] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 3.0 in stage 4.0 (TID 69, localhost, executor driver, partition 3, ANY, 7649 bytes)
2021-12-03 22:36:50,599 [dispatcher-event-loop-7] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 4.0 in stage 4.0 (TID 70, localhost, executor driver, partition 4, ANY, 7649 bytes)
2021-12-03 22:36:50,599 [dispatcher-event-loop-7] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 5.0 in stage 4.0 (TID 71, localhost, executor driver, partition 5, ANY, 7649 bytes)
2021-12-03 22:36:50,600 [dispatcher-event-loop-7] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 6.0 in stage 4.0 (TID 72, localhost, executor driver, partition 6, ANY, 7649 bytes)
2021-12-03 22:36:50,600 [dispatcher-event-loop-7] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 7.0 in stage 4.0 (TID 73, localhost, executor driver, partition 7, ANY, 7649 bytes)
2021-12-03 22:36:50,600 [dispatcher-event-loop-7] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 8.0 in stage 4.0 (TID 74, localhost, executor driver, partition 8, ANY, 7649 bytes)
2021-12-03 22:36:50,600 [dispatcher-event-loop-7] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 9.0 in stage 4.0 (TID 75, localhost, executor driver, partition 9, ANY, 7649 bytes)
2021-12-03 22:36:50,600 [dispatcher-event-loop-7] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 10.0 in stage 4.0 (TID 76, localhost, executor driver, partition 10, ANY, 7649 bytes)
2021-12-03 22:36:50,600 [dispatcher-event-loop-7] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 11.0 in stage 4.0 (TID 77, localhost, executor driver, partition 11, ANY, 7649 bytes)
2021-12-03 22:36:50,600 [Executor task launch worker for task 66] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 4.0 (TID 66)
2021-12-03 22:36:50,600 [Executor task launch worker for task 67] INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 4.0 (TID 67)
2021-12-03 22:36:50,600 [Executor task launch worker for task 69] INFO [org.apache.spark.executor.Executor] - Running task 3.0 in stage 4.0 (TID 69)
2021-12-03 22:36:50,600 [Executor task launch worker for task 76] INFO [org.apache.spark.executor.Executor] - Running task 10.0 in stage 4.0 (TID 76)
2021-12-03 22:36:50,600 [Executor task launch worker for task 77] INFO [org.apache.spark.executor.Executor] - Running task 11.0 in stage 4.0 (TID 77)
2021-12-03 22:36:50,600 [Executor task launch worker for task 71] INFO [org.apache.spark.executor.Executor] - Running task 5.0 in stage 4.0 (TID 71)
2021-12-03 22:36:50,600 [Executor task launch worker for task 74] INFO [org.apache.spark.executor.Executor] - Running task 8.0 in stage 4.0 (TID 74)
2021-12-03 22:36:50,600 [Executor task launch worker for task 68] INFO [org.apache.spark.executor.Executor] - Running task 2.0 in stage 4.0 (TID 68)
2021-12-03 22:36:50,601 [Executor task launch worker for task 73] INFO [org.apache.spark.executor.Executor] - Running task 7.0 in stage 4.0 (TID 73)
2021-12-03 22:36:50,601 [Executor task launch worker for task 70] INFO [org.apache.spark.executor.Executor] - Running task 4.0 in stage 4.0 (TID 70)
2021-12-03 22:36:50,600 [Executor task launch worker for task 72] INFO [org.apache.spark.executor.Executor] - Running task 6.0 in stage 4.0 (TID 72)
2021-12-03 22:36:50,600 [Executor task launch worker for task 75] INFO [org.apache.spark.executor.Executor] - Running task 9.0 in stage 4.0 (TID 75)
2021-12-03 22:36:50,603 [Executor task launch worker for task 75] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 22:36:50,603 [Executor task launch worker for task 75] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 22:36:50,603 [Executor task launch worker for task 66] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 22:36:50,603 [Executor task launch worker for task 66] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 22:36:50,603 [Executor task launch worker for task 70] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 22:36:50,603 [Executor task launch worker for task 70] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 22:36:50,603 [Executor task launch worker for task 67] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 22:36:50,603 [Executor task launch worker for task 67] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 22:36:50,603 [Executor task launch worker for task 68] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 22:36:50,603 [Executor task launch worker for task 68] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 22:36:50,604 [Executor task launch worker for task 73] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 22:36:50,604 [Executor task launch worker for task 73] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 1 ms
2021-12-03 22:36:50,604 [Executor task launch worker for task 74] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 22:36:50,603 [Executor task launch worker for task 77] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 22:36:50,604 [Executor task launch worker for task 74] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 22:36:50,604 [Executor task launch worker for task 72] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 22:36:50,604 [Executor task launch worker for task 72] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 22:36:50,603 [Executor task launch worker for task 71] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 22:36:50,604 [Executor task launch worker for task 69] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 22:36:50,604 [Executor task launch worker for task 69] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 1 ms
2021-12-03 22:36:50,604 [Executor task launch worker for task 71] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 1 ms
2021-12-03 22:36:50,604 [Executor task launch worker for task 77] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 1 ms
2021-12-03 22:36:50,604 [Executor task launch worker for task 76] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 22:36:50,604 [Executor task launch worker for task 76] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 22:36:50,754 [Executor task launch worker for task 75] INFO [org.apache.spark.executor.Executor] - Finished task 9.0 in stage 4.0 (TID 75). 1192 bytes result sent to driver
2021-12-03 22:36:50,754 [dispatcher-event-loop-8] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 12.0 in stage 4.0 (TID 78, localhost, executor driver, partition 12, ANY, 7649 bytes)
2021-12-03 22:36:50,757 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 9.0 in stage 4.0 (TID 75) in 157 ms on localhost (executor driver) (1/22)
2021-12-03 22:36:50,757 [Executor task launch worker for task 77] INFO [org.apache.spark.executor.Executor] - Finished task 11.0 in stage 4.0 (TID 77). 1185 bytes result sent to driver
2021-12-03 22:36:50,757 [Executor task launch worker for task 78] INFO [org.apache.spark.executor.Executor] - Running task 12.0 in stage 4.0 (TID 78)
2021-12-03 22:36:50,759 [Executor task launch worker for task 78] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 22:36:50,759 [Executor task launch worker for task 78] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 1 ms
2021-12-03 22:36:50,759 [Executor task launch worker for task 76] INFO [org.apache.spark.executor.Executor] - Finished task 10.0 in stage 4.0 (TID 76). 1187 bytes result sent to driver
2021-12-03 22:36:50,759 [dispatcher-event-loop-10] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 13.0 in stage 4.0 (TID 79, localhost, executor driver, partition 13, ANY, 7649 bytes)
2021-12-03 22:36:50,760 [dispatcher-event-loop-10] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 14.0 in stage 4.0 (TID 80, localhost, executor driver, partition 14, ANY, 7649 bytes)
2021-12-03 22:36:50,760 [Executor task launch worker for task 74] INFO [org.apache.spark.executor.Executor] - Finished task 8.0 in stage 4.0 (TID 74). 1187 bytes result sent to driver
2021-12-03 22:36:50,761 [Executor task launch worker for task 71] INFO [org.apache.spark.executor.Executor] - Finished task 5.0 in stage 4.0 (TID 71). 1189 bytes result sent to driver
2021-12-03 22:36:50,761 [Executor task launch worker for task 79] INFO [org.apache.spark.executor.Executor] - Running task 13.0 in stage 4.0 (TID 79)
2021-12-03 22:36:50,762 [dispatcher-event-loop-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 15.0 in stage 4.0 (TID 81, localhost, executor driver, partition 15, ANY, 7649 bytes)
2021-12-03 22:36:50,762 [dispatcher-event-loop-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 16.0 in stage 4.0 (TID 82, localhost, executor driver, partition 16, ANY, 7649 bytes)
2021-12-03 22:36:50,762 [Executor task launch worker for task 79] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 22:36:50,762 [Executor task launch worker for task 79] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 22:36:50,762 [Executor task launch worker for task 80] INFO [org.apache.spark.executor.Executor] - Running task 14.0 in stage 4.0 (TID 80)
2021-12-03 22:36:50,763 [Executor task launch worker for task 81] INFO [org.apache.spark.executor.Executor] - Running task 15.0 in stage 4.0 (TID 81)
2021-12-03 22:36:50,764 [Executor task launch worker for task 81] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 22:36:50,764 [Executor task launch worker for task 81] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 22:36:50,765 [Executor task launch worker for task 82] INFO [org.apache.spark.executor.Executor] - Running task 16.0 in stage 4.0 (TID 82)
2021-12-03 22:36:50,765 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 11.0 in stage 4.0 (TID 77) in 165 ms on localhost (executor driver) (2/22)
2021-12-03 22:36:50,765 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 10.0 in stage 4.0 (TID 76) in 165 ms on localhost (executor driver) (3/22)
2021-12-03 22:36:50,765 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 8.0 in stage 4.0 (TID 74) in 165 ms on localhost (executor driver) (4/22)
2021-12-03 22:36:50,765 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 5.0 in stage 4.0 (TID 71) in 166 ms on localhost (executor driver) (5/22)
2021-12-03 22:36:50,766 [Executor task launch worker for task 82] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 22:36:50,766 [Executor task launch worker for task 82] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 1 ms
2021-12-03 22:36:50,767 [Executor task launch worker for task 72] INFO [org.apache.spark.executor.Executor] - Finished task 6.0 in stage 4.0 (TID 72). 1181 bytes result sent to driver
2021-12-03 22:36:50,768 [dispatcher-event-loop-11] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 17.0 in stage 4.0 (TID 83, localhost, executor driver, partition 17, ANY, 7649 bytes)
2021-12-03 22:36:50,768 [Executor task launch worker for task 80] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 22:36:50,768 [Executor task launch worker for task 80] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 22:36:50,768 [Executor task launch worker for task 83] INFO [org.apache.spark.executor.Executor] - Running task 17.0 in stage 4.0 (TID 83)
2021-12-03 22:36:50,769 [Executor task launch worker for task 83] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 22:36:50,769 [Executor task launch worker for task 83] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 22:36:50,770 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 6.0 in stage 4.0 (TID 72) in 171 ms on localhost (executor driver) (6/22)
2021-12-03 22:36:50,775 [Executor task launch worker for task 66] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 4.0 (TID 66). 1188 bytes result sent to driver
2021-12-03 22:36:50,775 [dispatcher-event-loop-8] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 18.0 in stage 4.0 (TID 84, localhost, executor driver, partition 18, ANY, 7649 bytes)
2021-12-03 22:36:50,775 [Executor task launch worker for task 84] INFO [org.apache.spark.executor.Executor] - Running task 18.0 in stage 4.0 (TID 84)
2021-12-03 22:36:50,775 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 4.0 (TID 66) in 177 ms on localhost (executor driver) (7/22)
2021-12-03 22:36:50,777 [Executor task launch worker for task 84] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 22:36:50,777 [Executor task launch worker for task 84] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 22:36:50,790 [Executor task launch worker for task 73] INFO [org.apache.spark.executor.Executor] - Finished task 7.0 in stage 4.0 (TID 73). 1186 bytes result sent to driver
2021-12-03 22:36:50,791 [dispatcher-event-loop-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 19.0 in stage 4.0 (TID 85, localhost, executor driver, partition 19, ANY, 7649 bytes)
2021-12-03 22:36:50,791 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 7.0 in stage 4.0 (TID 73) in 191 ms on localhost (executor driver) (8/22)
2021-12-03 22:36:50,791 [Executor task launch worker for task 85] INFO [org.apache.spark.executor.Executor] - Running task 19.0 in stage 4.0 (TID 85)
2021-12-03 22:36:50,792 [Executor task launch worker for task 68] INFO [org.apache.spark.executor.Executor] - Finished task 2.0 in stage 4.0 (TID 68). 1189 bytes result sent to driver
2021-12-03 22:36:50,792 [Executor task launch worker for task 85] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 22:36:50,792 [Executor task launch worker for task 85] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 22:36:50,792 [dispatcher-event-loop-5] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 20.0 in stage 4.0 (TID 86, localhost, executor driver, partition 20, ANY, 7649 bytes)
2021-12-03 22:36:50,793 [Executor task launch worker for task 86] INFO [org.apache.spark.executor.Executor] - Running task 20.0 in stage 4.0 (TID 86)
2021-12-03 22:36:50,793 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 2.0 in stage 4.0 (TID 68) in 194 ms on localhost (executor driver) (9/22)
2021-12-03 22:36:50,794 [Executor task launch worker for task 86] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 22:36:50,794 [Executor task launch worker for task 86] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 22:36:50,799 [Executor task launch worker for task 67] INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 4.0 (TID 67). 1183 bytes result sent to driver
2021-12-03 22:36:50,800 [Executor task launch worker for task 69] INFO [org.apache.spark.executor.Executor] - Finished task 3.0 in stage 4.0 (TID 69). 1184 bytes result sent to driver
2021-12-03 22:36:50,802 [dispatcher-event-loop-6] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 21.0 in stage 4.0 (TID 87, localhost, executor driver, partition 21, ANY, 7649 bytes)
2021-12-03 22:36:50,803 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 3.0 in stage 4.0 (TID 69) in 204 ms on localhost (executor driver) (10/22)
2021-12-03 22:36:50,803 [Executor task launch worker for task 87] INFO [org.apache.spark.executor.Executor] - Running task 21.0 in stage 4.0 (TID 87)
2021-12-03 22:36:50,804 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 4.0 (TID 67) in 206 ms on localhost (executor driver) (11/22)
2021-12-03 22:36:50,804 [Executor task launch worker for task 87] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 22:36:50,804 [Executor task launch worker for task 87] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 22:36:50,822 [Executor task launch worker for task 70] INFO [org.apache.spark.executor.Executor] - Finished task 4.0 in stage 4.0 (TID 70). 1187 bytes result sent to driver
2021-12-03 22:36:50,824 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 4.0 in stage 4.0 (TID 70) in 225 ms on localhost (executor driver) (12/22)
2021-12-03 22:36:50,868 [Executor task launch worker for task 79] INFO [org.apache.spark.executor.Executor] - Finished task 13.0 in stage 4.0 (TID 79). 1141 bytes result sent to driver
2021-12-03 22:36:50,869 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 13.0 in stage 4.0 (TID 79) in 110 ms on localhost (executor driver) (13/22)
2021-12-03 22:36:50,871 [Executor task launch worker for task 82] INFO [org.apache.spark.executor.Executor] - Finished task 16.0 in stage 4.0 (TID 82). 1100 bytes result sent to driver
2021-12-03 22:36:50,871 [Executor task launch worker for task 80] INFO [org.apache.spark.executor.Executor] - Finished task 14.0 in stage 4.0 (TID 80). 1185 bytes result sent to driver
2021-12-03 22:36:50,871 [Executor task launch worker for task 81] INFO [org.apache.spark.executor.Executor] - Finished task 15.0 in stage 4.0 (TID 81). 1094 bytes result sent to driver
2021-12-03 22:36:50,871 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 16.0 in stage 4.0 (TID 82) in 109 ms on localhost (executor driver) (14/22)
2021-12-03 22:36:50,871 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 14.0 in stage 4.0 (TID 80) in 112 ms on localhost (executor driver) (15/22)
2021-12-03 22:36:50,871 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 15.0 in stage 4.0 (TID 81) in 110 ms on localhost (executor driver) (16/22)
2021-12-03 22:36:50,874 [Executor task launch worker for task 78] INFO [org.apache.spark.executor.Executor] - Finished task 12.0 in stage 4.0 (TID 78). 1142 bytes result sent to driver
2021-12-03 22:36:50,875 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 12.0 in stage 4.0 (TID 78) in 121 ms on localhost (executor driver) (17/22)
2021-12-03 22:36:50,876 [Executor task launch worker for task 83] INFO [org.apache.spark.executor.Executor] - Finished task 17.0 in stage 4.0 (TID 83). 1142 bytes result sent to driver
2021-12-03 22:36:50,876 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 17.0 in stage 4.0 (TID 83) in 109 ms on localhost (executor driver) (18/22)
2021-12-03 22:36:50,883 [Executor task launch worker for task 84] INFO [org.apache.spark.executor.Executor] - Finished task 18.0 in stage 4.0 (TID 84). 1137 bytes result sent to driver
2021-12-03 22:36:50,883 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 18.0 in stage 4.0 (TID 84) in 108 ms on localhost (executor driver) (19/22)
2021-12-03 22:36:50,886 [Executor task launch worker for task 85] INFO [org.apache.spark.executor.Executor] - Finished task 19.0 in stage 4.0 (TID 85). 1103 bytes result sent to driver
2021-12-03 22:36:50,887 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 19.0 in stage 4.0 (TID 85) in 97 ms on localhost (executor driver) (20/22)
2021-12-03 22:36:50,898 [Executor task launch worker for task 86] INFO [org.apache.spark.executor.Executor] - Finished task 20.0 in stage 4.0 (TID 86). 1103 bytes result sent to driver
2021-12-03 22:36:50,898 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 20.0 in stage 4.0 (TID 86) in 106 ms on localhost (executor driver) (21/22)
2021-12-03 22:36:50,899 [Executor task launch worker for task 87] INFO [org.apache.spark.executor.Executor] - Finished task 21.0 in stage 4.0 (TID 87). 1101 bytes result sent to driver
2021-12-03 22:36:50,899 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 21.0 in stage 4.0 (TID 87) in 97 ms on localhost (executor driver) (22/22)
2021-12-03 22:36:50,899 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 4.0, whose tasks have all completed, from pool 
2021-12-03 22:36:50,899 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 4 (sortByKey at PaidPromotionAdjustParameter.scala:73) finished in 0.307 s
2021-12-03 22:36:50,899 [main] INFO [org.apache.spark.scheduler.DAGScheduler] - Job 2 finished: sortByKey at PaidPromotionAdjustParameter.scala:73, took 0.311403 s
2021-12-03 22:36:50,920 [main] INFO [org.apache.spark.SparkContext] - Starting job: zipWithIndex at PaidPromotionAdjustParameter.scala:74
2021-12-03 22:36:50,920 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 5 (map at PaidPromotionAdjustParameter.scala:72)
2021-12-03 22:36:50,920 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 3 (zipWithIndex at PaidPromotionAdjustParameter.scala:74) with 21 output partitions
2021-12-03 22:36:50,920 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 7 (zipWithIndex at PaidPromotionAdjustParameter.scala:74)
2021-12-03 22:36:50,920 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 6)
2021-12-03 22:36:50,920 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List(ShuffleMapStage 6)
2021-12-03 22:36:50,921 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ShuffleMapStage 6 (MapPartitionsRDD[5] at map at PaidPromotionAdjustParameter.scala:72), which has no missing parents
2021-12-03 22:36:50,929 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_5 stored as values in memory (estimated size 4.1 KB, free 1990.4 MB)
2021-12-03 22:36:50,931 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_5_piece0 stored as bytes in memory (estimated size 2.4 KB, free 1990.4 MB)
2021-12-03 22:36:50,931 [dispatcher-event-loop-1] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_5_piece0 in memory on qb:59961 (size: 2.4 KB, free: 1990.8 MB)
2021-12-03 22:36:50,931 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 5 from broadcast at DAGScheduler.scala:1039
2021-12-03 22:36:50,932 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 22 missing tasks from ShuffleMapStage 6 (MapPartitionsRDD[5] at map at PaidPromotionAdjustParameter.scala:72) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14))
2021-12-03 22:36:50,932 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 6.0 with 22 tasks
2021-12-03 22:36:50,932 [dispatcher-event-loop-9] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 6.0 (TID 88, localhost, executor driver, partition 0, ANY, 7638 bytes)
2021-12-03 22:36:50,932 [dispatcher-event-loop-9] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 6.0 (TID 89, localhost, executor driver, partition 1, ANY, 7638 bytes)
2021-12-03 22:36:50,932 [dispatcher-event-loop-9] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 2.0 in stage 6.0 (TID 90, localhost, executor driver, partition 2, ANY, 7638 bytes)
2021-12-03 22:36:50,933 [dispatcher-event-loop-9] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 3.0 in stage 6.0 (TID 91, localhost, executor driver, partition 3, ANY, 7638 bytes)
2021-12-03 22:36:50,933 [dispatcher-event-loop-9] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 4.0 in stage 6.0 (TID 92, localhost, executor driver, partition 4, ANY, 7638 bytes)
2021-12-03 22:36:50,933 [dispatcher-event-loop-9] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 5.0 in stage 6.0 (TID 93, localhost, executor driver, partition 5, ANY, 7638 bytes)
2021-12-03 22:36:50,933 [dispatcher-event-loop-9] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 6.0 in stage 6.0 (TID 94, localhost, executor driver, partition 6, ANY, 7638 bytes)
2021-12-03 22:36:50,933 [dispatcher-event-loop-9] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 7.0 in stage 6.0 (TID 95, localhost, executor driver, partition 7, ANY, 7638 bytes)
2021-12-03 22:36:50,933 [dispatcher-event-loop-9] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 8.0 in stage 6.0 (TID 96, localhost, executor driver, partition 8, ANY, 7638 bytes)
2021-12-03 22:36:50,933 [dispatcher-event-loop-9] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 9.0 in stage 6.0 (TID 97, localhost, executor driver, partition 9, ANY, 7638 bytes)
2021-12-03 22:36:50,933 [dispatcher-event-loop-9] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 10.0 in stage 6.0 (TID 98, localhost, executor driver, partition 10, ANY, 7638 bytes)
2021-12-03 22:36:50,934 [dispatcher-event-loop-9] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 11.0 in stage 6.0 (TID 99, localhost, executor driver, partition 11, ANY, 7638 bytes)
2021-12-03 22:36:50,934 [Executor task launch worker for task 88] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 6.0 (TID 88)
2021-12-03 22:36:50,934 [Executor task launch worker for task 96] INFO [org.apache.spark.executor.Executor] - Running task 8.0 in stage 6.0 (TID 96)
2021-12-03 22:36:50,934 [Executor task launch worker for task 99] INFO [org.apache.spark.executor.Executor] - Running task 11.0 in stage 6.0 (TID 99)
2021-12-03 22:36:50,934 [Executor task launch worker for task 94] INFO [org.apache.spark.executor.Executor] - Running task 6.0 in stage 6.0 (TID 94)
2021-12-03 22:36:50,934 [Executor task launch worker for task 93] INFO [org.apache.spark.executor.Executor] - Running task 5.0 in stage 6.0 (TID 93)
2021-12-03 22:36:50,934 [Executor task launch worker for task 91] INFO [org.apache.spark.executor.Executor] - Running task 3.0 in stage 6.0 (TID 91)
2021-12-03 22:36:50,934 [Executor task launch worker for task 92] INFO [org.apache.spark.executor.Executor] - Running task 4.0 in stage 6.0 (TID 92)
2021-12-03 22:36:50,934 [Executor task launch worker for task 89] INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 6.0 (TID 89)
2021-12-03 22:36:50,934 [Executor task launch worker for task 90] INFO [org.apache.spark.executor.Executor] - Running task 2.0 in stage 6.0 (TID 90)
2021-12-03 22:36:50,934 [Executor task launch worker for task 98] INFO [org.apache.spark.executor.Executor] - Running task 10.0 in stage 6.0 (TID 98)
2021-12-03 22:36:50,934 [Executor task launch worker for task 97] INFO [org.apache.spark.executor.Executor] - Running task 9.0 in stage 6.0 (TID 97)
2021-12-03 22:36:50,934 [Executor task launch worker for task 95] INFO [org.apache.spark.executor.Executor] - Running task 7.0 in stage 6.0 (TID 95)
2021-12-03 22:36:50,944 [Executor task launch worker for task 98] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 22:36:50,944 [Executor task launch worker for task 98] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 22:36:50,944 [Executor task launch worker for task 89] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 22:36:50,944 [Executor task launch worker for task 90] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 22:36:50,944 [Executor task launch worker for task 89] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 22:36:50,944 [Executor task launch worker for task 90] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 22:36:50,944 [Executor task launch worker for task 88] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 22:36:50,944 [Executor task launch worker for task 88] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 22:36:50,944 [Executor task launch worker for task 93] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 22:36:50,944 [Executor task launch worker for task 93] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 22:36:50,944 [Executor task launch worker for task 95] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 22:36:50,944 [Executor task launch worker for task 95] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 22:36:50,944 [Executor task launch worker for task 97] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 22:36:50,944 [Executor task launch worker for task 99] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 22:36:50,944 [Executor task launch worker for task 94] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 22:36:50,944 [Executor task launch worker for task 92] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 22:36:50,944 [Executor task launch worker for task 94] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 22:36:50,944 [Executor task launch worker for task 99] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 22:36:50,944 [Executor task launch worker for task 91] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 22:36:50,944 [Executor task launch worker for task 97] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 22:36:50,944 [Executor task launch worker for task 91] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 22:36:50,944 [Executor task launch worker for task 92] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 22:36:50,945 [Executor task launch worker for task 96] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 22:36:50,945 [Executor task launch worker for task 96] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 22:36:51,453 [Executor task launch worker for task 91] INFO [org.apache.spark.executor.Executor] - Finished task 3.0 in stage 6.0 (TID 91). 1310 bytes result sent to driver
2021-12-03 22:36:51,456 [dispatcher-event-loop-8] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 12.0 in stage 6.0 (TID 100, localhost, executor driver, partition 12, ANY, 7638 bytes)
2021-12-03 22:36:51,456 [Executor task launch worker for task 100] INFO [org.apache.spark.executor.Executor] - Running task 12.0 in stage 6.0 (TID 100)
2021-12-03 22:36:51,458 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 3.0 in stage 6.0 (TID 91) in 525 ms on localhost (executor driver) (1/22)
2021-12-03 22:36:51,478 [Executor task launch worker for task 100] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 22:36:51,478 [Executor task launch worker for task 100] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 1 ms
2021-12-03 22:36:51,486 [Executor task launch worker for task 98] INFO [org.apache.spark.executor.Executor] - Finished task 10.0 in stage 6.0 (TID 98). 1267 bytes result sent to driver
2021-12-03 22:36:51,487 [dispatcher-event-loop-10] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 13.0 in stage 6.0 (TID 101, localhost, executor driver, partition 13, ANY, 7638 bytes)
2021-12-03 22:36:51,487 [Executor task launch worker for task 101] INFO [org.apache.spark.executor.Executor] - Running task 13.0 in stage 6.0 (TID 101)
2021-12-03 22:36:51,487 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 10.0 in stage 6.0 (TID 98) in 554 ms on localhost (executor driver) (2/22)
2021-12-03 22:36:51,490 [Executor task launch worker for task 96] INFO [org.apache.spark.executor.Executor] - Finished task 8.0 in stage 6.0 (TID 96). 1267 bytes result sent to driver
2021-12-03 22:36:51,492 [dispatcher-event-loop-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 14.0 in stage 6.0 (TID 102, localhost, executor driver, partition 14, ANY, 7638 bytes)
2021-12-03 22:36:51,492 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 8.0 in stage 6.0 (TID 96) in 559 ms on localhost (executor driver) (3/22)
2021-12-03 22:36:51,493 [Executor task launch worker for task 101] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 22:36:51,493 [Executor task launch worker for task 101] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 22:36:51,495 [Executor task launch worker for task 102] INFO [org.apache.spark.executor.Executor] - Running task 14.0 in stage 6.0 (TID 102)
2021-12-03 22:36:51,501 [Executor task launch worker for task 92] INFO [org.apache.spark.executor.Executor] - Finished task 4.0 in stage 6.0 (TID 92). 1310 bytes result sent to driver
2021-12-03 22:36:51,502 [dispatcher-event-loop-5] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 15.0 in stage 6.0 (TID 103, localhost, executor driver, partition 15, ANY, 7638 bytes)
2021-12-03 22:36:51,502 [Executor task launch worker for task 103] INFO [org.apache.spark.executor.Executor] - Running task 15.0 in stage 6.0 (TID 103)
2021-12-03 22:36:51,502 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 4.0 in stage 6.0 (TID 92) in 569 ms on localhost (executor driver) (4/22)
2021-12-03 22:36:51,504 [Executor task launch worker for task 102] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 22:36:51,504 [Executor task launch worker for task 102] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 22:36:51,505 [Executor task launch worker for task 95] INFO [org.apache.spark.executor.Executor] - Finished task 7.0 in stage 6.0 (TID 95). 1267 bytes result sent to driver
2021-12-03 22:36:51,506 [Executor task launch worker for task 103] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 22:36:51,506 [Executor task launch worker for task 103] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 22:36:51,510 [dispatcher-event-loop-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 16.0 in stage 6.0 (TID 104, localhost, executor driver, partition 16, ANY, 7638 bytes)
2021-12-03 22:36:51,510 [Executor task launch worker for task 104] INFO [org.apache.spark.executor.Executor] - Running task 16.0 in stage 6.0 (TID 104)
2021-12-03 22:36:51,510 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 7.0 in stage 6.0 (TID 95) in 577 ms on localhost (executor driver) (5/22)
2021-12-03 22:36:51,513 [Executor task launch worker for task 99] INFO [org.apache.spark.executor.Executor] - Finished task 11.0 in stage 6.0 (TID 99). 1267 bytes result sent to driver
2021-12-03 22:36:51,514 [dispatcher-event-loop-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 17.0 in stage 6.0 (TID 105, localhost, executor driver, partition 17, ANY, 7638 bytes)
2021-12-03 22:36:51,514 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 11.0 in stage 6.0 (TID 99) in 580 ms on localhost (executor driver) (6/22)
2021-12-03 22:36:51,514 [Executor task launch worker for task 104] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 22:36:51,515 [Executor task launch worker for task 104] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 1 ms
2021-12-03 22:36:51,516 [Executor task launch worker for task 105] INFO [org.apache.spark.executor.Executor] - Running task 17.0 in stage 6.0 (TID 105)
2021-12-03 22:36:51,520 [Executor task launch worker for task 105] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 22:36:51,520 [Executor task launch worker for task 105] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 22:36:51,523 [Executor task launch worker for task 90] INFO [org.apache.spark.executor.Executor] - Finished task 2.0 in stage 6.0 (TID 90). 1310 bytes result sent to driver
2021-12-03 22:36:51,524 [dispatcher-event-loop-8] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 18.0 in stage 6.0 (TID 106, localhost, executor driver, partition 18, ANY, 7638 bytes)
2021-12-03 22:36:51,524 [Executor task launch worker for task 106] INFO [org.apache.spark.executor.Executor] - Running task 18.0 in stage 6.0 (TID 106)
2021-12-03 22:36:51,524 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 2.0 in stage 6.0 (TID 90) in 592 ms on localhost (executor driver) (7/22)
2021-12-03 22:36:51,529 [Executor task launch worker for task 106] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 22:36:51,529 [Executor task launch worker for task 106] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 22:36:51,544 [Executor task launch worker for task 88] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 6.0 (TID 88). 1310 bytes result sent to driver
2021-12-03 22:36:51,545 [dispatcher-event-loop-10] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 19.0 in stage 6.0 (TID 107, localhost, executor driver, partition 19, ANY, 7638 bytes)
2021-12-03 22:36:51,546 [Executor task launch worker for task 107] INFO [org.apache.spark.executor.Executor] - Running task 19.0 in stage 6.0 (TID 107)
2021-12-03 22:36:51,551 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 6.0 (TID 88) in 619 ms on localhost (executor driver) (8/22)
2021-12-03 22:36:51,553 [Executor task launch worker for task 93] INFO [org.apache.spark.executor.Executor] - Finished task 5.0 in stage 6.0 (TID 93). 1267 bytes result sent to driver
2021-12-03 22:36:51,556 [Executor task launch worker for task 107] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 22:36:51,556 [Executor task launch worker for task 107] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 22:36:51,557 [dispatcher-event-loop-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 20.0 in stage 6.0 (TID 108, localhost, executor driver, partition 20, ANY, 7638 bytes)
2021-12-03 22:36:51,557 [Executor task launch worker for task 108] INFO [org.apache.spark.executor.Executor] - Running task 20.0 in stage 6.0 (TID 108)
2021-12-03 22:36:51,557 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 5.0 in stage 6.0 (TID 93) in 624 ms on localhost (executor driver) (9/22)
2021-12-03 22:36:51,561 [Executor task launch worker for task 108] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 22:36:51,561 [Executor task launch worker for task 108] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 22:36:51,565 [Executor task launch worker for task 94] INFO [org.apache.spark.executor.Executor] - Finished task 6.0 in stage 6.0 (TID 94). 1310 bytes result sent to driver
2021-12-03 22:36:51,566 [dispatcher-event-loop-5] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 21.0 in stage 6.0 (TID 109, localhost, executor driver, partition 21, ANY, 7638 bytes)
2021-12-03 22:36:51,567 [Executor task launch worker for task 109] INFO [org.apache.spark.executor.Executor] - Running task 21.0 in stage 6.0 (TID 109)
2021-12-03 22:36:51,570 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 6.0 in stage 6.0 (TID 94) in 637 ms on localhost (executor driver) (10/22)
2021-12-03 22:36:51,571 [Executor task launch worker for task 109] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 22:36:51,571 [Executor task launch worker for task 109] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 22:36:51,595 [Executor task launch worker for task 89] INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 6.0 (TID 89). 1267 bytes result sent to driver
2021-12-03 22:36:51,596 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 6.0 (TID 89) in 664 ms on localhost (executor driver) (11/22)
2021-12-03 22:36:51,644 [Executor task launch worker for task 97] INFO [org.apache.spark.executor.Executor] - Finished task 9.0 in stage 6.0 (TID 97). 1267 bytes result sent to driver
2021-12-03 22:36:51,647 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 9.0 in stage 6.0 (TID 97) in 714 ms on localhost (executor driver) (12/22)
2021-12-03 22:36:51,989 [Executor task launch worker for task 105] INFO [org.apache.spark.executor.Executor] - Finished task 17.0 in stage 6.0 (TID 105). 1267 bytes result sent to driver
2021-12-03 22:36:51,990 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 17.0 in stage 6.0 (TID 105) in 476 ms on localhost (executor driver) (13/22)
2021-12-03 22:36:51,993 [Executor task launch worker for task 100] INFO [org.apache.spark.executor.Executor] - Finished task 12.0 in stage 6.0 (TID 100). 1267 bytes result sent to driver
2021-12-03 22:36:51,994 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 12.0 in stage 6.0 (TID 100) in 538 ms on localhost (executor driver) (14/22)
2021-12-03 22:36:52,023 [Executor task launch worker for task 102] INFO [org.apache.spark.executor.Executor] - Finished task 14.0 in stage 6.0 (TID 102). 1267 bytes result sent to driver
2021-12-03 22:36:52,024 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 14.0 in stage 6.0 (TID 102) in 532 ms on localhost (executor driver) (15/22)
2021-12-03 22:36:52,028 [Executor task launch worker for task 104] INFO [org.apache.spark.executor.Executor] - Finished task 16.0 in stage 6.0 (TID 104). 1310 bytes result sent to driver
2021-12-03 22:36:52,029 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 16.0 in stage 6.0 (TID 104) in 520 ms on localhost (executor driver) (16/22)
2021-12-03 22:36:52,030 [Executor task launch worker for task 106] INFO [org.apache.spark.executor.Executor] - Finished task 18.0 in stage 6.0 (TID 106). 1267 bytes result sent to driver
2021-12-03 22:36:52,030 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 18.0 in stage 6.0 (TID 106) in 506 ms on localhost (executor driver) (17/22)
2021-12-03 22:36:52,032 [Executor task launch worker for task 108] INFO [org.apache.spark.executor.Executor] - Finished task 20.0 in stage 6.0 (TID 108). 1310 bytes result sent to driver
2021-12-03 22:36:52,033 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 20.0 in stage 6.0 (TID 108) in 476 ms on localhost (executor driver) (18/22)
2021-12-03 22:36:52,037 [Executor task launch worker for task 101] INFO [org.apache.spark.executor.Executor] - Finished task 13.0 in stage 6.0 (TID 101). 1267 bytes result sent to driver
2021-12-03 22:36:52,037 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 13.0 in stage 6.0 (TID 101) in 550 ms on localhost (executor driver) (19/22)
2021-12-03 22:36:52,048 [Executor task launch worker for task 103] INFO [org.apache.spark.executor.Executor] - Finished task 15.0 in stage 6.0 (TID 103). 1267 bytes result sent to driver
2021-12-03 22:36:52,049 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 15.0 in stage 6.0 (TID 103) in 547 ms on localhost (executor driver) (20/22)
2021-12-03 22:36:52,049 [Executor task launch worker for task 109] INFO [org.apache.spark.executor.Executor] - Finished task 21.0 in stage 6.0 (TID 109). 1267 bytes result sent to driver
2021-12-03 22:36:52,049 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 21.0 in stage 6.0 (TID 109) in 483 ms on localhost (executor driver) (21/22)
2021-12-03 22:36:52,056 [Executor task launch worker for task 107] INFO [org.apache.spark.executor.Executor] - Finished task 19.0 in stage 6.0 (TID 107). 1267 bytes result sent to driver
2021-12-03 22:36:52,057 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 19.0 in stage 6.0 (TID 107) in 512 ms on localhost (executor driver) (22/22)
2021-12-03 22:36:52,057 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 6.0, whose tasks have all completed, from pool 
2021-12-03 22:36:52,057 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ShuffleMapStage 6 (map at PaidPromotionAdjustParameter.scala:72) finished in 1.135 s
2021-12-03 22:36:52,057 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - looking for newly runnable stages
2021-12-03 22:36:52,057 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - running: Set()
2021-12-03 22:36:52,057 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - waiting: Set(ResultStage 7)
2021-12-03 22:36:52,057 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - failed: Set()
2021-12-03 22:36:52,057 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 7 (ShuffledRDD[8] at sortByKey at PaidPromotionAdjustParameter.scala:73), which has no missing parents
2021-12-03 22:36:52,060 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_6 stored as values in memory (estimated size 3.4 KB, free 1990.4 MB)
2021-12-03 22:36:52,061 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_6_piece0 stored as bytes in memory (estimated size 2.0 KB, free 1990.4 MB)
2021-12-03 22:36:52,062 [dispatcher-event-loop-3] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_6_piece0 in memory on qb:59961 (size: 2.0 KB, free: 1990.8 MB)
2021-12-03 22:36:52,062 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 6 from broadcast at DAGScheduler.scala:1039
2021-12-03 22:36:52,062 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 21 missing tasks from ResultStage 7 (ShuffledRDD[8] at sortByKey at PaidPromotionAdjustParameter.scala:73) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14))
2021-12-03 22:36:52,062 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 7.0 with 21 tasks
2021-12-03 22:36:52,063 [dispatcher-event-loop-6] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 7.0 (TID 110, localhost, executor driver, partition 0, ANY, 7649 bytes)
2021-12-03 22:36:52,063 [dispatcher-event-loop-6] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 7.0 (TID 111, localhost, executor driver, partition 1, ANY, 7649 bytes)
2021-12-03 22:36:52,063 [dispatcher-event-loop-6] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 2.0 in stage 7.0 (TID 112, localhost, executor driver, partition 2, ANY, 7649 bytes)
2021-12-03 22:36:52,063 [dispatcher-event-loop-6] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 3.0 in stage 7.0 (TID 113, localhost, executor driver, partition 3, ANY, 7649 bytes)
2021-12-03 22:36:52,063 [dispatcher-event-loop-6] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 4.0 in stage 7.0 (TID 114, localhost, executor driver, partition 4, ANY, 7649 bytes)
2021-12-03 22:36:52,063 [dispatcher-event-loop-6] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 5.0 in stage 7.0 (TID 115, localhost, executor driver, partition 5, ANY, 7649 bytes)
2021-12-03 22:36:52,063 [dispatcher-event-loop-6] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 6.0 in stage 7.0 (TID 116, localhost, executor driver, partition 6, ANY, 7649 bytes)
2021-12-03 22:36:52,063 [dispatcher-event-loop-6] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 7.0 in stage 7.0 (TID 117, localhost, executor driver, partition 7, ANY, 7649 bytes)
2021-12-03 22:36:52,063 [dispatcher-event-loop-6] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 8.0 in stage 7.0 (TID 118, localhost, executor driver, partition 8, ANY, 7649 bytes)
2021-12-03 22:36:52,064 [dispatcher-event-loop-6] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 9.0 in stage 7.0 (TID 119, localhost, executor driver, partition 9, ANY, 7649 bytes)
2021-12-03 22:36:52,064 [dispatcher-event-loop-6] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 10.0 in stage 7.0 (TID 120, localhost, executor driver, partition 10, ANY, 7649 bytes)
2021-12-03 22:36:52,064 [dispatcher-event-loop-6] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 11.0 in stage 7.0 (TID 121, localhost, executor driver, partition 11, ANY, 7649 bytes)
2021-12-03 22:36:52,064 [Executor task launch worker for task 110] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 7.0 (TID 110)
2021-12-03 22:36:52,064 [Executor task launch worker for task 120] INFO [org.apache.spark.executor.Executor] - Running task 10.0 in stage 7.0 (TID 120)
2021-12-03 22:36:52,064 [Executor task launch worker for task 112] INFO [org.apache.spark.executor.Executor] - Running task 2.0 in stage 7.0 (TID 112)
2021-12-03 22:36:52,064 [Executor task launch worker for task 121] INFO [org.apache.spark.executor.Executor] - Running task 11.0 in stage 7.0 (TID 121)
2021-12-03 22:36:52,064 [Executor task launch worker for task 114] INFO [org.apache.spark.executor.Executor] - Running task 4.0 in stage 7.0 (TID 114)
2021-12-03 22:36:52,064 [Executor task launch worker for task 116] INFO [org.apache.spark.executor.Executor] - Running task 6.0 in stage 7.0 (TID 116)
2021-12-03 22:36:52,064 [Executor task launch worker for task 111] INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 7.0 (TID 111)
2021-12-03 22:36:52,064 [Executor task launch worker for task 119] INFO [org.apache.spark.executor.Executor] - Running task 9.0 in stage 7.0 (TID 119)
2021-12-03 22:36:52,064 [Executor task launch worker for task 118] INFO [org.apache.spark.executor.Executor] - Running task 8.0 in stage 7.0 (TID 118)
2021-12-03 22:36:52,064 [Executor task launch worker for task 115] INFO [org.apache.spark.executor.Executor] - Running task 5.0 in stage 7.0 (TID 115)
2021-12-03 22:36:52,064 [Executor task launch worker for task 113] INFO [org.apache.spark.executor.Executor] - Running task 3.0 in stage 7.0 (TID 113)
2021-12-03 22:36:52,064 [Executor task launch worker for task 117] INFO [org.apache.spark.executor.Executor] - Running task 7.0 in stage 7.0 (TID 117)
2021-12-03 22:36:52,072 [Executor task launch worker for task 112] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 22:36:52,072 [Executor task launch worker for task 116] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 22:36:52,072 [Executor task launch worker for task 115] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 22:36:52,072 [Executor task launch worker for task 117] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 22:36:52,072 [Executor task launch worker for task 115] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 22:36:52,072 [Executor task launch worker for task 119] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 22:36:52,072 [Executor task launch worker for task 116] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 22:36:52,072 [Executor task launch worker for task 113] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 22:36:52,072 [Executor task launch worker for task 112] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 22:36:52,072 [Executor task launch worker for task 113] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 22:36:52,072 [Executor task launch worker for task 118] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 22:36:52,072 [Executor task launch worker for task 121] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 22:36:52,072 [Executor task launch worker for task 119] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 22:36:52,073 [Executor task launch worker for task 120] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 22:36:52,072 [Executor task launch worker for task 117] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 22:36:52,073 [Executor task launch worker for task 120] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 1 ms
2021-12-03 22:36:52,073 [Executor task launch worker for task 114] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 22:36:52,073 [Executor task launch worker for task 114] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 1 ms
2021-12-03 22:36:52,072 [Executor task launch worker for task 121] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 22:36:52,072 [Executor task launch worker for task 118] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 22:36:52,072 [Executor task launch worker for task 110] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 22:36:52,072 [Executor task launch worker for task 111] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 22:36:52,073 [Executor task launch worker for task 110] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 1 ms
2021-12-03 22:36:52,073 [Executor task launch worker for task 111] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 1 ms
2021-12-03 22:36:52,353 [Executor task launch worker for task 119] INFO [org.apache.spark.executor.Executor] - Finished task 9.0 in stage 7.0 (TID 119). 1055 bytes result sent to driver
2021-12-03 22:36:52,353 [Executor task launch worker for task 121] INFO [org.apache.spark.executor.Executor] - Finished task 11.0 in stage 7.0 (TID 121). 1055 bytes result sent to driver
2021-12-03 22:36:52,353 [dispatcher-event-loop-9] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 12.0 in stage 7.0 (TID 122, localhost, executor driver, partition 12, ANY, 7649 bytes)
2021-12-03 22:36:52,353 [Executor task launch worker for task 122] INFO [org.apache.spark.executor.Executor] - Running task 12.0 in stage 7.0 (TID 122)
2021-12-03 22:36:52,353 [dispatcher-event-loop-9] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 13.0 in stage 7.0 (TID 123, localhost, executor driver, partition 13, ANY, 7649 bytes)
2021-12-03 22:36:52,353 [Executor task launch worker for task 123] INFO [org.apache.spark.executor.Executor] - Running task 13.0 in stage 7.0 (TID 123)
2021-12-03 22:36:52,355 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 9.0 in stage 7.0 (TID 119) in 291 ms on localhost (executor driver) (1/21)
2021-12-03 22:36:52,355 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 11.0 in stage 7.0 (TID 121) in 291 ms on localhost (executor driver) (2/21)
2021-12-03 22:36:52,356 [Executor task launch worker for task 115] INFO [org.apache.spark.executor.Executor] - Finished task 5.0 in stage 7.0 (TID 115). 1055 bytes result sent to driver
2021-12-03 22:36:52,356 [dispatcher-event-loop-10] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 14.0 in stage 7.0 (TID 124, localhost, executor driver, partition 14, ANY, 7649 bytes)
2021-12-03 22:36:52,357 [Executor task launch worker for task 123] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 22:36:52,357 [Executor task launch worker for task 123] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 1 ms
2021-12-03 22:36:52,359 [Executor task launch worker for task 124] INFO [org.apache.spark.executor.Executor] - Running task 14.0 in stage 7.0 (TID 124)
2021-12-03 22:36:52,359 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 5.0 in stage 7.0 (TID 115) in 296 ms on localhost (executor driver) (3/21)
2021-12-03 22:36:52,362 [Executor task launch worker for task 118] INFO [org.apache.spark.executor.Executor] - Finished task 8.0 in stage 7.0 (TID 118). 1055 bytes result sent to driver
2021-12-03 22:36:52,362 [Executor task launch worker for task 116] INFO [org.apache.spark.executor.Executor] - Finished task 6.0 in stage 7.0 (TID 116). 1055 bytes result sent to driver
2021-12-03 22:36:52,362 [Executor task launch worker for task 113] INFO [org.apache.spark.executor.Executor] - Finished task 3.0 in stage 7.0 (TID 113). 1055 bytes result sent to driver
2021-12-03 22:36:52,362 [dispatcher-event-loop-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 15.0 in stage 7.0 (TID 125, localhost, executor driver, partition 15, ANY, 7649 bytes)
2021-12-03 22:36:52,362 [Executor task launch worker for task 125] INFO [org.apache.spark.executor.Executor] - Running task 15.0 in stage 7.0 (TID 125)
2021-12-03 22:36:52,362 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 8.0 in stage 7.0 (TID 118) in 299 ms on localhost (executor driver) (4/21)
2021-12-03 22:36:52,363 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 6.0 in stage 7.0 (TID 116) in 300 ms on localhost (executor driver) (5/21)
2021-12-03 22:36:52,363 [Executor task launch worker for task 122] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 22:36:52,363 [Executor task launch worker for task 122] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 22:36:52,363 [Executor task launch worker for task 120] INFO [org.apache.spark.executor.Executor] - Finished task 10.0 in stage 7.0 (TID 120). 1055 bytes result sent to driver
2021-12-03 22:36:52,363 [dispatcher-event-loop-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 16.0 in stage 7.0 (TID 126, localhost, executor driver, partition 16, ANY, 7649 bytes)
2021-12-03 22:36:52,363 [Executor task launch worker for task 126] INFO [org.apache.spark.executor.Executor] - Running task 16.0 in stage 7.0 (TID 126)
2021-12-03 22:36:52,363 [Executor task launch worker for task 124] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 22:36:52,363 [Executor task launch worker for task 124] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 22:36:52,363 [dispatcher-event-loop-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 17.0 in stage 7.0 (TID 127, localhost, executor driver, partition 17, ANY, 7649 bytes)
2021-12-03 22:36:52,363 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 3.0 in stage 7.0 (TID 113) in 300 ms on localhost (executor driver) (6/21)
2021-12-03 22:36:52,364 [Executor task launch worker for task 127] INFO [org.apache.spark.executor.Executor] - Running task 17.0 in stage 7.0 (TID 127)
2021-12-03 22:36:52,364 [dispatcher-event-loop-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 18.0 in stage 7.0 (TID 128, localhost, executor driver, partition 18, ANY, 7649 bytes)
2021-12-03 22:36:52,364 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 10.0 in stage 7.0 (TID 120) in 300 ms on localhost (executor driver) (7/21)
2021-12-03 22:36:52,364 [Executor task launch worker for task 128] INFO [org.apache.spark.executor.Executor] - Running task 18.0 in stage 7.0 (TID 128)
2021-12-03 22:36:52,365 [Executor task launch worker for task 114] INFO [org.apache.spark.executor.Executor] - Finished task 4.0 in stage 7.0 (TID 114). 1055 bytes result sent to driver
2021-12-03 22:36:52,365 [Executor task launch worker for task 111] INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 7.0 (TID 111). 1055 bytes result sent to driver
2021-12-03 22:36:52,365 [dispatcher-event-loop-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 19.0 in stage 7.0 (TID 129, localhost, executor driver, partition 19, ANY, 7649 bytes)
2021-12-03 22:36:52,366 [Executor task launch worker for task 129] INFO [org.apache.spark.executor.Executor] - Running task 19.0 in stage 7.0 (TID 129)
2021-12-03 22:36:52,366 [dispatcher-event-loop-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 20.0 in stage 7.0 (TID 130, localhost, executor driver, partition 20, ANY, 7649 bytes)
2021-12-03 22:36:52,366 [Executor task launch worker for task 130] INFO [org.apache.spark.executor.Executor] - Running task 20.0 in stage 7.0 (TID 130)
2021-12-03 22:36:52,366 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 4.0 in stage 7.0 (TID 114) in 303 ms on localhost (executor driver) (8/21)
2021-12-03 22:36:52,366 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 7.0 (TID 111) in 303 ms on localhost (executor driver) (9/21)
2021-12-03 22:36:52,366 [Executor task launch worker for task 125] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 22:36:52,366 [Executor task launch worker for task 125] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 22:36:52,367 [Executor task launch worker for task 117] INFO [org.apache.spark.executor.Executor] - Finished task 7.0 in stage 7.0 (TID 117). 1055 bytes result sent to driver
2021-12-03 22:36:52,367 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 7.0 in stage 7.0 (TID 117) in 304 ms on localhost (executor driver) (10/21)
2021-12-03 22:36:52,368 [Executor task launch worker for task 112] INFO [org.apache.spark.executor.Executor] - Finished task 2.0 in stage 7.0 (TID 112). 1055 bytes result sent to driver
2021-12-03 22:36:52,369 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 2.0 in stage 7.0 (TID 112) in 306 ms on localhost (executor driver) (11/21)
2021-12-03 22:36:52,369 [Executor task launch worker for task 127] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 22:36:52,369 [Executor task launch worker for task 127] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 22:36:52,369 [Executor task launch worker for task 129] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 22:36:52,369 [Executor task launch worker for task 129] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 22:36:52,369 [Executor task launch worker for task 126] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 22:36:52,369 [Executor task launch worker for task 126] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 22:36:52,370 [Executor task launch worker for task 110] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 7.0 (TID 110). 1055 bytes result sent to driver
2021-12-03 22:36:52,370 [Executor task launch worker for task 130] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 22:36:52,370 [Executor task launch worker for task 130] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 22:36:52,370 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 7.0 (TID 110) in 307 ms on localhost (executor driver) (12/21)
2021-12-03 22:36:52,371 [Executor task launch worker for task 128] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 22:36:52,371 [Executor task launch worker for task 128] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 22:36:52,447 [Executor task launch worker for task 124] INFO [org.apache.spark.executor.Executor] - Finished task 14.0 in stage 7.0 (TID 124). 1098 bytes result sent to driver
2021-12-03 22:36:52,447 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 14.0 in stage 7.0 (TID 124) in 91 ms on localhost (executor driver) (13/21)
2021-12-03 22:36:52,457 [Executor task launch worker for task 126] INFO [org.apache.spark.executor.Executor] - Finished task 16.0 in stage 7.0 (TID 126). 1098 bytes result sent to driver
2021-12-03 22:36:52,457 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 16.0 in stage 7.0 (TID 126) in 94 ms on localhost (executor driver) (14/21)
2021-12-03 22:36:52,461 [Executor task launch worker for task 128] INFO [org.apache.spark.executor.Executor] - Finished task 18.0 in stage 7.0 (TID 128). 1098 bytes result sent to driver
2021-12-03 22:36:52,461 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 18.0 in stage 7.0 (TID 128) in 97 ms on localhost (executor driver) (15/21)
2021-12-03 22:36:52,462 [Executor task launch worker for task 125] INFO [org.apache.spark.executor.Executor] - Finished task 15.0 in stage 7.0 (TID 125). 1098 bytes result sent to driver
2021-12-03 22:36:52,462 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 15.0 in stage 7.0 (TID 125) in 100 ms on localhost (executor driver) (16/21)
2021-12-03 22:36:52,462 [Executor task launch worker for task 129] INFO [org.apache.spark.executor.Executor] - Finished task 19.0 in stage 7.0 (TID 129). 1098 bytes result sent to driver
2021-12-03 22:36:52,463 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 19.0 in stage 7.0 (TID 129) in 98 ms on localhost (executor driver) (17/21)
2021-12-03 22:36:52,467 [Executor task launch worker for task 123] INFO [org.apache.spark.executor.Executor] - Finished task 13.0 in stage 7.0 (TID 123). 1098 bytes result sent to driver
2021-12-03 22:36:52,467 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 13.0 in stage 7.0 (TID 123) in 114 ms on localhost (executor driver) (18/21)
2021-12-03 22:36:52,469 [Executor task launch worker for task 130] INFO [org.apache.spark.executor.Executor] - Finished task 20.0 in stage 7.0 (TID 130). 1098 bytes result sent to driver
2021-12-03 22:36:52,469 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 20.0 in stage 7.0 (TID 130) in 103 ms on localhost (executor driver) (19/21)
2021-12-03 22:36:52,470 [Executor task launch worker for task 127] INFO [org.apache.spark.executor.Executor] - Finished task 17.0 in stage 7.0 (TID 127). 1098 bytes result sent to driver
2021-12-03 22:36:52,470 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 17.0 in stage 7.0 (TID 127) in 107 ms on localhost (executor driver) (20/21)
2021-12-03 22:36:52,472 [Executor task launch worker for task 122] INFO [org.apache.spark.executor.Executor] - Finished task 12.0 in stage 7.0 (TID 122). 1098 bytes result sent to driver
2021-12-03 22:36:52,472 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 12.0 in stage 7.0 (TID 122) in 119 ms on localhost (executor driver) (21/21)
2021-12-03 22:36:52,472 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 7.0, whose tasks have all completed, from pool 
2021-12-03 22:36:52,472 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 7 (zipWithIndex at PaidPromotionAdjustParameter.scala:74) finished in 0.414 s
2021-12-03 22:36:52,473 [main] INFO [org.apache.spark.scheduler.DAGScheduler] - Job 3 finished: zipWithIndex at PaidPromotionAdjustParameter.scala:74, took 1.553307 s
2021-12-03 22:36:52,510 [main] INFO [org.apache.spark.SparkContext] - Starting job: count at PaidPromotionAdjustParameter.scala:79
2021-12-03 22:36:52,511 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 4 (count at PaidPromotionAdjustParameter.scala:79) with 22 output partitions
2021-12-03 22:36:52,511 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 10 (count at PaidPromotionAdjustParameter.scala:79)
2021-12-03 22:36:52,511 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 9)
2021-12-03 22:36:52,511 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2021-12-03 22:36:52,511 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 10 (MapPartitionsRDD[11] at map at PaidPromotionAdjustParameter.scala:76), which has no missing parents
2021-12-03 22:36:52,515 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_7 stored as values in memory (estimated size 4.2 KB, free 1990.4 MB)
2021-12-03 22:36:52,517 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_7_piece0 stored as bytes in memory (estimated size 2.4 KB, free 1990.4 MB)
2021-12-03 22:36:52,517 [dispatcher-event-loop-4] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_7_piece0 in memory on qb:59961 (size: 2.4 KB, free: 1990.8 MB)
2021-12-03 22:36:52,517 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 7 from broadcast at DAGScheduler.scala:1039
2021-12-03 22:36:52,518 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 22 missing tasks from ResultStage 10 (MapPartitionsRDD[11] at map at PaidPromotionAdjustParameter.scala:76) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14))
2021-12-03 22:36:52,518 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 10.0 with 22 tasks
2021-12-03 22:36:52,519 [dispatcher-event-loop-5] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 10.0 (TID 131, localhost, executor driver, partition 0, ANY, 7759 bytes)
2021-12-03 22:36:52,519 [dispatcher-event-loop-5] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 10.0 (TID 132, localhost, executor driver, partition 1, ANY, 7759 bytes)
2021-12-03 22:36:52,519 [dispatcher-event-loop-5] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 2.0 in stage 10.0 (TID 133, localhost, executor driver, partition 2, ANY, 7759 bytes)
2021-12-03 22:36:52,519 [dispatcher-event-loop-5] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 3.0 in stage 10.0 (TID 134, localhost, executor driver, partition 3, ANY, 7759 bytes)
2021-12-03 22:36:52,519 [dispatcher-event-loop-5] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 4.0 in stage 10.0 (TID 135, localhost, executor driver, partition 4, ANY, 7759 bytes)
2021-12-03 22:36:52,519 [dispatcher-event-loop-5] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 5.0 in stage 10.0 (TID 136, localhost, executor driver, partition 5, ANY, 7759 bytes)
2021-12-03 22:36:52,519 [dispatcher-event-loop-5] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 6.0 in stage 10.0 (TID 137, localhost, executor driver, partition 6, ANY, 7759 bytes)
2021-12-03 22:36:52,519 [dispatcher-event-loop-5] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 7.0 in stage 10.0 (TID 138, localhost, executor driver, partition 7, ANY, 7759 bytes)
2021-12-03 22:36:52,519 [dispatcher-event-loop-5] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 8.0 in stage 10.0 (TID 139, localhost, executor driver, partition 8, ANY, 7759 bytes)
2021-12-03 22:36:52,519 [dispatcher-event-loop-5] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 9.0 in stage 10.0 (TID 140, localhost, executor driver, partition 9, ANY, 7759 bytes)
2021-12-03 22:36:52,519 [dispatcher-event-loop-5] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 10.0 in stage 10.0 (TID 141, localhost, executor driver, partition 10, ANY, 7759 bytes)
2021-12-03 22:36:52,519 [dispatcher-event-loop-5] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 11.0 in stage 10.0 (TID 142, localhost, executor driver, partition 11, ANY, 7759 bytes)
2021-12-03 22:36:52,520 [Executor task launch worker for task 136] INFO [org.apache.spark.executor.Executor] - Running task 5.0 in stage 10.0 (TID 136)
2021-12-03 22:36:52,520 [Executor task launch worker for task 133] INFO [org.apache.spark.executor.Executor] - Running task 2.0 in stage 10.0 (TID 133)
2021-12-03 22:36:52,520 [Executor task launch worker for task 131] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 10.0 (TID 131)
2021-12-03 22:36:52,520 [Executor task launch worker for task 138] INFO [org.apache.spark.executor.Executor] - Running task 7.0 in stage 10.0 (TID 138)
2021-12-03 22:36:52,520 [Executor task launch worker for task 134] INFO [org.apache.spark.executor.Executor] - Running task 3.0 in stage 10.0 (TID 134)
2021-12-03 22:36:52,520 [Executor task launch worker for task 135] INFO [org.apache.spark.executor.Executor] - Running task 4.0 in stage 10.0 (TID 135)
2021-12-03 22:36:52,520 [Executor task launch worker for task 139] INFO [org.apache.spark.executor.Executor] - Running task 8.0 in stage 10.0 (TID 139)
2021-12-03 22:36:52,520 [Executor task launch worker for task 140] INFO [org.apache.spark.executor.Executor] - Running task 9.0 in stage 10.0 (TID 140)
2021-12-03 22:36:52,520 [Executor task launch worker for task 137] INFO [org.apache.spark.executor.Executor] - Running task 6.0 in stage 10.0 (TID 137)
2021-12-03 22:36:52,520 [Executor task launch worker for task 141] INFO [org.apache.spark.executor.Executor] - Running task 10.0 in stage 10.0 (TID 141)
2021-12-03 22:36:52,520 [Executor task launch worker for task 132] INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 10.0 (TID 132)
2021-12-03 22:36:52,520 [Executor task launch worker for task 142] INFO [org.apache.spark.executor.Executor] - Running task 11.0 in stage 10.0 (TID 142)
2021-12-03 22:36:52,524 [Executor task launch worker for task 142] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 22:36:52,524 [Executor task launch worker for task 131] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 22:36:52,524 [Executor task launch worker for task 142] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 22:36:52,524 [Executor task launch worker for task 131] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 22:36:52,525 [Executor task launch worker for task 135] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 22:36:52,525 [Executor task launch worker for task 135] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 22:36:52,525 [Executor task launch worker for task 132] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 22:36:52,525 [Executor task launch worker for task 132] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 22:36:52,526 [Executor task launch worker for task 140] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 22:36:52,526 [Executor task launch worker for task 140] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 22:36:52,526 [Executor task launch worker for task 133] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 22:36:52,526 [Executor task launch worker for task 133] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 22:36:52,527 [Executor task launch worker for task 137] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 22:36:52,527 [Executor task launch worker for task 137] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 22:36:52,527 [Executor task launch worker for task 141] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 22:36:52,527 [Executor task launch worker for task 141] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 22:36:52,528 [Executor task launch worker for task 136] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 22:36:52,528 [Executor task launch worker for task 136] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 22:36:52,528 [Executor task launch worker for task 139] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 22:36:52,528 [Executor task launch worker for task 139] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 22:36:52,529 [Executor task launch worker for task 138] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 22:36:52,529 [Executor task launch worker for task 138] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 22:36:52,529 [Executor task launch worker for task 134] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 22:36:52,529 [Executor task launch worker for task 134] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 22:36:52,645 [Executor task launch worker for task 135] INFO [org.apache.spark.executor.Executor] - Finished task 4.0 in stage 10.0 (TID 135). 1055 bytes result sent to driver
2021-12-03 22:36:52,646 [dispatcher-event-loop-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 12.0 in stage 10.0 (TID 143, localhost, executor driver, partition 12, ANY, 7759 bytes)
2021-12-03 22:36:52,646 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 4.0 in stage 10.0 (TID 135) in 127 ms on localhost (executor driver) (1/22)
2021-12-03 22:36:52,646 [Executor task launch worker for task 143] INFO [org.apache.spark.executor.Executor] - Running task 12.0 in stage 10.0 (TID 143)
2021-12-03 22:36:52,646 [Executor task launch worker for task 140] INFO [org.apache.spark.executor.Executor] - Finished task 9.0 in stage 10.0 (TID 140). 1055 bytes result sent to driver
2021-12-03 22:36:52,646 [dispatcher-event-loop-6] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 13.0 in stage 10.0 (TID 144, localhost, executor driver, partition 13, ANY, 7759 bytes)
2021-12-03 22:36:52,646 [Executor task launch worker for task 144] INFO [org.apache.spark.executor.Executor] - Running task 13.0 in stage 10.0 (TID 144)
2021-12-03 22:36:52,646 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 9.0 in stage 10.0 (TID 140) in 127 ms on localhost (executor driver) (2/22)
2021-12-03 22:36:52,649 [Executor task launch worker for task 143] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 22:36:52,649 [Executor task launch worker for task 143] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 22:36:52,650 [Executor task launch worker for task 144] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 22:36:52,650 [Executor task launch worker for task 144] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 22:36:52,651 [Executor task launch worker for task 136] INFO [org.apache.spark.executor.Executor] - Finished task 5.0 in stage 10.0 (TID 136). 1055 bytes result sent to driver
2021-12-03 22:36:52,652 [dispatcher-event-loop-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 14.0 in stage 10.0 (TID 145, localhost, executor driver, partition 14, ANY, 7759 bytes)
2021-12-03 22:36:52,652 [Executor task launch worker for task 145] INFO [org.apache.spark.executor.Executor] - Running task 14.0 in stage 10.0 (TID 145)
2021-12-03 22:36:52,652 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 5.0 in stage 10.0 (TID 136) in 133 ms on localhost (executor driver) (3/22)
2021-12-03 22:36:52,655 [Executor task launch worker for task 142] INFO [org.apache.spark.executor.Executor] - Finished task 11.0 in stage 10.0 (TID 142). 1055 bytes result sent to driver
2021-12-03 22:36:52,656 [dispatcher-event-loop-11] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 15.0 in stage 10.0 (TID 146, localhost, executor driver, partition 15, ANY, 7759 bytes)
2021-12-03 22:36:52,656 [Executor task launch worker for task 146] INFO [org.apache.spark.executor.Executor] - Running task 15.0 in stage 10.0 (TID 146)
2021-12-03 22:36:52,656 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 11.0 in stage 10.0 (TID 142) in 137 ms on localhost (executor driver) (4/22)
2021-12-03 22:36:52,656 [Executor task launch worker for task 145] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 22:36:52,656 [Executor task launch worker for task 145] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 22:36:52,658 [Executor task launch worker for task 137] INFO [org.apache.spark.executor.Executor] - Finished task 6.0 in stage 10.0 (TID 137). 1055 bytes result sent to driver
2021-12-03 22:36:52,658 [Executor task launch worker for task 131] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 10.0 (TID 131). 1053 bytes result sent to driver
2021-12-03 22:36:52,659 [dispatcher-event-loop-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 16.0 in stage 10.0 (TID 147, localhost, executor driver, partition 16, ANY, 7759 bytes)
2021-12-03 22:36:52,659 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 6.0 in stage 10.0 (TID 137) in 140 ms on localhost (executor driver) (5/22)
2021-12-03 22:36:52,659 [Executor task launch worker for task 147] INFO [org.apache.spark.executor.Executor] - Running task 16.0 in stage 10.0 (TID 147)
2021-12-03 22:36:52,659 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 10.0 (TID 131) in 141 ms on localhost (executor driver) (6/22)
2021-12-03 22:36:52,659 [Executor task launch worker for task 141] INFO [org.apache.spark.executor.Executor] - Finished task 10.0 in stage 10.0 (TID 141). 1055 bytes result sent to driver
2021-12-03 22:36:52,659 [dispatcher-event-loop-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 17.0 in stage 10.0 (TID 148, localhost, executor driver, partition 17, ANY, 7759 bytes)
2021-12-03 22:36:52,659 [Executor task launch worker for task 148] INFO [org.apache.spark.executor.Executor] - Running task 17.0 in stage 10.0 (TID 148)
2021-12-03 22:36:52,659 [dispatcher-event-loop-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 18.0 in stage 10.0 (TID 149, localhost, executor driver, partition 18, ANY, 7759 bytes)
2021-12-03 22:36:52,660 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 10.0 in stage 10.0 (TID 141) in 141 ms on localhost (executor driver) (7/22)
2021-12-03 22:36:52,660 [Executor task launch worker for task 146] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 22:36:52,660 [Executor task launch worker for task 146] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 22:36:52,660 [Executor task launch worker for task 149] INFO [org.apache.spark.executor.Executor] - Running task 18.0 in stage 10.0 (TID 149)
2021-12-03 22:36:52,660 [Executor task launch worker for task 132] INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 10.0 (TID 132). 1053 bytes result sent to driver
2021-12-03 22:36:52,661 [dispatcher-event-loop-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 19.0 in stage 10.0 (TID 150, localhost, executor driver, partition 19, ANY, 7759 bytes)
2021-12-03 22:36:52,661 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 10.0 (TID 132) in 142 ms on localhost (executor driver) (8/22)
2021-12-03 22:36:52,661 [Executor task launch worker for task 150] INFO [org.apache.spark.executor.Executor] - Running task 19.0 in stage 10.0 (TID 150)
2021-12-03 22:36:52,662 [Executor task launch worker for task 147] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 22:36:52,662 [Executor task launch worker for task 147] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 22:36:52,663 [Executor task launch worker for task 148] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 22:36:52,663 [Executor task launch worker for task 148] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 22:36:52,664 [Executor task launch worker for task 149] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 22:36:52,664 [Executor task launch worker for task 150] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 22:36:52,664 [Executor task launch worker for task 149] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 22:36:52,664 [Executor task launch worker for task 150] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 22:36:52,675 [Executor task launch worker for task 134] INFO [org.apache.spark.executor.Executor] - Finished task 3.0 in stage 10.0 (TID 134). 1055 bytes result sent to driver
2021-12-03 22:36:52,675 [dispatcher-event-loop-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 20.0 in stage 10.0 (TID 151, localhost, executor driver, partition 20, ANY, 7759 bytes)
2021-12-03 22:36:52,676 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 3.0 in stage 10.0 (TID 134) in 157 ms on localhost (executor driver) (9/22)
2021-12-03 22:36:52,676 [Executor task launch worker for task 151] INFO [org.apache.spark.executor.Executor] - Running task 20.0 in stage 10.0 (TID 151)
2021-12-03 22:36:52,680 [Executor task launch worker for task 151] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 22:36:52,680 [Executor task launch worker for task 151] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 22:36:52,716 [Executor task launch worker for task 139] INFO [org.apache.spark.executor.Executor] - Finished task 8.0 in stage 10.0 (TID 139). 1098 bytes result sent to driver
2021-12-03 22:36:52,720 [dispatcher-event-loop-11] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 21.0 in stage 10.0 (TID 152, localhost, executor driver, partition 21, ANY, 7759 bytes)
2021-12-03 22:36:52,720 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 8.0 in stage 10.0 (TID 139) in 201 ms on localhost (executor driver) (10/22)
2021-12-03 22:36:52,721 [Executor task launch worker for task 138] INFO [org.apache.spark.executor.Executor] - Finished task 7.0 in stage 10.0 (TID 138). 1098 bytes result sent to driver
2021-12-03 22:36:52,721 [Executor task launch worker for task 133] INFO [org.apache.spark.executor.Executor] - Finished task 2.0 in stage 10.0 (TID 133). 1098 bytes result sent to driver
2021-12-03 22:36:52,721 [Executor task launch worker for task 152] INFO [org.apache.spark.executor.Executor] - Running task 21.0 in stage 10.0 (TID 152)
2021-12-03 22:36:52,726 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 2.0 in stage 10.0 (TID 133) in 207 ms on localhost (executor driver) (11/22)
2021-12-03 22:36:52,726 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 7.0 in stage 10.0 (TID 138) in 207 ms on localhost (executor driver) (12/22)
2021-12-03 22:36:52,732 [dispatcher-event-loop-1] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_6_piece0 on qb:59961 in memory (size: 2.0 KB, free: 1990.8 MB)
2021-12-03 22:36:52,735 [Executor task launch worker for task 152] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 22:36:52,735 [Executor task launch worker for task 152] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 22:36:52,768 [Executor task launch worker for task 145] INFO [org.apache.spark.executor.Executor] - Finished task 14.0 in stage 10.0 (TID 145). 1141 bytes result sent to driver
2021-12-03 22:36:52,768 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 14.0 in stage 10.0 (TID 145) in 117 ms on localhost (executor driver) (13/22)
2021-12-03 22:36:52,786 [Executor task launch worker for task 147] INFO [org.apache.spark.executor.Executor] - Finished task 16.0 in stage 10.0 (TID 147). 1098 bytes result sent to driver
2021-12-03 22:36:52,786 [Executor task launch worker for task 150] INFO [org.apache.spark.executor.Executor] - Finished task 19.0 in stage 10.0 (TID 150). 1098 bytes result sent to driver
2021-12-03 22:36:52,786 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 16.0 in stage 10.0 (TID 147) in 128 ms on localhost (executor driver) (14/22)
2021-12-03 22:36:52,786 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 19.0 in stage 10.0 (TID 150) in 125 ms on localhost (executor driver) (15/22)
2021-12-03 22:36:52,788 [Executor task launch worker for task 144] INFO [org.apache.spark.executor.Executor] - Finished task 13.0 in stage 10.0 (TID 144). 1098 bytes result sent to driver
2021-12-03 22:36:52,788 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 13.0 in stage 10.0 (TID 144) in 142 ms on localhost (executor driver) (16/22)
2021-12-03 22:36:52,792 [Executor task launch worker for task 146] INFO [org.apache.spark.executor.Executor] - Finished task 15.0 in stage 10.0 (TID 146). 1098 bytes result sent to driver
2021-12-03 22:36:52,792 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 15.0 in stage 10.0 (TID 146) in 136 ms on localhost (executor driver) (17/22)
2021-12-03 22:36:52,793 [Executor task launch worker for task 149] INFO [org.apache.spark.executor.Executor] - Finished task 18.0 in stage 10.0 (TID 149). 1098 bytes result sent to driver
2021-12-03 22:36:52,793 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 18.0 in stage 10.0 (TID 149) in 134 ms on localhost (executor driver) (18/22)
2021-12-03 22:36:52,795 [Executor task launch worker for task 151] INFO [org.apache.spark.executor.Executor] - Finished task 20.0 in stage 10.0 (TID 151). 1096 bytes result sent to driver
2021-12-03 22:36:52,796 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 20.0 in stage 10.0 (TID 151) in 121 ms on localhost (executor driver) (19/22)
2021-12-03 22:36:52,799 [Executor task launch worker for task 143] INFO [org.apache.spark.executor.Executor] - Finished task 12.0 in stage 10.0 (TID 143). 1141 bytes result sent to driver
2021-12-03 22:36:52,799 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 12.0 in stage 10.0 (TID 143) in 154 ms on localhost (executor driver) (20/22)
2021-12-03 22:36:52,800 [Executor task launch worker for task 148] INFO [org.apache.spark.executor.Executor] - Finished task 17.0 in stage 10.0 (TID 148). 1098 bytes result sent to driver
2021-12-03 22:36:52,801 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 17.0 in stage 10.0 (TID 148) in 141 ms on localhost (executor driver) (21/22)
2021-12-03 22:36:52,817 [Executor task launch worker for task 152] INFO [org.apache.spark.executor.Executor] - Finished task 21.0 in stage 10.0 (TID 152). 1053 bytes result sent to driver
2021-12-03 22:36:52,817 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 21.0 in stage 10.0 (TID 152) in 97 ms on localhost (executor driver) (22/22)
2021-12-03 22:36:52,817 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 10.0, whose tasks have all completed, from pool 
2021-12-03 22:36:52,817 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 10 (count at PaidPromotionAdjustParameter.scala:79) finished in 0.304 s
2021-12-03 22:36:52,818 [main] INFO [org.apache.spark.scheduler.DAGScheduler] - Job 4 finished: count at PaidPromotionAdjustParameter.scala:79, took 0.307479 s
2021-12-03 22:36:52,818 [main] INFO [PaidPromotion$] - 小数据集个数：922280
2021-12-03 22:36:52,832 [main] INFO [org.apache.spark.SparkContext] - Starting job: count at PaidPromotionAdjustParameter.scala:85
2021-12-03 22:36:52,833 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 5 (count at PaidPromotionAdjustParameter.scala:85) with 22 output partitions
2021-12-03 22:36:52,833 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 11 (count at PaidPromotionAdjustParameter.scala:85)
2021-12-03 22:36:52,833 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List()
2021-12-03 22:36:52,833 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2021-12-03 22:36:52,833 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 11 (MapPartitionsRDD[12] at map at PaidPromotionAdjustParameter.scala:83), which has no missing parents
2021-12-03 22:36:52,835 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_8 stored as values in memory (estimated size 3.4 KB, free 1990.4 MB)
2021-12-03 22:36:52,837 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_8_piece0 stored as bytes in memory (estimated size 2022.0 B, free 1990.4 MB)
2021-12-03 22:36:52,837 [dispatcher-event-loop-0] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_8_piece0 in memory on qb:59961 (size: 2022.0 B, free: 1990.8 MB)
2021-12-03 22:36:52,837 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 8 from broadcast at DAGScheduler.scala:1039
2021-12-03 22:36:52,838 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 22 missing tasks from ResultStage 11 (MapPartitionsRDD[12] at map at PaidPromotionAdjustParameter.scala:83) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14))
2021-12-03 22:36:52,838 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 11.0 with 22 tasks
2021-12-03 22:36:52,838 [dispatcher-event-loop-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 11.0 (TID 153, localhost, executor driver, partition 0, ANY, 7899 bytes)
2021-12-03 22:36:52,838 [dispatcher-event-loop-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 11.0 (TID 154, localhost, executor driver, partition 1, ANY, 7899 bytes)
2021-12-03 22:36:52,838 [dispatcher-event-loop-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 2.0 in stage 11.0 (TID 155, localhost, executor driver, partition 2, ANY, 7899 bytes)
2021-12-03 22:36:52,839 [dispatcher-event-loop-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 3.0 in stage 11.0 (TID 156, localhost, executor driver, partition 3, ANY, 7899 bytes)
2021-12-03 22:36:52,839 [dispatcher-event-loop-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 4.0 in stage 11.0 (TID 157, localhost, executor driver, partition 4, ANY, 7899 bytes)
2021-12-03 22:36:52,839 [dispatcher-event-loop-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 5.0 in stage 11.0 (TID 158, localhost, executor driver, partition 5, ANY, 7899 bytes)
2021-12-03 22:36:52,839 [dispatcher-event-loop-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 6.0 in stage 11.0 (TID 159, localhost, executor driver, partition 6, ANY, 7899 bytes)
2021-12-03 22:36:52,839 [dispatcher-event-loop-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 7.0 in stage 11.0 (TID 160, localhost, executor driver, partition 7, ANY, 7899 bytes)
2021-12-03 22:36:52,839 [dispatcher-event-loop-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 8.0 in stage 11.0 (TID 161, localhost, executor driver, partition 8, ANY, 7899 bytes)
2021-12-03 22:36:52,839 [dispatcher-event-loop-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 9.0 in stage 11.0 (TID 162, localhost, executor driver, partition 9, ANY, 7899 bytes)
2021-12-03 22:36:52,839 [dispatcher-event-loop-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 10.0 in stage 11.0 (TID 163, localhost, executor driver, partition 10, ANY, 7899 bytes)
2021-12-03 22:36:52,839 [dispatcher-event-loop-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 11.0 in stage 11.0 (TID 164, localhost, executor driver, partition 11, ANY, 7899 bytes)
2021-12-03 22:36:52,839 [Executor task launch worker for task 154] INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 11.0 (TID 154)
2021-12-03 22:36:52,839 [Executor task launch worker for task 161] INFO [org.apache.spark.executor.Executor] - Running task 8.0 in stage 11.0 (TID 161)
2021-12-03 22:36:52,839 [Executor task launch worker for task 158] INFO [org.apache.spark.executor.Executor] - Running task 5.0 in stage 11.0 (TID 158)
2021-12-03 22:36:52,839 [Executor task launch worker for task 156] INFO [org.apache.spark.executor.Executor] - Running task 3.0 in stage 11.0 (TID 156)
2021-12-03 22:36:52,839 [Executor task launch worker for task 157] INFO [org.apache.spark.executor.Executor] - Running task 4.0 in stage 11.0 (TID 157)
2021-12-03 22:36:52,839 [Executor task launch worker for task 155] INFO [org.apache.spark.executor.Executor] - Running task 2.0 in stage 11.0 (TID 155)
2021-12-03 22:36:52,839 [Executor task launch worker for task 153] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 11.0 (TID 153)
2021-12-03 22:36:52,839 [Executor task launch worker for task 164] INFO [org.apache.spark.executor.Executor] - Running task 11.0 in stage 11.0 (TID 164)
2021-12-03 22:36:52,839 [Executor task launch worker for task 163] INFO [org.apache.spark.executor.Executor] - Running task 10.0 in stage 11.0 (TID 163)
2021-12-03 22:36:52,839 [Executor task launch worker for task 160] INFO [org.apache.spark.executor.Executor] - Running task 7.0 in stage 11.0 (TID 160)
2021-12-03 22:36:52,839 [Executor task launch worker for task 162] INFO [org.apache.spark.executor.Executor] - Running task 9.0 in stage 11.0 (TID 162)
2021-12-03 22:36:52,839 [Executor task launch worker for task 159] INFO [org.apache.spark.executor.Executor] - Running task 6.0 in stage 11.0 (TID 159)
2021-12-03 22:36:52,840 [Executor task launch worker for task 155] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:268435456+134217728
2021-12-03 22:36:52,840 [Executor task launch worker for task 153] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:0+134217728
2021-12-03 22:36:52,840 [Executor task launch worker for task 164] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:1476395008+134217728
2021-12-03 22:36:52,841 [Executor task launch worker for task 162] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:1207959552+134217728
2021-12-03 22:36:52,840 [Executor task launch worker for task 163] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:1342177280+134217728
2021-12-03 22:36:52,841 [Executor task launch worker for task 154] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:134217728+134217728
2021-12-03 22:36:52,840 [Executor task launch worker for task 161] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:1073741824+134217728
2021-12-03 22:36:52,841 [Executor task launch worker for task 156] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:402653184+134217728
2021-12-03 22:36:52,841 [Executor task launch worker for task 158] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:671088640+134217728
2021-12-03 22:36:52,841 [Executor task launch worker for task 159] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:805306368+134217728
2021-12-03 22:36:52,841 [Executor task launch worker for task 157] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:536870912+134217728
2021-12-03 22:36:52,840 [Executor task launch worker for task 160] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:939524096+134217728
2021-12-03 22:36:54,190 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 162
2021-12-03 22:36:54,190 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 150
2021-12-03 22:36:54,190 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 170
2021-12-03 22:36:54,190 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 168
2021-12-03 22:36:54,190 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 173
2021-12-03 22:36:54,190 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 165
2021-12-03 22:36:54,190 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 160
2021-12-03 22:36:54,190 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 161
2021-12-03 22:36:54,190 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 158
2021-12-03 22:36:54,190 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 166
2021-12-03 22:36:54,190 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 169
2021-12-03 22:36:54,190 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 152
2021-12-03 22:36:54,190 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 159
2021-12-03 22:36:54,190 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 153
2021-12-03 22:36:54,190 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 174
2021-12-03 22:36:54,191 [dispatcher-event-loop-3] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_7_piece0 on qb:59961 in memory (size: 2.4 KB, free: 1990.8 MB)
2021-12-03 22:36:54,191 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 151
2021-12-03 22:36:54,191 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 164
2021-12-03 22:36:54,191 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 155
2021-12-03 22:36:54,191 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 154
2021-12-03 22:36:54,191 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 167
2021-12-03 22:36:54,191 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 157
2021-12-03 22:36:54,191 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 163
2021-12-03 22:36:54,191 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 156
2021-12-03 22:36:54,191 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 171
2021-12-03 22:36:54,191 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 172
2021-12-03 22:38:03,439 [Thread-1] INFO [org.apache.spark.SparkContext] - Invoking stop() from shutdown hook
2021-12-03 22:38:03,444 [Thread-1] INFO [org.spark_project.jetty.server.AbstractConnector] - Stopped Spark@3414a8c3{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2021-12-03 22:38:03,445 [Thread-1] INFO [org.apache.spark.ui.SparkUI] - Stopped Spark web UI at http://qb:4040
2021-12-03 22:38:03,450 [main] INFO [org.apache.spark.scheduler.DAGScheduler] - Job 5 failed: count at PaidPromotionAdjustParameter.scala:85, took 70.617806 s
2021-12-03 22:38:03,451 [Thread-1] INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 11 (count at PaidPromotionAdjustParameter.scala:85) failed in 70.615 s due to Stage cancelled because SparkContext was shut down
2021-12-03 22:38:03,457 [dispatcher-event-loop-4] INFO [org.apache.spark.MapOutputTrackerMasterEndpoint] - MapOutputTrackerMasterEndpoint stopped!
2021-12-03 22:38:03,544 [Thread-1] INFO [org.apache.spark.storage.memory.MemoryStore] - MemoryStore cleared
2021-12-03 22:38:03,544 [Thread-1] INFO [org.apache.spark.storage.BlockManager] - BlockManager stopped
2021-12-03 22:38:03,544 [Thread-1] INFO [org.apache.spark.storage.BlockManagerMaster] - BlockManagerMaster stopped
2021-12-03 22:38:03,547 [dispatcher-event-loop-6] INFO [org.apache.spark.scheduler.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint] - OutputCommitCoordinator stopped!
2021-12-03 22:38:03,549 [Thread-1] INFO [org.apache.spark.SparkContext] - Successfully stopped SparkContext
2021-12-03 22:38:03,549 [Thread-1] INFO [org.apache.spark.util.ShutdownHookManager] - Shutdown hook called
2021-12-03 22:38:03,550 [Thread-1] INFO [org.apache.spark.util.ShutdownHookManager] - Deleting directory C:\Users\ACER\AppData\Local\Temp\spark-6e31209b-8b5d-48f6-9a22-ca32d97ead5c
2021-12-03 22:39:25,970 [main] INFO [org.apache.spark.SparkContext] - Running Spark version 2.3.0
2021-12-03 22:39:26,255 [main] INFO [org.apache.spark.SparkContext] - Submitted application: PaidPromotion
2021-12-03 22:39:26,306 [main] INFO [org.apache.spark.SecurityManager] - Changing view acls to: ACER,root
2021-12-03 22:39:26,306 [main] INFO [org.apache.spark.SecurityManager] - Changing modify acls to: ACER,root
2021-12-03 22:39:26,307 [main] INFO [org.apache.spark.SecurityManager] - Changing view acls groups to: 
2021-12-03 22:39:26,307 [main] INFO [org.apache.spark.SecurityManager] - Changing modify acls groups to: 
2021-12-03 22:39:26,307 [main] INFO [org.apache.spark.SecurityManager] - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(ACER, root); groups with view permissions: Set(); users  with modify permissions: Set(ACER, root); groups with modify permissions: Set()
2021-12-03 22:39:26,905 [main] INFO [org.apache.spark.util.Utils] - Successfully started service 'sparkDriver' on port 54331.
2021-12-03 22:39:26,924 [main] INFO [org.apache.spark.SparkEnv] - Registering MapOutputTracker
2021-12-03 22:39:26,939 [main] INFO [org.apache.spark.SparkEnv] - Registering BlockManagerMaster
2021-12-03 22:39:26,941 [main] INFO [org.apache.spark.storage.BlockManagerMasterEndpoint] - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2021-12-03 22:39:26,942 [main] INFO [org.apache.spark.storage.BlockManagerMasterEndpoint] - BlockManagerMasterEndpoint up
2021-12-03 22:39:26,949 [main] INFO [org.apache.spark.storage.DiskBlockManager] - Created local directory at C:\Users\ACER\AppData\Local\Temp\blockmgr-f2323e06-d31c-4ba9-958e-89f2b35d9800
2021-12-03 22:39:26,962 [main] INFO [org.apache.spark.storage.memory.MemoryStore] - MemoryStore started with capacity 1990.8 MB
2021-12-03 22:39:26,971 [main] INFO [org.apache.spark.SparkEnv] - Registering OutputCommitCoordinator
2021-12-03 22:39:27,025 [main] INFO [org.spark_project.jetty.util.log] - Logging initialized @2911ms
2021-12-03 22:39:27,072 [main] INFO [org.spark_project.jetty.server.Server] - jetty-9.3.z-SNAPSHOT
2021-12-03 22:39:27,082 [main] INFO [org.spark_project.jetty.server.Server] - Started @2968ms
2021-12-03 22:39:27,104 [main] INFO [org.spark_project.jetty.server.AbstractConnector] - Started ServerConnector@3414a8c3{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2021-12-03 22:39:27,104 [main] INFO [org.apache.spark.util.Utils] - Successfully started service 'SparkUI' on port 4040.
2021-12-03 22:39:27,125 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@27b45ea{/jobs,null,AVAILABLE,@Spark}
2021-12-03 22:39:27,126 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@4fc142ec{/jobs/json,null,AVAILABLE,@Spark}
2021-12-03 22:39:27,127 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@702b06fb{/jobs/job,null,AVAILABLE,@Spark}
2021-12-03 22:39:27,128 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@2b22a1cc{/jobs/job/json,null,AVAILABLE,@Spark}
2021-12-03 22:39:27,129 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@7fd8c559{/stages,null,AVAILABLE,@Spark}
2021-12-03 22:39:27,130 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@55a88417{/stages/json,null,AVAILABLE,@Spark}
2021-12-03 22:39:27,131 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@19962194{/stages/stage,null,AVAILABLE,@Spark}
2021-12-03 22:39:27,132 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@3cbf1ba4{/stages/stage/json,null,AVAILABLE,@Spark}
2021-12-03 22:39:27,133 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@3dd818e8{/stages/pool,null,AVAILABLE,@Spark}
2021-12-03 22:39:27,134 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@47b67fcb{/stages/pool/json,null,AVAILABLE,@Spark}
2021-12-03 22:39:27,135 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@66420549{/storage,null,AVAILABLE,@Spark}
2021-12-03 22:39:27,136 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@42b28ff1{/storage/json,null,AVAILABLE,@Spark}
2021-12-03 22:39:27,138 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@706fe5c6{/storage/rdd,null,AVAILABLE,@Spark}
2021-12-03 22:39:27,139 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@6b3f6585{/storage/rdd/json,null,AVAILABLE,@Spark}
2021-12-03 22:39:27,140 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@64469d8{/environment,null,AVAILABLE,@Spark}
2021-12-03 22:39:27,142 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@1cec219f{/environment/json,null,AVAILABLE,@Spark}
2021-12-03 22:39:27,143 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@3cb8c8ce{/executors,null,AVAILABLE,@Spark}
2021-12-03 22:39:27,144 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@260a3a5e{/executors/json,null,AVAILABLE,@Spark}
2021-12-03 22:39:27,145 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@2e51d054{/executors/threadDump,null,AVAILABLE,@Spark}
2021-12-03 22:39:27,146 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@608bc8f8{/executors/threadDump/json,null,AVAILABLE,@Spark}
2021-12-03 22:39:27,151 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@381d7219{/static,null,AVAILABLE,@Spark}
2021-12-03 22:39:27,152 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@5f117b3d{/,null,AVAILABLE,@Spark}
2021-12-03 22:39:27,154 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@11f406f8{/api,null,AVAILABLE,@Spark}
2021-12-03 22:39:27,155 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@fb713e7{/jobs/job/kill,null,AVAILABLE,@Spark}
2021-12-03 22:39:27,156 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@35f639fa{/stages/stage/kill,null,AVAILABLE,@Spark}
2021-12-03 22:39:27,158 [main] INFO [org.apache.spark.ui.SparkUI] - Bound SparkUI to 0.0.0.0, and started at http://qb:4040
2021-12-03 22:39:27,238 [main] INFO [org.apache.spark.executor.Executor] - Starting executor ID driver on host localhost
2021-12-03 22:39:27,274 [main] INFO [org.apache.spark.util.Utils] - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 54372.
2021-12-03 22:39:27,275 [main] INFO [org.apache.spark.network.netty.NettyBlockTransferService] - Server created on qb:54372
2021-12-03 22:39:27,276 [main] INFO [org.apache.spark.storage.BlockManager] - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2021-12-03 22:39:27,277 [main] INFO [org.apache.spark.storage.BlockManagerMaster] - Registering BlockManager BlockManagerId(driver, qb, 54372, None)
2021-12-03 22:39:27,280 [dispatcher-event-loop-10] INFO [org.apache.spark.storage.BlockManagerMasterEndpoint] - Registering block manager qb:54372 with 1990.8 MB RAM, BlockManagerId(driver, qb, 54372, None)
2021-12-03 22:39:27,281 [main] INFO [org.apache.spark.storage.BlockManagerMaster] - Registered BlockManager BlockManagerId(driver, qb, 54372, None)
2021-12-03 22:39:27,282 [main] INFO [org.apache.spark.storage.BlockManager] - Initialized BlockManager: BlockManagerId(driver, qb, 54372, None)
2021-12-03 22:39:27,407 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@30893e08{/metrics/json,null,AVAILABLE,@Spark}
2021-12-03 22:39:27,875 [main] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_0 stored as values in memory (estimated size 312.7 KB, free 1990.5 MB)
2021-12-03 22:39:28,076 [main] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_0_piece0 stored as bytes in memory (estimated size 27.3 KB, free 1990.5 MB)
2021-12-03 22:39:28,078 [dispatcher-event-loop-0] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_0_piece0 in memory on qb:54372 (size: 27.3 KB, free: 1990.8 MB)
2021-12-03 22:39:28,081 [main] INFO [org.apache.spark.SparkContext] - Created broadcast 0 from textFile at PaidPromotionAdjustParameter.scala:57
2021-12-03 22:39:28,408 [main] WARN [org.apache.hadoop.hdfs.shortcircuit.DomainSocketFactory] - The short-circuit local reads feature cannot be used because UNIX Domain sockets are not available on Windows.
2021-12-03 22:39:28,477 [main] INFO [org.apache.hadoop.mapred.FileInputFormat] - Total input paths to process : 1
2021-12-03 22:39:28,508 [main] INFO [org.apache.hadoop.net.NetworkTopology] - Adding a new node: /default-rack/192.168.1.34:50010
2021-12-03 22:39:28,509 [main] INFO [org.apache.hadoop.net.NetworkTopology] - Adding a new node: /default-rack/192.168.1.33:50010
2021-12-03 22:39:28,509 [main] INFO [org.apache.hadoop.net.NetworkTopology] - Adding a new node: /default-rack/172.16.1.220:50010
2021-12-03 22:39:28,515 [main] INFO [org.apache.spark.SparkContext] - Starting job: count at PaidPromotionAdjustParameter.scala:59
2021-12-03 22:39:28,525 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 0 (count at PaidPromotionAdjustParameter.scala:59) with 22 output partitions
2021-12-03 22:39:28,525 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 0 (count at PaidPromotionAdjustParameter.scala:59)
2021-12-03 22:39:28,525 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List()
2021-12-03 22:39:28,526 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2021-12-03 22:39:28,531 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 0 (/sk/chongqing/data/behavior_data.bcp MapPartitionsRDD[1] at textFile at PaidPromotionAdjustParameter.scala:57), which has no missing parents
2021-12-03 22:39:28,563 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_1 stored as values in memory (estimated size 3.1 KB, free 1990.5 MB)
2021-12-03 22:39:28,569 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_1_piece0 stored as bytes in memory (estimated size 1902.0 B, free 1990.5 MB)
2021-12-03 22:39:28,569 [dispatcher-event-loop-1] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_1_piece0 in memory on qb:54372 (size: 1902.0 B, free: 1990.8 MB)
2021-12-03 22:39:28,569 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 1 from broadcast at DAGScheduler.scala:1039
2021-12-03 22:39:28,580 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 22 missing tasks from ResultStage 0 (/sk/chongqing/data/behavior_data.bcp MapPartitionsRDD[1] at textFile at PaidPromotionAdjustParameter.scala:57) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14))
2021-12-03 22:39:28,580 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 0.0 with 22 tasks
2021-12-03 22:39:28,612 [dispatcher-event-loop-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 0.0 (TID 0, localhost, executor driver, partition 0, ANY, 7899 bytes)
2021-12-03 22:39:28,614 [dispatcher-event-loop-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 0.0 (TID 1, localhost, executor driver, partition 1, ANY, 7899 bytes)
2021-12-03 22:39:28,614 [dispatcher-event-loop-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 2.0 in stage 0.0 (TID 2, localhost, executor driver, partition 2, ANY, 7899 bytes)
2021-12-03 22:39:28,615 [dispatcher-event-loop-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 3.0 in stage 0.0 (TID 3, localhost, executor driver, partition 3, ANY, 7899 bytes)
2021-12-03 22:39:28,615 [dispatcher-event-loop-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 4.0 in stage 0.0 (TID 4, localhost, executor driver, partition 4, ANY, 7899 bytes)
2021-12-03 22:39:28,615 [dispatcher-event-loop-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 5.0 in stage 0.0 (TID 5, localhost, executor driver, partition 5, ANY, 7899 bytes)
2021-12-03 22:39:28,616 [dispatcher-event-loop-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 6.0 in stage 0.0 (TID 6, localhost, executor driver, partition 6, ANY, 7899 bytes)
2021-12-03 22:39:28,616 [dispatcher-event-loop-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 7.0 in stage 0.0 (TID 7, localhost, executor driver, partition 7, ANY, 7899 bytes)
2021-12-03 22:39:28,616 [dispatcher-event-loop-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 8.0 in stage 0.0 (TID 8, localhost, executor driver, partition 8, ANY, 7899 bytes)
2021-12-03 22:39:28,617 [dispatcher-event-loop-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 9.0 in stage 0.0 (TID 9, localhost, executor driver, partition 9, ANY, 7899 bytes)
2021-12-03 22:39:28,617 [dispatcher-event-loop-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 10.0 in stage 0.0 (TID 10, localhost, executor driver, partition 10, ANY, 7899 bytes)
2021-12-03 22:39:28,617 [dispatcher-event-loop-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 11.0 in stage 0.0 (TID 11, localhost, executor driver, partition 11, ANY, 7899 bytes)
2021-12-03 22:39:28,624 [Executor task launch worker for task 9] INFO [org.apache.spark.executor.Executor] - Running task 9.0 in stage 0.0 (TID 9)
2021-12-03 22:39:28,624 [Executor task launch worker for task 1] INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 0.0 (TID 1)
2021-12-03 22:39:28,624 [Executor task launch worker for task 6] INFO [org.apache.spark.executor.Executor] - Running task 6.0 in stage 0.0 (TID 6)
2021-12-03 22:39:28,624 [Executor task launch worker for task 8] INFO [org.apache.spark.executor.Executor] - Running task 8.0 in stage 0.0 (TID 8)
2021-12-03 22:39:28,624 [Executor task launch worker for task 2] INFO [org.apache.spark.executor.Executor] - Running task 2.0 in stage 0.0 (TID 2)
2021-12-03 22:39:28,624 [Executor task launch worker for task 4] INFO [org.apache.spark.executor.Executor] - Running task 4.0 in stage 0.0 (TID 4)
2021-12-03 22:39:28,624 [Executor task launch worker for task 0] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 0.0 (TID 0)
2021-12-03 22:39:28,624 [Executor task launch worker for task 7] INFO [org.apache.spark.executor.Executor] - Running task 7.0 in stage 0.0 (TID 7)
2021-12-03 22:39:28,624 [Executor task launch worker for task 11] INFO [org.apache.spark.executor.Executor] - Running task 11.0 in stage 0.0 (TID 11)
2021-12-03 22:39:28,624 [Executor task launch worker for task 10] INFO [org.apache.spark.executor.Executor] - Running task 10.0 in stage 0.0 (TID 10)
2021-12-03 22:39:28,624 [Executor task launch worker for task 3] INFO [org.apache.spark.executor.Executor] - Running task 3.0 in stage 0.0 (TID 3)
2021-12-03 22:39:28,624 [Executor task launch worker for task 5] INFO [org.apache.spark.executor.Executor] - Running task 5.0 in stage 0.0 (TID 5)
2021-12-03 22:39:28,676 [Executor task launch worker for task 8] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:1073741824+134217728
2021-12-03 22:39:28,676 [Executor task launch worker for task 2] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:268435456+134217728
2021-12-03 22:39:28,676 [Executor task launch worker for task 1] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:134217728+134217728
2021-12-03 22:39:28,676 [Executor task launch worker for task 11] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:1476395008+134217728
2021-12-03 22:39:28,676 [Executor task launch worker for task 3] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:402653184+134217728
2021-12-03 22:39:28,676 [Executor task launch worker for task 0] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:0+134217728
2021-12-03 22:39:28,676 [Executor task launch worker for task 9] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:1207959552+134217728
2021-12-03 22:39:28,676 [Executor task launch worker for task 10] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:1342177280+134217728
2021-12-03 22:39:28,676 [Executor task launch worker for task 4] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:536870912+134217728
2021-12-03 22:39:28,676 [Executor task launch worker for task 7] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:939524096+134217728
2021-12-03 22:39:28,676 [Executor task launch worker for task 5] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:671088640+134217728
2021-12-03 22:39:28,676 [Executor task launch worker for task 6] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:805306368+134217728
2021-12-03 22:41:17,575 [Executor task launch worker for task 6] INFO [org.apache.spark.executor.Executor] - Finished task 6.0 in stage 0.0 (TID 6). 798 bytes result sent to driver
2021-12-03 22:41:17,577 [dispatcher-event-loop-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 12.0 in stage 0.0 (TID 12, localhost, executor driver, partition 12, ANY, 7899 bytes)
2021-12-03 22:41:17,577 [Executor task launch worker for task 12] INFO [org.apache.spark.executor.Executor] - Running task 12.0 in stage 0.0 (TID 12)
2021-12-03 22:41:17,579 [Executor task launch worker for task 12] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:1610612736+134217728
2021-12-03 22:41:17,586 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 6.0 in stage 0.0 (TID 6) in 108970 ms on localhost (executor driver) (1/22)
2021-12-03 22:41:23,637 [Executor task launch worker for task 1] INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 0.0 (TID 1). 798 bytes result sent to driver
2021-12-03 22:41:23,638 [dispatcher-event-loop-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 13.0 in stage 0.0 (TID 13, localhost, executor driver, partition 13, ANY, 7899 bytes)
2021-12-03 22:41:23,638 [Executor task launch worker for task 13] INFO [org.apache.spark.executor.Executor] - Running task 13.0 in stage 0.0 (TID 13)
2021-12-03 22:41:23,640 [Executor task launch worker for task 13] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:1744830464+134217728
2021-12-03 22:41:23,642 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 0.0 (TID 1) in 115028 ms on localhost (executor driver) (2/22)
2021-12-03 22:41:29,317 [Executor task launch worker for task 11] INFO [org.apache.spark.executor.Executor] - Finished task 11.0 in stage 0.0 (TID 11). 798 bytes result sent to driver
2021-12-03 22:41:29,321 [dispatcher-event-loop-8] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 14.0 in stage 0.0 (TID 14, localhost, executor driver, partition 14, ANY, 7899 bytes)
2021-12-03 22:41:29,321 [Executor task launch worker for task 14] INFO [org.apache.spark.executor.Executor] - Running task 14.0 in stage 0.0 (TID 14)
2021-12-03 22:41:29,322 [Executor task launch worker for task 14] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:1879048192+134217728
2021-12-03 22:41:29,324 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 11.0 in stage 0.0 (TID 11) in 120707 ms on localhost (executor driver) (3/22)
2021-12-03 22:41:45,863 [Executor task launch worker for task 0] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 0.0 (TID 0). 798 bytes result sent to driver
2021-12-03 22:41:45,867 [dispatcher-event-loop-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 15.0 in stage 0.0 (TID 15, localhost, executor driver, partition 15, ANY, 7899 bytes)
2021-12-03 22:41:45,867 [Executor task launch worker for task 15] INFO [org.apache.spark.executor.Executor] - Running task 15.0 in stage 0.0 (TID 15)
2021-12-03 22:41:45,869 [Executor task launch worker for task 15] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:2013265920+134217728
2021-12-03 22:41:45,870 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 0.0 (TID 0) in 137267 ms on localhost (executor driver) (4/22)
2021-12-03 22:41:46,365 [Executor task launch worker for task 2] INFO [org.apache.spark.executor.Executor] - Finished task 2.0 in stage 0.0 (TID 2). 798 bytes result sent to driver
2021-12-03 22:41:46,366 [dispatcher-event-loop-5] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 16.0 in stage 0.0 (TID 16, localhost, executor driver, partition 16, ANY, 7899 bytes)
2021-12-03 22:41:46,366 [Executor task launch worker for task 16] INFO [org.apache.spark.executor.Executor] - Running task 16.0 in stage 0.0 (TID 16)
2021-12-03 22:41:46,366 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 2.0 in stage 0.0 (TID 2) in 137752 ms on localhost (executor driver) (5/22)
2021-12-03 22:41:46,371 [Executor task launch worker for task 16] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:2147483648+134217728
2021-12-03 22:41:48,705 [Executor task launch worker for task 10] INFO [org.apache.spark.executor.Executor] - Finished task 10.0 in stage 0.0 (TID 10). 798 bytes result sent to driver
2021-12-03 22:41:48,706 [dispatcher-event-loop-7] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 17.0 in stage 0.0 (TID 17, localhost, executor driver, partition 17, ANY, 7899 bytes)
2021-12-03 22:41:48,706 [Executor task launch worker for task 17] INFO [org.apache.spark.executor.Executor] - Running task 17.0 in stage 0.0 (TID 17)
2021-12-03 22:41:48,706 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 10.0 in stage 0.0 (TID 10) in 140089 ms on localhost (executor driver) (6/22)
2021-12-03 22:41:48,707 [Executor task launch worker for task 17] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:2281701376+134217728
2021-12-03 22:41:52,665 [Executor task launch worker for task 5] INFO [org.apache.spark.executor.Executor] - Finished task 5.0 in stage 0.0 (TID 5). 755 bytes result sent to driver
2021-12-03 22:41:52,666 [dispatcher-event-loop-8] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 18.0 in stage 0.0 (TID 18, localhost, executor driver, partition 18, ANY, 7899 bytes)
2021-12-03 22:41:52,666 [Executor task launch worker for task 18] INFO [org.apache.spark.executor.Executor] - Running task 18.0 in stage 0.0 (TID 18)
2021-12-03 22:41:52,666 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 5.0 in stage 0.0 (TID 5) in 144051 ms on localhost (executor driver) (7/22)
2021-12-03 22:41:52,670 [Executor task launch worker for task 18] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:2415919104+134217728
2021-12-03 22:42:03,627 [Executor task launch worker for task 3] INFO [org.apache.spark.executor.Executor] - Finished task 3.0 in stage 0.0 (TID 3). 798 bytes result sent to driver
2021-12-03 22:42:03,628 [dispatcher-event-loop-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 19.0 in stage 0.0 (TID 19, localhost, executor driver, partition 19, ANY, 7899 bytes)
2021-12-03 22:42:03,628 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 3.0 in stage 0.0 (TID 3) in 155014 ms on localhost (executor driver) (8/22)
2021-12-03 22:42:03,628 [Executor task launch worker for task 19] INFO [org.apache.spark.executor.Executor] - Running task 19.0 in stage 0.0 (TID 19)
2021-12-03 22:42:03,629 [Executor task launch worker for task 19] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:2550136832+134217728
2021-12-03 22:42:05,892 [Executor task launch worker for task 4] INFO [org.apache.spark.executor.Executor] - Finished task 4.0 in stage 0.0 (TID 4). 798 bytes result sent to driver
2021-12-03 22:42:05,893 [dispatcher-event-loop-5] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 20.0 in stage 0.0 (TID 20, localhost, executor driver, partition 20, ANY, 7899 bytes)
2021-12-03 22:42:05,893 [Executor task launch worker for task 20] INFO [org.apache.spark.executor.Executor] - Running task 20.0 in stage 0.0 (TID 20)
2021-12-03 22:42:05,893 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 4.0 in stage 0.0 (TID 4) in 157278 ms on localhost (executor driver) (9/22)
2021-12-03 22:42:05,894 [Executor task launch worker for task 20] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:2684354560+134217728
2021-12-03 22:42:08,374 [Executor task launch worker for task 8] INFO [org.apache.spark.executor.Executor] - Finished task 8.0 in stage 0.0 (TID 8). 841 bytes result sent to driver
2021-12-03 22:42:08,374 [dispatcher-event-loop-7] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 21.0 in stage 0.0 (TID 21, localhost, executor driver, partition 21, ANY, 7899 bytes)
2021-12-03 22:42:08,374 [Executor task launch worker for task 21] INFO [org.apache.spark.executor.Executor] - Running task 21.0 in stage 0.0 (TID 21)
2021-12-03 22:42:08,374 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 8.0 in stage 0.0 (TID 8) in 159758 ms on localhost (executor driver) (10/22)
2021-12-03 22:42:08,375 [Executor task launch worker for task 21] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:2818572288+147216171
2021-12-03 22:42:08,426 [Executor task launch worker for task 9] INFO [org.apache.spark.executor.Executor] - Finished task 9.0 in stage 0.0 (TID 9). 798 bytes result sent to driver
2021-12-03 22:42:08,428 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 9.0 in stage 0.0 (TID 9) in 159812 ms on localhost (executor driver) (11/22)
2021-12-03 22:42:17,499 [Executor task launch worker for task 7] INFO [org.apache.spark.executor.Executor] - Finished task 7.0 in stage 0.0 (TID 7). 755 bytes result sent to driver
2021-12-03 22:42:17,499 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 7.0 in stage 0.0 (TID 7) in 168883 ms on localhost (executor driver) (12/22)
2021-12-03 22:43:04,040 [Executor task launch worker for task 13] INFO [org.apache.spark.executor.Executor] - Finished task 13.0 in stage 0.0 (TID 13). 798 bytes result sent to driver
2021-12-03 22:43:04,040 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 13.0 in stage 0.0 (TID 13) in 100402 ms on localhost (executor driver) (13/22)
2021-12-03 22:43:19,098 [Executor task launch worker for task 12] INFO [org.apache.spark.executor.Executor] - Finished task 12.0 in stage 0.0 (TID 12). 755 bytes result sent to driver
2021-12-03 22:43:19,098 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 12.0 in stage 0.0 (TID 12) in 121521 ms on localhost (executor driver) (14/22)
2021-12-03 22:43:21,157 [Executor task launch worker for task 16] INFO [org.apache.spark.executor.Executor] - Finished task 16.0 in stage 0.0 (TID 16). 712 bytes result sent to driver
2021-12-03 22:43:21,157 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 16.0 in stage 0.0 (TID 16) in 94791 ms on localhost (executor driver) (15/22)
2021-12-03 22:43:28,636 [Executor task launch worker for task 18] INFO [org.apache.spark.executor.Executor] - Finished task 18.0 in stage 0.0 (TID 18). 798 bytes result sent to driver
2021-12-03 22:43:28,640 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 18.0 in stage 0.0 (TID 18) in 95974 ms on localhost (executor driver) (16/22)
2021-12-03 22:43:32,712 [Executor task launch worker for task 14] INFO [org.apache.spark.executor.Executor] - Finished task 14.0 in stage 0.0 (TID 14). 712 bytes result sent to driver
2021-12-03 22:43:32,712 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 14.0 in stage 0.0 (TID 14) in 123394 ms on localhost (executor driver) (17/22)
2021-12-03 22:43:41,448 [Executor task launch worker for task 19] INFO [org.apache.spark.executor.Executor] - Finished task 19.0 in stage 0.0 (TID 19). 712 bytes result sent to driver
2021-12-03 22:43:41,448 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 19.0 in stage 0.0 (TID 19) in 97820 ms on localhost (executor driver) (18/22)
2021-12-03 22:43:41,917 [Executor task launch worker for task 21] INFO [org.apache.spark.executor.Executor] - Finished task 21.0 in stage 0.0 (TID 21). 755 bytes result sent to driver
2021-12-03 22:43:41,918 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 21.0 in stage 0.0 (TID 21) in 93544 ms on localhost (executor driver) (19/22)
2021-12-03 22:43:42,601 [Executor task launch worker for task 17] INFO [org.apache.spark.executor.Executor] - Finished task 17.0 in stage 0.0 (TID 17). 712 bytes result sent to driver
2021-12-03 22:43:42,602 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 17.0 in stage 0.0 (TID 17) in 113896 ms on localhost (executor driver) (20/22)
2021-12-03 22:43:43,175 [Executor task launch worker for task 15] INFO [org.apache.spark.executor.Executor] - Finished task 15.0 in stage 0.0 (TID 15). 755 bytes result sent to driver
2021-12-03 22:43:43,176 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 15.0 in stage 0.0 (TID 15) in 117313 ms on localhost (executor driver) (21/22)
2021-12-03 22:43:44,719 [Executor task launch worker for task 20] INFO [org.apache.spark.executor.Executor] - Finished task 20.0 in stage 0.0 (TID 20). 755 bytes result sent to driver
2021-12-03 22:43:44,720 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 20.0 in stage 0.0 (TID 20) in 98828 ms on localhost (executor driver) (22/22)
2021-12-03 22:43:44,726 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 0.0, whose tasks have all completed, from pool 
2021-12-03 22:43:44,727 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 0 (count at PaidPromotionAdjustParameter.scala:59) finished in 256.174 s
2021-12-03 22:43:44,732 [main] INFO [org.apache.spark.scheduler.DAGScheduler] - Job 0 finished: count at PaidPromotionAdjustParameter.scala:59, took 256.216639 s
2021-12-03 22:43:44,733 [main] INFO [PaidPromotion$] - 收视总数68489201
2021-12-03 22:43:44,886 [main] INFO [org.apache.spark.SparkContext] - Starting job: count at PaidPromotionAdjustParameter.scala:68
2021-12-03 22:43:44,893 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 3 (map at PaidPromotionAdjustParameter.scala:67)
2021-12-03 22:43:44,894 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 1 (count at PaidPromotionAdjustParameter.scala:68) with 22 output partitions
2021-12-03 22:43:44,894 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 2 (count at PaidPromotionAdjustParameter.scala:68)
2021-12-03 22:43:44,894 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 1)
2021-12-03 22:43:44,895 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List(ShuffleMapStage 1)
2021-12-03 22:43:44,896 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ShuffleMapStage 1 (MapPartitionsRDD[3] at map at PaidPromotionAdjustParameter.scala:67), which has no missing parents
2021-12-03 22:43:44,908 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_2 stored as values in memory (estimated size 4.7 KB, free 1990.5 MB)
2021-12-03 22:43:44,911 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_2_piece0 stored as bytes in memory (estimated size 2.7 KB, free 1990.5 MB)
2021-12-03 22:43:44,911 [dispatcher-event-loop-7] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_2_piece0 in memory on qb:54372 (size: 2.7 KB, free: 1990.8 MB)
2021-12-03 22:43:44,912 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 2 from broadcast at DAGScheduler.scala:1039
2021-12-03 22:43:44,914 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 22 missing tasks from ShuffleMapStage 1 (MapPartitionsRDD[3] at map at PaidPromotionAdjustParameter.scala:67) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14))
2021-12-03 22:43:44,914 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 1.0 with 22 tasks
2021-12-03 22:43:44,915 [dispatcher-event-loop-4] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 1.0 (TID 22, localhost, executor driver, partition 0, ANY, 7888 bytes)
2021-12-03 22:43:44,915 [dispatcher-event-loop-4] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 1.0 (TID 23, localhost, executor driver, partition 1, ANY, 7888 bytes)
2021-12-03 22:43:44,916 [dispatcher-event-loop-4] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 2.0 in stage 1.0 (TID 24, localhost, executor driver, partition 2, ANY, 7888 bytes)
2021-12-03 22:43:44,916 [dispatcher-event-loop-4] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 3.0 in stage 1.0 (TID 25, localhost, executor driver, partition 3, ANY, 7888 bytes)
2021-12-03 22:43:44,916 [dispatcher-event-loop-4] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 4.0 in stage 1.0 (TID 26, localhost, executor driver, partition 4, ANY, 7888 bytes)
2021-12-03 22:43:44,916 [dispatcher-event-loop-4] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 5.0 in stage 1.0 (TID 27, localhost, executor driver, partition 5, ANY, 7888 bytes)
2021-12-03 22:43:44,916 [dispatcher-event-loop-4] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 6.0 in stage 1.0 (TID 28, localhost, executor driver, partition 6, ANY, 7888 bytes)
2021-12-03 22:43:44,916 [dispatcher-event-loop-4] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 7.0 in stage 1.0 (TID 29, localhost, executor driver, partition 7, ANY, 7888 bytes)
2021-12-03 22:43:44,917 [dispatcher-event-loop-4] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 8.0 in stage 1.0 (TID 30, localhost, executor driver, partition 8, ANY, 7888 bytes)
2021-12-03 22:43:44,917 [dispatcher-event-loop-4] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 9.0 in stage 1.0 (TID 31, localhost, executor driver, partition 9, ANY, 7888 bytes)
2021-12-03 22:43:44,917 [dispatcher-event-loop-4] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 10.0 in stage 1.0 (TID 32, localhost, executor driver, partition 10, ANY, 7888 bytes)
2021-12-03 22:43:44,917 [dispatcher-event-loop-4] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 11.0 in stage 1.0 (TID 33, localhost, executor driver, partition 11, ANY, 7888 bytes)
2021-12-03 22:43:44,918 [Executor task launch worker for task 22] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 1.0 (TID 22)
2021-12-03 22:43:44,918 [Executor task launch worker for task 24] INFO [org.apache.spark.executor.Executor] - Running task 2.0 in stage 1.0 (TID 24)
2021-12-03 22:43:44,918 [Executor task launch worker for task 31] INFO [org.apache.spark.executor.Executor] - Running task 9.0 in stage 1.0 (TID 31)
2021-12-03 22:43:44,918 [Executor task launch worker for task 30] INFO [org.apache.spark.executor.Executor] - Running task 8.0 in stage 1.0 (TID 30)
2021-12-03 22:43:44,918 [Executor task launch worker for task 27] INFO [org.apache.spark.executor.Executor] - Running task 5.0 in stage 1.0 (TID 27)
2021-12-03 22:43:44,918 [Executor task launch worker for task 25] INFO [org.apache.spark.executor.Executor] - Running task 3.0 in stage 1.0 (TID 25)
2021-12-03 22:43:44,918 [Executor task launch worker for task 23] INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 1.0 (TID 23)
2021-12-03 22:43:44,918 [Executor task launch worker for task 26] INFO [org.apache.spark.executor.Executor] - Running task 4.0 in stage 1.0 (TID 26)
2021-12-03 22:43:44,918 [Executor task launch worker for task 28] INFO [org.apache.spark.executor.Executor] - Running task 6.0 in stage 1.0 (TID 28)
2021-12-03 22:43:44,918 [Executor task launch worker for task 29] INFO [org.apache.spark.executor.Executor] - Running task 7.0 in stage 1.0 (TID 29)
2021-12-03 22:43:44,919 [Executor task launch worker for task 33] INFO [org.apache.spark.executor.Executor] - Running task 11.0 in stage 1.0 (TID 33)
2021-12-03 22:43:44,919 [Executor task launch worker for task 32] INFO [org.apache.spark.executor.Executor] - Running task 10.0 in stage 1.0 (TID 32)
2021-12-03 22:43:44,922 [Executor task launch worker for task 28] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:805306368+134217728
2021-12-03 22:43:44,922 [Executor task launch worker for task 22] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:0+134217728
2021-12-03 22:43:44,922 [Executor task launch worker for task 32] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:1342177280+134217728
2021-12-03 22:43:44,922 [Executor task launch worker for task 30] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:1073741824+134217728
2021-12-03 22:43:44,922 [Executor task launch worker for task 26] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:536870912+134217728
2021-12-03 22:43:44,922 [Executor task launch worker for task 33] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:1476395008+134217728
2021-12-03 22:43:44,922 [Executor task launch worker for task 27] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:671088640+134217728
2021-12-03 22:43:44,922 [Executor task launch worker for task 25] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:402653184+134217728
2021-12-03 22:43:44,922 [Executor task launch worker for task 23] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:134217728+134217728
2021-12-03 22:43:44,922 [Executor task launch worker for task 29] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:939524096+134217728
2021-12-03 22:43:44,922 [Executor task launch worker for task 24] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:268435456+134217728
2021-12-03 22:43:44,922 [Executor task launch worker for task 31] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:1207959552+134217728
2021-12-03 22:45:46,544 [Executor task launch worker for task 29] INFO [org.apache.spark.executor.Executor] - Finished task 7.0 in stage 1.0 (TID 29). 1095 bytes result sent to driver
2021-12-03 22:45:46,545 [dispatcher-event-loop-11] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 12.0 in stage 1.0 (TID 34, localhost, executor driver, partition 12, ANY, 7888 bytes)
2021-12-03 22:45:46,545 [Executor task launch worker for task 34] INFO [org.apache.spark.executor.Executor] - Running task 12.0 in stage 1.0 (TID 34)
2021-12-03 22:45:46,546 [Executor task launch worker for task 34] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:1610612736+134217728
2021-12-03 22:45:46,559 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 7.0 in stage 1.0 (TID 29) in 121643 ms on localhost (executor driver) (1/22)
2021-12-03 22:45:47,797 [Executor task launch worker for task 33] INFO [org.apache.spark.executor.Executor] - Finished task 11.0 in stage 1.0 (TID 33). 1095 bytes result sent to driver
2021-12-03 22:45:47,798 [dispatcher-event-loop-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 13.0 in stage 1.0 (TID 35, localhost, executor driver, partition 13, ANY, 7888 bytes)
2021-12-03 22:45:47,798 [Executor task launch worker for task 35] INFO [org.apache.spark.executor.Executor] - Running task 13.0 in stage 1.0 (TID 35)
2021-12-03 22:45:47,798 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 11.0 in stage 1.0 (TID 33) in 122881 ms on localhost (executor driver) (2/22)
2021-12-03 22:45:47,799 [Executor task launch worker for task 35] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:1744830464+134217728
2021-12-03 22:45:48,314 [Executor task launch worker for task 26] INFO [org.apache.spark.executor.Executor] - Finished task 4.0 in stage 1.0 (TID 26). 1138 bytes result sent to driver
2021-12-03 22:45:48,314 [dispatcher-event-loop-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 14.0 in stage 1.0 (TID 36, localhost, executor driver, partition 14, ANY, 7888 bytes)
2021-12-03 22:45:48,314 [Executor task launch worker for task 36] INFO [org.apache.spark.executor.Executor] - Running task 14.0 in stage 1.0 (TID 36)
2021-12-03 22:45:48,315 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 4.0 in stage 1.0 (TID 26) in 123399 ms on localhost (executor driver) (3/22)
2021-12-03 22:45:48,315 [Executor task launch worker for task 36] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:1879048192+134217728
2021-12-03 22:45:54,314 [Executor task launch worker for task 30] INFO [org.apache.spark.executor.Executor] - Finished task 8.0 in stage 1.0 (TID 30). 1052 bytes result sent to driver
2021-12-03 22:45:54,314 [dispatcher-event-loop-7] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 15.0 in stage 1.0 (TID 37, localhost, executor driver, partition 15, ANY, 7888 bytes)
2021-12-03 22:45:54,314 [Executor task launch worker for task 37] INFO [org.apache.spark.executor.Executor] - Running task 15.0 in stage 1.0 (TID 37)
2021-12-03 22:45:54,314 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 8.0 in stage 1.0 (TID 30) in 129397 ms on localhost (executor driver) (4/22)
2021-12-03 22:45:54,319 [Executor task launch worker for task 37] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:2013265920+134217728
2021-12-03 22:45:55,509 [Executor task launch worker for task 27] INFO [org.apache.spark.executor.Executor] - Finished task 5.0 in stage 1.0 (TID 27). 1052 bytes result sent to driver
2021-12-03 22:45:55,509 [dispatcher-event-loop-9] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 16.0 in stage 1.0 (TID 38, localhost, executor driver, partition 16, ANY, 7888 bytes)
2021-12-03 22:45:55,509 [Executor task launch worker for task 38] INFO [org.apache.spark.executor.Executor] - Running task 16.0 in stage 1.0 (TID 38)
2021-12-03 22:45:55,509 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 5.0 in stage 1.0 (TID 27) in 130593 ms on localhost (executor driver) (5/22)
2021-12-03 22:45:55,510 [Executor task launch worker for task 38] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:2147483648+134217728
2021-12-03 22:45:57,533 [Executor task launch worker for task 25] INFO [org.apache.spark.executor.Executor] - Finished task 3.0 in stage 1.0 (TID 25). 1052 bytes result sent to driver
2021-12-03 22:45:57,533 [dispatcher-event-loop-11] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 17.0 in stage 1.0 (TID 39, localhost, executor driver, partition 17, ANY, 7888 bytes)
2021-12-03 22:45:57,533 [Executor task launch worker for task 39] INFO [org.apache.spark.executor.Executor] - Running task 17.0 in stage 1.0 (TID 39)
2021-12-03 22:45:57,533 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 3.0 in stage 1.0 (TID 25) in 132617 ms on localhost (executor driver) (6/22)
2021-12-03 22:45:57,534 [Executor task launch worker for task 39] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:2281701376+134217728
2021-12-03 22:46:07,677 [Executor task launch worker for task 24] INFO [org.apache.spark.executor.Executor] - Finished task 2.0 in stage 1.0 (TID 24). 1052 bytes result sent to driver
2021-12-03 22:46:07,678 [dispatcher-event-loop-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 18.0 in stage 1.0 (TID 40, localhost, executor driver, partition 18, ANY, 7888 bytes)
2021-12-03 22:46:07,678 [Executor task launch worker for task 40] INFO [org.apache.spark.executor.Executor] - Running task 18.0 in stage 1.0 (TID 40)
2021-12-03 22:46:07,678 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 2.0 in stage 1.0 (TID 24) in 142763 ms on localhost (executor driver) (7/22)
2021-12-03 22:46:07,679 [Executor task launch worker for task 40] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:2415919104+134217728
2021-12-03 22:46:09,531 [Executor task launch worker for task 31] INFO [org.apache.spark.executor.Executor] - Finished task 9.0 in stage 1.0 (TID 31). 1095 bytes result sent to driver
2021-12-03 22:46:09,531 [dispatcher-event-loop-5] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 19.0 in stage 1.0 (TID 41, localhost, executor driver, partition 19, ANY, 7888 bytes)
2021-12-03 22:46:09,531 [Executor task launch worker for task 41] INFO [org.apache.spark.executor.Executor] - Running task 19.0 in stage 1.0 (TID 41)
2021-12-03 22:46:09,532 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 9.0 in stage 1.0 (TID 31) in 144615 ms on localhost (executor driver) (8/22)
2021-12-03 22:46:09,532 [Executor task launch worker for task 41] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:2550136832+134217728
2021-12-03 22:46:11,926 [Executor task launch worker for task 32] INFO [org.apache.spark.executor.Executor] - Finished task 10.0 in stage 1.0 (TID 32). 1138 bytes result sent to driver
2021-12-03 22:46:11,926 [dispatcher-event-loop-7] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 20.0 in stage 1.0 (TID 42, localhost, executor driver, partition 20, ANY, 7888 bytes)
2021-12-03 22:46:11,926 [Executor task launch worker for task 42] INFO [org.apache.spark.executor.Executor] - Running task 20.0 in stage 1.0 (TID 42)
2021-12-03 22:46:11,926 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 10.0 in stage 1.0 (TID 32) in 147009 ms on localhost (executor driver) (9/22)
2021-12-03 22:46:11,927 [Executor task launch worker for task 42] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:2684354560+134217728
2021-12-03 22:46:22,269 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 13
2021-12-03 22:46:22,270 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 16
2021-12-03 22:46:22,270 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 3
2021-12-03 22:46:22,281 [dispatcher-event-loop-0] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_1_piece0 on qb:54372 in memory (size: 1902.0 B, free: 1990.8 MB)
2021-12-03 22:46:22,283 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 10
2021-12-03 22:46:22,283 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 15
2021-12-03 22:46:22,283 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 9
2021-12-03 22:46:22,283 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 17
2021-12-03 22:46:22,283 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 6
2021-12-03 22:46:22,283 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 11
2021-12-03 22:46:22,283 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 21
2021-12-03 22:46:22,283 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 22
2021-12-03 22:46:22,283 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 20
2021-12-03 22:46:22,283 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 5
2021-12-03 22:46:22,283 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 12
2021-12-03 22:46:22,283 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1
2021-12-03 22:46:22,283 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 18
2021-12-03 22:46:22,283 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 14
2021-12-03 22:46:22,283 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 19
2021-12-03 22:46:22,283 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 0
2021-12-03 22:46:22,283 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 7
2021-12-03 22:46:22,283 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 2
2021-12-03 22:46:22,283 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 8
2021-12-03 22:46:22,283 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 24
2021-12-03 22:46:22,283 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 23
2021-12-03 22:46:22,284 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 4
2021-12-03 22:46:31,595 [Executor task launch worker for task 22] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 1.0 (TID 22). 1095 bytes result sent to driver
2021-12-03 22:46:31,595 [dispatcher-event-loop-5] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 21.0 in stage 1.0 (TID 43, localhost, executor driver, partition 21, ANY, 7888 bytes)
2021-12-03 22:46:31,595 [Executor task launch worker for task 43] INFO [org.apache.spark.executor.Executor] - Running task 21.0 in stage 1.0 (TID 43)
2021-12-03 22:46:31,596 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 1.0 (TID 22) in 166682 ms on localhost (executor driver) (10/22)
2021-12-03 22:46:31,596 [Executor task launch worker for task 43] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:2818572288+147216171
2021-12-03 22:46:32,677 [Executor task launch worker for task 23] INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 1.0 (TID 23). 1095 bytes result sent to driver
2021-12-03 22:46:32,677 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 1.0 (TID 23) in 167762 ms on localhost (executor driver) (11/22)
2021-12-03 22:46:35,483 [Executor task launch worker for task 28] INFO [org.apache.spark.executor.Executor] - Finished task 6.0 in stage 1.0 (TID 28). 1095 bytes result sent to driver
2021-12-03 22:46:35,484 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 6.0 in stage 1.0 (TID 28) in 170568 ms on localhost (executor driver) (12/22)
2021-12-03 22:47:35,339 [Executor task launch worker for task 34] INFO [org.apache.spark.executor.Executor] - Finished task 12.0 in stage 1.0 (TID 34). 1052 bytes result sent to driver
2021-12-03 22:47:35,340 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 12.0 in stage 1.0 (TID 34) in 108795 ms on localhost (executor driver) (13/22)
2021-12-03 22:47:38,913 [Executor task launch worker for task 39] INFO [org.apache.spark.executor.Executor] - Finished task 17.0 in stage 1.0 (TID 39). 1052 bytes result sent to driver
2021-12-03 22:47:38,914 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 17.0 in stage 1.0 (TID 39) in 101381 ms on localhost (executor driver) (14/22)
2021-12-03 22:47:46,087 [Executor task launch worker for task 37] INFO [org.apache.spark.executor.Executor] - Finished task 15.0 in stage 1.0 (TID 37). 1052 bytes result sent to driver
2021-12-03 22:47:46,088 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 15.0 in stage 1.0 (TID 37) in 111774 ms on localhost (executor driver) (15/22)
2021-12-03 22:47:47,210 [Executor task launch worker for task 35] INFO [org.apache.spark.executor.Executor] - Finished task 13.0 in stage 1.0 (TID 35). 1009 bytes result sent to driver
2021-12-03 22:47:47,211 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 13.0 in stage 1.0 (TID 35) in 119413 ms on localhost (executor driver) (16/22)
2021-12-03 22:47:50,385 [Executor task launch worker for task 40] INFO [org.apache.spark.executor.Executor] - Finished task 18.0 in stage 1.0 (TID 40). 1052 bytes result sent to driver
2021-12-03 22:47:50,385 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 18.0 in stage 1.0 (TID 40) in 102708 ms on localhost (executor driver) (17/22)
2021-12-03 22:47:52,050 [Executor task launch worker for task 42] INFO [org.apache.spark.executor.Executor] - Finished task 20.0 in stage 1.0 (TID 42). 1052 bytes result sent to driver
2021-12-03 22:47:52,051 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 20.0 in stage 1.0 (TID 42) in 100125 ms on localhost (executor driver) (18/22)
2021-12-03 22:47:57,177 [Executor task launch worker for task 36] INFO [org.apache.spark.executor.Executor] - Finished task 14.0 in stage 1.0 (TID 36). 1052 bytes result sent to driver
2021-12-03 22:47:57,177 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 14.0 in stage 1.0 (TID 36) in 128863 ms on localhost (executor driver) (19/22)
2021-12-03 22:47:59,150 [Executor task launch worker for task 41] INFO [org.apache.spark.executor.Executor] - Finished task 19.0 in stage 1.0 (TID 41). 1052 bytes result sent to driver
2021-12-03 22:47:59,151 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 19.0 in stage 1.0 (TID 41) in 109620 ms on localhost (executor driver) (20/22)
2021-12-03 22:47:59,741 [Executor task launch worker for task 38] INFO [org.apache.spark.executor.Executor] - Finished task 16.0 in stage 1.0 (TID 38). 1009 bytes result sent to driver
2021-12-03 22:47:59,741 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 16.0 in stage 1.0 (TID 38) in 124232 ms on localhost (executor driver) (21/22)
2021-12-03 22:48:01,408 [Executor task launch worker for task 43] INFO [org.apache.spark.executor.Executor] - Finished task 21.0 in stage 1.0 (TID 43). 1052 bytes result sent to driver
2021-12-03 22:48:01,408 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 21.0 in stage 1.0 (TID 43) in 89813 ms on localhost (executor driver) (22/22)
2021-12-03 22:48:01,408 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 1.0, whose tasks have all completed, from pool 
2021-12-03 22:48:01,408 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ShuffleMapStage 1 (map at PaidPromotionAdjustParameter.scala:67) finished in 256.507 s
2021-12-03 22:48:01,412 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - looking for newly runnable stages
2021-12-03 22:48:01,412 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - running: Set()
2021-12-03 22:48:01,413 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - waiting: Set(ResultStage 2)
2021-12-03 22:48:01,413 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - failed: Set()
2021-12-03 22:48:01,416 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 2 (ShuffledRDD[4] at reduceByKey at PaidPromotionAdjustParameter.scala:67), which has no missing parents
2021-12-03 22:48:01,421 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_3 stored as values in memory (estimated size 3.0 KB, free 1990.5 MB)
2021-12-03 22:48:01,425 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_3_piece0 stored as bytes in memory (estimated size 1906.0 B, free 1990.5 MB)
2021-12-03 22:48:01,425 [dispatcher-event-loop-1] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_3_piece0 in memory on qb:54372 (size: 1906.0 B, free: 1990.8 MB)
2021-12-03 22:48:01,425 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 3 from broadcast at DAGScheduler.scala:1039
2021-12-03 22:48:01,426 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 22 missing tasks from ResultStage 2 (ShuffledRDD[4] at reduceByKey at PaidPromotionAdjustParameter.scala:67) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14))
2021-12-03 22:48:01,426 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 2.0 with 22 tasks
2021-12-03 22:48:01,427 [dispatcher-event-loop-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 2.0 (TID 44, localhost, executor driver, partition 0, ANY, 7649 bytes)
2021-12-03 22:48:01,428 [dispatcher-event-loop-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 2.0 (TID 45, localhost, executor driver, partition 1, ANY, 7649 bytes)
2021-12-03 22:48:01,428 [dispatcher-event-loop-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 2.0 in stage 2.0 (TID 46, localhost, executor driver, partition 2, ANY, 7649 bytes)
2021-12-03 22:48:01,428 [dispatcher-event-loop-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 3.0 in stage 2.0 (TID 47, localhost, executor driver, partition 3, ANY, 7649 bytes)
2021-12-03 22:48:01,428 [dispatcher-event-loop-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 4.0 in stage 2.0 (TID 48, localhost, executor driver, partition 4, ANY, 7649 bytes)
2021-12-03 22:48:01,428 [dispatcher-event-loop-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 5.0 in stage 2.0 (TID 49, localhost, executor driver, partition 5, ANY, 7649 bytes)
2021-12-03 22:48:01,428 [dispatcher-event-loop-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 6.0 in stage 2.0 (TID 50, localhost, executor driver, partition 6, ANY, 7649 bytes)
2021-12-03 22:48:01,428 [dispatcher-event-loop-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 7.0 in stage 2.0 (TID 51, localhost, executor driver, partition 7, ANY, 7649 bytes)
2021-12-03 22:48:01,429 [dispatcher-event-loop-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 8.0 in stage 2.0 (TID 52, localhost, executor driver, partition 8, ANY, 7649 bytes)
2021-12-03 22:48:01,429 [dispatcher-event-loop-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 9.0 in stage 2.0 (TID 53, localhost, executor driver, partition 9, ANY, 7649 bytes)
2021-12-03 22:48:01,429 [dispatcher-event-loop-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 10.0 in stage 2.0 (TID 54, localhost, executor driver, partition 10, ANY, 7649 bytes)
2021-12-03 22:48:01,429 [dispatcher-event-loop-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 11.0 in stage 2.0 (TID 55, localhost, executor driver, partition 11, ANY, 7649 bytes)
2021-12-03 22:48:01,429 [Executor task launch worker for task 45] INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 2.0 (TID 45)
2021-12-03 22:48:01,429 [Executor task launch worker for task 52] INFO [org.apache.spark.executor.Executor] - Running task 8.0 in stage 2.0 (TID 52)
2021-12-03 22:48:01,429 [Executor task launch worker for task 53] INFO [org.apache.spark.executor.Executor] - Running task 9.0 in stage 2.0 (TID 53)
2021-12-03 22:48:01,429 [Executor task launch worker for task 46] INFO [org.apache.spark.executor.Executor] - Running task 2.0 in stage 2.0 (TID 46)
2021-12-03 22:48:01,429 [Executor task launch worker for task 51] INFO [org.apache.spark.executor.Executor] - Running task 7.0 in stage 2.0 (TID 51)
2021-12-03 22:48:01,429 [Executor task launch worker for task 50] INFO [org.apache.spark.executor.Executor] - Running task 6.0 in stage 2.0 (TID 50)
2021-12-03 22:48:01,429 [Executor task launch worker for task 48] INFO [org.apache.spark.executor.Executor] - Running task 4.0 in stage 2.0 (TID 48)
2021-12-03 22:48:01,429 [Executor task launch worker for task 44] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 2.0 (TID 44)
2021-12-03 22:48:01,429 [Executor task launch worker for task 49] INFO [org.apache.spark.executor.Executor] - Running task 5.0 in stage 2.0 (TID 49)
2021-12-03 22:48:01,429 [Executor task launch worker for task 47] INFO [org.apache.spark.executor.Executor] - Running task 3.0 in stage 2.0 (TID 47)
2021-12-03 22:48:01,430 [Executor task launch worker for task 55] INFO [org.apache.spark.executor.Executor] - Running task 11.0 in stage 2.0 (TID 55)
2021-12-03 22:48:01,430 [Executor task launch worker for task 54] INFO [org.apache.spark.executor.Executor] - Running task 10.0 in stage 2.0 (TID 54)
2021-12-03 22:48:01,444 [Executor task launch worker for task 50] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 22:48:01,444 [Executor task launch worker for task 54] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 22:48:01,445 [Executor task launch worker for task 55] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 22:48:01,445 [Executor task launch worker for task 49] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 22:48:01,444 [Executor task launch worker for task 48] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 22:48:01,444 [Executor task launch worker for task 51] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 22:48:01,444 [Executor task launch worker for task 45] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 22:48:01,444 [Executor task launch worker for task 53] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 22:48:01,444 [Executor task launch worker for task 44] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 22:48:01,444 [Executor task launch worker for task 46] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 22:48:01,444 [Executor task launch worker for task 47] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 22:48:01,444 [Executor task launch worker for task 52] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 22:48:01,446 [Executor task launch worker for task 48] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 6 ms
2021-12-03 22:48:01,447 [Executor task launch worker for task 50] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 7 ms
2021-12-03 22:48:01,446 [Executor task launch worker for task 51] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 6 ms
2021-12-03 22:48:01,446 [Executor task launch worker for task 47] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 6 ms
2021-12-03 22:48:01,446 [Executor task launch worker for task 53] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 6 ms
2021-12-03 22:48:01,446 [Executor task launch worker for task 52] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 6 ms
2021-12-03 22:48:01,446 [Executor task launch worker for task 46] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 6 ms
2021-12-03 22:48:01,446 [Executor task launch worker for task 54] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 6 ms
2021-12-03 22:48:01,446 [Executor task launch worker for task 55] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 6 ms
2021-12-03 22:48:01,446 [Executor task launch worker for task 49] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 6 ms
2021-12-03 22:48:01,446 [Executor task launch worker for task 45] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 6 ms
2021-12-03 22:48:01,446 [Executor task launch worker for task 44] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 6 ms
2021-12-03 22:48:01,820 [Executor task launch worker for task 47] INFO [org.apache.spark.executor.Executor] - Finished task 3.0 in stage 2.0 (TID 47). 1055 bytes result sent to driver
2021-12-03 22:48:01,823 [Executor task launch worker for task 54] INFO [org.apache.spark.executor.Executor] - Finished task 10.0 in stage 2.0 (TID 54). 1055 bytes result sent to driver
2021-12-03 22:48:01,823 [Executor task launch worker for task 45] INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 2.0 (TID 45). 1055 bytes result sent to driver
2021-12-03 22:48:01,823 [Executor task launch worker for task 49] INFO [org.apache.spark.executor.Executor] - Finished task 5.0 in stage 2.0 (TID 49). 1055 bytes result sent to driver
2021-12-03 22:48:01,824 [dispatcher-event-loop-6] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 12.0 in stage 2.0 (TID 56, localhost, executor driver, partition 12, ANY, 7649 bytes)
2021-12-03 22:48:01,824 [dispatcher-event-loop-6] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 13.0 in stage 2.0 (TID 57, localhost, executor driver, partition 13, ANY, 7649 bytes)
2021-12-03 22:48:01,825 [dispatcher-event-loop-6] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 14.0 in stage 2.0 (TID 58, localhost, executor driver, partition 14, ANY, 7649 bytes)
2021-12-03 22:48:01,825 [Executor task launch worker for task 46] INFO [org.apache.spark.executor.Executor] - Finished task 2.0 in stage 2.0 (TID 46). 1055 bytes result sent to driver
2021-12-03 22:48:01,825 [Executor task launch worker for task 58] INFO [org.apache.spark.executor.Executor] - Running task 14.0 in stage 2.0 (TID 58)
2021-12-03 22:48:01,825 [dispatcher-event-loop-6] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 15.0 in stage 2.0 (TID 59, localhost, executor driver, partition 15, ANY, 7649 bytes)
2021-12-03 22:48:01,825 [Executor task launch worker for task 56] INFO [org.apache.spark.executor.Executor] - Running task 12.0 in stage 2.0 (TID 56)
2021-12-03 22:48:01,826 [Executor task launch worker for task 58] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 22:48:01,826 [Executor task launch worker for task 58] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 22:48:01,826 [Executor task launch worker for task 52] INFO [org.apache.spark.executor.Executor] - Finished task 8.0 in stage 2.0 (TID 52). 1055 bytes result sent to driver
2021-12-03 22:48:01,826 [dispatcher-event-loop-6] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 16.0 in stage 2.0 (TID 60, localhost, executor driver, partition 16, ANY, 7649 bytes)
2021-12-03 22:48:01,827 [dispatcher-event-loop-6] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 17.0 in stage 2.0 (TID 61, localhost, executor driver, partition 17, ANY, 7649 bytes)
2021-12-03 22:48:01,827 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 3.0 in stage 2.0 (TID 47) in 399 ms on localhost (executor driver) (1/22)
2021-12-03 22:48:01,827 [Executor task launch worker for task 56] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 22:48:01,827 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 2.0 in stage 2.0 (TID 46) in 399 ms on localhost (executor driver) (2/22)
2021-12-03 22:48:01,827 [Executor task launch worker for task 56] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 22:48:01,827 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 8.0 in stage 2.0 (TID 52) in 399 ms on localhost (executor driver) (3/22)
2021-12-03 22:48:01,827 [Executor task launch worker for task 60] INFO [org.apache.spark.executor.Executor] - Running task 16.0 in stage 2.0 (TID 60)
2021-12-03 22:48:01,828 [Executor task launch worker for task 59] INFO [org.apache.spark.executor.Executor] - Running task 15.0 in stage 2.0 (TID 59)
2021-12-03 22:48:01,828 [Executor task launch worker for task 60] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 22:48:01,828 [Executor task launch worker for task 60] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 22:48:01,828 [Executor task launch worker for task 59] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 22:48:01,828 [Executor task launch worker for task 61] INFO [org.apache.spark.executor.Executor] - Running task 17.0 in stage 2.0 (TID 61)
2021-12-03 22:48:01,828 [Executor task launch worker for task 59] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 22:48:01,829 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 5.0 in stage 2.0 (TID 49) in 401 ms on localhost (executor driver) (4/22)
2021-12-03 22:48:01,829 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 2.0 (TID 45) in 402 ms on localhost (executor driver) (5/22)
2021-12-03 22:48:01,829 [Executor task launch worker for task 57] INFO [org.apache.spark.executor.Executor] - Running task 13.0 in stage 2.0 (TID 57)
2021-12-03 22:48:01,829 [Executor task launch worker for task 61] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 22:48:01,829 [Executor task launch worker for task 61] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 22:48:01,830 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 10.0 in stage 2.0 (TID 54) in 401 ms on localhost (executor driver) (6/22)
2021-12-03 22:48:01,830 [Executor task launch worker for task 57] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 22:48:01,830 [Executor task launch worker for task 57] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 22:48:01,835 [Executor task launch worker for task 51] INFO [org.apache.spark.executor.Executor] - Finished task 7.0 in stage 2.0 (TID 51). 1055 bytes result sent to driver
2021-12-03 22:48:01,836 [Executor task launch worker for task 48] INFO [org.apache.spark.executor.Executor] - Finished task 4.0 in stage 2.0 (TID 48). 1055 bytes result sent to driver
2021-12-03 22:48:01,836 [dispatcher-event-loop-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 18.0 in stage 2.0 (TID 62, localhost, executor driver, partition 18, ANY, 7649 bytes)
2021-12-03 22:48:01,836 [Executor task launch worker for task 62] INFO [org.apache.spark.executor.Executor] - Running task 18.0 in stage 2.0 (TID 62)
2021-12-03 22:48:01,836 [dispatcher-event-loop-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 19.0 in stage 2.0 (TID 63, localhost, executor driver, partition 19, ANY, 7649 bytes)
2021-12-03 22:48:01,836 [Executor task launch worker for task 63] INFO [org.apache.spark.executor.Executor] - Running task 19.0 in stage 2.0 (TID 63)
2021-12-03 22:48:01,836 [Executor task launch worker for task 44] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 2.0 (TID 44). 1055 bytes result sent to driver
2021-12-03 22:48:01,837 [Executor task launch worker for task 50] INFO [org.apache.spark.executor.Executor] - Finished task 6.0 in stage 2.0 (TID 50). 1055 bytes result sent to driver
2021-12-03 22:48:01,837 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 4.0 in stage 2.0 (TID 48) in 409 ms on localhost (executor driver) (7/22)
2021-12-03 22:48:01,837 [dispatcher-event-loop-6] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 20.0 in stage 2.0 (TID 64, localhost, executor driver, partition 20, ANY, 7649 bytes)
2021-12-03 22:48:01,837 [Executor task launch worker for task 55] INFO [org.apache.spark.executor.Executor] - Finished task 11.0 in stage 2.0 (TID 55). 1055 bytes result sent to driver
2021-12-03 22:48:01,837 [Executor task launch worker for task 63] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 22:48:01,837 [Executor task launch worker for task 63] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 22:48:01,837 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 7.0 in stage 2.0 (TID 51) in 409 ms on localhost (executor driver) (8/22)
2021-12-03 22:48:01,837 [Executor task launch worker for task 53] INFO [org.apache.spark.executor.Executor] - Finished task 9.0 in stage 2.0 (TID 53). 1055 bytes result sent to driver
2021-12-03 22:48:01,837 [Executor task launch worker for task 64] INFO [org.apache.spark.executor.Executor] - Running task 20.0 in stage 2.0 (TID 64)
2021-12-03 22:48:01,837 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 2.0 (TID 44) in 411 ms on localhost (executor driver) (9/22)
2021-12-03 22:48:01,837 [Executor task launch worker for task 62] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 22:48:01,838 [Executor task launch worker for task 62] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 1 ms
2021-12-03 22:48:01,838 [dispatcher-event-loop-6] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 21.0 in stage 2.0 (TID 65, localhost, executor driver, partition 21, ANY, 7649 bytes)
2021-12-03 22:48:01,838 [Executor task launch worker for task 65] INFO [org.apache.spark.executor.Executor] - Running task 21.0 in stage 2.0 (TID 65)
2021-12-03 22:48:01,838 [Executor task launch worker for task 64] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 22:48:01,838 [Executor task launch worker for task 64] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 22:48:01,838 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 9.0 in stage 2.0 (TID 53) in 409 ms on localhost (executor driver) (10/22)
2021-12-03 22:48:01,839 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 6.0 in stage 2.0 (TID 50) in 411 ms on localhost (executor driver) (11/22)
2021-12-03 22:48:01,839 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 11.0 in stage 2.0 (TID 55) in 410 ms on localhost (executor driver) (12/22)
2021-12-03 22:48:01,839 [Executor task launch worker for task 65] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 22:48:01,839 [Executor task launch worker for task 65] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 22:48:01,967 [Executor task launch worker for task 58] INFO [org.apache.spark.executor.Executor] - Finished task 14.0 in stage 2.0 (TID 58). 1055 bytes result sent to driver
2021-12-03 22:48:01,968 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 14.0 in stage 2.0 (TID 58) in 144 ms on localhost (executor driver) (13/22)
2021-12-03 22:48:01,985 [Executor task launch worker for task 65] INFO [org.apache.spark.executor.Executor] - Finished task 21.0 in stage 2.0 (TID 65). 1098 bytes result sent to driver
2021-12-03 22:48:01,986 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 21.0 in stage 2.0 (TID 65) in 148 ms on localhost (executor driver) (14/22)
2021-12-03 22:48:01,987 [Executor task launch worker for task 59] INFO [org.apache.spark.executor.Executor] - Finished task 15.0 in stage 2.0 (TID 59). 1055 bytes result sent to driver
2021-12-03 22:48:01,989 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 15.0 in stage 2.0 (TID 59) in 164 ms on localhost (executor driver) (15/22)
2021-12-03 22:48:01,995 [Executor task launch worker for task 61] INFO [org.apache.spark.executor.Executor] - Finished task 17.0 in stage 2.0 (TID 61). 1055 bytes result sent to driver
2021-12-03 22:48:01,995 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 17.0 in stage 2.0 (TID 61) in 168 ms on localhost (executor driver) (16/22)
2021-12-03 22:48:01,995 [Executor task launch worker for task 57] INFO [org.apache.spark.executor.Executor] - Finished task 13.0 in stage 2.0 (TID 57). 1098 bytes result sent to driver
2021-12-03 22:48:01,995 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 13.0 in stage 2.0 (TID 57) in 171 ms on localhost (executor driver) (17/22)
2021-12-03 22:48:02,002 [Executor task launch worker for task 63] INFO [org.apache.spark.executor.Executor] - Finished task 19.0 in stage 2.0 (TID 63). 1055 bytes result sent to driver
2021-12-03 22:48:02,002 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 19.0 in stage 2.0 (TID 63) in 166 ms on localhost (executor driver) (18/22)
2021-12-03 22:48:02,003 [Executor task launch worker for task 56] INFO [org.apache.spark.executor.Executor] - Finished task 12.0 in stage 2.0 (TID 56). 1098 bytes result sent to driver
2021-12-03 22:48:02,003 [Executor task launch worker for task 62] INFO [org.apache.spark.executor.Executor] - Finished task 18.0 in stage 2.0 (TID 62). 1098 bytes result sent to driver
2021-12-03 22:48:02,003 [Executor task launch worker for task 60] INFO [org.apache.spark.executor.Executor] - Finished task 16.0 in stage 2.0 (TID 60). 1055 bytes result sent to driver
2021-12-03 22:48:02,003 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 12.0 in stage 2.0 (TID 56) in 179 ms on localhost (executor driver) (19/22)
2021-12-03 22:48:02,003 [Executor task launch worker for task 64] INFO [org.apache.spark.executor.Executor] - Finished task 20.0 in stage 2.0 (TID 64). 1098 bytes result sent to driver
2021-12-03 22:48:02,004 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 18.0 in stage 2.0 (TID 62) in 168 ms on localhost (executor driver) (20/22)
2021-12-03 22:48:02,004 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 16.0 in stage 2.0 (TID 60) in 178 ms on localhost (executor driver) (21/22)
2021-12-03 22:48:02,004 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 20.0 in stage 2.0 (TID 64) in 167 ms on localhost (executor driver) (22/22)
2021-12-03 22:48:02,004 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 2.0, whose tasks have all completed, from pool 
2021-12-03 22:48:02,004 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 2 (count at PaidPromotionAdjustParameter.scala:68) finished in 0.585 s
2021-12-03 22:48:02,004 [main] INFO [org.apache.spark.scheduler.DAGScheduler] - Job 1 finished: count at PaidPromotionAdjustParameter.scala:68, took 257.118245 s
2021-12-03 22:48:02,005 [main] INFO [PaidPromotion$] - 用户总数1207347
2021-12-03 22:48:02,045 [main] INFO [org.apache.spark.SparkContext] - Starting job: sortByKey at PaidPromotionAdjustParameter.scala:73
2021-12-03 22:48:02,046 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 2 (sortByKey at PaidPromotionAdjustParameter.scala:73) with 22 output partitions
2021-12-03 22:48:02,046 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 4 (sortByKey at PaidPromotionAdjustParameter.scala:73)
2021-12-03 22:48:02,046 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 3)
2021-12-03 22:48:02,046 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2021-12-03 22:48:02,046 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 4 (MapPartitionsRDD[7] at sortByKey at PaidPromotionAdjustParameter.scala:73), which has no missing parents
2021-12-03 22:48:02,051 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_4 stored as values in memory (estimated size 4.1 KB, free 1990.5 MB)
2021-12-03 22:48:02,053 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_4_piece0 stored as bytes in memory (estimated size 2.4 KB, free 1990.4 MB)
2021-12-03 22:48:02,053 [dispatcher-event-loop-6] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_4_piece0 in memory on qb:54372 (size: 2.4 KB, free: 1990.8 MB)
2021-12-03 22:48:02,054 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 4 from broadcast at DAGScheduler.scala:1039
2021-12-03 22:48:02,054 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 22 missing tasks from ResultStage 4 (MapPartitionsRDD[7] at sortByKey at PaidPromotionAdjustParameter.scala:73) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14))
2021-12-03 22:48:02,054 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 4.0 with 22 tasks
2021-12-03 22:48:02,055 [dispatcher-event-loop-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 4.0 (TID 66, localhost, executor driver, partition 0, ANY, 7649 bytes)
2021-12-03 22:48:02,055 [dispatcher-event-loop-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 4.0 (TID 67, localhost, executor driver, partition 1, ANY, 7649 bytes)
2021-12-03 22:48:02,055 [dispatcher-event-loop-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 2.0 in stage 4.0 (TID 68, localhost, executor driver, partition 2, ANY, 7649 bytes)
2021-12-03 22:48:02,055 [dispatcher-event-loop-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 3.0 in stage 4.0 (TID 69, localhost, executor driver, partition 3, ANY, 7649 bytes)
2021-12-03 22:48:02,055 [dispatcher-event-loop-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 4.0 in stage 4.0 (TID 70, localhost, executor driver, partition 4, ANY, 7649 bytes)
2021-12-03 22:48:02,055 [dispatcher-event-loop-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 5.0 in stage 4.0 (TID 71, localhost, executor driver, partition 5, ANY, 7649 bytes)
2021-12-03 22:48:02,056 [dispatcher-event-loop-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 6.0 in stage 4.0 (TID 72, localhost, executor driver, partition 6, ANY, 7649 bytes)
2021-12-03 22:48:02,056 [dispatcher-event-loop-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 7.0 in stage 4.0 (TID 73, localhost, executor driver, partition 7, ANY, 7649 bytes)
2021-12-03 22:48:02,056 [dispatcher-event-loop-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 8.0 in stage 4.0 (TID 74, localhost, executor driver, partition 8, ANY, 7649 bytes)
2021-12-03 22:48:02,056 [dispatcher-event-loop-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 9.0 in stage 4.0 (TID 75, localhost, executor driver, partition 9, ANY, 7649 bytes)
2021-12-03 22:48:02,056 [dispatcher-event-loop-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 10.0 in stage 4.0 (TID 76, localhost, executor driver, partition 10, ANY, 7649 bytes)
2021-12-03 22:48:02,056 [dispatcher-event-loop-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 11.0 in stage 4.0 (TID 77, localhost, executor driver, partition 11, ANY, 7649 bytes)
2021-12-03 22:48:02,056 [Executor task launch worker for task 68] INFO [org.apache.spark.executor.Executor] - Running task 2.0 in stage 4.0 (TID 68)
2021-12-03 22:48:02,056 [Executor task launch worker for task 67] INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 4.0 (TID 67)
2021-12-03 22:48:02,056 [Executor task launch worker for task 72] INFO [org.apache.spark.executor.Executor] - Running task 6.0 in stage 4.0 (TID 72)
2021-12-03 22:48:02,056 [Executor task launch worker for task 73] INFO [org.apache.spark.executor.Executor] - Running task 7.0 in stage 4.0 (TID 73)
2021-12-03 22:48:02,056 [Executor task launch worker for task 69] INFO [org.apache.spark.executor.Executor] - Running task 3.0 in stage 4.0 (TID 69)
2021-12-03 22:48:02,056 [Executor task launch worker for task 66] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 4.0 (TID 66)
2021-12-03 22:48:02,056 [Executor task launch worker for task 71] INFO [org.apache.spark.executor.Executor] - Running task 5.0 in stage 4.0 (TID 71)
2021-12-03 22:48:02,056 [Executor task launch worker for task 70] INFO [org.apache.spark.executor.Executor] - Running task 4.0 in stage 4.0 (TID 70)
2021-12-03 22:48:02,056 [Executor task launch worker for task 76] INFO [org.apache.spark.executor.Executor] - Running task 10.0 in stage 4.0 (TID 76)
2021-12-03 22:48:02,056 [Executor task launch worker for task 77] INFO [org.apache.spark.executor.Executor] - Running task 11.0 in stage 4.0 (TID 77)
2021-12-03 22:48:02,056 [Executor task launch worker for task 75] INFO [org.apache.spark.executor.Executor] - Running task 9.0 in stage 4.0 (TID 75)
2021-12-03 22:48:02,056 [Executor task launch worker for task 74] INFO [org.apache.spark.executor.Executor] - Running task 8.0 in stage 4.0 (TID 74)
2021-12-03 22:48:02,058 [Executor task launch worker for task 77] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 22:48:02,058 [Executor task launch worker for task 77] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 22:48:02,058 [Executor task launch worker for task 73] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 22:48:02,058 [Executor task launch worker for task 73] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 22:48:02,058 [Executor task launch worker for task 67] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 22:48:02,058 [Executor task launch worker for task 66] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 22:48:02,058 [Executor task launch worker for task 67] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 22:48:02,058 [Executor task launch worker for task 66] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 22:48:02,058 [Executor task launch worker for task 72] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 22:48:02,058 [Executor task launch worker for task 72] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 22:48:02,058 [Executor task launch worker for task 69] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 22:48:02,058 [Executor task launch worker for task 69] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 22:48:02,058 [Executor task launch worker for task 70] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 22:48:02,058 [Executor task launch worker for task 71] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 22:48:02,058 [Executor task launch worker for task 71] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 22:48:02,058 [Executor task launch worker for task 70] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 22:48:02,058 [Executor task launch worker for task 76] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 22:48:02,058 [Executor task launch worker for task 76] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 22:48:02,058 [Executor task launch worker for task 75] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 22:48:02,058 [Executor task launch worker for task 75] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 22:48:02,058 [Executor task launch worker for task 74] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 22:48:02,058 [Executor task launch worker for task 74] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 22:48:02,058 [Executor task launch worker for task 68] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 22:48:02,058 [Executor task launch worker for task 68] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 22:48:02,168 [Executor task launch worker for task 73] INFO [org.apache.spark.executor.Executor] - Finished task 7.0 in stage 4.0 (TID 73). 1100 bytes result sent to driver
2021-12-03 22:48:02,169 [dispatcher-event-loop-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 12.0 in stage 4.0 (TID 78, localhost, executor driver, partition 12, ANY, 7649 bytes)
2021-12-03 22:48:02,169 [Executor task launch worker for task 78] INFO [org.apache.spark.executor.Executor] - Running task 12.0 in stage 4.0 (TID 78)
2021-12-03 22:48:02,169 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 7.0 in stage 4.0 (TID 73) in 113 ms on localhost (executor driver) (1/22)
2021-12-03 22:48:02,170 [Executor task launch worker for task 78] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 22:48:02,170 [Executor task launch worker for task 78] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 22:48:02,182 [Executor task launch worker for task 70] INFO [org.apache.spark.executor.Executor] - Finished task 4.0 in stage 4.0 (TID 70). 1144 bytes result sent to driver
2021-12-03 22:48:02,182 [Executor task launch worker for task 75] INFO [org.apache.spark.executor.Executor] - Finished task 9.0 in stage 4.0 (TID 75). 1149 bytes result sent to driver
2021-12-03 22:48:02,182 [dispatcher-event-loop-5] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 13.0 in stage 4.0 (TID 79, localhost, executor driver, partition 13, ANY, 7649 bytes)
2021-12-03 22:48:02,182 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 4.0 in stage 4.0 (TID 70) in 127 ms on localhost (executor driver) (2/22)
2021-12-03 22:48:02,182 [Executor task launch worker for task 79] INFO [org.apache.spark.executor.Executor] - Running task 13.0 in stage 4.0 (TID 79)
2021-12-03 22:48:02,183 [dispatcher-event-loop-5] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 14.0 in stage 4.0 (TID 80, localhost, executor driver, partition 14, ANY, 7649 bytes)
2021-12-03 22:48:02,183 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 9.0 in stage 4.0 (TID 75) in 127 ms on localhost (executor driver) (3/22)
2021-12-03 22:48:02,183 [Executor task launch worker for task 80] INFO [org.apache.spark.executor.Executor] - Running task 14.0 in stage 4.0 (TID 80)
2021-12-03 22:48:02,183 [Executor task launch worker for task 79] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 22:48:02,184 [Executor task launch worker for task 79] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 1 ms
2021-12-03 22:48:02,184 [Executor task launch worker for task 80] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 22:48:02,184 [Executor task launch worker for task 80] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 22:48:02,190 [Executor task launch worker for task 74] INFO [org.apache.spark.executor.Executor] - Finished task 8.0 in stage 4.0 (TID 74). 1144 bytes result sent to driver
2021-12-03 22:48:02,190 [dispatcher-event-loop-9] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 15.0 in stage 4.0 (TID 81, localhost, executor driver, partition 15, ANY, 7649 bytes)
2021-12-03 22:48:02,190 [Executor task launch worker for task 81] INFO [org.apache.spark.executor.Executor] - Running task 15.0 in stage 4.0 (TID 81)
2021-12-03 22:48:02,190 [Executor task launch worker for task 66] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 4.0 (TID 66). 1145 bytes result sent to driver
2021-12-03 22:48:02,190 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 8.0 in stage 4.0 (TID 74) in 134 ms on localhost (executor driver) (4/22)
2021-12-03 22:48:02,191 [dispatcher-event-loop-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 16.0 in stage 4.0 (TID 82, localhost, executor driver, partition 16, ANY, 7649 bytes)
2021-12-03 22:48:02,191 [Executor task launch worker for task 82] INFO [org.apache.spark.executor.Executor] - Running task 16.0 in stage 4.0 (TID 82)
2021-12-03 22:48:02,191 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 4.0 (TID 66) in 136 ms on localhost (executor driver) (5/22)
2021-12-03 22:48:02,191 [Executor task launch worker for task 81] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 22:48:02,191 [Executor task launch worker for task 81] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 22:48:02,192 [Executor task launch worker for task 82] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 22:48:02,192 [Executor task launch worker for task 82] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 22:48:02,194 [Executor task launch worker for task 76] INFO [org.apache.spark.executor.Executor] - Finished task 10.0 in stage 4.0 (TID 76). 1144 bytes result sent to driver
2021-12-03 22:48:02,195 [dispatcher-event-loop-6] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 17.0 in stage 4.0 (TID 83, localhost, executor driver, partition 17, ANY, 7649 bytes)
2021-12-03 22:48:02,195 [Executor task launch worker for task 83] INFO [org.apache.spark.executor.Executor] - Running task 17.0 in stage 4.0 (TID 83)
2021-12-03 22:48:02,195 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 10.0 in stage 4.0 (TID 76) in 139 ms on localhost (executor driver) (6/22)
2021-12-03 22:48:02,197 [Executor task launch worker for task 83] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 22:48:02,197 [Executor task launch worker for task 83] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 22:48:02,198 [Executor task launch worker for task 77] INFO [org.apache.spark.executor.Executor] - Finished task 11.0 in stage 4.0 (TID 77). 1142 bytes result sent to driver
2021-12-03 22:48:02,198 [dispatcher-event-loop-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 18.0 in stage 4.0 (TID 84, localhost, executor driver, partition 18, ANY, 7649 bytes)
2021-12-03 22:48:02,198 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 11.0 in stage 4.0 (TID 77) in 142 ms on localhost (executor driver) (7/22)
2021-12-03 22:48:02,198 [Executor task launch worker for task 84] INFO [org.apache.spark.executor.Executor] - Running task 18.0 in stage 4.0 (TID 84)
2021-12-03 22:48:02,200 [Executor task launch worker for task 84] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 22:48:02,200 [Executor task launch worker for task 84] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 22:48:02,204 [Executor task launch worker for task 72] INFO [org.apache.spark.executor.Executor] - Finished task 6.0 in stage 4.0 (TID 72). 1138 bytes result sent to driver
2021-12-03 22:48:02,204 [dispatcher-event-loop-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 19.0 in stage 4.0 (TID 85, localhost, executor driver, partition 19, ANY, 7649 bytes)
2021-12-03 22:48:02,204 [Executor task launch worker for task 85] INFO [org.apache.spark.executor.Executor] - Running task 19.0 in stage 4.0 (TID 85)
2021-12-03 22:48:02,205 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 6.0 in stage 4.0 (TID 72) in 149 ms on localhost (executor driver) (8/22)
2021-12-03 22:48:02,206 [Executor task launch worker for task 85] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 22:48:02,206 [Executor task launch worker for task 85] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 1 ms
2021-12-03 22:48:02,206 [Executor task launch worker for task 69] INFO [org.apache.spark.executor.Executor] - Finished task 3.0 in stage 4.0 (TID 69). 1141 bytes result sent to driver
2021-12-03 22:48:02,206 [dispatcher-event-loop-5] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 20.0 in stage 4.0 (TID 86, localhost, executor driver, partition 20, ANY, 7649 bytes)
2021-12-03 22:48:02,206 [Executor task launch worker for task 86] INFO [org.apache.spark.executor.Executor] - Running task 20.0 in stage 4.0 (TID 86)
2021-12-03 22:48:02,207 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 3.0 in stage 4.0 (TID 69) in 152 ms on localhost (executor driver) (9/22)
2021-12-03 22:48:02,208 [Executor task launch worker for task 86] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 22:48:02,208 [Executor task launch worker for task 86] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 22:48:02,209 [Executor task launch worker for task 67] INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 4.0 (TID 67). 1140 bytes result sent to driver
2021-12-03 22:48:02,210 [dispatcher-event-loop-9] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 21.0 in stage 4.0 (TID 87, localhost, executor driver, partition 21, ANY, 7649 bytes)
2021-12-03 22:48:02,210 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 4.0 (TID 67) in 155 ms on localhost (executor driver) (10/22)
2021-12-03 22:48:02,210 [Executor task launch worker for task 87] INFO [org.apache.spark.executor.Executor] - Running task 21.0 in stage 4.0 (TID 87)
2021-12-03 22:48:02,212 [Executor task launch worker for task 71] INFO [org.apache.spark.executor.Executor] - Finished task 5.0 in stage 4.0 (TID 71). 1146 bytes result sent to driver
2021-12-03 22:48:02,212 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 5.0 in stage 4.0 (TID 71) in 157 ms on localhost (executor driver) (11/22)
2021-12-03 22:48:02,214 [Executor task launch worker for task 87] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 22:48:02,214 [Executor task launch worker for task 87] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 1 ms
2021-12-03 22:48:02,229 [Executor task launch worker for task 68] INFO [org.apache.spark.executor.Executor] - Finished task 2.0 in stage 4.0 (TID 68). 1103 bytes result sent to driver
2021-12-03 22:48:02,231 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 2.0 in stage 4.0 (TID 68) in 176 ms on localhost (executor driver) (12/22)
2021-12-03 22:48:02,283 [Executor task launch worker for task 78] INFO [org.apache.spark.executor.Executor] - Finished task 12.0 in stage 4.0 (TID 78). 1142 bytes result sent to driver
2021-12-03 22:48:02,283 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 12.0 in stage 4.0 (TID 78) in 114 ms on localhost (executor driver) (13/22)
2021-12-03 22:48:02,304 [Executor task launch worker for task 80] INFO [org.apache.spark.executor.Executor] - Finished task 14.0 in stage 4.0 (TID 80). 1185 bytes result sent to driver
2021-12-03 22:48:02,304 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 14.0 in stage 4.0 (TID 80) in 121 ms on localhost (executor driver) (14/22)
2021-12-03 22:48:02,306 [Executor task launch worker for task 79] INFO [org.apache.spark.executor.Executor] - Finished task 13.0 in stage 4.0 (TID 79). 1184 bytes result sent to driver
2021-12-03 22:48:02,306 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 13.0 in stage 4.0 (TID 79) in 124 ms on localhost (executor driver) (15/22)
2021-12-03 22:48:02,308 [Executor task launch worker for task 82] INFO [org.apache.spark.executor.Executor] - Finished task 16.0 in stage 4.0 (TID 82). 1143 bytes result sent to driver
2021-12-03 22:48:02,308 [Executor task launch worker for task 81] INFO [org.apache.spark.executor.Executor] - Finished task 15.0 in stage 4.0 (TID 81). 1180 bytes result sent to driver
2021-12-03 22:48:02,308 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 16.0 in stage 4.0 (TID 82) in 117 ms on localhost (executor driver) (16/22)
2021-12-03 22:48:02,309 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 15.0 in stage 4.0 (TID 81) in 119 ms on localhost (executor driver) (17/22)
2021-12-03 22:48:02,311 [Executor task launch worker for task 83] INFO [org.apache.spark.executor.Executor] - Finished task 17.0 in stage 4.0 (TID 83). 1185 bytes result sent to driver
2021-12-03 22:48:02,312 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 17.0 in stage 4.0 (TID 83) in 117 ms on localhost (executor driver) (18/22)
2021-12-03 22:48:02,314 [Executor task launch worker for task 84] INFO [org.apache.spark.executor.Executor] - Finished task 18.0 in stage 4.0 (TID 84). 1180 bytes result sent to driver
2021-12-03 22:48:02,314 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 18.0 in stage 4.0 (TID 84) in 116 ms on localhost (executor driver) (19/22)
2021-12-03 22:48:02,325 [Executor task launch worker for task 85] INFO [org.apache.spark.executor.Executor] - Finished task 19.0 in stage 4.0 (TID 85). 1189 bytes result sent to driver
2021-12-03 22:48:02,326 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 19.0 in stage 4.0 (TID 85) in 122 ms on localhost (executor driver) (20/22)
2021-12-03 22:48:02,328 [Executor task launch worker for task 86] INFO [org.apache.spark.executor.Executor] - Finished task 20.0 in stage 4.0 (TID 86). 1232 bytes result sent to driver
2021-12-03 22:48:02,328 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 20.0 in stage 4.0 (TID 86) in 122 ms on localhost (executor driver) (21/22)
2021-12-03 22:48:02,335 [Executor task launch worker for task 87] INFO [org.apache.spark.executor.Executor] - Finished task 21.0 in stage 4.0 (TID 87). 1187 bytes result sent to driver
2021-12-03 22:48:02,336 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 21.0 in stage 4.0 (TID 87) in 126 ms on localhost (executor driver) (22/22)
2021-12-03 22:48:02,336 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 4.0, whose tasks have all completed, from pool 
2021-12-03 22:48:02,336 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 4 (sortByKey at PaidPromotionAdjustParameter.scala:73) finished in 0.286 s
2021-12-03 22:48:02,336 [main] INFO [org.apache.spark.scheduler.DAGScheduler] - Job 2 finished: sortByKey at PaidPromotionAdjustParameter.scala:73, took 0.291199 s
2021-12-03 22:48:02,358 [main] INFO [org.apache.spark.SparkContext] - Starting job: zipWithIndex at PaidPromotionAdjustParameter.scala:74
2021-12-03 22:48:02,359 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 5 (map at PaidPromotionAdjustParameter.scala:72)
2021-12-03 22:48:02,359 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 3 (zipWithIndex at PaidPromotionAdjustParameter.scala:74) with 21 output partitions
2021-12-03 22:48:02,359 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 7 (zipWithIndex at PaidPromotionAdjustParameter.scala:74)
2021-12-03 22:48:02,359 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 6)
2021-12-03 22:48:02,359 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List(ShuffleMapStage 6)
2021-12-03 22:48:02,359 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ShuffleMapStage 6 (MapPartitionsRDD[5] at map at PaidPromotionAdjustParameter.scala:72), which has no missing parents
2021-12-03 22:48:02,367 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_5 stored as values in memory (estimated size 4.1 KB, free 1990.4 MB)
2021-12-03 22:48:02,370 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_5_piece0 stored as bytes in memory (estimated size 2.4 KB, free 1990.4 MB)
2021-12-03 22:48:02,370 [dispatcher-event-loop-2] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_5_piece0 in memory on qb:54372 (size: 2.4 KB, free: 1990.8 MB)
2021-12-03 22:48:02,370 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 5 from broadcast at DAGScheduler.scala:1039
2021-12-03 22:48:02,371 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 22 missing tasks from ShuffleMapStage 6 (MapPartitionsRDD[5] at map at PaidPromotionAdjustParameter.scala:72) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14))
2021-12-03 22:48:02,371 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 6.0 with 22 tasks
2021-12-03 22:48:02,371 [dispatcher-event-loop-11] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 6.0 (TID 88, localhost, executor driver, partition 0, ANY, 7638 bytes)
2021-12-03 22:48:02,372 [dispatcher-event-loop-11] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 6.0 (TID 89, localhost, executor driver, partition 1, ANY, 7638 bytes)
2021-12-03 22:48:02,372 [dispatcher-event-loop-11] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 2.0 in stage 6.0 (TID 90, localhost, executor driver, partition 2, ANY, 7638 bytes)
2021-12-03 22:48:02,372 [dispatcher-event-loop-11] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 3.0 in stage 6.0 (TID 91, localhost, executor driver, partition 3, ANY, 7638 bytes)
2021-12-03 22:48:02,372 [dispatcher-event-loop-11] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 4.0 in stage 6.0 (TID 92, localhost, executor driver, partition 4, ANY, 7638 bytes)
2021-12-03 22:48:02,372 [dispatcher-event-loop-11] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 5.0 in stage 6.0 (TID 93, localhost, executor driver, partition 5, ANY, 7638 bytes)
2021-12-03 22:48:02,372 [dispatcher-event-loop-11] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 6.0 in stage 6.0 (TID 94, localhost, executor driver, partition 6, ANY, 7638 bytes)
2021-12-03 22:48:02,372 [dispatcher-event-loop-11] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 7.0 in stage 6.0 (TID 95, localhost, executor driver, partition 7, ANY, 7638 bytes)
2021-12-03 22:48:02,372 [dispatcher-event-loop-11] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 8.0 in stage 6.0 (TID 96, localhost, executor driver, partition 8, ANY, 7638 bytes)
2021-12-03 22:48:02,372 [dispatcher-event-loop-11] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 9.0 in stage 6.0 (TID 97, localhost, executor driver, partition 9, ANY, 7638 bytes)
2021-12-03 22:48:02,372 [dispatcher-event-loop-11] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 10.0 in stage 6.0 (TID 98, localhost, executor driver, partition 10, ANY, 7638 bytes)
2021-12-03 22:48:02,372 [dispatcher-event-loop-11] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 11.0 in stage 6.0 (TID 99, localhost, executor driver, partition 11, ANY, 7638 bytes)
2021-12-03 22:48:02,373 [Executor task launch worker for task 89] INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 6.0 (TID 89)
2021-12-03 22:48:02,373 [Executor task launch worker for task 88] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 6.0 (TID 88)
2021-12-03 22:48:02,373 [Executor task launch worker for task 95] INFO [org.apache.spark.executor.Executor] - Running task 7.0 in stage 6.0 (TID 95)
2021-12-03 22:48:02,373 [Executor task launch worker for task 97] INFO [org.apache.spark.executor.Executor] - Running task 9.0 in stage 6.0 (TID 97)
2021-12-03 22:48:02,373 [Executor task launch worker for task 98] INFO [org.apache.spark.executor.Executor] - Running task 10.0 in stage 6.0 (TID 98)
2021-12-03 22:48:02,373 [Executor task launch worker for task 91] INFO [org.apache.spark.executor.Executor] - Running task 3.0 in stage 6.0 (TID 91)
2021-12-03 22:48:02,373 [Executor task launch worker for task 93] INFO [org.apache.spark.executor.Executor] - Running task 5.0 in stage 6.0 (TID 93)
2021-12-03 22:48:02,373 [Executor task launch worker for task 92] INFO [org.apache.spark.executor.Executor] - Running task 4.0 in stage 6.0 (TID 92)
2021-12-03 22:48:02,373 [Executor task launch worker for task 90] INFO [org.apache.spark.executor.Executor] - Running task 2.0 in stage 6.0 (TID 90)
2021-12-03 22:48:02,373 [Executor task launch worker for task 99] INFO [org.apache.spark.executor.Executor] - Running task 11.0 in stage 6.0 (TID 99)
2021-12-03 22:48:02,373 [Executor task launch worker for task 94] INFO [org.apache.spark.executor.Executor] - Running task 6.0 in stage 6.0 (TID 94)
2021-12-03 22:48:02,373 [Executor task launch worker for task 96] INFO [org.apache.spark.executor.Executor] - Running task 8.0 in stage 6.0 (TID 96)
2021-12-03 22:48:02,382 [Executor task launch worker for task 90] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 22:48:02,382 [Executor task launch worker for task 89] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 22:48:02,382 [Executor task launch worker for task 90] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 22:48:02,382 [Executor task launch worker for task 92] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 22:48:02,382 [Executor task launch worker for task 89] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 22:48:02,383 [Executor task launch worker for task 97] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 22:48:02,383 [Executor task launch worker for task 97] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 22:48:02,382 [Executor task launch worker for task 99] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 22:48:02,383 [Executor task launch worker for task 99] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 1 ms
2021-12-03 22:48:02,383 [Executor task launch worker for task 93] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 22:48:02,383 [Executor task launch worker for task 93] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 22:48:02,383 [Executor task launch worker for task 98] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 22:48:02,383 [Executor task launch worker for task 92] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 1 ms
2021-12-03 22:48:02,383 [Executor task launch worker for task 98] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 1 ms
2021-12-03 22:48:02,383 [Executor task launch worker for task 94] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 22:48:02,383 [Executor task launch worker for task 88] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 22:48:02,383 [Executor task launch worker for task 88] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 22:48:02,383 [Executor task launch worker for task 95] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 22:48:02,383 [Executor task launch worker for task 94] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 22:48:02,383 [Executor task launch worker for task 95] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 22:48:02,383 [Executor task launch worker for task 96] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 22:48:02,383 [Executor task launch worker for task 96] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 22:48:02,383 [Executor task launch worker for task 91] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 22:48:02,383 [Executor task launch worker for task 91] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 22:48:02,625 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 87
2021-12-03 22:48:02,625 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 85
2021-12-03 22:48:02,625 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 88
2021-12-03 22:48:02,625 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 99
2021-12-03 22:48:02,625 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 96
2021-12-03 22:48:02,625 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 77
2021-12-03 22:48:02,625 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 95
2021-12-03 22:48:02,625 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 76
2021-12-03 22:48:02,625 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 90
2021-12-03 22:48:02,625 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 84
2021-12-03 22:48:02,625 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 75
2021-12-03 22:48:02,625 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 97
2021-12-03 22:48:02,625 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 83
2021-12-03 22:48:02,625 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 89
2021-12-03 22:48:02,625 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 81
2021-12-03 22:48:02,625 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 82
2021-12-03 22:48:02,625 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 94
2021-12-03 22:48:02,625 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 79
2021-12-03 22:48:02,625 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 91
2021-12-03 22:48:02,625 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 78
2021-12-03 22:48:02,625 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 98
2021-12-03 22:48:02,645 [dispatcher-event-loop-6] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_4_piece0 on qb:54372 in memory (size: 2.4 KB, free: 1990.8 MB)
2021-12-03 22:48:02,647 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 80
2021-12-03 22:48:02,647 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 86
2021-12-03 22:48:02,647 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 92
2021-12-03 22:48:02,647 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 93
2021-12-03 22:48:02,988 [Executor task launch worker for task 91] INFO [org.apache.spark.executor.Executor] - Finished task 3.0 in stage 6.0 (TID 91). 1267 bytes result sent to driver
2021-12-03 22:48:02,990 [dispatcher-event-loop-7] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 12.0 in stage 6.0 (TID 100, localhost, executor driver, partition 12, ANY, 7638 bytes)
2021-12-03 22:48:02,990 [Executor task launch worker for task 100] INFO [org.apache.spark.executor.Executor] - Running task 12.0 in stage 6.0 (TID 100)
2021-12-03 22:48:02,990 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 3.0 in stage 6.0 (TID 91) in 618 ms on localhost (executor driver) (1/22)
2021-12-03 22:48:02,997 [Executor task launch worker for task 100] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 22:48:02,997 [Executor task launch worker for task 100] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 1 ms
2021-12-03 22:48:03,018 [Executor task launch worker for task 93] INFO [org.apache.spark.executor.Executor] - Finished task 5.0 in stage 6.0 (TID 93). 1267 bytes result sent to driver
2021-12-03 22:48:03,019 [Executor task launch worker for task 97] INFO [org.apache.spark.executor.Executor] - Finished task 9.0 in stage 6.0 (TID 97). 1267 bytes result sent to driver
2021-12-03 22:48:03,020 [dispatcher-event-loop-8] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 13.0 in stage 6.0 (TID 101, localhost, executor driver, partition 13, ANY, 7638 bytes)
2021-12-03 22:48:03,020 [Executor task launch worker for task 101] INFO [org.apache.spark.executor.Executor] - Running task 13.0 in stage 6.0 (TID 101)
2021-12-03 22:48:03,020 [dispatcher-event-loop-8] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 14.0 in stage 6.0 (TID 102, localhost, executor driver, partition 14, ANY, 7638 bytes)
2021-12-03 22:48:03,021 [Executor task launch worker for task 92] INFO [org.apache.spark.executor.Executor] - Finished task 4.0 in stage 6.0 (TID 92). 1267 bytes result sent to driver
2021-12-03 22:48:03,021 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 9.0 in stage 6.0 (TID 97) in 649 ms on localhost (executor driver) (2/22)
2021-12-03 22:48:03,021 [Executor task launch worker for task 102] INFO [org.apache.spark.executor.Executor] - Running task 14.0 in stage 6.0 (TID 102)
2021-12-03 22:48:03,022 [dispatcher-event-loop-10] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 15.0 in stage 6.0 (TID 103, localhost, executor driver, partition 15, ANY, 7638 bytes)
2021-12-03 22:48:03,022 [Executor task launch worker for task 103] INFO [org.apache.spark.executor.Executor] - Running task 15.0 in stage 6.0 (TID 103)
2021-12-03 22:48:03,022 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 5.0 in stage 6.0 (TID 93) in 650 ms on localhost (executor driver) (3/22)
2021-12-03 22:48:03,023 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 4.0 in stage 6.0 (TID 92) in 651 ms on localhost (executor driver) (4/22)
2021-12-03 22:48:03,023 [Executor task launch worker for task 94] INFO [org.apache.spark.executor.Executor] - Finished task 6.0 in stage 6.0 (TID 94). 1267 bytes result sent to driver
2021-12-03 22:48:03,024 [dispatcher-event-loop-11] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 16.0 in stage 6.0 (TID 104, localhost, executor driver, partition 16, ANY, 7638 bytes)
2021-12-03 22:48:03,024 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 6.0 in stage 6.0 (TID 94) in 652 ms on localhost (executor driver) (5/22)
2021-12-03 22:48:03,025 [Executor task launch worker for task 99] INFO [org.apache.spark.executor.Executor] - Finished task 11.0 in stage 6.0 (TID 99). 1267 bytes result sent to driver
2021-12-03 22:48:03,025 [Executor task launch worker for task 101] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 22:48:03,025 [Executor task launch worker for task 101] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 22:48:03,026 [Executor task launch worker for task 104] INFO [org.apache.spark.executor.Executor] - Running task 16.0 in stage 6.0 (TID 104)
2021-12-03 22:48:03,027 [Executor task launch worker for task 96] INFO [org.apache.spark.executor.Executor] - Finished task 8.0 in stage 6.0 (TID 96). 1310 bytes result sent to driver
2021-12-03 22:48:03,027 [dispatcher-event-loop-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 17.0 in stage 6.0 (TID 105, localhost, executor driver, partition 17, ANY, 7638 bytes)
2021-12-03 22:48:03,028 [Executor task launch worker for task 105] INFO [org.apache.spark.executor.Executor] - Running task 17.0 in stage 6.0 (TID 105)
2021-12-03 22:48:03,028 [Executor task launch worker for task 103] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 22:48:03,028 [Executor task launch worker for task 103] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 22:48:03,031 [Executor task launch worker for task 102] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 22:48:03,031 [Executor task launch worker for task 102] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 22:48:03,032 [Executor task launch worker for task 105] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 22:48:03,032 [Executor task launch worker for task 105] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 22:48:03,033 [Executor task launch worker for task 98] INFO [org.apache.spark.executor.Executor] - Finished task 10.0 in stage 6.0 (TID 98). 1267 bytes result sent to driver
2021-12-03 22:48:03,034 [Executor task launch worker for task 104] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 22:48:03,034 [Executor task launch worker for task 104] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 22:48:03,034 [dispatcher-event-loop-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 18.0 in stage 6.0 (TID 106, localhost, executor driver, partition 18, ANY, 7638 bytes)
2021-12-03 22:48:03,034 [Executor task launch worker for task 106] INFO [org.apache.spark.executor.Executor] - Running task 18.0 in stage 6.0 (TID 106)
2021-12-03 22:48:03,035 [dispatcher-event-loop-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 19.0 in stage 6.0 (TID 107, localhost, executor driver, partition 19, ANY, 7638 bytes)
2021-12-03 22:48:03,035 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 10.0 in stage 6.0 (TID 98) in 663 ms on localhost (executor driver) (6/22)
2021-12-03 22:48:03,035 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 11.0 in stage 6.0 (TID 99) in 663 ms on localhost (executor driver) (7/22)
2021-12-03 22:48:03,035 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 8.0 in stage 6.0 (TID 96) in 663 ms on localhost (executor driver) (8/22)
2021-12-03 22:48:03,035 [Executor task launch worker for task 107] INFO [org.apache.spark.executor.Executor] - Running task 19.0 in stage 6.0 (TID 107)
2021-12-03 22:48:03,041 [Executor task launch worker for task 106] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 22:48:03,041 [Executor task launch worker for task 106] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 22:48:03,042 [Executor task launch worker for task 88] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 6.0 (TID 88). 1267 bytes result sent to driver
2021-12-03 22:48:03,043 [dispatcher-event-loop-9] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 20.0 in stage 6.0 (TID 108, localhost, executor driver, partition 20, ANY, 7638 bytes)
2021-12-03 22:48:03,044 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 6.0 (TID 88) in 673 ms on localhost (executor driver) (9/22)
2021-12-03 22:48:03,044 [Executor task launch worker for task 107] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 22:48:03,044 [Executor task launch worker for task 108] INFO [org.apache.spark.executor.Executor] - Running task 20.0 in stage 6.0 (TID 108)
2021-12-03 22:48:03,044 [Executor task launch worker for task 107] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 22:48:03,049 [Executor task launch worker for task 108] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 22:48:03,049 [Executor task launch worker for task 108] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 22:48:03,057 [Executor task launch worker for task 89] INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 6.0 (TID 89). 1310 bytes result sent to driver
2021-12-03 22:48:03,058 [dispatcher-event-loop-4] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 21.0 in stage 6.0 (TID 109, localhost, executor driver, partition 21, ANY, 7638 bytes)
2021-12-03 22:48:03,058 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 6.0 (TID 89) in 687 ms on localhost (executor driver) (10/22)
2021-12-03 22:48:03,058 [Executor task launch worker for task 109] INFO [org.apache.spark.executor.Executor] - Running task 21.0 in stage 6.0 (TID 109)
2021-12-03 22:48:03,062 [Executor task launch worker for task 95] INFO [org.apache.spark.executor.Executor] - Finished task 7.0 in stage 6.0 (TID 95). 1267 bytes result sent to driver
2021-12-03 22:48:03,063 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 7.0 in stage 6.0 (TID 95) in 691 ms on localhost (executor driver) (11/22)
2021-12-03 22:48:03,070 [Executor task launch worker for task 109] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 22:48:03,071 [Executor task launch worker for task 109] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 1 ms
2021-12-03 22:48:03,075 [Executor task launch worker for task 90] INFO [org.apache.spark.executor.Executor] - Finished task 2.0 in stage 6.0 (TID 90). 1267 bytes result sent to driver
2021-12-03 22:48:03,076 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 2.0 in stage 6.0 (TID 90) in 704 ms on localhost (executor driver) (12/22)
2021-12-03 22:48:03,406 [Executor task launch worker for task 105] INFO [org.apache.spark.executor.Executor] - Finished task 17.0 in stage 6.0 (TID 105). 1267 bytes result sent to driver
2021-12-03 22:48:03,406 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 17.0 in stage 6.0 (TID 105) in 379 ms on localhost (executor driver) (13/22)
2021-12-03 22:48:03,407 [Executor task launch worker for task 101] INFO [org.apache.spark.executor.Executor] - Finished task 13.0 in stage 6.0 (TID 101). 1224 bytes result sent to driver
2021-12-03 22:48:03,408 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 13.0 in stage 6.0 (TID 101) in 388 ms on localhost (executor driver) (14/22)
2021-12-03 22:48:03,445 [Executor task launch worker for task 100] INFO [org.apache.spark.executor.Executor] - Finished task 12.0 in stage 6.0 (TID 100). 1224 bytes result sent to driver
2021-12-03 22:48:03,445 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 12.0 in stage 6.0 (TID 100) in 456 ms on localhost (executor driver) (15/22)
2021-12-03 22:48:03,446 [Executor task launch worker for task 107] INFO [org.apache.spark.executor.Executor] - Finished task 19.0 in stage 6.0 (TID 107). 1224 bytes result sent to driver
2021-12-03 22:48:03,446 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 19.0 in stage 6.0 (TID 107) in 412 ms on localhost (executor driver) (16/22)
2021-12-03 22:48:03,450 [Executor task launch worker for task 106] INFO [org.apache.spark.executor.Executor] - Finished task 18.0 in stage 6.0 (TID 106). 1224 bytes result sent to driver
2021-12-03 22:48:03,450 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 18.0 in stage 6.0 (TID 106) in 422 ms on localhost (executor driver) (17/22)
2021-12-03 22:48:03,451 [Executor task launch worker for task 103] INFO [org.apache.spark.executor.Executor] - Finished task 15.0 in stage 6.0 (TID 103). 1224 bytes result sent to driver
2021-12-03 22:48:03,452 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 15.0 in stage 6.0 (TID 103) in 430 ms on localhost (executor driver) (18/22)
2021-12-03 22:48:03,452 [Executor task launch worker for task 104] INFO [org.apache.spark.executor.Executor] - Finished task 16.0 in stage 6.0 (TID 104). 1224 bytes result sent to driver
2021-12-03 22:48:03,452 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 16.0 in stage 6.0 (TID 104) in 428 ms on localhost (executor driver) (19/22)
2021-12-03 22:48:03,460 [Executor task launch worker for task 102] INFO [org.apache.spark.executor.Executor] - Finished task 14.0 in stage 6.0 (TID 102). 1224 bytes result sent to driver
2021-12-03 22:48:03,460 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 14.0 in stage 6.0 (TID 102) in 440 ms on localhost (executor driver) (20/22)
2021-12-03 22:48:03,462 [Executor task launch worker for task 108] INFO [org.apache.spark.executor.Executor] - Finished task 20.0 in stage 6.0 (TID 108). 1267 bytes result sent to driver
2021-12-03 22:48:03,462 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 20.0 in stage 6.0 (TID 108) in 419 ms on localhost (executor driver) (21/22)
2021-12-03 22:48:03,464 [Executor task launch worker for task 109] INFO [org.apache.spark.executor.Executor] - Finished task 21.0 in stage 6.0 (TID 109). 1224 bytes result sent to driver
2021-12-03 22:48:03,464 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 21.0 in stage 6.0 (TID 109) in 407 ms on localhost (executor driver) (22/22)
2021-12-03 22:48:03,464 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 6.0, whose tasks have all completed, from pool 
2021-12-03 22:48:03,464 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ShuffleMapStage 6 (map at PaidPromotionAdjustParameter.scala:72) finished in 1.103 s
2021-12-03 22:48:03,464 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - looking for newly runnable stages
2021-12-03 22:48:03,465 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - running: Set()
2021-12-03 22:48:03,465 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - waiting: Set(ResultStage 7)
2021-12-03 22:48:03,465 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - failed: Set()
2021-12-03 22:48:03,465 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 7 (ShuffledRDD[8] at sortByKey at PaidPromotionAdjustParameter.scala:73), which has no missing parents
2021-12-03 22:48:03,467 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_6 stored as values in memory (estimated size 3.4 KB, free 1990.4 MB)
2021-12-03 22:48:03,469 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_6_piece0 stored as bytes in memory (estimated size 2.0 KB, free 1990.4 MB)
2021-12-03 22:48:03,469 [dispatcher-event-loop-11] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_6_piece0 in memory on qb:54372 (size: 2.0 KB, free: 1990.8 MB)
2021-12-03 22:48:03,469 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 6 from broadcast at DAGScheduler.scala:1039
2021-12-03 22:48:03,470 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 21 missing tasks from ResultStage 7 (ShuffledRDD[8] at sortByKey at PaidPromotionAdjustParameter.scala:73) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14))
2021-12-03 22:48:03,470 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 7.0 with 21 tasks
2021-12-03 22:48:03,470 [dispatcher-event-loop-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 7.0 (TID 110, localhost, executor driver, partition 0, ANY, 7649 bytes)
2021-12-03 22:48:03,470 [dispatcher-event-loop-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 7.0 (TID 111, localhost, executor driver, partition 1, ANY, 7649 bytes)
2021-12-03 22:48:03,470 [dispatcher-event-loop-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 2.0 in stage 7.0 (TID 112, localhost, executor driver, partition 2, ANY, 7649 bytes)
2021-12-03 22:48:03,471 [dispatcher-event-loop-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 3.0 in stage 7.0 (TID 113, localhost, executor driver, partition 3, ANY, 7649 bytes)
2021-12-03 22:48:03,471 [dispatcher-event-loop-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 4.0 in stage 7.0 (TID 114, localhost, executor driver, partition 4, ANY, 7649 bytes)
2021-12-03 22:48:03,471 [dispatcher-event-loop-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 5.0 in stage 7.0 (TID 115, localhost, executor driver, partition 5, ANY, 7649 bytes)
2021-12-03 22:48:03,471 [dispatcher-event-loop-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 6.0 in stage 7.0 (TID 116, localhost, executor driver, partition 6, ANY, 7649 bytes)
2021-12-03 22:48:03,471 [dispatcher-event-loop-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 7.0 in stage 7.0 (TID 117, localhost, executor driver, partition 7, ANY, 7649 bytes)
2021-12-03 22:48:03,471 [dispatcher-event-loop-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 8.0 in stage 7.0 (TID 118, localhost, executor driver, partition 8, ANY, 7649 bytes)
2021-12-03 22:48:03,471 [dispatcher-event-loop-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 9.0 in stage 7.0 (TID 119, localhost, executor driver, partition 9, ANY, 7649 bytes)
2021-12-03 22:48:03,471 [dispatcher-event-loop-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 10.0 in stage 7.0 (TID 120, localhost, executor driver, partition 10, ANY, 7649 bytes)
2021-12-03 22:48:03,471 [dispatcher-event-loop-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 11.0 in stage 7.0 (TID 121, localhost, executor driver, partition 11, ANY, 7649 bytes)
2021-12-03 22:48:03,471 [Executor task launch worker for task 110] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 7.0 (TID 110)
2021-12-03 22:48:03,471 [Executor task launch worker for task 116] INFO [org.apache.spark.executor.Executor] - Running task 6.0 in stage 7.0 (TID 116)
2021-12-03 22:48:03,471 [Executor task launch worker for task 115] INFO [org.apache.spark.executor.Executor] - Running task 5.0 in stage 7.0 (TID 115)
2021-12-03 22:48:03,471 [Executor task launch worker for task 114] INFO [org.apache.spark.executor.Executor] - Running task 4.0 in stage 7.0 (TID 114)
2021-12-03 22:48:03,471 [Executor task launch worker for task 111] INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 7.0 (TID 111)
2021-12-03 22:48:03,471 [Executor task launch worker for task 113] INFO [org.apache.spark.executor.Executor] - Running task 3.0 in stage 7.0 (TID 113)
2021-12-03 22:48:03,471 [Executor task launch worker for task 112] INFO [org.apache.spark.executor.Executor] - Running task 2.0 in stage 7.0 (TID 112)
2021-12-03 22:48:03,471 [Executor task launch worker for task 120] INFO [org.apache.spark.executor.Executor] - Running task 10.0 in stage 7.0 (TID 120)
2021-12-03 22:48:03,471 [Executor task launch worker for task 121] INFO [org.apache.spark.executor.Executor] - Running task 11.0 in stage 7.0 (TID 121)
2021-12-03 22:48:03,471 [Executor task launch worker for task 118] INFO [org.apache.spark.executor.Executor] - Running task 8.0 in stage 7.0 (TID 118)
2021-12-03 22:48:03,471 [Executor task launch worker for task 117] INFO [org.apache.spark.executor.Executor] - Running task 7.0 in stage 7.0 (TID 117)
2021-12-03 22:48:03,471 [Executor task launch worker for task 119] INFO [org.apache.spark.executor.Executor] - Running task 9.0 in stage 7.0 (TID 119)
2021-12-03 22:48:03,477 [Executor task launch worker for task 113] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 22:48:03,477 [Executor task launch worker for task 110] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 22:48:03,477 [Executor task launch worker for task 113] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 22:48:03,477 [Executor task launch worker for task 110] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 22:48:03,477 [Executor task launch worker for task 117] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 22:48:03,477 [Executor task launch worker for task 117] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 22:48:03,477 [Executor task launch worker for task 118] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 22:48:03,477 [Executor task launch worker for task 118] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 22:48:03,478 [Executor task launch worker for task 121] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 22:48:03,478 [Executor task launch worker for task 121] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 22:48:03,478 [Executor task launch worker for task 120] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 22:48:03,478 [Executor task launch worker for task 120] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 22:48:03,479 [Executor task launch worker for task 119] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 22:48:03,479 [Executor task launch worker for task 119] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 22:48:03,479 [Executor task launch worker for task 111] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 22:48:03,479 [Executor task launch worker for task 111] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 22:48:03,480 [Executor task launch worker for task 115] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 22:48:03,480 [Executor task launch worker for task 115] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 22:48:03,481 [Executor task launch worker for task 114] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 22:48:03,481 [Executor task launch worker for task 114] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 22:48:03,481 [Executor task launch worker for task 112] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 22:48:03,481 [Executor task launch worker for task 112] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 22:48:03,482 [Executor task launch worker for task 116] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 22:48:03,482 [Executor task launch worker for task 116] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 22:48:03,804 [Executor task launch worker for task 110] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 7.0 (TID 110). 1098 bytes result sent to driver
2021-12-03 22:48:03,805 [dispatcher-event-loop-7] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 12.0 in stage 7.0 (TID 122, localhost, executor driver, partition 12, ANY, 7649 bytes)
2021-12-03 22:48:03,806 [Executor task launch worker for task 122] INFO [org.apache.spark.executor.Executor] - Running task 12.0 in stage 7.0 (TID 122)
2021-12-03 22:48:03,806 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 7.0 (TID 110) in 335 ms on localhost (executor driver) (1/21)
2021-12-03 22:48:03,807 [Executor task launch worker for task 116] INFO [org.apache.spark.executor.Executor] - Finished task 6.0 in stage 7.0 (TID 116). 1098 bytes result sent to driver
2021-12-03 22:48:03,808 [dispatcher-event-loop-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 13.0 in stage 7.0 (TID 123, localhost, executor driver, partition 13, ANY, 7649 bytes)
2021-12-03 22:48:03,808 [Executor task launch worker for task 123] INFO [org.apache.spark.executor.Executor] - Running task 13.0 in stage 7.0 (TID 123)
2021-12-03 22:48:03,808 [Executor task launch worker for task 119] INFO [org.apache.spark.executor.Executor] - Finished task 9.0 in stage 7.0 (TID 119). 1098 bytes result sent to driver
2021-12-03 22:48:03,808 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 6.0 in stage 7.0 (TID 116) in 337 ms on localhost (executor driver) (2/21)
2021-12-03 22:48:03,808 [dispatcher-event-loop-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 14.0 in stage 7.0 (TID 124, localhost, executor driver, partition 14, ANY, 7649 bytes)
2021-12-03 22:48:03,808 [Executor task launch worker for task 121] INFO [org.apache.spark.executor.Executor] - Finished task 11.0 in stage 7.0 (TID 121). 1098 bytes result sent to driver
2021-12-03 22:48:03,809 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 9.0 in stage 7.0 (TID 119) in 338 ms on localhost (executor driver) (3/21)
2021-12-03 22:48:03,809 [Executor task launch worker for task 124] INFO [org.apache.spark.executor.Executor] - Running task 14.0 in stage 7.0 (TID 124)
2021-12-03 22:48:03,810 [dispatcher-event-loop-9] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 15.0 in stage 7.0 (TID 125, localhost, executor driver, partition 15, ANY, 7649 bytes)
2021-12-03 22:48:03,810 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 11.0 in stage 7.0 (TID 121) in 339 ms on localhost (executor driver) (4/21)
2021-12-03 22:48:03,810 [Executor task launch worker for task 120] INFO [org.apache.spark.executor.Executor] - Finished task 10.0 in stage 7.0 (TID 120). 1098 bytes result sent to driver
2021-12-03 22:48:03,810 [Executor task launch worker for task 125] INFO [org.apache.spark.executor.Executor] - Running task 15.0 in stage 7.0 (TID 125)
2021-12-03 22:48:03,811 [Executor task launch worker for task 122] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 22:48:03,811 [Executor task launch worker for task 122] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 22:48:03,811 [dispatcher-event-loop-8] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 16.0 in stage 7.0 (TID 126, localhost, executor driver, partition 16, ANY, 7649 bytes)
2021-12-03 22:48:03,811 [Executor task launch worker for task 115] INFO [org.apache.spark.executor.Executor] - Finished task 5.0 in stage 7.0 (TID 115). 1098 bytes result sent to driver
2021-12-03 22:48:03,812 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 10.0 in stage 7.0 (TID 120) in 341 ms on localhost (executor driver) (5/21)
2021-12-03 22:48:03,812 [Executor task launch worker for task 126] INFO [org.apache.spark.executor.Executor] - Running task 16.0 in stage 7.0 (TID 126)
2021-12-03 22:48:03,812 [dispatcher-event-loop-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 17.0 in stage 7.0 (TID 127, localhost, executor driver, partition 17, ANY, 7649 bytes)
2021-12-03 22:48:03,812 [Executor task launch worker for task 127] INFO [org.apache.spark.executor.Executor] - Running task 17.0 in stage 7.0 (TID 127)
2021-12-03 22:48:03,813 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 5.0 in stage 7.0 (TID 115) in 341 ms on localhost (executor driver) (6/21)
2021-12-03 22:48:03,813 [Executor task launch worker for task 123] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 22:48:03,813 [Executor task launch worker for task 123] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 22:48:03,814 [Executor task launch worker for task 124] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 22:48:03,814 [Executor task launch worker for task 124] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 22:48:03,814 [Executor task launch worker for task 125] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 22:48:03,815 [Executor task launch worker for task 125] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 1 ms
2021-12-03 22:48:03,816 [Executor task launch worker for task 114] INFO [org.apache.spark.executor.Executor] - Finished task 4.0 in stage 7.0 (TID 114). 1098 bytes result sent to driver
2021-12-03 22:48:03,816 [Executor task launch worker for task 126] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 22:48:03,816 [Executor task launch worker for task 126] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 22:48:03,816 [Executor task launch worker for task 118] INFO [org.apache.spark.executor.Executor] - Finished task 8.0 in stage 7.0 (TID 118). 1098 bytes result sent to driver
2021-12-03 22:48:03,816 [dispatcher-event-loop-7] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 18.0 in stage 7.0 (TID 128, localhost, executor driver, partition 18, ANY, 7649 bytes)
2021-12-03 22:48:03,816 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 4.0 in stage 7.0 (TID 114) in 345 ms on localhost (executor driver) (7/21)
2021-12-03 22:48:03,816 [Executor task launch worker for task 128] INFO [org.apache.spark.executor.Executor] - Running task 18.0 in stage 7.0 (TID 128)
2021-12-03 22:48:03,817 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 8.0 in stage 7.0 (TID 118) in 345 ms on localhost (executor driver) (8/21)
2021-12-03 22:48:03,817 [Executor task launch worker for task 117] INFO [org.apache.spark.executor.Executor] - Finished task 7.0 in stage 7.0 (TID 117). 1098 bytes result sent to driver
2021-12-03 22:48:03,817 [dispatcher-event-loop-7] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 19.0 in stage 7.0 (TID 129, localhost, executor driver, partition 19, ANY, 7649 bytes)
2021-12-03 22:48:03,818 [Executor task launch worker for task 129] INFO [org.apache.spark.executor.Executor] - Running task 19.0 in stage 7.0 (TID 129)
2021-12-03 22:48:03,818 [dispatcher-event-loop-7] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 20.0 in stage 7.0 (TID 130, localhost, executor driver, partition 20, ANY, 7649 bytes)
2021-12-03 22:48:03,818 [Executor task launch worker for task 130] INFO [org.apache.spark.executor.Executor] - Running task 20.0 in stage 7.0 (TID 130)
2021-12-03 22:48:03,818 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 7.0 in stage 7.0 (TID 117) in 347 ms on localhost (executor driver) (9/21)
2021-12-03 22:48:03,818 [Executor task launch worker for task 113] INFO [org.apache.spark.executor.Executor] - Finished task 3.0 in stage 7.0 (TID 113). 1098 bytes result sent to driver
2021-12-03 22:48:03,819 [Executor task launch worker for task 127] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 22:48:03,819 [Executor task launch worker for task 127] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 22:48:03,819 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 3.0 in stage 7.0 (TID 113) in 349 ms on localhost (executor driver) (10/21)
2021-12-03 22:48:03,820 [Executor task launch worker for task 128] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 22:48:03,820 [Executor task launch worker for task 128] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 22:48:03,821 [Executor task launch worker for task 130] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 22:48:03,821 [Executor task launch worker for task 130] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 22:48:03,823 [Executor task launch worker for task 129] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 22:48:03,823 [Executor task launch worker for task 129] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 22:48:03,827 [Executor task launch worker for task 111] INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 7.0 (TID 111). 1098 bytes result sent to driver
2021-12-03 22:48:03,828 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 7.0 (TID 111) in 358 ms on localhost (executor driver) (11/21)
2021-12-03 22:48:03,829 [Executor task launch worker for task 112] INFO [org.apache.spark.executor.Executor] - Finished task 2.0 in stage 7.0 (TID 112). 1098 bytes result sent to driver
2021-12-03 22:48:03,830 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 2.0 in stage 7.0 (TID 112) in 360 ms on localhost (executor driver) (12/21)
2021-12-03 22:48:03,880 [Executor task launch worker for task 124] INFO [org.apache.spark.executor.Executor] - Finished task 14.0 in stage 7.0 (TID 124). 1098 bytes result sent to driver
2021-12-03 22:48:03,881 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 14.0 in stage 7.0 (TID 124) in 73 ms on localhost (executor driver) (13/21)
2021-12-03 22:48:03,894 [Executor task launch worker for task 126] INFO [org.apache.spark.executor.Executor] - Finished task 16.0 in stage 7.0 (TID 126). 1055 bytes result sent to driver
2021-12-03 22:48:03,894 [Executor task launch worker for task 123] INFO [org.apache.spark.executor.Executor] - Finished task 13.0 in stage 7.0 (TID 123). 1055 bytes result sent to driver
2021-12-03 22:48:03,894 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 16.0 in stage 7.0 (TID 126) in 83 ms on localhost (executor driver) (14/21)
2021-12-03 22:48:03,894 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 13.0 in stage 7.0 (TID 123) in 87 ms on localhost (executor driver) (15/21)
2021-12-03 22:48:03,899 [Executor task launch worker for task 125] INFO [org.apache.spark.executor.Executor] - Finished task 15.0 in stage 7.0 (TID 125). 1098 bytes result sent to driver
2021-12-03 22:48:03,899 [Executor task launch worker for task 128] INFO [org.apache.spark.executor.Executor] - Finished task 18.0 in stage 7.0 (TID 128). 1055 bytes result sent to driver
2021-12-03 22:48:03,900 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 15.0 in stage 7.0 (TID 125) in 91 ms on localhost (executor driver) (16/21)
2021-12-03 22:48:03,900 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 18.0 in stage 7.0 (TID 128) in 84 ms on localhost (executor driver) (17/21)
2021-12-03 22:48:03,905 [Executor task launch worker for task 129] INFO [org.apache.spark.executor.Executor] - Finished task 19.0 in stage 7.0 (TID 129). 1055 bytes result sent to driver
2021-12-03 22:48:03,905 [Executor task launch worker for task 130] INFO [org.apache.spark.executor.Executor] - Finished task 20.0 in stage 7.0 (TID 130). 1055 bytes result sent to driver
2021-12-03 22:48:03,905 [Executor task launch worker for task 122] INFO [org.apache.spark.executor.Executor] - Finished task 12.0 in stage 7.0 (TID 122). 1055 bytes result sent to driver
2021-12-03 22:48:03,905 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 19.0 in stage 7.0 (TID 129) in 88 ms on localhost (executor driver) (18/21)
2021-12-03 22:48:03,905 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 20.0 in stage 7.0 (TID 130) in 88 ms on localhost (executor driver) (19/21)
2021-12-03 22:48:03,905 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 12.0 in stage 7.0 (TID 122) in 100 ms on localhost (executor driver) (20/21)
2021-12-03 22:48:03,911 [Executor task launch worker for task 127] INFO [org.apache.spark.executor.Executor] - Finished task 17.0 in stage 7.0 (TID 127). 1055 bytes result sent to driver
2021-12-03 22:48:03,911 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 17.0 in stage 7.0 (TID 127) in 99 ms on localhost (executor driver) (21/21)
2021-12-03 22:48:03,911 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 7.0, whose tasks have all completed, from pool 
2021-12-03 22:48:03,912 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 7 (zipWithIndex at PaidPromotionAdjustParameter.scala:74) finished in 0.446 s
2021-12-03 22:48:03,912 [main] INFO [org.apache.spark.scheduler.DAGScheduler] - Job 3 finished: zipWithIndex at PaidPromotionAdjustParameter.scala:74, took 1.553374 s
2021-12-03 22:48:03,945 [main] INFO [org.apache.spark.SparkContext] - Starting job: takeSample at PaidPromotionAdjustParameter.scala:77
2021-12-03 22:48:03,946 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 4 (takeSample at PaidPromotionAdjustParameter.scala:77) with 22 output partitions
2021-12-03 22:48:03,946 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 10 (takeSample at PaidPromotionAdjustParameter.scala:77)
2021-12-03 22:48:03,946 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 9)
2021-12-03 22:48:03,946 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2021-12-03 22:48:03,946 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 10 (MapPartitionsRDD[11] at map at PaidPromotionAdjustParameter.scala:76), which has no missing parents
2021-12-03 22:48:03,950 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_7 stored as values in memory (estimated size 4.2 KB, free 1990.4 MB)
2021-12-03 22:48:03,952 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_7_piece0 stored as bytes in memory (estimated size 2.4 KB, free 1990.4 MB)
2021-12-03 22:48:03,952 [dispatcher-event-loop-9] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_7_piece0 in memory on qb:54372 (size: 2.4 KB, free: 1990.8 MB)
2021-12-03 22:48:03,952 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 7 from broadcast at DAGScheduler.scala:1039
2021-12-03 22:48:03,953 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 22 missing tasks from ResultStage 10 (MapPartitionsRDD[11] at map at PaidPromotionAdjustParameter.scala:76) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14))
2021-12-03 22:48:03,953 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 10.0 with 22 tasks
2021-12-03 22:48:03,954 [dispatcher-event-loop-8] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 10.0 (TID 131, localhost, executor driver, partition 0, ANY, 7759 bytes)
2021-12-03 22:48:03,954 [dispatcher-event-loop-8] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 10.0 (TID 132, localhost, executor driver, partition 1, ANY, 7759 bytes)
2021-12-03 22:48:03,954 [dispatcher-event-loop-8] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 2.0 in stage 10.0 (TID 133, localhost, executor driver, partition 2, ANY, 7759 bytes)
2021-12-03 22:48:03,954 [dispatcher-event-loop-8] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 3.0 in stage 10.0 (TID 134, localhost, executor driver, partition 3, ANY, 7759 bytes)
2021-12-03 22:48:03,954 [dispatcher-event-loop-8] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 4.0 in stage 10.0 (TID 135, localhost, executor driver, partition 4, ANY, 7759 bytes)
2021-12-03 22:48:03,954 [dispatcher-event-loop-8] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 5.0 in stage 10.0 (TID 136, localhost, executor driver, partition 5, ANY, 7759 bytes)
2021-12-03 22:48:03,954 [dispatcher-event-loop-8] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 6.0 in stage 10.0 (TID 137, localhost, executor driver, partition 6, ANY, 7759 bytes)
2021-12-03 22:48:03,954 [dispatcher-event-loop-8] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 7.0 in stage 10.0 (TID 138, localhost, executor driver, partition 7, ANY, 7759 bytes)
2021-12-03 22:48:03,954 [dispatcher-event-loop-8] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 8.0 in stage 10.0 (TID 139, localhost, executor driver, partition 8, ANY, 7759 bytes)
2021-12-03 22:48:03,954 [dispatcher-event-loop-8] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 9.0 in stage 10.0 (TID 140, localhost, executor driver, partition 9, ANY, 7759 bytes)
2021-12-03 22:48:03,955 [dispatcher-event-loop-8] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 10.0 in stage 10.0 (TID 141, localhost, executor driver, partition 10, ANY, 7759 bytes)
2021-12-03 22:48:03,955 [dispatcher-event-loop-8] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 11.0 in stage 10.0 (TID 142, localhost, executor driver, partition 11, ANY, 7759 bytes)
2021-12-03 22:48:03,955 [Executor task launch worker for task 132] INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 10.0 (TID 132)
2021-12-03 22:48:03,955 [Executor task launch worker for task 141] INFO [org.apache.spark.executor.Executor] - Running task 10.0 in stage 10.0 (TID 141)
2021-12-03 22:48:03,955 [Executor task launch worker for task 136] INFO [org.apache.spark.executor.Executor] - Running task 5.0 in stage 10.0 (TID 136)
2021-12-03 22:48:03,955 [Executor task launch worker for task 137] INFO [org.apache.spark.executor.Executor] - Running task 6.0 in stage 10.0 (TID 137)
2021-12-03 22:48:03,955 [Executor task launch worker for task 135] INFO [org.apache.spark.executor.Executor] - Running task 4.0 in stage 10.0 (TID 135)
2021-12-03 22:48:03,955 [Executor task launch worker for task 142] INFO [org.apache.spark.executor.Executor] - Running task 11.0 in stage 10.0 (TID 142)
2021-12-03 22:48:03,955 [Executor task launch worker for task 140] INFO [org.apache.spark.executor.Executor] - Running task 9.0 in stage 10.0 (TID 140)
2021-12-03 22:48:03,955 [Executor task launch worker for task 138] INFO [org.apache.spark.executor.Executor] - Running task 7.0 in stage 10.0 (TID 138)
2021-12-03 22:48:03,955 [Executor task launch worker for task 139] INFO [org.apache.spark.executor.Executor] - Running task 8.0 in stage 10.0 (TID 139)
2021-12-03 22:48:03,955 [Executor task launch worker for task 134] INFO [org.apache.spark.executor.Executor] - Running task 3.0 in stage 10.0 (TID 134)
2021-12-03 22:48:03,955 [Executor task launch worker for task 131] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 10.0 (TID 131)
2021-12-03 22:48:03,955 [Executor task launch worker for task 133] INFO [org.apache.spark.executor.Executor] - Running task 2.0 in stage 10.0 (TID 133)
2021-12-03 22:48:03,959 [Executor task launch worker for task 136] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 22:48:03,959 [Executor task launch worker for task 136] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 22:48:03,959 [Executor task launch worker for task 137] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 22:48:03,960 [Executor task launch worker for task 137] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 1 ms
2021-12-03 22:48:03,960 [Executor task launch worker for task 138] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 22:48:03,960 [Executor task launch worker for task 138] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 22:48:03,961 [Executor task launch worker for task 140] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 22:48:03,961 [Executor task launch worker for task 140] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 22:48:03,961 [Executor task launch worker for task 131] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 22:48:03,961 [Executor task launch worker for task 131] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 22:48:03,962 [Executor task launch worker for task 142] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 22:48:03,962 [Executor task launch worker for task 142] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 1 ms
2021-12-03 22:48:03,962 [Executor task launch worker for task 135] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 22:48:03,962 [Executor task launch worker for task 135] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 22:48:03,962 [Executor task launch worker for task 132] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 22:48:03,963 [Executor task launch worker for task 132] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 1 ms
2021-12-03 22:48:03,963 [Executor task launch worker for task 133] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 22:48:03,963 [Executor task launch worker for task 133] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 22:48:03,963 [Executor task launch worker for task 139] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 22:48:03,964 [Executor task launch worker for task 139] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 1 ms
2021-12-03 22:48:03,964 [Executor task launch worker for task 141] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 22:48:03,964 [Executor task launch worker for task 141] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 22:48:03,964 [Executor task launch worker for task 134] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 22:48:03,964 [Executor task launch worker for task 134] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 22:48:04,050 [dispatcher-event-loop-2] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_6_piece0 on qb:54372 in memory (size: 2.0 KB, free: 1990.8 MB)
2021-12-03 22:48:04,129 [Executor task launch worker for task 136] INFO [org.apache.spark.executor.Executor] - Finished task 5.0 in stage 10.0 (TID 136). 1098 bytes result sent to driver
2021-12-03 22:48:04,129 [Executor task launch worker for task 139] INFO [org.apache.spark.executor.Executor] - Finished task 8.0 in stage 10.0 (TID 139). 1098 bytes result sent to driver
2021-12-03 22:48:04,129 [Executor task launch worker for task 131] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 10.0 (TID 131). 1096 bytes result sent to driver
2021-12-03 22:48:04,129 [dispatcher-event-loop-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 12.0 in stage 10.0 (TID 143, localhost, executor driver, partition 12, ANY, 7759 bytes)
2021-12-03 22:48:04,129 [Executor task launch worker for task 135] INFO [org.apache.spark.executor.Executor] - Finished task 4.0 in stage 10.0 (TID 135). 1098 bytes result sent to driver
2021-12-03 22:48:04,129 [Executor task launch worker for task 143] INFO [org.apache.spark.executor.Executor] - Running task 12.0 in stage 10.0 (TID 143)
2021-12-03 22:48:04,129 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 5.0 in stage 10.0 (TID 136) in 175 ms on localhost (executor driver) (1/22)
2021-12-03 22:48:04,129 [dispatcher-event-loop-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 13.0 in stage 10.0 (TID 144, localhost, executor driver, partition 13, ANY, 7759 bytes)
2021-12-03 22:48:04,130 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 8.0 in stage 10.0 (TID 139) in 176 ms on localhost (executor driver) (2/22)
2021-12-03 22:48:04,130 [Executor task launch worker for task 144] INFO [org.apache.spark.executor.Executor] - Running task 13.0 in stage 10.0 (TID 144)
2021-12-03 22:48:04,130 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 10.0 (TID 131) in 177 ms on localhost (executor driver) (3/22)
2021-12-03 22:48:04,133 [Executor task launch worker for task 140] INFO [org.apache.spark.executor.Executor] - Finished task 9.0 in stage 10.0 (TID 140). 1098 bytes result sent to driver
2021-12-03 22:48:04,133 [Executor task launch worker for task 143] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 22:48:04,133 [Executor task launch worker for task 143] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 22:48:04,133 [dispatcher-event-loop-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 14.0 in stage 10.0 (TID 145, localhost, executor driver, partition 14, ANY, 7759 bytes)
2021-12-03 22:48:04,134 [dispatcher-event-loop-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 15.0 in stage 10.0 (TID 146, localhost, executor driver, partition 15, ANY, 7759 bytes)
2021-12-03 22:48:04,134 [Executor task launch worker for task 146] INFO [org.apache.spark.executor.Executor] - Running task 15.0 in stage 10.0 (TID 146)
2021-12-03 22:48:04,134 [dispatcher-event-loop-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 16.0 in stage 10.0 (TID 147, localhost, executor driver, partition 16, ANY, 7759 bytes)
2021-12-03 22:48:04,134 [Executor task launch worker for task 147] INFO [org.apache.spark.executor.Executor] - Running task 16.0 in stage 10.0 (TID 147)
2021-12-03 22:48:04,137 [Executor task launch worker for task 145] INFO [org.apache.spark.executor.Executor] - Running task 14.0 in stage 10.0 (TID 145)
2021-12-03 22:48:04,137 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 4.0 in stage 10.0 (TID 135) in 183 ms on localhost (executor driver) (4/22)
2021-12-03 22:48:04,137 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 9.0 in stage 10.0 (TID 140) in 183 ms on localhost (executor driver) (5/22)
2021-12-03 22:48:04,138 [Executor task launch worker for task 146] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 22:48:04,138 [Executor task launch worker for task 146] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 22:48:04,139 [Executor task launch worker for task 144] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 22:48:04,139 [Executor task launch worker for task 147] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 22:48:04,139 [Executor task launch worker for task 147] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 22:48:04,139 [Executor task launch worker for task 144] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 22:48:04,140 [Executor task launch worker for task 145] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 22:48:04,140 [Executor task launch worker for task 145] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 22:48:04,155 [Executor task launch worker for task 137] INFO [org.apache.spark.executor.Executor] - Finished task 6.0 in stage 10.0 (TID 137). 1098 bytes result sent to driver
2021-12-03 22:48:04,155 [dispatcher-event-loop-4] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 17.0 in stage 10.0 (TID 148, localhost, executor driver, partition 17, ANY, 7759 bytes)
2021-12-03 22:48:04,155 [Executor task launch worker for task 148] INFO [org.apache.spark.executor.Executor] - Running task 17.0 in stage 10.0 (TID 148)
2021-12-03 22:48:04,155 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 6.0 in stage 10.0 (TID 137) in 201 ms on localhost (executor driver) (6/22)
2021-12-03 22:48:04,159 [Executor task launch worker for task 141] INFO [org.apache.spark.executor.Executor] - Finished task 10.0 in stage 10.0 (TID 141). 1098 bytes result sent to driver
2021-12-03 22:48:04,160 [Executor task launch worker for task 138] INFO [org.apache.spark.executor.Executor] - Finished task 7.0 in stage 10.0 (TID 138). 1098 bytes result sent to driver
2021-12-03 22:48:04,160 [Executor task launch worker for task 148] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 22:48:04,160 [Executor task launch worker for task 148] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 22:48:04,161 [dispatcher-event-loop-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 18.0 in stage 10.0 (TID 149, localhost, executor driver, partition 18, ANY, 7759 bytes)
2021-12-03 22:48:04,161 [dispatcher-event-loop-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 19.0 in stage 10.0 (TID 150, localhost, executor driver, partition 19, ANY, 7759 bytes)
2021-12-03 22:48:04,162 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 10.0 in stage 10.0 (TID 141) in 207 ms on localhost (executor driver) (7/22)
2021-12-03 22:48:04,162 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 7.0 in stage 10.0 (TID 138) in 208 ms on localhost (executor driver) (8/22)
2021-12-03 22:48:04,162 [Executor task launch worker for task 149] INFO [org.apache.spark.executor.Executor] - Running task 18.0 in stage 10.0 (TID 149)
2021-12-03 22:48:04,164 [Executor task launch worker for task 150] INFO [org.apache.spark.executor.Executor] - Running task 19.0 in stage 10.0 (TID 150)
2021-12-03 22:48:04,164 [Executor task launch worker for task 142] INFO [org.apache.spark.executor.Executor] - Finished task 11.0 in stage 10.0 (TID 142). 1098 bytes result sent to driver
2021-12-03 22:48:04,166 [dispatcher-event-loop-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 20.0 in stage 10.0 (TID 151, localhost, executor driver, partition 20, ANY, 7759 bytes)
2021-12-03 22:48:04,167 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 11.0 in stage 10.0 (TID 142) in 212 ms on localhost (executor driver) (9/22)
2021-12-03 22:48:04,167 [Executor task launch worker for task 151] INFO [org.apache.spark.executor.Executor] - Running task 20.0 in stage 10.0 (TID 151)
2021-12-03 22:48:04,169 [Executor task launch worker for task 150] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 22:48:04,169 [Executor task launch worker for task 150] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 22:48:04,170 [Executor task launch worker for task 151] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 22:48:04,170 [Executor task launch worker for task 151] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 22:48:04,171 [Executor task launch worker for task 149] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 22:48:04,171 [Executor task launch worker for task 149] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 22:48:04,192 [Executor task launch worker for task 134] INFO [org.apache.spark.executor.Executor] - Finished task 3.0 in stage 10.0 (TID 134). 1098 bytes result sent to driver
2021-12-03 22:48:04,192 [dispatcher-event-loop-7] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 21.0 in stage 10.0 (TID 152, localhost, executor driver, partition 21, ANY, 7759 bytes)
2021-12-03 22:48:04,192 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 3.0 in stage 10.0 (TID 134) in 238 ms on localhost (executor driver) (10/22)
2021-12-03 22:48:04,192 [Executor task launch worker for task 152] INFO [org.apache.spark.executor.Executor] - Running task 21.0 in stage 10.0 (TID 152)
2021-12-03 22:48:04,195 [Executor task launch worker for task 133] INFO [org.apache.spark.executor.Executor] - Finished task 2.0 in stage 10.0 (TID 133). 1098 bytes result sent to driver
2021-12-03 22:48:04,196 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 2.0 in stage 10.0 (TID 133) in 242 ms on localhost (executor driver) (11/22)
2021-12-03 22:48:04,196 [Executor task launch worker for task 152] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 22:48:04,196 [Executor task launch worker for task 152] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 22:48:04,207 [Executor task launch worker for task 132] INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 10.0 (TID 132). 1096 bytes result sent to driver
2021-12-03 22:48:04,211 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 10.0 (TID 132) in 257 ms on localhost (executor driver) (12/22)
2021-12-03 22:48:04,218 [Executor task launch worker for task 147] INFO [org.apache.spark.executor.Executor] - Finished task 16.0 in stage 10.0 (TID 147). 1098 bytes result sent to driver
2021-12-03 22:48:04,218 [Executor task launch worker for task 145] INFO [org.apache.spark.executor.Executor] - Finished task 14.0 in stage 10.0 (TID 145). 1098 bytes result sent to driver
2021-12-03 22:48:04,218 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 16.0 in stage 10.0 (TID 147) in 84 ms on localhost (executor driver) (13/22)
2021-12-03 22:48:04,218 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 14.0 in stage 10.0 (TID 145) in 85 ms on localhost (executor driver) (14/22)
2021-12-03 22:48:04,231 [Executor task launch worker for task 146] INFO [org.apache.spark.executor.Executor] - Finished task 15.0 in stage 10.0 (TID 146). 1055 bytes result sent to driver
2021-12-03 22:48:04,232 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 15.0 in stage 10.0 (TID 146) in 98 ms on localhost (executor driver) (15/22)
2021-12-03 22:48:04,241 [Executor task launch worker for task 144] INFO [org.apache.spark.executor.Executor] - Finished task 13.0 in stage 10.0 (TID 144). 1098 bytes result sent to driver
2021-12-03 22:48:04,241 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 13.0 in stage 10.0 (TID 144) in 112 ms on localhost (executor driver) (16/22)
2021-12-03 22:48:04,243 [Executor task launch worker for task 143] INFO [org.apache.spark.executor.Executor] - Finished task 12.0 in stage 10.0 (TID 143). 1055 bytes result sent to driver
2021-12-03 22:48:04,244 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 12.0 in stage 10.0 (TID 143) in 114 ms on localhost (executor driver) (17/22)
2021-12-03 22:48:04,258 [Executor task launch worker for task 149] INFO [org.apache.spark.executor.Executor] - Finished task 18.0 in stage 10.0 (TID 149). 1055 bytes result sent to driver
2021-12-03 22:48:04,258 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 18.0 in stage 10.0 (TID 149) in 98 ms on localhost (executor driver) (18/22)
2021-12-03 22:48:04,263 [Executor task launch worker for task 150] INFO [org.apache.spark.executor.Executor] - Finished task 19.0 in stage 10.0 (TID 150). 1055 bytes result sent to driver
2021-12-03 22:48:04,263 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 19.0 in stage 10.0 (TID 150) in 102 ms on localhost (executor driver) (19/22)
2021-12-03 22:48:04,265 [Executor task launch worker for task 151] INFO [org.apache.spark.executor.Executor] - Finished task 20.0 in stage 10.0 (TID 151). 1053 bytes result sent to driver
2021-12-03 22:48:04,265 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 20.0 in stage 10.0 (TID 151) in 99 ms on localhost (executor driver) (20/22)
2021-12-03 22:48:04,267 [Executor task launch worker for task 148] INFO [org.apache.spark.executor.Executor] - Finished task 17.0 in stage 10.0 (TID 148). 1055 bytes result sent to driver
2021-12-03 22:48:04,267 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 17.0 in stage 10.0 (TID 148) in 112 ms on localhost (executor driver) (21/22)
2021-12-03 22:48:04,275 [Executor task launch worker for task 152] INFO [org.apache.spark.executor.Executor] - Finished task 21.0 in stage 10.0 (TID 152). 1053 bytes result sent to driver
2021-12-03 22:48:04,275 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 21.0 in stage 10.0 (TID 152) in 83 ms on localhost (executor driver) (22/22)
2021-12-03 22:48:04,275 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 10.0, whose tasks have all completed, from pool 
2021-12-03 22:48:04,275 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 10 (takeSample at PaidPromotionAdjustParameter.scala:77) finished in 0.328 s
2021-12-03 22:48:04,276 [main] INFO [org.apache.spark.scheduler.DAGScheduler] - Job 4 finished: takeSample at PaidPromotionAdjustParameter.scala:77, took 0.330310 s
2021-12-03 22:48:04,293 [main] INFO [org.apache.spark.SparkContext] - Starting job: takeSample at PaidPromotionAdjustParameter.scala:77
2021-12-03 22:48:04,293 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 5 (takeSample at PaidPromotionAdjustParameter.scala:77) with 22 output partitions
2021-12-03 22:48:04,293 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 13 (takeSample at PaidPromotionAdjustParameter.scala:77)
2021-12-03 22:48:04,293 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 12)
2021-12-03 22:48:04,294 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2021-12-03 22:48:04,294 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 13 (PartitionwiseSampledRDD[12] at takeSample at PaidPromotionAdjustParameter.scala:77), which has no missing parents
2021-12-03 22:48:04,298 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_8 stored as values in memory (estimated size 4.9 KB, free 1990.4 MB)
2021-12-03 22:48:04,300 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_8_piece0 stored as bytes in memory (estimated size 2.8 KB, free 1990.4 MB)
2021-12-03 22:48:04,300 [dispatcher-event-loop-2] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_8_piece0 in memory on qb:54372 (size: 2.8 KB, free: 1990.8 MB)
2021-12-03 22:48:04,301 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 8 from broadcast at DAGScheduler.scala:1039
2021-12-03 22:48:04,301 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 22 missing tasks from ResultStage 13 (PartitionwiseSampledRDD[12] at takeSample at PaidPromotionAdjustParameter.scala:77) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14))
2021-12-03 22:48:04,302 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 13.0 with 22 tasks
2021-12-03 22:48:04,303 [dispatcher-event-loop-4] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 13.0 (TID 153, localhost, executor driver, partition 0, ANY, 7868 bytes)
2021-12-03 22:48:04,304 [dispatcher-event-loop-4] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 13.0 (TID 154, localhost, executor driver, partition 1, ANY, 7868 bytes)
2021-12-03 22:48:04,304 [dispatcher-event-loop-4] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 2.0 in stage 13.0 (TID 155, localhost, executor driver, partition 2, ANY, 7868 bytes)
2021-12-03 22:48:04,304 [dispatcher-event-loop-4] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 3.0 in stage 13.0 (TID 156, localhost, executor driver, partition 3, ANY, 7868 bytes)
2021-12-03 22:48:04,304 [dispatcher-event-loop-4] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 4.0 in stage 13.0 (TID 157, localhost, executor driver, partition 4, ANY, 7868 bytes)
2021-12-03 22:48:04,304 [dispatcher-event-loop-4] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 5.0 in stage 13.0 (TID 158, localhost, executor driver, partition 5, ANY, 7868 bytes)
2021-12-03 22:48:04,304 [dispatcher-event-loop-4] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 6.0 in stage 13.0 (TID 159, localhost, executor driver, partition 6, ANY, 7868 bytes)
2021-12-03 22:48:04,304 [dispatcher-event-loop-4] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 7.0 in stage 13.0 (TID 160, localhost, executor driver, partition 7, ANY, 7868 bytes)
2021-12-03 22:48:04,304 [dispatcher-event-loop-4] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 8.0 in stage 13.0 (TID 161, localhost, executor driver, partition 8, ANY, 7868 bytes)
2021-12-03 22:48:04,304 [dispatcher-event-loop-4] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 9.0 in stage 13.0 (TID 162, localhost, executor driver, partition 9, ANY, 7868 bytes)
2021-12-03 22:48:04,304 [dispatcher-event-loop-4] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 10.0 in stage 13.0 (TID 163, localhost, executor driver, partition 10, ANY, 7868 bytes)
2021-12-03 22:48:04,305 [dispatcher-event-loop-4] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 11.0 in stage 13.0 (TID 164, localhost, executor driver, partition 11, ANY, 7868 bytes)
2021-12-03 22:48:04,305 [Executor task launch worker for task 153] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 13.0 (TID 153)
2021-12-03 22:48:04,305 [Executor task launch worker for task 154] INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 13.0 (TID 154)
2021-12-03 22:48:04,305 [Executor task launch worker for task 161] INFO [org.apache.spark.executor.Executor] - Running task 8.0 in stage 13.0 (TID 161)
2021-12-03 22:48:04,305 [Executor task launch worker for task 160] INFO [org.apache.spark.executor.Executor] - Running task 7.0 in stage 13.0 (TID 160)
2021-12-03 22:48:04,305 [Executor task launch worker for task 155] INFO [org.apache.spark.executor.Executor] - Running task 2.0 in stage 13.0 (TID 155)
2021-12-03 22:48:04,305 [Executor task launch worker for task 156] INFO [org.apache.spark.executor.Executor] - Running task 3.0 in stage 13.0 (TID 156)
2021-12-03 22:48:04,305 [Executor task launch worker for task 157] INFO [org.apache.spark.executor.Executor] - Running task 4.0 in stage 13.0 (TID 157)
2021-12-03 22:48:04,305 [Executor task launch worker for task 158] INFO [org.apache.spark.executor.Executor] - Running task 5.0 in stage 13.0 (TID 158)
2021-12-03 22:48:04,305 [Executor task launch worker for task 163] INFO [org.apache.spark.executor.Executor] - Running task 10.0 in stage 13.0 (TID 163)
2021-12-03 22:48:04,305 [Executor task launch worker for task 164] INFO [org.apache.spark.executor.Executor] - Running task 11.0 in stage 13.0 (TID 164)
2021-12-03 22:48:04,305 [Executor task launch worker for task 159] INFO [org.apache.spark.executor.Executor] - Running task 6.0 in stage 13.0 (TID 159)
2021-12-03 22:48:04,305 [Executor task launch worker for task 162] INFO [org.apache.spark.executor.Executor] - Running task 9.0 in stage 13.0 (TID 162)
2021-12-03 22:48:04,310 [Executor task launch worker for task 160] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 22:48:04,310 [Executor task launch worker for task 164] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 22:48:04,310 [Executor task launch worker for task 160] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 22:48:04,310 [Executor task launch worker for task 164] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 22:48:04,310 [Executor task launch worker for task 154] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 22:48:04,310 [Executor task launch worker for task 154] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 22:48:04,310 [Executor task launch worker for task 153] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 22:48:04,310 [Executor task launch worker for task 153] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 22:48:04,311 [Executor task launch worker for task 155] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 22:48:04,311 [Executor task launch worker for task 155] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 22:48:04,311 [Executor task launch worker for task 157] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 22:48:04,311 [Executor task launch worker for task 157] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 22:48:04,312 [Executor task launch worker for task 156] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 22:48:04,312 [Executor task launch worker for task 156] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 22:48:04,312 [Executor task launch worker for task 161] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 22:48:04,312 [Executor task launch worker for task 161] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 22:48:04,313 [Executor task launch worker for task 162] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 22:48:04,313 [Executor task launch worker for task 162] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 22:48:04,314 [Executor task launch worker for task 159] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 22:48:04,314 [Executor task launch worker for task 159] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 22:48:04,314 [Executor task launch worker for task 158] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 22:48:04,314 [Executor task launch worker for task 158] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 22:48:04,315 [Executor task launch worker for task 163] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 22:48:04,315 [Executor task launch worker for task 163] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 22:48:04,367 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 172
2021-12-03 22:48:04,367 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 160
2021-12-03 22:48:04,367 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 165
2021-12-03 22:48:04,367 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 152
2021-12-03 22:48:04,367 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 153
2021-12-03 22:48:04,367 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 157
2021-12-03 22:48:04,367 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 151
2021-12-03 22:48:04,367 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 155
2021-12-03 22:48:04,367 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 156
2021-12-03 22:48:04,368 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 161
2021-12-03 22:48:04,368 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 154
2021-12-03 22:48:04,368 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 162
2021-12-03 22:48:04,368 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 166
2021-12-03 22:48:04,368 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 150
2021-12-03 22:48:04,368 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 158
2021-12-03 22:48:04,368 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 163
2021-12-03 22:48:04,368 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 174
2021-12-03 22:48:04,374 [dispatcher-event-loop-5] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_7_piece0 on qb:54372 in memory (size: 2.4 KB, free: 1990.8 MB)
2021-12-03 22:48:04,375 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 173
2021-12-03 22:48:04,375 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 170
2021-12-03 22:48:04,375 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 167
2021-12-03 22:48:04,375 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 169
2021-12-03 22:48:04,375 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 164
2021-12-03 22:48:04,375 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 168
2021-12-03 22:48:04,375 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 171
2021-12-03 22:48:04,375 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 159
2021-12-03 22:48:04,440 [Executor task launch worker for task 153] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 13.0 (TID 153). 1097 bytes result sent to driver
2021-12-03 22:48:04,441 [dispatcher-event-loop-10] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 12.0 in stage 13.0 (TID 165, localhost, executor driver, partition 12, ANY, 7868 bytes)
2021-12-03 22:48:04,441 [Executor task launch worker for task 165] INFO [org.apache.spark.executor.Executor] - Running task 12.0 in stage 13.0 (TID 165)
2021-12-03 22:48:04,442 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 13.0 (TID 153) in 140 ms on localhost (executor driver) (1/22)
2021-12-03 22:48:04,447 [Executor task launch worker for task 165] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 22:48:04,447 [Executor task launch worker for task 165] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 22:48:04,471 [Executor task launch worker for task 158] INFO [org.apache.spark.executor.Executor] - Finished task 5.0 in stage 13.0 (TID 158). 768921 bytes result sent to driver
2021-12-03 22:48:04,471 [dispatcher-event-loop-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 13.0 in stage 13.0 (TID 166, localhost, executor driver, partition 13, ANY, 7868 bytes)
2021-12-03 22:48:04,471 [Executor task launch worker for task 166] INFO [org.apache.spark.executor.Executor] - Running task 13.0 in stage 13.0 (TID 166)
2021-12-03 22:48:04,475 [Executor task launch worker for task 166] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 22:48:04,475 [Executor task launch worker for task 166] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 22:48:04,479 [Executor task launch worker for task 154] INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 13.0 (TID 154). 1097 bytes result sent to driver
2021-12-03 22:48:04,480 [Executor task launch worker for task 162] INFO [org.apache.spark.executor.Executor] - Finished task 9.0 in stage 13.0 (TID 162). 826489 bytes result sent to driver
2021-12-03 22:48:04,480 [dispatcher-event-loop-7] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 14.0 in stage 13.0 (TID 167, localhost, executor driver, partition 14, ANY, 7868 bytes)
2021-12-03 22:48:04,481 [Executor task launch worker for task 167] INFO [org.apache.spark.executor.Executor] - Running task 14.0 in stage 13.0 (TID 167)
2021-12-03 22:48:04,481 [dispatcher-event-loop-7] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 15.0 in stage 13.0 (TID 168, localhost, executor driver, partition 15, ANY, 7868 bytes)
2021-12-03 22:48:04,481 [Executor task launch worker for task 168] INFO [org.apache.spark.executor.Executor] - Running task 15.0 in stage 13.0 (TID 168)
2021-12-03 22:48:04,481 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 13.0 (TID 154) in 177 ms on localhost (executor driver) (2/22)
2021-12-03 22:48:04,482 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 5.0 in stage 13.0 (TID 158) in 178 ms on localhost (executor driver) (3/22)
2021-12-03 22:48:04,485 [Executor task launch worker for task 168] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 22:48:04,485 [Executor task launch worker for task 168] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 22:48:04,486 [Executor task launch worker for task 167] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 22:48:04,486 [Executor task launch worker for task 167] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 22:48:04,492 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 9.0 in stage 13.0 (TID 162) in 187 ms on localhost (executor driver) (4/22)
2021-12-03 22:48:04,497 [Executor task launch worker for task 157] INFO [org.apache.spark.executor.Executor] - Finished task 4.0 in stage 13.0 (TID 157). 975714 bytes result sent to driver
2021-12-03 22:48:04,498 [dispatcher-event-loop-4] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 16.0 in stage 13.0 (TID 169, localhost, executor driver, partition 16, ANY, 7868 bytes)
2021-12-03 22:48:04,509 [Executor task launch worker for task 155] INFO [org.apache.spark.executor.Executor] - Finished task 2.0 in stage 13.0 (TID 155). 607094 bytes result sent to driver
2021-12-03 22:48:04,509 [Executor task launch worker for task 160] INFO [org.apache.spark.storage.memory.MemoryStore] - Block taskresult_160 stored as bytes in memory (estimated size 1221.2 KB, free 1984.2 MB)
2021-12-03 22:48:04,510 [Executor task launch worker for task 169] INFO [org.apache.spark.executor.Executor] - Running task 16.0 in stage 13.0 (TID 169)
2021-12-03 22:48:04,513 [dispatcher-event-loop-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 17.0 in stage 13.0 (TID 170, localhost, executor driver, partition 17, ANY, 7868 bytes)
2021-12-03 22:48:04,514 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 4.0 in stage 13.0 (TID 157) in 210 ms on localhost (executor driver) (5/22)
2021-12-03 22:48:04,514 [Executor task launch worker for task 169] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 22:48:04,514 [Executor task launch worker for task 170] INFO [org.apache.spark.executor.Executor] - Running task 17.0 in stage 13.0 (TID 170)
2021-12-03 22:48:04,514 [Executor task launch worker for task 169] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 22:48:04,514 [dispatcher-event-loop-6] INFO [org.apache.spark.storage.BlockManagerInfo] - Added taskresult_160 in memory on qb:54372 (size: 1221.2 KB, free: 1989.6 MB)
2021-12-03 22:48:04,515 [Executor task launch worker for task 160] INFO [org.apache.spark.executor.Executor] - Finished task 7.0 in stage 13.0 (TID 160). 1250487 bytes result sent via BlockManager)
2021-12-03 22:48:04,518 [dispatcher-event-loop-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 18.0 in stage 13.0 (TID 171, localhost, executor driver, partition 18, ANY, 7868 bytes)
2021-12-03 22:48:04,518 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 2.0 in stage 13.0 (TID 155) in 214 ms on localhost (executor driver) (6/22)
2021-12-03 22:48:04,518 [Executor task launch worker for task 171] INFO [org.apache.spark.executor.Executor] - Running task 18.0 in stage 13.0 (TID 171)
2021-12-03 22:48:04,518 [Executor task launch worker for task 170] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 22:48:04,518 [Executor task launch worker for task 170] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 22:48:04,523 [Executor task launch worker for task 171] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 22:48:04,523 [Executor task launch worker for task 171] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 22:48:04,529 [Executor task launch worker for task 163] INFO [org.apache.spark.executor.Executor] - Finished task 10.0 in stage 13.0 (TID 163). 935688 bytes result sent to driver
2021-12-03 22:48:04,530 [dispatcher-event-loop-8] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 19.0 in stage 13.0 (TID 172, localhost, executor driver, partition 19, ANY, 7868 bytes)
2021-12-03 22:48:04,530 [Executor task launch worker for task 172] INFO [org.apache.spark.executor.Executor] - Running task 19.0 in stage 13.0 (TID 172)
2021-12-03 22:48:04,534 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 10.0 in stage 13.0 (TID 163) in 230 ms on localhost (executor driver) (7/22)
2021-12-03 22:48:04,546 [Executor task launch worker for task 161] INFO [org.apache.spark.executor.Executor] - Finished task 8.0 in stage 13.0 (TID 161). 1028650 bytes result sent to driver
2021-12-03 22:48:04,546 [dispatcher-event-loop-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 20.0 in stage 13.0 (TID 173, localhost, executor driver, partition 20, ANY, 7868 bytes)
2021-12-03 22:48:04,547 [Executor task launch worker for task 164] INFO [org.apache.spark.executor.Executor] - Finished task 11.0 in stage 13.0 (TID 164). 844265 bytes result sent to driver
2021-12-03 22:48:04,547 [dispatcher-event-loop-11] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 21.0 in stage 13.0 (TID 174, localhost, executor driver, partition 21, ANY, 7868 bytes)
2021-12-03 22:48:04,551 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 8.0 in stage 13.0 (TID 161) in 247 ms on localhost (executor driver) (8/22)
2021-12-03 22:48:04,552 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 11.0 in stage 13.0 (TID 164) in 247 ms on localhost (executor driver) (9/22)
2021-12-03 22:48:04,552 [Executor task launch worker for task 173] INFO [org.apache.spark.executor.Executor] - Running task 20.0 in stage 13.0 (TID 173)
2021-12-03 22:48:04,555 [Executor task launch worker for task 174] INFO [org.apache.spark.executor.Executor] - Running task 21.0 in stage 13.0 (TID 174)
2021-12-03 22:48:04,556 [Executor task launch worker for task 159] INFO [org.apache.spark.executor.Executor] - Finished task 6.0 in stage 13.0 (TID 159). 1020251 bytes result sent to driver
2021-12-03 22:48:04,561 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 6.0 in stage 13.0 (TID 159) in 257 ms on localhost (executor driver) (10/22)
2021-12-03 22:48:04,562 [Executor task launch worker for task 172] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 22:48:04,562 [Executor task launch worker for task 172] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 22:48:04,563 [Executor task launch worker for task 173] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 22:48:04,563 [Executor task launch worker for task 173] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 22:48:04,564 [Executor task launch worker for task 174] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 22:48:04,564 [Executor task launch worker for task 174] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 1 ms
2021-12-03 22:48:04,580 [Executor task launch worker for task 167] INFO [org.apache.spark.executor.Executor] - Finished task 14.0 in stage 13.0 (TID 167). 604477 bytes result sent to driver
2021-12-03 22:48:04,589 [Executor task launch worker for task 156] INFO [org.apache.spark.executor.Executor] - Finished task 3.0 in stage 13.0 (TID 156). 996518 bytes result sent to driver
2021-12-03 22:48:04,591 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 14.0 in stage 13.0 (TID 167) in 111 ms on localhost (executor driver) (11/22)
2021-12-03 22:48:04,601 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 3.0 in stage 13.0 (TID 156) in 297 ms on localhost (executor driver) (12/22)
2021-12-03 22:48:04,620 [Executor task launch worker for task 165] INFO [org.apache.spark.storage.memory.MemoryStore] - Block taskresult_165 stored as bytes in memory (estimated size 1168.1 KB, free 1973.0 MB)
2021-12-03 22:48:04,620 [dispatcher-event-loop-1] INFO [org.apache.spark.storage.BlockManagerInfo] - Added taskresult_165 in memory on qb:54372 (size: 1168.1 KB, free: 1988.4 MB)
2021-12-03 22:48:04,621 [Executor task launch worker for task 165] INFO [org.apache.spark.executor.Executor] - Finished task 12.0 in stage 13.0 (TID 165). 1196095 bytes result sent via BlockManager)
2021-12-03 22:48:04,622 [Executor task launch worker for task 168] INFO [org.apache.spark.executor.Executor] - Finished task 15.0 in stage 13.0 (TID 168). 1003536 bytes result sent to driver
2021-12-03 22:48:04,629 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 15.0 in stage 13.0 (TID 168) in 148 ms on localhost (executor driver) (13/22)
2021-12-03 22:48:04,630 [task-result-getter-0] INFO [org.apache.spark.network.client.TransportClientFactory] - Successfully created connection to qb/192.168.2.180:54372 after 85 ms (0 ms spent in bootstraps)
2021-12-03 22:48:04,637 [Executor task launch worker for task 166] INFO [org.apache.spark.storage.memory.MemoryStore] - Block taskresult_166 stored as bytes in memory (estimated size 1073.7 KB, free 1977.0 MB)
2021-12-03 22:48:04,638 [dispatcher-event-loop-7] INFO [org.apache.spark.storage.BlockManagerInfo] - Added taskresult_166 in memory on qb:54372 (size: 1073.7 KB, free: 1987.4 MB)
2021-12-03 22:48:04,638 [Executor task launch worker for task 166] INFO [org.apache.spark.executor.Executor] - Finished task 13.0 in stage 13.0 (TID 166). 1099430 bytes result sent via BlockManager)
2021-12-03 22:48:04,643 [Executor task launch worker for task 171] INFO [org.apache.spark.executor.Executor] - Finished task 18.0 in stage 13.0 (TID 171). 963734 bytes result sent to driver
2021-12-03 22:48:04,646 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 18.0 in stage 13.0 (TID 171) in 129 ms on localhost (executor driver) (14/22)
2021-12-03 22:48:04,652 [Executor task launch worker for task 169] INFO [org.apache.spark.executor.Executor] - Finished task 16.0 in stage 13.0 (TID 169). 760223 bytes result sent to driver
2021-12-03 22:48:04,656 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 16.0 in stage 13.0 (TID 169) in 158 ms on localhost (executor driver) (15/22)
2021-12-03 22:48:04,823 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 145
2021-12-03 22:48:04,823 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 122
2021-12-03 22:48:04,823 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 102
2021-12-03 22:48:04,823 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 62
2021-12-03 22:48:04,824 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 100
2021-12-03 22:48:04,824 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 65
2021-12-03 22:48:04,824 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 25
2021-12-03 22:48:04,824 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 57
2021-12-03 22:48:04,824 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 50
2021-12-03 22:48:04,824 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 128
2021-12-03 22:48:04,824 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 101
2021-12-03 22:48:04,824 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 146
2021-12-03 22:48:04,824 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 103
2021-12-03 22:48:04,824 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 38
2021-12-03 22:48:04,824 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 27
2021-12-03 22:48:04,824 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 47
2021-12-03 22:48:04,824 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 68
2021-12-03 22:48:04,824 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 118
2021-12-03 22:48:04,824 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 71
2021-12-03 22:48:04,824 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 36
2021-12-03 22:48:04,824 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 34
2021-12-03 22:48:04,824 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 35
2021-12-03 22:48:04,824 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 121
2021-12-03 22:48:04,824 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 60
2021-12-03 22:48:04,825 [dispatcher-event-loop-6] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_5_piece0 on qb:54372 in memory (size: 2.4 KB, free: 1987.4 MB)
2021-12-03 22:48:04,825 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 136
2021-12-03 22:48:04,825 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 112
2021-12-03 22:48:04,825 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 109
2021-12-03 22:48:04,825 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 56
2021-12-03 22:48:04,826 [dispatcher-event-loop-3] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_3_piece0 on qb:54372 in memory (size: 1906.0 B, free: 1987.4 MB)
2021-12-03 22:48:04,826 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 66
2021-12-03 22:48:04,826 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 105
2021-12-03 22:48:04,826 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 26
2021-12-03 22:48:04,826 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 58
2021-12-03 22:48:04,826 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 143
2021-12-03 22:48:04,826 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 124
2021-12-03 22:48:04,826 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 28
2021-12-03 22:48:04,826 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 149
2021-12-03 22:48:04,826 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 140
2021-12-03 22:48:04,826 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 132
2021-12-03 22:48:04,826 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 123
2021-12-03 22:48:04,826 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 114
2021-12-03 22:48:04,826 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 67
2021-12-03 22:48:04,826 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 64
2021-12-03 22:48:04,826 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 70
2021-12-03 22:48:04,827 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 129
2021-12-03 22:48:04,827 [dispatcher-event-loop-2] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_2_piece0 on qb:54372 in memory (size: 2.7 KB, free: 1987.4 MB)
2021-12-03 22:48:04,827 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 48
2021-12-03 22:48:04,828 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 139
2021-12-03 22:48:04,828 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 116
2021-12-03 22:48:04,828 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 141
2021-12-03 22:48:04,828 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 33
2021-12-03 22:48:04,828 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 133
2021-12-03 22:48:04,828 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 107
2021-12-03 22:48:04,828 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 120
2021-12-03 22:48:04,828 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 45
2021-12-03 22:48:04,828 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 131
2021-12-03 22:48:04,828 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 119
2021-12-03 22:48:04,828 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 41
2021-12-03 22:48:04,828 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 63
2021-12-03 22:48:04,828 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 127
2021-12-03 22:48:04,828 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 148
2021-12-03 22:48:04,828 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 69
2021-12-03 22:48:04,828 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 113
2021-12-03 22:48:04,828 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 130
2021-12-03 22:48:04,828 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 74
2021-12-03 22:48:04,828 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 59
2021-12-03 22:48:04,828 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 115
2021-12-03 22:48:04,828 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 61
2021-12-03 22:48:04,828 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 31
2021-12-03 22:48:04,828 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 40
2021-12-03 22:48:04,828 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 144
2021-12-03 22:48:04,828 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 30
2021-12-03 22:48:04,828 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 147
2021-12-03 22:48:04,828 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 106
2021-12-03 22:48:04,828 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 42
2021-12-03 22:48:04,828 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 55
2021-12-03 22:48:04,828 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 46
2021-12-03 22:48:04,828 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 117
2021-12-03 22:48:04,828 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 110
2021-12-03 22:48:04,828 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 108
2021-12-03 22:48:04,828 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 54
2021-12-03 22:48:04,828 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 39
2021-12-03 22:48:04,828 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 104
2021-12-03 22:48:04,828 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 53
2021-12-03 22:48:04,828 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 111
2021-12-03 22:48:04,828 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 142
2021-12-03 22:48:04,828 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 126
2021-12-03 22:48:04,828 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 32
2021-12-03 22:48:04,828 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 72
2021-12-03 22:48:04,829 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 138
2021-12-03 22:48:04,829 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 29
2021-12-03 22:48:04,829 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 73
2021-12-03 22:48:04,829 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 52
2021-12-03 22:48:04,829 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 134
2021-12-03 22:48:04,829 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 137
2021-12-03 22:48:04,829 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 37
2021-12-03 22:48:04,829 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 49
2021-12-03 22:48:04,829 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 125
2021-12-03 22:48:04,829 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 51
2021-12-03 22:48:04,829 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 43
2021-12-03 22:48:04,829 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 135
2021-12-03 22:48:04,829 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 44
2021-12-03 22:48:04,832 [Executor task launch worker for task 173] INFO [org.apache.spark.executor.Executor] - Finished task 20.0 in stage 13.0 (TID 173). 1097 bytes result sent to driver
2021-12-03 22:48:04,833 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 20.0 in stage 13.0 (TID 173) in 287 ms on localhost (executor driver) (16/22)
2021-12-03 22:48:04,843 [Executor task launch worker for task 170] INFO [org.apache.spark.storage.memory.MemoryStore] - Block taskresult_170 stored as bytes in memory (estimated size 1256.5 KB, free 1980.8 MB)
2021-12-03 22:48:04,843 [dispatcher-event-loop-4] INFO [org.apache.spark.storage.BlockManagerInfo] - Added taskresult_170 in memory on qb:54372 (size: 1256.5 KB, free: 1986.2 MB)
2021-12-03 22:48:04,843 [Executor task launch worker for task 170] INFO [org.apache.spark.executor.Executor] - Finished task 17.0 in stage 13.0 (TID 170). 1286668 bytes result sent via BlockManager)
2021-12-03 22:48:04,846 [Executor task launch worker for task 174] INFO [org.apache.spark.executor.Executor] - Finished task 21.0 in stage 13.0 (TID 174). 1097 bytes result sent to driver
2021-12-03 22:48:04,849 [Executor task launch worker for task 172] INFO [org.apache.spark.executor.Executor] - Finished task 19.0 in stage 13.0 (TID 172). 554445 bytes result sent to driver
2021-12-03 22:48:04,877 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 13.0 in stage 13.0 (TID 166) in 406 ms on localhost (executor driver) (17/22)
2021-12-03 22:48:04,877 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 21.0 in stage 13.0 (TID 174) in 330 ms on localhost (executor driver) (18/22)
2021-12-03 22:48:04,878 [dispatcher-event-loop-3] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed taskresult_166 on qb:54372 in memory (size: 1073.7 KB, free: 1987.2 MB)
2021-12-03 22:48:04,879 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 19.0 in stage 13.0 (TID 172) in 350 ms on localhost (executor driver) (19/22)
2021-12-03 22:48:04,887 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 7.0 in stage 13.0 (TID 160) in 583 ms on localhost (executor driver) (20/22)
2021-12-03 22:48:04,887 [dispatcher-event-loop-2] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed taskresult_160 on qb:54372 in memory (size: 1221.2 KB, free: 1988.4 MB)
2021-12-03 22:48:04,898 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 12.0 in stage 13.0 (TID 165) in 457 ms on localhost (executor driver) (21/22)
2021-12-03 22:48:04,898 [dispatcher-event-loop-5] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed taskresult_165 on qb:54372 in memory (size: 1168.1 KB, free: 1989.5 MB)
2021-12-03 22:48:04,908 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 17.0 in stage 13.0 (TID 170) in 395 ms on localhost (executor driver) (22/22)
2021-12-03 22:48:04,908 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 13.0, whose tasks have all completed, from pool 
2021-12-03 22:48:04,909 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 13 (takeSample at PaidPromotionAdjustParameter.scala:77) finished in 0.613 s
2021-12-03 22:48:04,909 [dispatcher-event-loop-6] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed taskresult_170 on qb:54372 in memory (size: 1256.5 KB, free: 1990.8 MB)
2021-12-03 22:48:04,909 [main] INFO [org.apache.spark.scheduler.DAGScheduler] - Job 5 finished: takeSample at PaidPromotionAdjustParameter.scala:77, took 0.616787 s
2021-12-03 22:48:04,988 [main] INFO [PaidPromotion$] - 小数据集个数：500000
2021-12-03 22:48:05,250 [main] INFO [org.apache.spark.SparkContext] - Starting job: count at PaidPromotionAdjustParameter.scala:85
2021-12-03 22:48:05,250 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 6 (count at PaidPromotionAdjustParameter.scala:85) with 22 output partitions
2021-12-03 22:48:05,250 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 14 (count at PaidPromotionAdjustParameter.scala:85)
2021-12-03 22:48:05,250 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List()
2021-12-03 22:48:05,250 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2021-12-03 22:48:05,251 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 14 (MapPartitionsRDD[14] at map at PaidPromotionAdjustParameter.scala:83), which has no missing parents
2021-12-03 22:48:05,457 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_9 stored as values in memory (estimated size 16.7 MB, free 1973.8 MB)
2021-12-03 22:48:05,494 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_9_piece0 stored as bytes in memory (estimated size 4.0 MB, free 1969.8 MB)
2021-12-03 22:48:05,494 [dispatcher-event-loop-9] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_9_piece0 in memory on qb:54372 (size: 4.0 MB, free: 1986.8 MB)
2021-12-03 22:48:05,495 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_9_piece1 stored as bytes in memory (estimated size 1767.4 KB, free 1968.0 MB)
2021-12-03 22:48:05,495 [dispatcher-event-loop-1] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_9_piece1 in memory on qb:54372 (size: 1767.4 KB, free: 1985.0 MB)
2021-12-03 22:48:05,495 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 9 from broadcast at DAGScheduler.scala:1039
2021-12-03 22:48:05,495 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 22 missing tasks from ResultStage 14 (MapPartitionsRDD[14] at map at PaidPromotionAdjustParameter.scala:83) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14))
2021-12-03 22:48:05,496 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 14.0 with 22 tasks
2021-12-03 22:48:05,496 [dispatcher-event-loop-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 14.0 (TID 175, localhost, executor driver, partition 0, ANY, 7903 bytes)
2021-12-03 22:48:05,496 [dispatcher-event-loop-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 14.0 (TID 176, localhost, executor driver, partition 1, ANY, 7903 bytes)
2021-12-03 22:48:05,496 [dispatcher-event-loop-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 2.0 in stage 14.0 (TID 177, localhost, executor driver, partition 2, ANY, 7903 bytes)
2021-12-03 22:48:05,496 [dispatcher-event-loop-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 3.0 in stage 14.0 (TID 178, localhost, executor driver, partition 3, ANY, 7903 bytes)
2021-12-03 22:48:05,497 [dispatcher-event-loop-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 4.0 in stage 14.0 (TID 179, localhost, executor driver, partition 4, ANY, 7903 bytes)
2021-12-03 22:48:05,497 [dispatcher-event-loop-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 5.0 in stage 14.0 (TID 180, localhost, executor driver, partition 5, ANY, 7903 bytes)
2021-12-03 22:48:05,497 [dispatcher-event-loop-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 6.0 in stage 14.0 (TID 181, localhost, executor driver, partition 6, ANY, 7903 bytes)
2021-12-03 22:48:05,497 [dispatcher-event-loop-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 7.0 in stage 14.0 (TID 182, localhost, executor driver, partition 7, ANY, 7903 bytes)
2021-12-03 22:48:05,497 [dispatcher-event-loop-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 8.0 in stage 14.0 (TID 183, localhost, executor driver, partition 8, ANY, 7903 bytes)
2021-12-03 22:48:05,497 [dispatcher-event-loop-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 9.0 in stage 14.0 (TID 184, localhost, executor driver, partition 9, ANY, 7903 bytes)
2021-12-03 22:48:05,497 [dispatcher-event-loop-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 10.0 in stage 14.0 (TID 185, localhost, executor driver, partition 10, ANY, 7903 bytes)
2021-12-03 22:48:05,497 [dispatcher-event-loop-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 11.0 in stage 14.0 (TID 186, localhost, executor driver, partition 11, ANY, 7903 bytes)
2021-12-03 22:48:05,497 [Executor task launch worker for task 175] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 14.0 (TID 175)
2021-12-03 22:48:05,497 [Executor task launch worker for task 176] INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 14.0 (TID 176)
2021-12-03 22:48:05,497 [Executor task launch worker for task 186] INFO [org.apache.spark.executor.Executor] - Running task 11.0 in stage 14.0 (TID 186)
2021-12-03 22:48:05,497 [Executor task launch worker for task 183] INFO [org.apache.spark.executor.Executor] - Running task 8.0 in stage 14.0 (TID 183)
2021-12-03 22:48:05,497 [Executor task launch worker for task 182] INFO [org.apache.spark.executor.Executor] - Running task 7.0 in stage 14.0 (TID 182)
2021-12-03 22:48:05,497 [Executor task launch worker for task 177] INFO [org.apache.spark.executor.Executor] - Running task 2.0 in stage 14.0 (TID 177)
2021-12-03 22:48:05,497 [Executor task launch worker for task 184] INFO [org.apache.spark.executor.Executor] - Running task 9.0 in stage 14.0 (TID 184)
2021-12-03 22:48:05,497 [Executor task launch worker for task 185] INFO [org.apache.spark.executor.Executor] - Running task 10.0 in stage 14.0 (TID 185)
2021-12-03 22:48:05,497 [Executor task launch worker for task 181] INFO [org.apache.spark.executor.Executor] - Running task 6.0 in stage 14.0 (TID 181)
2021-12-03 22:48:05,497 [Executor task launch worker for task 179] INFO [org.apache.spark.executor.Executor] - Running task 4.0 in stage 14.0 (TID 179)
2021-12-03 22:48:05,497 [Executor task launch worker for task 178] INFO [org.apache.spark.executor.Executor] - Running task 3.0 in stage 14.0 (TID 178)
2021-12-03 22:48:05,497 [Executor task launch worker for task 180] INFO [org.apache.spark.executor.Executor] - Running task 5.0 in stage 14.0 (TID 180)
2021-12-03 22:48:06,523 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 189
2021-12-03 22:48:06,523 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 195
2021-12-03 22:48:06,523 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 185
2021-12-03 22:48:06,523 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 188
2021-12-03 22:48:06,523 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 194
2021-12-03 22:48:06,523 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 190
2021-12-03 22:48:06,523 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 176
2021-12-03 22:48:06,523 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 199
2021-12-03 22:48:06,523 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 182
2021-12-03 22:48:06,523 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 183
2021-12-03 22:48:06,523 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 181
2021-12-03 22:48:06,523 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 175
2021-12-03 22:48:06,523 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 178
2021-12-03 22:48:06,524 [dispatcher-event-loop-2] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_8_piece0 on qb:54372 in memory (size: 2.8 KB, free: 1985.0 MB)
2021-12-03 22:48:06,524 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 196
2021-12-03 22:48:06,524 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 187
2021-12-03 22:48:06,524 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 198
2021-12-03 22:48:06,524 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 191
2021-12-03 22:48:06,524 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 180
2021-12-03 22:48:06,524 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 197
2021-12-03 22:48:06,524 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 179
2021-12-03 22:48:06,525 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 192
2021-12-03 22:48:06,525 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 184
2021-12-03 22:48:06,525 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 193
2021-12-03 22:48:06,525 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 177
2021-12-03 22:48:06,525 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 186
2021-12-03 22:48:06,589 [Executor task launch worker for task 175] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:0+134217728
2021-12-03 22:48:06,589 [Executor task launch worker for task 180] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:671088640+134217728
2021-12-03 22:48:06,594 [Executor task launch worker for task 178] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:402653184+134217728
2021-12-03 22:48:06,597 [Executor task launch worker for task 179] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:536870912+134217728
2021-12-03 22:48:06,597 [Executor task launch worker for task 183] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:1073741824+134217728
2021-12-03 22:48:06,599 [Executor task launch worker for task 176] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:134217728+134217728
2021-12-03 22:48:06,602 [Executor task launch worker for task 182] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:939524096+134217728
2021-12-03 22:48:06,604 [Executor task launch worker for task 177] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:268435456+134217728
2021-12-03 22:48:06,604 [Executor task launch worker for task 184] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:1207959552+134217728
2021-12-03 22:48:06,607 [Executor task launch worker for task 186] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:1476395008+134217728
2021-12-03 22:48:06,607 [Executor task launch worker for task 181] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:805306368+134217728
2021-12-03 22:48:06,614 [Executor task launch worker for task 185] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:1342177280+134217728
2021-12-03 22:53:33,613 [Thread-1] INFO [org.apache.spark.SparkContext] - Invoking stop() from shutdown hook
2021-12-03 22:53:33,620 [Thread-1] INFO [org.spark_project.jetty.server.AbstractConnector] - Stopped Spark@3414a8c3{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2021-12-03 22:53:33,627 [Thread-1] INFO [org.apache.spark.ui.SparkUI] - Stopped Spark web UI at http://qb:4040
2021-12-03 22:53:33,641 [main] INFO [org.apache.spark.scheduler.DAGScheduler] - Job 6 failed: count at PaidPromotionAdjustParameter.scala:85, took 328.391756 s
2021-12-03 22:53:33,646 [Thread-1] INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 14 (count at PaidPromotionAdjustParameter.scala:85) failed in 328.388 s due to Stage cancelled because SparkContext was shut down
2021-12-03 22:53:33,684 [dispatcher-event-loop-11] INFO [org.apache.spark.MapOutputTrackerMasterEndpoint] - MapOutputTrackerMasterEndpoint stopped!
2021-12-03 22:53:33,839 [Thread-1] INFO [org.apache.spark.storage.memory.MemoryStore] - MemoryStore cleared
2021-12-03 22:53:33,840 [Thread-1] INFO [org.apache.spark.storage.BlockManager] - BlockManager stopped
2021-12-03 22:53:33,841 [Thread-1] INFO [org.apache.spark.storage.BlockManagerMaster] - BlockManagerMaster stopped
2021-12-03 22:53:33,844 [dispatcher-event-loop-6] INFO [org.apache.spark.scheduler.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint] - OutputCommitCoordinator stopped!
2021-12-03 22:53:33,847 [Thread-1] INFO [org.apache.spark.SparkContext] - Successfully stopped SparkContext
2021-12-03 22:53:33,848 [Thread-1] INFO [org.apache.spark.util.ShutdownHookManager] - Shutdown hook called
2021-12-03 22:53:33,850 [Thread-1] INFO [org.apache.spark.util.ShutdownHookManager] - Deleting directory C:\Users\ACER\AppData\Local\Temp\spark-85f438ed-e3f2-4ffd-9629-46f705ba3396
2021-12-03 22:53:49,608 [main] INFO [org.apache.spark.SparkContext] - Running Spark version 2.3.0
2021-12-03 22:53:49,876 [main] INFO [org.apache.spark.SparkContext] - Submitted application: PaidPromotion
2021-12-03 22:53:49,943 [main] INFO [org.apache.spark.SecurityManager] - Changing view acls to: ACER,root
2021-12-03 22:53:49,944 [main] INFO [org.apache.spark.SecurityManager] - Changing modify acls to: ACER,root
2021-12-03 22:53:49,944 [main] INFO [org.apache.spark.SecurityManager] - Changing view acls groups to: 
2021-12-03 22:53:49,945 [main] INFO [org.apache.spark.SecurityManager] - Changing modify acls groups to: 
2021-12-03 22:53:49,945 [main] INFO [org.apache.spark.SecurityManager] - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(ACER, root); groups with view permissions: Set(); users  with modify permissions: Set(ACER, root); groups with modify permissions: Set()
2021-12-03 22:53:50,540 [main] INFO [org.apache.spark.util.Utils] - Successfully started service 'sparkDriver' on port 58587.
2021-12-03 22:53:50,556 [main] INFO [org.apache.spark.SparkEnv] - Registering MapOutputTracker
2021-12-03 22:53:50,570 [main] INFO [org.apache.spark.SparkEnv] - Registering BlockManagerMaster
2021-12-03 22:53:50,572 [main] INFO [org.apache.spark.storage.BlockManagerMasterEndpoint] - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2021-12-03 22:53:50,572 [main] INFO [org.apache.spark.storage.BlockManagerMasterEndpoint] - BlockManagerMasterEndpoint up
2021-12-03 22:53:50,580 [main] INFO [org.apache.spark.storage.DiskBlockManager] - Created local directory at C:\Users\ACER\AppData\Local\Temp\blockmgr-ed066eb6-b24a-449d-91e7-a883fdaaa384
2021-12-03 22:53:50,594 [main] INFO [org.apache.spark.storage.memory.MemoryStore] - MemoryStore started with capacity 1990.8 MB
2021-12-03 22:53:50,603 [main] INFO [org.apache.spark.SparkEnv] - Registering OutputCommitCoordinator
2021-12-03 22:53:50,653 [main] INFO [org.spark_project.jetty.util.log] - Logging initialized @1923ms
2021-12-03 22:53:50,702 [main] INFO [org.spark_project.jetty.server.Server] - jetty-9.3.z-SNAPSHOT
2021-12-03 22:53:50,712 [main] INFO [org.spark_project.jetty.server.Server] - Started @1982ms
2021-12-03 22:53:50,734 [main] INFO [org.spark_project.jetty.server.AbstractConnector] - Started ServerConnector@5f7f2382{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2021-12-03 22:53:50,734 [main] INFO [org.apache.spark.util.Utils] - Successfully started service 'SparkUI' on port 4040.
2021-12-03 22:53:50,752 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@3af17be2{/jobs,null,AVAILABLE,@Spark}
2021-12-03 22:53:50,753 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@6a1d204a{/jobs/json,null,AVAILABLE,@Spark}
2021-12-03 22:53:50,754 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@72ccd81a{/jobs/job,null,AVAILABLE,@Spark}
2021-12-03 22:53:50,755 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@5d25e6bb{/jobs/job/json,null,AVAILABLE,@Spark}
2021-12-03 22:53:50,756 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@7859e786{/stages,null,AVAILABLE,@Spark}
2021-12-03 22:53:50,757 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@5118388b{/stages/json,null,AVAILABLE,@Spark}
2021-12-03 22:53:50,757 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@71104a4{/stages/stage,null,AVAILABLE,@Spark}
2021-12-03 22:53:50,759 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@332a7fce{/stages/stage/json,null,AVAILABLE,@Spark}
2021-12-03 22:53:50,760 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@37ebc9d8{/stages/pool,null,AVAILABLE,@Spark}
2021-12-03 22:53:50,761 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@6e9319f{/stages/pool/json,null,AVAILABLE,@Spark}
2021-12-03 22:53:50,762 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@2c177f9e{/storage,null,AVAILABLE,@Spark}
2021-12-03 22:53:50,763 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@f9b7332{/storage/json,null,AVAILABLE,@Spark}
2021-12-03 22:53:50,764 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@192f2f27{/storage/rdd,null,AVAILABLE,@Spark}
2021-12-03 22:53:50,765 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@b672aa8{/storage/rdd/json,null,AVAILABLE,@Spark}
2021-12-03 22:53:50,766 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@7997b197{/environment,null,AVAILABLE,@Spark}
2021-12-03 22:53:50,767 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@11acdc30{/environment/json,null,AVAILABLE,@Spark}
2021-12-03 22:53:50,768 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@611f8234{/executors,null,AVAILABLE,@Spark}
2021-12-03 22:53:50,769 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@62923ee6{/executors/json,null,AVAILABLE,@Spark}
2021-12-03 22:53:50,770 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@4b6166aa{/executors/threadDump,null,AVAILABLE,@Spark}
2021-12-03 22:53:50,771 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@a1217f9{/executors/threadDump/json,null,AVAILABLE,@Spark}
2021-12-03 22:53:50,776 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@791cbf87{/static,null,AVAILABLE,@Spark}
2021-12-03 22:53:50,777 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@cf65451{/,null,AVAILABLE,@Spark}
2021-12-03 22:53:50,779 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@46074492{/api,null,AVAILABLE,@Spark}
2021-12-03 22:53:50,780 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@5ae76500{/jobs/job/kill,null,AVAILABLE,@Spark}
2021-12-03 22:53:50,781 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@24f360b2{/stages/stage/kill,null,AVAILABLE,@Spark}
2021-12-03 22:53:50,782 [main] INFO [org.apache.spark.ui.SparkUI] - Bound SparkUI to 0.0.0.0, and started at http://qb:4040
2021-12-03 22:53:50,852 [main] INFO [org.apache.spark.executor.Executor] - Starting executor ID driver on host localhost
2021-12-03 22:53:50,888 [main] INFO [org.apache.spark.util.Utils] - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 58628.
2021-12-03 22:53:50,889 [main] INFO [org.apache.spark.network.netty.NettyBlockTransferService] - Server created on qb:58628
2021-12-03 22:53:50,890 [main] INFO [org.apache.spark.storage.BlockManager] - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2021-12-03 22:53:50,891 [main] INFO [org.apache.spark.storage.BlockManagerMaster] - Registering BlockManager BlockManagerId(driver, qb, 58628, None)
2021-12-03 22:53:50,893 [dispatcher-event-loop-10] INFO [org.apache.spark.storage.BlockManagerMasterEndpoint] - Registering block manager qb:58628 with 1990.8 MB RAM, BlockManagerId(driver, qb, 58628, None)
2021-12-03 22:53:50,894 [main] INFO [org.apache.spark.storage.BlockManagerMaster] - Registered BlockManager BlockManagerId(driver, qb, 58628, None)
2021-12-03 22:53:50,894 [main] INFO [org.apache.spark.storage.BlockManager] - Initialized BlockManager: BlockManagerId(driver, qb, 58628, None)
2021-12-03 22:53:51,006 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@7c9b78e3{/metrics/json,null,AVAILABLE,@Spark}
2021-12-03 22:53:51,411 [main] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_0 stored as values in memory (estimated size 312.7 KB, free 1990.5 MB)
2021-12-03 22:53:51,594 [main] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_0_piece0 stored as bytes in memory (estimated size 27.3 KB, free 1990.5 MB)
2021-12-03 22:53:51,596 [dispatcher-event-loop-0] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_0_piece0 in memory on qb:58628 (size: 27.3 KB, free: 1990.8 MB)
2021-12-03 22:53:51,599 [main] INFO [org.apache.spark.SparkContext] - Created broadcast 0 from textFile at PaidPromotionAdjustParameter.scala:57
2021-12-03 22:53:51,893 [main] WARN [org.apache.hadoop.hdfs.shortcircuit.DomainSocketFactory] - The short-circuit local reads feature cannot be used because UNIX Domain sockets are not available on Windows.
2021-12-03 22:53:51,961 [main] INFO [org.apache.hadoop.mapred.FileInputFormat] - Total input paths to process : 1
2021-12-03 22:53:51,993 [main] INFO [org.apache.hadoop.net.NetworkTopology] - Adding a new node: /default-rack/172.16.1.220:50010
2021-12-03 22:53:51,993 [main] INFO [org.apache.hadoop.net.NetworkTopology] - Adding a new node: /default-rack/192.168.1.34:50010
2021-12-03 22:53:51,993 [main] INFO [org.apache.hadoop.net.NetworkTopology] - Adding a new node: /default-rack/192.168.1.33:50010
2021-12-03 22:53:51,999 [main] INFO [org.apache.spark.SparkContext] - Starting job: count at PaidPromotionAdjustParameter.scala:59
2021-12-03 22:53:52,008 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 0 (count at PaidPromotionAdjustParameter.scala:59) with 22 output partitions
2021-12-03 22:53:52,008 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 0 (count at PaidPromotionAdjustParameter.scala:59)
2021-12-03 22:53:52,009 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List()
2021-12-03 22:53:52,010 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2021-12-03 22:53:52,015 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 0 (/sk/chongqing/data/behavior_data.bcp MapPartitionsRDD[1] at textFile at PaidPromotionAdjustParameter.scala:57), which has no missing parents
2021-12-03 22:53:52,044 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_1 stored as values in memory (estimated size 3.1 KB, free 1990.5 MB)
2021-12-03 22:53:52,049 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_1_piece0 stored as bytes in memory (estimated size 1903.0 B, free 1990.5 MB)
2021-12-03 22:53:52,049 [dispatcher-event-loop-1] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_1_piece0 in memory on qb:58628 (size: 1903.0 B, free: 1990.8 MB)
2021-12-03 22:53:52,050 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 1 from broadcast at DAGScheduler.scala:1039
2021-12-03 22:53:52,059 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 22 missing tasks from ResultStage 0 (/sk/chongqing/data/behavior_data.bcp MapPartitionsRDD[1] at textFile at PaidPromotionAdjustParameter.scala:57) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14))
2021-12-03 22:53:52,059 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 0.0 with 22 tasks
2021-12-03 22:53:52,088 [dispatcher-event-loop-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 0.0 (TID 0, localhost, executor driver, partition 0, ANY, 7899 bytes)
2021-12-03 22:53:52,090 [dispatcher-event-loop-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 0.0 (TID 1, localhost, executor driver, partition 1, ANY, 7899 bytes)
2021-12-03 22:53:52,090 [dispatcher-event-loop-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 2.0 in stage 0.0 (TID 2, localhost, executor driver, partition 2, ANY, 7899 bytes)
2021-12-03 22:53:52,090 [dispatcher-event-loop-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 3.0 in stage 0.0 (TID 3, localhost, executor driver, partition 3, ANY, 7899 bytes)
2021-12-03 22:53:52,090 [dispatcher-event-loop-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 4.0 in stage 0.0 (TID 4, localhost, executor driver, partition 4, ANY, 7899 bytes)
2021-12-03 22:53:52,091 [dispatcher-event-loop-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 5.0 in stage 0.0 (TID 5, localhost, executor driver, partition 5, ANY, 7899 bytes)
2021-12-03 22:53:52,091 [dispatcher-event-loop-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 6.0 in stage 0.0 (TID 6, localhost, executor driver, partition 6, ANY, 7899 bytes)
2021-12-03 22:53:52,091 [dispatcher-event-loop-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 7.0 in stage 0.0 (TID 7, localhost, executor driver, partition 7, ANY, 7899 bytes)
2021-12-03 22:53:52,091 [dispatcher-event-loop-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 8.0 in stage 0.0 (TID 8, localhost, executor driver, partition 8, ANY, 7899 bytes)
2021-12-03 22:53:52,092 [dispatcher-event-loop-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 9.0 in stage 0.0 (TID 9, localhost, executor driver, partition 9, ANY, 7899 bytes)
2021-12-03 22:53:52,092 [dispatcher-event-loop-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 10.0 in stage 0.0 (TID 10, localhost, executor driver, partition 10, ANY, 7899 bytes)
2021-12-03 22:53:52,092 [dispatcher-event-loop-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 11.0 in stage 0.0 (TID 11, localhost, executor driver, partition 11, ANY, 7899 bytes)
2021-12-03 22:53:52,096 [Executor task launch worker for task 3] INFO [org.apache.spark.executor.Executor] - Running task 3.0 in stage 0.0 (TID 3)
2021-12-03 22:53:52,097 [Executor task launch worker for task 6] INFO [org.apache.spark.executor.Executor] - Running task 6.0 in stage 0.0 (TID 6)
2021-12-03 22:53:52,097 [Executor task launch worker for task 2] INFO [org.apache.spark.executor.Executor] - Running task 2.0 in stage 0.0 (TID 2)
2021-12-03 22:53:52,096 [Executor task launch worker for task 0] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 0.0 (TID 0)
2021-12-03 22:53:52,096 [Executor task launch worker for task 4] INFO [org.apache.spark.executor.Executor] - Running task 4.0 in stage 0.0 (TID 4)
2021-12-03 22:53:52,096 [Executor task launch worker for task 5] INFO [org.apache.spark.executor.Executor] - Running task 5.0 in stage 0.0 (TID 5)
2021-12-03 22:53:52,097 [Executor task launch worker for task 9] INFO [org.apache.spark.executor.Executor] - Running task 9.0 in stage 0.0 (TID 9)
2021-12-03 22:53:52,097 [Executor task launch worker for task 8] INFO [org.apache.spark.executor.Executor] - Running task 8.0 in stage 0.0 (TID 8)
2021-12-03 22:53:52,097 [Executor task launch worker for task 1] INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 0.0 (TID 1)
2021-12-03 22:53:52,097 [Executor task launch worker for task 11] INFO [org.apache.spark.executor.Executor] - Running task 11.0 in stage 0.0 (TID 11)
2021-12-03 22:53:52,097 [Executor task launch worker for task 7] INFO [org.apache.spark.executor.Executor] - Running task 7.0 in stage 0.0 (TID 7)
2021-12-03 22:53:52,097 [Executor task launch worker for task 10] INFO [org.apache.spark.executor.Executor] - Running task 10.0 in stage 0.0 (TID 10)
2021-12-03 22:53:52,136 [Executor task launch worker for task 11] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:1476395008+134217728
2021-12-03 22:53:52,136 [Executor task launch worker for task 6] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:805306368+134217728
2021-12-03 22:53:52,136 [Executor task launch worker for task 10] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:1342177280+134217728
2021-12-03 22:53:52,136 [Executor task launch worker for task 3] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:402653184+134217728
2021-12-03 22:53:52,136 [Executor task launch worker for task 8] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:1073741824+134217728
2021-12-03 22:53:52,136 [Executor task launch worker for task 5] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:671088640+134217728
2021-12-03 22:53:52,136 [Executor task launch worker for task 7] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:939524096+134217728
2021-12-03 22:53:52,136 [Executor task launch worker for task 2] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:268435456+134217728
2021-12-03 22:53:52,136 [Executor task launch worker for task 1] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:134217728+134217728
2021-12-03 22:53:52,136 [Executor task launch worker for task 9] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:1207959552+134217728
2021-12-03 22:53:52,136 [Executor task launch worker for task 4] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:536870912+134217728
2021-12-03 22:53:52,136 [Executor task launch worker for task 0] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:0+134217728
2021-12-03 22:55:58,587 [Executor task launch worker for task 5] INFO [org.apache.spark.executor.Executor] - Finished task 5.0 in stage 0.0 (TID 5). 755 bytes result sent to driver
2021-12-03 22:55:58,588 [dispatcher-event-loop-7] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 12.0 in stage 0.0 (TID 12, localhost, executor driver, partition 12, ANY, 7899 bytes)
2021-12-03 22:55:58,588 [Executor task launch worker for task 12] INFO [org.apache.spark.executor.Executor] - Running task 12.0 in stage 0.0 (TID 12)
2021-12-03 22:55:58,591 [Executor task launch worker for task 12] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:1610612736+134217728
2021-12-03 22:55:58,596 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 5.0 in stage 0.0 (TID 5) in 126505 ms on localhost (executor driver) (1/22)
2021-12-03 22:55:59,585 [Executor task launch worker for task 10] INFO [org.apache.spark.executor.Executor] - Finished task 10.0 in stage 0.0 (TID 10). 755 bytes result sent to driver
2021-12-03 22:55:59,588 [dispatcher-event-loop-8] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 13.0 in stage 0.0 (TID 13, localhost, executor driver, partition 13, ANY, 7899 bytes)
2021-12-03 22:55:59,588 [Executor task launch worker for task 13] INFO [org.apache.spark.executor.Executor] - Running task 13.0 in stage 0.0 (TID 13)
2021-12-03 22:55:59,589 [Executor task launch worker for task 13] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:1744830464+134217728
2021-12-03 22:55:59,591 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 10.0 in stage 0.0 (TID 10) in 127499 ms on localhost (executor driver) (2/22)
2021-12-03 22:56:03,882 [Executor task launch worker for task 1] INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 0.0 (TID 1). 755 bytes result sent to driver
2021-12-03 22:56:03,883 [dispatcher-event-loop-11] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 14.0 in stage 0.0 (TID 14, localhost, executor driver, partition 14, ANY, 7899 bytes)
2021-12-03 22:56:03,883 [Executor task launch worker for task 14] INFO [org.apache.spark.executor.Executor] - Running task 14.0 in stage 0.0 (TID 14)
2021-12-03 22:56:03,884 [Executor task launch worker for task 14] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:1879048192+134217728
2021-12-03 22:56:03,886 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 0.0 (TID 1) in 131797 ms on localhost (executor driver) (3/22)
2021-12-03 22:56:07,582 [Executor task launch worker for task 11] INFO [org.apache.spark.executor.Executor] - Finished task 11.0 in stage 0.0 (TID 11). 755 bytes result sent to driver
2021-12-03 22:56:07,583 [dispatcher-event-loop-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 15.0 in stage 0.0 (TID 15, localhost, executor driver, partition 15, ANY, 7899 bytes)
2021-12-03 22:56:07,583 [Executor task launch worker for task 15] INFO [org.apache.spark.executor.Executor] - Running task 15.0 in stage 0.0 (TID 15)
2021-12-03 22:56:07,584 [Executor task launch worker for task 15] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:2013265920+134217728
2021-12-03 22:56:07,585 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 11.0 in stage 0.0 (TID 11) in 135493 ms on localhost (executor driver) (4/22)
2021-12-03 22:56:09,243 [Executor task launch worker for task 9] INFO [org.apache.spark.executor.Executor] - Finished task 9.0 in stage 0.0 (TID 9). 755 bytes result sent to driver
2021-12-03 22:56:09,243 [dispatcher-event-loop-6] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 16.0 in stage 0.0 (TID 16, localhost, executor driver, partition 16, ANY, 7899 bytes)
2021-12-03 22:56:09,244 [Executor task launch worker for task 16] INFO [org.apache.spark.executor.Executor] - Running task 16.0 in stage 0.0 (TID 16)
2021-12-03 22:56:09,244 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 9.0 in stage 0.0 (TID 9) in 137153 ms on localhost (executor driver) (5/22)
2021-12-03 22:56:09,245 [Executor task launch worker for task 16] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:2147483648+134217728
2021-12-03 22:56:19,667 [Executor task launch worker for task 4] INFO [org.apache.spark.executor.Executor] - Finished task 4.0 in stage 0.0 (TID 4). 755 bytes result sent to driver
2021-12-03 22:56:19,667 [dispatcher-event-loop-8] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 17.0 in stage 0.0 (TID 17, localhost, executor driver, partition 17, ANY, 7899 bytes)
2021-12-03 22:56:19,667 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 4.0 in stage 0.0 (TID 4) in 147577 ms on localhost (executor driver) (6/22)
2021-12-03 22:56:19,667 [Executor task launch worker for task 17] INFO [org.apache.spark.executor.Executor] - Running task 17.0 in stage 0.0 (TID 17)
2021-12-03 22:56:19,669 [Executor task launch worker for task 17] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:2281701376+134217728
2021-12-03 22:56:19,745 [Executor task launch worker for task 7] INFO [org.apache.spark.executor.Executor] - Finished task 7.0 in stage 0.0 (TID 7). 755 bytes result sent to driver
2021-12-03 22:56:19,745 [dispatcher-event-loop-10] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 18.0 in stage 0.0 (TID 18, localhost, executor driver, partition 18, ANY, 7899 bytes)
2021-12-03 22:56:19,745 [Executor task launch worker for task 18] INFO [org.apache.spark.executor.Executor] - Running task 18.0 in stage 0.0 (TID 18)
2021-12-03 22:56:19,745 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 7.0 in stage 0.0 (TID 7) in 147654 ms on localhost (executor driver) (7/22)
2021-12-03 22:56:19,747 [Executor task launch worker for task 18] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:2415919104+134217728
2021-12-03 22:56:22,659 [Executor task launch worker for task 8] INFO [org.apache.spark.executor.Executor] - Finished task 8.0 in stage 0.0 (TID 8). 755 bytes result sent to driver
2021-12-03 22:56:22,659 [dispatcher-event-loop-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 19.0 in stage 0.0 (TID 19, localhost, executor driver, partition 19, ANY, 7899 bytes)
2021-12-03 22:56:22,659 [Executor task launch worker for task 19] INFO [org.apache.spark.executor.Executor] - Running task 19.0 in stage 0.0 (TID 19)
2021-12-03 22:56:22,659 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 8.0 in stage 0.0 (TID 8) in 150568 ms on localhost (executor driver) (8/22)
2021-12-03 22:56:22,660 [Executor task launch worker for task 19] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:2550136832+134217728
2021-12-03 22:56:27,814 [Executor task launch worker for task 3] INFO [org.apache.spark.executor.Executor] - Finished task 3.0 in stage 0.0 (TID 3). 755 bytes result sent to driver
2021-12-03 22:56:27,815 [dispatcher-event-loop-6] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 20.0 in stage 0.0 (TID 20, localhost, executor driver, partition 20, ANY, 7899 bytes)
2021-12-03 22:56:27,815 [Executor task launch worker for task 20] INFO [org.apache.spark.executor.Executor] - Running task 20.0 in stage 0.0 (TID 20)
2021-12-03 22:56:27,815 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 3.0 in stage 0.0 (TID 3) in 155725 ms on localhost (executor driver) (9/22)
2021-12-03 22:56:27,815 [Executor task launch worker for task 20] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:2684354560+134217728
2021-12-03 22:56:31,321 [Executor task launch worker for task 0] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 0.0 (TID 0). 755 bytes result sent to driver
2021-12-03 22:56:31,321 [dispatcher-event-loop-7] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 21.0 in stage 0.0 (TID 21, localhost, executor driver, partition 21, ANY, 7899 bytes)
2021-12-03 22:56:31,321 [Executor task launch worker for task 21] INFO [org.apache.spark.executor.Executor] - Running task 21.0 in stage 0.0 (TID 21)
2021-12-03 22:56:31,321 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 0.0 (TID 0) in 159240 ms on localhost (executor driver) (10/22)
2021-12-03 22:56:31,322 [Executor task launch worker for task 21] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:2818572288+147216171
2021-12-03 22:56:33,800 [Executor task launch worker for task 2] INFO [org.apache.spark.executor.Executor] - Finished task 2.0 in stage 0.0 (TID 2). 755 bytes result sent to driver
2021-12-03 22:56:33,802 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 2.0 in stage 0.0 (TID 2) in 161712 ms on localhost (executor driver) (11/22)
2021-12-03 22:56:51,580 [Executor task launch worker for task 6] INFO [org.apache.spark.executor.Executor] - Finished task 6.0 in stage 0.0 (TID 6). 755 bytes result sent to driver
2021-12-03 22:56:51,581 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 6.0 in stage 0.0 (TID 6) in 179490 ms on localhost (executor driver) (12/22)
2021-12-03 22:57:27,504 [Executor task launch worker for task 16] INFO [org.apache.spark.executor.Executor] - Finished task 16.0 in stage 0.0 (TID 16). 755 bytes result sent to driver
2021-12-03 22:57:27,504 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 16.0 in stage 0.0 (TID 16) in 78261 ms on localhost (executor driver) (13/22)
2021-12-03 22:57:54,109 [Executor task launch worker for task 14] INFO [org.apache.spark.executor.Executor] - Finished task 14.0 in stage 0.0 (TID 14). 755 bytes result sent to driver
2021-12-03 22:57:54,109 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 14.0 in stage 0.0 (TID 14) in 110226 ms on localhost (executor driver) (14/22)
2021-12-03 22:58:01,033 [Executor task launch worker for task 18] INFO [org.apache.spark.executor.Executor] - Finished task 18.0 in stage 0.0 (TID 18). 755 bytes result sent to driver
2021-12-03 22:58:01,034 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 18.0 in stage 0.0 (TID 18) in 101289 ms on localhost (executor driver) (15/22)
2021-12-03 22:58:02,160 [Executor task launch worker for task 12] INFO [org.apache.spark.executor.Executor] - Finished task 12.0 in stage 0.0 (TID 12). 755 bytes result sent to driver
2021-12-03 22:58:02,161 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 12.0 in stage 0.0 (TID 12) in 123573 ms on localhost (executor driver) (16/22)
2021-12-03 22:58:04,862 [Executor task launch worker for task 15] INFO [org.apache.spark.executor.Executor] - Finished task 15.0 in stage 0.0 (TID 15). 712 bytes result sent to driver
2021-12-03 22:58:04,862 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 15.0 in stage 0.0 (TID 15) in 117279 ms on localhost (executor driver) (17/22)
2021-12-03 22:58:06,921 [Executor task launch worker for task 17] INFO [org.apache.spark.executor.Executor] - Finished task 17.0 in stage 0.0 (TID 17). 755 bytes result sent to driver
2021-12-03 22:58:06,921 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 17.0 in stage 0.0 (TID 17) in 107254 ms on localhost (executor driver) (18/22)
2021-12-03 22:58:08,587 [Executor task launch worker for task 19] INFO [org.apache.spark.executor.Executor] - Finished task 19.0 in stage 0.0 (TID 19). 712 bytes result sent to driver
2021-12-03 22:58:08,588 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 19.0 in stage 0.0 (TID 19) in 105928 ms on localhost (executor driver) (19/22)
2021-12-03 22:58:10,109 [Executor task launch worker for task 13] INFO [org.apache.spark.executor.Executor] - Finished task 13.0 in stage 0.0 (TID 13). 712 bytes result sent to driver
2021-12-03 22:58:10,109 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 13.0 in stage 0.0 (TID 13) in 130523 ms on localhost (executor driver) (20/22)
2021-12-03 22:58:11,964 [Executor task launch worker for task 20] INFO [org.apache.spark.executor.Executor] - Finished task 20.0 in stage 0.0 (TID 20). 712 bytes result sent to driver
2021-12-03 22:58:11,964 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 20.0 in stage 0.0 (TID 20) in 104150 ms on localhost (executor driver) (21/22)
2021-12-03 22:58:12,582 [Executor task launch worker for task 21] INFO [org.apache.spark.executor.Executor] - Finished task 21.0 in stage 0.0 (TID 21). 712 bytes result sent to driver
2021-12-03 22:58:12,582 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 21.0 in stage 0.0 (TID 21) in 101261 ms on localhost (executor driver) (22/22)
2021-12-03 22:58:12,583 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 0.0, whose tasks have all completed, from pool 
2021-12-03 22:58:12,583 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 0 (count at PaidPromotionAdjustParameter.scala:59) finished in 260.555 s
2021-12-03 22:58:12,587 [main] INFO [org.apache.spark.scheduler.DAGScheduler] - Job 0 finished: count at PaidPromotionAdjustParameter.scala:59, took 260.588713 s
2021-12-03 22:58:12,588 [main] INFO [PaidPromotion$] - 收视总数68489201
2021-12-03 22:58:12,605 [main] INFO [org.apache.spark.SparkContext] - Starting job: count at PaidPromotionAdjustParameter.scala:68
2021-12-03 22:58:12,612 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 3 (map at PaidPromotionAdjustParameter.scala:67)
2021-12-03 22:58:12,612 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 1 (count at PaidPromotionAdjustParameter.scala:68) with 22 output partitions
2021-12-03 22:58:12,613 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 2 (count at PaidPromotionAdjustParameter.scala:68)
2021-12-03 22:58:12,613 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 1)
2021-12-03 22:58:12,613 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List(ShuffleMapStage 1)
2021-12-03 22:58:12,614 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ShuffleMapStage 1 (MapPartitionsRDD[3] at map at PaidPromotionAdjustParameter.scala:67), which has no missing parents
2021-12-03 22:58:12,623 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_2 stored as values in memory (estimated size 4.7 KB, free 1990.5 MB)
2021-12-03 22:58:12,625 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_2_piece0 stored as bytes in memory (estimated size 2.7 KB, free 1990.5 MB)
2021-12-03 22:58:12,626 [dispatcher-event-loop-8] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_2_piece0 in memory on qb:58628 (size: 2.7 KB, free: 1990.8 MB)
2021-12-03 22:58:12,626 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 2 from broadcast at DAGScheduler.scala:1039
2021-12-03 22:58:12,628 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 22 missing tasks from ShuffleMapStage 1 (MapPartitionsRDD[3] at map at PaidPromotionAdjustParameter.scala:67) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14))
2021-12-03 22:58:12,628 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 1.0 with 22 tasks
2021-12-03 22:58:12,629 [dispatcher-event-loop-9] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 1.0 (TID 22, localhost, executor driver, partition 0, ANY, 7888 bytes)
2021-12-03 22:58:12,629 [dispatcher-event-loop-9] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 1.0 (TID 23, localhost, executor driver, partition 1, ANY, 7888 bytes)
2021-12-03 22:58:12,629 [dispatcher-event-loop-9] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 2.0 in stage 1.0 (TID 24, localhost, executor driver, partition 2, ANY, 7888 bytes)
2021-12-03 22:58:12,629 [dispatcher-event-loop-9] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 3.0 in stage 1.0 (TID 25, localhost, executor driver, partition 3, ANY, 7888 bytes)
2021-12-03 22:58:12,630 [dispatcher-event-loop-9] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 4.0 in stage 1.0 (TID 26, localhost, executor driver, partition 4, ANY, 7888 bytes)
2021-12-03 22:58:12,630 [dispatcher-event-loop-9] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 5.0 in stage 1.0 (TID 27, localhost, executor driver, partition 5, ANY, 7888 bytes)
2021-12-03 22:58:12,630 [dispatcher-event-loop-9] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 6.0 in stage 1.0 (TID 28, localhost, executor driver, partition 6, ANY, 7888 bytes)
2021-12-03 22:58:12,630 [dispatcher-event-loop-9] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 7.0 in stage 1.0 (TID 29, localhost, executor driver, partition 7, ANY, 7888 bytes)
2021-12-03 22:58:12,630 [dispatcher-event-loop-9] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 8.0 in stage 1.0 (TID 30, localhost, executor driver, partition 8, ANY, 7888 bytes)
2021-12-03 22:58:12,630 [dispatcher-event-loop-9] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 9.0 in stage 1.0 (TID 31, localhost, executor driver, partition 9, ANY, 7888 bytes)
2021-12-03 22:58:12,631 [dispatcher-event-loop-9] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 10.0 in stage 1.0 (TID 32, localhost, executor driver, partition 10, ANY, 7888 bytes)
2021-12-03 22:58:12,631 [dispatcher-event-loop-9] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 11.0 in stage 1.0 (TID 33, localhost, executor driver, partition 11, ANY, 7888 bytes)
2021-12-03 22:58:12,631 [Executor task launch worker for task 22] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 1.0 (TID 22)
2021-12-03 22:58:12,631 [Executor task launch worker for task 24] INFO [org.apache.spark.executor.Executor] - Running task 2.0 in stage 1.0 (TID 24)
2021-12-03 22:58:12,631 [Executor task launch worker for task 31] INFO [org.apache.spark.executor.Executor] - Running task 9.0 in stage 1.0 (TID 31)
2021-12-03 22:58:12,631 [Executor task launch worker for task 29] INFO [org.apache.spark.executor.Executor] - Running task 7.0 in stage 1.0 (TID 29)
2021-12-03 22:58:12,631 [Executor task launch worker for task 30] INFO [org.apache.spark.executor.Executor] - Running task 8.0 in stage 1.0 (TID 30)
2021-12-03 22:58:12,631 [Executor task launch worker for task 28] INFO [org.apache.spark.executor.Executor] - Running task 6.0 in stage 1.0 (TID 28)
2021-12-03 22:58:12,631 [Executor task launch worker for task 26] INFO [org.apache.spark.executor.Executor] - Running task 4.0 in stage 1.0 (TID 26)
2021-12-03 22:58:12,631 [Executor task launch worker for task 25] INFO [org.apache.spark.executor.Executor] - Running task 3.0 in stage 1.0 (TID 25)
2021-12-03 22:58:12,631 [Executor task launch worker for task 27] INFO [org.apache.spark.executor.Executor] - Running task 5.0 in stage 1.0 (TID 27)
2021-12-03 22:58:12,631 [Executor task launch worker for task 23] INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 1.0 (TID 23)
2021-12-03 22:58:12,632 [Executor task launch worker for task 33] INFO [org.apache.spark.executor.Executor] - Running task 11.0 in stage 1.0 (TID 33)
2021-12-03 22:58:12,632 [Executor task launch worker for task 32] INFO [org.apache.spark.executor.Executor] - Running task 10.0 in stage 1.0 (TID 32)
2021-12-03 22:58:12,649 [Executor task launch worker for task 23] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:134217728+134217728
2021-12-03 22:58:12,649 [Executor task launch worker for task 26] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:536870912+134217728
2021-12-03 22:58:12,649 [Executor task launch worker for task 32] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:1342177280+134217728
2021-12-03 22:58:12,649 [Executor task launch worker for task 22] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:0+134217728
2021-12-03 22:58:12,649 [Executor task launch worker for task 33] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:1476395008+134217728
2021-12-03 22:58:12,649 [Executor task launch worker for task 24] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:268435456+134217728
2021-12-03 22:58:12,649 [Executor task launch worker for task 27] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:671088640+134217728
2021-12-03 22:58:12,649 [Executor task launch worker for task 29] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:939524096+134217728
2021-12-03 22:58:12,649 [Executor task launch worker for task 30] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:1073741824+134217728
2021-12-03 22:58:12,649 [Executor task launch worker for task 28] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:805306368+134217728
2021-12-03 22:58:12,649 [Executor task launch worker for task 25] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:402653184+134217728
2021-12-03 22:58:12,649 [Executor task launch worker for task 31] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:1207959552+134217728
2021-12-03 23:00:14,544 [Executor task launch worker for task 27] INFO [org.apache.spark.executor.Executor] - Finished task 5.0 in stage 1.0 (TID 27). 1052 bytes result sent to driver
2021-12-03 23:00:14,544 [dispatcher-event-loop-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 12.0 in stage 1.0 (TID 34, localhost, executor driver, partition 12, ANY, 7888 bytes)
2021-12-03 23:00:14,544 [Executor task launch worker for task 34] INFO [org.apache.spark.executor.Executor] - Running task 12.0 in stage 1.0 (TID 34)
2021-12-03 23:00:14,545 [Executor task launch worker for task 34] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:1610612736+134217728
2021-12-03 23:00:14,557 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 5.0 in stage 1.0 (TID 27) in 121927 ms on localhost (executor driver) (1/22)
2021-12-03 23:00:14,640 [Executor task launch worker for task 23] INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 1.0 (TID 23). 1052 bytes result sent to driver
2021-12-03 23:00:14,640 [dispatcher-event-loop-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 13.0 in stage 1.0 (TID 35, localhost, executor driver, partition 13, ANY, 7888 bytes)
2021-12-03 23:00:14,641 [Executor task launch worker for task 35] INFO [org.apache.spark.executor.Executor] - Running task 13.0 in stage 1.0 (TID 35)
2021-12-03 23:00:14,641 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 1.0 (TID 23) in 122012 ms on localhost (executor driver) (2/22)
2021-12-03 23:00:14,642 [Executor task launch worker for task 35] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:1744830464+134217728
2021-12-03 23:00:21,485 [Executor task launch worker for task 32] INFO [org.apache.spark.executor.Executor] - Finished task 10.0 in stage 1.0 (TID 32). 1052 bytes result sent to driver
2021-12-03 23:00:21,486 [dispatcher-event-loop-6] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 14.0 in stage 1.0 (TID 36, localhost, executor driver, partition 14, ANY, 7888 bytes)
2021-12-03 23:00:21,486 [Executor task launch worker for task 36] INFO [org.apache.spark.executor.Executor] - Running task 14.0 in stage 1.0 (TID 36)
2021-12-03 23:00:21,486 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 10.0 in stage 1.0 (TID 32) in 128856 ms on localhost (executor driver) (3/22)
2021-12-03 23:00:21,487 [Executor task launch worker for task 36] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:1879048192+134217728
2021-12-03 23:00:28,711 [Executor task launch worker for task 22] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 1.0 (TID 22). 1052 bytes result sent to driver
2021-12-03 23:00:28,712 [dispatcher-event-loop-8] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 15.0 in stage 1.0 (TID 37, localhost, executor driver, partition 15, ANY, 7888 bytes)
2021-12-03 23:00:28,712 [Executor task launch worker for task 37] INFO [org.apache.spark.executor.Executor] - Running task 15.0 in stage 1.0 (TID 37)
2021-12-03 23:00:28,712 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 1.0 (TID 22) in 136084 ms on localhost (executor driver) (4/22)
2021-12-03 23:00:28,713 [Executor task launch worker for task 37] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:2013265920+134217728
2021-12-03 23:00:33,335 [Executor task launch worker for task 25] INFO [org.apache.spark.executor.Executor] - Finished task 3.0 in stage 1.0 (TID 25). 1095 bytes result sent to driver
2021-12-03 23:00:33,335 [dispatcher-event-loop-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 16.0 in stage 1.0 (TID 38, localhost, executor driver, partition 16, ANY, 7888 bytes)
2021-12-03 23:00:33,335 [Executor task launch worker for task 38] INFO [org.apache.spark.executor.Executor] - Running task 16.0 in stage 1.0 (TID 38)
2021-12-03 23:00:33,335 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 3.0 in stage 1.0 (TID 25) in 140706 ms on localhost (executor driver) (5/22)
2021-12-03 23:00:33,336 [Executor task launch worker for task 38] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:2147483648+134217728
2021-12-03 23:00:35,593 [Executor task launch worker for task 33] INFO [org.apache.spark.executor.Executor] - Finished task 11.0 in stage 1.0 (TID 33). 1052 bytes result sent to driver
2021-12-03 23:00:35,594 [dispatcher-event-loop-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 17.0 in stage 1.0 (TID 39, localhost, executor driver, partition 17, ANY, 7888 bytes)
2021-12-03 23:00:35,594 [Executor task launch worker for task 39] INFO [org.apache.spark.executor.Executor] - Running task 17.0 in stage 1.0 (TID 39)
2021-12-03 23:00:35,594 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 11.0 in stage 1.0 (TID 33) in 142963 ms on localhost (executor driver) (6/22)
2021-12-03 23:00:35,595 [Executor task launch worker for task 39] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:2281701376+134217728
2021-12-03 23:00:42,573 [Executor task launch worker for task 28] INFO [org.apache.spark.executor.Executor] - Finished task 6.0 in stage 1.0 (TID 28). 1052 bytes result sent to driver
2021-12-03 23:00:42,573 [dispatcher-event-loop-7] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 18.0 in stage 1.0 (TID 40, localhost, executor driver, partition 18, ANY, 7888 bytes)
2021-12-03 23:00:42,573 [Executor task launch worker for task 40] INFO [org.apache.spark.executor.Executor] - Running task 18.0 in stage 1.0 (TID 40)
2021-12-03 23:00:42,573 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 6.0 in stage 1.0 (TID 28) in 149943 ms on localhost (executor driver) (7/22)
2021-12-03 23:00:42,574 [Executor task launch worker for task 40] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:2415919104+134217728
2021-12-03 23:00:48,017 [Executor task launch worker for task 26] INFO [org.apache.spark.executor.Executor] - Finished task 4.0 in stage 1.0 (TID 26). 1052 bytes result sent to driver
2021-12-03 23:00:48,018 [dispatcher-event-loop-8] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 19.0 in stage 1.0 (TID 41, localhost, executor driver, partition 19, ANY, 7888 bytes)
2021-12-03 23:00:48,018 [Executor task launch worker for task 41] INFO [org.apache.spark.executor.Executor] - Running task 19.0 in stage 1.0 (TID 41)
2021-12-03 23:00:48,018 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 4.0 in stage 1.0 (TID 26) in 155389 ms on localhost (executor driver) (8/22)
2021-12-03 23:00:48,018 [Executor task launch worker for task 41] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:2550136832+134217728
2021-12-03 23:00:49,778 [Executor task launch worker for task 29] INFO [org.apache.spark.executor.Executor] - Finished task 7.0 in stage 1.0 (TID 29). 1052 bytes result sent to driver
2021-12-03 23:00:49,778 [dispatcher-event-loop-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 20.0 in stage 1.0 (TID 42, localhost, executor driver, partition 20, ANY, 7888 bytes)
2021-12-03 23:00:49,778 [Executor task launch worker for task 42] INFO [org.apache.spark.executor.Executor] - Running task 20.0 in stage 1.0 (TID 42)
2021-12-03 23:00:49,778 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 7.0 in stage 1.0 (TID 29) in 157148 ms on localhost (executor driver) (9/22)
2021-12-03 23:00:49,779 [Executor task launch worker for task 42] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:2684354560+134217728
2021-12-03 23:00:55,717 [Executor task launch worker for task 24] INFO [org.apache.spark.executor.Executor] - Finished task 2.0 in stage 1.0 (TID 24). 1052 bytes result sent to driver
2021-12-03 23:00:55,718 [dispatcher-event-loop-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 21.0 in stage 1.0 (TID 43, localhost, executor driver, partition 21, ANY, 7888 bytes)
2021-12-03 23:00:55,718 [Executor task launch worker for task 43] INFO [org.apache.spark.executor.Executor] - Running task 21.0 in stage 1.0 (TID 43)
2021-12-03 23:00:55,718 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 2.0 in stage 1.0 (TID 24) in 163089 ms on localhost (executor driver) (10/22)
2021-12-03 23:00:55,719 [Executor task launch worker for task 43] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:2818572288+147216171
2021-12-03 23:00:56,575 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 4
2021-12-03 23:00:56,575 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 20
2021-12-03 23:00:56,575 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 16
2021-12-03 23:00:56,575 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 2
2021-12-03 23:00:56,575 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 22
2021-12-03 23:00:56,575 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 3
2021-12-03 23:00:56,575 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 24
2021-12-03 23:00:56,575 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 8
2021-12-03 23:00:56,575 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 6
2021-12-03 23:00:56,575 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 12
2021-12-03 23:00:56,575 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1
2021-12-03 23:00:56,575 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 19
2021-12-03 23:00:56,575 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 5
2021-12-03 23:00:56,575 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 11
2021-12-03 23:00:56,575 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 9
2021-12-03 23:00:56,575 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 13
2021-12-03 23:00:56,576 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 10
2021-12-03 23:00:56,576 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 23
2021-12-03 23:00:56,576 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 14
2021-12-03 23:00:56,576 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 0
2021-12-03 23:00:56,576 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 15
2021-12-03 23:00:56,576 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 18
2021-12-03 23:00:56,576 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 7
2021-12-03 23:00:56,584 [dispatcher-event-loop-4] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_1_piece0 on qb:58628 in memory (size: 1903.0 B, free: 1990.8 MB)
2021-12-03 23:00:56,586 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 17
2021-12-03 23:00:56,586 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 21
2021-12-03 23:01:08,975 [Executor task launch worker for task 31] INFO [org.apache.spark.executor.Executor] - Finished task 9.0 in stage 1.0 (TID 31). 1052 bytes result sent to driver
2021-12-03 23:01:08,975 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 9.0 in stage 1.0 (TID 31) in 176345 ms on localhost (executor driver) (11/22)
2021-12-03 23:01:16,534 [Executor task launch worker for task 30] INFO [org.apache.spark.executor.Executor] - Finished task 8.0 in stage 1.0 (TID 30). 1052 bytes result sent to driver
2021-12-03 23:01:16,535 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 8.0 in stage 1.0 (TID 30) in 183905 ms on localhost (executor driver) (12/22)
2021-12-03 23:01:58,613 [Executor task launch worker for task 34] INFO [org.apache.spark.executor.Executor] - Finished task 12.0 in stage 1.0 (TID 34). 1095 bytes result sent to driver
2021-12-03 23:01:58,614 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 12.0 in stage 1.0 (TID 34) in 104070 ms on localhost (executor driver) (13/22)
2021-12-03 23:02:06,939 [Executor task launch worker for task 37] INFO [org.apache.spark.executor.Executor] - Finished task 15.0 in stage 1.0 (TID 37). 1052 bytes result sent to driver
2021-12-03 23:02:06,939 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 15.0 in stage 1.0 (TID 37) in 98228 ms on localhost (executor driver) (14/22)
2021-12-03 23:02:10,339 [Executor task launch worker for task 35] INFO [org.apache.spark.executor.Executor] - Finished task 13.0 in stage 1.0 (TID 35). 1009 bytes result sent to driver
2021-12-03 23:02:10,340 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 13.0 in stage 1.0 (TID 35) in 115700 ms on localhost (executor driver) (15/22)
2021-12-03 23:02:10,496 [Executor task launch worker for task 36] INFO [org.apache.spark.executor.Executor] - Finished task 14.0 in stage 1.0 (TID 36). 1009 bytes result sent to driver
2021-12-03 23:02:10,496 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 14.0 in stage 1.0 (TID 36) in 109010 ms on localhost (executor driver) (16/22)
2021-12-03 23:02:16,629 [Executor task launch worker for task 43] INFO [org.apache.spark.executor.Executor] - Finished task 21.0 in stage 1.0 (TID 43). 1009 bytes result sent to driver
2021-12-03 23:02:16,630 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 21.0 in stage 1.0 (TID 43) in 80912 ms on localhost (executor driver) (17/22)
2021-12-03 23:02:18,293 [Executor task launch worker for task 39] INFO [org.apache.spark.executor.Executor] - Finished task 17.0 in stage 1.0 (TID 39). 1009 bytes result sent to driver
2021-12-03 23:02:18,293 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 17.0 in stage 1.0 (TID 39) in 102699 ms on localhost (executor driver) (18/22)
2021-12-03 23:02:19,588 [Executor task launch worker for task 42] INFO [org.apache.spark.executor.Executor] - Finished task 20.0 in stage 1.0 (TID 42). 1009 bytes result sent to driver
2021-12-03 23:02:19,588 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 20.0 in stage 1.0 (TID 42) in 89810 ms on localhost (executor driver) (19/22)
2021-12-03 23:02:53,443 [Executor task launch worker for task 38] INFO [org.apache.spark.executor.Executor] - Finished task 16.0 in stage 1.0 (TID 38). 1052 bytes result sent to driver
2021-12-03 23:02:53,444 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 16.0 in stage 1.0 (TID 38) in 140109 ms on localhost (executor driver) (20/22)
2021-12-03 23:02:54,124 [Executor task launch worker for task 41] INFO [org.apache.spark.executor.Executor] - Finished task 19.0 in stage 1.0 (TID 41). 1009 bytes result sent to driver
2021-12-03 23:02:54,125 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 19.0 in stage 1.0 (TID 41) in 126108 ms on localhost (executor driver) (21/22)
2021-12-03 23:02:54,943 [Executor task launch worker for task 40] INFO [org.apache.spark.executor.Executor] - Finished task 18.0 in stage 1.0 (TID 40). 1009 bytes result sent to driver
2021-12-03 23:02:54,943 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 18.0 in stage 1.0 (TID 40) in 132370 ms on localhost (executor driver) (22/22)
2021-12-03 23:02:54,943 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 1.0, whose tasks have all completed, from pool 
2021-12-03 23:02:54,943 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ShuffleMapStage 1 (map at PaidPromotionAdjustParameter.scala:67) finished in 282.326 s
2021-12-03 23:02:54,944 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - looking for newly runnable stages
2021-12-03 23:02:54,944 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - running: Set()
2021-12-03 23:02:54,944 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - waiting: Set(ResultStage 2)
2021-12-03 23:02:54,945 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - failed: Set()
2021-12-03 23:02:54,947 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 2 (ShuffledRDD[4] at reduceByKey at PaidPromotionAdjustParameter.scala:67), which has no missing parents
2021-12-03 23:02:54,952 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_3 stored as values in memory (estimated size 3.0 KB, free 1990.5 MB)
2021-12-03 23:02:54,954 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_3_piece0 stored as bytes in memory (estimated size 1906.0 B, free 1990.5 MB)
2021-12-03 23:02:54,954 [dispatcher-event-loop-3] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_3_piece0 in memory on qb:58628 (size: 1906.0 B, free: 1990.8 MB)
2021-12-03 23:02:54,954 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 3 from broadcast at DAGScheduler.scala:1039
2021-12-03 23:02:54,955 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 22 missing tasks from ResultStage 2 (ShuffledRDD[4] at reduceByKey at PaidPromotionAdjustParameter.scala:67) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14))
2021-12-03 23:02:54,955 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 2.0 with 22 tasks
2021-12-03 23:02:54,956 [dispatcher-event-loop-11] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 2.0 (TID 44, localhost, executor driver, partition 0, ANY, 7649 bytes)
2021-12-03 23:02:54,956 [dispatcher-event-loop-11] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 2.0 (TID 45, localhost, executor driver, partition 1, ANY, 7649 bytes)
2021-12-03 23:02:54,956 [dispatcher-event-loop-11] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 2.0 in stage 2.0 (TID 46, localhost, executor driver, partition 2, ANY, 7649 bytes)
2021-12-03 23:02:54,956 [dispatcher-event-loop-11] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 3.0 in stage 2.0 (TID 47, localhost, executor driver, partition 3, ANY, 7649 bytes)
2021-12-03 23:02:54,956 [dispatcher-event-loop-11] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 4.0 in stage 2.0 (TID 48, localhost, executor driver, partition 4, ANY, 7649 bytes)
2021-12-03 23:02:54,956 [dispatcher-event-loop-11] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 5.0 in stage 2.0 (TID 49, localhost, executor driver, partition 5, ANY, 7649 bytes)
2021-12-03 23:02:54,956 [dispatcher-event-loop-11] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 6.0 in stage 2.0 (TID 50, localhost, executor driver, partition 6, ANY, 7649 bytes)
2021-12-03 23:02:54,957 [dispatcher-event-loop-11] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 7.0 in stage 2.0 (TID 51, localhost, executor driver, partition 7, ANY, 7649 bytes)
2021-12-03 23:02:54,957 [dispatcher-event-loop-11] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 8.0 in stage 2.0 (TID 52, localhost, executor driver, partition 8, ANY, 7649 bytes)
2021-12-03 23:02:54,957 [dispatcher-event-loop-11] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 9.0 in stage 2.0 (TID 53, localhost, executor driver, partition 9, ANY, 7649 bytes)
2021-12-03 23:02:54,957 [dispatcher-event-loop-11] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 10.0 in stage 2.0 (TID 54, localhost, executor driver, partition 10, ANY, 7649 bytes)
2021-12-03 23:02:54,957 [dispatcher-event-loop-11] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 11.0 in stage 2.0 (TID 55, localhost, executor driver, partition 11, ANY, 7649 bytes)
2021-12-03 23:02:54,957 [Executor task launch worker for task 45] INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 2.0 (TID 45)
2021-12-03 23:02:54,957 [Executor task launch worker for task 46] INFO [org.apache.spark.executor.Executor] - Running task 2.0 in stage 2.0 (TID 46)
2021-12-03 23:02:54,957 [Executor task launch worker for task 53] INFO [org.apache.spark.executor.Executor] - Running task 9.0 in stage 2.0 (TID 53)
2021-12-03 23:02:54,957 [Executor task launch worker for task 51] INFO [org.apache.spark.executor.Executor] - Running task 7.0 in stage 2.0 (TID 51)
2021-12-03 23:02:54,957 [Executor task launch worker for task 49] INFO [org.apache.spark.executor.Executor] - Running task 5.0 in stage 2.0 (TID 49)
2021-12-03 23:02:54,957 [Executor task launch worker for task 52] INFO [org.apache.spark.executor.Executor] - Running task 8.0 in stage 2.0 (TID 52)
2021-12-03 23:02:54,957 [Executor task launch worker for task 44] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 2.0 (TID 44)
2021-12-03 23:02:54,957 [Executor task launch worker for task 50] INFO [org.apache.spark.executor.Executor] - Running task 6.0 in stage 2.0 (TID 50)
2021-12-03 23:02:54,957 [Executor task launch worker for task 48] INFO [org.apache.spark.executor.Executor] - Running task 4.0 in stage 2.0 (TID 48)
2021-12-03 23:02:54,957 [Executor task launch worker for task 47] INFO [org.apache.spark.executor.Executor] - Running task 3.0 in stage 2.0 (TID 47)
2021-12-03 23:02:54,958 [Executor task launch worker for task 54] INFO [org.apache.spark.executor.Executor] - Running task 10.0 in stage 2.0 (TID 54)
2021-12-03 23:02:54,958 [Executor task launch worker for task 55] INFO [org.apache.spark.executor.Executor] - Running task 11.0 in stage 2.0 (TID 55)
2021-12-03 23:02:54,971 [Executor task launch worker for task 48] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 23:02:54,971 [Executor task launch worker for task 50] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 23:02:54,971 [Executor task launch worker for task 52] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 23:02:54,971 [Executor task launch worker for task 45] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 23:02:54,971 [Executor task launch worker for task 55] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 23:02:54,971 [Executor task launch worker for task 44] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 23:02:54,971 [Executor task launch worker for task 46] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 23:02:54,971 [Executor task launch worker for task 51] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 23:02:54,971 [Executor task launch worker for task 54] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 23:02:54,971 [Executor task launch worker for task 47] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 23:02:54,971 [Executor task launch worker for task 53] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 23:02:54,971 [Executor task launch worker for task 49] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 23:02:54,973 [Executor task launch worker for task 54] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 6 ms
2021-12-03 23:02:54,973 [Executor task launch worker for task 47] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 6 ms
2021-12-03 23:02:54,974 [Executor task launch worker for task 48] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 7 ms
2021-12-03 23:02:54,974 [Executor task launch worker for task 51] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 7 ms
2021-12-03 23:02:54,973 [Executor task launch worker for task 49] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 6 ms
2021-12-03 23:02:54,973 [Executor task launch worker for task 44] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 6 ms
2021-12-03 23:02:54,973 [Executor task launch worker for task 52] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 6 ms
2021-12-03 23:02:54,973 [Executor task launch worker for task 53] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 6 ms
2021-12-03 23:02:54,973 [Executor task launch worker for task 46] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 6 ms
2021-12-03 23:02:54,973 [Executor task launch worker for task 55] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 6 ms
2021-12-03 23:02:54,973 [Executor task launch worker for task 45] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 6 ms
2021-12-03 23:02:54,973 [Executor task launch worker for task 50] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 6 ms
2021-12-03 23:02:55,397 [Executor task launch worker for task 44] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 2.0 (TID 44). 1098 bytes result sent to driver
2021-12-03 23:02:55,410 [dispatcher-event-loop-9] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 12.0 in stage 2.0 (TID 56, localhost, executor driver, partition 12, ANY, 7649 bytes)
2021-12-03 23:02:55,414 [Executor task launch worker for task 56] INFO [org.apache.spark.executor.Executor] - Running task 12.0 in stage 2.0 (TID 56)
2021-12-03 23:02:55,414 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 2.0 (TID 44) in 459 ms on localhost (executor driver) (1/22)
2021-12-03 23:02:55,415 [Executor task launch worker for task 56] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 23:02:55,415 [Executor task launch worker for task 56] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 23:02:55,420 [Executor task launch worker for task 51] INFO [org.apache.spark.executor.Executor] - Finished task 7.0 in stage 2.0 (TID 51). 1098 bytes result sent to driver
2021-12-03 23:02:55,420 [Executor task launch worker for task 45] INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 2.0 (TID 45). 1098 bytes result sent to driver
2021-12-03 23:02:55,420 [Executor task launch worker for task 54] INFO [org.apache.spark.executor.Executor] - Finished task 10.0 in stage 2.0 (TID 54). 1055 bytes result sent to driver
2021-12-03 23:02:55,420 [dispatcher-event-loop-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 13.0 in stage 2.0 (TID 57, localhost, executor driver, partition 13, ANY, 7649 bytes)
2021-12-03 23:02:55,421 [Executor task launch worker for task 46] INFO [org.apache.spark.executor.Executor] - Finished task 2.0 in stage 2.0 (TID 46). 1098 bytes result sent to driver
2021-12-03 23:02:55,421 [dispatcher-event-loop-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 14.0 in stage 2.0 (TID 58, localhost, executor driver, partition 14, ANY, 7649 bytes)
2021-12-03 23:02:55,421 [Executor task launch worker for task 53] INFO [org.apache.spark.executor.Executor] - Finished task 9.0 in stage 2.0 (TID 53). 1098 bytes result sent to driver
2021-12-03 23:02:55,421 [dispatcher-event-loop-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 15.0 in stage 2.0 (TID 59, localhost, executor driver, partition 15, ANY, 7649 bytes)
2021-12-03 23:02:55,421 [Executor task launch worker for task 57] INFO [org.apache.spark.executor.Executor] - Running task 13.0 in stage 2.0 (TID 57)
2021-12-03 23:02:55,421 [Executor task launch worker for task 52] INFO [org.apache.spark.executor.Executor] - Finished task 8.0 in stage 2.0 (TID 52). 1098 bytes result sent to driver
2021-12-03 23:02:55,421 [Executor task launch worker for task 59] INFO [org.apache.spark.executor.Executor] - Running task 15.0 in stage 2.0 (TID 59)
2021-12-03 23:02:55,421 [Executor task launch worker for task 55] INFO [org.apache.spark.executor.Executor] - Finished task 11.0 in stage 2.0 (TID 55). 1098 bytes result sent to driver
2021-12-03 23:02:55,421 [Executor task launch worker for task 49] INFO [org.apache.spark.executor.Executor] - Finished task 5.0 in stage 2.0 (TID 49). 1098 bytes result sent to driver
2021-12-03 23:02:55,421 [Executor task launch worker for task 58] INFO [org.apache.spark.executor.Executor] - Running task 14.0 in stage 2.0 (TID 58)
2021-12-03 23:02:55,421 [Executor task launch worker for task 48] INFO [org.apache.spark.executor.Executor] - Finished task 4.0 in stage 2.0 (TID 48). 1098 bytes result sent to driver
2021-12-03 23:02:55,422 [dispatcher-event-loop-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 16.0 in stage 2.0 (TID 60, localhost, executor driver, partition 16, ANY, 7649 bytes)
2021-12-03 23:02:55,422 [Executor task launch worker for task 60] INFO [org.apache.spark.executor.Executor] - Running task 16.0 in stage 2.0 (TID 60)
2021-12-03 23:02:55,422 [dispatcher-event-loop-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 17.0 in stage 2.0 (TID 61, localhost, executor driver, partition 17, ANY, 7649 bytes)
2021-12-03 23:02:55,422 [Executor task launch worker for task 61] INFO [org.apache.spark.executor.Executor] - Running task 17.0 in stage 2.0 (TID 61)
2021-12-03 23:02:55,422 [Executor task launch worker for task 59] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 23:02:55,422 [Executor task launch worker for task 50] INFO [org.apache.spark.executor.Executor] - Finished task 6.0 in stage 2.0 (TID 50). 1098 bytes result sent to driver
2021-12-03 23:02:55,422 [Executor task launch worker for task 59] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 23:02:55,423 [dispatcher-event-loop-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 18.0 in stage 2.0 (TID 62, localhost, executor driver, partition 18, ANY, 7649 bytes)
2021-12-03 23:02:55,423 [Executor task launch worker for task 57] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 23:02:55,423 [Executor task launch worker for task 57] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 1 ms
2021-12-03 23:02:55,423 [Executor task launch worker for task 62] INFO [org.apache.spark.executor.Executor] - Running task 18.0 in stage 2.0 (TID 62)
2021-12-03 23:02:55,423 [dispatcher-event-loop-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 19.0 in stage 2.0 (TID 63, localhost, executor driver, partition 19, ANY, 7649 bytes)
2021-12-03 23:02:55,423 [Executor task launch worker for task 58] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 23:02:55,423 [Executor task launch worker for task 58] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 23:02:55,423 [Executor task launch worker for task 63] INFO [org.apache.spark.executor.Executor] - Running task 19.0 in stage 2.0 (TID 63)
2021-12-03 23:02:55,423 [Executor task launch worker for task 60] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 23:02:55,423 [Executor task launch worker for task 60] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 23:02:55,423 [Executor task launch worker for task 61] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 23:02:55,423 [Executor task launch worker for task 61] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 23:02:55,423 [dispatcher-event-loop-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 20.0 in stage 2.0 (TID 64, localhost, executor driver, partition 20, ANY, 7649 bytes)
2021-12-03 23:02:55,424 [Executor task launch worker for task 64] INFO [org.apache.spark.executor.Executor] - Running task 20.0 in stage 2.0 (TID 64)
2021-12-03 23:02:55,424 [dispatcher-event-loop-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 21.0 in stage 2.0 (TID 65, localhost, executor driver, partition 21, ANY, 7649 bytes)
2021-12-03 23:02:55,424 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 7.0 in stage 2.0 (TID 51) in 468 ms on localhost (executor driver) (2/22)
2021-12-03 23:02:55,424 [Executor task launch worker for task 65] INFO [org.apache.spark.executor.Executor] - Running task 21.0 in stage 2.0 (TID 65)
2021-12-03 23:02:55,424 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 2.0 in stage 2.0 (TID 46) in 468 ms on localhost (executor driver) (3/22)
2021-12-03 23:02:55,424 [Executor task launch worker for task 63] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 23:02:55,424 [Executor task launch worker for task 63] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 23:02:55,424 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 9.0 in stage 2.0 (TID 53) in 467 ms on localhost (executor driver) (4/22)
2021-12-03 23:02:55,424 [Executor task launch worker for task 62] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 23:02:55,424 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 8.0 in stage 2.0 (TID 52) in 467 ms on localhost (executor driver) (5/22)
2021-12-03 23:02:55,424 [Executor task launch worker for task 62] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 23:02:55,424 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 11.0 in stage 2.0 (TID 55) in 467 ms on localhost (executor driver) (6/22)
2021-12-03 23:02:55,425 [Executor task launch worker for task 47] INFO [org.apache.spark.executor.Executor] - Finished task 3.0 in stage 2.0 (TID 47). 1098 bytes result sent to driver
2021-12-03 23:02:55,425 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 4.0 in stage 2.0 (TID 48) in 469 ms on localhost (executor driver) (7/22)
2021-12-03 23:02:55,425 [Executor task launch worker for task 64] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 23:02:55,425 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 2.0 (TID 45) in 469 ms on localhost (executor driver) (8/22)
2021-12-03 23:02:55,425 [Executor task launch worker for task 64] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 23:02:55,425 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 10.0 in stage 2.0 (TID 54) in 468 ms on localhost (executor driver) (9/22)
2021-12-03 23:02:55,425 [Executor task launch worker for task 65] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 23:02:55,425 [Executor task launch worker for task 65] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 23:02:55,425 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 3.0 in stage 2.0 (TID 47) in 469 ms on localhost (executor driver) (10/22)
2021-12-03 23:02:55,426 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 6.0 in stage 2.0 (TID 50) in 470 ms on localhost (executor driver) (11/22)
2021-12-03 23:02:55,426 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 5.0 in stage 2.0 (TID 49) in 470 ms on localhost (executor driver) (12/22)
2021-12-03 23:02:55,525 [Executor task launch worker for task 60] INFO [org.apache.spark.executor.Executor] - Finished task 16.0 in stage 2.0 (TID 60). 1055 bytes result sent to driver
2021-12-03 23:02:55,526 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 16.0 in stage 2.0 (TID 60) in 104 ms on localhost (executor driver) (13/22)
2021-12-03 23:02:55,527 [Executor task launch worker for task 61] INFO [org.apache.spark.executor.Executor] - Finished task 17.0 in stage 2.0 (TID 61). 1012 bytes result sent to driver
2021-12-03 23:02:55,528 [Executor task launch worker for task 63] INFO [org.apache.spark.executor.Executor] - Finished task 19.0 in stage 2.0 (TID 63). 1012 bytes result sent to driver
2021-12-03 23:02:55,528 [Executor task launch worker for task 65] INFO [org.apache.spark.executor.Executor] - Finished task 21.0 in stage 2.0 (TID 65). 1012 bytes result sent to driver
2021-12-03 23:02:55,528 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 17.0 in stage 2.0 (TID 61) in 106 ms on localhost (executor driver) (14/22)
2021-12-03 23:02:55,529 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 19.0 in stage 2.0 (TID 63) in 106 ms on localhost (executor driver) (15/22)
2021-12-03 23:02:55,529 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 21.0 in stage 2.0 (TID 65) in 105 ms on localhost (executor driver) (16/22)
2021-12-03 23:02:55,529 [Executor task launch worker for task 57] INFO [org.apache.spark.executor.Executor] - Finished task 13.0 in stage 2.0 (TID 57). 1012 bytes result sent to driver
2021-12-03 23:02:55,530 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 13.0 in stage 2.0 (TID 57) in 110 ms on localhost (executor driver) (17/22)
2021-12-03 23:02:55,532 [Executor task launch worker for task 62] INFO [org.apache.spark.executor.Executor] - Finished task 18.0 in stage 2.0 (TID 62). 1055 bytes result sent to driver
2021-12-03 23:02:55,532 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 18.0 in stage 2.0 (TID 62) in 110 ms on localhost (executor driver) (18/22)
2021-12-03 23:02:55,533 [Executor task launch worker for task 64] INFO [org.apache.spark.executor.Executor] - Finished task 20.0 in stage 2.0 (TID 64). 1055 bytes result sent to driver
2021-12-03 23:02:55,534 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 20.0 in stage 2.0 (TID 64) in 110 ms on localhost (executor driver) (19/22)
2021-12-03 23:02:55,536 [Executor task launch worker for task 59] INFO [org.apache.spark.executor.Executor] - Finished task 15.0 in stage 2.0 (TID 59). 1012 bytes result sent to driver
2021-12-03 23:02:55,536 [Executor task launch worker for task 58] INFO [org.apache.spark.executor.Executor] - Finished task 14.0 in stage 2.0 (TID 58). 1055 bytes result sent to driver
2021-12-03 23:02:55,536 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 15.0 in stage 2.0 (TID 59) in 115 ms on localhost (executor driver) (20/22)
2021-12-03 23:02:55,536 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 14.0 in stage 2.0 (TID 58) in 115 ms on localhost (executor driver) (21/22)
2021-12-03 23:02:55,536 [Executor task launch worker for task 56] INFO [org.apache.spark.executor.Executor] - Finished task 12.0 in stage 2.0 (TID 56). 1012 bytes result sent to driver
2021-12-03 23:02:55,536 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 12.0 in stage 2.0 (TID 56) in 127 ms on localhost (executor driver) (22/22)
2021-12-03 23:02:55,537 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 2.0, whose tasks have all completed, from pool 
2021-12-03 23:02:55,537 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 2 (count at PaidPromotionAdjustParameter.scala:68) finished in 0.587 s
2021-12-03 23:02:55,537 [main] INFO [org.apache.spark.scheduler.DAGScheduler] - Job 1 finished: count at PaidPromotionAdjustParameter.scala:68, took 282.930853 s
2021-12-03 23:02:55,537 [main] INFO [PaidPromotion$] - 用户总数1207347
2021-12-03 23:02:55,557 [main] INFO [org.apache.spark.SparkContext] - Starting job: sortByKey at PaidPromotionAdjustParameter.scala:73
2021-12-03 23:02:55,558 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 2 (sortByKey at PaidPromotionAdjustParameter.scala:73) with 22 output partitions
2021-12-03 23:02:55,558 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 4 (sortByKey at PaidPromotionAdjustParameter.scala:73)
2021-12-03 23:02:55,558 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 3)
2021-12-03 23:02:55,558 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2021-12-03 23:02:55,558 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 4 (MapPartitionsRDD[7] at sortByKey at PaidPromotionAdjustParameter.scala:73), which has no missing parents
2021-12-03 23:02:55,561 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_4 stored as values in memory (estimated size 4.1 KB, free 1990.5 MB)
2021-12-03 23:02:55,563 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_4_piece0 stored as bytes in memory (estimated size 2.4 KB, free 1990.4 MB)
2021-12-03 23:02:55,563 [dispatcher-event-loop-3] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_4_piece0 in memory on qb:58628 (size: 2.4 KB, free: 1990.8 MB)
2021-12-03 23:02:55,563 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 4 from broadcast at DAGScheduler.scala:1039
2021-12-03 23:02:55,563 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 22 missing tasks from ResultStage 4 (MapPartitionsRDD[7] at sortByKey at PaidPromotionAdjustParameter.scala:73) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14))
2021-12-03 23:02:55,563 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 4.0 with 22 tasks
2021-12-03 23:02:55,564 [dispatcher-event-loop-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 4.0 (TID 66, localhost, executor driver, partition 0, ANY, 7649 bytes)
2021-12-03 23:02:55,564 [dispatcher-event-loop-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 4.0 (TID 67, localhost, executor driver, partition 1, ANY, 7649 bytes)
2021-12-03 23:02:55,564 [dispatcher-event-loop-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 2.0 in stage 4.0 (TID 68, localhost, executor driver, partition 2, ANY, 7649 bytes)
2021-12-03 23:02:55,564 [dispatcher-event-loop-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 3.0 in stage 4.0 (TID 69, localhost, executor driver, partition 3, ANY, 7649 bytes)
2021-12-03 23:02:55,565 [dispatcher-event-loop-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 4.0 in stage 4.0 (TID 70, localhost, executor driver, partition 4, ANY, 7649 bytes)
2021-12-03 23:02:55,565 [dispatcher-event-loop-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 5.0 in stage 4.0 (TID 71, localhost, executor driver, partition 5, ANY, 7649 bytes)
2021-12-03 23:02:55,565 [dispatcher-event-loop-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 6.0 in stage 4.0 (TID 72, localhost, executor driver, partition 6, ANY, 7649 bytes)
2021-12-03 23:02:55,565 [dispatcher-event-loop-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 7.0 in stage 4.0 (TID 73, localhost, executor driver, partition 7, ANY, 7649 bytes)
2021-12-03 23:02:55,565 [dispatcher-event-loop-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 8.0 in stage 4.0 (TID 74, localhost, executor driver, partition 8, ANY, 7649 bytes)
2021-12-03 23:02:55,565 [dispatcher-event-loop-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 9.0 in stage 4.0 (TID 75, localhost, executor driver, partition 9, ANY, 7649 bytes)
2021-12-03 23:02:55,565 [dispatcher-event-loop-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 10.0 in stage 4.0 (TID 76, localhost, executor driver, partition 10, ANY, 7649 bytes)
2021-12-03 23:02:55,565 [dispatcher-event-loop-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 11.0 in stage 4.0 (TID 77, localhost, executor driver, partition 11, ANY, 7649 bytes)
2021-12-03 23:02:55,565 [Executor task launch worker for task 66] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 4.0 (TID 66)
2021-12-03 23:02:55,565 [Executor task launch worker for task 69] INFO [org.apache.spark.executor.Executor] - Running task 3.0 in stage 4.0 (TID 69)
2021-12-03 23:02:55,565 [Executor task launch worker for task 73] INFO [org.apache.spark.executor.Executor] - Running task 7.0 in stage 4.0 (TID 73)
2021-12-03 23:02:55,565 [Executor task launch worker for task 76] INFO [org.apache.spark.executor.Executor] - Running task 10.0 in stage 4.0 (TID 76)
2021-12-03 23:02:55,565 [Executor task launch worker for task 71] INFO [org.apache.spark.executor.Executor] - Running task 5.0 in stage 4.0 (TID 71)
2021-12-03 23:02:55,565 [Executor task launch worker for task 70] INFO [org.apache.spark.executor.Executor] - Running task 4.0 in stage 4.0 (TID 70)
2021-12-03 23:02:55,565 [Executor task launch worker for task 72] INFO [org.apache.spark.executor.Executor] - Running task 6.0 in stage 4.0 (TID 72)
2021-12-03 23:02:55,565 [Executor task launch worker for task 67] INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 4.0 (TID 67)
2021-12-03 23:02:55,565 [Executor task launch worker for task 68] INFO [org.apache.spark.executor.Executor] - Running task 2.0 in stage 4.0 (TID 68)
2021-12-03 23:02:55,565 [Executor task launch worker for task 77] INFO [org.apache.spark.executor.Executor] - Running task 11.0 in stage 4.0 (TID 77)
2021-12-03 23:02:55,565 [Executor task launch worker for task 75] INFO [org.apache.spark.executor.Executor] - Running task 9.0 in stage 4.0 (TID 75)
2021-12-03 23:02:55,565 [Executor task launch worker for task 74] INFO [org.apache.spark.executor.Executor] - Running task 8.0 in stage 4.0 (TID 74)
2021-12-03 23:02:55,567 [Executor task launch worker for task 68] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 23:02:55,567 [Executor task launch worker for task 72] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 23:02:55,567 [Executor task launch worker for task 68] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 23:02:55,567 [Executor task launch worker for task 67] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 23:02:55,567 [Executor task launch worker for task 72] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 23:02:55,567 [Executor task launch worker for task 67] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 23:02:55,567 [Executor task launch worker for task 66] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 23:02:55,567 [Executor task launch worker for task 77] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 23:02:55,567 [Executor task launch worker for task 66] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 23:02:55,567 [Executor task launch worker for task 77] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 23:02:55,567 [Executor task launch worker for task 69] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 23:02:55,567 [Executor task launch worker for task 69] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 23:02:55,567 [Executor task launch worker for task 71] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 23:02:55,567 [Executor task launch worker for task 71] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 23:02:55,567 [Executor task launch worker for task 75] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 23:02:55,567 [Executor task launch worker for task 75] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 23:02:55,567 [Executor task launch worker for task 73] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 23:02:55,567 [Executor task launch worker for task 73] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 23:02:55,567 [Executor task launch worker for task 76] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 23:02:55,567 [Executor task launch worker for task 76] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 23:02:55,567 [Executor task launch worker for task 70] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 23:02:55,567 [Executor task launch worker for task 70] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 23:02:55,567 [Executor task launch worker for task 74] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 23:02:55,567 [Executor task launch worker for task 74] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 23:02:55,677 [Executor task launch worker for task 74] INFO [org.apache.spark.executor.Executor] - Finished task 8.0 in stage 4.0 (TID 74). 1144 bytes result sent to driver
2021-12-03 23:02:55,678 [dispatcher-event-loop-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 12.0 in stage 4.0 (TID 78, localhost, executor driver, partition 12, ANY, 7649 bytes)
2021-12-03 23:02:55,678 [Executor task launch worker for task 78] INFO [org.apache.spark.executor.Executor] - Running task 12.0 in stage 4.0 (TID 78)
2021-12-03 23:02:55,678 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 8.0 in stage 4.0 (TID 74) in 113 ms on localhost (executor driver) (1/22)
2021-12-03 23:02:55,679 [Executor task launch worker for task 78] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 23:02:55,679 [Executor task launch worker for task 78] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 23:02:55,684 [Executor task launch worker for task 76] INFO [org.apache.spark.executor.Executor] - Finished task 10.0 in stage 4.0 (TID 76). 1101 bytes result sent to driver
2021-12-03 23:02:55,684 [dispatcher-event-loop-6] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 13.0 in stage 4.0 (TID 79, localhost, executor driver, partition 13, ANY, 7649 bytes)
2021-12-03 23:02:55,684 [Executor task launch worker for task 79] INFO [org.apache.spark.executor.Executor] - Running task 13.0 in stage 4.0 (TID 79)
2021-12-03 23:02:55,685 [Executor task launch worker for task 79] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 23:02:55,685 [Executor task launch worker for task 79] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 23:02:55,686 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 10.0 in stage 4.0 (TID 76) in 121 ms on localhost (executor driver) (2/22)
2021-12-03 23:02:55,688 [Executor task launch worker for task 72] INFO [org.apache.spark.executor.Executor] - Finished task 6.0 in stage 4.0 (TID 72). 1095 bytes result sent to driver
2021-12-03 23:02:55,690 [Executor task launch worker for task 66] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 4.0 (TID 66). 1145 bytes result sent to driver
2021-12-03 23:02:55,691 [dispatcher-event-loop-9] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 14.0 in stage 4.0 (TID 80, localhost, executor driver, partition 14, ANY, 7649 bytes)
2021-12-03 23:02:55,691 [dispatcher-event-loop-9] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 15.0 in stage 4.0 (TID 81, localhost, executor driver, partition 15, ANY, 7649 bytes)
2021-12-03 23:02:55,691 [Executor task launch worker for task 68] INFO [org.apache.spark.executor.Executor] - Finished task 2.0 in stage 4.0 (TID 68). 1146 bytes result sent to driver
2021-12-03 23:02:55,691 [Executor task launch worker for task 80] INFO [org.apache.spark.executor.Executor] - Running task 14.0 in stage 4.0 (TID 80)
2021-12-03 23:02:55,692 [Executor task launch worker for task 81] INFO [org.apache.spark.executor.Executor] - Running task 15.0 in stage 4.0 (TID 81)
2021-12-03 23:02:55,692 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 6.0 in stage 4.0 (TID 72) in 127 ms on localhost (executor driver) (3/22)
2021-12-03 23:02:55,692 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 4.0 (TID 66) in 128 ms on localhost (executor driver) (4/22)
2021-12-03 23:02:55,693 [Executor task launch worker for task 81] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 23:02:55,693 [Executor task launch worker for task 81] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 1 ms
2021-12-03 23:02:55,694 [dispatcher-event-loop-5] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 16.0 in stage 4.0 (TID 82, localhost, executor driver, partition 16, ANY, 7649 bytes)
2021-12-03 23:02:55,694 [Executor task launch worker for task 82] INFO [org.apache.spark.executor.Executor] - Running task 16.0 in stage 4.0 (TID 82)
2021-12-03 23:02:55,695 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 2.0 in stage 4.0 (TID 68) in 131 ms on localhost (executor driver) (5/22)
2021-12-03 23:02:55,695 [Executor task launch worker for task 73] INFO [org.apache.spark.executor.Executor] - Finished task 7.0 in stage 4.0 (TID 73). 1143 bytes result sent to driver
2021-12-03 23:02:55,695 [dispatcher-event-loop-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 17.0 in stage 4.0 (TID 83, localhost, executor driver, partition 17, ANY, 7649 bytes)
2021-12-03 23:02:55,695 [Executor task launch worker for task 82] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 23:02:55,696 [Executor task launch worker for task 82] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 1 ms
2021-12-03 23:02:55,696 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 7.0 in stage 4.0 (TID 73) in 131 ms on localhost (executor driver) (6/22)
2021-12-03 23:02:55,696 [Executor task launch worker for task 83] INFO [org.apache.spark.executor.Executor] - Running task 17.0 in stage 4.0 (TID 83)
2021-12-03 23:02:55,696 [Executor task launch worker for task 80] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 23:02:55,696 [Executor task launch worker for task 80] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 23:02:55,696 [Executor task launch worker for task 67] INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 4.0 (TID 67). 1140 bytes result sent to driver
2021-12-03 23:02:55,696 [Executor task launch worker for task 83] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 23:02:55,696 [Executor task launch worker for task 77] INFO [org.apache.spark.executor.Executor] - Finished task 11.0 in stage 4.0 (TID 77). 1142 bytes result sent to driver
2021-12-03 23:02:55,697 [Executor task launch worker for task 83] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 1 ms
2021-12-03 23:02:55,697 [dispatcher-event-loop-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 18.0 in stage 4.0 (TID 84, localhost, executor driver, partition 18, ANY, 7649 bytes)
2021-12-03 23:02:55,698 [Executor task launch worker for task 84] INFO [org.apache.spark.executor.Executor] - Running task 18.0 in stage 4.0 (TID 84)
2021-12-03 23:02:55,698 [dispatcher-event-loop-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 19.0 in stage 4.0 (TID 85, localhost, executor driver, partition 19, ANY, 7649 bytes)
2021-12-03 23:02:55,698 [Executor task launch worker for task 85] INFO [org.apache.spark.executor.Executor] - Running task 19.0 in stage 4.0 (TID 85)
2021-12-03 23:02:55,698 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 4.0 (TID 67) in 134 ms on localhost (executor driver) (7/22)
2021-12-03 23:02:55,698 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 11.0 in stage 4.0 (TID 77) in 133 ms on localhost (executor driver) (8/22)
2021-12-03 23:02:55,698 [Executor task launch worker for task 71] INFO [org.apache.spark.executor.Executor] - Finished task 5.0 in stage 4.0 (TID 71). 1146 bytes result sent to driver
2021-12-03 23:02:55,699 [Executor task launch worker for task 85] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 23:02:55,699 [Executor task launch worker for task 85] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 23:02:55,699 [Executor task launch worker for task 84] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 23:02:55,699 [Executor task launch worker for task 84] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 23:02:55,699 [dispatcher-event-loop-9] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 20.0 in stage 4.0 (TID 86, localhost, executor driver, partition 20, ANY, 7649 bytes)
2021-12-03 23:02:55,699 [Executor task launch worker for task 86] INFO [org.apache.spark.executor.Executor] - Running task 20.0 in stage 4.0 (TID 86)
2021-12-03 23:02:55,699 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 5.0 in stage 4.0 (TID 71) in 134 ms on localhost (executor driver) (9/22)
2021-12-03 23:02:55,700 [Executor task launch worker for task 75] INFO [org.apache.spark.executor.Executor] - Finished task 9.0 in stage 4.0 (TID 75). 1149 bytes result sent to driver
2021-12-03 23:02:55,700 [dispatcher-event-loop-8] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 21.0 in stage 4.0 (TID 87, localhost, executor driver, partition 21, ANY, 7649 bytes)
2021-12-03 23:02:55,700 [Executor task launch worker for task 87] INFO [org.apache.spark.executor.Executor] - Running task 21.0 in stage 4.0 (TID 87)
2021-12-03 23:02:55,700 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 9.0 in stage 4.0 (TID 75) in 135 ms on localhost (executor driver) (10/22)
2021-12-03 23:02:55,701 [Executor task launch worker for task 86] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 23:02:55,701 [Executor task launch worker for task 86] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 23:02:55,701 [Executor task launch worker for task 87] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 23:02:55,701 [Executor task launch worker for task 87] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 23:02:55,702 [Executor task launch worker for task 70] INFO [org.apache.spark.executor.Executor] - Finished task 4.0 in stage 4.0 (TID 70). 1101 bytes result sent to driver
2021-12-03 23:02:55,702 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 4.0 in stage 4.0 (TID 70) in 138 ms on localhost (executor driver) (11/22)
2021-12-03 23:02:55,703 [Executor task launch worker for task 69] INFO [org.apache.spark.executor.Executor] - Finished task 3.0 in stage 4.0 (TID 69). 1141 bytes result sent to driver
2021-12-03 23:02:55,703 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 3.0 in stage 4.0 (TID 69) in 139 ms on localhost (executor driver) (12/22)
2021-12-03 23:02:55,790 [Executor task launch worker for task 78] INFO [org.apache.spark.executor.Executor] - Finished task 12.0 in stage 4.0 (TID 78). 1185 bytes result sent to driver
2021-12-03 23:02:55,790 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 12.0 in stage 4.0 (TID 78) in 112 ms on localhost (executor driver) (13/22)
2021-12-03 23:02:55,794 [Executor task launch worker for task 80] INFO [org.apache.spark.executor.Executor] - Finished task 14.0 in stage 4.0 (TID 80). 1142 bytes result sent to driver
2021-12-03 23:02:55,794 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 14.0 in stage 4.0 (TID 80) in 104 ms on localhost (executor driver) (14/22)
2021-12-03 23:02:55,795 [Executor task launch worker for task 81] INFO [org.apache.spark.executor.Executor] - Finished task 15.0 in stage 4.0 (TID 81). 1137 bytes result sent to driver
2021-12-03 23:02:55,795 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 15.0 in stage 4.0 (TID 81) in 104 ms on localhost (executor driver) (15/22)
2021-12-03 23:02:55,795 [Executor task launch worker for task 86] INFO [org.apache.spark.executor.Executor] - Finished task 20.0 in stage 4.0 (TID 86). 1189 bytes result sent to driver
2021-12-03 23:02:55,795 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 20.0 in stage 4.0 (TID 86) in 96 ms on localhost (executor driver) (16/22)
2021-12-03 23:02:55,796 [Executor task launch worker for task 83] INFO [org.apache.spark.executor.Executor] - Finished task 17.0 in stage 4.0 (TID 83). 1142 bytes result sent to driver
2021-12-03 23:02:55,796 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 17.0 in stage 4.0 (TID 83) in 101 ms on localhost (executor driver) (17/22)
2021-12-03 23:02:55,797 [Executor task launch worker for task 85] INFO [org.apache.spark.executor.Executor] - Finished task 19.0 in stage 4.0 (TID 85). 1146 bytes result sent to driver
2021-12-03 23:02:55,797 [Executor task launch worker for task 87] INFO [org.apache.spark.executor.Executor] - Finished task 21.0 in stage 4.0 (TID 87). 1230 bytes result sent to driver
2021-12-03 23:02:55,797 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 19.0 in stage 4.0 (TID 85) in 100 ms on localhost (executor driver) (18/22)
2021-12-03 23:02:55,797 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 21.0 in stage 4.0 (TID 87) in 97 ms on localhost (executor driver) (19/22)
2021-12-03 23:02:55,803 [Executor task launch worker for task 79] INFO [org.apache.spark.executor.Executor] - Finished task 13.0 in stage 4.0 (TID 79). 1141 bytes result sent to driver
2021-12-03 23:02:55,803 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 13.0 in stage 4.0 (TID 79) in 119 ms on localhost (executor driver) (20/22)
2021-12-03 23:02:55,807 [Executor task launch worker for task 84] INFO [org.apache.spark.executor.Executor] - Finished task 18.0 in stage 4.0 (TID 84). 1137 bytes result sent to driver
2021-12-03 23:02:55,807 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 18.0 in stage 4.0 (TID 84) in 110 ms on localhost (executor driver) (21/22)
2021-12-03 23:02:55,812 [Executor task launch worker for task 82] INFO [org.apache.spark.executor.Executor] - Finished task 16.0 in stage 4.0 (TID 82). 1186 bytes result sent to driver
2021-12-03 23:02:55,812 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 16.0 in stage 4.0 (TID 82) in 118 ms on localhost (executor driver) (22/22)
2021-12-03 23:02:55,812 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 4.0, whose tasks have all completed, from pool 
2021-12-03 23:02:55,813 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 4 (sortByKey at PaidPromotionAdjustParameter.scala:73) finished in 0.253 s
2021-12-03 23:02:55,813 [main] INFO [org.apache.spark.scheduler.DAGScheduler] - Job 2 finished: sortByKey at PaidPromotionAdjustParameter.scala:73, took 0.255733 s
2021-12-03 23:02:55,827 [main] INFO [org.apache.spark.SparkContext] - Starting job: zipWithIndex at PaidPromotionAdjustParameter.scala:74
2021-12-03 23:02:55,828 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 5 (map at PaidPromotionAdjustParameter.scala:72)
2021-12-03 23:02:55,828 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 3 (zipWithIndex at PaidPromotionAdjustParameter.scala:74) with 21 output partitions
2021-12-03 23:02:55,828 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 7 (zipWithIndex at PaidPromotionAdjustParameter.scala:74)
2021-12-03 23:02:55,828 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 6)
2021-12-03 23:02:55,828 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List(ShuffleMapStage 6)
2021-12-03 23:02:55,829 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ShuffleMapStage 6 (MapPartitionsRDD[5] at map at PaidPromotionAdjustParameter.scala:72), which has no missing parents
2021-12-03 23:02:55,834 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_5 stored as values in memory (estimated size 4.1 KB, free 1990.4 MB)
2021-12-03 23:02:55,836 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_5_piece0 stored as bytes in memory (estimated size 2.4 KB, free 1990.4 MB)
2021-12-03 23:02:55,837 [dispatcher-event-loop-10] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_5_piece0 in memory on qb:58628 (size: 2.4 KB, free: 1990.8 MB)
2021-12-03 23:02:55,837 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 5 from broadcast at DAGScheduler.scala:1039
2021-12-03 23:02:55,837 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 22 missing tasks from ShuffleMapStage 6 (MapPartitionsRDD[5] at map at PaidPromotionAdjustParameter.scala:72) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14))
2021-12-03 23:02:55,837 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 6.0 with 22 tasks
2021-12-03 23:02:55,838 [dispatcher-event-loop-11] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 6.0 (TID 88, localhost, executor driver, partition 0, ANY, 7638 bytes)
2021-12-03 23:02:55,838 [dispatcher-event-loop-11] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 6.0 (TID 89, localhost, executor driver, partition 1, ANY, 7638 bytes)
2021-12-03 23:02:55,838 [dispatcher-event-loop-11] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 2.0 in stage 6.0 (TID 90, localhost, executor driver, partition 2, ANY, 7638 bytes)
2021-12-03 23:02:55,838 [dispatcher-event-loop-11] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 3.0 in stage 6.0 (TID 91, localhost, executor driver, partition 3, ANY, 7638 bytes)
2021-12-03 23:02:55,838 [dispatcher-event-loop-11] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 4.0 in stage 6.0 (TID 92, localhost, executor driver, partition 4, ANY, 7638 bytes)
2021-12-03 23:02:55,838 [dispatcher-event-loop-11] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 5.0 in stage 6.0 (TID 93, localhost, executor driver, partition 5, ANY, 7638 bytes)
2021-12-03 23:02:55,838 [dispatcher-event-loop-11] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 6.0 in stage 6.0 (TID 94, localhost, executor driver, partition 6, ANY, 7638 bytes)
2021-12-03 23:02:55,838 [dispatcher-event-loop-11] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 7.0 in stage 6.0 (TID 95, localhost, executor driver, partition 7, ANY, 7638 bytes)
2021-12-03 23:02:55,838 [dispatcher-event-loop-11] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 8.0 in stage 6.0 (TID 96, localhost, executor driver, partition 8, ANY, 7638 bytes)
2021-12-03 23:02:55,838 [dispatcher-event-loop-11] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 9.0 in stage 6.0 (TID 97, localhost, executor driver, partition 9, ANY, 7638 bytes)
2021-12-03 23:02:55,838 [dispatcher-event-loop-11] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 10.0 in stage 6.0 (TID 98, localhost, executor driver, partition 10, ANY, 7638 bytes)
2021-12-03 23:02:55,839 [dispatcher-event-loop-11] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 11.0 in stage 6.0 (TID 99, localhost, executor driver, partition 11, ANY, 7638 bytes)
2021-12-03 23:02:55,839 [Executor task launch worker for task 89] INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 6.0 (TID 89)
2021-12-03 23:02:55,839 [Executor task launch worker for task 91] INFO [org.apache.spark.executor.Executor] - Running task 3.0 in stage 6.0 (TID 91)
2021-12-03 23:02:55,839 [Executor task launch worker for task 99] INFO [org.apache.spark.executor.Executor] - Running task 11.0 in stage 6.0 (TID 99)
2021-12-03 23:02:55,839 [Executor task launch worker for task 98] INFO [org.apache.spark.executor.Executor] - Running task 10.0 in stage 6.0 (TID 98)
2021-12-03 23:02:55,839 [Executor task launch worker for task 97] INFO [org.apache.spark.executor.Executor] - Running task 9.0 in stage 6.0 (TID 97)
2021-12-03 23:02:55,839 [Executor task launch worker for task 96] INFO [org.apache.spark.executor.Executor] - Running task 8.0 in stage 6.0 (TID 96)
2021-12-03 23:02:55,839 [Executor task launch worker for task 95] INFO [org.apache.spark.executor.Executor] - Running task 7.0 in stage 6.0 (TID 95)
2021-12-03 23:02:55,839 [Executor task launch worker for task 92] INFO [org.apache.spark.executor.Executor] - Running task 4.0 in stage 6.0 (TID 92)
2021-12-03 23:02:55,839 [Executor task launch worker for task 93] INFO [org.apache.spark.executor.Executor] - Running task 5.0 in stage 6.0 (TID 93)
2021-12-03 23:02:55,839 [Executor task launch worker for task 94] INFO [org.apache.spark.executor.Executor] - Running task 6.0 in stage 6.0 (TID 94)
2021-12-03 23:02:55,839 [Executor task launch worker for task 88] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 6.0 (TID 88)
2021-12-03 23:02:55,839 [Executor task launch worker for task 90] INFO [org.apache.spark.executor.Executor] - Running task 2.0 in stage 6.0 (TID 90)
2021-12-03 23:02:55,846 [Executor task launch worker for task 92] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 23:02:55,846 [Executor task launch worker for task 93] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 23:02:55,846 [Executor task launch worker for task 96] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 23:02:55,846 [Executor task launch worker for task 92] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 23:02:55,846 [Executor task launch worker for task 88] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 23:02:55,846 [Executor task launch worker for task 96] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 23:02:55,846 [Executor task launch worker for task 93] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 23:02:55,847 [Executor task launch worker for task 90] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 23:02:55,847 [Executor task launch worker for task 94] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 23:02:55,847 [Executor task launch worker for task 95] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 23:02:55,847 [Executor task launch worker for task 88] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 1 ms
2021-12-03 23:02:55,847 [Executor task launch worker for task 95] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 1 ms
2021-12-03 23:02:55,847 [Executor task launch worker for task 97] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 23:02:55,847 [Executor task launch worker for task 99] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 23:02:55,847 [Executor task launch worker for task 97] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 23:02:55,847 [Executor task launch worker for task 94] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 1 ms
2021-12-03 23:02:55,847 [Executor task launch worker for task 89] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 23:02:55,847 [Executor task launch worker for task 90] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 1 ms
2021-12-03 23:02:55,847 [Executor task launch worker for task 89] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 23:02:55,847 [Executor task launch worker for task 98] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 23:02:55,847 [Executor task launch worker for task 99] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 23:02:55,847 [Executor task launch worker for task 98] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 23:02:55,847 [Executor task launch worker for task 91] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 23:02:55,847 [Executor task launch worker for task 91] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 23:02:56,260 [Executor task launch worker for task 99] INFO [org.apache.spark.executor.Executor] - Finished task 11.0 in stage 6.0 (TID 99). 1267 bytes result sent to driver
2021-12-03 23:02:56,261 [dispatcher-event-loop-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 12.0 in stage 6.0 (TID 100, localhost, executor driver, partition 12, ANY, 7638 bytes)
2021-12-03 23:02:56,261 [Executor task launch worker for task 100] INFO [org.apache.spark.executor.Executor] - Running task 12.0 in stage 6.0 (TID 100)
2021-12-03 23:02:56,261 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 11.0 in stage 6.0 (TID 99) in 422 ms on localhost (executor driver) (1/22)
2021-12-03 23:02:56,264 [Executor task launch worker for task 100] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 23:02:56,264 [Executor task launch worker for task 100] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 23:02:56,271 [Executor task launch worker for task 92] INFO [org.apache.spark.executor.Executor] - Finished task 4.0 in stage 6.0 (TID 92). 1267 bytes result sent to driver
2021-12-03 23:02:56,272 [dispatcher-event-loop-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 13.0 in stage 6.0 (TID 101, localhost, executor driver, partition 13, ANY, 7638 bytes)
2021-12-03 23:02:56,272 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 4.0 in stage 6.0 (TID 92) in 434 ms on localhost (executor driver) (2/22)
2021-12-03 23:02:56,272 [Executor task launch worker for task 101] INFO [org.apache.spark.executor.Executor] - Running task 13.0 in stage 6.0 (TID 101)
2021-12-03 23:02:56,273 [Executor task launch worker for task 96] INFO [org.apache.spark.executor.Executor] - Finished task 8.0 in stage 6.0 (TID 96). 1267 bytes result sent to driver
2021-12-03 23:02:56,274 [dispatcher-event-loop-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 14.0 in stage 6.0 (TID 102, localhost, executor driver, partition 14, ANY, 7638 bytes)
2021-12-03 23:02:56,274 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 8.0 in stage 6.0 (TID 96) in 436 ms on localhost (executor driver) (3/22)
2021-12-03 23:02:56,274 [Executor task launch worker for task 97] INFO [org.apache.spark.executor.Executor] - Finished task 9.0 in stage 6.0 (TID 97). 1267 bytes result sent to driver
2021-12-03 23:02:56,274 [Executor task launch worker for task 102] INFO [org.apache.spark.executor.Executor] - Running task 14.0 in stage 6.0 (TID 102)
2021-12-03 23:02:56,275 [dispatcher-event-loop-9] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 15.0 in stage 6.0 (TID 103, localhost, executor driver, partition 15, ANY, 7638 bytes)
2021-12-03 23:02:56,275 [Executor task launch worker for task 103] INFO [org.apache.spark.executor.Executor] - Running task 15.0 in stage 6.0 (TID 103)
2021-12-03 23:02:56,275 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 9.0 in stage 6.0 (TID 97) in 437 ms on localhost (executor driver) (4/22)
2021-12-03 23:02:56,278 [Executor task launch worker for task 102] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 23:02:56,278 [Executor task launch worker for task 102] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 23:02:56,278 [Executor task launch worker for task 103] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 23:02:56,278 [Executor task launch worker for task 103] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 23:02:56,279 [Executor task launch worker for task 101] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 23:02:56,279 [Executor task launch worker for task 101] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 2 ms
2021-12-03 23:02:56,288 [Executor task launch worker for task 95] INFO [org.apache.spark.executor.Executor] - Finished task 7.0 in stage 6.0 (TID 95). 1224 bytes result sent to driver
2021-12-03 23:02:56,288 [dispatcher-event-loop-4] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 16.0 in stage 6.0 (TID 104, localhost, executor driver, partition 16, ANY, 7638 bytes)
2021-12-03 23:02:56,289 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 7.0 in stage 6.0 (TID 95) in 451 ms on localhost (executor driver) (5/22)
2021-12-03 23:02:56,289 [Executor task launch worker for task 104] INFO [org.apache.spark.executor.Executor] - Running task 16.0 in stage 6.0 (TID 104)
2021-12-03 23:02:56,290 [Executor task launch worker for task 93] INFO [org.apache.spark.executor.Executor] - Finished task 5.0 in stage 6.0 (TID 93). 1224 bytes result sent to driver
2021-12-03 23:02:56,290 [Executor task launch worker for task 88] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 6.0 (TID 88). 1224 bytes result sent to driver
2021-12-03 23:02:56,291 [Executor task launch worker for task 94] INFO [org.apache.spark.executor.Executor] - Finished task 6.0 in stage 6.0 (TID 94). 1224 bytes result sent to driver
2021-12-03 23:02:56,292 [dispatcher-event-loop-10] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 17.0 in stage 6.0 (TID 105, localhost, executor driver, partition 17, ANY, 7638 bytes)
2021-12-03 23:02:56,292 [dispatcher-event-loop-10] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 18.0 in stage 6.0 (TID 106, localhost, executor driver, partition 18, ANY, 7638 bytes)
2021-12-03 23:02:56,292 [dispatcher-event-loop-10] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 19.0 in stage 6.0 (TID 107, localhost, executor driver, partition 19, ANY, 7638 bytes)
2021-12-03 23:02:56,292 [Executor task launch worker for task 107] INFO [org.apache.spark.executor.Executor] - Running task 19.0 in stage 6.0 (TID 107)
2021-12-03 23:02:56,293 [Executor task launch worker for task 104] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 23:02:56,293 [Executor task launch worker for task 104] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 1 ms
2021-12-03 23:02:56,293 [Executor task launch worker for task 106] INFO [org.apache.spark.executor.Executor] - Running task 18.0 in stage 6.0 (TID 106)
2021-12-03 23:02:56,293 [Executor task launch worker for task 105] INFO [org.apache.spark.executor.Executor] - Running task 17.0 in stage 6.0 (TID 105)
2021-12-03 23:02:56,293 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 5.0 in stage 6.0 (TID 93) in 455 ms on localhost (executor driver) (6/22)
2021-12-03 23:02:56,296 [Executor task launch worker for task 107] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 23:02:56,296 [Executor task launch worker for task 107] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 1 ms
2021-12-03 23:02:56,293 [Executor task launch worker for task 89] INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 6.0 (TID 89). 1267 bytes result sent to driver
2021-12-03 23:02:56,296 [Executor task launch worker for task 106] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 23:02:56,296 [Executor task launch worker for task 106] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 23:02:56,297 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 6.0 in stage 6.0 (TID 94) in 459 ms on localhost (executor driver) (7/22)
2021-12-03 23:02:56,297 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 6.0 (TID 89) in 459 ms on localhost (executor driver) (8/22)
2021-12-03 23:02:56,298 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 6.0 (TID 88) in 460 ms on localhost (executor driver) (9/22)
2021-12-03 23:02:56,299 [dispatcher-event-loop-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 20.0 in stage 6.0 (TID 108, localhost, executor driver, partition 20, ANY, 7638 bytes)
2021-12-03 23:02:56,299 [Executor task launch worker for task 105] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 23:02:56,299 [Executor task launch worker for task 105] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 23:02:56,299 [Executor task launch worker for task 108] INFO [org.apache.spark.executor.Executor] - Running task 20.0 in stage 6.0 (TID 108)
2021-12-03 23:02:56,302 [Executor task launch worker for task 108] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 23:02:56,302 [Executor task launch worker for task 108] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 23:02:56,304 [Executor task launch worker for task 91] INFO [org.apache.spark.executor.Executor] - Finished task 3.0 in stage 6.0 (TID 91). 1267 bytes result sent to driver
2021-12-03 23:02:56,304 [dispatcher-event-loop-9] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 21.0 in stage 6.0 (TID 109, localhost, executor driver, partition 21, ANY, 7638 bytes)
2021-12-03 23:02:56,305 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 3.0 in stage 6.0 (TID 91) in 467 ms on localhost (executor driver) (10/22)
2021-12-03 23:02:56,305 [Executor task launch worker for task 90] INFO [org.apache.spark.executor.Executor] - Finished task 2.0 in stage 6.0 (TID 90). 1267 bytes result sent to driver
2021-12-03 23:02:56,306 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 2.0 in stage 6.0 (TID 90) in 468 ms on localhost (executor driver) (11/22)
2021-12-03 23:02:56,307 [Executor task launch worker for task 109] INFO [org.apache.spark.executor.Executor] - Running task 21.0 in stage 6.0 (TID 109)
2021-12-03 23:02:56,310 [Executor task launch worker for task 109] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 23:02:56,310 [Executor task launch worker for task 109] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 23:02:56,324 [Executor task launch worker for task 98] INFO [org.apache.spark.executor.Executor] - Finished task 10.0 in stage 6.0 (TID 98). 1267 bytes result sent to driver
2021-12-03 23:02:56,328 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 10.0 in stage 6.0 (TID 98) in 490 ms on localhost (executor driver) (12/22)
2021-12-03 23:02:56,393 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 92
2021-12-03 23:02:56,393 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 88
2021-12-03 23:02:56,393 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 93
2021-12-03 23:02:56,393 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 97
2021-12-03 23:02:56,393 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 98
2021-12-03 23:02:56,393 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 89
2021-12-03 23:02:56,393 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 95
2021-12-03 23:02:56,393 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 94
2021-12-03 23:02:56,393 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 78
2021-12-03 23:02:56,413 [dispatcher-event-loop-11] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_4_piece0 on qb:58628 in memory (size: 2.4 KB, free: 1990.8 MB)
2021-12-03 23:02:56,417 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 77
2021-12-03 23:02:56,417 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 83
2021-12-03 23:02:56,417 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 75
2021-12-03 23:02:56,417 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 79
2021-12-03 23:02:56,417 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 84
2021-12-03 23:02:56,417 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 82
2021-12-03 23:02:56,417 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 87
2021-12-03 23:02:56,417 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 76
2021-12-03 23:02:56,417 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 80
2021-12-03 23:02:56,417 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 86
2021-12-03 23:02:56,417 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 81
2021-12-03 23:02:56,417 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 99
2021-12-03 23:02:56,417 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 96
2021-12-03 23:02:56,417 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 90
2021-12-03 23:02:56,418 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 91
2021-12-03 23:02:56,418 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 85
2021-12-03 23:02:56,699 [Executor task launch worker for task 100] INFO [org.apache.spark.executor.Executor] - Finished task 12.0 in stage 6.0 (TID 100). 1310 bytes result sent to driver
2021-12-03 23:02:56,700 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 12.0 in stage 6.0 (TID 100) in 439 ms on localhost (executor driver) (13/22)
2021-12-03 23:02:56,710 [Executor task launch worker for task 106] INFO [org.apache.spark.executor.Executor] - Finished task 18.0 in stage 6.0 (TID 106). 1310 bytes result sent to driver
2021-12-03 23:02:56,713 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 18.0 in stage 6.0 (TID 106) in 421 ms on localhost (executor driver) (14/22)
2021-12-03 23:02:56,721 [Executor task launch worker for task 103] INFO [org.apache.spark.executor.Executor] - Finished task 15.0 in stage 6.0 (TID 103). 1267 bytes result sent to driver
2021-12-03 23:02:56,722 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 15.0 in stage 6.0 (TID 103) in 447 ms on localhost (executor driver) (15/22)
2021-12-03 23:02:56,723 [Executor task launch worker for task 101] INFO [org.apache.spark.executor.Executor] - Finished task 13.0 in stage 6.0 (TID 101). 1267 bytes result sent to driver
2021-12-03 23:02:56,723 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 13.0 in stage 6.0 (TID 101) in 451 ms on localhost (executor driver) (16/22)
2021-12-03 23:02:56,728 [Executor task launch worker for task 108] INFO [org.apache.spark.executor.Executor] - Finished task 20.0 in stage 6.0 (TID 108). 1267 bytes result sent to driver
2021-12-03 23:02:56,729 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 20.0 in stage 6.0 (TID 108) in 431 ms on localhost (executor driver) (17/22)
2021-12-03 23:02:56,745 [Executor task launch worker for task 105] INFO [org.apache.spark.executor.Executor] - Finished task 17.0 in stage 6.0 (TID 105). 1267 bytes result sent to driver
2021-12-03 23:02:56,745 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 17.0 in stage 6.0 (TID 105) in 454 ms on localhost (executor driver) (18/22)
2021-12-03 23:02:56,752 [Executor task launch worker for task 104] INFO [org.apache.spark.executor.Executor] - Finished task 16.0 in stage 6.0 (TID 104). 1267 bytes result sent to driver
2021-12-03 23:02:56,752 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 16.0 in stage 6.0 (TID 104) in 464 ms on localhost (executor driver) (19/22)
2021-12-03 23:02:56,753 [Executor task launch worker for task 107] INFO [org.apache.spark.executor.Executor] - Finished task 19.0 in stage 6.0 (TID 107). 1267 bytes result sent to driver
2021-12-03 23:02:56,753 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 19.0 in stage 6.0 (TID 107) in 461 ms on localhost (executor driver) (20/22)
2021-12-03 23:02:56,763 [Executor task launch worker for task 109] INFO [org.apache.spark.executor.Executor] - Finished task 21.0 in stage 6.0 (TID 109). 1267 bytes result sent to driver
2021-12-03 23:02:56,764 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 21.0 in stage 6.0 (TID 109) in 460 ms on localhost (executor driver) (21/22)
2021-12-03 23:02:56,785 [Executor task launch worker for task 102] INFO [org.apache.spark.executor.Executor] - Finished task 14.0 in stage 6.0 (TID 102). 1267 bytes result sent to driver
2021-12-03 23:02:56,785 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 14.0 in stage 6.0 (TID 102) in 512 ms on localhost (executor driver) (22/22)
2021-12-03 23:02:56,785 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 6.0, whose tasks have all completed, from pool 
2021-12-03 23:02:56,785 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ShuffleMapStage 6 (map at PaidPromotionAdjustParameter.scala:72) finished in 0.955 s
2021-12-03 23:02:56,785 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - looking for newly runnable stages
2021-12-03 23:02:56,785 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - running: Set()
2021-12-03 23:02:56,785 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - waiting: Set(ResultStage 7)
2021-12-03 23:02:56,785 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - failed: Set()
2021-12-03 23:02:56,786 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 7 (ShuffledRDD[8] at sortByKey at PaidPromotionAdjustParameter.scala:73), which has no missing parents
2021-12-03 23:02:56,788 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_6 stored as values in memory (estimated size 3.4 KB, free 1990.4 MB)
2021-12-03 23:02:56,789 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_6_piece0 stored as bytes in memory (estimated size 2.0 KB, free 1990.4 MB)
2021-12-03 23:02:56,789 [dispatcher-event-loop-11] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_6_piece0 in memory on qb:58628 (size: 2.0 KB, free: 1990.8 MB)
2021-12-03 23:02:56,790 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 6 from broadcast at DAGScheduler.scala:1039
2021-12-03 23:02:56,790 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 21 missing tasks from ResultStage 7 (ShuffledRDD[8] at sortByKey at PaidPromotionAdjustParameter.scala:73) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14))
2021-12-03 23:02:56,790 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 7.0 with 21 tasks
2021-12-03 23:02:56,790 [dispatcher-event-loop-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 7.0 (TID 110, localhost, executor driver, partition 0, ANY, 7649 bytes)
2021-12-03 23:02:56,790 [dispatcher-event-loop-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 7.0 (TID 111, localhost, executor driver, partition 1, ANY, 7649 bytes)
2021-12-03 23:02:56,790 [dispatcher-event-loop-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 2.0 in stage 7.0 (TID 112, localhost, executor driver, partition 2, ANY, 7649 bytes)
2021-12-03 23:02:56,791 [dispatcher-event-loop-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 3.0 in stage 7.0 (TID 113, localhost, executor driver, partition 3, ANY, 7649 bytes)
2021-12-03 23:02:56,791 [dispatcher-event-loop-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 4.0 in stage 7.0 (TID 114, localhost, executor driver, partition 4, ANY, 7649 bytes)
2021-12-03 23:02:56,791 [dispatcher-event-loop-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 5.0 in stage 7.0 (TID 115, localhost, executor driver, partition 5, ANY, 7649 bytes)
2021-12-03 23:02:56,791 [dispatcher-event-loop-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 6.0 in stage 7.0 (TID 116, localhost, executor driver, partition 6, ANY, 7649 bytes)
2021-12-03 23:02:56,791 [dispatcher-event-loop-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 7.0 in stage 7.0 (TID 117, localhost, executor driver, partition 7, ANY, 7649 bytes)
2021-12-03 23:02:56,791 [dispatcher-event-loop-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 8.0 in stage 7.0 (TID 118, localhost, executor driver, partition 8, ANY, 7649 bytes)
2021-12-03 23:02:56,791 [dispatcher-event-loop-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 9.0 in stage 7.0 (TID 119, localhost, executor driver, partition 9, ANY, 7649 bytes)
2021-12-03 23:02:56,791 [dispatcher-event-loop-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 10.0 in stage 7.0 (TID 120, localhost, executor driver, partition 10, ANY, 7649 bytes)
2021-12-03 23:02:56,791 [dispatcher-event-loop-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 11.0 in stage 7.0 (TID 121, localhost, executor driver, partition 11, ANY, 7649 bytes)
2021-12-03 23:02:56,791 [Executor task launch worker for task 110] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 7.0 (TID 110)
2021-12-03 23:02:56,791 [Executor task launch worker for task 115] INFO [org.apache.spark.executor.Executor] - Running task 5.0 in stage 7.0 (TID 115)
2021-12-03 23:02:56,791 [Executor task launch worker for task 114] INFO [org.apache.spark.executor.Executor] - Running task 4.0 in stage 7.0 (TID 114)
2021-12-03 23:02:56,791 [Executor task launch worker for task 113] INFO [org.apache.spark.executor.Executor] - Running task 3.0 in stage 7.0 (TID 113)
2021-12-03 23:02:56,791 [Executor task launch worker for task 112] INFO [org.apache.spark.executor.Executor] - Running task 2.0 in stage 7.0 (TID 112)
2021-12-03 23:02:56,791 [Executor task launch worker for task 111] INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 7.0 (TID 111)
2021-12-03 23:02:56,791 [Executor task launch worker for task 121] INFO [org.apache.spark.executor.Executor] - Running task 11.0 in stage 7.0 (TID 121)
2021-12-03 23:02:56,791 [Executor task launch worker for task 120] INFO [org.apache.spark.executor.Executor] - Running task 10.0 in stage 7.0 (TID 120)
2021-12-03 23:02:56,791 [Executor task launch worker for task 118] INFO [org.apache.spark.executor.Executor] - Running task 8.0 in stage 7.0 (TID 118)
2021-12-03 23:02:56,791 [Executor task launch worker for task 119] INFO [org.apache.spark.executor.Executor] - Running task 9.0 in stage 7.0 (TID 119)
2021-12-03 23:02:56,791 [Executor task launch worker for task 116] INFO [org.apache.spark.executor.Executor] - Running task 6.0 in stage 7.0 (TID 116)
2021-12-03 23:02:56,791 [Executor task launch worker for task 117] INFO [org.apache.spark.executor.Executor] - Running task 7.0 in stage 7.0 (TID 117)
2021-12-03 23:02:56,794 [Executor task launch worker for task 116] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 23:02:56,794 [Executor task launch worker for task 116] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 23:02:56,795 [Executor task launch worker for task 119] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 23:02:56,795 [Executor task launch worker for task 119] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 23:02:56,795 [Executor task launch worker for task 114] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 23:02:56,795 [Executor task launch worker for task 114] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 23:02:56,795 [Executor task launch worker for task 110] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 23:02:56,795 [Executor task launch worker for task 110] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 23:02:56,795 [Executor task launch worker for task 121] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 23:02:56,795 [Executor task launch worker for task 121] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 23:02:56,796 [Executor task launch worker for task 117] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 23:02:56,796 [Executor task launch worker for task 117] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 23:02:56,796 [Executor task launch worker for task 111] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 23:02:56,796 [Executor task launch worker for task 111] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 23:02:56,797 [Executor task launch worker for task 118] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 23:02:56,797 [Executor task launch worker for task 118] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 1 ms
2021-12-03 23:02:56,797 [Executor task launch worker for task 120] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 23:02:56,797 [Executor task launch worker for task 120] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 23:02:56,797 [Executor task launch worker for task 115] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 23:02:56,797 [Executor task launch worker for task 115] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 23:02:56,798 [Executor task launch worker for task 113] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 23:02:56,798 [Executor task launch worker for task 113] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 23:02:56,798 [Executor task launch worker for task 112] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 23:02:56,798 [Executor task launch worker for task 112] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 23:02:57,115 [Executor task launch worker for task 121] INFO [org.apache.spark.executor.Executor] - Finished task 11.0 in stage 7.0 (TID 121). 1055 bytes result sent to driver
2021-12-03 23:02:57,116 [dispatcher-event-loop-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 12.0 in stage 7.0 (TID 122, localhost, executor driver, partition 12, ANY, 7649 bytes)
2021-12-03 23:02:57,116 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 11.0 in stage 7.0 (TID 121) in 325 ms on localhost (executor driver) (1/21)
2021-12-03 23:02:57,117 [Executor task launch worker for task 119] INFO [org.apache.spark.executor.Executor] - Finished task 9.0 in stage 7.0 (TID 119). 1055 bytes result sent to driver
2021-12-03 23:02:57,122 [Executor task launch worker for task 122] INFO [org.apache.spark.executor.Executor] - Running task 12.0 in stage 7.0 (TID 122)
2021-12-03 23:02:57,122 [dispatcher-event-loop-6] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 13.0 in stage 7.0 (TID 123, localhost, executor driver, partition 13, ANY, 7649 bytes)
2021-12-03 23:02:57,122 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 9.0 in stage 7.0 (TID 119) in 331 ms on localhost (executor driver) (2/21)
2021-12-03 23:02:57,122 [Executor task launch worker for task 123] INFO [org.apache.spark.executor.Executor] - Running task 13.0 in stage 7.0 (TID 123)
2021-12-03 23:02:57,124 [Executor task launch worker for task 120] INFO [org.apache.spark.executor.Executor] - Finished task 10.0 in stage 7.0 (TID 120). 1055 bytes result sent to driver
2021-12-03 23:02:57,124 [Executor task launch worker for task 122] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 23:02:57,124 [Executor task launch worker for task 122] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 23:02:57,125 [Executor task launch worker for task 123] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 23:02:57,125 [Executor task launch worker for task 123] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 23:02:57,125 [dispatcher-event-loop-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 14.0 in stage 7.0 (TID 124, localhost, executor driver, partition 14, ANY, 7649 bytes)
2021-12-03 23:02:57,126 [Executor task launch worker for task 124] INFO [org.apache.spark.executor.Executor] - Running task 14.0 in stage 7.0 (TID 124)
2021-12-03 23:02:57,126 [Executor task launch worker for task 115] INFO [org.apache.spark.executor.Executor] - Finished task 5.0 in stage 7.0 (TID 115). 1055 bytes result sent to driver
2021-12-03 23:02:57,126 [dispatcher-event-loop-9] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 15.0 in stage 7.0 (TID 125, localhost, executor driver, partition 15, ANY, 7649 bytes)
2021-12-03 23:02:57,126 [Executor task launch worker for task 125] INFO [org.apache.spark.executor.Executor] - Running task 15.0 in stage 7.0 (TID 125)
2021-12-03 23:02:57,126 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 10.0 in stage 7.0 (TID 120) in 335 ms on localhost (executor driver) (3/21)
2021-12-03 23:02:57,126 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 5.0 in stage 7.0 (TID 115) in 335 ms on localhost (executor driver) (4/21)
2021-12-03 23:02:57,126 [Executor task launch worker for task 116] INFO [org.apache.spark.executor.Executor] - Finished task 6.0 in stage 7.0 (TID 116). 1055 bytes result sent to driver
2021-12-03 23:02:57,126 [Executor task launch worker for task 118] INFO [org.apache.spark.executor.Executor] - Finished task 8.0 in stage 7.0 (TID 118). 1055 bytes result sent to driver
2021-12-03 23:02:57,127 [dispatcher-event-loop-5] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 16.0 in stage 7.0 (TID 126, localhost, executor driver, partition 16, ANY, 7649 bytes)
2021-12-03 23:02:57,127 [Executor task launch worker for task 126] INFO [org.apache.spark.executor.Executor] - Running task 16.0 in stage 7.0 (TID 126)
2021-12-03 23:02:57,127 [dispatcher-event-loop-5] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 17.0 in stage 7.0 (TID 127, localhost, executor driver, partition 17, ANY, 7649 bytes)
2021-12-03 23:02:57,127 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 6.0 in stage 7.0 (TID 116) in 336 ms on localhost (executor driver) (5/21)
2021-12-03 23:02:57,127 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 8.0 in stage 7.0 (TID 118) in 336 ms on localhost (executor driver) (6/21)
2021-12-03 23:02:57,128 [Executor task launch worker for task 127] INFO [org.apache.spark.executor.Executor] - Running task 17.0 in stage 7.0 (TID 127)
2021-12-03 23:02:57,128 [Executor task launch worker for task 124] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 23:02:57,128 [Executor task launch worker for task 124] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 23:02:57,129 [Executor task launch worker for task 111] INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 7.0 (TID 111). 1055 bytes result sent to driver
2021-12-03 23:02:57,129 [Executor task launch worker for task 126] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 23:02:57,129 [Executor task launch worker for task 125] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 23:02:57,129 [Executor task launch worker for task 126] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 23:02:57,129 [dispatcher-event-loop-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 18.0 in stage 7.0 (TID 128, localhost, executor driver, partition 18, ANY, 7649 bytes)
2021-12-03 23:02:57,129 [Executor task launch worker for task 125] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 23:02:57,130 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 7.0 (TID 111) in 340 ms on localhost (executor driver) (7/21)
2021-12-03 23:02:57,130 [Executor task launch worker for task 128] INFO [org.apache.spark.executor.Executor] - Running task 18.0 in stage 7.0 (TID 128)
2021-12-03 23:02:57,130 [Executor task launch worker for task 110] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 7.0 (TID 110). 1098 bytes result sent to driver
2021-12-03 23:02:57,130 [dispatcher-event-loop-6] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 19.0 in stage 7.0 (TID 129, localhost, executor driver, partition 19, ANY, 7649 bytes)
2021-12-03 23:02:57,130 [Executor task launch worker for task 114] INFO [org.apache.spark.executor.Executor] - Finished task 4.0 in stage 7.0 (TID 114). 1098 bytes result sent to driver
2021-12-03 23:02:57,130 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 7.0 (TID 110) in 340 ms on localhost (executor driver) (8/21)
2021-12-03 23:02:57,131 [Executor task launch worker for task 129] INFO [org.apache.spark.executor.Executor] - Running task 19.0 in stage 7.0 (TID 129)
2021-12-03 23:02:57,131 [Executor task launch worker for task 127] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 23:02:57,131 [Executor task launch worker for task 127] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 23:02:57,131 [dispatcher-event-loop-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 20.0 in stage 7.0 (TID 130, localhost, executor driver, partition 20, ANY, 7649 bytes)
2021-12-03 23:02:57,131 [Executor task launch worker for task 130] INFO [org.apache.spark.executor.Executor] - Running task 20.0 in stage 7.0 (TID 130)
2021-12-03 23:02:57,131 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 4.0 in stage 7.0 (TID 114) in 340 ms on localhost (executor driver) (9/21)
2021-12-03 23:02:57,132 [Executor task launch worker for task 128] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 23:02:57,132 [Executor task launch worker for task 117] INFO [org.apache.spark.executor.Executor] - Finished task 7.0 in stage 7.0 (TID 117). 1055 bytes result sent to driver
2021-12-03 23:02:57,133 [Executor task launch worker for task 128] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 1 ms
2021-12-03 23:02:57,133 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 7.0 in stage 7.0 (TID 117) in 342 ms on localhost (executor driver) (10/21)
2021-12-03 23:02:57,133 [Executor task launch worker for task 129] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 23:02:57,133 [Executor task launch worker for task 129] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 23:02:57,134 [Executor task launch worker for task 130] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 23:02:57,134 [Executor task launch worker for task 130] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 23:02:57,136 [Executor task launch worker for task 113] INFO [org.apache.spark.executor.Executor] - Finished task 3.0 in stage 7.0 (TID 113). 1055 bytes result sent to driver
2021-12-03 23:02:57,136 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 3.0 in stage 7.0 (TID 113) in 346 ms on localhost (executor driver) (11/21)
2021-12-03 23:02:57,137 [Executor task launch worker for task 112] INFO [org.apache.spark.executor.Executor] - Finished task 2.0 in stage 7.0 (TID 112). 1055 bytes result sent to driver
2021-12-03 23:02:57,137 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 2.0 in stage 7.0 (TID 112) in 347 ms on localhost (executor driver) (12/21)
2021-12-03 23:02:57,189 [Executor task launch worker for task 124] INFO [org.apache.spark.executor.Executor] - Finished task 14.0 in stage 7.0 (TID 124). 1055 bytes result sent to driver
2021-12-03 23:02:57,189 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 14.0 in stage 7.0 (TID 124) in 64 ms on localhost (executor driver) (13/21)
2021-12-03 23:02:57,196 [Executor task launch worker for task 126] INFO [org.apache.spark.executor.Executor] - Finished task 16.0 in stage 7.0 (TID 126). 1055 bytes result sent to driver
2021-12-03 23:02:57,196 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 16.0 in stage 7.0 (TID 126) in 69 ms on localhost (executor driver) (14/21)
2021-12-03 23:02:57,202 [Executor task launch worker for task 130] INFO [org.apache.spark.executor.Executor] - Finished task 20.0 in stage 7.0 (TID 130). 1055 bytes result sent to driver
2021-12-03 23:02:57,203 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 20.0 in stage 7.0 (TID 130) in 71 ms on localhost (executor driver) (15/21)
2021-12-03 23:02:57,205 [Executor task launch worker for task 128] INFO [org.apache.spark.executor.Executor] - Finished task 18.0 in stage 7.0 (TID 128). 1055 bytes result sent to driver
2021-12-03 23:02:57,205 [Executor task launch worker for task 123] INFO [org.apache.spark.executor.Executor] - Finished task 13.0 in stage 7.0 (TID 123). 1055 bytes result sent to driver
2021-12-03 23:02:57,205 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 18.0 in stage 7.0 (TID 128) in 76 ms on localhost (executor driver) (16/21)
2021-12-03 23:02:57,205 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 13.0 in stage 7.0 (TID 123) in 83 ms on localhost (executor driver) (17/21)
2021-12-03 23:02:57,205 [Executor task launch worker for task 125] INFO [org.apache.spark.executor.Executor] - Finished task 15.0 in stage 7.0 (TID 125). 1055 bytes result sent to driver
2021-12-03 23:02:57,205 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 15.0 in stage 7.0 (TID 125) in 79 ms on localhost (executor driver) (18/21)
2021-12-03 23:02:57,207 [Executor task launch worker for task 129] INFO [org.apache.spark.executor.Executor] - Finished task 19.0 in stage 7.0 (TID 129). 1055 bytes result sent to driver
2021-12-03 23:02:57,207 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 19.0 in stage 7.0 (TID 129) in 77 ms on localhost (executor driver) (19/21)
2021-12-03 23:02:57,213 [Executor task launch worker for task 122] INFO [org.apache.spark.executor.Executor] - Finished task 12.0 in stage 7.0 (TID 122). 1098 bytes result sent to driver
2021-12-03 23:02:57,213 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 12.0 in stage 7.0 (TID 122) in 97 ms on localhost (executor driver) (20/21)
2021-12-03 23:02:57,213 [Executor task launch worker for task 127] INFO [org.apache.spark.executor.Executor] - Finished task 17.0 in stage 7.0 (TID 127). 1055 bytes result sent to driver
2021-12-03 23:02:57,213 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 17.0 in stage 7.0 (TID 127) in 86 ms on localhost (executor driver) (21/21)
2021-12-03 23:02:57,213 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 7.0, whose tasks have all completed, from pool 
2021-12-03 23:02:57,213 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 7 (zipWithIndex at PaidPromotionAdjustParameter.scala:74) finished in 0.427 s
2021-12-03 23:02:57,222 [main] INFO [org.apache.spark.scheduler.DAGScheduler] - Job 3 finished: zipWithIndex at PaidPromotionAdjustParameter.scala:74, took 1.386258 s
2021-12-03 23:02:57,222 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 120
2021-12-03 23:02:57,222 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 135
2021-12-03 23:02:57,222 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 124
2021-12-03 23:02:57,222 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 143
2021-12-03 23:02:57,222 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 144
2021-12-03 23:02:57,222 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 145
2021-12-03 23:02:57,222 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 132
2021-12-03 23:02:57,222 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 128
2021-12-03 23:02:57,222 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 130
2021-12-03 23:02:57,222 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 123
2021-12-03 23:02:57,222 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 109
2021-12-03 23:02:57,223 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 116
2021-12-03 23:02:57,223 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 149
2021-12-03 23:02:57,223 [dispatcher-event-loop-10] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_6_piece0 on qb:58628 in memory (size: 2.0 KB, free: 1990.8 MB)
2021-12-03 23:02:57,223 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 119
2021-12-03 23:02:57,223 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 125
2021-12-03 23:02:57,223 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 102
2021-12-03 23:02:57,223 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 131
2021-12-03 23:02:57,223 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 142
2021-12-03 23:02:57,223 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 147
2021-12-03 23:02:57,223 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 122
2021-12-03 23:02:57,224 [dispatcher-event-loop-1] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_5_piece0 on qb:58628 in memory (size: 2.4 KB, free: 1990.8 MB)
2021-12-03 23:02:57,224 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 126
2021-12-03 23:02:57,224 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 137
2021-12-03 23:02:57,224 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 103
2021-12-03 23:02:57,224 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 114
2021-12-03 23:02:57,224 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 129
2021-12-03 23:02:57,224 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 133
2021-12-03 23:02:57,224 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 141
2021-12-03 23:02:57,224 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 140
2021-12-03 23:02:57,224 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 139
2021-12-03 23:02:57,224 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 134
2021-12-03 23:02:57,224 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 115
2021-12-03 23:02:57,224 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 117
2021-12-03 23:02:57,224 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 148
2021-12-03 23:02:57,224 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 136
2021-12-03 23:02:57,224 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 104
2021-12-03 23:02:57,224 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 100
2021-12-03 23:02:57,224 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 106
2021-12-03 23:02:57,224 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 138
2021-12-03 23:02:57,224 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 146
2021-12-03 23:02:57,224 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 113
2021-12-03 23:02:57,224 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 127
2021-12-03 23:02:57,224 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 118
2021-12-03 23:02:57,224 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 105
2021-12-03 23:02:57,224 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 121
2021-12-03 23:02:57,224 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 111
2021-12-03 23:02:57,224 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 101
2021-12-03 23:02:57,225 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 112
2021-12-03 23:02:57,225 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 110
2021-12-03 23:02:57,225 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 108
2021-12-03 23:02:57,225 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 107
2021-12-03 23:02:57,232 [main] INFO [org.apache.spark.SparkContext] - Starting job: takeSample at PaidPromotionAdjustParameter.scala:77
2021-12-03 23:02:57,232 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 4 (takeSample at PaidPromotionAdjustParameter.scala:77) with 22 output partitions
2021-12-03 23:02:57,232 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 10 (takeSample at PaidPromotionAdjustParameter.scala:77)
2021-12-03 23:02:57,232 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 9)
2021-12-03 23:02:57,232 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2021-12-03 23:02:57,232 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 10 (MapPartitionsRDD[11] at map at PaidPromotionAdjustParameter.scala:76), which has no missing parents
2021-12-03 23:02:57,236 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_7 stored as values in memory (estimated size 4.2 KB, free 1990.5 MB)
2021-12-03 23:02:57,237 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_7_piece0 stored as bytes in memory (estimated size 2.4 KB, free 1990.4 MB)
2021-12-03 23:02:57,237 [dispatcher-event-loop-0] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_7_piece0 in memory on qb:58628 (size: 2.4 KB, free: 1990.8 MB)
2021-12-03 23:02:57,237 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 7 from broadcast at DAGScheduler.scala:1039
2021-12-03 23:02:57,238 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 22 missing tasks from ResultStage 10 (MapPartitionsRDD[11] at map at PaidPromotionAdjustParameter.scala:76) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14))
2021-12-03 23:02:57,238 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 10.0 with 22 tasks
2021-12-03 23:02:57,238 [dispatcher-event-loop-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 10.0 (TID 131, localhost, executor driver, partition 0, ANY, 7759 bytes)
2021-12-03 23:02:57,238 [dispatcher-event-loop-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 10.0 (TID 132, localhost, executor driver, partition 1, ANY, 7759 bytes)
2021-12-03 23:02:57,239 [dispatcher-event-loop-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 2.0 in stage 10.0 (TID 133, localhost, executor driver, partition 2, ANY, 7759 bytes)
2021-12-03 23:02:57,239 [dispatcher-event-loop-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 3.0 in stage 10.0 (TID 134, localhost, executor driver, partition 3, ANY, 7759 bytes)
2021-12-03 23:02:57,239 [dispatcher-event-loop-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 4.0 in stage 10.0 (TID 135, localhost, executor driver, partition 4, ANY, 7759 bytes)
2021-12-03 23:02:57,239 [dispatcher-event-loop-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 5.0 in stage 10.0 (TID 136, localhost, executor driver, partition 5, ANY, 7759 bytes)
2021-12-03 23:02:57,239 [dispatcher-event-loop-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 6.0 in stage 10.0 (TID 137, localhost, executor driver, partition 6, ANY, 7759 bytes)
2021-12-03 23:02:57,239 [dispatcher-event-loop-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 7.0 in stage 10.0 (TID 138, localhost, executor driver, partition 7, ANY, 7759 bytes)
2021-12-03 23:02:57,239 [dispatcher-event-loop-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 8.0 in stage 10.0 (TID 139, localhost, executor driver, partition 8, ANY, 7759 bytes)
2021-12-03 23:02:57,239 [dispatcher-event-loop-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 9.0 in stage 10.0 (TID 140, localhost, executor driver, partition 9, ANY, 7759 bytes)
2021-12-03 23:02:57,239 [dispatcher-event-loop-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 10.0 in stage 10.0 (TID 141, localhost, executor driver, partition 10, ANY, 7759 bytes)
2021-12-03 23:02:57,239 [dispatcher-event-loop-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 11.0 in stage 10.0 (TID 142, localhost, executor driver, partition 11, ANY, 7759 bytes)
2021-12-03 23:02:57,239 [Executor task launch worker for task 132] INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 10.0 (TID 132)
2021-12-03 23:02:57,239 [Executor task launch worker for task 138] INFO [org.apache.spark.executor.Executor] - Running task 7.0 in stage 10.0 (TID 138)
2021-12-03 23:02:57,239 [Executor task launch worker for task 141] INFO [org.apache.spark.executor.Executor] - Running task 10.0 in stage 10.0 (TID 141)
2021-12-03 23:02:57,239 [Executor task launch worker for task 133] INFO [org.apache.spark.executor.Executor] - Running task 2.0 in stage 10.0 (TID 133)
2021-12-03 23:02:57,239 [Executor task launch worker for task 142] INFO [org.apache.spark.executor.Executor] - Running task 11.0 in stage 10.0 (TID 142)
2021-12-03 23:02:57,239 [Executor task launch worker for task 134] INFO [org.apache.spark.executor.Executor] - Running task 3.0 in stage 10.0 (TID 134)
2021-12-03 23:02:57,239 [Executor task launch worker for task 137] INFO [org.apache.spark.executor.Executor] - Running task 6.0 in stage 10.0 (TID 137)
2021-12-03 23:02:57,239 [Executor task launch worker for task 131] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 10.0 (TID 131)
2021-12-03 23:02:57,239 [Executor task launch worker for task 135] INFO [org.apache.spark.executor.Executor] - Running task 4.0 in stage 10.0 (TID 135)
2021-12-03 23:02:57,239 [Executor task launch worker for task 140] INFO [org.apache.spark.executor.Executor] - Running task 9.0 in stage 10.0 (TID 140)
2021-12-03 23:02:57,239 [Executor task launch worker for task 139] INFO [org.apache.spark.executor.Executor] - Running task 8.0 in stage 10.0 (TID 139)
2021-12-03 23:02:57,239 [Executor task launch worker for task 136] INFO [org.apache.spark.executor.Executor] - Running task 5.0 in stage 10.0 (TID 136)
2021-12-03 23:02:57,242 [Executor task launch worker for task 131] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 23:02:57,242 [Executor task launch worker for task 131] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 23:02:57,242 [Executor task launch worker for task 134] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 23:02:57,242 [Executor task launch worker for task 134] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 23:02:57,243 [Executor task launch worker for task 140] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 23:02:57,243 [Executor task launch worker for task 140] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 23:02:57,243 [Executor task launch worker for task 132] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 23:02:57,243 [Executor task launch worker for task 132] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 23:02:57,243 [Executor task launch worker for task 135] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 23:02:57,243 [Executor task launch worker for task 135] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 23:02:57,244 [Executor task launch worker for task 133] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 23:02:57,244 [Executor task launch worker for task 133] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 23:02:57,244 [Executor task launch worker for task 141] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 23:02:57,244 [Executor task launch worker for task 141] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 23:02:57,244 [Executor task launch worker for task 136] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 23:02:57,244 [Executor task launch worker for task 136] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 23:02:57,245 [Executor task launch worker for task 138] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 23:02:57,245 [Executor task launch worker for task 138] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 23:02:57,245 [Executor task launch worker for task 142] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 23:02:57,245 [Executor task launch worker for task 142] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 23:02:57,245 [Executor task launch worker for task 137] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 23:02:57,245 [Executor task launch worker for task 137] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 23:02:57,246 [Executor task launch worker for task 139] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 23:02:57,246 [Executor task launch worker for task 139] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 23:02:57,351 [Executor task launch worker for task 131] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 10.0 (TID 131). 1053 bytes result sent to driver
2021-12-03 23:02:57,352 [dispatcher-event-loop-6] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 12.0 in stage 10.0 (TID 143, localhost, executor driver, partition 12, ANY, 7759 bytes)
2021-12-03 23:02:57,352 [Executor task launch worker for task 143] INFO [org.apache.spark.executor.Executor] - Running task 12.0 in stage 10.0 (TID 143)
2021-12-03 23:02:57,353 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 10.0 (TID 131) in 115 ms on localhost (executor driver) (1/22)
2021-12-03 23:02:57,354 [Executor task launch worker for task 140] INFO [org.apache.spark.executor.Executor] - Finished task 9.0 in stage 10.0 (TID 140). 1055 bytes result sent to driver
2021-12-03 23:02:57,354 [dispatcher-event-loop-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 13.0 in stage 10.0 (TID 144, localhost, executor driver, partition 13, ANY, 7759 bytes)
2021-12-03 23:02:57,354 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 9.0 in stage 10.0 (TID 140) in 115 ms on localhost (executor driver) (2/22)
2021-12-03 23:02:57,355 [Executor task launch worker for task 144] INFO [org.apache.spark.executor.Executor] - Running task 13.0 in stage 10.0 (TID 144)
2021-12-03 23:02:57,355 [Executor task launch worker for task 143] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 23:02:57,355 [Executor task launch worker for task 143] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 23:02:57,357 [Executor task launch worker for task 142] INFO [org.apache.spark.executor.Executor] - Finished task 11.0 in stage 10.0 (TID 142). 1055 bytes result sent to driver
2021-12-03 23:02:57,357 [Executor task launch worker for task 144] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 23:02:57,357 [Executor task launch worker for task 144] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 23:02:57,358 [dispatcher-event-loop-4] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 14.0 in stage 10.0 (TID 145, localhost, executor driver, partition 14, ANY, 7759 bytes)
2021-12-03 23:02:57,358 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 11.0 in stage 10.0 (TID 142) in 119 ms on localhost (executor driver) (3/22)
2021-12-03 23:02:57,358 [Executor task launch worker for task 145] INFO [org.apache.spark.executor.Executor] - Running task 14.0 in stage 10.0 (TID 145)
2021-12-03 23:02:57,361 [Executor task launch worker for task 145] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 23:02:57,361 [Executor task launch worker for task 145] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 23:02:57,368 [Executor task launch worker for task 141] INFO [org.apache.spark.executor.Executor] - Finished task 10.0 in stage 10.0 (TID 141). 1055 bytes result sent to driver
2021-12-03 23:02:57,368 [Executor task launch worker for task 134] INFO [org.apache.spark.executor.Executor] - Finished task 3.0 in stage 10.0 (TID 134). 1055 bytes result sent to driver
2021-12-03 23:02:57,369 [dispatcher-event-loop-10] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 15.0 in stage 10.0 (TID 146, localhost, executor driver, partition 15, ANY, 7759 bytes)
2021-12-03 23:02:57,369 [Executor task launch worker for task 146] INFO [org.apache.spark.executor.Executor] - Running task 15.0 in stage 10.0 (TID 146)
2021-12-03 23:02:57,369 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 10.0 in stage 10.0 (TID 141) in 130 ms on localhost (executor driver) (4/22)
2021-12-03 23:02:57,369 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 3.0 in stage 10.0 (TID 134) in 130 ms on localhost (executor driver) (5/22)
2021-12-03 23:02:57,369 [dispatcher-event-loop-10] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 16.0 in stage 10.0 (TID 147, localhost, executor driver, partition 16, ANY, 7759 bytes)
2021-12-03 23:02:57,369 [Executor task launch worker for task 147] INFO [org.apache.spark.executor.Executor] - Running task 16.0 in stage 10.0 (TID 147)
2021-12-03 23:02:57,371 [Executor task launch worker for task 136] INFO [org.apache.spark.executor.Executor] - Finished task 5.0 in stage 10.0 (TID 136). 1055 bytes result sent to driver
2021-12-03 23:02:57,372 [Executor task launch worker for task 146] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 23:02:57,372 [dispatcher-event-loop-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 17.0 in stage 10.0 (TID 148, localhost, executor driver, partition 17, ANY, 7759 bytes)
2021-12-03 23:02:57,372 [Executor task launch worker for task 146] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 23:02:57,372 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 5.0 in stage 10.0 (TID 136) in 133 ms on localhost (executor driver) (6/22)
2021-12-03 23:02:57,372 [Executor task launch worker for task 148] INFO [org.apache.spark.executor.Executor] - Running task 17.0 in stage 10.0 (TID 148)
2021-12-03 23:02:57,372 [Executor task launch worker for task 147] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 23:02:57,372 [Executor task launch worker for task 147] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 23:02:57,375 [Executor task launch worker for task 139] INFO [org.apache.spark.executor.Executor] - Finished task 8.0 in stage 10.0 (TID 139). 1055 bytes result sent to driver
2021-12-03 23:02:57,375 [Executor task launch worker for task 148] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 23:02:57,375 [Executor task launch worker for task 148] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 23:02:57,375 [dispatcher-event-loop-6] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 18.0 in stage 10.0 (TID 149, localhost, executor driver, partition 18, ANY, 7759 bytes)
2021-12-03 23:02:57,376 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 8.0 in stage 10.0 (TID 139) in 137 ms on localhost (executor driver) (7/22)
2021-12-03 23:02:57,376 [Executor task launch worker for task 149] INFO [org.apache.spark.executor.Executor] - Running task 18.0 in stage 10.0 (TID 149)
2021-12-03 23:02:57,381 [Executor task launch worker for task 138] INFO [org.apache.spark.executor.Executor] - Finished task 7.0 in stage 10.0 (TID 138). 1055 bytes result sent to driver
2021-12-03 23:02:57,381 [dispatcher-event-loop-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 19.0 in stage 10.0 (TID 150, localhost, executor driver, partition 19, ANY, 7759 bytes)
2021-12-03 23:02:57,381 [Executor task launch worker for task 149] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 23:02:57,381 [Executor task launch worker for task 149] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 23:02:57,381 [Executor task launch worker for task 150] INFO [org.apache.spark.executor.Executor] - Running task 19.0 in stage 10.0 (TID 150)
2021-12-03 23:02:57,381 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 7.0 in stage 10.0 (TID 138) in 142 ms on localhost (executor driver) (8/22)
2021-12-03 23:02:57,382 [Executor task launch worker for task 137] INFO [org.apache.spark.executor.Executor] - Finished task 6.0 in stage 10.0 (TID 137). 1055 bytes result sent to driver
2021-12-03 23:02:57,382 [dispatcher-event-loop-4] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 20.0 in stage 10.0 (TID 151, localhost, executor driver, partition 20, ANY, 7759 bytes)
2021-12-03 23:02:57,382 [Executor task launch worker for task 151] INFO [org.apache.spark.executor.Executor] - Running task 20.0 in stage 10.0 (TID 151)
2021-12-03 23:02:57,382 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 6.0 in stage 10.0 (TID 137) in 143 ms on localhost (executor driver) (9/22)
2021-12-03 23:02:57,384 [Executor task launch worker for task 150] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 23:02:57,384 [Executor task launch worker for task 150] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 23:02:57,385 [Executor task launch worker for task 151] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 23:02:57,385 [Executor task launch worker for task 151] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 23:02:57,395 [Executor task launch worker for task 132] INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 10.0 (TID 132). 1053 bytes result sent to driver
2021-12-03 23:02:57,397 [dispatcher-event-loop-11] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 21.0 in stage 10.0 (TID 152, localhost, executor driver, partition 21, ANY, 7759 bytes)
2021-12-03 23:02:57,397 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 10.0 (TID 132) in 159 ms on localhost (executor driver) (10/22)
2021-12-03 23:02:57,397 [Executor task launch worker for task 152] INFO [org.apache.spark.executor.Executor] - Running task 21.0 in stage 10.0 (TID 152)
2021-12-03 23:02:57,401 [Executor task launch worker for task 152] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 23:02:57,401 [Executor task launch worker for task 152] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 1 ms
2021-12-03 23:02:57,403 [Executor task launch worker for task 135] INFO [org.apache.spark.executor.Executor] - Finished task 4.0 in stage 10.0 (TID 135). 1055 bytes result sent to driver
2021-12-03 23:02:57,404 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 4.0 in stage 10.0 (TID 135) in 165 ms on localhost (executor driver) (11/22)
2021-12-03 23:02:57,416 [Executor task launch worker for task 133] INFO [org.apache.spark.executor.Executor] - Finished task 2.0 in stage 10.0 (TID 133). 1055 bytes result sent to driver
2021-12-03 23:02:57,416 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 2.0 in stage 10.0 (TID 133) in 178 ms on localhost (executor driver) (12/22)
2021-12-03 23:02:57,436 [Executor task launch worker for task 145] INFO [org.apache.spark.executor.Executor] - Finished task 14.0 in stage 10.0 (TID 145). 1055 bytes result sent to driver
2021-12-03 23:02:57,437 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 14.0 in stage 10.0 (TID 145) in 79 ms on localhost (executor driver) (13/22)
2021-12-03 23:02:57,442 [Executor task launch worker for task 147] INFO [org.apache.spark.executor.Executor] - Finished task 16.0 in stage 10.0 (TID 147). 1055 bytes result sent to driver
2021-12-03 23:02:57,442 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 16.0 in stage 10.0 (TID 147) in 73 ms on localhost (executor driver) (14/22)
2021-12-03 23:02:57,449 [Executor task launch worker for task 144] INFO [org.apache.spark.executor.Executor] - Finished task 13.0 in stage 10.0 (TID 144). 1055 bytes result sent to driver
2021-12-03 23:02:57,449 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 13.0 in stage 10.0 (TID 144) in 95 ms on localhost (executor driver) (15/22)
2021-12-03 23:02:57,463 [Executor task launch worker for task 149] INFO [org.apache.spark.executor.Executor] - Finished task 18.0 in stage 10.0 (TID 149). 1055 bytes result sent to driver
2021-12-03 23:02:57,463 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 18.0 in stage 10.0 (TID 149) in 88 ms on localhost (executor driver) (16/22)
2021-12-03 23:02:57,465 [Executor task launch worker for task 150] INFO [org.apache.spark.executor.Executor] - Finished task 19.0 in stage 10.0 (TID 150). 1055 bytes result sent to driver
2021-12-03 23:02:57,465 [Executor task launch worker for task 143] INFO [org.apache.spark.executor.Executor] - Finished task 12.0 in stage 10.0 (TID 143). 1055 bytes result sent to driver
2021-12-03 23:02:57,466 [Executor task launch worker for task 146] INFO [org.apache.spark.executor.Executor] - Finished task 15.0 in stage 10.0 (TID 146). 1055 bytes result sent to driver
2021-12-03 23:02:57,466 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 19.0 in stage 10.0 (TID 150) in 85 ms on localhost (executor driver) (17/22)
2021-12-03 23:02:57,466 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 12.0 in stage 10.0 (TID 143) in 114 ms on localhost (executor driver) (18/22)
2021-12-03 23:02:57,466 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 15.0 in stage 10.0 (TID 146) in 97 ms on localhost (executor driver) (19/22)
2021-12-03 23:02:57,468 [Executor task launch worker for task 148] INFO [org.apache.spark.executor.Executor] - Finished task 17.0 in stage 10.0 (TID 148). 1098 bytes result sent to driver
2021-12-03 23:02:57,468 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 17.0 in stage 10.0 (TID 148) in 96 ms on localhost (executor driver) (20/22)
2021-12-03 23:02:57,469 [Executor task launch worker for task 151] INFO [org.apache.spark.executor.Executor] - Finished task 20.0 in stage 10.0 (TID 151). 1053 bytes result sent to driver
2021-12-03 23:02:57,469 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 20.0 in stage 10.0 (TID 151) in 87 ms on localhost (executor driver) (21/22)
2021-12-03 23:02:57,474 [Executor task launch worker for task 152] INFO [org.apache.spark.executor.Executor] - Finished task 21.0 in stage 10.0 (TID 152). 1053 bytes result sent to driver
2021-12-03 23:02:57,475 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 21.0 in stage 10.0 (TID 152) in 79 ms on localhost (executor driver) (22/22)
2021-12-03 23:02:57,475 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 10.0, whose tasks have all completed, from pool 
2021-12-03 23:02:57,475 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 10 (takeSample at PaidPromotionAdjustParameter.scala:77) finished in 0.241 s
2021-12-03 23:02:57,475 [main] INFO [org.apache.spark.scheduler.DAGScheduler] - Job 4 finished: takeSample at PaidPromotionAdjustParameter.scala:77, took 0.243490 s
2021-12-03 23:02:57,487 [main] INFO [org.apache.spark.SparkContext] - Starting job: takeSample at PaidPromotionAdjustParameter.scala:77
2021-12-03 23:02:57,487 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 5 (takeSample at PaidPromotionAdjustParameter.scala:77) with 22 output partitions
2021-12-03 23:02:57,487 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 13 (takeSample at PaidPromotionAdjustParameter.scala:77)
2021-12-03 23:02:57,487 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 12)
2021-12-03 23:02:57,487 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2021-12-03 23:02:57,488 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 13 (PartitionwiseSampledRDD[12] at takeSample at PaidPromotionAdjustParameter.scala:77), which has no missing parents
2021-12-03 23:02:57,490 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_8 stored as values in memory (estimated size 4.9 KB, free 1990.4 MB)
2021-12-03 23:02:57,491 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_8_piece0 stored as bytes in memory (estimated size 2.8 KB, free 1990.4 MB)
2021-12-03 23:02:57,491 [dispatcher-event-loop-10] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_8_piece0 in memory on qb:58628 (size: 2.8 KB, free: 1990.8 MB)
2021-12-03 23:02:57,492 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 8 from broadcast at DAGScheduler.scala:1039
2021-12-03 23:02:57,492 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 22 missing tasks from ResultStage 13 (PartitionwiseSampledRDD[12] at takeSample at PaidPromotionAdjustParameter.scala:77) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14))
2021-12-03 23:02:57,492 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 13.0 with 22 tasks
2021-12-03 23:02:57,493 [dispatcher-event-loop-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 13.0 (TID 153, localhost, executor driver, partition 0, ANY, 7868 bytes)
2021-12-03 23:02:57,493 [dispatcher-event-loop-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 13.0 (TID 154, localhost, executor driver, partition 1, ANY, 7868 bytes)
2021-12-03 23:02:57,493 [dispatcher-event-loop-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 2.0 in stage 13.0 (TID 155, localhost, executor driver, partition 2, ANY, 7868 bytes)
2021-12-03 23:02:57,493 [dispatcher-event-loop-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 3.0 in stage 13.0 (TID 156, localhost, executor driver, partition 3, ANY, 7868 bytes)
2021-12-03 23:02:57,493 [dispatcher-event-loop-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 4.0 in stage 13.0 (TID 157, localhost, executor driver, partition 4, ANY, 7868 bytes)
2021-12-03 23:02:57,493 [dispatcher-event-loop-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 5.0 in stage 13.0 (TID 158, localhost, executor driver, partition 5, ANY, 7868 bytes)
2021-12-03 23:02:57,493 [dispatcher-event-loop-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 6.0 in stage 13.0 (TID 159, localhost, executor driver, partition 6, ANY, 7868 bytes)
2021-12-03 23:02:57,493 [dispatcher-event-loop-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 7.0 in stage 13.0 (TID 160, localhost, executor driver, partition 7, ANY, 7868 bytes)
2021-12-03 23:02:57,493 [dispatcher-event-loop-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 8.0 in stage 13.0 (TID 161, localhost, executor driver, partition 8, ANY, 7868 bytes)
2021-12-03 23:02:57,493 [dispatcher-event-loop-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 9.0 in stage 13.0 (TID 162, localhost, executor driver, partition 9, ANY, 7868 bytes)
2021-12-03 23:02:57,494 [dispatcher-event-loop-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 10.0 in stage 13.0 (TID 163, localhost, executor driver, partition 10, ANY, 7868 bytes)
2021-12-03 23:02:57,494 [dispatcher-event-loop-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 11.0 in stage 13.0 (TID 164, localhost, executor driver, partition 11, ANY, 7868 bytes)
2021-12-03 23:02:57,494 [Executor task launch worker for task 153] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 13.0 (TID 153)
2021-12-03 23:02:57,494 [Executor task launch worker for task 154] INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 13.0 (TID 154)
2021-12-03 23:02:57,494 [Executor task launch worker for task 163] INFO [org.apache.spark.executor.Executor] - Running task 10.0 in stage 13.0 (TID 163)
2021-12-03 23:02:57,494 [Executor task launch worker for task 164] INFO [org.apache.spark.executor.Executor] - Running task 11.0 in stage 13.0 (TID 164)
2021-12-03 23:02:57,494 [Executor task launch worker for task 156] INFO [org.apache.spark.executor.Executor] - Running task 3.0 in stage 13.0 (TID 156)
2021-12-03 23:02:57,494 [Executor task launch worker for task 159] INFO [org.apache.spark.executor.Executor] - Running task 6.0 in stage 13.0 (TID 159)
2021-12-03 23:02:57,494 [Executor task launch worker for task 155] INFO [org.apache.spark.executor.Executor] - Running task 2.0 in stage 13.0 (TID 155)
2021-12-03 23:02:57,494 [Executor task launch worker for task 157] INFO [org.apache.spark.executor.Executor] - Running task 4.0 in stage 13.0 (TID 157)
2021-12-03 23:02:57,494 [Executor task launch worker for task 158] INFO [org.apache.spark.executor.Executor] - Running task 5.0 in stage 13.0 (TID 158)
2021-12-03 23:02:57,494 [Executor task launch worker for task 161] INFO [org.apache.spark.executor.Executor] - Running task 8.0 in stage 13.0 (TID 161)
2021-12-03 23:02:57,494 [Executor task launch worker for task 160] INFO [org.apache.spark.executor.Executor] - Running task 7.0 in stage 13.0 (TID 160)
2021-12-03 23:02:57,494 [Executor task launch worker for task 162] INFO [org.apache.spark.executor.Executor] - Running task 9.0 in stage 13.0 (TID 162)
2021-12-03 23:02:57,497 [Executor task launch worker for task 161] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 23:02:57,497 [Executor task launch worker for task 164] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 23:02:57,497 [Executor task launch worker for task 156] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 23:02:57,497 [Executor task launch worker for task 164] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 23:02:57,497 [Executor task launch worker for task 161] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 23:02:57,497 [Executor task launch worker for task 156] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 23:02:57,497 [Executor task launch worker for task 163] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 23:02:57,497 [Executor task launch worker for task 163] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 23:02:57,498 [Executor task launch worker for task 162] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 23:02:57,498 [Executor task launch worker for task 162] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 1 ms
2021-12-03 23:02:57,498 [Executor task launch worker for task 160] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 23:02:57,498 [Executor task launch worker for task 160] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 23:02:57,498 [Executor task launch worker for task 159] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 23:02:57,498 [Executor task launch worker for task 159] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 23:02:57,498 [Executor task launch worker for task 154] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 23:02:57,499 [Executor task launch worker for task 154] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 1 ms
2021-12-03 23:02:57,499 [Executor task launch worker for task 153] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 23:02:57,499 [Executor task launch worker for task 153] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 23:02:57,499 [Executor task launch worker for task 155] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 23:02:57,499 [Executor task launch worker for task 155] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 23:02:57,499 [Executor task launch worker for task 157] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 23:02:57,499 [Executor task launch worker for task 157] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 23:02:57,500 [Executor task launch worker for task 158] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 23:02:57,500 [Executor task launch worker for task 158] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 23:02:57,564 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 161
2021-12-03 23:02:57,564 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 171
2021-12-03 23:02:57,564 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 157
2021-12-03 23:02:57,564 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 167
2021-12-03 23:02:57,564 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 156
2021-12-03 23:02:57,564 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 160
2021-12-03 23:02:57,564 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 174
2021-12-03 23:02:57,564 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 153
2021-12-03 23:02:57,564 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 162
2021-12-03 23:02:57,564 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 150
2021-12-03 23:02:57,564 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 169
2021-12-03 23:02:57,564 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 166
2021-12-03 23:02:57,564 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 170
2021-12-03 23:02:57,564 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 155
2021-12-03 23:02:57,564 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 152
2021-12-03 23:02:57,568 [dispatcher-event-loop-6] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_7_piece0 on qb:58628 in memory (size: 2.4 KB, free: 1990.8 MB)
2021-12-03 23:02:57,571 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 158
2021-12-03 23:02:57,572 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 154
2021-12-03 23:02:57,572 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 173
2021-12-03 23:02:57,572 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 172
2021-12-03 23:02:57,572 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 151
2021-12-03 23:02:57,572 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 159
2021-12-03 23:02:57,572 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 164
2021-12-03 23:02:57,572 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 165
2021-12-03 23:02:57,572 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 163
2021-12-03 23:02:57,572 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 168
2021-12-03 23:02:57,635 [Executor task launch worker for task 153] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 13.0 (TID 153). 1097 bytes result sent to driver
2021-12-03 23:02:57,636 [dispatcher-event-loop-7] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 12.0 in stage 13.0 (TID 165, localhost, executor driver, partition 12, ANY, 7868 bytes)
2021-12-03 23:02:57,636 [Executor task launch worker for task 165] INFO [org.apache.spark.executor.Executor] - Running task 12.0 in stage 13.0 (TID 165)
2021-12-03 23:02:57,636 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 13.0 (TID 153) in 144 ms on localhost (executor driver) (1/22)
2021-12-03 23:02:57,639 [Executor task launch worker for task 165] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 23:02:57,639 [Executor task launch worker for task 165] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 23:02:57,652 [Executor task launch worker for task 154] INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 13.0 (TID 154). 1097 bytes result sent to driver
2021-12-03 23:02:57,652 [Executor task launch worker for task 162] INFO [org.apache.spark.executor.Executor] - Finished task 9.0 in stage 13.0 (TID 162). 824799 bytes result sent to driver
2021-12-03 23:02:57,653 [dispatcher-event-loop-4] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 13.0 in stage 13.0 (TID 166, localhost, executor driver, partition 13, ANY, 7868 bytes)
2021-12-03 23:02:57,653 [Executor task launch worker for task 166] INFO [org.apache.spark.executor.Executor] - Running task 13.0 in stage 13.0 (TID 166)
2021-12-03 23:02:57,653 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 13.0 (TID 154) in 160 ms on localhost (executor driver) (2/22)
2021-12-03 23:02:57,654 [dispatcher-event-loop-4] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 14.0 in stage 13.0 (TID 167, localhost, executor driver, partition 14, ANY, 7868 bytes)
2021-12-03 23:02:57,654 [Executor task launch worker for task 167] INFO [org.apache.spark.executor.Executor] - Running task 14.0 in stage 13.0 (TID 167)
2021-12-03 23:02:57,658 [Executor task launch worker for task 166] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 23:02:57,658 [Executor task launch worker for task 166] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 1 ms
2021-12-03 23:02:57,658 [Executor task launch worker for task 167] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 23:02:57,658 [Executor task launch worker for task 167] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 23:02:57,662 [Executor task launch worker for task 163] INFO [org.apache.spark.executor.Executor] - Finished task 10.0 in stage 13.0 (TID 163). 929622 bytes result sent to driver
2021-12-03 23:02:57,663 [Executor task launch worker for task 161] INFO [org.apache.spark.executor.Executor] - Finished task 8.0 in stage 13.0 (TID 161). 1033879 bytes result sent to driver
2021-12-03 23:02:57,664 [dispatcher-event-loop-5] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 15.0 in stage 13.0 (TID 168, localhost, executor driver, partition 15, ANY, 7868 bytes)
2021-12-03 23:02:57,664 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 9.0 in stage 13.0 (TID 162) in 171 ms on localhost (executor driver) (3/22)
2021-12-03 23:02:57,664 [Executor task launch worker for task 168] INFO [org.apache.spark.executor.Executor] - Running task 15.0 in stage 13.0 (TID 168)
2021-12-03 23:02:57,665 [dispatcher-event-loop-5] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 16.0 in stage 13.0 (TID 169, localhost, executor driver, partition 16, ANY, 7868 bytes)
2021-12-03 23:02:57,665 [Executor task launch worker for task 169] INFO [org.apache.spark.executor.Executor] - Running task 16.0 in stage 13.0 (TID 169)
2021-12-03 23:02:57,668 [Executor task launch worker for task 168] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 23:02:57,668 [Executor task launch worker for task 168] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 23:02:57,668 [Executor task launch worker for task 169] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 23:02:57,668 [Executor task launch worker for task 169] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 23:02:57,671 [Executor task launch worker for task 158] INFO [org.apache.spark.executor.Executor] - Finished task 5.0 in stage 13.0 (TID 158). 772071 bytes result sent to driver
2021-12-03 23:02:57,671 [Executor task launch worker for task 160] INFO [org.apache.spark.storage.memory.MemoryStore] - Block taskresult_160 stored as bytes in memory (estimated size 1219.4 KB, free 1989.3 MB)
2021-12-03 23:02:57,672 [Executor task launch worker for task 157] INFO [org.apache.spark.executor.Executor] - Finished task 4.0 in stage 13.0 (TID 157). 969612 bytes result sent to driver
2021-12-03 23:02:57,672 [dispatcher-event-loop-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 17.0 in stage 13.0 (TID 170, localhost, executor driver, partition 17, ANY, 7868 bytes)
2021-12-03 23:02:57,672 [Executor task launch worker for task 170] INFO [org.apache.spark.executor.Executor] - Running task 17.0 in stage 13.0 (TID 170)
2021-12-03 23:02:57,672 [dispatcher-event-loop-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 18.0 in stage 13.0 (TID 171, localhost, executor driver, partition 18, ANY, 7868 bytes)
2021-12-03 23:02:57,673 [Executor task launch worker for task 171] INFO [org.apache.spark.executor.Executor] - Running task 18.0 in stage 13.0 (TID 171)
2021-12-03 23:02:57,673 [Executor task launch worker for task 155] INFO [org.apache.spark.executor.Executor] - Finished task 2.0 in stage 13.0 (TID 155). 611173 bytes result sent to driver
2021-12-03 23:02:57,674 [dispatcher-event-loop-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 19.0 in stage 13.0 (TID 172, localhost, executor driver, partition 19, ANY, 7868 bytes)
2021-12-03 23:02:57,674 [Executor task launch worker for task 172] INFO [org.apache.spark.executor.Executor] - Running task 19.0 in stage 13.0 (TID 172)
2021-12-03 23:02:57,674 [dispatcher-event-loop-3] INFO [org.apache.spark.storage.BlockManagerInfo] - Added taskresult_160 in memory on qb:58628 (size: 1219.4 KB, free: 1989.6 MB)
2021-12-03 23:02:57,676 [Executor task launch worker for task 160] INFO [org.apache.spark.executor.Executor] - Finished task 7.0 in stage 13.0 (TID 160). 1248708 bytes result sent via BlockManager)
2021-12-03 23:02:57,676 [Executor task launch worker for task 171] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 23:02:57,676 [Executor task launch worker for task 171] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 23:02:57,676 [Executor task launch worker for task 172] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 23:02:57,676 [Executor task launch worker for task 172] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 23:02:57,677 [dispatcher-event-loop-11] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 20.0 in stage 13.0 (TID 173, localhost, executor driver, partition 20, ANY, 7868 bytes)
2021-12-03 23:02:57,679 [Executor task launch worker for task 173] INFO [org.apache.spark.executor.Executor] - Running task 20.0 in stage 13.0 (TID 173)
2021-12-03 23:02:57,682 [Executor task launch worker for task 173] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 23:02:57,682 [Executor task launch worker for task 173] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 23:02:57,690 [Executor task launch worker for task 156] INFO [org.apache.spark.executor.Executor] - Finished task 3.0 in stage 13.0 (TID 156). 996970 bytes result sent to driver
2021-12-03 23:02:57,691 [dispatcher-event-loop-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 21.0 in stage 13.0 (TID 174, localhost, executor driver, partition 21, ANY, 7868 bytes)
2021-12-03 23:02:57,691 [Executor task launch worker for task 174] INFO [org.apache.spark.executor.Executor] - Running task 21.0 in stage 13.0 (TID 174)
2021-12-03 23:02:57,692 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 8.0 in stage 13.0 (TID 161) in 199 ms on localhost (executor driver) (4/22)
2021-12-03 23:02:57,692 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 5.0 in stage 13.0 (TID 158) in 199 ms on localhost (executor driver) (5/22)
2021-12-03 23:02:57,694 [Executor task launch worker for task 174] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 23:02:57,694 [Executor task launch worker for task 174] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 23:02:57,696 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 4.0 in stage 13.0 (TID 157) in 203 ms on localhost (executor driver) (6/22)
2021-12-03 23:02:57,698 [Executor task launch worker for task 164] INFO [org.apache.spark.executor.Executor] - Finished task 11.0 in stage 13.0 (TID 164). 838990 bytes result sent to driver
2021-12-03 23:02:57,700 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 10.0 in stage 13.0 (TID 163) in 207 ms on localhost (executor driver) (7/22)
2021-12-03 23:02:57,701 [Executor task launch worker for task 170] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-03 23:02:57,701 [Executor task launch worker for task 170] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-03 23:02:57,701 [Executor task launch worker for task 159] INFO [org.apache.spark.executor.Executor] - Finished task 6.0 in stage 13.0 (TID 159). 1024835 bytes result sent to driver
2021-12-03 23:02:57,707 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 2.0 in stage 13.0 (TID 155) in 214 ms on localhost (executor driver) (8/22)
2021-12-03 23:02:57,715 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 3.0 in stage 13.0 (TID 156) in 222 ms on localhost (executor driver) (9/22)
2021-12-03 23:02:57,715 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 11.0 in stage 13.0 (TID 164) in 221 ms on localhost (executor driver) (10/22)
2021-12-03 23:02:57,719 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 6.0 in stage 13.0 (TID 159) in 226 ms on localhost (executor driver) (11/22)
2021-12-03 23:02:57,741 [Executor task launch worker for task 167] INFO [org.apache.spark.executor.Executor] - Finished task 14.0 in stage 13.0 (TID 167). 606688 bytes result sent to driver
2021-12-03 23:02:57,744 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 14.0 in stage 13.0 (TID 167) in 90 ms on localhost (executor driver) (12/22)
2021-12-03 23:02:57,748 [task-result-getter-0] INFO [org.apache.spark.network.client.TransportClientFactory] - Successfully created connection to qb/192.168.2.180:58628 after 35 ms (0 ms spent in bootstraps)
2021-12-03 23:02:57,785 [Executor task launch worker for task 173] INFO [org.apache.spark.executor.Executor] - Finished task 20.0 in stage 13.0 (TID 173). 1054 bytes result sent to driver
2021-12-03 23:02:57,785 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 20.0 in stage 13.0 (TID 173) in 108 ms on localhost (executor driver) (13/22)
2021-12-03 23:02:57,789 [Executor task launch worker for task 168] INFO [org.apache.spark.executor.Executor] - Finished task 15.0 in stage 13.0 (TID 168). 1001737 bytes result sent to driver
2021-12-03 23:02:57,791 [Executor task launch worker for task 165] INFO [org.apache.spark.storage.memory.MemoryStore] - Block taskresult_165 stored as bytes in memory (estimated size 1170.2 KB, free 1968.0 MB)
2021-12-03 23:02:57,791 [dispatcher-event-loop-9] INFO [org.apache.spark.storage.BlockManagerInfo] - Added taskresult_165 in memory on qb:58628 (size: 1170.2 KB, free: 1988.4 MB)
2021-12-03 23:02:57,792 [Executor task launch worker for task 165] INFO [org.apache.spark.executor.Executor] - Finished task 12.0 in stage 13.0 (TID 165). 1198316 bytes result sent via BlockManager)
2021-12-03 23:02:57,795 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 15.0 in stage 13.0 (TID 168) in 132 ms on localhost (executor driver) (14/22)
2021-12-03 23:02:57,798 [Executor task launch worker for task 166] INFO [org.apache.spark.storage.memory.MemoryStore] - Block taskresult_166 stored as bytes in memory (estimated size 1061.5 KB, free 1972.0 MB)
2021-12-03 23:02:57,798 [dispatcher-event-loop-10] INFO [org.apache.spark.storage.BlockManagerInfo] - Added taskresult_166 in memory on qb:58628 (size: 1061.5 KB, free: 1987.4 MB)
2021-12-03 23:02:57,798 [Executor task launch worker for task 166] INFO [org.apache.spark.executor.Executor] - Finished task 13.0 in stage 13.0 (TID 166). 1086995 bytes result sent via BlockManager)
2021-12-03 23:02:57,802 [Executor task launch worker for task 171] INFO [org.apache.spark.executor.Executor] - Finished task 18.0 in stage 13.0 (TID 171). 955972 bytes result sent to driver
2021-12-03 23:02:57,805 [Executor task launch worker for task 169] INFO [org.apache.spark.executor.Executor] - Finished task 16.0 in stage 13.0 (TID 169). 752131 bytes result sent to driver
2021-12-03 23:02:57,806 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 18.0 in stage 13.0 (TID 171) in 134 ms on localhost (executor driver) (15/22)
2021-12-03 23:02:57,807 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 16.0 in stage 13.0 (TID 169) in 142 ms on localhost (executor driver) (16/22)
2021-12-03 23:02:57,808 [Executor task launch worker for task 174] INFO [org.apache.spark.executor.Executor] - Finished task 21.0 in stage 13.0 (TID 174). 1054 bytes result sent to driver
2021-12-03 23:02:57,808 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 21.0 in stage 13.0 (TID 174) in 117 ms on localhost (executor driver) (17/22)
2021-12-03 23:02:57,810 [Executor task launch worker for task 172] INFO [org.apache.spark.executor.Executor] - Finished task 19.0 in stage 13.0 (TID 172). 551440 bytes result sent to driver
2021-12-03 23:02:57,811 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 19.0 in stage 13.0 (TID 172) in 137 ms on localhost (executor driver) (18/22)
2021-12-03 23:02:57,816 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 7.0 in stage 13.0 (TID 160) in 323 ms on localhost (executor driver) (19/22)
2021-12-03 23:02:57,817 [dispatcher-event-loop-3] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed taskresult_160 on qb:58628 in memory (size: 1219.4 KB, free: 1988.6 MB)
2021-12-03 23:02:57,826 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 12.0 in stage 13.0 (TID 165) in 191 ms on localhost (executor driver) (20/22)
2021-12-03 23:02:57,827 [dispatcher-event-loop-10] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed taskresult_165 on qb:58628 in memory (size: 1170.2 KB, free: 1989.7 MB)
2021-12-03 23:02:57,830 [Executor task launch worker for task 170] INFO [org.apache.spark.storage.memory.MemoryStore] - Block taskresult_170 stored as bytes in memory (estimated size 1256.5 KB, free 1988.2 MB)
2021-12-03 23:02:57,830 [dispatcher-event-loop-1] INFO [org.apache.spark.storage.BlockManagerInfo] - Added taskresult_170 in memory on qb:58628 (size: 1256.5 KB, free: 1988.5 MB)
2021-12-03 23:02:57,830 [Executor task launch worker for task 170] INFO [org.apache.spark.executor.Executor] - Finished task 17.0 in stage 13.0 (TID 170). 1286658 bytes result sent via BlockManager)
2021-12-03 23:02:57,835 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 13.0 in stage 13.0 (TID 166) in 182 ms on localhost (executor driver) (21/22)
2021-12-03 23:02:57,836 [dispatcher-event-loop-0] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed taskresult_166 on qb:58628 in memory (size: 1061.5 KB, free: 1989.5 MB)
2021-12-03 23:02:57,846 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 17.0 in stage 13.0 (TID 170) in 174 ms on localhost (executor driver) (22/22)
2021-12-03 23:02:57,846 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 13.0, whose tasks have all completed, from pool 
2021-12-03 23:02:57,846 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 13 (takeSample at PaidPromotionAdjustParameter.scala:77) finished in 0.357 s
2021-12-03 23:02:57,846 [dispatcher-event-loop-3] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed taskresult_170 on qb:58628 in memory (size: 1256.5 KB, free: 1990.8 MB)
2021-12-03 23:02:57,846 [main] INFO [org.apache.spark.scheduler.DAGScheduler] - Job 5 finished: takeSample at PaidPromotionAdjustParameter.scala:77, took 0.359283 s
2021-12-03 23:02:57,911 [main] INFO [PaidPromotion$] - 小数据集个数：500000
2021-12-03 23:02:58,120 [main] INFO [org.apache.spark.SparkContext] - Starting job: count at PaidPromotionAdjustParameter.scala:85
2021-12-03 23:02:58,120 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 6 (count at PaidPromotionAdjustParameter.scala:85) with 22 output partitions
2021-12-03 23:02:58,121 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 14 (count at PaidPromotionAdjustParameter.scala:85)
2021-12-03 23:02:58,121 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List()
2021-12-03 23:02:58,121 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2021-12-03 23:02:58,121 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 14 (MapPartitionsRDD[14] at map at PaidPromotionAdjustParameter.scala:83), which has no missing parents
2021-12-03 23:02:58,296 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_9 stored as values in memory (estimated size 16.7 MB, free 1973.8 MB)
2021-12-03 23:02:58,332 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_9_piece0 stored as bytes in memory (estimated size 4.0 MB, free 1969.8 MB)
2021-12-03 23:02:58,333 [dispatcher-event-loop-11] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_9_piece0 in memory on qb:58628 (size: 4.0 MB, free: 1986.8 MB)
2021-12-03 23:02:58,333 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_9_piece1 stored as bytes in memory (estimated size 1768.8 KB, free 1968.0 MB)
2021-12-03 23:02:58,334 [dispatcher-event-loop-4] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_9_piece1 in memory on qb:58628 (size: 1768.8 KB, free: 1985.0 MB)
2021-12-03 23:02:58,334 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 9 from broadcast at DAGScheduler.scala:1039
2021-12-03 23:02:58,334 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 22 missing tasks from ResultStage 14 (MapPartitionsRDD[14] at map at PaidPromotionAdjustParameter.scala:83) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14))
2021-12-03 23:02:58,334 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 14.0 with 22 tasks
2021-12-03 23:02:58,335 [dispatcher-event-loop-10] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 14.0 (TID 175, localhost, executor driver, partition 0, ANY, 7903 bytes)
2021-12-03 23:02:58,335 [dispatcher-event-loop-10] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 14.0 (TID 176, localhost, executor driver, partition 1, ANY, 7903 bytes)
2021-12-03 23:02:58,335 [dispatcher-event-loop-10] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 2.0 in stage 14.0 (TID 177, localhost, executor driver, partition 2, ANY, 7903 bytes)
2021-12-03 23:02:58,335 [dispatcher-event-loop-10] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 3.0 in stage 14.0 (TID 178, localhost, executor driver, partition 3, ANY, 7903 bytes)
2021-12-03 23:02:58,336 [dispatcher-event-loop-10] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 4.0 in stage 14.0 (TID 179, localhost, executor driver, partition 4, ANY, 7903 bytes)
2021-12-03 23:02:58,336 [dispatcher-event-loop-10] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 5.0 in stage 14.0 (TID 180, localhost, executor driver, partition 5, ANY, 7903 bytes)
2021-12-03 23:02:58,336 [dispatcher-event-loop-10] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 6.0 in stage 14.0 (TID 181, localhost, executor driver, partition 6, ANY, 7903 bytes)
2021-12-03 23:02:58,336 [dispatcher-event-loop-10] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 7.0 in stage 14.0 (TID 182, localhost, executor driver, partition 7, ANY, 7903 bytes)
2021-12-03 23:02:58,336 [dispatcher-event-loop-10] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 8.0 in stage 14.0 (TID 183, localhost, executor driver, partition 8, ANY, 7903 bytes)
2021-12-03 23:02:58,336 [dispatcher-event-loop-10] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 9.0 in stage 14.0 (TID 184, localhost, executor driver, partition 9, ANY, 7903 bytes)
2021-12-03 23:02:58,337 [dispatcher-event-loop-10] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 10.0 in stage 14.0 (TID 185, localhost, executor driver, partition 10, ANY, 7903 bytes)
2021-12-03 23:02:58,337 [dispatcher-event-loop-10] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 11.0 in stage 14.0 (TID 186, localhost, executor driver, partition 11, ANY, 7903 bytes)
2021-12-03 23:02:58,337 [Executor task launch worker for task 176] INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 14.0 (TID 176)
2021-12-03 23:02:58,337 [Executor task launch worker for task 183] INFO [org.apache.spark.executor.Executor] - Running task 8.0 in stage 14.0 (TID 183)
2021-12-03 23:02:58,337 [Executor task launch worker for task 182] INFO [org.apache.spark.executor.Executor] - Running task 7.0 in stage 14.0 (TID 182)
2021-12-03 23:02:58,337 [Executor task launch worker for task 180] INFO [org.apache.spark.executor.Executor] - Running task 5.0 in stage 14.0 (TID 180)
2021-12-03 23:02:58,337 [Executor task launch worker for task 181] INFO [org.apache.spark.executor.Executor] - Running task 6.0 in stage 14.0 (TID 181)
2021-12-03 23:02:58,337 [Executor task launch worker for task 178] INFO [org.apache.spark.executor.Executor] - Running task 3.0 in stage 14.0 (TID 178)
2021-12-03 23:02:58,337 [Executor task launch worker for task 175] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 14.0 (TID 175)
2021-12-03 23:02:58,337 [Executor task launch worker for task 177] INFO [org.apache.spark.executor.Executor] - Running task 2.0 in stage 14.0 (TID 177)
2021-12-03 23:02:58,337 [Executor task launch worker for task 179] INFO [org.apache.spark.executor.Executor] - Running task 4.0 in stage 14.0 (TID 179)
2021-12-03 23:02:58,337 [Executor task launch worker for task 185] INFO [org.apache.spark.executor.Executor] - Running task 10.0 in stage 14.0 (TID 185)
2021-12-03 23:02:58,337 [Executor task launch worker for task 186] INFO [org.apache.spark.executor.Executor] - Running task 11.0 in stage 14.0 (TID 186)
2021-12-03 23:02:58,337 [Executor task launch worker for task 184] INFO [org.apache.spark.executor.Executor] - Running task 9.0 in stage 14.0 (TID 184)
2021-12-03 23:02:58,520 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 26
2021-12-03 23:02:58,520 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 176
2021-12-03 23:02:58,520 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 48
2021-12-03 23:02:58,520 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 59
2021-12-03 23:02:58,520 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 63
2021-12-03 23:02:58,520 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 34
2021-12-03 23:02:58,520 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 40
2021-12-03 23:02:58,520 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 73
2021-12-03 23:02:58,520 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 188
2021-12-03 23:02:58,520 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 197
2021-12-03 23:02:58,520 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 62
2021-12-03 23:02:58,520 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 184
2021-12-03 23:02:58,520 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 177
2021-12-03 23:02:58,520 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 45
2021-12-03 23:02:58,520 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 193
2021-12-03 23:02:58,520 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 179
2021-12-03 23:02:58,520 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 68
2021-12-03 23:02:58,520 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 51
2021-12-03 23:02:58,521 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 74
2021-12-03 23:02:58,521 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 43
2021-12-03 23:02:58,521 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 54
2021-12-03 23:02:58,521 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 194
2021-12-03 23:02:58,521 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 53
2021-12-03 23:02:58,521 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 192
2021-12-03 23:02:58,521 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 70
2021-12-03 23:02:58,521 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 199
2021-12-03 23:02:58,521 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 67
2021-12-03 23:02:58,521 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 32
2021-12-03 23:02:58,521 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 181
2021-12-03 23:02:58,521 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 180
2021-12-03 23:02:58,521 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 60
2021-12-03 23:02:58,521 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 25
2021-12-03 23:02:58,521 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 31
2021-12-03 23:02:58,521 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 27
2021-12-03 23:02:58,521 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 49
2021-12-03 23:02:58,521 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 196
2021-12-03 23:02:58,524 [dispatcher-event-loop-2] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_2_piece0 on qb:58628 in memory (size: 2.7 KB, free: 1985.0 MB)
2021-12-03 23:02:58,558 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 190
2021-12-03 23:02:58,558 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 178
2021-12-03 23:02:58,558 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 195
2021-12-03 23:02:58,558 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 56
2021-12-03 23:02:58,558 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 71
2021-12-03 23:02:58,558 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 55
2021-12-03 23:02:58,558 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 198
2021-12-03 23:02:58,558 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 50
2021-12-03 23:02:58,558 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 52
2021-12-03 23:02:58,558 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 58
2021-12-03 23:02:58,558 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 61
2021-12-03 23:02:58,559 [dispatcher-event-loop-6] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_3_piece0 on qb:58628 in memory (size: 1906.0 B, free: 1985.0 MB)
2021-12-03 23:02:58,560 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 186
2021-12-03 23:02:58,560 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 38
2021-12-03 23:02:58,560 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 187
2021-12-03 23:02:58,560 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 64
2021-12-03 23:02:58,561 [dispatcher-event-loop-3] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_8_piece0 on qb:58628 in memory (size: 2.8 KB, free: 1985.0 MB)
2021-12-03 23:02:58,561 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 46
2021-12-03 23:02:58,561 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 57
2021-12-03 23:02:58,561 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 39
2021-12-03 23:02:58,561 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 37
2021-12-03 23:02:58,561 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 47
2021-12-03 23:02:58,562 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 69
2021-12-03 23:02:58,562 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 33
2021-12-03 23:02:58,562 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 175
2021-12-03 23:02:58,562 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 28
2021-12-03 23:02:58,562 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 66
2021-12-03 23:02:58,562 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 29
2021-12-03 23:02:58,562 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 191
2021-12-03 23:02:58,562 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 183
2021-12-03 23:02:58,562 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 41
2021-12-03 23:02:58,562 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 182
2021-12-03 23:02:58,562 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 36
2021-12-03 23:02:58,562 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 44
2021-12-03 23:02:58,562 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 35
2021-12-03 23:02:58,562 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 72
2021-12-03 23:02:58,562 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 65
2021-12-03 23:02:58,562 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 30
2021-12-03 23:02:58,562 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 185
2021-12-03 23:02:58,562 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 42
2021-12-03 23:02:58,562 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 189
2021-12-03 23:02:59,868 [Executor task launch worker for task 181] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:805306368+134217728
2021-12-03 23:02:59,871 [Executor task launch worker for task 176] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:134217728+134217728
2021-12-03 23:02:59,871 [Executor task launch worker for task 184] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:1207959552+134217728
2021-12-03 23:02:59,871 [Executor task launch worker for task 177] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:268435456+134217728
2021-12-03 23:02:59,877 [Executor task launch worker for task 179] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:536870912+134217728
2021-12-03 23:02:59,877 [Executor task launch worker for task 185] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:1342177280+134217728
2021-12-03 23:02:59,879 [Executor task launch worker for task 178] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:402653184+134217728
2021-12-03 23:02:59,880 [Executor task launch worker for task 175] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:0+134217728
2021-12-03 23:02:59,882 [Executor task launch worker for task 183] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:1073741824+134217728
2021-12-03 23:02:59,888 [Executor task launch worker for task 182] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:939524096+134217728
2021-12-03 23:02:59,895 [Executor task launch worker for task 180] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:671088640+134217728
2021-12-03 23:02:59,898 [Executor task launch worker for task 186] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:1476395008+134217728
