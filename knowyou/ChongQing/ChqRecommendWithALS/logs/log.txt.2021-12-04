2021-12-04 14:58:30,834 [Executor task launch worker for task 176] INFO [org.apache.hadoop.hdfs.DFSClient] - Access token was invalid when connecting to /192.168.1.34:50010 : org.apache.hadoop.hdfs.security.token.block.InvalidBlockTokenException: Got access token error, status message , for OP_READ_BLOCK, self=/192.168.2.180:63985, remote=/192.168.1.34:50010, for file /sk/chongqing/data/behavior_data.bcp, for pool BP-1090623929-172.16.1.222-1605776978734 block 1074047875_307770
2021-12-04 14:58:30,963 [Executor task launch worker for task 176] INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 14.0 (TID 176). 797 bytes result sent to driver
2021-12-04 14:58:30,976 [dispatcher-event-loop-4] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 12.0 in stage 14.0 (TID 187, localhost, executor driver, partition 12, ANY, 7903 bytes)
2021-12-04 14:58:30,977 [Executor task launch worker for task 187] INFO [org.apache.spark.executor.Executor] - Running task 12.0 in stage 14.0 (TID 187)
2021-12-04 14:58:30,985 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 14.0 (TID 176) in 57332650 ms on localhost (executor driver) (1/22)
2021-12-04 14:58:31,159 [Executor task launch worker for task 187] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:1610612736+134217728
2021-12-04 14:58:33,816 [Executor task launch worker for task 180] INFO [org.apache.hadoop.hdfs.DFSClient] - Access token was invalid when connecting to /192.168.1.33:50010 : org.apache.hadoop.hdfs.security.token.block.InvalidBlockTokenException: Got access token error, status message , for OP_READ_BLOCK, self=/192.168.2.180:63992, remote=/192.168.1.33:50010, for file /sk/chongqing/data/behavior_data.bcp, for pool BP-1090623929-172.16.1.222-1605776978734 block 1074047907_307802
2021-12-04 14:58:33,895 [Executor task launch worker for task 180] INFO [org.apache.spark.executor.Executor] - Finished task 5.0 in stage 14.0 (TID 180). 797 bytes result sent to driver
2021-12-04 14:58:33,895 [dispatcher-event-loop-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 13.0 in stage 14.0 (TID 188, localhost, executor driver, partition 13, ANY, 7903 bytes)
2021-12-04 14:58:33,896 [Executor task launch worker for task 188] INFO [org.apache.spark.executor.Executor] - Running task 13.0 in stage 14.0 (TID 188)
2021-12-04 14:58:33,907 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 5.0 in stage 14.0 (TID 180) in 57335571 ms on localhost (executor driver) (2/22)
2021-12-04 14:58:34,059 [Executor task launch worker for task 188] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:1744830464+134217728
2021-12-04 15:01:26,058 [Executor task launch worker for task 186] INFO [org.apache.hadoop.hdfs.DFSClient] - Access token was invalid when connecting to /192.168.1.34:50010 : org.apache.hadoop.hdfs.security.token.block.InvalidBlockTokenException: Got access token error, status message , for OP_READ_BLOCK, self=/192.168.2.180:54854, remote=/192.168.1.34:50010, for file /sk/chongqing/data/behavior_data.bcp, for pool BP-1090623929-172.16.1.222-1605776978734 block 1074047958_307854
2021-12-04 15:01:26,190 [Executor task launch worker for task 186] INFO [org.apache.spark.executor.Executor] - Finished task 11.0 in stage 14.0 (TID 186). 797 bytes result sent to driver
2021-12-04 15:01:26,190 [dispatcher-event-loop-6] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 14.0 in stage 14.0 (TID 189, localhost, executor driver, partition 14, ANY, 7903 bytes)
2021-12-04 15:01:26,190 [Executor task launch worker for task 189] INFO [org.apache.spark.executor.Executor] - Running task 14.0 in stage 14.0 (TID 189)
2021-12-04 15:01:26,191 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 11.0 in stage 14.0 (TID 186) in 57507854 ms on localhost (executor driver) (3/22)
2021-12-04 15:01:26,391 [Executor task launch worker for task 189] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:1879048192+134217728
2021-12-04 15:14:57,573 [Executor task launch worker for task 175] INFO [org.apache.hadoop.hdfs.DFSClient] - Access token was invalid when connecting to /192.168.1.33:50010 : org.apache.hadoop.hdfs.security.token.block.InvalidBlockTokenException: Got access token error, status message , for OP_READ_BLOCK, self=/192.168.2.180:63677, remote=/192.168.1.33:50010, for file /sk/chongqing/data/behavior_data.bcp, for pool BP-1090623929-172.16.1.222-1605776978734 block 1074047869_307764
2021-12-04 15:14:57,698 [Executor task launch worker for task 175] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 14.0 (TID 175). 797 bytes result sent to driver
2021-12-04 15:14:57,699 [dispatcher-event-loop-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 15.0 in stage 14.0 (TID 190, localhost, executor driver, partition 15, ANY, 7903 bytes)
2021-12-04 15:14:57,699 [Executor task launch worker for task 190] INFO [org.apache.spark.executor.Executor] - Running task 15.0 in stage 14.0 (TID 190)
2021-12-04 15:14:57,708 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 14.0 (TID 175) in 58319373 ms on localhost (executor driver) (4/22)
2021-12-04 15:14:57,884 [Executor task launch worker for task 190] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:2013265920+134217728
2021-12-04 15:15:03,727 [Executor task launch worker for task 177] INFO [org.apache.hadoop.hdfs.DFSClient] - Access token was invalid when connecting to /192.168.1.33:50010 : org.apache.hadoop.hdfs.security.token.block.InvalidBlockTokenException: Got access token error, status message , for OP_READ_BLOCK, self=/192.168.2.180:63683, remote=/192.168.1.33:50010, for file /sk/chongqing/data/behavior_data.bcp, for pool BP-1090623929-172.16.1.222-1605776978734 block 1074047878_307773
2021-12-04 15:15:03,842 [Executor task launch worker for task 177] INFO [org.apache.spark.executor.Executor] - Finished task 2.0 in stage 14.0 (TID 177). 797 bytes result sent to driver
2021-12-04 15:15:03,847 [dispatcher-event-loop-9] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 16.0 in stage 14.0 (TID 191, localhost, executor driver, partition 16, ANY, 7903 bytes)
2021-12-04 15:15:03,847 [Executor task launch worker for task 191] INFO [org.apache.spark.executor.Executor] - Running task 16.0 in stage 14.0 (TID 191)
2021-12-04 15:15:03,847 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 2.0 in stage 14.0 (TID 177) in 58325512 ms on localhost (executor driver) (5/22)
2021-12-04 15:15:03,999 [Executor task launch worker for task 191] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:2147483648+134217728
2021-12-04 16:49:25,167 [main] INFO [org.apache.spark.SparkContext] - Running Spark version 2.3.0
2021-12-04 16:49:25,464 [main] INFO [org.apache.spark.SparkContext] - Submitted application: PaidPromotion
2021-12-04 16:49:25,511 [main] INFO [org.apache.spark.SecurityManager] - Changing view acls to: ACER,root
2021-12-04 16:49:25,511 [main] INFO [org.apache.spark.SecurityManager] - Changing modify acls to: ACER,root
2021-12-04 16:49:25,512 [main] INFO [org.apache.spark.SecurityManager] - Changing view acls groups to: 
2021-12-04 16:49:25,512 [main] INFO [org.apache.spark.SecurityManager] - Changing modify acls groups to: 
2021-12-04 16:49:25,513 [main] INFO [org.apache.spark.SecurityManager] - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(ACER, root); groups with view permissions: Set(); users  with modify permissions: Set(ACER, root); groups with modify permissions: Set()
2021-12-04 16:49:26,080 [main] INFO [org.apache.spark.util.Utils] - Successfully started service 'sparkDriver' on port 49390.
2021-12-04 16:49:26,095 [main] INFO [org.apache.spark.SparkEnv] - Registering MapOutputTracker
2021-12-04 16:49:26,109 [main] INFO [org.apache.spark.SparkEnv] - Registering BlockManagerMaster
2021-12-04 16:49:26,111 [main] INFO [org.apache.spark.storage.BlockManagerMasterEndpoint] - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2021-12-04 16:49:26,111 [main] INFO [org.apache.spark.storage.BlockManagerMasterEndpoint] - BlockManagerMasterEndpoint up
2021-12-04 16:49:26,118 [main] INFO [org.apache.spark.storage.DiskBlockManager] - Created local directory at C:\Users\ACER\AppData\Local\Temp\blockmgr-d64065d9-fea0-408b-9d30-c089ae18dffb
2021-12-04 16:49:26,132 [main] INFO [org.apache.spark.storage.memory.MemoryStore] - MemoryStore started with capacity 1990.8 MB
2021-12-04 16:49:26,141 [main] INFO [org.apache.spark.SparkEnv] - Registering OutputCommitCoordinator
2021-12-04 16:49:26,191 [main] INFO [org.spark_project.jetty.util.log] - Logging initialized @1839ms
2021-12-04 16:49:26,242 [main] INFO [org.spark_project.jetty.server.Server] - jetty-9.3.z-SNAPSHOT
2021-12-04 16:49:26,253 [main] INFO [org.spark_project.jetty.server.Server] - Started @1901ms
2021-12-04 16:49:26,277 [main] INFO [org.spark_project.jetty.server.AbstractConnector] - Started ServerConnector@5b800468{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2021-12-04 16:49:26,278 [main] INFO [org.apache.spark.util.Utils] - Successfully started service 'SparkUI' on port 4040.
2021-12-04 16:49:26,296 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@1568159{/jobs,null,AVAILABLE,@Spark}
2021-12-04 16:49:26,297 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@63cd604c{/jobs/json,null,AVAILABLE,@Spark}
2021-12-04 16:49:26,298 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@3954d008{/jobs/job,null,AVAILABLE,@Spark}
2021-12-04 16:49:26,300 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@6d8792db{/jobs/job/json,null,AVAILABLE,@Spark}
2021-12-04 16:49:26,301 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@3a1d593e{/stages,null,AVAILABLE,@Spark}
2021-12-04 16:49:26,302 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@285d851a{/stages/json,null,AVAILABLE,@Spark}
2021-12-04 16:49:26,303 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@7876d598{/stages/stage,null,AVAILABLE,@Spark}
2021-12-04 16:49:26,305 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@4985cbcb{/stages/stage/json,null,AVAILABLE,@Spark}
2021-12-04 16:49:26,306 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@54361a9{/stages/pool,null,AVAILABLE,@Spark}
2021-12-04 16:49:26,306 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@293bb8a5{/stages/pool/json,null,AVAILABLE,@Spark}
2021-12-04 16:49:26,307 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@290b1b2e{/storage,null,AVAILABLE,@Spark}
2021-12-04 16:49:26,308 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@5db4c359{/storage/json,null,AVAILABLE,@Spark}
2021-12-04 16:49:26,310 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@6fefce9e{/storage/rdd,null,AVAILABLE,@Spark}
2021-12-04 16:49:26,311 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@8a589a2{/storage/rdd/json,null,AVAILABLE,@Spark}
2021-12-04 16:49:26,312 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@5cc69cfe{/environment,null,AVAILABLE,@Spark}
2021-12-04 16:49:26,313 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@11dee337{/environment/json,null,AVAILABLE,@Spark}
2021-12-04 16:49:26,314 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@74bdc168{/executors,null,AVAILABLE,@Spark}
2021-12-04 16:49:26,316 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@7bb3a9fe{/executors/json,null,AVAILABLE,@Spark}
2021-12-04 16:49:26,318 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@f19c9d2{/executors/threadDump,null,AVAILABLE,@Spark}
2021-12-04 16:49:26,319 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@a77614d{/executors/threadDump/json,null,AVAILABLE,@Spark}
2021-12-04 16:49:26,327 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@523424b5{/static,null,AVAILABLE,@Spark}
2021-12-04 16:49:26,329 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@12cd9150{/,null,AVAILABLE,@Spark}
2021-12-04 16:49:26,330 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@32fe9d0a{/api,null,AVAILABLE,@Spark}
2021-12-04 16:49:26,332 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@59fc684e{/jobs/job/kill,null,AVAILABLE,@Spark}
2021-12-04 16:49:26,334 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@355e34c7{/stages/stage/kill,null,AVAILABLE,@Spark}
2021-12-04 16:49:26,336 [main] INFO [org.apache.spark.ui.SparkUI] - Bound SparkUI to 0.0.0.0, and started at http://qb:4040
2021-12-04 16:49:26,427 [main] INFO [org.apache.spark.executor.Executor] - Starting executor ID driver on host localhost
2021-12-04 16:49:26,476 [main] INFO [org.apache.spark.util.Utils] - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 49432.
2021-12-04 16:49:26,477 [main] INFO [org.apache.spark.network.netty.NettyBlockTransferService] - Server created on qb:49432
2021-12-04 16:49:26,478 [main] INFO [org.apache.spark.storage.BlockManager] - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2021-12-04 16:49:26,479 [main] INFO [org.apache.spark.storage.BlockManagerMaster] - Registering BlockManager BlockManagerId(driver, qb, 49432, None)
2021-12-04 16:49:26,481 [dispatcher-event-loop-10] INFO [org.apache.spark.storage.BlockManagerMasterEndpoint] - Registering block manager qb:49432 with 1990.8 MB RAM, BlockManagerId(driver, qb, 49432, None)
2021-12-04 16:49:26,483 [main] INFO [org.apache.spark.storage.BlockManagerMaster] - Registered BlockManager BlockManagerId(driver, qb, 49432, None)
2021-12-04 16:49:26,484 [main] INFO [org.apache.spark.storage.BlockManager] - Initialized BlockManager: BlockManagerId(driver, qb, 49432, None)
2021-12-04 16:49:26,618 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@6fe46b62{/metrics/json,null,AVAILABLE,@Spark}
2021-12-04 16:49:27,086 [main] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_0 stored as values in memory (estimated size 312.7 KB, free 1990.5 MB)
2021-12-04 16:49:27,287 [main] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_0_piece0 stored as bytes in memory (estimated size 27.3 KB, free 1990.5 MB)
2021-12-04 16:49:27,290 [dispatcher-event-loop-0] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_0_piece0 in memory on qb:49432 (size: 27.3 KB, free: 1990.8 MB)
2021-12-04 16:49:27,293 [main] INFO [org.apache.spark.SparkContext] - Created broadcast 0 from textFile at PaidPromotionAdjustParameter.scala:57
2021-12-04 16:49:27,632 [main] WARN [org.apache.hadoop.hdfs.shortcircuit.DomainSocketFactory] - The short-circuit local reads feature cannot be used because UNIX Domain sockets are not available on Windows.
2021-12-04 16:49:27,702 [main] INFO [org.apache.hadoop.mapred.FileInputFormat] - Total input paths to process : 1
2021-12-04 16:49:27,736 [main] INFO [org.apache.hadoop.net.NetworkTopology] - Adding a new node: /default-rack/192.168.1.34:50010
2021-12-04 16:49:27,736 [main] INFO [org.apache.hadoop.net.NetworkTopology] - Adding a new node: /default-rack/172.16.1.220:50010
2021-12-04 16:49:27,736 [main] INFO [org.apache.hadoop.net.NetworkTopology] - Adding a new node: /default-rack/192.168.1.33:50010
2021-12-04 16:49:27,742 [main] INFO [org.apache.spark.SparkContext] - Starting job: count at PaidPromotionAdjustParameter.scala:59
2021-12-04 16:49:27,752 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 0 (count at PaidPromotionAdjustParameter.scala:59) with 22 output partitions
2021-12-04 16:49:27,753 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 0 (count at PaidPromotionAdjustParameter.scala:59)
2021-12-04 16:49:27,754 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List()
2021-12-04 16:49:27,755 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2021-12-04 16:49:27,760 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 0 (/sk/chongqing/data/behavior_data.bcp MapPartitionsRDD[1] at textFile at PaidPromotionAdjustParameter.scala:57), which has no missing parents
2021-12-04 16:49:27,788 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_1 stored as values in memory (estimated size 3.1 KB, free 1990.5 MB)
2021-12-04 16:49:27,793 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_1_piece0 stored as bytes in memory (estimated size 1903.0 B, free 1990.5 MB)
2021-12-04 16:49:27,794 [dispatcher-event-loop-2] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_1_piece0 in memory on qb:49432 (size: 1903.0 B, free: 1990.8 MB)
2021-12-04 16:49:27,794 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 1 from broadcast at DAGScheduler.scala:1039
2021-12-04 16:49:27,803 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 22 missing tasks from ResultStage 0 (/sk/chongqing/data/behavior_data.bcp MapPartitionsRDD[1] at textFile at PaidPromotionAdjustParameter.scala:57) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14))
2021-12-04 16:49:27,804 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 0.0 with 22 tasks
2021-12-04 16:49:27,834 [dispatcher-event-loop-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 0.0 (TID 0, localhost, executor driver, partition 0, ANY, 7899 bytes)
2021-12-04 16:49:27,835 [dispatcher-event-loop-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 0.0 (TID 1, localhost, executor driver, partition 1, ANY, 7899 bytes)
2021-12-04 16:49:27,836 [dispatcher-event-loop-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 2.0 in stage 0.0 (TID 2, localhost, executor driver, partition 2, ANY, 7899 bytes)
2021-12-04 16:49:27,836 [dispatcher-event-loop-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 3.0 in stage 0.0 (TID 3, localhost, executor driver, partition 3, ANY, 7899 bytes)
2021-12-04 16:49:27,836 [dispatcher-event-loop-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 4.0 in stage 0.0 (TID 4, localhost, executor driver, partition 4, ANY, 7899 bytes)
2021-12-04 16:49:27,836 [dispatcher-event-loop-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 5.0 in stage 0.0 (TID 5, localhost, executor driver, partition 5, ANY, 7899 bytes)
2021-12-04 16:49:27,837 [dispatcher-event-loop-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 6.0 in stage 0.0 (TID 6, localhost, executor driver, partition 6, ANY, 7899 bytes)
2021-12-04 16:49:27,837 [dispatcher-event-loop-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 7.0 in stage 0.0 (TID 7, localhost, executor driver, partition 7, ANY, 7899 bytes)
2021-12-04 16:49:27,837 [dispatcher-event-loop-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 8.0 in stage 0.0 (TID 8, localhost, executor driver, partition 8, ANY, 7899 bytes)
2021-12-04 16:49:27,838 [dispatcher-event-loop-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 9.0 in stage 0.0 (TID 9, localhost, executor driver, partition 9, ANY, 7899 bytes)
2021-12-04 16:49:27,838 [dispatcher-event-loop-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 10.0 in stage 0.0 (TID 10, localhost, executor driver, partition 10, ANY, 7899 bytes)
2021-12-04 16:49:27,838 [dispatcher-event-loop-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 11.0 in stage 0.0 (TID 11, localhost, executor driver, partition 11, ANY, 7899 bytes)
2021-12-04 16:49:27,843 [Executor task launch worker for task 9] INFO [org.apache.spark.executor.Executor] - Running task 9.0 in stage 0.0 (TID 9)
2021-12-04 16:49:27,843 [Executor task launch worker for task 6] INFO [org.apache.spark.executor.Executor] - Running task 6.0 in stage 0.0 (TID 6)
2021-12-04 16:49:27,843 [Executor task launch worker for task 0] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 0.0 (TID 0)
2021-12-04 16:49:27,843 [Executor task launch worker for task 4] INFO [org.apache.spark.executor.Executor] - Running task 4.0 in stage 0.0 (TID 4)
2021-12-04 16:49:27,843 [Executor task launch worker for task 2] INFO [org.apache.spark.executor.Executor] - Running task 2.0 in stage 0.0 (TID 2)
2021-12-04 16:49:27,843 [Executor task launch worker for task 10] INFO [org.apache.spark.executor.Executor] - Running task 10.0 in stage 0.0 (TID 10)
2021-12-04 16:49:27,843 [Executor task launch worker for task 1] INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 0.0 (TID 1)
2021-12-04 16:49:27,843 [Executor task launch worker for task 5] INFO [org.apache.spark.executor.Executor] - Running task 5.0 in stage 0.0 (TID 5)
2021-12-04 16:49:27,843 [Executor task launch worker for task 7] INFO [org.apache.spark.executor.Executor] - Running task 7.0 in stage 0.0 (TID 7)
2021-12-04 16:49:27,843 [Executor task launch worker for task 8] INFO [org.apache.spark.executor.Executor] - Running task 8.0 in stage 0.0 (TID 8)
2021-12-04 16:49:27,843 [Executor task launch worker for task 11] INFO [org.apache.spark.executor.Executor] - Running task 11.0 in stage 0.0 (TID 11)
2021-12-04 16:49:27,843 [Executor task launch worker for task 3] INFO [org.apache.spark.executor.Executor] - Running task 3.0 in stage 0.0 (TID 3)
2021-12-04 16:49:27,882 [Executor task launch worker for task 1] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:134217728+134217728
2021-12-04 16:49:27,882 [Executor task launch worker for task 3] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:402653184+134217728
2021-12-04 16:49:27,882 [Executor task launch worker for task 10] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:1342177280+134217728
2021-12-04 16:49:27,882 [Executor task launch worker for task 0] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:0+134217728
2021-12-04 16:49:27,882 [Executor task launch worker for task 8] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:1073741824+134217728
2021-12-04 16:49:27,882 [Executor task launch worker for task 7] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:939524096+134217728
2021-12-04 16:49:27,882 [Executor task launch worker for task 5] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:671088640+134217728
2021-12-04 16:49:27,882 [Executor task launch worker for task 6] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:805306368+134217728
2021-12-04 16:49:27,882 [Executor task launch worker for task 9] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:1207959552+134217728
2021-12-04 16:49:27,882 [Executor task launch worker for task 2] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:268435456+134217728
2021-12-04 16:49:27,882 [Executor task launch worker for task 11] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:1476395008+134217728
2021-12-04 16:49:27,882 [Executor task launch worker for task 4] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:536870912+134217728
2021-12-04 16:51:19,832 [Executor task launch worker for task 0] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 0.0 (TID 0). 755 bytes result sent to driver
2021-12-04 16:51:19,834 [dispatcher-event-loop-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 12.0 in stage 0.0 (TID 12, localhost, executor driver, partition 12, ANY, 7899 bytes)
2021-12-04 16:51:19,834 [Executor task launch worker for task 12] INFO [org.apache.spark.executor.Executor] - Running task 12.0 in stage 0.0 (TID 12)
2021-12-04 16:51:19,836 [Executor task launch worker for task 12] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:1610612736+134217728
2021-12-04 16:51:19,841 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 0.0 (TID 0) in 112014 ms on localhost (executor driver) (1/22)
2021-12-04 16:51:22,301 [Executor task launch worker for task 7] INFO [org.apache.spark.executor.Executor] - Finished task 7.0 in stage 0.0 (TID 7). 755 bytes result sent to driver
2021-12-04 16:51:22,302 [dispatcher-event-loop-4] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 13.0 in stage 0.0 (TID 13, localhost, executor driver, partition 13, ANY, 7899 bytes)
2021-12-04 16:51:22,302 [Executor task launch worker for task 13] INFO [org.apache.spark.executor.Executor] - Running task 13.0 in stage 0.0 (TID 13)
2021-12-04 16:51:22,304 [Executor task launch worker for task 13] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:1744830464+134217728
2021-12-04 16:51:22,305 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 7.0 in stage 0.0 (TID 7) in 114468 ms on localhost (executor driver) (2/22)
2021-12-04 16:51:27,584 [Executor task launch worker for task 5] INFO [org.apache.spark.executor.Executor] - Finished task 5.0 in stage 0.0 (TID 5). 755 bytes result sent to driver
2021-12-04 16:51:27,585 [dispatcher-event-loop-9] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 14.0 in stage 0.0 (TID 14, localhost, executor driver, partition 14, ANY, 7899 bytes)
2021-12-04 16:51:27,585 [Executor task launch worker for task 14] INFO [org.apache.spark.executor.Executor] - Running task 14.0 in stage 0.0 (TID 14)
2021-12-04 16:51:27,586 [Executor task launch worker for task 14] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:1879048192+134217728
2021-12-04 16:51:27,588 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 5.0 in stage 0.0 (TID 5) in 119752 ms on localhost (executor driver) (3/22)
2021-12-04 16:51:32,506 [Executor task launch worker for task 2] INFO [org.apache.spark.executor.Executor] - Finished task 2.0 in stage 0.0 (TID 2). 755 bytes result sent to driver
2021-12-04 16:51:32,507 [dispatcher-event-loop-11] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 15.0 in stage 0.0 (TID 15, localhost, executor driver, partition 15, ANY, 7899 bytes)
2021-12-04 16:51:32,507 [Executor task launch worker for task 15] INFO [org.apache.spark.executor.Executor] - Running task 15.0 in stage 0.0 (TID 15)
2021-12-04 16:51:32,509 [Executor task launch worker for task 15] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:2013265920+134217728
2021-12-04 16:51:32,509 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 2.0 in stage 0.0 (TID 2) in 124674 ms on localhost (executor driver) (4/22)
2021-12-04 16:51:39,917 [Executor task launch worker for task 8] INFO [org.apache.spark.executor.Executor] - Finished task 8.0 in stage 0.0 (TID 8). 755 bytes result sent to driver
2021-12-04 16:51:39,917 [dispatcher-event-loop-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 16.0 in stage 0.0 (TID 16, localhost, executor driver, partition 16, ANY, 7899 bytes)
2021-12-04 16:51:39,918 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 8.0 in stage 0.0 (TID 8) in 132081 ms on localhost (executor driver) (5/22)
2021-12-04 16:51:39,918 [Executor task launch worker for task 16] INFO [org.apache.spark.executor.Executor] - Running task 16.0 in stage 0.0 (TID 16)
2021-12-04 16:51:39,919 [Executor task launch worker for task 16] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:2147483648+134217728
2021-12-04 16:51:42,819 [Executor task launch worker for task 6] INFO [org.apache.spark.executor.Executor] - Finished task 6.0 in stage 0.0 (TID 6). 755 bytes result sent to driver
2021-12-04 16:51:42,819 [dispatcher-event-loop-6] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 17.0 in stage 0.0 (TID 17, localhost, executor driver, partition 17, ANY, 7899 bytes)
2021-12-04 16:51:42,819 [Executor task launch worker for task 17] INFO [org.apache.spark.executor.Executor] - Running task 17.0 in stage 0.0 (TID 17)
2021-12-04 16:51:42,820 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 6.0 in stage 0.0 (TID 6) in 134982 ms on localhost (executor driver) (6/22)
2021-12-04 16:51:42,821 [Executor task launch worker for task 17] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:2281701376+134217728
2021-12-04 16:51:46,728 [Executor task launch worker for task 9] INFO [org.apache.spark.executor.Executor] - Finished task 9.0 in stage 0.0 (TID 9). 755 bytes result sent to driver
2021-12-04 16:51:46,729 [dispatcher-event-loop-9] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 18.0 in stage 0.0 (TID 18, localhost, executor driver, partition 18, ANY, 7899 bytes)
2021-12-04 16:51:46,729 [Executor task launch worker for task 18] INFO [org.apache.spark.executor.Executor] - Running task 18.0 in stage 0.0 (TID 18)
2021-12-04 16:51:46,729 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 9.0 in stage 0.0 (TID 9) in 138892 ms on localhost (executor driver) (7/22)
2021-12-04 16:51:46,730 [Executor task launch worker for task 18] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:2415919104+134217728
2021-12-04 16:51:52,523 [Executor task launch worker for task 4] INFO [org.apache.spark.executor.Executor] - Finished task 4.0 in stage 0.0 (TID 4). 755 bytes result sent to driver
2021-12-04 16:51:52,524 [dispatcher-event-loop-11] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 19.0 in stage 0.0 (TID 19, localhost, executor driver, partition 19, ANY, 7899 bytes)
2021-12-04 16:51:52,524 [Executor task launch worker for task 19] INFO [org.apache.spark.executor.Executor] - Running task 19.0 in stage 0.0 (TID 19)
2021-12-04 16:51:52,524 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 4.0 in stage 0.0 (TID 4) in 144688 ms on localhost (executor driver) (8/22)
2021-12-04 16:51:52,525 [Executor task launch worker for task 19] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:2550136832+134217728
2021-12-04 16:52:05,657 [Executor task launch worker for task 10] INFO [org.apache.spark.executor.Executor] - Finished task 10.0 in stage 0.0 (TID 10). 755 bytes result sent to driver
2021-12-04 16:52:05,657 [dispatcher-event-loop-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 20.0 in stage 0.0 (TID 20, localhost, executor driver, partition 20, ANY, 7899 bytes)
2021-12-04 16:52:05,657 [Executor task launch worker for task 20] INFO [org.apache.spark.executor.Executor] - Running task 20.0 in stage 0.0 (TID 20)
2021-12-04 16:52:05,657 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 10.0 in stage 0.0 (TID 10) in 157819 ms on localhost (executor driver) (9/22)
2021-12-04 16:52:05,658 [Executor task launch worker for task 20] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:2684354560+134217728
2021-12-04 16:52:14,666 [Executor task launch worker for task 3] INFO [org.apache.spark.executor.Executor] - Finished task 3.0 in stage 0.0 (TID 3). 755 bytes result sent to driver
2021-12-04 16:52:14,666 [dispatcher-event-loop-7] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 21.0 in stage 0.0 (TID 21, localhost, executor driver, partition 21, ANY, 7899 bytes)
2021-12-04 16:52:14,666 [Executor task launch worker for task 21] INFO [org.apache.spark.executor.Executor] - Running task 21.0 in stage 0.0 (TID 21)
2021-12-04 16:52:14,666 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 3.0 in stage 0.0 (TID 3) in 166830 ms on localhost (executor driver) (10/22)
2021-12-04 16:52:14,667 [Executor task launch worker for task 21] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:2818572288+147216171
2021-12-04 16:52:24,605 [Executor task launch worker for task 1] INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 0.0 (TID 1). 755 bytes result sent to driver
2021-12-04 16:52:24,607 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 0.0 (TID 1) in 176772 ms on localhost (executor driver) (11/22)
2021-12-04 16:52:32,172 [Executor task launch worker for task 11] INFO [org.apache.spark.executor.Executor] - Finished task 11.0 in stage 0.0 (TID 11). 755 bytes result sent to driver
2021-12-04 16:52:32,173 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 11.0 in stage 0.0 (TID 11) in 184335 ms on localhost (executor driver) (12/22)
2021-12-04 16:52:53,964 [Executor task launch worker for task 13] INFO [org.apache.spark.executor.Executor] - Finished task 13.0 in stage 0.0 (TID 13). 755 bytes result sent to driver
2021-12-04 16:52:53,964 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 13.0 in stage 0.0 (TID 13) in 91662 ms on localhost (executor driver) (13/22)
2021-12-04 16:53:02,404 [Executor task launch worker for task 14] INFO [org.apache.spark.executor.Executor] - Finished task 14.0 in stage 0.0 (TID 14). 712 bytes result sent to driver
2021-12-04 16:53:02,405 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 14.0 in stage 0.0 (TID 14) in 94820 ms on localhost (executor driver) (14/22)
2021-12-04 16:53:14,820 [Executor task launch worker for task 12] INFO [org.apache.spark.executor.Executor] - Finished task 12.0 in stage 0.0 (TID 12). 755 bytes result sent to driver
2021-12-04 16:53:14,820 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 12.0 in stage 0.0 (TID 12) in 114986 ms on localhost (executor driver) (15/22)
2021-12-04 16:53:18,333 [Executor task launch worker for task 18] INFO [org.apache.spark.executor.Executor] - Finished task 18.0 in stage 0.0 (TID 18). 755 bytes result sent to driver
2021-12-04 16:53:18,334 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 18.0 in stage 0.0 (TID 18) in 91605 ms on localhost (executor driver) (16/22)
2021-12-04 16:53:28,976 [Executor task launch worker for task 20] INFO [org.apache.spark.executor.Executor] - Finished task 20.0 in stage 0.0 (TID 20). 755 bytes result sent to driver
2021-12-04 16:53:28,976 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 20.0 in stage 0.0 (TID 20) in 83319 ms on localhost (executor driver) (17/22)
2021-12-04 16:53:38,813 [Executor task launch worker for task 15] INFO [org.apache.spark.executor.Executor] - Finished task 15.0 in stage 0.0 (TID 15). 755 bytes result sent to driver
2021-12-04 16:53:38,814 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 15.0 in stage 0.0 (TID 15) in 126307 ms on localhost (executor driver) (18/22)
2021-12-04 16:53:39,464 [Executor task launch worker for task 17] INFO [org.apache.spark.executor.Executor] - Finished task 17.0 in stage 0.0 (TID 17). 755 bytes result sent to driver
2021-12-04 16:53:39,464 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 17.0 in stage 0.0 (TID 17) in 116645 ms on localhost (executor driver) (19/22)
2021-12-04 16:53:40,114 [Executor task launch worker for task 16] INFO [org.apache.spark.executor.Executor] - Finished task 16.0 in stage 0.0 (TID 16). 798 bytes result sent to driver
2021-12-04 16:53:40,115 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 16.0 in stage 0.0 (TID 16) in 120198 ms on localhost (executor driver) (20/22)
2021-12-04 16:53:43,979 [Executor task launch worker for task 19] INFO [org.apache.spark.executor.Executor] - Finished task 19.0 in stage 0.0 (TID 19). 755 bytes result sent to driver
2021-12-04 16:53:43,979 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 19.0 in stage 0.0 (TID 19) in 111456 ms on localhost (executor driver) (21/22)
2021-12-04 16:53:46,001 [Executor task launch worker for task 21] INFO [org.apache.spark.executor.Executor] - Finished task 21.0 in stage 0.0 (TID 21). 755 bytes result sent to driver
2021-12-04 16:53:46,002 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 21.0 in stage 0.0 (TID 21) in 91336 ms on localhost (executor driver) (22/22)
2021-12-04 16:53:46,003 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 0.0, whose tasks have all completed, from pool 
2021-12-04 16:53:46,003 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 0 (count at PaidPromotionAdjustParameter.scala:59) finished in 258.230 s
2021-12-04 16:53:46,007 [main] INFO [org.apache.spark.scheduler.DAGScheduler] - Job 0 finished: count at PaidPromotionAdjustParameter.scala:59, took 258.265222 s
2021-12-04 16:53:46,008 [main] INFO [PaidPromotion$] - 收视总数68489201
2021-12-04 16:53:46,026 [main] INFO [org.apache.spark.SparkContext] - Starting job: count at PaidPromotionAdjustParameter.scala:68
2021-12-04 16:53:46,033 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 3 (map at PaidPromotionAdjustParameter.scala:67)
2021-12-04 16:53:46,033 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 1 (count at PaidPromotionAdjustParameter.scala:68) with 22 output partitions
2021-12-04 16:53:46,034 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 2 (count at PaidPromotionAdjustParameter.scala:68)
2021-12-04 16:53:46,034 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 1)
2021-12-04 16:53:46,034 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List(ShuffleMapStage 1)
2021-12-04 16:53:46,035 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ShuffleMapStage 1 (MapPartitionsRDD[3] at map at PaidPromotionAdjustParameter.scala:67), which has no missing parents
2021-12-04 16:53:46,044 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_2 stored as values in memory (estimated size 4.7 KB, free 1990.5 MB)
2021-12-04 16:53:46,047 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_2_piece0 stored as bytes in memory (estimated size 2.7 KB, free 1990.5 MB)
2021-12-04 16:53:46,047 [dispatcher-event-loop-7] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_2_piece0 in memory on qb:49432 (size: 2.7 KB, free: 1990.8 MB)
2021-12-04 16:53:46,048 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 2 from broadcast at DAGScheduler.scala:1039
2021-12-04 16:53:46,050 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 22 missing tasks from ShuffleMapStage 1 (MapPartitionsRDD[3] at map at PaidPromotionAdjustParameter.scala:67) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14))
2021-12-04 16:53:46,050 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 1.0 with 22 tasks
2021-12-04 16:53:46,051 [dispatcher-event-loop-8] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 1.0 (TID 22, localhost, executor driver, partition 0, ANY, 7888 bytes)
2021-12-04 16:53:46,051 [dispatcher-event-loop-8] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 1.0 (TID 23, localhost, executor driver, partition 1, ANY, 7888 bytes)
2021-12-04 16:53:46,051 [dispatcher-event-loop-8] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 2.0 in stage 1.0 (TID 24, localhost, executor driver, partition 2, ANY, 7888 bytes)
2021-12-04 16:53:46,051 [dispatcher-event-loop-8] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 3.0 in stage 1.0 (TID 25, localhost, executor driver, partition 3, ANY, 7888 bytes)
2021-12-04 16:53:46,052 [dispatcher-event-loop-8] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 4.0 in stage 1.0 (TID 26, localhost, executor driver, partition 4, ANY, 7888 bytes)
2021-12-04 16:53:46,052 [dispatcher-event-loop-8] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 5.0 in stage 1.0 (TID 27, localhost, executor driver, partition 5, ANY, 7888 bytes)
2021-12-04 16:53:46,052 [dispatcher-event-loop-8] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 6.0 in stage 1.0 (TID 28, localhost, executor driver, partition 6, ANY, 7888 bytes)
2021-12-04 16:53:46,052 [dispatcher-event-loop-8] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 7.0 in stage 1.0 (TID 29, localhost, executor driver, partition 7, ANY, 7888 bytes)
2021-12-04 16:53:46,052 [dispatcher-event-loop-8] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 8.0 in stage 1.0 (TID 30, localhost, executor driver, partition 8, ANY, 7888 bytes)
2021-12-04 16:53:46,052 [dispatcher-event-loop-8] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 9.0 in stage 1.0 (TID 31, localhost, executor driver, partition 9, ANY, 7888 bytes)
2021-12-04 16:53:46,053 [dispatcher-event-loop-8] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 10.0 in stage 1.0 (TID 32, localhost, executor driver, partition 10, ANY, 7888 bytes)
2021-12-04 16:53:46,053 [dispatcher-event-loop-8] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 11.0 in stage 1.0 (TID 33, localhost, executor driver, partition 11, ANY, 7888 bytes)
2021-12-04 16:53:46,053 [Executor task launch worker for task 22] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 1.0 (TID 22)
2021-12-04 16:53:46,053 [Executor task launch worker for task 24] INFO [org.apache.spark.executor.Executor] - Running task 2.0 in stage 1.0 (TID 24)
2021-12-04 16:53:46,053 [Executor task launch worker for task 29] INFO [org.apache.spark.executor.Executor] - Running task 7.0 in stage 1.0 (TID 29)
2021-12-04 16:53:46,053 [Executor task launch worker for task 27] INFO [org.apache.spark.executor.Executor] - Running task 5.0 in stage 1.0 (TID 27)
2021-12-04 16:53:46,053 [Executor task launch worker for task 23] INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 1.0 (TID 23)
2021-12-04 16:53:46,053 [Executor task launch worker for task 28] INFO [org.apache.spark.executor.Executor] - Running task 6.0 in stage 1.0 (TID 28)
2021-12-04 16:53:46,053 [Executor task launch worker for task 26] INFO [org.apache.spark.executor.Executor] - Running task 4.0 in stage 1.0 (TID 26)
2021-12-04 16:53:46,053 [Executor task launch worker for task 25] INFO [org.apache.spark.executor.Executor] - Running task 3.0 in stage 1.0 (TID 25)
2021-12-04 16:53:46,054 [Executor task launch worker for task 33] INFO [org.apache.spark.executor.Executor] - Running task 11.0 in stage 1.0 (TID 33)
2021-12-04 16:53:46,054 [Executor task launch worker for task 32] INFO [org.apache.spark.executor.Executor] - Running task 10.0 in stage 1.0 (TID 32)
2021-12-04 16:53:46,053 [Executor task launch worker for task 31] INFO [org.apache.spark.executor.Executor] - Running task 9.0 in stage 1.0 (TID 31)
2021-12-04 16:53:46,053 [Executor task launch worker for task 30] INFO [org.apache.spark.executor.Executor] - Running task 8.0 in stage 1.0 (TID 30)
2021-12-04 16:53:46,059 [Executor task launch worker for task 27] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:671088640+134217728
2021-12-04 16:53:46,059 [Executor task launch worker for task 26] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:536870912+134217728
2021-12-04 16:53:46,060 [Executor task launch worker for task 31] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:1207959552+134217728
2021-12-04 16:53:46,059 [Executor task launch worker for task 32] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:1342177280+134217728
2021-12-04 16:53:46,059 [Executor task launch worker for task 28] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:805306368+134217728
2021-12-04 16:53:46,059 [Executor task launch worker for task 25] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:402653184+134217728
2021-12-04 16:53:46,059 [Executor task launch worker for task 24] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:268435456+134217728
2021-12-04 16:53:46,059 [Executor task launch worker for task 23] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:134217728+134217728
2021-12-04 16:53:46,059 [Executor task launch worker for task 29] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:939524096+134217728
2021-12-04 16:53:46,060 [Executor task launch worker for task 22] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:0+134217728
2021-12-04 16:53:46,060 [Executor task launch worker for task 30] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:1073741824+134217728
2021-12-04 16:53:46,060 [Executor task launch worker for task 33] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:1476395008+134217728
2021-12-04 16:54:56,768 [Executor task launch worker for task 27] INFO [org.apache.spark.executor.Executor] - Finished task 5.0 in stage 1.0 (TID 27). 1052 bytes result sent to driver
2021-12-04 16:54:56,768 [dispatcher-event-loop-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 12.0 in stage 1.0 (TID 34, localhost, executor driver, partition 12, ANY, 7888 bytes)
2021-12-04 16:54:56,769 [Executor task launch worker for task 34] INFO [org.apache.spark.executor.Executor] - Running task 12.0 in stage 1.0 (TID 34)
2021-12-04 16:54:56,769 [Executor task launch worker for task 34] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:1610612736+134217728
2021-12-04 16:54:56,781 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 5.0 in stage 1.0 (TID 27) in 70729 ms on localhost (executor driver) (1/22)
2021-12-04 16:55:12,505 [Executor task launch worker for task 24] INFO [org.apache.spark.executor.Executor] - Finished task 2.0 in stage 1.0 (TID 24). 1052 bytes result sent to driver
2021-12-04 16:55:12,505 [dispatcher-event-loop-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 13.0 in stage 1.0 (TID 35, localhost, executor driver, partition 13, ANY, 7888 bytes)
2021-12-04 16:55:12,505 [Executor task launch worker for task 35] INFO [org.apache.spark.executor.Executor] - Running task 13.0 in stage 1.0 (TID 35)
2021-12-04 16:55:12,506 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 2.0 in stage 1.0 (TID 24) in 86455 ms on localhost (executor driver) (2/22)
2021-12-04 16:55:12,506 [Executor task launch worker for task 35] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:1744830464+134217728
2021-12-04 16:55:15,934 [Executor task launch worker for task 28] INFO [org.apache.spark.executor.Executor] - Finished task 6.0 in stage 1.0 (TID 28). 1052 bytes result sent to driver
2021-12-04 16:55:15,934 [dispatcher-event-loop-5] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 14.0 in stage 1.0 (TID 36, localhost, executor driver, partition 14, ANY, 7888 bytes)
2021-12-04 16:55:15,934 [Executor task launch worker for task 36] INFO [org.apache.spark.executor.Executor] - Running task 14.0 in stage 1.0 (TID 36)
2021-12-04 16:55:15,935 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 6.0 in stage 1.0 (TID 28) in 89883 ms on localhost (executor driver) (3/22)
2021-12-04 16:55:15,935 [Executor task launch worker for task 36] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:1879048192+134217728
2021-12-04 16:55:35,993 [Executor task launch worker for task 34] INFO [org.apache.spark.executor.Executor] - Finished task 12.0 in stage 1.0 (TID 34). 1009 bytes result sent to driver
2021-12-04 16:55:35,995 [dispatcher-event-loop-4] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 15.0 in stage 1.0 (TID 37, localhost, executor driver, partition 15, ANY, 7888 bytes)
2021-12-04 16:55:35,995 [Executor task launch worker for task 37] INFO [org.apache.spark.executor.Executor] - Running task 15.0 in stage 1.0 (TID 37)
2021-12-04 16:55:35,995 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 12.0 in stage 1.0 (TID 34) in 39227 ms on localhost (executor driver) (4/22)
2021-12-04 16:55:35,995 [Executor task launch worker for task 37] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:2013265920+134217728
2021-12-04 16:56:22,467 [Executor task launch worker for task 37] INFO [org.apache.spark.executor.Executor] - Finished task 15.0 in stage 1.0 (TID 37). 1009 bytes result sent to driver
2021-12-04 16:56:22,468 [dispatcher-event-loop-8] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 16.0 in stage 1.0 (TID 38, localhost, executor driver, partition 16, ANY, 7888 bytes)
2021-12-04 16:56:22,468 [Executor task launch worker for task 38] INFO [org.apache.spark.executor.Executor] - Running task 16.0 in stage 1.0 (TID 38)
2021-12-04 16:56:22,468 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 15.0 in stage 1.0 (TID 37) in 46473 ms on localhost (executor driver) (5/22)
2021-12-04 16:56:22,469 [Executor task launch worker for task 38] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:2147483648+134217728
2021-12-04 16:56:26,150 [Executor task launch worker for task 36] INFO [org.apache.spark.executor.Executor] - Finished task 14.0 in stage 1.0 (TID 36). 1095 bytes result sent to driver
2021-12-04 16:56:26,151 [dispatcher-event-loop-6] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 17.0 in stage 1.0 (TID 39, localhost, executor driver, partition 17, ANY, 7888 bytes)
2021-12-04 16:56:26,151 [Executor task launch worker for task 39] INFO [org.apache.spark.executor.Executor] - Running task 17.0 in stage 1.0 (TID 39)
2021-12-04 16:56:26,151 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 14.0 in stage 1.0 (TID 36) in 70217 ms on localhost (executor driver) (6/22)
2021-12-04 16:56:26,152 [Executor task launch worker for task 39] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:2281701376+134217728
2021-12-04 16:56:34,315 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 14
2021-12-04 16:56:34,315 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 4
2021-12-04 16:56:34,315 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 21
2021-12-04 16:56:34,315 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 10
2021-12-04 16:56:34,315 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 20
2021-12-04 16:56:34,315 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 22
2021-12-04 16:56:34,315 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 17
2021-12-04 16:56:34,315 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 9
2021-12-04 16:56:34,315 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 2
2021-12-04 16:56:34,315 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 19
2021-12-04 16:56:34,315 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 11
2021-12-04 16:56:34,315 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 5
2021-12-04 16:56:34,315 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 16
2021-12-04 16:56:34,315 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 8
2021-12-04 16:56:34,315 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 3
2021-12-04 16:56:34,315 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 12
2021-12-04 16:56:34,315 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 0
2021-12-04 16:56:34,324 [dispatcher-event-loop-11] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_1_piece0 on qb:49432 in memory (size: 1903.0 B, free: 1990.8 MB)
2021-12-04 16:56:34,326 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 24
2021-12-04 16:56:34,326 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 18
2021-12-04 16:56:34,326 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 6
2021-12-04 16:56:34,326 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 15
2021-12-04 16:56:34,326 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 7
2021-12-04 16:56:34,327 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 13
2021-12-04 16:56:34,327 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1
2021-12-04 16:56:34,327 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 23
2021-12-04 16:56:43,666 [Executor task launch worker for task 32] INFO [org.apache.spark.executor.Executor] - Finished task 10.0 in stage 1.0 (TID 32). 1052 bytes result sent to driver
2021-12-04 16:56:43,667 [dispatcher-event-loop-8] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 18.0 in stage 1.0 (TID 40, localhost, executor driver, partition 18, ANY, 7888 bytes)
2021-12-04 16:56:43,667 [Executor task launch worker for task 40] INFO [org.apache.spark.executor.Executor] - Running task 18.0 in stage 1.0 (TID 40)
2021-12-04 16:56:43,667 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 10.0 in stage 1.0 (TID 32) in 177614 ms on localhost (executor driver) (7/22)
2021-12-04 16:56:43,668 [Executor task launch worker for task 40] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:2415919104+134217728
2021-12-04 16:56:44,115 [Executor task launch worker for task 31] INFO [org.apache.spark.executor.Executor] - Finished task 9.0 in stage 1.0 (TID 31). 1052 bytes result sent to driver
2021-12-04 16:56:44,115 [dispatcher-event-loop-4] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 19.0 in stage 1.0 (TID 41, localhost, executor driver, partition 19, ANY, 7888 bytes)
2021-12-04 16:56:44,115 [Executor task launch worker for task 41] INFO [org.apache.spark.executor.Executor] - Running task 19.0 in stage 1.0 (TID 41)
2021-12-04 16:56:44,115 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 9.0 in stage 1.0 (TID 31) in 178063 ms on localhost (executor driver) (8/22)
2021-12-04 16:56:44,116 [Executor task launch worker for task 41] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:2550136832+134217728
2021-12-04 16:57:08,060 [Executor task launch worker for task 29] INFO [org.apache.spark.executor.Executor] - Finished task 7.0 in stage 1.0 (TID 29). 1052 bytes result sent to driver
2021-12-04 16:57:08,060 [dispatcher-event-loop-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 20.0 in stage 1.0 (TID 42, localhost, executor driver, partition 20, ANY, 7888 bytes)
2021-12-04 16:57:08,060 [Executor task launch worker for task 42] INFO [org.apache.spark.executor.Executor] - Running task 20.0 in stage 1.0 (TID 42)
2021-12-04 16:57:08,061 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 7.0 in stage 1.0 (TID 29) in 202008 ms on localhost (executor driver) (9/22)
2021-12-04 16:57:08,061 [Executor task launch worker for task 42] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:2684354560+134217728
2021-12-04 16:57:12,951 [Executor task launch worker for task 30] INFO [org.apache.spark.executor.Executor] - Finished task 8.0 in stage 1.0 (TID 30). 1052 bytes result sent to driver
2021-12-04 16:57:12,952 [dispatcher-event-loop-8] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 21.0 in stage 1.0 (TID 43, localhost, executor driver, partition 21, ANY, 7888 bytes)
2021-12-04 16:57:12,952 [Executor task launch worker for task 43] INFO [org.apache.spark.executor.Executor] - Running task 21.0 in stage 1.0 (TID 43)
2021-12-04 16:57:12,952 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 8.0 in stage 1.0 (TID 30) in 206900 ms on localhost (executor driver) (10/22)
2021-12-04 16:57:12,953 [Executor task launch worker for task 43] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:2818572288+147216171
2021-12-04 16:57:16,309 [Executor task launch worker for task 22] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 1.0 (TID 22). 1052 bytes result sent to driver
2021-12-04 16:57:16,309 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 1.0 (TID 22) in 210259 ms on localhost (executor driver) (11/22)
2021-12-04 16:57:24,686 [Executor task launch worker for task 25] INFO [org.apache.spark.executor.Executor] - Finished task 3.0 in stage 1.0 (TID 25). 1052 bytes result sent to driver
2021-12-04 16:57:24,686 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 3.0 in stage 1.0 (TID 25) in 218635 ms on localhost (executor driver) (12/22)
2021-12-04 16:57:24,948 [Executor task launch worker for task 40] INFO [org.apache.spark.executor.Executor] - Finished task 18.0 in stage 1.0 (TID 40). 1009 bytes result sent to driver
2021-12-04 16:57:24,948 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 18.0 in stage 1.0 (TID 40) in 41281 ms on localhost (executor driver) (13/22)
2021-12-04 16:57:25,055 [Executor task launch worker for task 23] INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 1.0 (TID 23). 1052 bytes result sent to driver
2021-12-04 16:57:25,056 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 1.0 (TID 23) in 219005 ms on localhost (executor driver) (14/22)
2021-12-04 16:57:27,921 [Executor task launch worker for task 33] INFO [org.apache.spark.executor.Executor] - Finished task 11.0 in stage 1.0 (TID 33). 1052 bytes result sent to driver
2021-12-04 16:57:27,922 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 11.0 in stage 1.0 (TID 33) in 221868 ms on localhost (executor driver) (15/22)
2021-12-04 16:57:38,743 [Executor task launch worker for task 26] INFO [org.apache.spark.executor.Executor] - Finished task 4.0 in stage 1.0 (TID 26). 1052 bytes result sent to driver
2021-12-04 16:57:38,743 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 4.0 in stage 1.0 (TID 26) in 232691 ms on localhost (executor driver) (16/22)
2021-12-04 16:57:48,319 [Executor task launch worker for task 41] INFO [org.apache.spark.executor.Executor] - Finished task 19.0 in stage 1.0 (TID 41). 1052 bytes result sent to driver
2021-12-04 16:57:48,320 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 19.0 in stage 1.0 (TID 41) in 64205 ms on localhost (executor driver) (17/22)
2021-12-04 16:57:58,906 [Executor task launch worker for task 35] INFO [org.apache.spark.executor.Executor] - Finished task 13.0 in stage 1.0 (TID 35). 1052 bytes result sent to driver
2021-12-04 16:57:58,906 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 13.0 in stage 1.0 (TID 35) in 166401 ms on localhost (executor driver) (18/22)
2021-12-04 16:58:06,478 [Executor task launch worker for task 43] INFO [org.apache.spark.executor.Executor] - Finished task 21.0 in stage 1.0 (TID 43). 1052 bytes result sent to driver
2021-12-04 16:58:06,478 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 21.0 in stage 1.0 (TID 43) in 53526 ms on localhost (executor driver) (19/22)
2021-12-04 16:58:08,820 [Executor task launch worker for task 39] INFO [org.apache.spark.executor.Executor] - Finished task 17.0 in stage 1.0 (TID 39). 1052 bytes result sent to driver
2021-12-04 16:58:08,821 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 17.0 in stage 1.0 (TID 39) in 102670 ms on localhost (executor driver) (20/22)
2021-12-04 16:58:14,289 [Executor task launch worker for task 38] INFO [org.apache.spark.executor.Executor] - Finished task 16.0 in stage 1.0 (TID 38). 1052 bytes result sent to driver
2021-12-04 16:58:14,289 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 16.0 in stage 1.0 (TID 38) in 111822 ms on localhost (executor driver) (21/22)
2021-12-04 16:58:17,001 [Executor task launch worker for task 42] INFO [org.apache.spark.executor.Executor] - Finished task 20.0 in stage 1.0 (TID 42). 1052 bytes result sent to driver
2021-12-04 16:58:17,002 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 20.0 in stage 1.0 (TID 42) in 68942 ms on localhost (executor driver) (22/22)
2021-12-04 16:58:17,002 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 1.0, whose tasks have all completed, from pool 
2021-12-04 16:58:17,002 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ShuffleMapStage 1 (map at PaidPromotionAdjustParameter.scala:67) finished in 270.964 s
2021-12-04 16:58:17,002 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - looking for newly runnable stages
2021-12-04 16:58:17,003 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - running: Set()
2021-12-04 16:58:17,003 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - waiting: Set(ResultStage 2)
2021-12-04 16:58:17,003 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - failed: Set()
2021-12-04 16:58:17,005 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 2 (ShuffledRDD[4] at reduceByKey at PaidPromotionAdjustParameter.scala:67), which has no missing parents
2021-12-04 16:58:17,010 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_3 stored as values in memory (estimated size 3.0 KB, free 1990.5 MB)
2021-12-04 16:58:17,012 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_3_piece0 stored as bytes in memory (estimated size 1906.0 B, free 1990.5 MB)
2021-12-04 16:58:17,012 [dispatcher-event-loop-5] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_3_piece0 in memory on qb:49432 (size: 1906.0 B, free: 1990.8 MB)
2021-12-04 16:58:17,013 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 3 from broadcast at DAGScheduler.scala:1039
2021-12-04 16:58:17,013 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 22 missing tasks from ResultStage 2 (ShuffledRDD[4] at reduceByKey at PaidPromotionAdjustParameter.scala:67) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14))
2021-12-04 16:58:17,013 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 2.0 with 22 tasks
2021-12-04 16:58:17,014 [dispatcher-event-loop-7] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 2.0 (TID 44, localhost, executor driver, partition 0, ANY, 7649 bytes)
2021-12-04 16:58:17,014 [dispatcher-event-loop-7] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 2.0 (TID 45, localhost, executor driver, partition 1, ANY, 7649 bytes)
2021-12-04 16:58:17,015 [dispatcher-event-loop-7] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 2.0 in stage 2.0 (TID 46, localhost, executor driver, partition 2, ANY, 7649 bytes)
2021-12-04 16:58:17,015 [dispatcher-event-loop-7] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 3.0 in stage 2.0 (TID 47, localhost, executor driver, partition 3, ANY, 7649 bytes)
2021-12-04 16:58:17,015 [dispatcher-event-loop-7] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 4.0 in stage 2.0 (TID 48, localhost, executor driver, partition 4, ANY, 7649 bytes)
2021-12-04 16:58:17,015 [dispatcher-event-loop-7] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 5.0 in stage 2.0 (TID 49, localhost, executor driver, partition 5, ANY, 7649 bytes)
2021-12-04 16:58:17,015 [dispatcher-event-loop-7] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 6.0 in stage 2.0 (TID 50, localhost, executor driver, partition 6, ANY, 7649 bytes)
2021-12-04 16:58:17,015 [dispatcher-event-loop-7] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 7.0 in stage 2.0 (TID 51, localhost, executor driver, partition 7, ANY, 7649 bytes)
2021-12-04 16:58:17,015 [dispatcher-event-loop-7] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 8.0 in stage 2.0 (TID 52, localhost, executor driver, partition 8, ANY, 7649 bytes)
2021-12-04 16:58:17,015 [dispatcher-event-loop-7] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 9.0 in stage 2.0 (TID 53, localhost, executor driver, partition 9, ANY, 7649 bytes)
2021-12-04 16:58:17,015 [dispatcher-event-loop-7] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 10.0 in stage 2.0 (TID 54, localhost, executor driver, partition 10, ANY, 7649 bytes)
2021-12-04 16:58:17,015 [dispatcher-event-loop-7] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 11.0 in stage 2.0 (TID 55, localhost, executor driver, partition 11, ANY, 7649 bytes)
2021-12-04 16:58:17,016 [Executor task launch worker for task 44] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 2.0 (TID 44)
2021-12-04 16:58:17,016 [Executor task launch worker for task 47] INFO [org.apache.spark.executor.Executor] - Running task 3.0 in stage 2.0 (TID 47)
2021-12-04 16:58:17,016 [Executor task launch worker for task 46] INFO [org.apache.spark.executor.Executor] - Running task 2.0 in stage 2.0 (TID 46)
2021-12-04 16:58:17,016 [Executor task launch worker for task 54] INFO [org.apache.spark.executor.Executor] - Running task 10.0 in stage 2.0 (TID 54)
2021-12-04 16:58:17,016 [Executor task launch worker for task 50] INFO [org.apache.spark.executor.Executor] - Running task 6.0 in stage 2.0 (TID 50)
2021-12-04 16:58:17,016 [Executor task launch worker for task 51] INFO [org.apache.spark.executor.Executor] - Running task 7.0 in stage 2.0 (TID 51)
2021-12-04 16:58:17,016 [Executor task launch worker for task 52] INFO [org.apache.spark.executor.Executor] - Running task 8.0 in stage 2.0 (TID 52)
2021-12-04 16:58:17,016 [Executor task launch worker for task 45] INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 2.0 (TID 45)
2021-12-04 16:58:17,016 [Executor task launch worker for task 49] INFO [org.apache.spark.executor.Executor] - Running task 5.0 in stage 2.0 (TID 49)
2021-12-04 16:58:17,016 [Executor task launch worker for task 48] INFO [org.apache.spark.executor.Executor] - Running task 4.0 in stage 2.0 (TID 48)
2021-12-04 16:58:17,016 [Executor task launch worker for task 53] INFO [org.apache.spark.executor.Executor] - Running task 9.0 in stage 2.0 (TID 53)
2021-12-04 16:58:17,017 [Executor task launch worker for task 55] INFO [org.apache.spark.executor.Executor] - Running task 11.0 in stage 2.0 (TID 55)
2021-12-04 16:58:17,030 [Executor task launch worker for task 53] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-04 16:58:17,030 [Executor task launch worker for task 52] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-04 16:58:17,030 [Executor task launch worker for task 49] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-04 16:58:17,030 [Executor task launch worker for task 48] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-04 16:58:17,030 [Executor task launch worker for task 46] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-04 16:58:17,030 [Executor task launch worker for task 54] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-04 16:58:17,030 [Executor task launch worker for task 55] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-04 16:58:17,030 [Executor task launch worker for task 44] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-04 16:58:17,030 [Executor task launch worker for task 47] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-04 16:58:17,030 [Executor task launch worker for task 50] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-04 16:58:17,030 [Executor task launch worker for task 45] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-04 16:58:17,030 [Executor task launch worker for task 51] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-04 16:58:17,032 [Executor task launch worker for task 55] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 7 ms
2021-12-04 16:58:17,032 [Executor task launch worker for task 54] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 7 ms
2021-12-04 16:58:17,032 [Executor task launch worker for task 44] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 7 ms
2021-12-04 16:58:17,032 [Executor task launch worker for task 50] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 7 ms
2021-12-04 16:58:17,032 [Executor task launch worker for task 48] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 7 ms
2021-12-04 16:58:17,032 [Executor task launch worker for task 52] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 7 ms
2021-12-04 16:58:17,032 [Executor task launch worker for task 47] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 7 ms
2021-12-04 16:58:17,032 [Executor task launch worker for task 46] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 7 ms
2021-12-04 16:58:17,032 [Executor task launch worker for task 49] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 7 ms
2021-12-04 16:58:17,032 [Executor task launch worker for task 51] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 7 ms
2021-12-04 16:58:17,032 [Executor task launch worker for task 45] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 7 ms
2021-12-04 16:58:17,032 [Executor task launch worker for task 53] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 7 ms
2021-12-04 16:58:17,482 [Executor task launch worker for task 46] INFO [org.apache.spark.executor.Executor] - Finished task 2.0 in stage 2.0 (TID 46). 1098 bytes result sent to driver
2021-12-04 16:58:17,484 [Executor task launch worker for task 47] INFO [org.apache.spark.executor.Executor] - Finished task 3.0 in stage 2.0 (TID 47). 1098 bytes result sent to driver
2021-12-04 16:58:17,484 [dispatcher-event-loop-10] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 12.0 in stage 2.0 (TID 56, localhost, executor driver, partition 12, ANY, 7649 bytes)
2021-12-04 16:58:17,485 [Executor task launch worker for task 45] INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 2.0 (TID 45). 1098 bytes result sent to driver
2021-12-04 16:58:17,485 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 2.0 in stage 2.0 (TID 46) in 470 ms on localhost (executor driver) (1/22)
2021-12-04 16:58:17,485 [Executor task launch worker for task 53] INFO [org.apache.spark.executor.Executor] - Finished task 9.0 in stage 2.0 (TID 53). 1098 bytes result sent to driver
2021-12-04 16:58:17,485 [Executor task launch worker for task 56] INFO [org.apache.spark.executor.Executor] - Running task 12.0 in stage 2.0 (TID 56)
2021-12-04 16:58:17,485 [Executor task launch worker for task 52] INFO [org.apache.spark.executor.Executor] - Finished task 8.0 in stage 2.0 (TID 52). 1098 bytes result sent to driver
2021-12-04 16:58:17,486 [dispatcher-event-loop-10] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 13.0 in stage 2.0 (TID 57, localhost, executor driver, partition 13, ANY, 7649 bytes)
2021-12-04 16:58:17,486 [dispatcher-event-loop-10] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 14.0 in stage 2.0 (TID 58, localhost, executor driver, partition 14, ANY, 7649 bytes)
2021-12-04 16:58:17,487 [Executor task launch worker for task 56] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-04 16:58:17,487 [Executor task launch worker for task 56] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 1 ms
2021-12-04 16:58:17,487 [dispatcher-event-loop-10] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 15.0 in stage 2.0 (TID 59, localhost, executor driver, partition 15, ANY, 7649 bytes)
2021-12-04 16:58:17,487 [Executor task launch worker for task 58] INFO [org.apache.spark.executor.Executor] - Running task 14.0 in stage 2.0 (TID 58)
2021-12-04 16:58:17,487 [dispatcher-event-loop-10] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 16.0 in stage 2.0 (TID 60, localhost, executor driver, partition 16, ANY, 7649 bytes)
2021-12-04 16:58:17,487 [Executor task launch worker for task 50] INFO [org.apache.spark.executor.Executor] - Finished task 6.0 in stage 2.0 (TID 50). 1098 bytes result sent to driver
2021-12-04 16:58:17,487 [Executor task launch worker for task 57] INFO [org.apache.spark.executor.Executor] - Running task 13.0 in stage 2.0 (TID 57)
2021-12-04 16:58:17,488 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 2.0 (TID 45) in 474 ms on localhost (executor driver) (2/22)
2021-12-04 16:58:17,488 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 9.0 in stage 2.0 (TID 53) in 473 ms on localhost (executor driver) (3/22)
2021-12-04 16:58:17,488 [Executor task launch worker for task 58] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-04 16:58:17,488 [Executor task launch worker for task 58] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-04 16:58:17,488 [Executor task launch worker for task 44] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 2.0 (TID 44). 1098 bytes result sent to driver
2021-12-04 16:58:17,488 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 8.0 in stage 2.0 (TID 52) in 473 ms on localhost (executor driver) (4/22)
2021-12-04 16:58:17,488 [Executor task launch worker for task 48] INFO [org.apache.spark.executor.Executor] - Finished task 4.0 in stage 2.0 (TID 48). 1055 bytes result sent to driver
2021-12-04 16:58:17,488 [Executor task launch worker for task 60] INFO [org.apache.spark.executor.Executor] - Running task 16.0 in stage 2.0 (TID 60)
2021-12-04 16:58:17,489 [Executor task launch worker for task 57] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-04 16:58:17,489 [Executor task launch worker for task 57] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 1 ms
2021-12-04 16:58:17,489 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 3.0 in stage 2.0 (TID 47) in 474 ms on localhost (executor driver) (5/22)
2021-12-04 16:58:17,489 [Executor task launch worker for task 59] INFO [org.apache.spark.executor.Executor] - Running task 15.0 in stage 2.0 (TID 59)
2021-12-04 16:58:17,490 [Executor task launch worker for task 60] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-04 16:58:17,490 [Executor task launch worker for task 60] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-04 16:58:17,490 [dispatcher-event-loop-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 17.0 in stage 2.0 (TID 61, localhost, executor driver, partition 17, ANY, 7649 bytes)
2021-12-04 16:58:17,490 [dispatcher-event-loop-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 18.0 in stage 2.0 (TID 62, localhost, executor driver, partition 18, ANY, 7649 bytes)
2021-12-04 16:58:17,490 [Executor task launch worker for task 61] INFO [org.apache.spark.executor.Executor] - Running task 17.0 in stage 2.0 (TID 61)
2021-12-04 16:58:17,490 [dispatcher-event-loop-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 19.0 in stage 2.0 (TID 63, localhost, executor driver, partition 19, ANY, 7649 bytes)
2021-12-04 16:58:17,491 [Executor task launch worker for task 63] INFO [org.apache.spark.executor.Executor] - Running task 19.0 in stage 2.0 (TID 63)
2021-12-04 16:58:17,491 [Executor task launch worker for task 59] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-04 16:58:17,491 [Executor task launch worker for task 59] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 1 ms
2021-12-04 16:58:17,491 [Executor task launch worker for task 62] INFO [org.apache.spark.executor.Executor] - Running task 18.0 in stage 2.0 (TID 62)
2021-12-04 16:58:17,492 [Executor task launch worker for task 62] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-04 16:58:17,492 [Executor task launch worker for task 62] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 1 ms
2021-12-04 16:58:17,492 [Executor task launch worker for task 54] INFO [org.apache.spark.executor.Executor] - Finished task 10.0 in stage 2.0 (TID 54). 1098 bytes result sent to driver
2021-12-04 16:58:17,492 [Executor task launch worker for task 63] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-04 16:58:17,492 [Executor task launch worker for task 63] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-04 16:58:17,492 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 4.0 in stage 2.0 (TID 48) in 475 ms on localhost (executor driver) (6/22)
2021-12-04 16:58:17,492 [Executor task launch worker for task 55] INFO [org.apache.spark.executor.Executor] - Finished task 11.0 in stage 2.0 (TID 55). 1098 bytes result sent to driver
2021-12-04 16:58:17,492 [Executor task launch worker for task 61] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-04 16:58:17,492 [Executor task launch worker for task 61] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-04 16:58:17,493 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 6.0 in stage 2.0 (TID 50) in 477 ms on localhost (executor driver) (7/22)
2021-12-04 16:58:17,494 [dispatcher-event-loop-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 20.0 in stage 2.0 (TID 64, localhost, executor driver, partition 20, ANY, 7649 bytes)
2021-12-04 16:58:17,494 [Executor task launch worker for task 64] INFO [org.apache.spark.executor.Executor] - Running task 20.0 in stage 2.0 (TID 64)
2021-12-04 16:58:17,494 [dispatcher-event-loop-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 21.0 in stage 2.0 (TID 65, localhost, executor driver, partition 21, ANY, 7649 bytes)
2021-12-04 16:58:17,494 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 2.0 (TID 44) in 480 ms on localhost (executor driver) (8/22)
2021-12-04 16:58:17,494 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 10.0 in stage 2.0 (TID 54) in 479 ms on localhost (executor driver) (9/22)
2021-12-04 16:58:17,495 [Executor task launch worker for task 51] INFO [org.apache.spark.executor.Executor] - Finished task 7.0 in stage 2.0 (TID 51). 1098 bytes result sent to driver
2021-12-04 16:58:17,495 [Executor task launch worker for task 64] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-04 16:58:17,495 [Executor task launch worker for task 64] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-04 16:58:17,495 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 11.0 in stage 2.0 (TID 55) in 480 ms on localhost (executor driver) (10/22)
2021-12-04 16:58:17,495 [Executor task launch worker for task 65] INFO [org.apache.spark.executor.Executor] - Running task 21.0 in stage 2.0 (TID 65)
2021-12-04 16:58:17,495 [Executor task launch worker for task 49] INFO [org.apache.spark.executor.Executor] - Finished task 5.0 in stage 2.0 (TID 49). 1055 bytes result sent to driver
2021-12-04 16:58:17,496 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 5.0 in stage 2.0 (TID 49) in 481 ms on localhost (executor driver) (11/22)
2021-12-04 16:58:17,497 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 7.0 in stage 2.0 (TID 51) in 481 ms on localhost (executor driver) (12/22)
2021-12-04 16:58:17,497 [Executor task launch worker for task 65] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-04 16:58:17,497 [Executor task launch worker for task 65] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 1 ms
2021-12-04 16:58:17,583 [Executor task launch worker for task 58] INFO [org.apache.spark.executor.Executor] - Finished task 14.0 in stage 2.0 (TID 58). 1055 bytes result sent to driver
2021-12-04 16:58:17,585 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 14.0 in stage 2.0 (TID 58) in 99 ms on localhost (executor driver) (13/22)
2021-12-04 16:58:17,587 [Executor task launch worker for task 56] INFO [org.apache.spark.executor.Executor] - Finished task 12.0 in stage 2.0 (TID 56). 1012 bytes result sent to driver
2021-12-04 16:58:17,587 [Executor task launch worker for task 57] INFO [org.apache.spark.executor.Executor] - Finished task 13.0 in stage 2.0 (TID 57). 1055 bytes result sent to driver
2021-12-04 16:58:17,587 [Executor task launch worker for task 60] INFO [org.apache.spark.executor.Executor] - Finished task 16.0 in stage 2.0 (TID 60). 1055 bytes result sent to driver
2021-12-04 16:58:17,588 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 12.0 in stage 2.0 (TID 56) in 104 ms on localhost (executor driver) (14/22)
2021-12-04 16:58:17,588 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 13.0 in stage 2.0 (TID 57) in 103 ms on localhost (executor driver) (15/22)
2021-12-04 16:58:17,588 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 16.0 in stage 2.0 (TID 60) in 101 ms on localhost (executor driver) (16/22)
2021-12-04 16:58:17,590 [Executor task launch worker for task 61] INFO [org.apache.spark.executor.Executor] - Finished task 17.0 in stage 2.0 (TID 61). 1055 bytes result sent to driver
2021-12-04 16:58:17,590 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 17.0 in stage 2.0 (TID 61) in 100 ms on localhost (executor driver) (17/22)
2021-12-04 16:58:17,591 [Executor task launch worker for task 62] INFO [org.apache.spark.executor.Executor] - Finished task 18.0 in stage 2.0 (TID 62). 1012 bytes result sent to driver
2021-12-04 16:58:17,591 [Executor task launch worker for task 59] INFO [org.apache.spark.executor.Executor] - Finished task 15.0 in stage 2.0 (TID 59). 1055 bytes result sent to driver
2021-12-04 16:58:17,591 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 18.0 in stage 2.0 (TID 62) in 101 ms on localhost (executor driver) (18/22)
2021-12-04 16:58:17,591 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 15.0 in stage 2.0 (TID 59) in 104 ms on localhost (executor driver) (19/22)
2021-12-04 16:58:17,593 [Executor task launch worker for task 63] INFO [org.apache.spark.executor.Executor] - Finished task 19.0 in stage 2.0 (TID 63). 1012 bytes result sent to driver
2021-12-04 16:58:17,594 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 19.0 in stage 2.0 (TID 63) in 104 ms on localhost (executor driver) (20/22)
2021-12-04 16:58:17,597 [Executor task launch worker for task 65] INFO [org.apache.spark.executor.Executor] - Finished task 21.0 in stage 2.0 (TID 65). 1055 bytes result sent to driver
2021-12-04 16:58:17,597 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 21.0 in stage 2.0 (TID 65) in 103 ms on localhost (executor driver) (21/22)
2021-12-04 16:58:17,600 [Executor task launch worker for task 64] INFO [org.apache.spark.executor.Executor] - Finished task 20.0 in stage 2.0 (TID 64). 1055 bytes result sent to driver
2021-12-04 16:58:17,601 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 20.0 in stage 2.0 (TID 64) in 108 ms on localhost (executor driver) (22/22)
2021-12-04 16:58:17,601 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 2.0, whose tasks have all completed, from pool 
2021-12-04 16:58:17,601 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 2 (count at PaidPromotionAdjustParameter.scala:68) finished in 0.593 s
2021-12-04 16:58:17,601 [main] INFO [org.apache.spark.scheduler.DAGScheduler] - Job 1 finished: count at PaidPromotionAdjustParameter.scala:68, took 271.574177 s
2021-12-04 16:58:17,601 [main] INFO [PaidPromotion$] - 用户总数1207347
2021-12-04 16:58:17,619 [main] INFO [org.apache.spark.SparkContext] - Starting job: sortByKey at PaidPromotionAdjustParameter.scala:73
2021-12-04 16:58:17,620 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 2 (sortByKey at PaidPromotionAdjustParameter.scala:73) with 22 output partitions
2021-12-04 16:58:17,620 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 4 (sortByKey at PaidPromotionAdjustParameter.scala:73)
2021-12-04 16:58:17,620 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 3)
2021-12-04 16:58:17,620 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2021-12-04 16:58:17,620 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 4 (MapPartitionsRDD[7] at sortByKey at PaidPromotionAdjustParameter.scala:73), which has no missing parents
2021-12-04 16:58:17,623 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_4 stored as values in memory (estimated size 4.1 KB, free 1990.5 MB)
2021-12-04 16:58:17,624 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_4_piece0 stored as bytes in memory (estimated size 2.4 KB, free 1990.4 MB)
2021-12-04 16:58:17,624 [dispatcher-event-loop-6] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_4_piece0 in memory on qb:49432 (size: 2.4 KB, free: 1990.8 MB)
2021-12-04 16:58:17,625 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 4 from broadcast at DAGScheduler.scala:1039
2021-12-04 16:58:17,625 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 22 missing tasks from ResultStage 4 (MapPartitionsRDD[7] at sortByKey at PaidPromotionAdjustParameter.scala:73) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14))
2021-12-04 16:58:17,625 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 4.0 with 22 tasks
2021-12-04 16:58:17,625 [dispatcher-event-loop-5] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 4.0 (TID 66, localhost, executor driver, partition 0, ANY, 7649 bytes)
2021-12-04 16:58:17,626 [dispatcher-event-loop-5] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 4.0 (TID 67, localhost, executor driver, partition 1, ANY, 7649 bytes)
2021-12-04 16:58:17,626 [dispatcher-event-loop-5] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 2.0 in stage 4.0 (TID 68, localhost, executor driver, partition 2, ANY, 7649 bytes)
2021-12-04 16:58:17,626 [dispatcher-event-loop-5] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 3.0 in stage 4.0 (TID 69, localhost, executor driver, partition 3, ANY, 7649 bytes)
2021-12-04 16:58:17,626 [dispatcher-event-loop-5] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 4.0 in stage 4.0 (TID 70, localhost, executor driver, partition 4, ANY, 7649 bytes)
2021-12-04 16:58:17,626 [dispatcher-event-loop-5] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 5.0 in stage 4.0 (TID 71, localhost, executor driver, partition 5, ANY, 7649 bytes)
2021-12-04 16:58:17,626 [dispatcher-event-loop-5] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 6.0 in stage 4.0 (TID 72, localhost, executor driver, partition 6, ANY, 7649 bytes)
2021-12-04 16:58:17,626 [dispatcher-event-loop-5] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 7.0 in stage 4.0 (TID 73, localhost, executor driver, partition 7, ANY, 7649 bytes)
2021-12-04 16:58:17,626 [dispatcher-event-loop-5] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 8.0 in stage 4.0 (TID 74, localhost, executor driver, partition 8, ANY, 7649 bytes)
2021-12-04 16:58:17,626 [dispatcher-event-loop-5] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 9.0 in stage 4.0 (TID 75, localhost, executor driver, partition 9, ANY, 7649 bytes)
2021-12-04 16:58:17,626 [dispatcher-event-loop-5] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 10.0 in stage 4.0 (TID 76, localhost, executor driver, partition 10, ANY, 7649 bytes)
2021-12-04 16:58:17,626 [dispatcher-event-loop-5] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 11.0 in stage 4.0 (TID 77, localhost, executor driver, partition 11, ANY, 7649 bytes)
2021-12-04 16:58:17,626 [Executor task launch worker for task 66] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 4.0 (TID 66)
2021-12-04 16:58:17,626 [Executor task launch worker for task 69] INFO [org.apache.spark.executor.Executor] - Running task 3.0 in stage 4.0 (TID 69)
2021-12-04 16:58:17,627 [Executor task launch worker for task 74] INFO [org.apache.spark.executor.Executor] - Running task 8.0 in stage 4.0 (TID 74)
2021-12-04 16:58:17,627 [Executor task launch worker for task 73] INFO [org.apache.spark.executor.Executor] - Running task 7.0 in stage 4.0 (TID 73)
2021-12-04 16:58:17,627 [Executor task launch worker for task 72] INFO [org.apache.spark.executor.Executor] - Running task 6.0 in stage 4.0 (TID 72)
2021-12-04 16:58:17,626 [Executor task launch worker for task 70] INFO [org.apache.spark.executor.Executor] - Running task 4.0 in stage 4.0 (TID 70)
2021-12-04 16:58:17,626 [Executor task launch worker for task 68] INFO [org.apache.spark.executor.Executor] - Running task 2.0 in stage 4.0 (TID 68)
2021-12-04 16:58:17,626 [Executor task launch worker for task 67] INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 4.0 (TID 67)
2021-12-04 16:58:17,626 [Executor task launch worker for task 71] INFO [org.apache.spark.executor.Executor] - Running task 5.0 in stage 4.0 (TID 71)
2021-12-04 16:58:17,627 [Executor task launch worker for task 77] INFO [org.apache.spark.executor.Executor] - Running task 11.0 in stage 4.0 (TID 77)
2021-12-04 16:58:17,627 [Executor task launch worker for task 75] INFO [org.apache.spark.executor.Executor] - Running task 9.0 in stage 4.0 (TID 75)
2021-12-04 16:58:17,627 [Executor task launch worker for task 76] INFO [org.apache.spark.executor.Executor] - Running task 10.0 in stage 4.0 (TID 76)
2021-12-04 16:58:17,628 [Executor task launch worker for task 73] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-04 16:58:17,628 [Executor task launch worker for task 73] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-04 16:58:17,628 [Executor task launch worker for task 67] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-04 16:58:17,628 [Executor task launch worker for task 67] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-04 16:58:17,628 [Executor task launch worker for task 68] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-04 16:58:17,628 [Executor task launch worker for task 66] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-04 16:58:17,628 [Executor task launch worker for task 68] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-04 16:58:17,628 [Executor task launch worker for task 70] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-04 16:58:17,628 [Executor task launch worker for task 66] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-04 16:58:17,628 [Executor task launch worker for task 72] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-04 16:58:17,628 [Executor task launch worker for task 70] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-04 16:58:17,628 [Executor task launch worker for task 72] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-04 16:58:17,628 [Executor task launch worker for task 71] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-04 16:58:17,628 [Executor task launch worker for task 71] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-04 16:58:17,628 [Executor task launch worker for task 74] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-04 16:58:17,629 [Executor task launch worker for task 74] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 1 ms
2021-12-04 16:58:17,629 [Executor task launch worker for task 69] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-04 16:58:17,629 [Executor task launch worker for task 69] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 1 ms
2021-12-04 16:58:17,629 [Executor task launch worker for task 75] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-04 16:58:17,629 [Executor task launch worker for task 75] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-04 16:58:17,629 [Executor task launch worker for task 77] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-04 16:58:17,629 [Executor task launch worker for task 77] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-04 16:58:17,629 [Executor task launch worker for task 76] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-04 16:58:17,629 [Executor task launch worker for task 76] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-04 16:58:17,738 [Executor task launch worker for task 72] INFO [org.apache.spark.executor.Executor] - Finished task 6.0 in stage 4.0 (TID 72). 1138 bytes result sent to driver
2021-12-04 16:58:17,738 [dispatcher-event-loop-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 12.0 in stage 4.0 (TID 78, localhost, executor driver, partition 12, ANY, 7649 bytes)
2021-12-04 16:58:17,738 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 6.0 in stage 4.0 (TID 72) in 112 ms on localhost (executor driver) (1/22)
2021-12-04 16:58:17,741 [Executor task launch worker for task 75] INFO [org.apache.spark.executor.Executor] - Finished task 9.0 in stage 4.0 (TID 75). 1149 bytes result sent to driver
2021-12-04 16:58:17,742 [Executor task launch worker for task 78] INFO [org.apache.spark.executor.Executor] - Running task 12.0 in stage 4.0 (TID 78)
2021-12-04 16:58:17,742 [dispatcher-event-loop-11] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 13.0 in stage 4.0 (TID 79, localhost, executor driver, partition 13, ANY, 7649 bytes)
2021-12-04 16:58:17,743 [Executor task launch worker for task 77] INFO [org.apache.spark.executor.Executor] - Finished task 11.0 in stage 4.0 (TID 77). 1142 bytes result sent to driver
2021-12-04 16:58:17,743 [Executor task launch worker for task 79] INFO [org.apache.spark.executor.Executor] - Running task 13.0 in stage 4.0 (TID 79)
2021-12-04 16:58:17,743 [Executor task launch worker for task 78] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-04 16:58:17,743 [Executor task launch worker for task 78] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-04 16:58:17,743 [Executor task launch worker for task 71] INFO [org.apache.spark.executor.Executor] - Finished task 5.0 in stage 4.0 (TID 71). 1146 bytes result sent to driver
2021-12-04 16:58:17,744 [Executor task launch worker for task 79] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-04 16:58:17,744 [Executor task launch worker for task 79] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-04 16:58:17,745 [dispatcher-event-loop-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 14.0 in stage 4.0 (TID 80, localhost, executor driver, partition 14, ANY, 7649 bytes)
2021-12-04 16:58:17,745 [dispatcher-event-loop-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 15.0 in stage 4.0 (TID 81, localhost, executor driver, partition 15, ANY, 7649 bytes)
2021-12-04 16:58:17,745 [Executor task launch worker for task 73] INFO [org.apache.spark.executor.Executor] - Finished task 7.0 in stage 4.0 (TID 73). 1143 bytes result sent to driver
2021-12-04 16:58:17,746 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 11.0 in stage 4.0 (TID 77) in 120 ms on localhost (executor driver) (2/22)
2021-12-04 16:58:17,746 [Executor task launch worker for task 81] INFO [org.apache.spark.executor.Executor] - Running task 15.0 in stage 4.0 (TID 81)
2021-12-04 16:58:17,746 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 5.0 in stage 4.0 (TID 71) in 120 ms on localhost (executor driver) (3/22)
2021-12-04 16:58:17,747 [Executor task launch worker for task 81] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-04 16:58:17,747 [Executor task launch worker for task 81] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-04 16:58:17,747 [Executor task launch worker for task 80] INFO [org.apache.spark.executor.Executor] - Running task 14.0 in stage 4.0 (TID 80)
2021-12-04 16:58:17,748 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 9.0 in stage 4.0 (TID 75) in 122 ms on localhost (executor driver) (4/22)
2021-12-04 16:58:17,748 [Executor task launch worker for task 80] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-04 16:58:17,748 [Executor task launch worker for task 80] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-04 16:58:17,748 [Executor task launch worker for task 68] INFO [org.apache.spark.executor.Executor] - Finished task 2.0 in stage 4.0 (TID 68). 1146 bytes result sent to driver
2021-12-04 16:58:17,750 [Executor task launch worker for task 69] INFO [org.apache.spark.executor.Executor] - Finished task 3.0 in stage 4.0 (TID 69). 1141 bytes result sent to driver
2021-12-04 16:58:17,751 [dispatcher-event-loop-9] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 16.0 in stage 4.0 (TID 82, localhost, executor driver, partition 16, ANY, 7649 bytes)
2021-12-04 16:58:17,751 [Executor task launch worker for task 67] INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 4.0 (TID 67). 1140 bytes result sent to driver
2021-12-04 16:58:17,751 [dispatcher-event-loop-9] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 17.0 in stage 4.0 (TID 83, localhost, executor driver, partition 17, ANY, 7649 bytes)
2021-12-04 16:58:17,751 [Executor task launch worker for task 82] INFO [org.apache.spark.executor.Executor] - Running task 16.0 in stage 4.0 (TID 82)
2021-12-04 16:58:17,751 [dispatcher-event-loop-9] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 18.0 in stage 4.0 (TID 84, localhost, executor driver, partition 18, ANY, 7649 bytes)
2021-12-04 16:58:17,751 [Executor task launch worker for task 83] INFO [org.apache.spark.executor.Executor] - Running task 17.0 in stage 4.0 (TID 83)
2021-12-04 16:58:17,751 [Executor task launch worker for task 84] INFO [org.apache.spark.executor.Executor] - Running task 18.0 in stage 4.0 (TID 84)
2021-12-04 16:58:17,751 [dispatcher-event-loop-9] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 19.0 in stage 4.0 (TID 85, localhost, executor driver, partition 19, ANY, 7649 bytes)
2021-12-04 16:58:17,752 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 7.0 in stage 4.0 (TID 73) in 126 ms on localhost (executor driver) (5/22)
2021-12-04 16:58:17,752 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 3.0 in stage 4.0 (TID 69) in 126 ms on localhost (executor driver) (6/22)
2021-12-04 16:58:17,752 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 4.0 (TID 67) in 126 ms on localhost (executor driver) (7/22)
2021-12-04 16:58:17,751 [Executor task launch worker for task 70] INFO [org.apache.spark.executor.Executor] - Finished task 4.0 in stage 4.0 (TID 70). 1144 bytes result sent to driver
2021-12-04 16:58:17,752 [Executor task launch worker for task 85] INFO [org.apache.spark.executor.Executor] - Running task 19.0 in stage 4.0 (TID 85)
2021-12-04 16:58:17,752 [Executor task launch worker for task 82] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-04 16:58:17,752 [Executor task launch worker for task 82] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-04 16:58:17,752 [Executor task launch worker for task 84] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-04 16:58:17,753 [dispatcher-event-loop-9] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 20.0 in stage 4.0 (TID 86, localhost, executor driver, partition 20, ANY, 7649 bytes)
2021-12-04 16:58:17,753 [Executor task launch worker for task 84] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 1 ms
2021-12-04 16:58:17,753 [Executor task launch worker for task 86] INFO [org.apache.spark.executor.Executor] - Running task 20.0 in stage 4.0 (TID 86)
2021-12-04 16:58:17,753 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 2.0 in stage 4.0 (TID 68) in 127 ms on localhost (executor driver) (8/22)
2021-12-04 16:58:17,753 [Executor task launch worker for task 74] INFO [org.apache.spark.executor.Executor] - Finished task 8.0 in stage 4.0 (TID 74). 1144 bytes result sent to driver
2021-12-04 16:58:17,753 [Executor task launch worker for task 85] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-04 16:58:17,753 [Executor task launch worker for task 85] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-04 16:58:17,753 [dispatcher-event-loop-5] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 21.0 in stage 4.0 (TID 87, localhost, executor driver, partition 21, ANY, 7649 bytes)
2021-12-04 16:58:17,753 [Executor task launch worker for task 87] INFO [org.apache.spark.executor.Executor] - Running task 21.0 in stage 4.0 (TID 87)
2021-12-04 16:58:17,754 [Executor task launch worker for task 86] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-04 16:58:17,754 [Executor task launch worker for task 76] INFO [org.apache.spark.executor.Executor] - Finished task 10.0 in stage 4.0 (TID 76). 1144 bytes result sent to driver
2021-12-04 16:58:17,754 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 8.0 in stage 4.0 (TID 74) in 128 ms on localhost (executor driver) (9/22)
2021-12-04 16:58:17,754 [Executor task launch worker for task 86] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-04 16:58:17,755 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 4.0 in stage 4.0 (TID 70) in 129 ms on localhost (executor driver) (10/22)
2021-12-04 16:58:17,755 [Executor task launch worker for task 87] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-04 16:58:17,755 [Executor task launch worker for task 87] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-04 16:58:17,755 [Executor task launch worker for task 83] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-04 16:58:17,755 [Executor task launch worker for task 83] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-04 16:58:17,755 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 10.0 in stage 4.0 (TID 76) in 129 ms on localhost (executor driver) (11/22)
2021-12-04 16:58:17,757 [Executor task launch worker for task 66] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 4.0 (TID 66). 1145 bytes result sent to driver
2021-12-04 16:58:17,757 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 4.0 (TID 66) in 132 ms on localhost (executor driver) (12/22)
2021-12-04 16:58:17,841 [Executor task launch worker for task 79] INFO [org.apache.spark.executor.Executor] - Finished task 13.0 in stage 4.0 (TID 79). 1141 bytes result sent to driver
2021-12-04 16:58:17,841 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 13.0 in stage 4.0 (TID 79) in 99 ms on localhost (executor driver) (13/22)
2021-12-04 16:58:17,844 [Executor task launch worker for task 81] INFO [org.apache.spark.executor.Executor] - Finished task 15.0 in stage 4.0 (TID 81). 1180 bytes result sent to driver
2021-12-04 16:58:17,844 [Executor task launch worker for task 78] INFO [org.apache.spark.executor.Executor] - Finished task 12.0 in stage 4.0 (TID 78). 1228 bytes result sent to driver
2021-12-04 16:58:17,844 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 15.0 in stage 4.0 (TID 81) in 99 ms on localhost (executor driver) (14/22)
2021-12-04 16:58:17,844 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 12.0 in stage 4.0 (TID 78) in 106 ms on localhost (executor driver) (15/22)
2021-12-04 16:58:17,846 [Executor task launch worker for task 80] INFO [org.apache.spark.executor.Executor] - Finished task 14.0 in stage 4.0 (TID 80). 1185 bytes result sent to driver
2021-12-04 16:58:17,847 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 14.0 in stage 4.0 (TID 80) in 102 ms on localhost (executor driver) (16/22)
2021-12-04 16:58:17,847 [Executor task launch worker for task 84] INFO [org.apache.spark.executor.Executor] - Finished task 18.0 in stage 4.0 (TID 84). 1137 bytes result sent to driver
2021-12-04 16:58:17,847 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 18.0 in stage 4.0 (TID 84) in 96 ms on localhost (executor driver) (17/22)
2021-12-04 16:58:17,848 [Executor task launch worker for task 85] INFO [org.apache.spark.executor.Executor] - Finished task 19.0 in stage 4.0 (TID 85). 1189 bytes result sent to driver
2021-12-04 16:58:17,848 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 19.0 in stage 4.0 (TID 85) in 97 ms on localhost (executor driver) (18/22)
2021-12-04 16:58:17,852 [Executor task launch worker for task 86] INFO [org.apache.spark.executor.Executor] - Finished task 20.0 in stage 4.0 (TID 86). 1146 bytes result sent to driver
2021-12-04 16:58:17,852 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 20.0 in stage 4.0 (TID 86) in 100 ms on localhost (executor driver) (19/22)
2021-12-04 16:58:17,852 [Executor task launch worker for task 82] INFO [org.apache.spark.executor.Executor] - Finished task 16.0 in stage 4.0 (TID 82). 1143 bytes result sent to driver
2021-12-04 16:58:17,853 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 16.0 in stage 4.0 (TID 82) in 102 ms on localhost (executor driver) (20/22)
2021-12-04 16:58:17,855 [Executor task launch worker for task 83] INFO [org.apache.spark.executor.Executor] - Finished task 17.0 in stage 4.0 (TID 83). 1185 bytes result sent to driver
2021-12-04 16:58:17,855 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 17.0 in stage 4.0 (TID 83) in 104 ms on localhost (executor driver) (21/22)
2021-12-04 16:58:17,856 [Executor task launch worker for task 87] INFO [org.apache.spark.executor.Executor] - Finished task 21.0 in stage 4.0 (TID 87). 1187 bytes result sent to driver
2021-12-04 16:58:17,856 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 21.0 in stage 4.0 (TID 87) in 103 ms on localhost (executor driver) (22/22)
2021-12-04 16:58:17,856 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 4.0, whose tasks have all completed, from pool 
2021-12-04 16:58:17,857 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 4 (sortByKey at PaidPromotionAdjustParameter.scala:73) finished in 0.235 s
2021-12-04 16:58:17,857 [main] INFO [org.apache.spark.scheduler.DAGScheduler] - Job 2 finished: sortByKey at PaidPromotionAdjustParameter.scala:73, took 0.236868 s
2021-12-04 16:58:17,871 [main] INFO [org.apache.spark.SparkContext] - Starting job: zipWithIndex at PaidPromotionAdjustParameter.scala:74
2021-12-04 16:58:17,872 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 5 (map at PaidPromotionAdjustParameter.scala:72)
2021-12-04 16:58:17,872 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 3 (zipWithIndex at PaidPromotionAdjustParameter.scala:74) with 21 output partitions
2021-12-04 16:58:17,872 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 7 (zipWithIndex at PaidPromotionAdjustParameter.scala:74)
2021-12-04 16:58:17,872 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 6)
2021-12-04 16:58:17,872 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List(ShuffleMapStage 6)
2021-12-04 16:58:17,872 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ShuffleMapStage 6 (MapPartitionsRDD[5] at map at PaidPromotionAdjustParameter.scala:72), which has no missing parents
2021-12-04 16:58:17,879 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_5 stored as values in memory (estimated size 4.1 KB, free 1990.4 MB)
2021-12-04 16:58:17,882 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_5_piece0 stored as bytes in memory (estimated size 2.4 KB, free 1990.4 MB)
2021-12-04 16:58:17,882 [dispatcher-event-loop-4] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_5_piece0 in memory on qb:49432 (size: 2.4 KB, free: 1990.8 MB)
2021-12-04 16:58:17,882 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 5 from broadcast at DAGScheduler.scala:1039
2021-12-04 16:58:17,883 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 22 missing tasks from ShuffleMapStage 6 (MapPartitionsRDD[5] at map at PaidPromotionAdjustParameter.scala:72) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14))
2021-12-04 16:58:17,883 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 6.0 with 22 tasks
2021-12-04 16:58:17,883 [dispatcher-event-loop-9] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 6.0 (TID 88, localhost, executor driver, partition 0, ANY, 7638 bytes)
2021-12-04 16:58:17,883 [dispatcher-event-loop-9] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 6.0 (TID 89, localhost, executor driver, partition 1, ANY, 7638 bytes)
2021-12-04 16:58:17,883 [dispatcher-event-loop-9] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 2.0 in stage 6.0 (TID 90, localhost, executor driver, partition 2, ANY, 7638 bytes)
2021-12-04 16:58:17,883 [dispatcher-event-loop-9] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 3.0 in stage 6.0 (TID 91, localhost, executor driver, partition 3, ANY, 7638 bytes)
2021-12-04 16:58:17,883 [dispatcher-event-loop-9] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 4.0 in stage 6.0 (TID 92, localhost, executor driver, partition 4, ANY, 7638 bytes)
2021-12-04 16:58:17,884 [dispatcher-event-loop-9] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 5.0 in stage 6.0 (TID 93, localhost, executor driver, partition 5, ANY, 7638 bytes)
2021-12-04 16:58:17,884 [dispatcher-event-loop-9] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 6.0 in stage 6.0 (TID 94, localhost, executor driver, partition 6, ANY, 7638 bytes)
2021-12-04 16:58:17,884 [dispatcher-event-loop-9] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 7.0 in stage 6.0 (TID 95, localhost, executor driver, partition 7, ANY, 7638 bytes)
2021-12-04 16:58:17,884 [dispatcher-event-loop-9] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 8.0 in stage 6.0 (TID 96, localhost, executor driver, partition 8, ANY, 7638 bytes)
2021-12-04 16:58:17,884 [dispatcher-event-loop-9] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 9.0 in stage 6.0 (TID 97, localhost, executor driver, partition 9, ANY, 7638 bytes)
2021-12-04 16:58:17,884 [dispatcher-event-loop-9] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 10.0 in stage 6.0 (TID 98, localhost, executor driver, partition 10, ANY, 7638 bytes)
2021-12-04 16:58:17,884 [dispatcher-event-loop-9] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 11.0 in stage 6.0 (TID 99, localhost, executor driver, partition 11, ANY, 7638 bytes)
2021-12-04 16:58:17,884 [Executor task launch worker for task 90] INFO [org.apache.spark.executor.Executor] - Running task 2.0 in stage 6.0 (TID 90)
2021-12-04 16:58:17,884 [Executor task launch worker for task 92] INFO [org.apache.spark.executor.Executor] - Running task 4.0 in stage 6.0 (TID 92)
2021-12-04 16:58:17,884 [Executor task launch worker for task 97] INFO [org.apache.spark.executor.Executor] - Running task 9.0 in stage 6.0 (TID 97)
2021-12-04 16:58:17,884 [Executor task launch worker for task 95] INFO [org.apache.spark.executor.Executor] - Running task 7.0 in stage 6.0 (TID 95)
2021-12-04 16:58:17,884 [Executor task launch worker for task 99] INFO [org.apache.spark.executor.Executor] - Running task 11.0 in stage 6.0 (TID 99)
2021-12-04 16:58:17,884 [Executor task launch worker for task 96] INFO [org.apache.spark.executor.Executor] - Running task 8.0 in stage 6.0 (TID 96)
2021-12-04 16:58:17,884 [Executor task launch worker for task 98] INFO [org.apache.spark.executor.Executor] - Running task 10.0 in stage 6.0 (TID 98)
2021-12-04 16:58:17,884 [Executor task launch worker for task 93] INFO [org.apache.spark.executor.Executor] - Running task 5.0 in stage 6.0 (TID 93)
2021-12-04 16:58:17,884 [Executor task launch worker for task 88] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 6.0 (TID 88)
2021-12-04 16:58:17,884 [Executor task launch worker for task 94] INFO [org.apache.spark.executor.Executor] - Running task 6.0 in stage 6.0 (TID 94)
2021-12-04 16:58:17,884 [Executor task launch worker for task 91] INFO [org.apache.spark.executor.Executor] - Running task 3.0 in stage 6.0 (TID 91)
2021-12-04 16:58:17,884 [Executor task launch worker for task 89] INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 6.0 (TID 89)
2021-12-04 16:58:17,892 [Executor task launch worker for task 96] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-04 16:58:17,892 [Executor task launch worker for task 89] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-04 16:58:17,892 [Executor task launch worker for task 96] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-04 16:58:17,892 [Executor task launch worker for task 89] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-04 16:58:17,892 [Executor task launch worker for task 90] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-04 16:58:17,892 [Executor task launch worker for task 90] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-04 16:58:17,892 [Executor task launch worker for task 88] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-04 16:58:17,892 [Executor task launch worker for task 88] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-04 16:58:17,892 [Executor task launch worker for task 95] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-04 16:58:17,892 [Executor task launch worker for task 95] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-04 16:58:17,892 [Executor task launch worker for task 93] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-04 16:58:17,893 [Executor task launch worker for task 93] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 1 ms
2021-12-04 16:58:17,892 [Executor task launch worker for task 91] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-04 16:58:17,893 [Executor task launch worker for task 91] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 1 ms
2021-12-04 16:58:17,893 [Executor task launch worker for task 94] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-04 16:58:17,893 [Executor task launch worker for task 94] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-04 16:58:17,892 [Executor task launch worker for task 97] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-04 16:58:17,893 [Executor task launch worker for task 97] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 1 ms
2021-12-04 16:58:17,892 [Executor task launch worker for task 98] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-04 16:58:17,893 [Executor task launch worker for task 92] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-04 16:58:17,893 [Executor task launch worker for task 99] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-04 16:58:17,893 [Executor task launch worker for task 92] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 1 ms
2021-12-04 16:58:17,893 [Executor task launch worker for task 98] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 1 ms
2021-12-04 16:58:17,893 [Executor task launch worker for task 99] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-04 16:58:18,387 [Executor task launch worker for task 92] INFO [org.apache.spark.executor.Executor] - Finished task 4.0 in stage 6.0 (TID 92). 1310 bytes result sent to driver
2021-12-04 16:58:18,387 [dispatcher-event-loop-5] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 12.0 in stage 6.0 (TID 100, localhost, executor driver, partition 12, ANY, 7638 bytes)
2021-12-04 16:58:18,388 [Executor task launch worker for task 100] INFO [org.apache.spark.executor.Executor] - Running task 12.0 in stage 6.0 (TID 100)
2021-12-04 16:58:18,390 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 4.0 in stage 6.0 (TID 92) in 507 ms on localhost (executor driver) (1/22)
2021-12-04 16:58:18,391 [Executor task launch worker for task 100] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-04 16:58:18,391 [Executor task launch worker for task 100] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-04 16:58:18,397 [Executor task launch worker for task 99] INFO [org.apache.spark.executor.Executor] - Finished task 11.0 in stage 6.0 (TID 99). 1224 bytes result sent to driver
2021-12-04 16:58:18,398 [dispatcher-event-loop-6] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 13.0 in stage 6.0 (TID 101, localhost, executor driver, partition 13, ANY, 7638 bytes)
2021-12-04 16:58:18,398 [Executor task launch worker for task 101] INFO [org.apache.spark.executor.Executor] - Running task 13.0 in stage 6.0 (TID 101)
2021-12-04 16:58:18,398 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 11.0 in stage 6.0 (TID 99) in 514 ms on localhost (executor driver) (2/22)
2021-12-04 16:58:18,400 [Executor task launch worker for task 94] INFO [org.apache.spark.executor.Executor] - Finished task 6.0 in stage 6.0 (TID 94). 1224 bytes result sent to driver
2021-12-04 16:58:18,401 [Executor task launch worker for task 101] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-04 16:58:18,401 [dispatcher-event-loop-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 14.0 in stage 6.0 (TID 102, localhost, executor driver, partition 14, ANY, 7638 bytes)
2021-12-04 16:58:18,401 [Executor task launch worker for task 101] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-04 16:58:18,401 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 6.0 in stage 6.0 (TID 94) in 517 ms on localhost (executor driver) (3/22)
2021-12-04 16:58:18,401 [Executor task launch worker for task 102] INFO [org.apache.spark.executor.Executor] - Running task 14.0 in stage 6.0 (TID 102)
2021-12-04 16:58:18,403 [Executor task launch worker for task 88] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 6.0 (TID 88). 1224 bytes result sent to driver
2021-12-04 16:58:18,404 [dispatcher-event-loop-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 15.0 in stage 6.0 (TID 103, localhost, executor driver, partition 15, ANY, 7638 bytes)
2021-12-04 16:58:18,404 [Executor task launch worker for task 103] INFO [org.apache.spark.executor.Executor] - Running task 15.0 in stage 6.0 (TID 103)
2021-12-04 16:58:18,404 [Executor task launch worker for task 102] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-04 16:58:18,404 [Executor task launch worker for task 102] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-04 16:58:18,405 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 6.0 (TID 88) in 522 ms on localhost (executor driver) (4/22)
2021-12-04 16:58:18,406 [Executor task launch worker for task 93] INFO [org.apache.spark.executor.Executor] - Finished task 5.0 in stage 6.0 (TID 93). 1267 bytes result sent to driver
2021-12-04 16:58:18,406 [Executor task launch worker for task 97] INFO [org.apache.spark.executor.Executor] - Finished task 9.0 in stage 6.0 (TID 97). 1224 bytes result sent to driver
2021-12-04 16:58:18,406 [dispatcher-event-loop-11] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 16.0 in stage 6.0 (TID 104, localhost, executor driver, partition 16, ANY, 7638 bytes)
2021-12-04 16:58:18,407 [Executor task launch worker for task 104] INFO [org.apache.spark.executor.Executor] - Running task 16.0 in stage 6.0 (TID 104)
2021-12-04 16:58:18,407 [Executor task launch worker for task 103] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-04 16:58:18,407 [Executor task launch worker for task 103] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-04 16:58:18,407 [dispatcher-event-loop-11] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 17.0 in stage 6.0 (TID 105, localhost, executor driver, partition 17, ANY, 7638 bytes)
2021-12-04 16:58:18,407 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 5.0 in stage 6.0 (TID 93) in 523 ms on localhost (executor driver) (5/22)
2021-12-04 16:58:18,407 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 9.0 in stage 6.0 (TID 97) in 523 ms on localhost (executor driver) (6/22)
2021-12-04 16:58:18,407 [Executor task launch worker for task 105] INFO [org.apache.spark.executor.Executor] - Running task 17.0 in stage 6.0 (TID 105)
2021-12-04 16:58:18,408 [Executor task launch worker for task 98] INFO [org.apache.spark.executor.Executor] - Finished task 10.0 in stage 6.0 (TID 98). 1224 bytes result sent to driver
2021-12-04 16:58:18,409 [dispatcher-event-loop-5] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 18.0 in stage 6.0 (TID 106, localhost, executor driver, partition 18, ANY, 7638 bytes)
2021-12-04 16:58:18,409 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 10.0 in stage 6.0 (TID 98) in 525 ms on localhost (executor driver) (7/22)
2021-12-04 16:58:18,410 [Executor task launch worker for task 106] INFO [org.apache.spark.executor.Executor] - Running task 18.0 in stage 6.0 (TID 106)
2021-12-04 16:58:18,410 [Executor task launch worker for task 104] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-04 16:58:18,410 [Executor task launch worker for task 104] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-04 16:58:18,414 [Executor task launch worker for task 105] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-04 16:58:18,414 [Executor task launch worker for task 105] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-04 16:58:18,415 [Executor task launch worker for task 106] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-04 16:58:18,415 [Executor task launch worker for task 106] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 1 ms
2021-12-04 16:58:18,423 [Executor task launch worker for task 95] INFO [org.apache.spark.executor.Executor] - Finished task 7.0 in stage 6.0 (TID 95). 1267 bytes result sent to driver
2021-12-04 16:58:18,426 [dispatcher-event-loop-6] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 19.0 in stage 6.0 (TID 107, localhost, executor driver, partition 19, ANY, 7638 bytes)
2021-12-04 16:58:18,426 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 7.0 in stage 6.0 (TID 95) in 542 ms on localhost (executor driver) (8/22)
2021-12-04 16:58:18,426 [Executor task launch worker for task 107] INFO [org.apache.spark.executor.Executor] - Running task 19.0 in stage 6.0 (TID 107)
2021-12-04 16:58:18,437 [Executor task launch worker for task 107] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-04 16:58:18,437 [Executor task launch worker for task 107] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-04 16:58:18,450 [Executor task launch worker for task 89] INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 6.0 (TID 89). 1224 bytes result sent to driver
2021-12-04 16:58:18,450 [dispatcher-event-loop-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 20.0 in stage 6.0 (TID 108, localhost, executor driver, partition 20, ANY, 7638 bytes)
2021-12-04 16:58:18,450 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 6.0 (TID 89) in 567 ms on localhost (executor driver) (9/22)
2021-12-04 16:58:18,451 [Executor task launch worker for task 108] INFO [org.apache.spark.executor.Executor] - Running task 20.0 in stage 6.0 (TID 108)
2021-12-04 16:58:18,453 [Executor task launch worker for task 96] INFO [org.apache.spark.executor.Executor] - Finished task 8.0 in stage 6.0 (TID 96). 1267 bytes result sent to driver
2021-12-04 16:58:18,453 [dispatcher-event-loop-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 21.0 in stage 6.0 (TID 109, localhost, executor driver, partition 21, ANY, 7638 bytes)
2021-12-04 16:58:18,454 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 8.0 in stage 6.0 (TID 96) in 570 ms on localhost (executor driver) (10/22)
2021-12-04 16:58:18,454 [Executor task launch worker for task 109] INFO [org.apache.spark.executor.Executor] - Running task 21.0 in stage 6.0 (TID 109)
2021-12-04 16:58:18,456 [Executor task launch worker for task 108] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-04 16:58:18,456 [Executor task launch worker for task 108] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-04 16:58:18,457 [Executor task launch worker for task 109] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-04 16:58:18,457 [Executor task launch worker for task 109] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-04 16:58:18,471 [Executor task launch worker for task 90] INFO [org.apache.spark.executor.Executor] - Finished task 2.0 in stage 6.0 (TID 90). 1224 bytes result sent to driver
2021-12-04 16:58:18,471 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 2.0 in stage 6.0 (TID 90) in 588 ms on localhost (executor driver) (11/22)
2021-12-04 16:58:18,479 [Executor task launch worker for task 91] INFO [org.apache.spark.executor.Executor] - Finished task 3.0 in stage 6.0 (TID 91). 1224 bytes result sent to driver
2021-12-04 16:58:18,480 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 3.0 in stage 6.0 (TID 91) in 597 ms on localhost (executor driver) (12/22)
2021-12-04 16:58:18,527 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 78
2021-12-04 16:58:18,527 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 79
2021-12-04 16:58:18,527 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 81
2021-12-04 16:58:18,527 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 88
2021-12-04 16:58:18,527 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 90
2021-12-04 16:58:18,527 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 93
2021-12-04 16:58:18,527 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 82
2021-12-04 16:58:18,527 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 86
2021-12-04 16:58:18,527 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 91
2021-12-04 16:58:18,527 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 97
2021-12-04 16:58:18,527 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 87
2021-12-04 16:58:18,533 [dispatcher-event-loop-5] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_4_piece0 on qb:49432 in memory (size: 2.4 KB, free: 1990.8 MB)
2021-12-04 16:58:18,542 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 75
2021-12-04 16:58:18,542 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 89
2021-12-04 16:58:18,542 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 95
2021-12-04 16:58:18,542 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 84
2021-12-04 16:58:18,542 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 83
2021-12-04 16:58:18,542 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 85
2021-12-04 16:58:18,542 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 99
2021-12-04 16:58:18,542 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 92
2021-12-04 16:58:18,542 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 76
2021-12-04 16:58:18,542 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 94
2021-12-04 16:58:18,542 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 77
2021-12-04 16:58:18,542 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 80
2021-12-04 16:58:18,542 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 98
2021-12-04 16:58:18,542 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 96
2021-12-04 16:58:18,813 [Executor task launch worker for task 100] INFO [org.apache.spark.executor.Executor] - Finished task 12.0 in stage 6.0 (TID 100). 1267 bytes result sent to driver
2021-12-04 16:58:18,814 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 12.0 in stage 6.0 (TID 100) in 427 ms on localhost (executor driver) (13/22)
2021-12-04 16:58:18,821 [Executor task launch worker for task 106] INFO [org.apache.spark.executor.Executor] - Finished task 18.0 in stage 6.0 (TID 106). 1310 bytes result sent to driver
2021-12-04 16:58:18,821 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 18.0 in stage 6.0 (TID 106) in 412 ms on localhost (executor driver) (14/22)
2021-12-04 16:58:18,825 [Executor task launch worker for task 101] INFO [org.apache.spark.executor.Executor] - Finished task 13.0 in stage 6.0 (TID 101). 1267 bytes result sent to driver
2021-12-04 16:58:18,826 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 13.0 in stage 6.0 (TID 101) in 428 ms on localhost (executor driver) (15/22)
2021-12-04 16:58:18,837 [Executor task launch worker for task 103] INFO [org.apache.spark.executor.Executor] - Finished task 15.0 in stage 6.0 (TID 103). 1310 bytes result sent to driver
2021-12-04 16:58:18,837 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 15.0 in stage 6.0 (TID 103) in 434 ms on localhost (executor driver) (16/22)
2021-12-04 16:58:18,839 [Executor task launch worker for task 105] INFO [org.apache.spark.executor.Executor] - Finished task 17.0 in stage 6.0 (TID 105). 1267 bytes result sent to driver
2021-12-04 16:58:18,840 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 17.0 in stage 6.0 (TID 105) in 433 ms on localhost (executor driver) (17/22)
2021-12-04 16:58:18,855 [Executor task launch worker for task 102] INFO [org.apache.spark.executor.Executor] - Finished task 14.0 in stage 6.0 (TID 102). 1310 bytes result sent to driver
2021-12-04 16:58:18,856 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 14.0 in stage 6.0 (TID 102) in 455 ms on localhost (executor driver) (18/22)
2021-12-04 16:58:18,860 [Executor task launch worker for task 108] INFO [org.apache.spark.executor.Executor] - Finished task 20.0 in stage 6.0 (TID 108). 1267 bytes result sent to driver
2021-12-04 16:58:18,860 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 20.0 in stage 6.0 (TID 108) in 410 ms on localhost (executor driver) (19/22)
2021-12-04 16:58:18,867 [Executor task launch worker for task 104] INFO [org.apache.spark.executor.Executor] - Finished task 16.0 in stage 6.0 (TID 104). 1267 bytes result sent to driver
2021-12-04 16:58:18,867 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 16.0 in stage 6.0 (TID 104) in 461 ms on localhost (executor driver) (20/22)
2021-12-04 16:58:18,894 [Executor task launch worker for task 107] INFO [org.apache.spark.executor.Executor] - Finished task 19.0 in stage 6.0 (TID 107). 1267 bytes result sent to driver
2021-12-04 16:58:18,894 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 19.0 in stage 6.0 (TID 107) in 469 ms on localhost (executor driver) (21/22)
2021-12-04 16:58:18,917 [Executor task launch worker for task 109] INFO [org.apache.spark.executor.Executor] - Finished task 21.0 in stage 6.0 (TID 109). 1267 bytes result sent to driver
2021-12-04 16:58:18,918 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 21.0 in stage 6.0 (TID 109) in 465 ms on localhost (executor driver) (22/22)
2021-12-04 16:58:18,918 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 6.0, whose tasks have all completed, from pool 
2021-12-04 16:58:18,918 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ShuffleMapStage 6 (map at PaidPromotionAdjustParameter.scala:72) finished in 1.044 s
2021-12-04 16:58:18,918 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - looking for newly runnable stages
2021-12-04 16:58:18,918 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - running: Set()
2021-12-04 16:58:18,918 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - waiting: Set(ResultStage 7)
2021-12-04 16:58:18,918 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - failed: Set()
2021-12-04 16:58:18,918 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 7 (ShuffledRDD[8] at sortByKey at PaidPromotionAdjustParameter.scala:73), which has no missing parents
2021-12-04 16:58:18,920 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_6 stored as values in memory (estimated size 3.4 KB, free 1990.4 MB)
2021-12-04 16:58:18,921 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_6_piece0 stored as bytes in memory (estimated size 2.0 KB, free 1990.4 MB)
2021-12-04 16:58:18,922 [dispatcher-event-loop-9] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_6_piece0 in memory on qb:49432 (size: 2.0 KB, free: 1990.8 MB)
2021-12-04 16:58:18,922 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 6 from broadcast at DAGScheduler.scala:1039
2021-12-04 16:58:18,922 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 21 missing tasks from ResultStage 7 (ShuffledRDD[8] at sortByKey at PaidPromotionAdjustParameter.scala:73) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14))
2021-12-04 16:58:18,922 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 7.0 with 21 tasks
2021-12-04 16:58:18,923 [dispatcher-event-loop-5] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 7.0 (TID 110, localhost, executor driver, partition 0, ANY, 7649 bytes)
2021-12-04 16:58:18,923 [dispatcher-event-loop-5] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 7.0 (TID 111, localhost, executor driver, partition 1, ANY, 7649 bytes)
2021-12-04 16:58:18,923 [dispatcher-event-loop-5] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 2.0 in stage 7.0 (TID 112, localhost, executor driver, partition 2, ANY, 7649 bytes)
2021-12-04 16:58:18,923 [dispatcher-event-loop-5] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 3.0 in stage 7.0 (TID 113, localhost, executor driver, partition 3, ANY, 7649 bytes)
2021-12-04 16:58:18,923 [dispatcher-event-loop-5] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 4.0 in stage 7.0 (TID 114, localhost, executor driver, partition 4, ANY, 7649 bytes)
2021-12-04 16:58:18,923 [dispatcher-event-loop-5] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 5.0 in stage 7.0 (TID 115, localhost, executor driver, partition 5, ANY, 7649 bytes)
2021-12-04 16:58:18,924 [dispatcher-event-loop-5] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 6.0 in stage 7.0 (TID 116, localhost, executor driver, partition 6, ANY, 7649 bytes)
2021-12-04 16:58:18,924 [dispatcher-event-loop-5] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 7.0 in stage 7.0 (TID 117, localhost, executor driver, partition 7, ANY, 7649 bytes)
2021-12-04 16:58:18,924 [dispatcher-event-loop-5] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 8.0 in stage 7.0 (TID 118, localhost, executor driver, partition 8, ANY, 7649 bytes)
2021-12-04 16:58:18,924 [dispatcher-event-loop-5] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 9.0 in stage 7.0 (TID 119, localhost, executor driver, partition 9, ANY, 7649 bytes)
2021-12-04 16:58:18,924 [dispatcher-event-loop-5] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 10.0 in stage 7.0 (TID 120, localhost, executor driver, partition 10, ANY, 7649 bytes)
2021-12-04 16:58:18,924 [dispatcher-event-loop-5] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 11.0 in stage 7.0 (TID 121, localhost, executor driver, partition 11, ANY, 7649 bytes)
2021-12-04 16:58:18,924 [Executor task launch worker for task 110] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 7.0 (TID 110)
2021-12-04 16:58:18,924 [Executor task launch worker for task 113] INFO [org.apache.spark.executor.Executor] - Running task 3.0 in stage 7.0 (TID 113)
2021-12-04 16:58:18,924 [Executor task launch worker for task 120] INFO [org.apache.spark.executor.Executor] - Running task 10.0 in stage 7.0 (TID 120)
2021-12-04 16:58:18,924 [Executor task launch worker for task 117] INFO [org.apache.spark.executor.Executor] - Running task 7.0 in stage 7.0 (TID 117)
2021-12-04 16:58:18,924 [Executor task launch worker for task 119] INFO [org.apache.spark.executor.Executor] - Running task 9.0 in stage 7.0 (TID 119)
2021-12-04 16:58:18,924 [Executor task launch worker for task 114] INFO [org.apache.spark.executor.Executor] - Running task 4.0 in stage 7.0 (TID 114)
2021-12-04 16:58:18,924 [Executor task launch worker for task 115] INFO [org.apache.spark.executor.Executor] - Running task 5.0 in stage 7.0 (TID 115)
2021-12-04 16:58:18,924 [Executor task launch worker for task 116] INFO [org.apache.spark.executor.Executor] - Running task 6.0 in stage 7.0 (TID 116)
2021-12-04 16:58:18,924 [Executor task launch worker for task 112] INFO [org.apache.spark.executor.Executor] - Running task 2.0 in stage 7.0 (TID 112)
2021-12-04 16:58:18,924 [Executor task launch worker for task 111] INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 7.0 (TID 111)
2021-12-04 16:58:18,924 [Executor task launch worker for task 118] INFO [org.apache.spark.executor.Executor] - Running task 8.0 in stage 7.0 (TID 118)
2021-12-04 16:58:18,924 [Executor task launch worker for task 121] INFO [org.apache.spark.executor.Executor] - Running task 11.0 in stage 7.0 (TID 121)
2021-12-04 16:58:18,927 [Executor task launch worker for task 119] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-04 16:58:18,927 [Executor task launch worker for task 120] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-04 16:58:18,927 [Executor task launch worker for task 119] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-04 16:58:18,927 [Executor task launch worker for task 120] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-04 16:58:18,928 [Executor task launch worker for task 117] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-04 16:58:18,928 [Executor task launch worker for task 117] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-04 16:58:18,928 [Executor task launch worker for task 114] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-04 16:58:18,928 [Executor task launch worker for task 114] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-04 16:58:18,928 [Executor task launch worker for task 115] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-04 16:58:18,928 [Executor task launch worker for task 115] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-04 16:58:18,929 [Executor task launch worker for task 116] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-04 16:58:18,929 [Executor task launch worker for task 116] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 1 ms
2021-12-04 16:58:18,929 [Executor task launch worker for task 112] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-04 16:58:18,929 [Executor task launch worker for task 112] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-04 16:58:18,929 [Executor task launch worker for task 110] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-04 16:58:18,929 [Executor task launch worker for task 110] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-04 16:58:18,929 [Executor task launch worker for task 118] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-04 16:58:18,929 [Executor task launch worker for task 118] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-04 16:58:18,930 [Executor task launch worker for task 121] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-04 16:58:18,930 [Executor task launch worker for task 121] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-04 16:58:18,930 [Executor task launch worker for task 111] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-04 16:58:18,930 [Executor task launch worker for task 111] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-04 16:58:18,930 [Executor task launch worker for task 113] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-04 16:58:18,930 [Executor task launch worker for task 113] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-04 16:58:19,207 [Executor task launch worker for task 119] INFO [org.apache.spark.executor.Executor] - Finished task 9.0 in stage 7.0 (TID 119). 1055 bytes result sent to driver
2021-12-04 16:58:19,207 [dispatcher-event-loop-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 12.0 in stage 7.0 (TID 122, localhost, executor driver, partition 12, ANY, 7649 bytes)
2021-12-04 16:58:19,207 [Executor task launch worker for task 122] INFO [org.apache.spark.executor.Executor] - Running task 12.0 in stage 7.0 (TID 122)
2021-12-04 16:58:19,210 [Executor task launch worker for task 122] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-04 16:58:19,210 [Executor task launch worker for task 122] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 1 ms
2021-12-04 16:58:19,213 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 9.0 in stage 7.0 (TID 119) in 289 ms on localhost (executor driver) (1/21)
2021-12-04 16:58:19,215 [Executor task launch worker for task 115] INFO [org.apache.spark.executor.Executor] - Finished task 5.0 in stage 7.0 (TID 115). 1055 bytes result sent to driver
2021-12-04 16:58:19,217 [Executor task launch worker for task 118] INFO [org.apache.spark.executor.Executor] - Finished task 8.0 in stage 7.0 (TID 118). 1055 bytes result sent to driver
2021-12-04 16:58:19,217 [Executor task launch worker for task 113] INFO [org.apache.spark.executor.Executor] - Finished task 3.0 in stage 7.0 (TID 113). 1055 bytes result sent to driver
2021-12-04 16:58:19,217 [Executor task launch worker for task 114] INFO [org.apache.spark.executor.Executor] - Finished task 4.0 in stage 7.0 (TID 114). 1055 bytes result sent to driver
2021-12-04 16:58:19,217 [dispatcher-event-loop-7] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 13.0 in stage 7.0 (TID 123, localhost, executor driver, partition 13, ANY, 7649 bytes)
2021-12-04 16:58:19,217 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 5.0 in stage 7.0 (TID 115) in 294 ms on localhost (executor driver) (2/21)
2021-12-04 16:58:19,217 [Executor task launch worker for task 121] INFO [org.apache.spark.executor.Executor] - Finished task 11.0 in stage 7.0 (TID 121). 1055 bytes result sent to driver
2021-12-04 16:58:19,217 [Executor task launch worker for task 123] INFO [org.apache.spark.executor.Executor] - Running task 13.0 in stage 7.0 (TID 123)
2021-12-04 16:58:19,217 [dispatcher-event-loop-7] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 14.0 in stage 7.0 (TID 124, localhost, executor driver, partition 14, ANY, 7649 bytes)
2021-12-04 16:58:19,217 [dispatcher-event-loop-7] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 15.0 in stage 7.0 (TID 125, localhost, executor driver, partition 15, ANY, 7649 bytes)
2021-12-04 16:58:19,217 [Executor task launch worker for task 120] INFO [org.apache.spark.executor.Executor] - Finished task 10.0 in stage 7.0 (TID 120). 1055 bytes result sent to driver
2021-12-04 16:58:19,218 [dispatcher-event-loop-7] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 16.0 in stage 7.0 (TID 126, localhost, executor driver, partition 16, ANY, 7649 bytes)
2021-12-04 16:58:19,218 [Executor task launch worker for task 125] INFO [org.apache.spark.executor.Executor] - Running task 15.0 in stage 7.0 (TID 125)
2021-12-04 16:58:19,218 [Executor task launch worker for task 124] INFO [org.apache.spark.executor.Executor] - Running task 14.0 in stage 7.0 (TID 124)
2021-12-04 16:58:19,218 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 8.0 in stage 7.0 (TID 118) in 294 ms on localhost (executor driver) (3/21)
2021-12-04 16:58:19,218 [Executor task launch worker for task 126] INFO [org.apache.spark.executor.Executor] - Running task 16.0 in stage 7.0 (TID 126)
2021-12-04 16:58:19,219 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 3.0 in stage 7.0 (TID 113) in 296 ms on localhost (executor driver) (4/21)
2021-12-04 16:58:19,220 [dispatcher-event-loop-7] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 17.0 in stage 7.0 (TID 127, localhost, executor driver, partition 17, ANY, 7649 bytes)
2021-12-04 16:58:19,220 [Executor task launch worker for task 123] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-04 16:58:19,220 [dispatcher-event-loop-7] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 18.0 in stage 7.0 (TID 128, localhost, executor driver, partition 18, ANY, 7649 bytes)
2021-12-04 16:58:19,220 [Executor task launch worker for task 123] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-04 16:58:19,220 [Executor task launch worker for task 127] INFO [org.apache.spark.executor.Executor] - Running task 17.0 in stage 7.0 (TID 127)
2021-12-04 16:58:19,220 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 11.0 in stage 7.0 (TID 121) in 296 ms on localhost (executor driver) (5/21)
2021-12-04 16:58:19,220 [Executor task launch worker for task 125] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-04 16:58:19,220 [Executor task launch worker for task 125] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-04 16:58:19,220 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 4.0 in stage 7.0 (TID 114) in 297 ms on localhost (executor driver) (6/21)
2021-12-04 16:58:19,220 [Executor task launch worker for task 116] INFO [org.apache.spark.executor.Executor] - Finished task 6.0 in stage 7.0 (TID 116). 1055 bytes result sent to driver
2021-12-04 16:58:19,220 [Executor task launch worker for task 110] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 7.0 (TID 110). 1055 bytes result sent to driver
2021-12-04 16:58:19,220 [Executor task launch worker for task 128] INFO [org.apache.spark.executor.Executor] - Running task 18.0 in stage 7.0 (TID 128)
2021-12-04 16:58:19,220 [Executor task launch worker for task 126] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-04 16:58:19,220 [Executor task launch worker for task 126] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-04 16:58:19,220 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 10.0 in stage 7.0 (TID 120) in 296 ms on localhost (executor driver) (7/21)
2021-12-04 16:58:19,221 [dispatcher-event-loop-7] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 19.0 in stage 7.0 (TID 129, localhost, executor driver, partition 19, ANY, 7649 bytes)
2021-12-04 16:58:19,221 [Executor task launch worker for task 129] INFO [org.apache.spark.executor.Executor] - Running task 19.0 in stage 7.0 (TID 129)
2021-12-04 16:58:19,222 [dispatcher-event-loop-7] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 20.0 in stage 7.0 (TID 130, localhost, executor driver, partition 20, ANY, 7649 bytes)
2021-12-04 16:58:19,222 [Executor task launch worker for task 130] INFO [org.apache.spark.executor.Executor] - Running task 20.0 in stage 7.0 (TID 130)
2021-12-04 16:58:19,222 [Executor task launch worker for task 127] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-04 16:58:19,222 [Executor task launch worker for task 127] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-04 16:58:19,222 [Executor task launch worker for task 128] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-04 16:58:19,222 [Executor task launch worker for task 128] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-04 16:58:19,223 [Executor task launch worker for task 117] INFO [org.apache.spark.executor.Executor] - Finished task 7.0 in stage 7.0 (TID 117). 1055 bytes result sent to driver
2021-12-04 16:58:19,223 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 6.0 in stage 7.0 (TID 116) in 300 ms on localhost (executor driver) (8/21)
2021-12-04 16:58:19,223 [Executor task launch worker for task 124] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-04 16:58:19,223 [Executor task launch worker for task 124] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 2 ms
2021-12-04 16:58:19,224 [Executor task launch worker for task 130] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-04 16:58:19,224 [Executor task launch worker for task 130] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-04 16:58:19,224 [Executor task launch worker for task 129] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-04 16:58:19,224 [Executor task launch worker for task 129] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-04 16:58:19,224 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 7.0 in stage 7.0 (TID 117) in 300 ms on localhost (executor driver) (9/21)
2021-12-04 16:58:19,224 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 7.0 (TID 110) in 301 ms on localhost (executor driver) (10/21)
2021-12-04 16:58:19,239 [Executor task launch worker for task 112] INFO [org.apache.spark.executor.Executor] - Finished task 2.0 in stage 7.0 (TID 112). 1055 bytes result sent to driver
2021-12-04 16:58:19,239 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 2.0 in stage 7.0 (TID 112) in 316 ms on localhost (executor driver) (11/21)
2021-12-04 16:58:19,240 [Executor task launch worker for task 111] INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 7.0 (TID 111). 1055 bytes result sent to driver
2021-12-04 16:58:19,240 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 7.0 (TID 111) in 317 ms on localhost (executor driver) (12/21)
2021-12-04 16:58:19,287 [Executor task launch worker for task 124] INFO [org.apache.spark.executor.Executor] - Finished task 14.0 in stage 7.0 (TID 124). 1055 bytes result sent to driver
2021-12-04 16:58:19,287 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 14.0 in stage 7.0 (TID 124) in 70 ms on localhost (executor driver) (13/21)
2021-12-04 16:58:19,290 [Executor task launch worker for task 128] INFO [org.apache.spark.executor.Executor] - Finished task 18.0 in stage 7.0 (TID 128). 1055 bytes result sent to driver
2021-12-04 16:58:19,290 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 18.0 in stage 7.0 (TID 128) in 70 ms on localhost (executor driver) (14/21)
2021-12-04 16:58:19,293 [Executor task launch worker for task 126] INFO [org.apache.spark.executor.Executor] - Finished task 16.0 in stage 7.0 (TID 126). 1055 bytes result sent to driver
2021-12-04 16:58:19,293 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 16.0 in stage 7.0 (TID 126) in 75 ms on localhost (executor driver) (15/21)
2021-12-04 16:58:19,294 [Executor task launch worker for task 125] INFO [org.apache.spark.executor.Executor] - Finished task 15.0 in stage 7.0 (TID 125). 1055 bytes result sent to driver
2021-12-04 16:58:19,294 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 15.0 in stage 7.0 (TID 125) in 77 ms on localhost (executor driver) (16/21)
2021-12-04 16:58:19,294 [Executor task launch worker for task 130] INFO [org.apache.spark.executor.Executor] - Finished task 20.0 in stage 7.0 (TID 130). 1055 bytes result sent to driver
2021-12-04 16:58:19,294 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 20.0 in stage 7.0 (TID 130) in 73 ms on localhost (executor driver) (17/21)
2021-12-04 16:58:19,294 [Executor task launch worker for task 122] INFO [org.apache.spark.executor.Executor] - Finished task 12.0 in stage 7.0 (TID 122). 1055 bytes result sent to driver
2021-12-04 16:58:19,295 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 12.0 in stage 7.0 (TID 122) in 88 ms on localhost (executor driver) (18/21)
2021-12-04 16:58:19,298 [Executor task launch worker for task 129] INFO [org.apache.spark.executor.Executor] - Finished task 19.0 in stage 7.0 (TID 129). 1055 bytes result sent to driver
2021-12-04 16:58:19,298 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 19.0 in stage 7.0 (TID 129) in 77 ms on localhost (executor driver) (19/21)
2021-12-04 16:58:19,299 [Executor task launch worker for task 123] INFO [org.apache.spark.executor.Executor] - Finished task 13.0 in stage 7.0 (TID 123). 1055 bytes result sent to driver
2021-12-04 16:58:19,299 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 13.0 in stage 7.0 (TID 123) in 82 ms on localhost (executor driver) (20/21)
2021-12-04 16:58:19,310 [Executor task launch worker for task 127] INFO [org.apache.spark.executor.Executor] - Finished task 17.0 in stage 7.0 (TID 127). 1055 bytes result sent to driver
2021-12-04 16:58:19,310 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 17.0 in stage 7.0 (TID 127) in 91 ms on localhost (executor driver) (21/21)
2021-12-04 16:58:19,310 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 7.0, whose tasks have all completed, from pool 
2021-12-04 16:58:19,311 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 7 (zipWithIndex at PaidPromotionAdjustParameter.scala:74) finished in 0.392 s
2021-12-04 16:58:19,311 [main] INFO [org.apache.spark.scheduler.DAGScheduler] - Job 3 finished: zipWithIndex at PaidPromotionAdjustParameter.scala:74, took 1.439424 s
2021-12-04 16:58:19,322 [main] INFO [org.apache.spark.SparkContext] - Starting job: takeSample at PaidPromotionAdjustParameter.scala:77
2021-12-04 16:58:19,323 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 4 (takeSample at PaidPromotionAdjustParameter.scala:77) with 22 output partitions
2021-12-04 16:58:19,323 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 10 (takeSample at PaidPromotionAdjustParameter.scala:77)
2021-12-04 16:58:19,323 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 9)
2021-12-04 16:58:19,323 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2021-12-04 16:58:19,323 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 10 (MapPartitionsRDD[11] at map at PaidPromotionAdjustParameter.scala:76), which has no missing parents
2021-12-04 16:58:19,327 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_7 stored as values in memory (estimated size 4.2 KB, free 1990.4 MB)
2021-12-04 16:58:19,329 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_7_piece0 stored as bytes in memory (estimated size 2.4 KB, free 1990.4 MB)
2021-12-04 16:58:19,330 [dispatcher-event-loop-8] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_7_piece0 in memory on qb:49432 (size: 2.4 KB, free: 1990.8 MB)
2021-12-04 16:58:19,330 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 7 from broadcast at DAGScheduler.scala:1039
2021-12-04 16:58:19,330 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 22 missing tasks from ResultStage 10 (MapPartitionsRDD[11] at map at PaidPromotionAdjustParameter.scala:76) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14))
2021-12-04 16:58:19,330 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 10.0 with 22 tasks
2021-12-04 16:58:19,331 [dispatcher-event-loop-4] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 10.0 (TID 131, localhost, executor driver, partition 0, ANY, 7759 bytes)
2021-12-04 16:58:19,331 [dispatcher-event-loop-4] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 10.0 (TID 132, localhost, executor driver, partition 1, ANY, 7759 bytes)
2021-12-04 16:58:19,331 [dispatcher-event-loop-4] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 2.0 in stage 10.0 (TID 133, localhost, executor driver, partition 2, ANY, 7759 bytes)
2021-12-04 16:58:19,331 [dispatcher-event-loop-4] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 3.0 in stage 10.0 (TID 134, localhost, executor driver, partition 3, ANY, 7759 bytes)
2021-12-04 16:58:19,332 [dispatcher-event-loop-4] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 4.0 in stage 10.0 (TID 135, localhost, executor driver, partition 4, ANY, 7759 bytes)
2021-12-04 16:58:19,332 [dispatcher-event-loop-4] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 5.0 in stage 10.0 (TID 136, localhost, executor driver, partition 5, ANY, 7759 bytes)
2021-12-04 16:58:19,332 [dispatcher-event-loop-4] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 6.0 in stage 10.0 (TID 137, localhost, executor driver, partition 6, ANY, 7759 bytes)
2021-12-04 16:58:19,332 [dispatcher-event-loop-4] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 7.0 in stage 10.0 (TID 138, localhost, executor driver, partition 7, ANY, 7759 bytes)
2021-12-04 16:58:19,332 [dispatcher-event-loop-4] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 8.0 in stage 10.0 (TID 139, localhost, executor driver, partition 8, ANY, 7759 bytes)
2021-12-04 16:58:19,332 [dispatcher-event-loop-4] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 9.0 in stage 10.0 (TID 140, localhost, executor driver, partition 9, ANY, 7759 bytes)
2021-12-04 16:58:19,332 [dispatcher-event-loop-4] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 10.0 in stage 10.0 (TID 141, localhost, executor driver, partition 10, ANY, 7759 bytes)
2021-12-04 16:58:19,332 [dispatcher-event-loop-4] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 11.0 in stage 10.0 (TID 142, localhost, executor driver, partition 11, ANY, 7759 bytes)
2021-12-04 16:58:19,332 [Executor task launch worker for task 134] INFO [org.apache.spark.executor.Executor] - Running task 3.0 in stage 10.0 (TID 134)
2021-12-04 16:58:19,332 [Executor task launch worker for task 131] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 10.0 (TID 131)
2021-12-04 16:58:19,332 [Executor task launch worker for task 142] INFO [org.apache.spark.executor.Executor] - Running task 11.0 in stage 10.0 (TID 142)
2021-12-04 16:58:19,332 [Executor task launch worker for task 141] INFO [org.apache.spark.executor.Executor] - Running task 10.0 in stage 10.0 (TID 141)
2021-12-04 16:58:19,332 [Executor task launch worker for task 138] INFO [org.apache.spark.executor.Executor] - Running task 7.0 in stage 10.0 (TID 138)
2021-12-04 16:58:19,332 [Executor task launch worker for task 137] INFO [org.apache.spark.executor.Executor] - Running task 6.0 in stage 10.0 (TID 137)
2021-12-04 16:58:19,332 [Executor task launch worker for task 139] INFO [org.apache.spark.executor.Executor] - Running task 8.0 in stage 10.0 (TID 139)
2021-12-04 16:58:19,332 [Executor task launch worker for task 140] INFO [org.apache.spark.executor.Executor] - Running task 9.0 in stage 10.0 (TID 140)
2021-12-04 16:58:19,332 [Executor task launch worker for task 136] INFO [org.apache.spark.executor.Executor] - Running task 5.0 in stage 10.0 (TID 136)
2021-12-04 16:58:19,332 [Executor task launch worker for task 133] INFO [org.apache.spark.executor.Executor] - Running task 2.0 in stage 10.0 (TID 133)
2021-12-04 16:58:19,332 [Executor task launch worker for task 135] INFO [org.apache.spark.executor.Executor] - Running task 4.0 in stage 10.0 (TID 135)
2021-12-04 16:58:19,336 [Executor task launch worker for task 132] INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 10.0 (TID 132)
2021-12-04 16:58:19,336 [Executor task launch worker for task 137] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-04 16:58:19,336 [Executor task launch worker for task 131] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-04 16:58:19,336 [Executor task launch worker for task 138] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-04 16:58:19,336 [Executor task launch worker for task 136] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-04 16:58:19,336 [Executor task launch worker for task 142] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-04 16:58:19,336 [Executor task launch worker for task 137] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-04 16:58:19,337 [Executor task launch worker for task 142] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 1 ms
2021-12-04 16:58:19,336 [Executor task launch worker for task 136] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-04 16:58:19,336 [Executor task launch worker for task 138] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-04 16:58:19,336 [Executor task launch worker for task 131] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-04 16:58:19,337 [Executor task launch worker for task 134] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-04 16:58:19,337 [Executor task launch worker for task 134] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-04 16:58:19,337 [Executor task launch worker for task 140] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-04 16:58:19,337 [Executor task launch worker for task 140] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-04 16:58:19,337 [Executor task launch worker for task 139] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-04 16:58:19,337 [Executor task launch worker for task 139] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-04 16:58:19,338 [Executor task launch worker for task 141] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-04 16:58:19,338 [Executor task launch worker for task 141] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-04 16:58:19,338 [Executor task launch worker for task 135] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-04 16:58:19,338 [Executor task launch worker for task 135] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-04 16:58:19,338 [Executor task launch worker for task 133] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-04 16:58:19,338 [Executor task launch worker for task 133] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-04 16:58:19,339 [Executor task launch worker for task 132] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-04 16:58:19,339 [Executor task launch worker for task 132] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-04 16:58:19,362 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 130
2021-12-04 16:58:19,362 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 120
2021-12-04 16:58:19,362 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 123
2021-12-04 16:58:19,363 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 116
2021-12-04 16:58:19,363 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 122
2021-12-04 16:58:19,363 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 103
2021-12-04 16:58:19,363 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 110
2021-12-04 16:58:19,363 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 119
2021-12-04 16:58:19,363 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 100
2021-12-04 16:58:19,363 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 141
2021-12-04 16:58:19,363 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 113
2021-12-04 16:58:19,363 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 142
2021-12-04 16:58:19,363 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 138
2021-12-04 16:58:19,364 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 104
2021-12-04 16:58:19,364 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 102
2021-12-04 16:58:19,364 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 107
2021-12-04 16:58:19,364 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 132
2021-12-04 16:58:19,364 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 106
2021-12-04 16:58:19,364 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 108
2021-12-04 16:58:19,364 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 117
2021-12-04 16:58:19,364 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 145
2021-12-04 16:58:19,364 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 140
2021-12-04 16:58:19,364 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 148
2021-12-04 16:58:19,364 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 125
2021-12-04 16:58:19,364 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 126
2021-12-04 16:58:19,364 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 105
2021-12-04 16:58:19,364 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 134
2021-12-04 16:58:19,368 [dispatcher-event-loop-9] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_6_piece0 on qb:49432 in memory (size: 2.0 KB, free: 1990.8 MB)
2021-12-04 16:58:19,394 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 114
2021-12-04 16:58:19,394 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 129
2021-12-04 16:58:19,394 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 139
2021-12-04 16:58:19,394 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 144
2021-12-04 16:58:19,394 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 131
2021-12-04 16:58:19,394 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 115
2021-12-04 16:58:19,394 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 136
2021-12-04 16:58:19,394 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 149
2021-12-04 16:58:19,394 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 135
2021-12-04 16:58:19,394 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 101
2021-12-04 16:58:19,394 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 109
2021-12-04 16:58:19,394 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 133
2021-12-04 16:58:19,394 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 111
2021-12-04 16:58:19,394 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 124
2021-12-04 16:58:19,394 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 128
2021-12-04 16:58:19,394 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 118
2021-12-04 16:58:19,394 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 127
2021-12-04 16:58:19,394 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 143
2021-12-04 16:58:19,394 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 147
2021-12-04 16:58:19,394 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 137
2021-12-04 16:58:19,394 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 146
2021-12-04 16:58:19,394 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 112
2021-12-04 16:58:19,394 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 121
2021-12-04 16:58:19,395 [dispatcher-event-loop-1] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_5_piece0 on qb:49432 in memory (size: 2.4 KB, free: 1990.8 MB)
2021-12-04 16:58:19,446 [Executor task launch worker for task 140] INFO [org.apache.spark.executor.Executor] - Finished task 9.0 in stage 10.0 (TID 140). 1098 bytes result sent to driver
2021-12-04 16:58:19,446 [dispatcher-event-loop-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 12.0 in stage 10.0 (TID 143, localhost, executor driver, partition 12, ANY, 7759 bytes)
2021-12-04 16:58:19,446 [Executor task launch worker for task 143] INFO [org.apache.spark.executor.Executor] - Running task 12.0 in stage 10.0 (TID 143)
2021-12-04 16:58:19,446 [Executor task launch worker for task 136] INFO [org.apache.spark.executor.Executor] - Finished task 5.0 in stage 10.0 (TID 136). 1098 bytes result sent to driver
2021-12-04 16:58:19,448 [Executor task launch worker for task 142] INFO [org.apache.spark.executor.Executor] - Finished task 11.0 in stage 10.0 (TID 142). 1098 bytes result sent to driver
2021-12-04 16:58:19,450 [Executor task launch worker for task 143] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-04 16:58:19,450 [Executor task launch worker for task 143] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-04 16:58:19,453 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 9.0 in stage 10.0 (TID 140) in 121 ms on localhost (executor driver) (1/22)
2021-12-04 16:58:19,454 [dispatcher-event-loop-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 13.0 in stage 10.0 (TID 144, localhost, executor driver, partition 13, ANY, 7759 bytes)
2021-12-04 16:58:19,454 [Executor task launch worker for task 144] INFO [org.apache.spark.executor.Executor] - Running task 13.0 in stage 10.0 (TID 144)
2021-12-04 16:58:19,454 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 5.0 in stage 10.0 (TID 136) in 122 ms on localhost (executor driver) (2/22)
2021-12-04 16:58:19,454 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 11.0 in stage 10.0 (TID 142) in 122 ms on localhost (executor driver) (3/22)
2021-12-04 16:58:19,456 [dispatcher-event-loop-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 14.0 in stage 10.0 (TID 145, localhost, executor driver, partition 14, ANY, 7759 bytes)
2021-12-04 16:58:19,456 [Executor task launch worker for task 145] INFO [org.apache.spark.executor.Executor] - Running task 14.0 in stage 10.0 (TID 145)
2021-12-04 16:58:19,457 [Executor task launch worker for task 144] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-04 16:58:19,457 [Executor task launch worker for task 144] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-04 16:58:19,459 [Executor task launch worker for task 145] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-04 16:58:19,459 [Executor task launch worker for task 145] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-04 16:58:19,470 [Executor task launch worker for task 137] INFO [org.apache.spark.executor.Executor] - Finished task 6.0 in stage 10.0 (TID 137). 1098 bytes result sent to driver
2021-12-04 16:58:19,471 [dispatcher-event-loop-11] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 15.0 in stage 10.0 (TID 146, localhost, executor driver, partition 15, ANY, 7759 bytes)
2021-12-04 16:58:19,471 [Executor task launch worker for task 146] INFO [org.apache.spark.executor.Executor] - Running task 15.0 in stage 10.0 (TID 146)
2021-12-04 16:58:19,473 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 6.0 in stage 10.0 (TID 137) in 141 ms on localhost (executor driver) (4/22)
2021-12-04 16:58:19,473 [Executor task launch worker for task 134] INFO [org.apache.spark.executor.Executor] - Finished task 3.0 in stage 10.0 (TID 134). 1098 bytes result sent to driver
2021-12-04 16:58:19,473 [Executor task launch worker for task 146] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-04 16:58:19,473 [Executor task launch worker for task 146] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-04 16:58:19,473 [dispatcher-event-loop-9] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 16.0 in stage 10.0 (TID 147, localhost, executor driver, partition 16, ANY, 7759 bytes)
2021-12-04 16:58:19,473 [Executor task launch worker for task 147] INFO [org.apache.spark.executor.Executor] - Running task 16.0 in stage 10.0 (TID 147)
2021-12-04 16:58:19,474 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 3.0 in stage 10.0 (TID 134) in 143 ms on localhost (executor driver) (5/22)
2021-12-04 16:58:19,475 [Executor task launch worker for task 135] INFO [org.apache.spark.executor.Executor] - Finished task 4.0 in stage 10.0 (TID 135). 1098 bytes result sent to driver
2021-12-04 16:58:19,476 [dispatcher-event-loop-6] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 17.0 in stage 10.0 (TID 148, localhost, executor driver, partition 17, ANY, 7759 bytes)
2021-12-04 16:58:19,476 [Executor task launch worker for task 148] INFO [org.apache.spark.executor.Executor] - Running task 17.0 in stage 10.0 (TID 148)
2021-12-04 16:58:19,476 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 4.0 in stage 10.0 (TID 135) in 144 ms on localhost (executor driver) (6/22)
2021-12-04 16:58:19,476 [Executor task launch worker for task 147] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-04 16:58:19,476 [Executor task launch worker for task 147] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-04 16:58:19,478 [Executor task launch worker for task 148] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-04 16:58:19,478 [Executor task launch worker for task 148] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-04 16:58:19,481 [Executor task launch worker for task 138] INFO [org.apache.spark.executor.Executor] - Finished task 7.0 in stage 10.0 (TID 138). 1098 bytes result sent to driver
2021-12-04 16:58:19,482 [dispatcher-event-loop-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 18.0 in stage 10.0 (TID 149, localhost, executor driver, partition 18, ANY, 7759 bytes)
2021-12-04 16:58:19,482 [Executor task launch worker for task 149] INFO [org.apache.spark.executor.Executor] - Running task 18.0 in stage 10.0 (TID 149)
2021-12-04 16:58:19,482 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 7.0 in stage 10.0 (TID 138) in 150 ms on localhost (executor driver) (7/22)
2021-12-04 16:58:19,482 [Executor task launch worker for task 139] INFO [org.apache.spark.executor.Executor] - Finished task 8.0 in stage 10.0 (TID 139). 1098 bytes result sent to driver
2021-12-04 16:58:19,483 [dispatcher-event-loop-8] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 19.0 in stage 10.0 (TID 150, localhost, executor driver, partition 19, ANY, 7759 bytes)
2021-12-04 16:58:19,483 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 8.0 in stage 10.0 (TID 139) in 151 ms on localhost (executor driver) (8/22)
2021-12-04 16:58:19,483 [Executor task launch worker for task 150] INFO [org.apache.spark.executor.Executor] - Running task 19.0 in stage 10.0 (TID 150)
2021-12-04 16:58:19,484 [Executor task launch worker for task 149] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-04 16:58:19,485 [Executor task launch worker for task 149] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 1 ms
2021-12-04 16:58:19,485 [Executor task launch worker for task 131] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 10.0 (TID 131). 1096 bytes result sent to driver
2021-12-04 16:58:19,485 [Executor task launch worker for task 133] INFO [org.apache.spark.executor.Executor] - Finished task 2.0 in stage 10.0 (TID 133). 1098 bytes result sent to driver
2021-12-04 16:58:19,485 [dispatcher-event-loop-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 20.0 in stage 10.0 (TID 151, localhost, executor driver, partition 20, ANY, 7759 bytes)
2021-12-04 16:58:19,485 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 10.0 (TID 131) in 154 ms on localhost (executor driver) (9/22)
2021-12-04 16:58:19,485 [Executor task launch worker for task 151] INFO [org.apache.spark.executor.Executor] - Running task 20.0 in stage 10.0 (TID 151)
2021-12-04 16:58:19,486 [dispatcher-event-loop-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 21.0 in stage 10.0 (TID 152, localhost, executor driver, partition 21, ANY, 7759 bytes)
2021-12-04 16:58:19,486 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 2.0 in stage 10.0 (TID 133) in 155 ms on localhost (executor driver) (10/22)
2021-12-04 16:58:19,486 [Executor task launch worker for task 152] INFO [org.apache.spark.executor.Executor] - Running task 21.0 in stage 10.0 (TID 152)
2021-12-04 16:58:19,486 [Executor task launch worker for task 150] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-04 16:58:19,486 [Executor task launch worker for task 150] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-04 16:58:19,488 [Executor task launch worker for task 152] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-04 16:58:19,488 [Executor task launch worker for task 152] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-04 16:58:19,489 [Executor task launch worker for task 151] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-04 16:58:19,489 [Executor task launch worker for task 151] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-04 16:58:19,497 [Executor task launch worker for task 141] INFO [org.apache.spark.executor.Executor] - Finished task 10.0 in stage 10.0 (TID 141). 1098 bytes result sent to driver
2021-12-04 16:58:19,498 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 10.0 in stage 10.0 (TID 141) in 166 ms on localhost (executor driver) (11/22)
2021-12-04 16:58:19,507 [Executor task launch worker for task 132] INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 10.0 (TID 132). 1096 bytes result sent to driver
2021-12-04 16:58:19,507 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 10.0 (TID 132) in 176 ms on localhost (executor driver) (12/22)
2021-12-04 16:58:19,546 [Executor task launch worker for task 145] INFO [org.apache.spark.executor.Executor] - Finished task 14.0 in stage 10.0 (TID 145). 1055 bytes result sent to driver
2021-12-04 16:58:19,547 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 14.0 in stage 10.0 (TID 145) in 91 ms on localhost (executor driver) (13/22)
2021-12-04 16:58:19,553 [Executor task launch worker for task 147] INFO [org.apache.spark.executor.Executor] - Finished task 16.0 in stage 10.0 (TID 147). 1055 bytes result sent to driver
2021-12-04 16:58:19,553 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 16.0 in stage 10.0 (TID 147) in 80 ms on localhost (executor driver) (14/22)
2021-12-04 16:58:19,557 [Executor task launch worker for task 143] INFO [org.apache.spark.executor.Executor] - Finished task 12.0 in stage 10.0 (TID 143). 1055 bytes result sent to driver
2021-12-04 16:58:19,558 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 12.0 in stage 10.0 (TID 143) in 112 ms on localhost (executor driver) (15/22)
2021-12-04 16:58:19,562 [Executor task launch worker for task 144] INFO [org.apache.spark.executor.Executor] - Finished task 13.0 in stage 10.0 (TID 144). 1055 bytes result sent to driver
2021-12-04 16:58:19,562 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 13.0 in stage 10.0 (TID 144) in 109 ms on localhost (executor driver) (16/22)
2021-12-04 16:58:19,565 [Executor task launch worker for task 146] INFO [org.apache.spark.executor.Executor] - Finished task 15.0 in stage 10.0 (TID 146). 1098 bytes result sent to driver
2021-12-04 16:58:19,565 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 15.0 in stage 10.0 (TID 146) in 94 ms on localhost (executor driver) (17/22)
2021-12-04 16:58:19,571 [Executor task launch worker for task 149] INFO [org.apache.spark.executor.Executor] - Finished task 18.0 in stage 10.0 (TID 149). 1055 bytes result sent to driver
2021-12-04 16:58:19,571 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 18.0 in stage 10.0 (TID 149) in 90 ms on localhost (executor driver) (18/22)
2021-12-04 16:58:19,578 [Executor task launch worker for task 150] INFO [org.apache.spark.executor.Executor] - Finished task 19.0 in stage 10.0 (TID 150). 1055 bytes result sent to driver
2021-12-04 16:58:19,578 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 19.0 in stage 10.0 (TID 150) in 95 ms on localhost (executor driver) (19/22)
2021-12-04 16:58:19,580 [Executor task launch worker for task 152] INFO [org.apache.spark.executor.Executor] - Finished task 21.0 in stage 10.0 (TID 152). 1053 bytes result sent to driver
2021-12-04 16:58:19,580 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 21.0 in stage 10.0 (TID 152) in 94 ms on localhost (executor driver) (20/22)
2021-12-04 16:58:19,580 [Executor task launch worker for task 151] INFO [org.apache.spark.executor.Executor] - Finished task 20.0 in stage 10.0 (TID 151). 1053 bytes result sent to driver
2021-12-04 16:58:19,580 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 20.0 in stage 10.0 (TID 151) in 95 ms on localhost (executor driver) (21/22)
2021-12-04 16:58:19,581 [Executor task launch worker for task 148] INFO [org.apache.spark.executor.Executor] - Finished task 17.0 in stage 10.0 (TID 148). 1055 bytes result sent to driver
2021-12-04 16:58:19,581 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 17.0 in stage 10.0 (TID 148) in 106 ms on localhost (executor driver) (22/22)
2021-12-04 16:58:19,581 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 10.0, whose tasks have all completed, from pool 
2021-12-04 16:58:19,581 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 10 (takeSample at PaidPromotionAdjustParameter.scala:77) finished in 0.257 s
2021-12-04 16:58:19,581 [main] INFO [org.apache.spark.scheduler.DAGScheduler] - Job 4 finished: takeSample at PaidPromotionAdjustParameter.scala:77, took 0.259434 s
2021-12-04 16:58:19,595 [main] INFO [org.apache.spark.SparkContext] - Starting job: takeSample at PaidPromotionAdjustParameter.scala:77
2021-12-04 16:58:19,595 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 5 (takeSample at PaidPromotionAdjustParameter.scala:77) with 22 output partitions
2021-12-04 16:58:19,595 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 13 (takeSample at PaidPromotionAdjustParameter.scala:77)
2021-12-04 16:58:19,595 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 12)
2021-12-04 16:58:19,595 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2021-12-04 16:58:19,595 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 13 (PartitionwiseSampledRDD[12] at takeSample at PaidPromotionAdjustParameter.scala:77), which has no missing parents
2021-12-04 16:58:19,598 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_8 stored as values in memory (estimated size 4.9 KB, free 1990.4 MB)
2021-12-04 16:58:19,599 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_8_piece0 stored as bytes in memory (estimated size 2.8 KB, free 1990.4 MB)
2021-12-04 16:58:19,599 [dispatcher-event-loop-9] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_8_piece0 in memory on qb:49432 (size: 2.8 KB, free: 1990.8 MB)
2021-12-04 16:58:19,600 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 8 from broadcast at DAGScheduler.scala:1039
2021-12-04 16:58:19,600 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 22 missing tasks from ResultStage 13 (PartitionwiseSampledRDD[12] at takeSample at PaidPromotionAdjustParameter.scala:77) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14))
2021-12-04 16:58:19,600 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 13.0 with 22 tasks
2021-12-04 16:58:19,601 [dispatcher-event-loop-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 13.0 (TID 153, localhost, executor driver, partition 0, ANY, 7868 bytes)
2021-12-04 16:58:19,601 [dispatcher-event-loop-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 13.0 (TID 154, localhost, executor driver, partition 1, ANY, 7868 bytes)
2021-12-04 16:58:19,601 [dispatcher-event-loop-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 2.0 in stage 13.0 (TID 155, localhost, executor driver, partition 2, ANY, 7868 bytes)
2021-12-04 16:58:19,601 [dispatcher-event-loop-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 3.0 in stage 13.0 (TID 156, localhost, executor driver, partition 3, ANY, 7868 bytes)
2021-12-04 16:58:19,601 [dispatcher-event-loop-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 4.0 in stage 13.0 (TID 157, localhost, executor driver, partition 4, ANY, 7868 bytes)
2021-12-04 16:58:19,601 [dispatcher-event-loop-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 5.0 in stage 13.0 (TID 158, localhost, executor driver, partition 5, ANY, 7868 bytes)
2021-12-04 16:58:19,601 [dispatcher-event-loop-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 6.0 in stage 13.0 (TID 159, localhost, executor driver, partition 6, ANY, 7868 bytes)
2021-12-04 16:58:19,601 [dispatcher-event-loop-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 7.0 in stage 13.0 (TID 160, localhost, executor driver, partition 7, ANY, 7868 bytes)
2021-12-04 16:58:19,601 [dispatcher-event-loop-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 8.0 in stage 13.0 (TID 161, localhost, executor driver, partition 8, ANY, 7868 bytes)
2021-12-04 16:58:19,601 [dispatcher-event-loop-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 9.0 in stage 13.0 (TID 162, localhost, executor driver, partition 9, ANY, 7868 bytes)
2021-12-04 16:58:19,601 [dispatcher-event-loop-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 10.0 in stage 13.0 (TID 163, localhost, executor driver, partition 10, ANY, 7868 bytes)
2021-12-04 16:58:19,602 [dispatcher-event-loop-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 11.0 in stage 13.0 (TID 164, localhost, executor driver, partition 11, ANY, 7868 bytes)
2021-12-04 16:58:19,602 [Executor task launch worker for task 154] INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 13.0 (TID 154)
2021-12-04 16:58:19,602 [Executor task launch worker for task 153] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 13.0 (TID 153)
2021-12-04 16:58:19,602 [Executor task launch worker for task 163] INFO [org.apache.spark.executor.Executor] - Running task 10.0 in stage 13.0 (TID 163)
2021-12-04 16:58:19,602 [Executor task launch worker for task 160] INFO [org.apache.spark.executor.Executor] - Running task 7.0 in stage 13.0 (TID 160)
2021-12-04 16:58:19,602 [Executor task launch worker for task 158] INFO [org.apache.spark.executor.Executor] - Running task 5.0 in stage 13.0 (TID 158)
2021-12-04 16:58:19,602 [Executor task launch worker for task 155] INFO [org.apache.spark.executor.Executor] - Running task 2.0 in stage 13.0 (TID 155)
2021-12-04 16:58:19,602 [Executor task launch worker for task 157] INFO [org.apache.spark.executor.Executor] - Running task 4.0 in stage 13.0 (TID 157)
2021-12-04 16:58:19,602 [Executor task launch worker for task 159] INFO [org.apache.spark.executor.Executor] - Running task 6.0 in stage 13.0 (TID 159)
2021-12-04 16:58:19,602 [Executor task launch worker for task 156] INFO [org.apache.spark.executor.Executor] - Running task 3.0 in stage 13.0 (TID 156)
2021-12-04 16:58:19,602 [Executor task launch worker for task 162] INFO [org.apache.spark.executor.Executor] - Running task 9.0 in stage 13.0 (TID 162)
2021-12-04 16:58:19,602 [Executor task launch worker for task 164] INFO [org.apache.spark.executor.Executor] - Running task 11.0 in stage 13.0 (TID 164)
2021-12-04 16:58:19,602 [Executor task launch worker for task 161] INFO [org.apache.spark.executor.Executor] - Running task 8.0 in stage 13.0 (TID 161)
2021-12-04 16:58:19,605 [Executor task launch worker for task 162] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-04 16:58:19,605 [Executor task launch worker for task 159] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-04 16:58:19,605 [Executor task launch worker for task 162] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-04 16:58:19,605 [Executor task launch worker for task 159] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-04 16:58:19,605 [Executor task launch worker for task 164] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-04 16:58:19,605 [Executor task launch worker for task 164] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-04 16:58:19,605 [Executor task launch worker for task 161] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-04 16:58:19,605 [Executor task launch worker for task 161] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-04 16:58:19,606 [Executor task launch worker for task 155] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-04 16:58:19,606 [Executor task launch worker for task 155] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-04 16:58:19,606 [Executor task launch worker for task 156] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-04 16:58:19,606 [Executor task launch worker for task 156] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-04 16:58:19,606 [Executor task launch worker for task 163] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-04 16:58:19,606 [Executor task launch worker for task 163] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-04 16:58:19,606 [Executor task launch worker for task 153] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-04 16:58:19,606 [Executor task launch worker for task 153] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-04 16:58:19,607 [Executor task launch worker for task 157] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-04 16:58:19,607 [Executor task launch worker for task 157] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-04 16:58:19,607 [Executor task launch worker for task 160] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-04 16:58:19,607 [Executor task launch worker for task 160] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-04 16:58:19,608 [Executor task launch worker for task 154] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-04 16:58:19,608 [Executor task launch worker for task 154] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-04 16:58:19,608 [Executor task launch worker for task 158] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-04 16:58:19,608 [Executor task launch worker for task 158] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-04 16:58:19,656 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 163
2021-12-04 16:58:19,656 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 153
2021-12-04 16:58:19,656 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 155
2021-12-04 16:58:19,656 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 159
2021-12-04 16:58:19,656 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 172
2021-12-04 16:58:19,657 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 157
2021-12-04 16:58:19,665 [dispatcher-event-loop-0] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_7_piece0 on qb:49432 in memory (size: 2.4 KB, free: 1990.8 MB)
2021-12-04 16:58:19,669 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 150
2021-12-04 16:58:19,669 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 151
2021-12-04 16:58:19,669 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 162
2021-12-04 16:58:19,669 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 156
2021-12-04 16:58:19,669 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 154
2021-12-04 16:58:19,669 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 158
2021-12-04 16:58:19,669 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 168
2021-12-04 16:58:19,669 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 174
2021-12-04 16:58:19,669 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 166
2021-12-04 16:58:19,669 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 173
2021-12-04 16:58:19,669 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 160
2021-12-04 16:58:19,669 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 169
2021-12-04 16:58:19,669 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 171
2021-12-04 16:58:19,669 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 165
2021-12-04 16:58:19,669 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 152
2021-12-04 16:58:19,669 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 167
2021-12-04 16:58:19,669 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 164
2021-12-04 16:58:19,669 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 161
2021-12-04 16:58:19,669 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 170
2021-12-04 16:58:19,720 [Executor task launch worker for task 153] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 13.0 (TID 153). 1097 bytes result sent to driver
2021-12-04 16:58:19,720 [dispatcher-event-loop-7] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 12.0 in stage 13.0 (TID 165, localhost, executor driver, partition 12, ANY, 7868 bytes)
2021-12-04 16:58:19,721 [Executor task launch worker for task 165] INFO [org.apache.spark.executor.Executor] - Running task 12.0 in stage 13.0 (TID 165)
2021-12-04 16:58:19,724 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 13.0 (TID 153) in 124 ms on localhost (executor driver) (1/22)
2021-12-04 16:58:19,730 [Executor task launch worker for task 165] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-04 16:58:19,731 [Executor task launch worker for task 165] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 1 ms
2021-12-04 16:58:19,732 [Executor task launch worker for task 154] INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 13.0 (TID 154). 1097 bytes result sent to driver
2021-12-04 16:58:19,732 [dispatcher-event-loop-10] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 13.0 in stage 13.0 (TID 166, localhost, executor driver, partition 13, ANY, 7868 bytes)
2021-12-04 16:58:19,732 [Executor task launch worker for task 166] INFO [org.apache.spark.executor.Executor] - Running task 13.0 in stage 13.0 (TID 166)
2021-12-04 16:58:19,732 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 13.0 (TID 154) in 131 ms on localhost (executor driver) (2/22)
2021-12-04 16:58:19,735 [Executor task launch worker for task 166] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-04 16:58:19,735 [Executor task launch worker for task 166] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-04 16:58:19,754 [Executor task launch worker for task 162] INFO [org.apache.spark.executor.Executor] - Finished task 9.0 in stage 13.0 (TID 162). 825195 bytes result sent to driver
2021-12-04 16:58:19,754 [Executor task launch worker for task 164] INFO [org.apache.spark.executor.Executor] - Finished task 11.0 in stage 13.0 (TID 164). 842473 bytes result sent to driver
2021-12-04 16:58:19,754 [dispatcher-event-loop-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 14.0 in stage 13.0 (TID 167, localhost, executor driver, partition 14, ANY, 7868 bytes)
2021-12-04 16:58:19,754 [Executor task launch worker for task 167] INFO [org.apache.spark.executor.Executor] - Running task 14.0 in stage 13.0 (TID 167)
2021-12-04 16:58:19,755 [dispatcher-event-loop-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 15.0 in stage 13.0 (TID 168, localhost, executor driver, partition 15, ANY, 7868 bytes)
2021-12-04 16:58:19,755 [Executor task launch worker for task 168] INFO [org.apache.spark.executor.Executor] - Running task 15.0 in stage 13.0 (TID 168)
2021-12-04 16:58:19,759 [Executor task launch worker for task 167] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-04 16:58:19,759 [Executor task launch worker for task 167] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-04 16:58:19,760 [Executor task launch worker for task 161] INFO [org.apache.spark.executor.Executor] - Finished task 8.0 in stage 13.0 (TID 161). 1029767 bytes result sent to driver
2021-12-04 16:58:19,762 [Executor task launch worker for task 155] INFO [org.apache.spark.executor.Executor] - Finished task 2.0 in stage 13.0 (TID 155). 611206 bytes result sent to driver
2021-12-04 16:58:19,762 [Executor task launch worker for task 168] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-04 16:58:19,762 [Executor task launch worker for task 168] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-04 16:58:19,764 [dispatcher-event-loop-9] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 16.0 in stage 13.0 (TID 169, localhost, executor driver, partition 16, ANY, 7868 bytes)
2021-12-04 16:58:19,764 [Executor task launch worker for task 156] INFO [org.apache.spark.executor.Executor] - Finished task 3.0 in stage 13.0 (TID 156). 994317 bytes result sent to driver
2021-12-04 16:58:19,764 [dispatcher-event-loop-9] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 17.0 in stage 13.0 (TID 170, localhost, executor driver, partition 17, ANY, 7868 bytes)
2021-12-04 16:58:19,764 [Executor task launch worker for task 169] INFO [org.apache.spark.executor.Executor] - Running task 16.0 in stage 13.0 (TID 169)
2021-12-04 16:58:19,765 [dispatcher-event-loop-9] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 18.0 in stage 13.0 (TID 171, localhost, executor driver, partition 18, ANY, 7868 bytes)
2021-12-04 16:58:19,765 [Executor task launch worker for task 171] INFO [org.apache.spark.executor.Executor] - Running task 18.0 in stage 13.0 (TID 171)
2021-12-04 16:58:19,765 [Executor task launch worker for task 170] INFO [org.apache.spark.executor.Executor] - Running task 17.0 in stage 13.0 (TID 170)
2021-12-04 16:58:19,768 [Executor task launch worker for task 170] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-04 16:58:19,768 [Executor task launch worker for task 170] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-04 16:58:19,769 [Executor task launch worker for task 171] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-04 16:58:19,769 [Executor task launch worker for task 171] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-04 16:58:19,771 [Executor task launch worker for task 159] INFO [org.apache.spark.executor.Executor] - Finished task 6.0 in stage 13.0 (TID 159). 1032054 bytes result sent to driver
2021-12-04 16:58:19,772 [dispatcher-event-loop-10] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 19.0 in stage 13.0 (TID 172, localhost, executor driver, partition 19, ANY, 7868 bytes)
2021-12-04 16:58:19,773 [Executor task launch worker for task 172] INFO [org.apache.spark.executor.Executor] - Running task 19.0 in stage 13.0 (TID 172)
2021-12-04 16:58:19,774 [Executor task launch worker for task 160] INFO [org.apache.spark.storage.memory.MemoryStore] - Block taskresult_160 stored as bytes in memory (estimated size 1215.6 KB, free 1989.3 MB)
2021-12-04 16:58:19,775 [dispatcher-event-loop-11] INFO [org.apache.spark.storage.BlockManagerInfo] - Added taskresult_160 in memory on qb:49432 (size: 1215.6 KB, free: 1989.6 MB)
2021-12-04 16:58:19,776 [Executor task launch worker for task 172] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-04 16:58:19,776 [Executor task launch worker for task 172] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-04 16:58:19,777 [Executor task launch worker for task 160] INFO [org.apache.spark.executor.Executor] - Finished task 7.0 in stage 13.0 (TID 160). 1244751 bytes result sent via BlockManager)
2021-12-04 16:58:19,779 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 9.0 in stage 13.0 (TID 162) in 178 ms on localhost (executor driver) (3/22)
2021-12-04 16:58:19,779 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 11.0 in stage 13.0 (TID 164) in 178 ms on localhost (executor driver) (4/22)
2021-12-04 16:58:19,781 [dispatcher-event-loop-5] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 20.0 in stage 13.0 (TID 173, localhost, executor driver, partition 20, ANY, 7868 bytes)
2021-12-04 16:58:19,781 [Executor task launch worker for task 173] INFO [org.apache.spark.executor.Executor] - Running task 20.0 in stage 13.0 (TID 173)
2021-12-04 16:58:19,782 [Executor task launch worker for task 169] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-04 16:58:19,782 [Executor task launch worker for task 169] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 1 ms
2021-12-04 16:58:19,783 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 2.0 in stage 13.0 (TID 155) in 182 ms on localhost (executor driver) (5/22)
2021-12-04 16:58:19,784 [Executor task launch worker for task 163] INFO [org.apache.spark.executor.Executor] - Finished task 10.0 in stage 13.0 (TID 163). 937148 bytes result sent to driver
2021-12-04 16:58:19,784 [Executor task launch worker for task 173] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-04 16:58:19,784 [Executor task launch worker for task 173] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-04 16:58:19,785 [dispatcher-event-loop-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 21.0 in stage 13.0 (TID 174, localhost, executor driver, partition 21, ANY, 7868 bytes)
2021-12-04 16:58:19,785 [Executor task launch worker for task 174] INFO [org.apache.spark.executor.Executor] - Running task 21.0 in stage 13.0 (TID 174)
2021-12-04 16:58:19,787 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 8.0 in stage 13.0 (TID 161) in 186 ms on localhost (executor driver) (6/22)
2021-12-04 16:58:19,789 [Executor task launch worker for task 174] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 22 non-empty blocks out of 22 blocks
2021-12-04 16:58:19,789 [Executor task launch worker for task 174] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-04 16:58:19,792 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 10.0 in stage 13.0 (TID 163) in 191 ms on localhost (executor driver) (7/22)
2021-12-04 16:58:19,793 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 6.0 in stage 13.0 (TID 159) in 192 ms on localhost (executor driver) (8/22)
2021-12-04 16:58:19,799 [Executor task launch worker for task 157] INFO [org.apache.spark.executor.Executor] - Finished task 4.0 in stage 13.0 (TID 157). 975491 bytes result sent to driver
2021-12-04 16:58:19,803 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 3.0 in stage 13.0 (TID 156) in 202 ms on localhost (executor driver) (9/22)
2021-12-04 16:58:19,804 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 4.0 in stage 13.0 (TID 157) in 203 ms on localhost (executor driver) (10/22)
2021-12-04 16:58:19,821 [Executor task launch worker for task 158] INFO [org.apache.spark.executor.Executor] - Finished task 5.0 in stage 13.0 (TID 158). 774592 bytes result sent to driver
2021-12-04 16:58:19,824 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 5.0 in stage 13.0 (TID 158) in 223 ms on localhost (executor driver) (11/22)
2021-12-04 16:58:19,851 [Executor task launch worker for task 167] INFO [org.apache.spark.executor.Executor] - Finished task 14.0 in stage 13.0 (TID 167). 605327 bytes result sent to driver
2021-12-04 16:58:19,854 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 14.0 in stage 13.0 (TID 167) in 100 ms on localhost (executor driver) (12/22)
2021-12-04 16:58:19,858 [task-result-getter-0] INFO [org.apache.spark.network.client.TransportClientFactory] - Successfully created connection to qb/192.168.2.180:49432 after 55 ms (0 ms spent in bootstraps)
2021-12-04 16:58:19,881 [Executor task launch worker for task 169] INFO [org.apache.spark.executor.Executor] - Finished task 16.0 in stage 13.0 (TID 169). 753791 bytes result sent to driver
2021-12-04 16:58:19,886 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 16.0 in stage 13.0 (TID 169) in 122 ms on localhost (executor driver) (13/22)
2021-12-04 16:58:19,889 [Executor task launch worker for task 172] INFO [org.apache.spark.executor.Executor] - Finished task 19.0 in stage 13.0 (TID 172). 550678 bytes result sent to driver
2021-12-04 16:58:19,891 [Executor task launch worker for task 165] INFO [org.apache.spark.storage.memory.MemoryStore] - Block taskresult_165 stored as bytes in memory (estimated size 1166.1 KB, free 1968.0 MB)
2021-12-04 16:58:19,891 [dispatcher-event-loop-4] INFO [org.apache.spark.storage.BlockManagerInfo] - Added taskresult_165 in memory on qb:49432 (size: 1166.1 KB, free: 1988.4 MB)
2021-12-04 16:58:19,892 [Executor task launch worker for task 165] INFO [org.apache.spark.executor.Executor] - Finished task 12.0 in stage 13.0 (TID 165). 1194072 bytes result sent via BlockManager)
2021-12-04 16:58:19,892 [Executor task launch worker for task 171] INFO [org.apache.spark.executor.Executor] - Finished task 18.0 in stage 13.0 (TID 171). 961975 bytes result sent to driver
2021-12-04 16:58:19,892 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 19.0 in stage 13.0 (TID 172) in 120 ms on localhost (executor driver) (14/22)
2021-12-04 16:58:19,895 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 18.0 in stage 13.0 (TID 171) in 130 ms on localhost (executor driver) (15/22)
2021-12-04 16:58:19,897 [Executor task launch worker for task 174] INFO [org.apache.spark.executor.Executor] - Finished task 21.0 in stage 13.0 (TID 174). 1054 bytes result sent to driver
2021-12-04 16:58:19,897 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 21.0 in stage 13.0 (TID 174) in 112 ms on localhost (executor driver) (16/22)
2021-12-04 16:58:19,900 [Executor task launch worker for task 173] INFO [org.apache.spark.executor.Executor] - Finished task 20.0 in stage 13.0 (TID 173). 1054 bytes result sent to driver
2021-12-04 16:58:19,900 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 20.0 in stage 13.0 (TID 173) in 120 ms on localhost (executor driver) (17/22)
2021-12-04 16:58:19,902 [Executor task launch worker for task 168] INFO [org.apache.spark.executor.Executor] - Finished task 15.0 in stage 13.0 (TID 168). 1006679 bytes result sent to driver
2021-12-04 16:58:19,905 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 15.0 in stage 13.0 (TID 168) in 150 ms on localhost (executor driver) (18/22)
2021-12-04 16:58:19,919 [Executor task launch worker for task 166] INFO [org.apache.spark.storage.memory.MemoryStore] - Block taskresult_166 stored as bytes in memory (estimated size 1062.1 KB, free 1987.1 MB)
2021-12-04 16:58:19,920 [dispatcher-event-loop-6] INFO [org.apache.spark.storage.BlockManagerInfo] - Added taskresult_166 in memory on qb:49432 (size: 1062.1 KB, free: 1987.4 MB)
2021-12-04 16:58:19,920 [Executor task launch worker for task 166] INFO [org.apache.spark.executor.Executor] - Finished task 13.0 in stage 13.0 (TID 166). 1087589 bytes result sent via BlockManager)
2021-12-04 16:58:19,923 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 7.0 in stage 13.0 (TID 160) in 322 ms on localhost (executor driver) (19/22)
2021-12-04 16:58:19,924 [dispatcher-event-loop-4] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed taskresult_160 on qb:49432 in memory (size: 1215.6 KB, free: 1988.6 MB)
2021-12-04 16:58:19,928 [Executor task launch worker for task 170] INFO [org.apache.spark.storage.memory.MemoryStore] - Block taskresult_170 stored as bytes in memory (estimated size 1251.8 KB, free 1987.0 MB)
2021-12-04 16:58:19,929 [dispatcher-event-loop-11] INFO [org.apache.spark.storage.BlockManagerInfo] - Added taskresult_170 in memory on qb:49432 (size: 1251.8 KB, free: 1987.4 MB)
2021-12-04 16:58:19,929 [Executor task launch worker for task 170] INFO [org.apache.spark.executor.Executor] - Finished task 17.0 in stage 13.0 (TID 170). 1281848 bytes result sent via BlockManager)
2021-12-04 16:58:19,933 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 12.0 in stage 13.0 (TID 165) in 213 ms on localhost (executor driver) (20/22)
2021-12-04 16:58:19,934 [dispatcher-event-loop-9] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed taskresult_165 on qb:49432 in memory (size: 1166.1 KB, free: 1988.5 MB)
2021-12-04 16:58:19,942 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 13.0 in stage 13.0 (TID 166) in 210 ms on localhost (executor driver) (21/22)
2021-12-04 16:58:19,943 [dispatcher-event-loop-7] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed taskresult_166 on qb:49432 in memory (size: 1062.1 KB, free: 1989.5 MB)
2021-12-04 16:58:19,954 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 17.0 in stage 13.0 (TID 170) in 190 ms on localhost (executor driver) (22/22)
2021-12-04 16:58:19,954 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 13.0, whose tasks have all completed, from pool 
2021-12-04 16:58:19,954 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 13 (takeSample at PaidPromotionAdjustParameter.scala:77) finished in 0.357 s
2021-12-04 16:58:19,954 [dispatcher-event-loop-4] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed taskresult_170 on qb:49432 in memory (size: 1251.8 KB, free: 1990.8 MB)
2021-12-04 16:58:19,954 [main] INFO [org.apache.spark.scheduler.DAGScheduler] - Job 5 finished: takeSample at PaidPromotionAdjustParameter.scala:77, took 0.359378 s
2021-12-04 16:58:20,032 [main] INFO [PaidPromotion$] - 小数据集个数：500000
2021-12-04 16:58:20,238 [main] INFO [org.apache.spark.SparkContext] - Starting job: count at PaidPromotionAdjustParameter.scala:85
2021-12-04 16:58:20,238 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 6 (count at PaidPromotionAdjustParameter.scala:85) with 22 output partitions
2021-12-04 16:58:20,238 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 14 (count at PaidPromotionAdjustParameter.scala:85)
2021-12-04 16:58:20,238 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List()
2021-12-04 16:58:20,239 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2021-12-04 16:58:20,239 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 14 (MapPartitionsRDD[14] at map at PaidPromotionAdjustParameter.scala:83), which has no missing parents
2021-12-04 16:58:20,431 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_9 stored as values in memory (estimated size 16.7 MB, free 1973.8 MB)
2021-12-04 16:58:20,466 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_9_piece0 stored as bytes in memory (estimated size 4.0 MB, free 1969.8 MB)
2021-12-04 16:58:20,466 [dispatcher-event-loop-11] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_9_piece0 in memory on qb:49432 (size: 4.0 MB, free: 1986.8 MB)
2021-12-04 16:58:20,467 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_9_piece1 stored as bytes in memory (estimated size 1766.3 KB, free 1968.0 MB)
2021-12-04 16:58:20,467 [dispatcher-event-loop-5] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_9_piece1 in memory on qb:49432 (size: 1766.3 KB, free: 1985.0 MB)
2021-12-04 16:58:20,467 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 9 from broadcast at DAGScheduler.scala:1039
2021-12-04 16:58:20,468 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 22 missing tasks from ResultStage 14 (MapPartitionsRDD[14] at map at PaidPromotionAdjustParameter.scala:83) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14))
2021-12-04 16:58:20,468 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 14.0 with 22 tasks
2021-12-04 16:58:20,468 [dispatcher-event-loop-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 14.0 (TID 175, localhost, executor driver, partition 0, ANY, 7903 bytes)
2021-12-04 16:58:20,468 [dispatcher-event-loop-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 14.0 (TID 176, localhost, executor driver, partition 1, ANY, 7903 bytes)
2021-12-04 16:58:20,468 [dispatcher-event-loop-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 2.0 in stage 14.0 (TID 177, localhost, executor driver, partition 2, ANY, 7903 bytes)
2021-12-04 16:58:20,469 [dispatcher-event-loop-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 3.0 in stage 14.0 (TID 178, localhost, executor driver, partition 3, ANY, 7903 bytes)
2021-12-04 16:58:20,469 [dispatcher-event-loop-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 4.0 in stage 14.0 (TID 179, localhost, executor driver, partition 4, ANY, 7903 bytes)
2021-12-04 16:58:20,469 [dispatcher-event-loop-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 5.0 in stage 14.0 (TID 180, localhost, executor driver, partition 5, ANY, 7903 bytes)
2021-12-04 16:58:20,469 [dispatcher-event-loop-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 6.0 in stage 14.0 (TID 181, localhost, executor driver, partition 6, ANY, 7903 bytes)
2021-12-04 16:58:20,469 [dispatcher-event-loop-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 7.0 in stage 14.0 (TID 182, localhost, executor driver, partition 7, ANY, 7903 bytes)
2021-12-04 16:58:20,469 [dispatcher-event-loop-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 8.0 in stage 14.0 (TID 183, localhost, executor driver, partition 8, ANY, 7903 bytes)
2021-12-04 16:58:20,469 [dispatcher-event-loop-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 9.0 in stage 14.0 (TID 184, localhost, executor driver, partition 9, ANY, 7903 bytes)
2021-12-04 16:58:20,469 [dispatcher-event-loop-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 10.0 in stage 14.0 (TID 185, localhost, executor driver, partition 10, ANY, 7903 bytes)
2021-12-04 16:58:20,469 [dispatcher-event-loop-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 11.0 in stage 14.0 (TID 186, localhost, executor driver, partition 11, ANY, 7903 bytes)
2021-12-04 16:58:20,469 [Executor task launch worker for task 177] INFO [org.apache.spark.executor.Executor] - Running task 2.0 in stage 14.0 (TID 177)
2021-12-04 16:58:20,469 [Executor task launch worker for task 175] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 14.0 (TID 175)
2021-12-04 16:58:20,469 [Executor task launch worker for task 180] INFO [org.apache.spark.executor.Executor] - Running task 5.0 in stage 14.0 (TID 180)
2021-12-04 16:58:20,469 [Executor task launch worker for task 176] INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 14.0 (TID 176)
2021-12-04 16:58:20,469 [Executor task launch worker for task 178] INFO [org.apache.spark.executor.Executor] - Running task 3.0 in stage 14.0 (TID 178)
2021-12-04 16:58:20,469 [Executor task launch worker for task 186] INFO [org.apache.spark.executor.Executor] - Running task 11.0 in stage 14.0 (TID 186)
2021-12-04 16:58:20,469 [Executor task launch worker for task 185] INFO [org.apache.spark.executor.Executor] - Running task 10.0 in stage 14.0 (TID 185)
2021-12-04 16:58:20,469 [Executor task launch worker for task 184] INFO [org.apache.spark.executor.Executor] - Running task 9.0 in stage 14.0 (TID 184)
2021-12-04 16:58:20,469 [Executor task launch worker for task 183] INFO [org.apache.spark.executor.Executor] - Running task 8.0 in stage 14.0 (TID 183)
2021-12-04 16:58:20,469 [Executor task launch worker for task 181] INFO [org.apache.spark.executor.Executor] - Running task 6.0 in stage 14.0 (TID 181)
2021-12-04 16:58:20,469 [Executor task launch worker for task 179] INFO [org.apache.spark.executor.Executor] - Running task 4.0 in stage 14.0 (TID 179)
2021-12-04 16:58:20,469 [Executor task launch worker for task 182] INFO [org.apache.spark.executor.Executor] - Running task 7.0 in stage 14.0 (TID 182)
2021-12-04 16:58:20,664 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 49
2021-12-04 16:58:20,664 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 193
2021-12-04 16:58:20,664 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 178
2021-12-04 16:58:20,664 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 196
2021-12-04 16:58:20,664 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 176
2021-12-04 16:58:20,664 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 180
2021-12-04 16:58:20,664 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 192
2021-12-04 16:58:20,664 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 184
2021-12-04 16:58:20,664 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 197
2021-12-04 16:58:20,668 [dispatcher-event-loop-9] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_8_piece0 on qb:49432 in memory (size: 2.8 KB, free: 1985.0 MB)
2021-12-04 16:58:20,696 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 186
2021-12-04 16:58:20,696 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 191
2021-12-04 16:58:20,697 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 190
2021-12-04 16:58:20,697 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 177
2021-12-04 16:58:20,697 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 182
2021-12-04 16:58:20,697 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 195
2021-12-04 16:58:20,697 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 185
2021-12-04 16:58:20,697 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 199
2021-12-04 16:58:20,697 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 187
2021-12-04 16:58:20,697 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 183
2021-12-04 16:58:20,697 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 194
2021-12-04 16:58:20,697 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 188
2021-12-04 16:58:20,697 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 189
2021-12-04 16:58:20,697 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 198
2021-12-04 16:58:20,697 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 179
2021-12-04 16:58:20,697 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 181
2021-12-04 16:58:20,697 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 175
2021-12-04 16:58:20,698 [dispatcher-event-loop-7] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_3_piece0 on qb:49432 in memory (size: 1906.0 B, free: 1985.0 MB)
2021-12-04 16:58:20,698 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 73
2021-12-04 16:58:20,698 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 55
2021-12-04 16:58:20,698 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 42
2021-12-04 16:58:20,698 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 41
2021-12-04 16:58:20,698 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 54
2021-12-04 16:58:20,698 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 60
2021-12-04 16:58:20,698 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 56
2021-12-04 16:58:20,698 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 39
2021-12-04 16:58:20,698 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 47
2021-12-04 16:58:20,698 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 65
2021-12-04 16:58:20,698 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 45
2021-12-04 16:58:20,698 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 30
2021-12-04 16:58:20,698 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 69
2021-12-04 16:58:20,698 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 71
2021-12-04 16:58:20,699 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 72
2021-12-04 16:58:20,699 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 50
2021-12-04 16:58:20,699 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 66
2021-12-04 16:58:20,699 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 53
2021-12-04 16:58:20,699 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 59
2021-12-04 16:58:20,699 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 29
2021-12-04 16:58:20,699 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 70
2021-12-04 16:58:20,699 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 34
2021-12-04 16:58:20,699 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 61
2021-12-04 16:58:20,699 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 58
2021-12-04 16:58:20,699 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 40
2021-12-04 16:58:20,699 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 37
2021-12-04 16:58:20,699 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 32
2021-12-04 16:58:20,699 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 28
2021-12-04 16:58:20,699 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 62
2021-12-04 16:58:20,699 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 38
2021-12-04 16:58:20,699 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 74
2021-12-04 16:58:20,699 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 68
2021-12-04 16:58:20,699 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 51
2021-12-04 16:58:20,699 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 67
2021-12-04 16:58:20,699 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 48
2021-12-04 16:58:20,699 [dispatcher-event-loop-4] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_2_piece0 on qb:49432 in memory (size: 2.7 KB, free: 1985.0 MB)
2021-12-04 16:58:20,700 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 33
2021-12-04 16:58:20,700 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 35
2021-12-04 16:58:20,700 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 64
2021-12-04 16:58:20,700 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 57
2021-12-04 16:58:20,700 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 27
2021-12-04 16:58:20,700 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 63
2021-12-04 16:58:20,700 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 52
2021-12-04 16:58:20,700 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 44
2021-12-04 16:58:20,700 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 26
2021-12-04 16:58:20,700 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 31
2021-12-04 16:58:20,700 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 43
2021-12-04 16:58:20,700 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 36
2021-12-04 16:58:20,700 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 46
2021-12-04 16:58:20,700 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 25
2021-12-04 16:58:22,017 [Executor task launch worker for task 180] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:671088640+134217728
2021-12-04 16:58:22,019 [Executor task launch worker for task 178] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:402653184+134217728
2021-12-04 16:58:22,019 [Executor task launch worker for task 176] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:134217728+134217728
2021-12-04 16:58:22,019 [Executor task launch worker for task 185] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:1342177280+134217728
2021-12-04 16:58:22,022 [Executor task launch worker for task 182] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:939524096+134217728
2021-12-04 16:58:22,023 [Executor task launch worker for task 177] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:268435456+134217728
2021-12-04 16:58:22,026 [Executor task launch worker for task 181] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:805306368+134217728
2021-12-04 16:58:22,026 [Executor task launch worker for task 175] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:0+134217728
2021-12-04 16:58:22,029 [Executor task launch worker for task 179] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:536870912+134217728
2021-12-04 16:58:22,031 [Executor task launch worker for task 184] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:1207959552+134217728
2021-12-04 16:58:22,036 [Executor task launch worker for task 186] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:1476395008+134217728
2021-12-04 16:58:22,039 [Executor task launch worker for task 183] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:1073741824+134217728
2021-12-04 17:32:19,092 [main] INFO [org.apache.spark.SparkContext] - Running Spark version 2.3.0
2021-12-04 17:32:19,341 [main] INFO [org.apache.spark.SparkContext] - Submitted application: PaidPromotion
2021-12-04 17:32:19,386 [main] INFO [org.apache.spark.SecurityManager] - Changing view acls to: ACER,root
2021-12-04 17:32:19,387 [main] INFO [org.apache.spark.SecurityManager] - Changing modify acls to: ACER,root
2021-12-04 17:32:19,387 [main] INFO [org.apache.spark.SecurityManager] - Changing view acls groups to: 
2021-12-04 17:32:19,387 [main] INFO [org.apache.spark.SecurityManager] - Changing modify acls groups to: 
2021-12-04 17:32:19,388 [main] INFO [org.apache.spark.SecurityManager] - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(ACER, root); groups with view permissions: Set(); users  with modify permissions: Set(ACER, root); groups with modify permissions: Set()
2021-12-04 17:32:19,927 [main] INFO [org.apache.spark.util.Utils] - Successfully started service 'sparkDriver' on port 60179.
2021-12-04 17:32:19,944 [main] INFO [org.apache.spark.SparkEnv] - Registering MapOutputTracker
2021-12-04 17:32:19,960 [main] INFO [org.apache.spark.SparkEnv] - Registering BlockManagerMaster
2021-12-04 17:32:19,962 [main] INFO [org.apache.spark.storage.BlockManagerMasterEndpoint] - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2021-12-04 17:32:19,962 [main] INFO [org.apache.spark.storage.BlockManagerMasterEndpoint] - BlockManagerMasterEndpoint up
2021-12-04 17:32:19,971 [main] INFO [org.apache.spark.storage.DiskBlockManager] - Created local directory at C:\Users\ACER\AppData\Local\Temp\blockmgr-ddf5995d-71d5-4a5c-b639-58efc032aa6c
2021-12-04 17:32:19,985 [main] INFO [org.apache.spark.storage.memory.MemoryStore] - MemoryStore started with capacity 1990.8 MB
2021-12-04 17:32:19,994 [main] INFO [org.apache.spark.SparkEnv] - Registering OutputCommitCoordinator
2021-12-04 17:32:20,045 [main] INFO [org.spark_project.jetty.util.log] - Logging initialized @1769ms
2021-12-04 17:32:20,097 [main] INFO [org.spark_project.jetty.server.Server] - jetty-9.3.z-SNAPSHOT
2021-12-04 17:32:20,107 [main] INFO [org.spark_project.jetty.server.Server] - Started @1831ms
2021-12-04 17:32:20,132 [main] INFO [org.spark_project.jetty.server.AbstractConnector] - Started ServerConnector@5b800468{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2021-12-04 17:32:20,132 [main] INFO [org.apache.spark.util.Utils] - Successfully started service 'SparkUI' on port 4040.
2021-12-04 17:32:20,150 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@1568159{/jobs,null,AVAILABLE,@Spark}
2021-12-04 17:32:20,151 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@63cd604c{/jobs/json,null,AVAILABLE,@Spark}
2021-12-04 17:32:20,152 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@3954d008{/jobs/job,null,AVAILABLE,@Spark}
2021-12-04 17:32:20,153 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@6d8792db{/jobs/job/json,null,AVAILABLE,@Spark}
2021-12-04 17:32:20,154 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@3a1d593e{/stages,null,AVAILABLE,@Spark}
2021-12-04 17:32:20,156 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@285d851a{/stages/json,null,AVAILABLE,@Spark}
2021-12-04 17:32:20,157 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@7876d598{/stages/stage,null,AVAILABLE,@Spark}
2021-12-04 17:32:20,158 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@4985cbcb{/stages/stage/json,null,AVAILABLE,@Spark}
2021-12-04 17:32:20,159 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@54361a9{/stages/pool,null,AVAILABLE,@Spark}
2021-12-04 17:32:20,160 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@293bb8a5{/stages/pool/json,null,AVAILABLE,@Spark}
2021-12-04 17:32:20,161 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@290b1b2e{/storage,null,AVAILABLE,@Spark}
2021-12-04 17:32:20,162 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@5db4c359{/storage/json,null,AVAILABLE,@Spark}
2021-12-04 17:32:20,163 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@6fefce9e{/storage/rdd,null,AVAILABLE,@Spark}
2021-12-04 17:32:20,164 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@8a589a2{/storage/rdd/json,null,AVAILABLE,@Spark}
2021-12-04 17:32:20,165 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@5cc69cfe{/environment,null,AVAILABLE,@Spark}
2021-12-04 17:32:20,166 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@11dee337{/environment/json,null,AVAILABLE,@Spark}
2021-12-04 17:32:20,167 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@74bdc168{/executors,null,AVAILABLE,@Spark}
2021-12-04 17:32:20,169 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@7bb3a9fe{/executors/json,null,AVAILABLE,@Spark}
2021-12-04 17:32:20,170 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@f19c9d2{/executors/threadDump,null,AVAILABLE,@Spark}
2021-12-04 17:32:20,171 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@a77614d{/executors/threadDump/json,null,AVAILABLE,@Spark}
2021-12-04 17:32:20,177 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@523424b5{/static,null,AVAILABLE,@Spark}
2021-12-04 17:32:20,178 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@12cd9150{/,null,AVAILABLE,@Spark}
2021-12-04 17:32:20,180 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@32fe9d0a{/api,null,AVAILABLE,@Spark}
2021-12-04 17:32:20,181 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@59fc684e{/jobs/job/kill,null,AVAILABLE,@Spark}
2021-12-04 17:32:20,182 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@355e34c7{/stages/stage/kill,null,AVAILABLE,@Spark}
2021-12-04 17:32:20,184 [main] INFO [org.apache.spark.ui.SparkUI] - Bound SparkUI to 0.0.0.0, and started at http://qb:4040
2021-12-04 17:32:20,257 [main] INFO [org.apache.spark.executor.Executor] - Starting executor ID driver on host localhost
2021-12-04 17:32:20,305 [main] INFO [org.apache.spark.util.Utils] - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 60226.
2021-12-04 17:32:20,306 [main] INFO [org.apache.spark.network.netty.NettyBlockTransferService] - Server created on qb:60226
2021-12-04 17:32:20,307 [main] INFO [org.apache.spark.storage.BlockManager] - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2021-12-04 17:32:20,308 [main] INFO [org.apache.spark.storage.BlockManagerMaster] - Registering BlockManager BlockManagerId(driver, qb, 60226, None)
2021-12-04 17:32:20,310 [dispatcher-event-loop-10] INFO [org.apache.spark.storage.BlockManagerMasterEndpoint] - Registering block manager qb:60226 with 1990.8 MB RAM, BlockManagerId(driver, qb, 60226, None)
2021-12-04 17:32:20,312 [main] INFO [org.apache.spark.storage.BlockManagerMaster] - Registered BlockManager BlockManagerId(driver, qb, 60226, None)
2021-12-04 17:32:20,313 [main] INFO [org.apache.spark.storage.BlockManager] - Initialized BlockManager: BlockManagerId(driver, qb, 60226, None)
2021-12-04 17:32:20,442 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@6fe46b62{/metrics/json,null,AVAILABLE,@Spark}
2021-12-04 17:32:20,889 [main] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_0 stored as values in memory (estimated size 312.7 KB, free 1990.5 MB)
2021-12-04 17:32:21,129 [main] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_0_piece0 stored as bytes in memory (estimated size 27.3 KB, free 1990.5 MB)
2021-12-04 17:32:21,131 [dispatcher-event-loop-0] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_0_piece0 in memory on qb:60226 (size: 27.3 KB, free: 1990.8 MB)
2021-12-04 17:32:21,134 [main] INFO [org.apache.spark.SparkContext] - Created broadcast 0 from textFile at PaidPromotionAdjustParameter.scala:98
2021-12-04 17:32:21,456 [main] WARN [org.apache.hadoop.hdfs.shortcircuit.DomainSocketFactory] - The short-circuit local reads feature cannot be used because UNIX Domain sockets are not available on Windows.
2021-12-04 17:32:21,523 [main] INFO [org.apache.hadoop.mapred.FileInputFormat] - Total input paths to process : 1
2021-12-04 17:32:21,556 [main] INFO [org.apache.spark.SparkContext] - Starting job: count at PaidPromotionAdjustParameter.scala:100
2021-12-04 17:32:21,565 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 0 (count at PaidPromotionAdjustParameter.scala:100) with 2 output partitions
2021-12-04 17:32:21,565 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 0 (count at PaidPromotionAdjustParameter.scala:100)
2021-12-04 17:32:21,565 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List()
2021-12-04 17:32:21,566 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2021-12-04 17:32:21,571 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 0 (/sk/chongqing/data/order_data.bcp MapPartitionsRDD[1] at textFile at PaidPromotionAdjustParameter.scala:98), which has no missing parents
2021-12-04 17:32:21,599 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_1 stored as values in memory (estimated size 3.1 KB, free 1990.5 MB)
2021-12-04 17:32:21,603 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_1_piece0 stored as bytes in memory (estimated size 1900.0 B, free 1990.5 MB)
2021-12-04 17:32:21,604 [dispatcher-event-loop-1] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_1_piece0 in memory on qb:60226 (size: 1900.0 B, free: 1990.8 MB)
2021-12-04 17:32:21,604 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 1 from broadcast at DAGScheduler.scala:1039
2021-12-04 17:32:21,613 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from ResultStage 0 (/sk/chongqing/data/order_data.bcp MapPartitionsRDD[1] at textFile at PaidPromotionAdjustParameter.scala:98) (first 15 tasks are for partitions Vector(0, 1))
2021-12-04 17:32:21,614 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 0.0 with 2 tasks
2021-12-04 17:32:21,646 [dispatcher-event-loop-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 0.0 (TID 0, localhost, executor driver, partition 0, ANY, 7896 bytes)
2021-12-04 17:32:21,647 [dispatcher-event-loop-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 0.0 (TID 1, localhost, executor driver, partition 1, ANY, 7896 bytes)
2021-12-04 17:32:21,652 [Executor task launch worker for task 1] INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 0.0 (TID 1)
2021-12-04 17:32:21,652 [Executor task launch worker for task 0] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 0.0 (TID 0)
2021-12-04 17:32:21,692 [Executor task launch worker for task 1] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/order_data.bcp:3442194+3442195
2021-12-04 17:32:21,692 [Executor task launch worker for task 0] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/order_data.bcp:0+3442194
2021-12-04 17:32:22,355 [Executor task launch worker for task 1] INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 0.0 (TID 1). 754 bytes result sent to driver
2021-12-04 17:32:22,355 [Executor task launch worker for task 0] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 0.0 (TID 0). 711 bytes result sent to driver
2021-12-04 17:32:22,364 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 0.0 (TID 0) in 726 ms on localhost (executor driver) (1/2)
2021-12-04 17:32:22,365 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 0.0 (TID 1) in 718 ms on localhost (executor driver) (2/2)
2021-12-04 17:32:22,366 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 0.0, whose tasks have all completed, from pool 
2021-12-04 17:32:22,369 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 0 (count at PaidPromotionAdjustParameter.scala:100) finished in 0.785 s
2021-12-04 17:32:22,373 [main] INFO [org.apache.spark.scheduler.DAGScheduler] - Job 0 finished: count at PaidPromotionAdjustParameter.scala:100, took 0.817131 s
2021-12-04 17:32:22,374 [main] INFO [PaidPromotion$] - 订购总数107294
2021-12-04 17:32:22,379 [main] INFO [org.apache.spark.SparkContext] - Starting job: count at PaidPromotionAdjustParameter.scala:108
2021-12-04 17:32:22,380 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 1 (count at PaidPromotionAdjustParameter.scala:108) with 2 output partitions
2021-12-04 17:32:22,380 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 1 (count at PaidPromotionAdjustParameter.scala:108)
2021-12-04 17:32:22,380 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List()
2021-12-04 17:32:22,380 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2021-12-04 17:32:22,380 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 1 (MapPartitionsRDD[2] at map at PaidPromotionAdjustParameter.scala:104), which has no missing parents
2021-12-04 17:32:22,382 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_2 stored as values in memory (estimated size 3.3 KB, free 1990.5 MB)
2021-12-04 17:32:22,387 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_2_piece0 stored as bytes in memory (estimated size 1985.0 B, free 1990.5 MB)
2021-12-04 17:32:22,387 [dispatcher-event-loop-7] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_2_piece0 in memory on qb:60226 (size: 1985.0 B, free: 1990.8 MB)
2021-12-04 17:32:22,388 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 2 from broadcast at DAGScheduler.scala:1039
2021-12-04 17:32:22,389 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from ResultStage 1 (MapPartitionsRDD[2] at map at PaidPromotionAdjustParameter.scala:104) (first 15 tasks are for partitions Vector(0, 1))
2021-12-04 17:32:22,389 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 1.0 with 2 tasks
2021-12-04 17:32:22,390 [dispatcher-event-loop-8] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 1.0 (TID 2, localhost, executor driver, partition 0, ANY, 7896 bytes)
2021-12-04 17:32:22,390 [dispatcher-event-loop-8] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 1.0 (TID 3, localhost, executor driver, partition 1, ANY, 7896 bytes)
2021-12-04 17:32:22,390 [Executor task launch worker for task 2] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 1.0 (TID 2)
2021-12-04 17:32:22,390 [Executor task launch worker for task 3] INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 1.0 (TID 3)
2021-12-04 17:32:22,393 [Executor task launch worker for task 2] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/order_data.bcp:0+3442194
2021-12-04 17:32:22,393 [Executor task launch worker for task 3] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/order_data.bcp:3442194+3442195
2021-12-04 17:32:22,434 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 0
2021-12-04 17:32:22,434 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 4
2021-12-04 17:32:22,434 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 12
2021-12-04 17:32:22,434 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 2
2021-12-04 17:32:22,434 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 7
2021-12-04 17:32:22,434 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 16
2021-12-04 17:32:22,434 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 18
2021-12-04 17:32:22,434 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 22
2021-12-04 17:32:22,434 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 17
2021-12-04 17:32:22,434 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 20
2021-12-04 17:32:22,435 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 6
2021-12-04 17:32:22,435 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 14
2021-12-04 17:32:22,435 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 21
2021-12-04 17:32:22,435 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 11
2021-12-04 17:32:22,435 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 15
2021-12-04 17:32:22,435 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 24
2021-12-04 17:32:22,435 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 19
2021-12-04 17:32:22,435 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 23
2021-12-04 17:32:22,435 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 5
2021-12-04 17:32:22,447 [dispatcher-event-loop-1] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_1_piece0 on qb:60226 in memory (size: 1900.0 B, free: 1990.8 MB)
2021-12-04 17:32:22,449 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 3
2021-12-04 17:32:22,449 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 13
2021-12-04 17:32:22,449 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 8
2021-12-04 17:32:22,449 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 10
2021-12-04 17:32:22,449 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 9
2021-12-04 17:32:22,449 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1
2021-12-04 17:32:22,741 [Executor task launch worker for task 3] INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 1.0 (TID 3). 754 bytes result sent to driver
2021-12-04 17:32:22,744 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 1.0 (TID 3) in 354 ms on localhost (executor driver) (1/2)
2021-12-04 17:32:23,003 [Executor task launch worker for task 2] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 1.0 (TID 2). 754 bytes result sent to driver
2021-12-04 17:32:23,006 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 1.0 (TID 2) in 617 ms on localhost (executor driver) (2/2)
2021-12-04 17:32:23,006 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 1.0, whose tasks have all completed, from pool 
2021-12-04 17:32:23,006 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 1 (count at PaidPromotionAdjustParameter.scala:108) finished in 0.625 s
2021-12-04 17:32:23,006 [main] INFO [org.apache.spark.scheduler.DAGScheduler] - Job 1 finished: count at PaidPromotionAdjustParameter.scala:108, took 0.626686 s
2021-12-04 17:32:23,006 [main] INFO [PaidPromotion$] - 订购总数：107294
2021-12-04 17:32:23,020 [main] INFO [org.apache.spark.SparkContext] - Starting job: count at PaidPromotionAdjustParameter.scala:121
2021-12-04 17:32:23,020 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 2 (count at PaidPromotionAdjustParameter.scala:121) with 2 output partitions
2021-12-04 17:32:23,020 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 2 (count at PaidPromotionAdjustParameter.scala:121)
2021-12-04 17:32:23,020 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List()
2021-12-04 17:32:23,020 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2021-12-04 17:32:23,021 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 2 (MapPartitionsRDD[3] at randomSplit at PaidPromotionAdjustParameter.scala:114), which has no missing parents
2021-12-04 17:32:23,022 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_3 stored as values in memory (estimated size 3.6 KB, free 1990.5 MB)
2021-12-04 17:32:23,026 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_3_piece0 stored as bytes in memory (estimated size 2.1 KB, free 1990.5 MB)
2021-12-04 17:32:23,026 [dispatcher-event-loop-3] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_3_piece0 in memory on qb:60226 (size: 2.1 KB, free: 1990.8 MB)
2021-12-04 17:32:23,027 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 3 from broadcast at DAGScheduler.scala:1039
2021-12-04 17:32:23,027 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from ResultStage 2 (MapPartitionsRDD[3] at randomSplit at PaidPromotionAdjustParameter.scala:114) (first 15 tasks are for partitions Vector(0, 1))
2021-12-04 17:32:23,027 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 2.0 with 2 tasks
2021-12-04 17:32:23,028 [dispatcher-event-loop-6] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 2.0 (TID 4, localhost, executor driver, partition 0, ANY, 7896 bytes)
2021-12-04 17:32:23,028 [dispatcher-event-loop-6] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 2.0 (TID 5, localhost, executor driver, partition 1, ANY, 7896 bytes)
2021-12-04 17:32:23,028 [Executor task launch worker for task 5] INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 2.0 (TID 5)
2021-12-04 17:32:23,028 [Executor task launch worker for task 4] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 2.0 (TID 4)
2021-12-04 17:32:23,031 [Executor task launch worker for task 5] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/order_data.bcp:3442194+3442195
2021-12-04 17:32:23,031 [Executor task launch worker for task 4] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/order_data.bcp:0+3442194
2021-12-04 17:32:23,058 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 40
2021-12-04 17:32:23,058 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 46
2021-12-04 17:32:23,058 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 36
2021-12-04 17:32:23,058 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 25
2021-12-04 17:32:23,058 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 29
2021-12-04 17:32:23,058 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 44
2021-12-04 17:32:23,058 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 47
2021-12-04 17:32:23,058 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 28
2021-12-04 17:32:23,058 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 38
2021-12-04 17:32:23,058 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 35
2021-12-04 17:32:23,058 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 31
2021-12-04 17:32:23,058 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 39
2021-12-04 17:32:23,058 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 49
2021-12-04 17:32:23,058 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 37
2021-12-04 17:32:23,058 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 26
2021-12-04 17:32:23,058 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 30
2021-12-04 17:32:23,058 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 43
2021-12-04 17:32:23,058 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 42
2021-12-04 17:32:23,059 [dispatcher-event-loop-10] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_2_piece0 on qb:60226 in memory (size: 1985.0 B, free: 1990.8 MB)
2021-12-04 17:32:23,059 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 27
2021-12-04 17:32:23,059 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 32
2021-12-04 17:32:23,059 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 34
2021-12-04 17:32:23,059 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 41
2021-12-04 17:32:23,059 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 45
2021-12-04 17:32:23,059 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 33
2021-12-04 17:32:23,059 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 48
2021-12-04 17:32:23,416 [Executor task launch worker for task 4] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 2.0 (TID 4). 797 bytes result sent to driver
2021-12-04 17:32:23,416 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 2.0 (TID 4) in 388 ms on localhost (executor driver) (1/2)
2021-12-04 17:32:23,705 [Executor task launch worker for task 5] INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 2.0 (TID 5). 797 bytes result sent to driver
2021-12-04 17:32:23,706 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 2.0 (TID 5) in 678 ms on localhost (executor driver) (2/2)
2021-12-04 17:32:23,706 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 2.0, whose tasks have all completed, from pool 
2021-12-04 17:32:23,707 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 2 (count at PaidPromotionAdjustParameter.scala:121) finished in 0.686 s
2021-12-04 17:32:23,707 [main] INFO [org.apache.spark.scheduler.DAGScheduler] - Job 2 finished: count at PaidPromotionAdjustParameter.scala:121, took 0.687830 s
2021-12-04 17:32:23,707 [main] INFO [PaidPromotion$] - 初次切分训练集数量：77230
2021-12-04 17:32:23,710 [main] INFO [org.apache.spark.SparkContext] - Starting job: count at PaidPromotionAdjustParameter.scala:122
2021-12-04 17:32:23,711 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 3 (count at PaidPromotionAdjustParameter.scala:122) with 2 output partitions
2021-12-04 17:32:23,711 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 3 (count at PaidPromotionAdjustParameter.scala:122)
2021-12-04 17:32:23,711 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List()
2021-12-04 17:32:23,711 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2021-12-04 17:32:23,711 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 3 (MapPartitionsRDD[4] at randomSplit at PaidPromotionAdjustParameter.scala:114), which has no missing parents
2021-12-04 17:32:23,713 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_4 stored as values in memory (estimated size 3.6 KB, free 1990.5 MB)
2021-12-04 17:32:23,715 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_4_piece0 stored as bytes in memory (estimated size 2.1 KB, free 1990.5 MB)
2021-12-04 17:32:23,716 [dispatcher-event-loop-1] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_4_piece0 in memory on qb:60226 (size: 2.1 KB, free: 1990.8 MB)
2021-12-04 17:32:23,716 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 4 from broadcast at DAGScheduler.scala:1039
2021-12-04 17:32:23,717 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from ResultStage 3 (MapPartitionsRDD[4] at randomSplit at PaidPromotionAdjustParameter.scala:114) (first 15 tasks are for partitions Vector(0, 1))
2021-12-04 17:32:23,717 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 3.0 with 2 tasks
2021-12-04 17:32:23,718 [dispatcher-event-loop-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 3.0 (TID 6, localhost, executor driver, partition 0, ANY, 7896 bytes)
2021-12-04 17:32:23,718 [dispatcher-event-loop-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 3.0 (TID 7, localhost, executor driver, partition 1, ANY, 7896 bytes)
2021-12-04 17:32:23,718 [Executor task launch worker for task 7] INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 3.0 (TID 7)
2021-12-04 17:32:23,718 [Executor task launch worker for task 6] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 3.0 (TID 6)
2021-12-04 17:32:23,720 [Executor task launch worker for task 6] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/order_data.bcp:0+3442194
2021-12-04 17:32:23,720 [Executor task launch worker for task 7] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/order_data.bcp:3442194+3442195
2021-12-04 17:32:23,973 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 62
2021-12-04 17:32:23,973 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 66
2021-12-04 17:32:23,973 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 67
2021-12-04 17:32:23,973 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 55
2021-12-04 17:32:23,973 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 65
2021-12-04 17:32:23,973 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 72
2021-12-04 17:32:23,973 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 70
2021-12-04 17:32:23,974 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 53
2021-12-04 17:32:23,975 [dispatcher-event-loop-5] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_3_piece0 on qb:60226 in memory (size: 2.1 KB, free: 1990.8 MB)
2021-12-04 17:32:23,975 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 63
2021-12-04 17:32:23,975 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 58
2021-12-04 17:32:23,975 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 73
2021-12-04 17:32:23,976 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 54
2021-12-04 17:32:23,976 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 74
2021-12-04 17:32:23,976 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 59
2021-12-04 17:32:23,976 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 60
2021-12-04 17:32:23,976 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 64
2021-12-04 17:32:23,976 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 56
2021-12-04 17:32:23,976 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 68
2021-12-04 17:32:23,976 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 61
2021-12-04 17:32:23,976 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 71
2021-12-04 17:32:23,976 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 69
2021-12-04 17:32:23,976 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 57
2021-12-04 17:32:23,976 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 52
2021-12-04 17:32:23,976 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 50
2021-12-04 17:32:23,976 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 51
2021-12-04 17:32:24,197 [Executor task launch worker for task 6] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 3.0 (TID 6). 754 bytes result sent to driver
2021-12-04 17:32:24,197 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 3.0 (TID 6) in 480 ms on localhost (executor driver) (1/2)
2021-12-04 17:32:24,360 [Executor task launch worker for task 7] INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 3.0 (TID 7). 754 bytes result sent to driver
2021-12-04 17:32:24,360 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 3.0 (TID 7) in 642 ms on localhost (executor driver) (2/2)
2021-12-04 17:32:24,360 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 3.0, whose tasks have all completed, from pool 
2021-12-04 17:32:24,361 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 3 (count at PaidPromotionAdjustParameter.scala:122) finished in 0.648 s
2021-12-04 17:32:24,361 [main] INFO [org.apache.spark.scheduler.DAGScheduler] - Job 3 finished: count at PaidPromotionAdjustParameter.scala:122, took 0.650145 s
2021-12-04 17:32:24,361 [main] INFO [PaidPromotion$] - 初次切分验证集数量：30064
2021-12-04 17:32:24,413 [main] INFO [PaidPromotion$] - -----------------------------------
2021-12-04 17:32:24,414 [main] INFO [org.apache.spark.SparkContext] - Starting job: count at PaidPromotionAdjustParameter.scala:138
2021-12-04 17:32:24,421 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 6 (distinct at PaidPromotionAdjustParameter.scala:128)
2021-12-04 17:32:24,421 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 4 (count at PaidPromotionAdjustParameter.scala:138) with 2 output partitions
2021-12-04 17:32:24,421 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 5 (count at PaidPromotionAdjustParameter.scala:138)
2021-12-04 17:32:24,421 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 4)
2021-12-04 17:32:24,422 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List(ShuffleMapStage 4)
2021-12-04 17:32:24,423 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ShuffleMapStage 4 (MapPartitionsRDD[6] at distinct at PaidPromotionAdjustParameter.scala:128), which has no missing parents
2021-12-04 17:32:24,430 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_5 stored as values in memory (estimated size 5.2 KB, free 1990.5 MB)
2021-12-04 17:32:24,433 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_5_piece0 stored as bytes in memory (estimated size 2.9 KB, free 1990.5 MB)
2021-12-04 17:32:24,434 [dispatcher-event-loop-10] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_5_piece0 in memory on qb:60226 (size: 2.9 KB, free: 1990.8 MB)
2021-12-04 17:32:24,434 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 5 from broadcast at DAGScheduler.scala:1039
2021-12-04 17:32:24,436 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from ShuffleMapStage 4 (MapPartitionsRDD[6] at distinct at PaidPromotionAdjustParameter.scala:128) (first 15 tasks are for partitions Vector(0, 1))
2021-12-04 17:32:24,436 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 4.0 with 2 tasks
2021-12-04 17:32:24,437 [dispatcher-event-loop-11] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 4.0 (TID 8, localhost, executor driver, partition 0, ANY, 7885 bytes)
2021-12-04 17:32:24,437 [dispatcher-event-loop-11] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 4.0 (TID 9, localhost, executor driver, partition 1, ANY, 7885 bytes)
2021-12-04 17:32:24,438 [Executor task launch worker for task 9] INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 4.0 (TID 9)
2021-12-04 17:32:24,438 [Executor task launch worker for task 8] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 4.0 (TID 8)
2021-12-04 17:32:24,442 [Executor task launch worker for task 8] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/order_data.bcp:0+3442194
2021-12-04 17:32:24,442 [Executor task launch worker for task 9] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/order_data.bcp:3442194+3442195
2021-12-04 17:32:24,767 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 75
2021-12-04 17:32:24,768 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 88
2021-12-04 17:32:24,768 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 95
2021-12-04 17:32:24,768 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 98
2021-12-04 17:32:24,768 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 86
2021-12-04 17:32:24,768 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 97
2021-12-04 17:32:24,768 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 77
2021-12-04 17:32:24,768 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 81
2021-12-04 17:32:24,768 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 93
2021-12-04 17:32:24,768 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 83
2021-12-04 17:32:24,768 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 87
2021-12-04 17:32:24,768 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 99
2021-12-04 17:32:24,768 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 89
2021-12-04 17:32:24,768 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 76
2021-12-04 17:32:24,768 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 84
2021-12-04 17:32:24,768 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 82
2021-12-04 17:32:24,768 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 90
2021-12-04 17:32:24,768 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 80
2021-12-04 17:32:24,768 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 79
2021-12-04 17:32:24,768 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 92
2021-12-04 17:32:24,768 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 96
2021-12-04 17:32:24,769 [dispatcher-event-loop-3] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_4_piece0 on qb:60226 in memory (size: 2.1 KB, free: 1990.8 MB)
2021-12-04 17:32:24,769 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 85
2021-12-04 17:32:24,769 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 91
2021-12-04 17:32:24,769 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 94
2021-12-04 17:32:24,770 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 78
2021-12-04 17:32:24,892 [Executor task launch worker for task 9] INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 4.0 (TID 9). 1032 bytes result sent to driver
2021-12-04 17:32:24,904 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 4.0 (TID 9) in 467 ms on localhost (executor driver) (1/2)
2021-12-04 17:32:25,107 [Executor task launch worker for task 8] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 4.0 (TID 8). 1032 bytes result sent to driver
2021-12-04 17:32:25,108 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 4.0 (TID 8) in 672 ms on localhost (executor driver) (2/2)
2021-12-04 17:32:25,108 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 4.0, whose tasks have all completed, from pool 
2021-12-04 17:32:25,108 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ShuffleMapStage 4 (distinct at PaidPromotionAdjustParameter.scala:128) finished in 0.684 s
2021-12-04 17:32:25,109 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - looking for newly runnable stages
2021-12-04 17:32:25,109 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - running: Set()
2021-12-04 17:32:25,109 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - waiting: Set(ResultStage 5)
2021-12-04 17:32:25,110 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - failed: Set()
2021-12-04 17:32:25,112 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 5 (MapPartitionsRDD[8] at distinct at PaidPromotionAdjustParameter.scala:128), which has no missing parents
2021-12-04 17:32:25,116 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_6 stored as values in memory (estimated size 3.7 KB, free 1990.5 MB)
2021-12-04 17:32:25,119 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_6_piece0 stored as bytes in memory (estimated size 2.2 KB, free 1990.5 MB)
2021-12-04 17:32:25,119 [dispatcher-event-loop-5] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_6_piece0 in memory on qb:60226 (size: 2.2 KB, free: 1990.8 MB)
2021-12-04 17:32:25,119 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 6 from broadcast at DAGScheduler.scala:1039
2021-12-04 17:32:25,120 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from ResultStage 5 (MapPartitionsRDD[8] at distinct at PaidPromotionAdjustParameter.scala:128) (first 15 tasks are for partitions Vector(0, 1))
2021-12-04 17:32:25,120 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 5.0 with 2 tasks
2021-12-04 17:32:25,121 [dispatcher-event-loop-9] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 5.0 (TID 10, localhost, executor driver, partition 0, ANY, 7649 bytes)
2021-12-04 17:32:25,121 [dispatcher-event-loop-9] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 5.0 (TID 11, localhost, executor driver, partition 1, ANY, 7649 bytes)
2021-12-04 17:32:25,121 [Executor task launch worker for task 10] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 5.0 (TID 10)
2021-12-04 17:32:25,121 [Executor task launch worker for task 11] INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 5.0 (TID 11)
2021-12-04 17:32:25,131 [Executor task launch worker for task 10] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 2 non-empty blocks out of 2 blocks
2021-12-04 17:32:25,131 [Executor task launch worker for task 11] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 2 non-empty blocks out of 2 blocks
2021-12-04 17:32:25,133 [Executor task launch worker for task 10] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 4 ms
2021-12-04 17:32:25,133 [Executor task launch worker for task 11] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 4 ms
2021-12-04 17:32:25,283 [Executor task launch worker for task 11] INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 5.0 (TID 11). 1098 bytes result sent to driver
2021-12-04 17:32:25,283 [Executor task launch worker for task 10] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 5.0 (TID 10). 1098 bytes result sent to driver
2021-12-04 17:32:25,284 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 5.0 (TID 11) in 163 ms on localhost (executor driver) (1/2)
2021-12-04 17:32:25,284 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 5.0 (TID 10) in 164 ms on localhost (executor driver) (2/2)
2021-12-04 17:32:25,284 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 5.0, whose tasks have all completed, from pool 
2021-12-04 17:32:25,284 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 5 (count at PaidPromotionAdjustParameter.scala:138) finished in 0.171 s
2021-12-04 17:32:25,285 [main] INFO [org.apache.spark.scheduler.DAGScheduler] - Job 4 finished: count at PaidPromotionAdjustParameter.scala:138, took 0.869987 s
2021-12-04 17:32:25,285 [main] INFO [PaidPromotion$] - 训练集用户数 = 70664
2021-12-04 17:32:25,289 [main] INFO [org.apache.spark.SparkContext] - Starting job: count at PaidPromotionAdjustParameter.scala:139
2021-12-04 17:32:25,289 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 10 (distinct at PaidPromotionAdjustParameter.scala:129)
2021-12-04 17:32:25,289 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 5 (count at PaidPromotionAdjustParameter.scala:139) with 2 output partitions
2021-12-04 17:32:25,289 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 7 (count at PaidPromotionAdjustParameter.scala:139)
2021-12-04 17:32:25,289 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 6)
2021-12-04 17:32:25,289 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List(ShuffleMapStage 6)
2021-12-04 17:32:25,290 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ShuffleMapStage 6 (MapPartitionsRDD[10] at distinct at PaidPromotionAdjustParameter.scala:129), which has no missing parents
2021-12-04 17:32:25,291 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_7 stored as values in memory (estimated size 5.2 KB, free 1990.4 MB)
2021-12-04 17:32:25,294 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_7_piece0 stored as bytes in memory (estimated size 2.9 KB, free 1990.4 MB)
2021-12-04 17:32:25,294 [dispatcher-event-loop-1] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_7_piece0 in memory on qb:60226 (size: 2.9 KB, free: 1990.8 MB)
2021-12-04 17:32:25,295 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 7 from broadcast at DAGScheduler.scala:1039
2021-12-04 17:32:25,295 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from ShuffleMapStage 6 (MapPartitionsRDD[10] at distinct at PaidPromotionAdjustParameter.scala:129) (first 15 tasks are for partitions Vector(0, 1))
2021-12-04 17:32:25,295 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 6.0 with 2 tasks
2021-12-04 17:32:25,296 [dispatcher-event-loop-4] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 6.0 (TID 12, localhost, executor driver, partition 0, ANY, 7885 bytes)
2021-12-04 17:32:25,296 [dispatcher-event-loop-4] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 6.0 (TID 13, localhost, executor driver, partition 1, ANY, 7885 bytes)
2021-12-04 17:32:25,296 [Executor task launch worker for task 13] INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 6.0 (TID 13)
2021-12-04 17:32:25,296 [Executor task launch worker for task 12] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 6.0 (TID 12)
2021-12-04 17:32:25,297 [Executor task launch worker for task 13] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/order_data.bcp:3442194+3442195
2021-12-04 17:32:25,297 [Executor task launch worker for task 12] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/order_data.bcp:0+3442194
2021-12-04 17:32:25,630 [Executor task launch worker for task 13] INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 6.0 (TID 13). 946 bytes result sent to driver
2021-12-04 17:32:25,631 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 6.0 (TID 13) in 335 ms on localhost (executor driver) (1/2)
2021-12-04 17:32:25,671 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 130
2021-12-04 17:32:25,671 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 107
2021-12-04 17:32:25,671 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 134
2021-12-04 17:32:25,672 [dispatcher-event-loop-9] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_5_piece0 on qb:60226 in memory (size: 2.9 KB, free: 1990.8 MB)
2021-12-04 17:32:25,673 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 108
2021-12-04 17:32:25,673 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 142
2021-12-04 17:32:25,673 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 118
2021-12-04 17:32:25,673 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 117
2021-12-04 17:32:25,673 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 105
2021-12-04 17:32:25,673 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 121
2021-12-04 17:32:25,673 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 138
2021-12-04 17:32:25,673 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 141
2021-12-04 17:32:25,673 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 125
2021-12-04 17:32:25,673 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 131
2021-12-04 17:32:25,673 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 132
2021-12-04 17:32:25,673 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 119
2021-12-04 17:32:25,673 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 147
2021-12-04 17:32:25,673 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 135
2021-12-04 17:32:25,674 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 149
2021-12-04 17:32:25,674 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 110
2021-12-04 17:32:25,674 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 113
2021-12-04 17:32:25,674 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 109
2021-12-04 17:32:25,674 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 116
2021-12-04 17:32:25,674 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 140
2021-12-04 17:32:25,674 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 122
2021-12-04 17:32:25,674 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 102
2021-12-04 17:32:25,674 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 103
2021-12-04 17:32:25,674 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 101
2021-12-04 17:32:25,674 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 114
2021-12-04 17:32:25,674 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 120
2021-12-04 17:32:25,674 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 112
2021-12-04 17:32:25,674 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 124
2021-12-04 17:32:25,675 [dispatcher-event-loop-0] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_6_piece0 on qb:60226 in memory (size: 2.2 KB, free: 1990.8 MB)
2021-12-04 17:32:25,675 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 129
2021-12-04 17:32:25,675 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 145
2021-12-04 17:32:25,675 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 127
2021-12-04 17:32:25,675 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 144
2021-12-04 17:32:25,675 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 123
2021-12-04 17:32:25,675 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 100
2021-12-04 17:32:25,675 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 104
2021-12-04 17:32:25,675 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 106
2021-12-04 17:32:25,675 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 126
2021-12-04 17:32:25,675 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 115
2021-12-04 17:32:25,675 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 128
2021-12-04 17:32:25,675 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 133
2021-12-04 17:32:25,675 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 137
2021-12-04 17:32:25,675 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 111
2021-12-04 17:32:25,675 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 143
2021-12-04 17:32:25,675 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 146
2021-12-04 17:32:25,675 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 148
2021-12-04 17:32:25,675 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 136
2021-12-04 17:32:25,675 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 139
2021-12-04 17:32:25,923 [Executor task launch worker for task 12] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 6.0 (TID 12). 989 bytes result sent to driver
2021-12-04 17:32:25,923 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 6.0 (TID 12) in 627 ms on localhost (executor driver) (2/2)
2021-12-04 17:32:25,923 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 6.0, whose tasks have all completed, from pool 
2021-12-04 17:32:25,924 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ShuffleMapStage 6 (distinct at PaidPromotionAdjustParameter.scala:129) finished in 0.633 s
2021-12-04 17:32:25,924 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - looking for newly runnable stages
2021-12-04 17:32:25,924 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - running: Set()
2021-12-04 17:32:25,924 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - waiting: Set(ResultStage 7)
2021-12-04 17:32:25,924 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - failed: Set()
2021-12-04 17:32:25,924 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 7 (MapPartitionsRDD[12] at distinct at PaidPromotionAdjustParameter.scala:129), which has no missing parents
2021-12-04 17:32:25,925 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_8 stored as values in memory (estimated size 3.7 KB, free 1990.5 MB)
2021-12-04 17:32:25,927 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_8_piece0 stored as bytes in memory (estimated size 2.2 KB, free 1990.5 MB)
2021-12-04 17:32:25,928 [dispatcher-event-loop-1] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_8_piece0 in memory on qb:60226 (size: 2.2 KB, free: 1990.8 MB)
2021-12-04 17:32:25,928 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 8 from broadcast at DAGScheduler.scala:1039
2021-12-04 17:32:25,929 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from ResultStage 7 (MapPartitionsRDD[12] at distinct at PaidPromotionAdjustParameter.scala:129) (first 15 tasks are for partitions Vector(0, 1))
2021-12-04 17:32:25,929 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 7.0 with 2 tasks
2021-12-04 17:32:25,929 [dispatcher-event-loop-4] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 7.0 (TID 14, localhost, executor driver, partition 0, ANY, 7649 bytes)
2021-12-04 17:32:25,929 [dispatcher-event-loop-4] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 7.0 (TID 15, localhost, executor driver, partition 1, ANY, 7649 bytes)
2021-12-04 17:32:25,929 [Executor task launch worker for task 14] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 7.0 (TID 14)
2021-12-04 17:32:25,929 [Executor task launch worker for task 15] INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 7.0 (TID 15)
2021-12-04 17:32:25,931 [Executor task launch worker for task 15] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 2 non-empty blocks out of 2 blocks
2021-12-04 17:32:25,931 [Executor task launch worker for task 15] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-04 17:32:25,931 [Executor task launch worker for task 14] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 2 non-empty blocks out of 2 blocks
2021-12-04 17:32:25,932 [Executor task launch worker for task 14] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 1 ms
2021-12-04 17:32:25,973 [Executor task launch worker for task 14] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 7.0 (TID 14). 1055 bytes result sent to driver
2021-12-04 17:32:25,973 [Executor task launch worker for task 15] INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 7.0 (TID 15). 1055 bytes result sent to driver
2021-12-04 17:32:25,973 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 7.0 (TID 14) in 44 ms on localhost (executor driver) (1/2)
2021-12-04 17:32:25,973 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 7.0 (TID 15) in 44 ms on localhost (executor driver) (2/2)
2021-12-04 17:32:25,974 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 7.0, whose tasks have all completed, from pool 
2021-12-04 17:32:25,974 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 7 (count at PaidPromotionAdjustParameter.scala:139) finished in 0.050 s
2021-12-04 17:32:25,974 [main] INFO [org.apache.spark.scheduler.DAGScheduler] - Job 5 finished: count at PaidPromotionAdjustParameter.scala:139, took 0.685878 s
2021-12-04 17:32:25,975 [main] INFO [PaidPromotion$] - 验证集用户数 = 28899
2021-12-04 17:32:25,980 [main] INFO [org.apache.spark.SparkContext] - Starting job: count at PaidPromotionAdjustParameter.scala:140
2021-12-04 17:32:25,980 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 13 (intersection at PaidPromotionAdjustParameter.scala:130)
2021-12-04 17:32:25,981 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 14 (intersection at PaidPromotionAdjustParameter.scala:130)
2021-12-04 17:32:25,981 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 6 (count at PaidPromotionAdjustParameter.scala:140) with 2 output partitions
2021-12-04 17:32:25,981 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 12 (count at PaidPromotionAdjustParameter.scala:140)
2021-12-04 17:32:25,981 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 9, ShuffleMapStage 11)
2021-12-04 17:32:25,981 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List(ShuffleMapStage 9, ShuffleMapStage 11)
2021-12-04 17:32:25,981 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ShuffleMapStage 9 (MapPartitionsRDD[13] at intersection at PaidPromotionAdjustParameter.scala:130), which has no missing parents
2021-12-04 17:32:25,982 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_9 stored as values in memory (estimated size 4.0 KB, free 1990.5 MB)
2021-12-04 17:32:25,984 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_9_piece0 stored as bytes in memory (estimated size 2.3 KB, free 1990.4 MB)
2021-12-04 17:32:25,985 [dispatcher-event-loop-6] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_9_piece0 in memory on qb:60226 (size: 2.3 KB, free: 1990.8 MB)
2021-12-04 17:32:25,985 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 9 from broadcast at DAGScheduler.scala:1039
2021-12-04 17:32:25,986 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from ShuffleMapStage 9 (MapPartitionsRDD[13] at intersection at PaidPromotionAdjustParameter.scala:130) (first 15 tasks are for partitions Vector(0, 1))
2021-12-04 17:32:25,986 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 9.0 with 2 tasks
2021-12-04 17:32:25,986 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ShuffleMapStage 11 (MapPartitionsRDD[14] at intersection at PaidPromotionAdjustParameter.scala:130), which has no missing parents
2021-12-04 17:32:25,986 [dispatcher-event-loop-9] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 9.0 (TID 16, localhost, executor driver, partition 0, ANY, 7638 bytes)
2021-12-04 17:32:25,986 [dispatcher-event-loop-9] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 9.0 (TID 17, localhost, executor driver, partition 1, ANY, 7638 bytes)
2021-12-04 17:32:25,986 [Executor task launch worker for task 16] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 9.0 (TID 16)
2021-12-04 17:32:25,986 [Executor task launch worker for task 17] INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 9.0 (TID 17)
2021-12-04 17:32:25,987 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_10 stored as values in memory (estimated size 4.0 KB, free 1990.4 MB)
2021-12-04 17:32:25,988 [Executor task launch worker for task 17] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 2 non-empty blocks out of 2 blocks
2021-12-04 17:32:25,988 [Executor task launch worker for task 16] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 2 non-empty blocks out of 2 blocks
2021-12-04 17:32:25,988 [Executor task launch worker for task 17] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-04 17:32:25,988 [Executor task launch worker for task 16] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-04 17:32:25,989 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_10_piece0 stored as bytes in memory (estimated size 2.3 KB, free 1990.4 MB)
2021-12-04 17:32:25,990 [dispatcher-event-loop-0] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_10_piece0 in memory on qb:60226 (size: 2.3 KB, free: 1990.8 MB)
2021-12-04 17:32:25,991 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 10 from broadcast at DAGScheduler.scala:1039
2021-12-04 17:32:25,991 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from ShuffleMapStage 11 (MapPartitionsRDD[14] at intersection at PaidPromotionAdjustParameter.scala:130) (first 15 tasks are for partitions Vector(0, 1))
2021-12-04 17:32:25,991 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 11.0 with 2 tasks
2021-12-04 17:32:25,992 [dispatcher-event-loop-11] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 11.0 (TID 18, localhost, executor driver, partition 0, ANY, 7638 bytes)
2021-12-04 17:32:25,992 [dispatcher-event-loop-11] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 11.0 (TID 19, localhost, executor driver, partition 1, ANY, 7638 bytes)
2021-12-04 17:32:25,992 [Executor task launch worker for task 18] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 11.0 (TID 18)
2021-12-04 17:32:25,993 [Executor task launch worker for task 19] INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 11.0 (TID 19)
2021-12-04 17:32:25,994 [Executor task launch worker for task 18] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 2 non-empty blocks out of 2 blocks
2021-12-04 17:32:25,994 [Executor task launch worker for task 18] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-04 17:32:25,994 [Executor task launch worker for task 19] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 2 non-empty blocks out of 2 blocks
2021-12-04 17:32:25,994 [Executor task launch worker for task 19] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-04 17:32:26,062 [Executor task launch worker for task 19] INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 11.0 (TID 19). 1204 bytes result sent to driver
2021-12-04 17:32:26,062 [Executor task launch worker for task 18] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 11.0 (TID 18). 1204 bytes result sent to driver
2021-12-04 17:32:26,062 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 11.0 (TID 19) in 70 ms on localhost (executor driver) (1/2)
2021-12-04 17:32:26,063 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 11.0 (TID 18) in 71 ms on localhost (executor driver) (2/2)
2021-12-04 17:32:26,063 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 11.0, whose tasks have all completed, from pool 
2021-12-04 17:32:26,063 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ShuffleMapStage 11 (intersection at PaidPromotionAdjustParameter.scala:130) finished in 0.077 s
2021-12-04 17:32:26,063 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - looking for newly runnable stages
2021-12-04 17:32:26,063 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - running: Set(ShuffleMapStage 9)
2021-12-04 17:32:26,063 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - waiting: Set(ResultStage 12)
2021-12-04 17:32:26,063 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - failed: Set()
2021-12-04 17:32:26,078 [Executor task launch worker for task 16] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 9.0 (TID 16). 1204 bytes result sent to driver
2021-12-04 17:32:26,079 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 9.0 (TID 16) in 93 ms on localhost (executor driver) (1/2)
2021-12-04 17:32:26,080 [Executor task launch worker for task 17] INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 9.0 (TID 17). 1204 bytes result sent to driver
2021-12-04 17:32:26,080 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 9.0 (TID 17) in 94 ms on localhost (executor driver) (2/2)
2021-12-04 17:32:26,080 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 9.0, whose tasks have all completed, from pool 
2021-12-04 17:32:26,080 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ShuffleMapStage 9 (intersection at PaidPromotionAdjustParameter.scala:130) finished in 0.099 s
2021-12-04 17:32:26,080 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - looking for newly runnable stages
2021-12-04 17:32:26,081 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - running: Set()
2021-12-04 17:32:26,081 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - waiting: Set(ResultStage 12)
2021-12-04 17:32:26,081 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - failed: Set()
2021-12-04 17:32:26,081 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 12 (MapPartitionsRDD[18] at intersection at PaidPromotionAdjustParameter.scala:130), which has no missing parents
2021-12-04 17:32:26,082 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_11 stored as values in memory (estimated size 3.6 KB, free 1990.4 MB)
2021-12-04 17:32:26,085 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_11_piece0 stored as bytes in memory (estimated size 2.1 KB, free 1990.4 MB)
2021-12-04 17:32:26,085 [dispatcher-event-loop-6] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_11_piece0 in memory on qb:60226 (size: 2.1 KB, free: 1990.8 MB)
2021-12-04 17:32:26,086 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 11 from broadcast at DAGScheduler.scala:1039
2021-12-04 17:32:26,086 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from ResultStage 12 (MapPartitionsRDD[18] at intersection at PaidPromotionAdjustParameter.scala:130) (first 15 tasks are for partitions Vector(0, 1))
2021-12-04 17:32:26,086 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 12.0 with 2 tasks
2021-12-04 17:32:26,087 [dispatcher-event-loop-9] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 12.0 (TID 20, localhost, executor driver, partition 0, PROCESS_LOCAL, 7712 bytes)
2021-12-04 17:32:26,087 [dispatcher-event-loop-9] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 12.0 (TID 21, localhost, executor driver, partition 1, PROCESS_LOCAL, 7712 bytes)
2021-12-04 17:32:26,088 [Executor task launch worker for task 21] INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 12.0 (TID 21)
2021-12-04 17:32:26,088 [Executor task launch worker for task 20] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 12.0 (TID 20)
2021-12-04 17:32:26,090 [Executor task launch worker for task 20] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2021-12-04 17:32:26,090 [Executor task launch worker for task 21] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2021-12-04 17:32:26,090 [Executor task launch worker for task 20] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-04 17:32:26,090 [Executor task launch worker for task 21] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-04 17:32:26,093 [Executor task launch worker for task 20] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2021-12-04 17:32:26,093 [Executor task launch worker for task 21] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2021-12-04 17:32:26,093 [Executor task launch worker for task 20] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-04 17:32:26,093 [Executor task launch worker for task 21] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-04 17:32:26,225 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 183
2021-12-04 17:32:26,225 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 156
2021-12-04 17:32:26,226 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 180
2021-12-04 17:32:26,226 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 182
2021-12-04 17:32:26,226 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 190
2021-12-04 17:32:26,226 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 191
2021-12-04 17:32:26,226 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 185
2021-12-04 17:32:26,226 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 188
2021-12-04 17:32:26,227 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 184
2021-12-04 17:32:26,227 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 163
2021-12-04 17:32:26,227 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 193
2021-12-04 17:32:26,227 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 172
2021-12-04 17:32:26,227 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 167
2021-12-04 17:32:26,227 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 186
2021-12-04 17:32:26,227 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 179
2021-12-04 17:32:26,227 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 154
2021-12-04 17:32:26,227 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 166
2021-12-04 17:32:26,227 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 157
2021-12-04 17:32:26,227 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 171
2021-12-04 17:32:26,227 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 170
2021-12-04 17:32:26,227 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 175
2021-12-04 17:32:26,227 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 176
2021-12-04 17:32:26,227 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 162
2021-12-04 17:32:26,227 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 169
2021-12-04 17:32:26,227 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 173
2021-12-04 17:32:26,227 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 187
2021-12-04 17:32:26,227 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 165
2021-12-04 17:32:26,227 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 195
2021-12-04 17:32:26,228 [dispatcher-event-loop-1] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_9_piece0 on qb:60226 in memory (size: 2.3 KB, free: 1990.8 MB)
2021-12-04 17:32:26,229 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 194
2021-12-04 17:32:26,229 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 198
2021-12-04 17:32:26,229 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 168
2021-12-04 17:32:26,229 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 160
2021-12-04 17:32:26,229 [dispatcher-event-loop-3] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_10_piece0 on qb:60226 in memory (size: 2.3 KB, free: 1990.8 MB)
2021-12-04 17:32:26,229 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 159
2021-12-04 17:32:26,229 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 196
2021-12-04 17:32:26,229 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 152
2021-12-04 17:32:26,230 [dispatcher-event-loop-6] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_7_piece0 on qb:60226 in memory (size: 2.9 KB, free: 1990.8 MB)
2021-12-04 17:32:26,230 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 177
2021-12-04 17:32:26,230 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 197
2021-12-04 17:32:26,230 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 153
2021-12-04 17:32:26,230 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 174
2021-12-04 17:32:26,231 [dispatcher-event-loop-10] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_8_piece0 on qb:60226 in memory (size: 2.2 KB, free: 1990.8 MB)
2021-12-04 17:32:26,231 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 151
2021-12-04 17:32:26,231 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 199
2021-12-04 17:32:26,231 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 189
2021-12-04 17:32:26,231 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 158
2021-12-04 17:32:26,231 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 181
2021-12-04 17:32:26,231 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 150
2021-12-04 17:32:26,231 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 192
2021-12-04 17:32:26,231 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 178
2021-12-04 17:32:26,231 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 164
2021-12-04 17:32:26,231 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 161
2021-12-04 17:32:26,231 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 155
2021-12-04 17:32:26,278 [Executor task launch worker for task 21] INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 12.0 (TID 21). 1054 bytes result sent to driver
2021-12-04 17:32:26,278 [Executor task launch worker for task 20] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 12.0 (TID 20). 1054 bytes result sent to driver
2021-12-04 17:32:26,279 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 12.0 (TID 20) in 192 ms on localhost (executor driver) (1/2)
2021-12-04 17:32:26,279 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 12.0 (TID 21) in 192 ms on localhost (executor driver) (2/2)
2021-12-04 17:32:26,279 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 12.0, whose tasks have all completed, from pool 
2021-12-04 17:32:26,279 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 12 (count at PaidPromotionAdjustParameter.scala:140) finished in 0.198 s
2021-12-04 17:32:26,280 [main] INFO [org.apache.spark.scheduler.DAGScheduler] - Job 6 finished: count at PaidPromotionAdjustParameter.scala:140, took 0.299772 s
2021-12-04 17:32:26,280 [main] INFO [PaidPromotion$] - 共 同 用户数 = 4240
2021-12-04 17:32:26,282 [main] INFO [org.apache.spark.SparkContext] - Starting job: count at PaidPromotionAdjustParameter.scala:141
2021-12-04 17:32:26,283 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 20 (distinct at PaidPromotionAdjustParameter.scala:133)
2021-12-04 17:32:26,283 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 7 (count at PaidPromotionAdjustParameter.scala:141) with 2 output partitions
2021-12-04 17:32:26,283 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 14 (count at PaidPromotionAdjustParameter.scala:141)
2021-12-04 17:32:26,283 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 13)
2021-12-04 17:32:26,283 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List(ShuffleMapStage 13)
2021-12-04 17:32:26,283 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ShuffleMapStage 13 (MapPartitionsRDD[20] at distinct at PaidPromotionAdjustParameter.scala:133), which has no missing parents
2021-12-04 17:32:26,284 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_12 stored as values in memory (estimated size 5.2 KB, free 1990.5 MB)
2021-12-04 17:32:26,286 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_12_piece0 stored as bytes in memory (estimated size 2.9 KB, free 1990.5 MB)
2021-12-04 17:32:26,287 [dispatcher-event-loop-1] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_12_piece0 in memory on qb:60226 (size: 2.9 KB, free: 1990.8 MB)
2021-12-04 17:32:26,287 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 12 from broadcast at DAGScheduler.scala:1039
2021-12-04 17:32:26,288 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from ShuffleMapStage 13 (MapPartitionsRDD[20] at distinct at PaidPromotionAdjustParameter.scala:133) (first 15 tasks are for partitions Vector(0, 1))
2021-12-04 17:32:26,288 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 13.0 with 2 tasks
2021-12-04 17:32:26,288 [dispatcher-event-loop-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 13.0 (TID 22, localhost, executor driver, partition 0, ANY, 7885 bytes)
2021-12-04 17:32:26,288 [dispatcher-event-loop-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 13.0 (TID 23, localhost, executor driver, partition 1, ANY, 7885 bytes)
2021-12-04 17:32:26,289 [Executor task launch worker for task 22] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 13.0 (TID 22)
2021-12-04 17:32:26,289 [Executor task launch worker for task 23] INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 13.0 (TID 23)
2021-12-04 17:32:26,290 [Executor task launch worker for task 23] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/order_data.bcp:3442194+3442195
2021-12-04 17:32:26,290 [Executor task launch worker for task 22] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/order_data.bcp:0+3442194
2021-12-04 17:32:26,641 [Executor task launch worker for task 23] INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 13.0 (TID 23). 989 bytes result sent to driver
2021-12-04 17:32:26,641 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 13.0 (TID 23) in 353 ms on localhost (executor driver) (1/2)
2021-12-04 17:32:26,902 [Executor task launch worker for task 22] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 13.0 (TID 22). 989 bytes result sent to driver
2021-12-04 17:32:26,902 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 13.0 (TID 22) in 614 ms on localhost (executor driver) (2/2)
2021-12-04 17:32:26,902 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 13.0, whose tasks have all completed, from pool 
2021-12-04 17:32:26,903 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ShuffleMapStage 13 (distinct at PaidPromotionAdjustParameter.scala:133) finished in 0.619 s
2021-12-04 17:32:26,903 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - looking for newly runnable stages
2021-12-04 17:32:26,903 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - running: Set()
2021-12-04 17:32:26,903 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - waiting: Set(ResultStage 14)
2021-12-04 17:32:26,903 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - failed: Set()
2021-12-04 17:32:26,903 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 14 (MapPartitionsRDD[22] at distinct at PaidPromotionAdjustParameter.scala:133), which has no missing parents
2021-12-04 17:32:26,904 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_13 stored as values in memory (estimated size 3.7 KB, free 1990.5 MB)
2021-12-04 17:32:26,906 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_13_piece0 stored as bytes in memory (estimated size 2.2 KB, free 1990.4 MB)
2021-12-04 17:32:26,906 [dispatcher-event-loop-6] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_13_piece0 in memory on qb:60226 (size: 2.2 KB, free: 1990.8 MB)
2021-12-04 17:32:26,907 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 13 from broadcast at DAGScheduler.scala:1039
2021-12-04 17:32:26,907 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from ResultStage 14 (MapPartitionsRDD[22] at distinct at PaidPromotionAdjustParameter.scala:133) (first 15 tasks are for partitions Vector(0, 1))
2021-12-04 17:32:26,907 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 14.0 with 2 tasks
2021-12-04 17:32:26,907 [dispatcher-event-loop-8] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 14.0 (TID 24, localhost, executor driver, partition 0, ANY, 7649 bytes)
2021-12-04 17:32:26,907 [dispatcher-event-loop-8] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 14.0 (TID 25, localhost, executor driver, partition 1, ANY, 7649 bytes)
2021-12-04 17:32:26,908 [Executor task launch worker for task 24] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 14.0 (TID 24)
2021-12-04 17:32:26,908 [Executor task launch worker for task 25] INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 14.0 (TID 25)
2021-12-04 17:32:26,909 [Executor task launch worker for task 25] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 2 non-empty blocks out of 2 blocks
2021-12-04 17:32:26,909 [Executor task launch worker for task 24] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 2 non-empty blocks out of 2 blocks
2021-12-04 17:32:26,909 [Executor task launch worker for task 25] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-04 17:32:26,909 [Executor task launch worker for task 24] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-04 17:32:26,921 [Executor task launch worker for task 24] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 14.0 (TID 24). 1011 bytes result sent to driver
2021-12-04 17:32:26,921 [Executor task launch worker for task 25] INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 14.0 (TID 25). 967 bytes result sent to driver
2021-12-04 17:32:26,922 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 14.0 (TID 25) in 15 ms on localhost (executor driver) (1/2)
2021-12-04 17:32:26,922 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 14.0 (TID 24) in 15 ms on localhost (executor driver) (2/2)
2021-12-04 17:32:26,922 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 14.0, whose tasks have all completed, from pool 
2021-12-04 17:32:26,922 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 14 (count at PaidPromotionAdjustParameter.scala:141) finished in 0.019 s
2021-12-04 17:32:26,922 [main] INFO [org.apache.spark.scheduler.DAGScheduler] - Job 7 finished: count at PaidPromotionAdjustParameter.scala:141, took 0.639871 s
2021-12-04 17:32:26,923 [main] INFO [PaidPromotion$] - 训练集节目数 = 126
2021-12-04 17:32:26,925 [main] INFO [org.apache.spark.SparkContext] - Starting job: count at PaidPromotionAdjustParameter.scala:142
2021-12-04 17:32:26,926 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 24 (distinct at PaidPromotionAdjustParameter.scala:134)
2021-12-04 17:32:26,926 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 8 (count at PaidPromotionAdjustParameter.scala:142) with 2 output partitions
2021-12-04 17:32:26,926 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 16 (count at PaidPromotionAdjustParameter.scala:142)
2021-12-04 17:32:26,926 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 15)
2021-12-04 17:32:26,926 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List(ShuffleMapStage 15)
2021-12-04 17:32:26,926 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ShuffleMapStage 15 (MapPartitionsRDD[24] at distinct at PaidPromotionAdjustParameter.scala:134), which has no missing parents
2021-12-04 17:32:26,927 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_14 stored as values in memory (estimated size 5.2 KB, free 1990.4 MB)
2021-12-04 17:32:26,930 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_14_piece0 stored as bytes in memory (estimated size 2.9 KB, free 1990.4 MB)
2021-12-04 17:32:26,930 [dispatcher-event-loop-1] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_14_piece0 in memory on qb:60226 (size: 2.9 KB, free: 1990.8 MB)
2021-12-04 17:32:26,930 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 14 from broadcast at DAGScheduler.scala:1039
2021-12-04 17:32:26,931 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from ShuffleMapStage 15 (MapPartitionsRDD[24] at distinct at PaidPromotionAdjustParameter.scala:134) (first 15 tasks are for partitions Vector(0, 1))
2021-12-04 17:32:26,931 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 15.0 with 2 tasks
2021-12-04 17:32:26,931 [dispatcher-event-loop-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 15.0 (TID 26, localhost, executor driver, partition 0, ANY, 7885 bytes)
2021-12-04 17:32:26,932 [dispatcher-event-loop-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 15.0 (TID 27, localhost, executor driver, partition 1, ANY, 7885 bytes)
2021-12-04 17:32:26,932 [Executor task launch worker for task 27] INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 15.0 (TID 27)
2021-12-04 17:32:26,932 [Executor task launch worker for task 26] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 15.0 (TID 26)
2021-12-04 17:32:26,933 [Executor task launch worker for task 26] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/order_data.bcp:0+3442194
2021-12-04 17:32:26,933 [Executor task launch worker for task 27] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/order_data.bcp:3442194+3442195
2021-12-04 17:32:27,128 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 266
2021-12-04 17:32:27,128 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 254
2021-12-04 17:32:27,128 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 261
2021-12-04 17:32:27,128 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 312
2021-12-04 17:32:27,128 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 243
2021-12-04 17:32:27,128 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 294
2021-12-04 17:32:27,128 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 239
2021-12-04 17:32:27,128 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 324
2021-12-04 17:32:27,128 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 292
2021-12-04 17:32:27,128 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 227
2021-12-04 17:32:27,128 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 307
2021-12-04 17:32:27,128 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 276
2021-12-04 17:32:27,128 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 318
2021-12-04 17:32:27,128 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 235
2021-12-04 17:32:27,128 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 290
2021-12-04 17:32:27,128 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 257
2021-12-04 17:32:27,128 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 234
2021-12-04 17:32:27,128 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 278
2021-12-04 17:32:27,128 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 270
2021-12-04 17:32:27,128 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 212
2021-12-04 17:32:27,128 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 209
2021-12-04 17:32:27,128 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 264
2021-12-04 17:32:27,128 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 222
2021-12-04 17:32:27,128 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 260
2021-12-04 17:32:27,128 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 210
2021-12-04 17:32:27,128 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 228
2021-12-04 17:32:27,128 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 224
2021-12-04 17:32:27,128 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 246
2021-12-04 17:32:27,128 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 226
2021-12-04 17:32:27,129 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 286
2021-12-04 17:32:27,129 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 213
2021-12-04 17:32:27,129 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 220
2021-12-04 17:32:27,129 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 304
2021-12-04 17:32:27,129 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 223
2021-12-04 17:32:27,129 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 323
2021-12-04 17:32:27,129 [dispatcher-event-loop-6] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_11_piece0 on qb:60226 in memory (size: 2.1 KB, free: 1990.8 MB)
2021-12-04 17:32:27,130 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 268
2021-12-04 17:32:27,130 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 303
2021-12-04 17:32:27,130 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 208
2021-12-04 17:32:27,130 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 289
2021-12-04 17:32:27,130 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 273
2021-12-04 17:32:27,130 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 320
2021-12-04 17:32:27,130 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 232
2021-12-04 17:32:27,130 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 240
2021-12-04 17:32:27,130 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 301
2021-12-04 17:32:27,130 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 313
2021-12-04 17:32:27,130 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 242
2021-12-04 17:32:27,130 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 293
2021-12-04 17:32:27,130 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 221
2021-12-04 17:32:27,130 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 288
2021-12-04 17:32:27,130 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 259
2021-12-04 17:32:27,130 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 283
2021-12-04 17:32:27,130 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 281
2021-12-04 17:32:27,130 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 309
2021-12-04 17:32:27,130 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 211
2021-12-04 17:32:27,130 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 203
2021-12-04 17:32:27,130 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 236
2021-12-04 17:32:27,130 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 287
2021-12-04 17:32:27,130 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 308
2021-12-04 17:32:27,131 [dispatcher-event-loop-9] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_13_piece0 on qb:60226 in memory (size: 2.2 KB, free: 1990.8 MB)
2021-12-04 17:32:27,131 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 311
2021-12-04 17:32:27,131 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 319
2021-12-04 17:32:27,131 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 225
2021-12-04 17:32:27,131 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 244
2021-12-04 17:32:27,131 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 207
2021-12-04 17:32:27,131 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 265
2021-12-04 17:32:27,131 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 216
2021-12-04 17:32:27,131 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 231
2021-12-04 17:32:27,131 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 200
2021-12-04 17:32:27,131 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 238
2021-12-04 17:32:27,131 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 316
2021-12-04 17:32:27,131 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 253
2021-12-04 17:32:27,131 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 296
2021-12-04 17:32:27,132 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 310
2021-12-04 17:32:27,132 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 300
2021-12-04 17:32:27,132 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 298
2021-12-04 17:32:27,132 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 245
2021-12-04 17:32:27,132 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 201
2021-12-04 17:32:27,132 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 206
2021-12-04 17:32:27,132 [dispatcher-event-loop-1] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_12_piece0 on qb:60226 in memory (size: 2.9 KB, free: 1990.8 MB)
2021-12-04 17:32:27,132 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 302
2021-12-04 17:32:27,133 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 241
2021-12-04 17:32:27,133 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 247
2021-12-04 17:32:27,133 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 275
2021-12-04 17:32:27,133 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 282
2021-12-04 17:32:27,133 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 277
2021-12-04 17:32:27,133 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 279
2021-12-04 17:32:27,133 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 202
2021-12-04 17:32:27,133 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 230
2021-12-04 17:32:27,133 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 217
2021-12-04 17:32:27,133 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 204
2021-12-04 17:32:27,133 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 233
2021-12-04 17:32:27,133 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 256
2021-12-04 17:32:27,133 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 271
2021-12-04 17:32:27,133 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 262
2021-12-04 17:32:27,133 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 272
2021-12-04 17:32:27,133 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 237
2021-12-04 17:32:27,133 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 248
2021-12-04 17:32:27,133 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 218
2021-12-04 17:32:27,133 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 250
2021-12-04 17:32:27,133 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 284
2021-12-04 17:32:27,133 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 215
2021-12-04 17:32:27,133 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 258
2021-12-04 17:32:27,133 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 251
2021-12-04 17:32:27,133 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 305
2021-12-04 17:32:27,133 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 291
2021-12-04 17:32:27,133 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 205
2021-12-04 17:32:27,133 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 306
2021-12-04 17:32:27,133 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 297
2021-12-04 17:32:27,133 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 252
2021-12-04 17:32:27,133 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 274
2021-12-04 17:32:27,133 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 299
2021-12-04 17:32:27,133 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 229
2021-12-04 17:32:27,133 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 263
2021-12-04 17:32:27,133 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 315
2021-12-04 17:32:27,133 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 267
2021-12-04 17:32:27,133 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 295
2021-12-04 17:32:27,133 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 314
2021-12-04 17:32:27,133 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 269
2021-12-04 17:32:27,133 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 285
2021-12-04 17:32:27,133 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 322
2021-12-04 17:32:27,133 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 255
2021-12-04 17:32:27,133 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 214
2021-12-04 17:32:27,133 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 249
2021-12-04 17:32:27,133 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 321
2021-12-04 17:32:27,133 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 219
2021-12-04 17:32:27,133 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 317
2021-12-04 17:32:27,133 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 280
2021-12-04 17:32:27,281 [Executor task launch worker for task 27] INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 15.0 (TID 27). 1032 bytes result sent to driver
2021-12-04 17:32:27,281 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 15.0 (TID 27) in 350 ms on localhost (executor driver) (1/2)
2021-12-04 17:32:27,548 [Executor task launch worker for task 26] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 15.0 (TID 26). 1032 bytes result sent to driver
2021-12-04 17:32:27,548 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 15.0 (TID 26) in 617 ms on localhost (executor driver) (2/2)
2021-12-04 17:32:27,548 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 15.0, whose tasks have all completed, from pool 
2021-12-04 17:32:27,549 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ShuffleMapStage 15 (distinct at PaidPromotionAdjustParameter.scala:134) finished in 0.622 s
2021-12-04 17:32:27,549 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - looking for newly runnable stages
2021-12-04 17:32:27,549 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - running: Set()
2021-12-04 17:32:27,549 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - waiting: Set(ResultStage 16)
2021-12-04 17:32:27,549 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - failed: Set()
2021-12-04 17:32:27,549 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 16 (MapPartitionsRDD[26] at distinct at PaidPromotionAdjustParameter.scala:134), which has no missing parents
2021-12-04 17:32:27,550 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_15 stored as values in memory (estimated size 3.7 KB, free 1990.5 MB)
2021-12-04 17:32:27,552 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_15_piece0 stored as bytes in memory (estimated size 2.2 KB, free 1990.5 MB)
2021-12-04 17:32:27,552 [dispatcher-event-loop-3] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_15_piece0 in memory on qb:60226 (size: 2.2 KB, free: 1990.8 MB)
2021-12-04 17:32:27,552 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 15 from broadcast at DAGScheduler.scala:1039
2021-12-04 17:32:27,553 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from ResultStage 16 (MapPartitionsRDD[26] at distinct at PaidPromotionAdjustParameter.scala:134) (first 15 tasks are for partitions Vector(0, 1))
2021-12-04 17:32:27,553 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 16.0 with 2 tasks
2021-12-04 17:32:27,553 [dispatcher-event-loop-5] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 16.0 (TID 28, localhost, executor driver, partition 0, ANY, 7649 bytes)
2021-12-04 17:32:27,553 [dispatcher-event-loop-5] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 16.0 (TID 29, localhost, executor driver, partition 1, ANY, 7649 bytes)
2021-12-04 17:32:27,553 [Executor task launch worker for task 28] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 16.0 (TID 28)
2021-12-04 17:32:27,553 [Executor task launch worker for task 29] INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 16.0 (TID 29)
2021-12-04 17:32:27,554 [Executor task launch worker for task 28] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 2 non-empty blocks out of 2 blocks
2021-12-04 17:32:27,554 [Executor task launch worker for task 29] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 2 non-empty blocks out of 2 blocks
2021-12-04 17:32:27,554 [Executor task launch worker for task 28] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-04 17:32:27,554 [Executor task launch worker for task 29] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-04 17:32:27,566 [Executor task launch worker for task 28] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 16.0 (TID 28). 1010 bytes result sent to driver
2021-12-04 17:32:27,566 [Executor task launch worker for task 29] INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 16.0 (TID 29). 1010 bytes result sent to driver
2021-12-04 17:32:27,566 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 16.0 (TID 28) in 13 ms on localhost (executor driver) (1/2)
2021-12-04 17:32:27,566 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 16.0 (TID 29) in 13 ms on localhost (executor driver) (2/2)
2021-12-04 17:32:27,566 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 16.0, whose tasks have all completed, from pool 
2021-12-04 17:32:27,567 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 16 (count at PaidPromotionAdjustParameter.scala:142) finished in 0.018 s
2021-12-04 17:32:27,567 [main] INFO [org.apache.spark.scheduler.DAGScheduler] - Job 8 finished: count at PaidPromotionAdjustParameter.scala:142, took 0.641703 s
2021-12-04 17:32:27,567 [main] INFO [PaidPromotion$] - 验证集节目数 = 113
2021-12-04 17:32:27,569 [main] INFO [org.apache.spark.SparkContext] - Starting job: count at PaidPromotionAdjustParameter.scala:143
2021-12-04 17:32:27,570 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 28 (intersection at PaidPromotionAdjustParameter.scala:135)
2021-12-04 17:32:27,570 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 27 (intersection at PaidPromotionAdjustParameter.scala:135)
2021-12-04 17:32:27,570 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 9 (count at PaidPromotionAdjustParameter.scala:143) with 2 output partitions
2021-12-04 17:32:27,570 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 21 (count at PaidPromotionAdjustParameter.scala:143)
2021-12-04 17:32:27,570 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 20, ShuffleMapStage 18)
2021-12-04 17:32:27,570 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List(ShuffleMapStage 20, ShuffleMapStage 18)
2021-12-04 17:32:27,571 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ShuffleMapStage 18 (MapPartitionsRDD[28] at intersection at PaidPromotionAdjustParameter.scala:135), which has no missing parents
2021-12-04 17:32:27,571 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_16 stored as values in memory (estimated size 4.0 KB, free 1990.5 MB)
2021-12-04 17:32:27,573 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_16_piece0 stored as bytes in memory (estimated size 2.3 KB, free 1990.4 MB)
2021-12-04 17:32:27,574 [dispatcher-event-loop-9] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_16_piece0 in memory on qb:60226 (size: 2.3 KB, free: 1990.8 MB)
2021-12-04 17:32:27,574 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 16 from broadcast at DAGScheduler.scala:1039
2021-12-04 17:32:27,575 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from ShuffleMapStage 18 (MapPartitionsRDD[28] at intersection at PaidPromotionAdjustParameter.scala:135) (first 15 tasks are for partitions Vector(0, 1))
2021-12-04 17:32:27,575 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 18.0 with 2 tasks
2021-12-04 17:32:27,575 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ShuffleMapStage 20 (MapPartitionsRDD[27] at intersection at PaidPromotionAdjustParameter.scala:135), which has no missing parents
2021-12-04 17:32:27,575 [dispatcher-event-loop-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 18.0 (TID 30, localhost, executor driver, partition 0, ANY, 7638 bytes)
2021-12-04 17:32:27,575 [dispatcher-event-loop-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 18.0 (TID 31, localhost, executor driver, partition 1, ANY, 7638 bytes)
2021-12-04 17:32:27,575 [Executor task launch worker for task 30] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 18.0 (TID 30)
2021-12-04 17:32:27,575 [Executor task launch worker for task 31] INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 18.0 (TID 31)
2021-12-04 17:32:27,576 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_17 stored as values in memory (estimated size 4.0 KB, free 1990.4 MB)
2021-12-04 17:32:27,577 [Executor task launch worker for task 30] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 2 non-empty blocks out of 2 blocks
2021-12-04 17:32:27,577 [Executor task launch worker for task 30] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-04 17:32:27,577 [Executor task launch worker for task 31] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 2 non-empty blocks out of 2 blocks
2021-12-04 17:32:27,577 [Executor task launch worker for task 31] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-04 17:32:27,578 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_17_piece0 stored as bytes in memory (estimated size 2.3 KB, free 1990.4 MB)
2021-12-04 17:32:27,578 [dispatcher-event-loop-2] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_17_piece0 in memory on qb:60226 (size: 2.3 KB, free: 1990.8 MB)
2021-12-04 17:32:27,578 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 17 from broadcast at DAGScheduler.scala:1039
2021-12-04 17:32:27,578 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from ShuffleMapStage 20 (MapPartitionsRDD[27] at intersection at PaidPromotionAdjustParameter.scala:135) (first 15 tasks are for partitions Vector(0, 1))
2021-12-04 17:32:27,579 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 20.0 with 2 tasks
2021-12-04 17:32:27,579 [dispatcher-event-loop-4] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 20.0 (TID 32, localhost, executor driver, partition 0, ANY, 7638 bytes)
2021-12-04 17:32:27,579 [dispatcher-event-loop-4] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 20.0 (TID 33, localhost, executor driver, partition 1, ANY, 7638 bytes)
2021-12-04 17:32:27,579 [Executor task launch worker for task 32] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 20.0 (TID 32)
2021-12-04 17:32:27,579 [Executor task launch worker for task 33] INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 20.0 (TID 33)
2021-12-04 17:32:27,580 [Executor task launch worker for task 32] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 2 non-empty blocks out of 2 blocks
2021-12-04 17:32:27,580 [Executor task launch worker for task 32] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-04 17:32:27,580 [Executor task launch worker for task 33] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 2 non-empty blocks out of 2 blocks
2021-12-04 17:32:27,580 [Executor task launch worker for task 33] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-04 17:32:27,591 [Executor task launch worker for task 30] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 18.0 (TID 30). 1161 bytes result sent to driver
2021-12-04 17:32:27,591 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 18.0 (TID 30) in 16 ms on localhost (executor driver) (1/2)
2021-12-04 17:32:27,592 [Executor task launch worker for task 31] INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 18.0 (TID 31). 1204 bytes result sent to driver
2021-12-04 17:32:27,593 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 18.0 (TID 31) in 18 ms on localhost (executor driver) (2/2)
2021-12-04 17:32:27,593 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 18.0, whose tasks have all completed, from pool 
2021-12-04 17:32:27,593 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ShuffleMapStage 18 (intersection at PaidPromotionAdjustParameter.scala:135) finished in 0.022 s
2021-12-04 17:32:27,593 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - looking for newly runnable stages
2021-12-04 17:32:27,593 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - running: Set(ShuffleMapStage 20)
2021-12-04 17:32:27,593 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - waiting: Set(ResultStage 21)
2021-12-04 17:32:27,593 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - failed: Set()
2021-12-04 17:32:27,596 [Executor task launch worker for task 33] INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 20.0 (TID 33). 1118 bytes result sent to driver
2021-12-04 17:32:27,596 [Executor task launch worker for task 32] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 20.0 (TID 32). 1118 bytes result sent to driver
2021-12-04 17:32:27,596 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 20.0 (TID 33) in 17 ms on localhost (executor driver) (1/2)
2021-12-04 17:32:27,596 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 20.0 (TID 32) in 17 ms on localhost (executor driver) (2/2)
2021-12-04 17:32:27,596 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 20.0, whose tasks have all completed, from pool 
2021-12-04 17:32:27,596 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ShuffleMapStage 20 (intersection at PaidPromotionAdjustParameter.scala:135) finished in 0.021 s
2021-12-04 17:32:27,597 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - looking for newly runnable stages
2021-12-04 17:32:27,597 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - running: Set()
2021-12-04 17:32:27,597 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - waiting: Set(ResultStage 21)
2021-12-04 17:32:27,597 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - failed: Set()
2021-12-04 17:32:27,597 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 21 (MapPartitionsRDD[32] at intersection at PaidPromotionAdjustParameter.scala:135), which has no missing parents
2021-12-04 17:32:27,597 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_18 stored as values in memory (estimated size 3.6 KB, free 1990.4 MB)
2021-12-04 17:32:27,599 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_18_piece0 stored as bytes in memory (estimated size 2.1 KB, free 1990.4 MB)
2021-12-04 17:32:27,600 [dispatcher-event-loop-9] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_18_piece0 in memory on qb:60226 (size: 2.1 KB, free: 1990.8 MB)
2021-12-04 17:32:27,600 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 18 from broadcast at DAGScheduler.scala:1039
2021-12-04 17:32:27,600 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from ResultStage 21 (MapPartitionsRDD[32] at intersection at PaidPromotionAdjustParameter.scala:135) (first 15 tasks are for partitions Vector(0, 1))
2021-12-04 17:32:27,600 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 21.0 with 2 tasks
2021-12-04 17:32:27,601 [dispatcher-event-loop-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 21.0 (TID 34, localhost, executor driver, partition 0, PROCESS_LOCAL, 7712 bytes)
2021-12-04 17:32:27,601 [dispatcher-event-loop-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 21.0 (TID 35, localhost, executor driver, partition 1, PROCESS_LOCAL, 7712 bytes)
2021-12-04 17:32:27,601 [Executor task launch worker for task 35] INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 21.0 (TID 35)
2021-12-04 17:32:27,601 [Executor task launch worker for task 34] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 21.0 (TID 34)
2021-12-04 17:32:27,602 [Executor task launch worker for task 35] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2021-12-04 17:32:27,602 [Executor task launch worker for task 35] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-04 17:32:27,602 [Executor task launch worker for task 34] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2021-12-04 17:32:27,602 [Executor task launch worker for task 34] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-04 17:32:27,604 [Executor task launch worker for task 34] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2021-12-04 17:32:27,604 [Executor task launch worker for task 35] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2021-12-04 17:32:27,604 [Executor task launch worker for task 34] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-04 17:32:27,604 [Executor task launch worker for task 35] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-04 17:32:27,610 [Executor task launch worker for task 34] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 21.0 (TID 34). 1053 bytes result sent to driver
2021-12-04 17:32:27,610 [Executor task launch worker for task 35] INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 21.0 (TID 35). 1053 bytes result sent to driver
2021-12-04 17:32:27,611 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 21.0 (TID 35) in 10 ms on localhost (executor driver) (1/2)
2021-12-04 17:32:27,611 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 21.0 (TID 34) in 10 ms on localhost (executor driver) (2/2)
2021-12-04 17:32:27,611 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 21.0, whose tasks have all completed, from pool 
2021-12-04 17:32:27,611 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 21 (count at PaidPromotionAdjustParameter.scala:143) finished in 0.014 s
2021-12-04 17:32:27,612 [main] INFO [org.apache.spark.scheduler.DAGScheduler] - Job 9 finished: count at PaidPromotionAdjustParameter.scala:143, took 0.041923 s
2021-12-04 17:32:27,612 [main] INFO [PaidPromotion$] - 共 同 节目数 = 107
2021-12-04 17:32:27,622 [main] INFO [org.apache.spark.SparkContext] - Starting job: collect at PaidPromotionAdjustParameter.scala:146
2021-12-04 17:32:27,622 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 10 (collect at PaidPromotionAdjustParameter.scala:146) with 2 output partitions
2021-12-04 17:32:27,622 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 26 (collect at PaidPromotionAdjustParameter.scala:146)
2021-12-04 17:32:27,622 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 25, ShuffleMapStage 23)
2021-12-04 17:32:27,622 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2021-12-04 17:32:27,623 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 26 (MapPartitionsRDD[18] at intersection at PaidPromotionAdjustParameter.scala:130), which has no missing parents
2021-12-04 17:32:27,623 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_19 stored as values in memory (estimated size 3.8 KB, free 1990.4 MB)
2021-12-04 17:32:27,625 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_19_piece0 stored as bytes in memory (estimated size 2.2 KB, free 1990.4 MB)
2021-12-04 17:32:27,626 [dispatcher-event-loop-5] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_19_piece0 in memory on qb:60226 (size: 2.2 KB, free: 1990.8 MB)
2021-12-04 17:32:27,626 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 19 from broadcast at DAGScheduler.scala:1039
2021-12-04 17:32:27,626 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from ResultStage 26 (MapPartitionsRDD[18] at intersection at PaidPromotionAdjustParameter.scala:130) (first 15 tasks are for partitions Vector(0, 1))
2021-12-04 17:32:27,626 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 26.0 with 2 tasks
2021-12-04 17:32:27,627 [dispatcher-event-loop-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 26.0 (TID 36, localhost, executor driver, partition 0, PROCESS_LOCAL, 7712 bytes)
2021-12-04 17:32:27,627 [dispatcher-event-loop-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 26.0 (TID 37, localhost, executor driver, partition 1, PROCESS_LOCAL, 7712 bytes)
2021-12-04 17:32:27,627 [Executor task launch worker for task 37] INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 26.0 (TID 37)
2021-12-04 17:32:27,627 [Executor task launch worker for task 36] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 26.0 (TID 36)
2021-12-04 17:32:27,628 [Executor task launch worker for task 37] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2021-12-04 17:32:27,628 [Executor task launch worker for task 37] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-04 17:32:27,628 [Executor task launch worker for task 36] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2021-12-04 17:32:27,628 [Executor task launch worker for task 36] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-04 17:32:27,630 [Executor task launch worker for task 37] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2021-12-04 17:32:27,630 [Executor task launch worker for task 37] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 1 ms
2021-12-04 17:32:27,630 [Executor task launch worker for task 36] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2021-12-04 17:32:27,630 [Executor task launch worker for task 36] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-04 17:32:27,703 [Executor task launch worker for task 37] INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 26.0 (TID 37). 71797 bytes result sent to driver
2021-12-04 17:32:27,704 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 26.0 (TID 37) in 77 ms on localhost (executor driver) (1/2)
2021-12-04 17:32:27,704 [Executor task launch worker for task 36] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 26.0 (TID 36). 71000 bytes result sent to driver
2021-12-04 17:32:27,705 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 26.0 (TID 36) in 78 ms on localhost (executor driver) (2/2)
2021-12-04 17:32:27,705 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 26.0, whose tasks have all completed, from pool 
2021-12-04 17:32:27,705 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 26 (collect at PaidPromotionAdjustParameter.scala:146) finished in 0.082 s
2021-12-04 17:32:27,705 [main] INFO [org.apache.spark.scheduler.DAGScheduler] - Job 10 finished: collect at PaidPromotionAdjustParameter.scala:146, took 0.083170 s
2021-12-04 17:32:27,710 [main] INFO [org.apache.spark.SparkContext] - Starting job: collect at PaidPromotionAdjustParameter.scala:147
2021-12-04 17:32:27,710 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 11 (collect at PaidPromotionAdjustParameter.scala:147) with 2 output partitions
2021-12-04 17:32:27,710 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 31 (collect at PaidPromotionAdjustParameter.scala:147)
2021-12-04 17:32:27,711 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 30, ShuffleMapStage 28)
2021-12-04 17:32:27,711 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2021-12-04 17:32:27,711 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 31 (MapPartitionsRDD[32] at intersection at PaidPromotionAdjustParameter.scala:135), which has no missing parents
2021-12-04 17:32:27,711 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_20 stored as values in memory (estimated size 3.8 KB, free 1990.4 MB)
2021-12-04 17:32:27,717 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 410
2021-12-04 17:32:27,717 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 361
2021-12-04 17:32:27,717 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 442
2021-12-04 17:32:27,717 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 473
2021-12-04 17:32:27,717 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 370
2021-12-04 17:32:27,717 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 373
2021-12-04 17:32:27,718 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 425
2021-12-04 17:32:27,718 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 465
2021-12-04 17:32:27,718 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 466
2021-12-04 17:32:27,718 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 413
2021-12-04 17:32:27,718 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 342
2021-12-04 17:32:27,718 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 387
2021-12-04 17:32:27,718 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_20_piece0 stored as bytes in memory (estimated size 2.2 KB, free 1990.4 MB)
2021-12-04 17:32:27,718 [dispatcher-event-loop-9] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_20_piece0 in memory on qb:60226 (size: 2.2 KB, free: 1990.8 MB)
2021-12-04 17:32:27,718 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 20 from broadcast at DAGScheduler.scala:1039
2021-12-04 17:32:27,718 [dispatcher-event-loop-11] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_15_piece0 on qb:60226 in memory (size: 2.2 KB, free: 1990.8 MB)
2021-12-04 17:32:27,718 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from ResultStage 31 (MapPartitionsRDD[32] at intersection at PaidPromotionAdjustParameter.scala:135) (first 15 tasks are for partitions Vector(0, 1))
2021-12-04 17:32:27,718 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 31.0 with 2 tasks
2021-12-04 17:32:27,719 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 381
2021-12-04 17:32:27,719 [dispatcher-event-loop-5] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 31.0 (TID 38, localhost, executor driver, partition 0, PROCESS_LOCAL, 7712 bytes)
2021-12-04 17:32:27,719 [dispatcher-event-loop-5] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 31.0 (TID 39, localhost, executor driver, partition 1, PROCESS_LOCAL, 7712 bytes)
2021-12-04 17:32:27,719 [dispatcher-event-loop-3] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_17_piece0 on qb:60226 in memory (size: 2.3 KB, free: 1990.8 MB)
2021-12-04 17:32:27,719 [Executor task launch worker for task 38] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 31.0 (TID 38)
2021-12-04 17:32:27,719 [Executor task launch worker for task 39] INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 31.0 (TID 39)
2021-12-04 17:32:27,719 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 327
2021-12-04 17:32:27,719 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 431
2021-12-04 17:32:27,719 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 336
2021-12-04 17:32:27,719 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 408
2021-12-04 17:32:27,719 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 450
2021-12-04 17:32:27,719 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 347
2021-12-04 17:32:27,719 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 436
2021-12-04 17:32:27,720 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 400
2021-12-04 17:32:27,720 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 433
2021-12-04 17:32:27,720 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 344
2021-12-04 17:32:27,720 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 434
2021-12-04 17:32:27,720 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 449
2021-12-04 17:32:27,720 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 359
2021-12-04 17:32:27,720 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 403
2021-12-04 17:32:27,720 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 445
2021-12-04 17:32:27,720 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 458
2021-12-04 17:32:27,720 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 467
2021-12-04 17:32:27,720 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 350
2021-12-04 17:32:27,720 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 401
2021-12-04 17:32:27,720 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 409
2021-12-04 17:32:27,720 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 448
2021-12-04 17:32:27,720 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 398
2021-12-04 17:32:27,720 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 331
2021-12-04 17:32:27,720 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 405
2021-12-04 17:32:27,720 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 335
2021-12-04 17:32:27,720 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 358
2021-12-04 17:32:27,720 [Executor task launch worker for task 39] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2021-12-04 17:32:27,720 [Executor task launch worker for task 39] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-04 17:32:27,720 [Executor task launch worker for task 38] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2021-12-04 17:32:27,720 [Executor task launch worker for task 38] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-04 17:32:27,720 [dispatcher-event-loop-0] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_19_piece0 on qb:60226 in memory (size: 2.2 KB, free: 1990.8 MB)
2021-12-04 17:32:27,721 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 390
2021-12-04 17:32:27,721 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 355
2021-12-04 17:32:27,721 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 364
2021-12-04 17:32:27,721 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 365
2021-12-04 17:32:27,721 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 351
2021-12-04 17:32:27,721 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 325
2021-12-04 17:32:27,721 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 392
2021-12-04 17:32:27,721 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 404
2021-12-04 17:32:27,721 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 461
2021-12-04 17:32:27,721 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 356
2021-12-04 17:32:27,721 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 382
2021-12-04 17:32:27,721 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 383
2021-12-04 17:32:27,721 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 468
2021-12-04 17:32:27,721 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 415
2021-12-04 17:32:27,721 [dispatcher-event-loop-11] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_18_piece0 on qb:60226 in memory (size: 2.1 KB, free: 1990.8 MB)
2021-12-04 17:32:27,722 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 444
2021-12-04 17:32:27,722 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 348
2021-12-04 17:32:27,722 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 427
2021-12-04 17:32:27,722 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 369
2021-12-04 17:32:27,722 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 389
2021-12-04 17:32:27,722 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 367
2021-12-04 17:32:27,722 [Executor task launch worker for task 39] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2021-12-04 17:32:27,722 [Executor task launch worker for task 38] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2021-12-04 17:32:27,722 [Executor task launch worker for task 39] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-04 17:32:27,722 [Executor task launch worker for task 38] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-04 17:32:27,722 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 441
2021-12-04 17:32:27,722 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 406
2021-12-04 17:32:27,722 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 419
2021-12-04 17:32:27,722 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 418
2021-12-04 17:32:27,722 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 360
2021-12-04 17:32:27,722 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 421
2021-12-04 17:32:27,722 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 474
2021-12-04 17:32:27,722 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 375
2021-12-04 17:32:27,722 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 416
2021-12-04 17:32:27,722 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 426
2021-12-04 17:32:27,722 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 451
2021-12-04 17:32:27,722 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 341
2021-12-04 17:32:27,722 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 452
2021-12-04 17:32:27,722 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 329
2021-12-04 17:32:27,722 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 423
2021-12-04 17:32:27,722 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 453
2021-12-04 17:32:27,723 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 460
2021-12-04 17:32:27,723 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 437
2021-12-04 17:32:27,723 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 339
2021-12-04 17:32:27,723 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 447
2021-12-04 17:32:27,723 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 372
2021-12-04 17:32:27,723 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 379
2021-12-04 17:32:27,723 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 357
2021-12-04 17:32:27,723 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 368
2021-12-04 17:32:27,723 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 391
2021-12-04 17:32:27,723 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 346
2021-12-04 17:32:27,723 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 374
2021-12-04 17:32:27,723 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 438
2021-12-04 17:32:27,723 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 446
2021-12-04 17:32:27,723 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 420
2021-12-04 17:32:27,723 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 469
2021-12-04 17:32:27,723 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 463
2021-12-04 17:32:27,723 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 345
2021-12-04 17:32:27,723 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 377
2021-12-04 17:32:27,723 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 417
2021-12-04 17:32:27,723 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 435
2021-12-04 17:32:27,723 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 430
2021-12-04 17:32:27,723 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 395
2021-12-04 17:32:27,723 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 457
2021-12-04 17:32:27,723 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 462
2021-12-04 17:32:27,723 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 378
2021-12-04 17:32:27,723 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 334
2021-12-04 17:32:27,723 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 412
2021-12-04 17:32:27,723 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 332
2021-12-04 17:32:27,723 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 411
2021-12-04 17:32:27,723 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 388
2021-12-04 17:32:27,723 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 376
2021-12-04 17:32:27,723 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 428
2021-12-04 17:32:27,723 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 353
2021-12-04 17:32:27,723 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 384
2021-12-04 17:32:27,723 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 349
2021-12-04 17:32:27,723 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 432
2021-12-04 17:32:27,723 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 429
2021-12-04 17:32:27,723 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 440
2021-12-04 17:32:27,724 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 330
2021-12-04 17:32:27,724 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 472
2021-12-04 17:32:27,724 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 386
2021-12-04 17:32:27,724 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 439
2021-12-04 17:32:27,724 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 397
2021-12-04 17:32:27,724 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 328
2021-12-04 17:32:27,724 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 385
2021-12-04 17:32:27,725 [dispatcher-event-loop-5] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_14_piece0 on qb:60226 in memory (size: 2.9 KB, free: 1990.8 MB)
2021-12-04 17:32:27,725 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 362
2021-12-04 17:32:27,725 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 456
2021-12-04 17:32:27,725 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 407
2021-12-04 17:32:27,725 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 394
2021-12-04 17:32:27,725 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 393
2021-12-04 17:32:27,725 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 399
2021-12-04 17:32:27,725 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 402
2021-12-04 17:32:27,725 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 326
2021-12-04 17:32:27,725 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 343
2021-12-04 17:32:27,725 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 380
2021-12-04 17:32:27,725 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 443
2021-12-04 17:32:27,725 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 352
2021-12-04 17:32:27,725 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 464
2021-12-04 17:32:27,725 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 424
2021-12-04 17:32:27,725 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 338
2021-12-04 17:32:27,725 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 366
2021-12-04 17:32:27,725 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 414
2021-12-04 17:32:27,725 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 470
2021-12-04 17:32:27,725 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 333
2021-12-04 17:32:27,725 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 422
2021-12-04 17:32:27,725 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 455
2021-12-04 17:32:27,725 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 340
2021-12-04 17:32:27,725 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 396
2021-12-04 17:32:27,725 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 354
2021-12-04 17:32:27,725 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 454
2021-12-04 17:32:27,725 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 459
2021-12-04 17:32:27,726 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 337
2021-12-04 17:32:27,726 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 371
2021-12-04 17:32:27,726 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 471
2021-12-04 17:32:27,726 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 363
2021-12-04 17:32:27,726 [dispatcher-event-loop-7] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_16_piece0 on qb:60226 in memory (size: 2.3 KB, free: 1990.8 MB)
2021-12-04 17:32:27,728 [Executor task launch worker for task 39] INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 31.0 (TID 39). 2509 bytes result sent to driver
2021-12-04 17:32:27,728 [Executor task launch worker for task 38] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 31.0 (TID 38). 2765 bytes result sent to driver
2021-12-04 17:32:27,728 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 31.0 (TID 39) in 9 ms on localhost (executor driver) (1/2)
2021-12-04 17:32:27,728 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 31.0 (TID 38) in 9 ms on localhost (executor driver) (2/2)
2021-12-04 17:32:27,728 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 31.0, whose tasks have all completed, from pool 
2021-12-04 17:32:27,729 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 31 (collect at PaidPromotionAdjustParameter.scala:147) finished in 0.018 s
2021-12-04 17:32:27,729 [main] INFO [org.apache.spark.scheduler.DAGScheduler] - Job 11 finished: collect at PaidPromotionAdjustParameter.scala:147, took 0.018900 s
2021-12-04 17:32:27,744 [main] INFO [org.apache.spark.SparkContext] - Starting job: count at PaidPromotionAdjustParameter.scala:156
2021-12-04 17:32:27,745 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 12 (count at PaidPromotionAdjustParameter.scala:156) with 4 output partitions
2021-12-04 17:32:27,745 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 32 (count at PaidPromotionAdjustParameter.scala:156)
2021-12-04 17:32:27,745 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List()
2021-12-04 17:32:27,745 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2021-12-04 17:32:27,746 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 32 (UnionRDD[35] at union at PaidPromotionAdjustParameter.scala:154), which has no missing parents
2021-12-04 17:32:27,753 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_21 stored as values in memory (estimated size 152.6 KB, free 1990.3 MB)
2021-12-04 17:32:27,755 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_21_piece0 stored as bytes in memory (estimated size 54.4 KB, free 1990.3 MB)
2021-12-04 17:32:27,755 [dispatcher-event-loop-0] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_21_piece0 in memory on qb:60226 (size: 54.4 KB, free: 1990.7 MB)
2021-12-04 17:32:27,756 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 21 from broadcast at DAGScheduler.scala:1039
2021-12-04 17:32:27,756 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 4 missing tasks from ResultStage 32 (UnionRDD[35] at union at PaidPromotionAdjustParameter.scala:154) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
2021-12-04 17:32:27,756 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 32.0 with 4 tasks
2021-12-04 17:32:27,757 [dispatcher-event-loop-9] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 32.0 (TID 40, localhost, executor driver, partition 0, ANY, 8005 bytes)
2021-12-04 17:32:27,758 [dispatcher-event-loop-9] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 32.0 (TID 41, localhost, executor driver, partition 1, ANY, 8005 bytes)
2021-12-04 17:32:27,758 [dispatcher-event-loop-9] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 2.0 in stage 32.0 (TID 42, localhost, executor driver, partition 2, ANY, 8005 bytes)
2021-12-04 17:32:27,758 [dispatcher-event-loop-9] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 3.0 in stage 32.0 (TID 43, localhost, executor driver, partition 3, ANY, 8005 bytes)
2021-12-04 17:32:27,758 [Executor task launch worker for task 40] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 32.0 (TID 40)
2021-12-04 17:32:27,758 [Executor task launch worker for task 43] INFO [org.apache.spark.executor.Executor] - Running task 3.0 in stage 32.0 (TID 43)
2021-12-04 17:32:27,758 [Executor task launch worker for task 42] INFO [org.apache.spark.executor.Executor] - Running task 2.0 in stage 32.0 (TID 42)
2021-12-04 17:32:27,758 [Executor task launch worker for task 41] INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 32.0 (TID 41)
2021-12-04 17:32:27,761 [Executor task launch worker for task 41] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/order_data.bcp:3442194+3442195
2021-12-04 17:32:27,762 [Executor task launch worker for task 43] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/order_data.bcp:3442194+3442195
2021-12-04 17:32:27,762 [Executor task launch worker for task 42] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/order_data.bcp:0+3442194
2021-12-04 17:32:27,762 [Executor task launch worker for task 40] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/order_data.bcp:0+3442194
2021-12-04 17:32:28,165 [Executor task launch worker for task 43] INFO [org.apache.spark.executor.Executor] - Finished task 3.0 in stage 32.0 (TID 43). 711 bytes result sent to driver
2021-12-04 17:32:28,166 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 3.0 in stage 32.0 (TID 43) in 407 ms on localhost (executor driver) (1/4)
2021-12-04 17:32:28,961 [Executor task launch worker for task 41] INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 32.0 (TID 41). 711 bytes result sent to driver
2021-12-04 17:32:28,961 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 32.0 (TID 41) in 1204 ms on localhost (executor driver) (2/4)
2021-12-04 17:32:28,965 [Executor task launch worker for task 40] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 32.0 (TID 40). 711 bytes result sent to driver
2021-12-04 17:32:28,965 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 32.0 (TID 40) in 1209 ms on localhost (executor driver) (3/4)
2021-12-04 17:32:28,977 [Executor task launch worker for task 42] INFO [org.apache.spark.executor.Executor] - Finished task 2.0 in stage 32.0 (TID 42). 754 bytes result sent to driver
2021-12-04 17:32:28,977 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 2.0 in stage 32.0 (TID 42) in 1219 ms on localhost (executor driver) (4/4)
2021-12-04 17:32:28,977 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 32.0, whose tasks have all completed, from pool 
2021-12-04 17:32:28,978 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 32 (count at PaidPromotionAdjustParameter.scala:156) finished in 1.231 s
2021-12-04 17:32:28,978 [main] INFO [org.apache.spark.scheduler.DAGScheduler] - Job 12 finished: count at PaidPromotionAdjustParameter.scala:156, took 1.234097 s
2021-12-04 17:32:28,978 [main] INFO [PaidPromotion$] - 最终训练集数量：102558
2021-12-04 17:32:28,980 [main] INFO [org.apache.spark.SparkContext] - Starting job: count at PaidPromotionAdjustParameter.scala:157
2021-12-04 17:32:28,980 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 13 (count at PaidPromotionAdjustParameter.scala:157) with 2 output partitions
2021-12-04 17:32:28,980 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 33 (count at PaidPromotionAdjustParameter.scala:157)
2021-12-04 17:32:28,980 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List()
2021-12-04 17:32:28,980 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2021-12-04 17:32:28,980 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 33 (MapPartitionsRDD[33] at filter at PaidPromotionAdjustParameter.scala:150), which has no missing parents
2021-12-04 17:32:28,983 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_22 stored as values in memory (estimated size 152.1 KB, free 1990.1 MB)
2021-12-04 17:32:28,988 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_22_piece0 stored as bytes in memory (estimated size 54.1 KB, free 1990.1 MB)
2021-12-04 17:32:28,988 [dispatcher-event-loop-8] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_22_piece0 in memory on qb:60226 (size: 54.1 KB, free: 1990.7 MB)
2021-12-04 17:32:28,988 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 22 from broadcast at DAGScheduler.scala:1039
2021-12-04 17:32:28,990 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from ResultStage 33 (MapPartitionsRDD[33] at filter at PaidPromotionAdjustParameter.scala:150) (first 15 tasks are for partitions Vector(0, 1))
2021-12-04 17:32:28,990 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 33.0 with 2 tasks
2021-12-04 17:32:28,990 [dispatcher-event-loop-10] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 33.0 (TID 44, localhost, executor driver, partition 0, ANY, 7896 bytes)
2021-12-04 17:32:28,990 [dispatcher-event-loop-10] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 33.0 (TID 45, localhost, executor driver, partition 1, ANY, 7896 bytes)
2021-12-04 17:32:28,990 [Executor task launch worker for task 45] INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 33.0 (TID 45)
2021-12-04 17:32:28,990 [Executor task launch worker for task 44] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 33.0 (TID 44)
2021-12-04 17:32:28,993 [Executor task launch worker for task 44] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/order_data.bcp:0+3442194
2021-12-04 17:32:28,993 [Executor task launch worker for task 45] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/order_data.bcp:3442194+3442195
2021-12-04 17:32:29,089 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 482
2021-12-04 17:32:29,089 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 475
2021-12-04 17:32:29,089 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 477
2021-12-04 17:32:29,089 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 496
2021-12-04 17:32:29,089 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 523
2021-12-04 17:32:29,089 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 509
2021-12-04 17:32:29,089 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 488
2021-12-04 17:32:29,089 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 500
2021-12-04 17:32:29,089 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 517
2021-12-04 17:32:29,089 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 486
2021-12-04 17:32:29,089 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 487
2021-12-04 17:32:29,089 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 501
2021-12-04 17:32:29,089 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 507
2021-12-04 17:32:29,089 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 497
2021-12-04 17:32:29,089 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 485
2021-12-04 17:32:29,089 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 498
2021-12-04 17:32:29,089 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 480
2021-12-04 17:32:29,089 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 494
2021-12-04 17:32:29,089 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 520
2021-12-04 17:32:29,089 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 493
2021-12-04 17:32:29,089 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 511
2021-12-04 17:32:29,089 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 518
2021-12-04 17:32:29,089 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 479
2021-12-04 17:32:29,090 [dispatcher-event-loop-4] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_21_piece0 on qb:60226 in memory (size: 54.4 KB, free: 1990.7 MB)
2021-12-04 17:32:29,090 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 516
2021-12-04 17:32:29,090 [dispatcher-event-loop-6] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_20_piece0 on qb:60226 in memory (size: 2.2 KB, free: 1990.7 MB)
2021-12-04 17:32:29,091 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 519
2021-12-04 17:32:29,091 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 489
2021-12-04 17:32:29,091 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 503
2021-12-04 17:32:29,091 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 512
2021-12-04 17:32:29,091 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 510
2021-12-04 17:32:29,091 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 513
2021-12-04 17:32:29,091 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 508
2021-12-04 17:32:29,091 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 515
2021-12-04 17:32:29,091 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 505
2021-12-04 17:32:29,091 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 481
2021-12-04 17:32:29,091 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 499
2021-12-04 17:32:29,091 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 504
2021-12-04 17:32:29,091 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 524
2021-12-04 17:32:29,091 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 495
2021-12-04 17:32:29,091 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 514
2021-12-04 17:32:29,091 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 490
2021-12-04 17:32:29,091 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 491
2021-12-04 17:32:29,091 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 502
2021-12-04 17:32:29,091 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 506
2021-12-04 17:32:29,091 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 492
2021-12-04 17:32:29,091 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 476
2021-12-04 17:32:29,091 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 522
2021-12-04 17:32:29,091 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 483
2021-12-04 17:32:29,091 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 521
2021-12-04 17:32:29,091 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 478
2021-12-04 17:32:29,091 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 484
2021-12-04 17:32:29,508 [Executor task launch worker for task 44] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 33.0 (TID 44). 753 bytes result sent to driver
2021-12-04 17:32:29,508 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 33.0 (TID 44) in 518 ms on localhost (executor driver) (1/2)
2021-12-04 17:32:29,898 [Executor task launch worker for task 45] INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 33.0 (TID 45). 753 bytes result sent to driver
2021-12-04 17:32:29,898 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 33.0 (TID 45) in 908 ms on localhost (executor driver) (2/2)
2021-12-04 17:32:29,898 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 33.0, whose tasks have all completed, from pool 
2021-12-04 17:32:29,899 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 33 (count at PaidPromotionAdjustParameter.scala:157) finished in 0.919 s
2021-12-04 17:32:29,899 [main] INFO [org.apache.spark.scheduler.DAGScheduler] - Job 13 finished: count at PaidPromotionAdjustParameter.scala:157, took 0.918680 s
2021-12-04 17:32:29,899 [main] INFO [PaidPromotion$] - 最终验证集数量：4736
2021-12-04 17:32:29,931 [main] INFO [PaidPromotion$] - -----------------------------------
2021-12-04 17:32:29,933 [main] INFO [org.apache.spark.SparkContext] - Starting job: count at PaidPromotionAdjustParameter.scala:169
2021-12-04 17:32:29,933 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 37 (distinct at PaidPromotionAdjustParameter.scala:160)
2021-12-04 17:32:29,933 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 14 (count at PaidPromotionAdjustParameter.scala:169) with 4 output partitions
2021-12-04 17:32:29,933 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 35 (count at PaidPromotionAdjustParameter.scala:169)
2021-12-04 17:32:29,933 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 34)
2021-12-04 17:32:29,933 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List(ShuffleMapStage 34)
2021-12-04 17:32:29,933 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ShuffleMapStage 34 (MapPartitionsRDD[37] at distinct at PaidPromotionAdjustParameter.scala:160), which has no missing parents
2021-12-04 17:32:29,935 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_23 stored as values in memory (estimated size 154.2 KB, free 1990.1 MB)
2021-12-04 17:32:29,937 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_23_piece0 stored as bytes in memory (estimated size 55.4 KB, free 1990.1 MB)
2021-12-04 17:32:29,938 [dispatcher-event-loop-8] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_23_piece0 in memory on qb:60226 (size: 55.4 KB, free: 1990.7 MB)
2021-12-04 17:32:29,938 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 23 from broadcast at DAGScheduler.scala:1039
2021-12-04 17:32:29,938 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 4 missing tasks from ShuffleMapStage 34 (MapPartitionsRDD[37] at distinct at PaidPromotionAdjustParameter.scala:160) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
2021-12-04 17:32:29,938 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 34.0 with 4 tasks
2021-12-04 17:32:29,938 [dispatcher-event-loop-10] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 34.0 (TID 46, localhost, executor driver, partition 0, ANY, 7994 bytes)
2021-12-04 17:32:29,939 [dispatcher-event-loop-10] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 34.0 (TID 47, localhost, executor driver, partition 1, ANY, 7994 bytes)
2021-12-04 17:32:29,939 [dispatcher-event-loop-10] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 2.0 in stage 34.0 (TID 48, localhost, executor driver, partition 2, ANY, 7994 bytes)
2021-12-04 17:32:29,939 [dispatcher-event-loop-10] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 3.0 in stage 34.0 (TID 49, localhost, executor driver, partition 3, ANY, 7994 bytes)
2021-12-04 17:32:29,939 [Executor task launch worker for task 46] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 34.0 (TID 46)
2021-12-04 17:32:29,939 [Executor task launch worker for task 48] INFO [org.apache.spark.executor.Executor] - Running task 2.0 in stage 34.0 (TID 48)
2021-12-04 17:32:29,939 [Executor task launch worker for task 49] INFO [org.apache.spark.executor.Executor] - Running task 3.0 in stage 34.0 (TID 49)
2021-12-04 17:32:29,939 [Executor task launch worker for task 47] INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 34.0 (TID 47)
2021-12-04 17:32:29,942 [Executor task launch worker for task 49] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/order_data.bcp:3442194+3442195
2021-12-04 17:32:29,942 [Executor task launch worker for task 47] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/order_data.bcp:3442194+3442195
2021-12-04 17:32:29,942 [Executor task launch worker for task 46] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/order_data.bcp:0+3442194
2021-12-04 17:32:29,942 [Executor task launch worker for task 48] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/order_data.bcp:0+3442194
2021-12-04 17:32:30,583 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 536
2021-12-04 17:32:30,583 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 529
2021-12-04 17:32:30,583 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 545
2021-12-04 17:32:30,583 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 528
2021-12-04 17:32:30,583 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 532
2021-12-04 17:32:30,583 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 548
2021-12-04 17:32:30,583 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 546
2021-12-04 17:32:30,583 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 525
2021-12-04 17:32:30,583 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 549
2021-12-04 17:32:30,584 [dispatcher-event-loop-2] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_22_piece0 on qb:60226 in memory (size: 54.1 KB, free: 1990.7 MB)
2021-12-04 17:32:30,584 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 538
2021-12-04 17:32:30,584 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 540
2021-12-04 17:32:30,584 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 531
2021-12-04 17:32:30,584 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 543
2021-12-04 17:32:30,584 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 535
2021-12-04 17:32:30,584 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 527
2021-12-04 17:32:30,584 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 539
2021-12-04 17:32:30,584 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 526
2021-12-04 17:32:30,584 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 537
2021-12-04 17:32:30,584 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 542
2021-12-04 17:32:30,584 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 530
2021-12-04 17:32:30,584 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 534
2021-12-04 17:32:30,584 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 547
2021-12-04 17:32:30,584 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 533
2021-12-04 17:32:30,584 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 541
2021-12-04 17:32:30,584 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 544
2021-12-04 17:32:30,663 [Executor task launch worker for task 46] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 34.0 (TID 46). 1034 bytes result sent to driver
2021-12-04 17:32:30,664 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 34.0 (TID 46) in 726 ms on localhost (executor driver) (1/4)
2021-12-04 17:32:30,759 [Executor task launch worker for task 49] INFO [org.apache.spark.executor.Executor] - Finished task 3.0 in stage 34.0 (TID 49). 1034 bytes result sent to driver
2021-12-04 17:32:30,759 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 3.0 in stage 34.0 (TID 49) in 820 ms on localhost (executor driver) (2/4)
2021-12-04 17:32:31,131 [Executor task launch worker for task 48] INFO [org.apache.spark.executor.Executor] - Finished task 2.0 in stage 34.0 (TID 48). 1034 bytes result sent to driver
2021-12-04 17:32:31,131 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 2.0 in stage 34.0 (TID 48) in 1192 ms on localhost (executor driver) (3/4)
2021-12-04 17:32:31,214 [Executor task launch worker for task 47] INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 34.0 (TID 47). 1034 bytes result sent to driver
2021-12-04 17:32:31,214 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 34.0 (TID 47) in 1275 ms on localhost (executor driver) (4/4)
2021-12-04 17:32:31,214 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 34.0, whose tasks have all completed, from pool 
2021-12-04 17:32:31,215 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ShuffleMapStage 34 (distinct at PaidPromotionAdjustParameter.scala:160) finished in 1.281 s
2021-12-04 17:32:31,215 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - looking for newly runnable stages
2021-12-04 17:32:31,215 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - running: Set()
2021-12-04 17:32:31,215 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - waiting: Set(ResultStage 35)
2021-12-04 17:32:31,215 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - failed: Set()
2021-12-04 17:32:31,215 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 35 (MapPartitionsRDD[39] at distinct at PaidPromotionAdjustParameter.scala:160), which has no missing parents
2021-12-04 17:32:31,216 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_24 stored as values in memory (estimated size 3.7 KB, free 1990.3 MB)
2021-12-04 17:32:31,218 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_24_piece0 stored as bytes in memory (estimated size 2.2 KB, free 1990.3 MB)
2021-12-04 17:32:31,218 [dispatcher-event-loop-10] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_24_piece0 in memory on qb:60226 (size: 2.2 KB, free: 1990.7 MB)
2021-12-04 17:32:31,218 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 24 from broadcast at DAGScheduler.scala:1039
2021-12-04 17:32:31,218 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 4 missing tasks from ResultStage 35 (MapPartitionsRDD[39] at distinct at PaidPromotionAdjustParameter.scala:160) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
2021-12-04 17:32:31,218 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 35.0 with 4 tasks
2021-12-04 17:32:31,219 [dispatcher-event-loop-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 35.0 (TID 50, localhost, executor driver, partition 0, ANY, 7649 bytes)
2021-12-04 17:32:31,219 [dispatcher-event-loop-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 35.0 (TID 51, localhost, executor driver, partition 1, ANY, 7649 bytes)
2021-12-04 17:32:31,219 [dispatcher-event-loop-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 2.0 in stage 35.0 (TID 52, localhost, executor driver, partition 2, ANY, 7649 bytes)
2021-12-04 17:32:31,219 [dispatcher-event-loop-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 3.0 in stage 35.0 (TID 53, localhost, executor driver, partition 3, ANY, 7649 bytes)
2021-12-04 17:32:31,219 [Executor task launch worker for task 51] INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 35.0 (TID 51)
2021-12-04 17:32:31,219 [Executor task launch worker for task 53] INFO [org.apache.spark.executor.Executor] - Running task 3.0 in stage 35.0 (TID 53)
2021-12-04 17:32:31,219 [Executor task launch worker for task 50] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 35.0 (TID 50)
2021-12-04 17:32:31,219 [Executor task launch worker for task 52] INFO [org.apache.spark.executor.Executor] - Running task 2.0 in stage 35.0 (TID 52)
2021-12-04 17:32:31,220 [Executor task launch worker for task 53] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 4 non-empty blocks out of 4 blocks
2021-12-04 17:32:31,220 [Executor task launch worker for task 52] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 4 non-empty blocks out of 4 blocks
2021-12-04 17:32:31,220 [Executor task launch worker for task 53] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-04 17:32:31,220 [Executor task launch worker for task 51] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 4 non-empty blocks out of 4 blocks
2021-12-04 17:32:31,220 [Executor task launch worker for task 50] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 4 non-empty blocks out of 4 blocks
2021-12-04 17:32:31,220 [Executor task launch worker for task 51] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-04 17:32:31,220 [Executor task launch worker for task 52] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-04 17:32:31,220 [Executor task launch worker for task 50] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-04 17:32:31,261 [Executor task launch worker for task 52] INFO [org.apache.spark.executor.Executor] - Finished task 2.0 in stage 35.0 (TID 52). 1055 bytes result sent to driver
2021-12-04 17:32:31,261 [Executor task launch worker for task 51] INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 35.0 (TID 51). 1055 bytes result sent to driver
2021-12-04 17:32:31,261 [Executor task launch worker for task 53] INFO [org.apache.spark.executor.Executor] - Finished task 3.0 in stage 35.0 (TID 53). 1055 bytes result sent to driver
2021-12-04 17:32:31,261 [Executor task launch worker for task 50] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 35.0 (TID 50). 1055 bytes result sent to driver
2021-12-04 17:32:31,262 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 2.0 in stage 35.0 (TID 52) in 43 ms on localhost (executor driver) (1/4)
2021-12-04 17:32:31,262 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 3.0 in stage 35.0 (TID 53) in 43 ms on localhost (executor driver) (2/4)
2021-12-04 17:32:31,262 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 35.0 (TID 50) in 43 ms on localhost (executor driver) (3/4)
2021-12-04 17:32:31,262 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 35.0 (TID 51) in 43 ms on localhost (executor driver) (4/4)
2021-12-04 17:32:31,262 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 35.0, whose tasks have all completed, from pool 
2021-12-04 17:32:31,262 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 35 (count at PaidPromotionAdjustParameter.scala:169) finished in 0.047 s
2021-12-04 17:32:31,263 [main] INFO [org.apache.spark.scheduler.DAGScheduler] - Job 14 finished: count at PaidPromotionAdjustParameter.scala:169, took 1.330614 s
2021-12-04 17:32:31,263 [main] INFO [PaidPromotion$] - 最终训练集用户数 = 95323
2021-12-04 17:32:31,265 [main] INFO [org.apache.spark.SparkContext] - Starting job: count at PaidPromotionAdjustParameter.scala:170
2021-12-04 17:32:31,266 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 41 (distinct at PaidPromotionAdjustParameter.scala:161)
2021-12-04 17:32:31,266 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 15 (count at PaidPromotionAdjustParameter.scala:170) with 2 output partitions
2021-12-04 17:32:31,266 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 37 (count at PaidPromotionAdjustParameter.scala:170)
2021-12-04 17:32:31,266 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 36)
2021-12-04 17:32:31,266 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List(ShuffleMapStage 36)
2021-12-04 17:32:31,266 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ShuffleMapStage 36 (MapPartitionsRDD[41] at distinct at PaidPromotionAdjustParameter.scala:161), which has no missing parents
2021-12-04 17:32:31,267 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_25 stored as values in memory (estimated size 153.6 KB, free 1990.1 MB)
2021-12-04 17:32:31,269 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_25_piece0 stored as bytes in memory (estimated size 55.0 KB, free 1990.1 MB)
2021-12-04 17:32:31,270 [dispatcher-event-loop-7] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_25_piece0 in memory on qb:60226 (size: 55.0 KB, free: 1990.7 MB)
2021-12-04 17:32:31,270 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 25 from broadcast at DAGScheduler.scala:1039
2021-12-04 17:32:31,270 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from ShuffleMapStage 36 (MapPartitionsRDD[41] at distinct at PaidPromotionAdjustParameter.scala:161) (first 15 tasks are for partitions Vector(0, 1))
2021-12-04 17:32:31,270 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 36.0 with 2 tasks
2021-12-04 17:32:31,271 [dispatcher-event-loop-8] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 36.0 (TID 54, localhost, executor driver, partition 0, ANY, 7885 bytes)
2021-12-04 17:32:31,271 [dispatcher-event-loop-8] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 36.0 (TID 55, localhost, executor driver, partition 1, ANY, 7885 bytes)
2021-12-04 17:32:31,271 [Executor task launch worker for task 54] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 36.0 (TID 54)
2021-12-04 17:32:31,271 [Executor task launch worker for task 55] INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 36.0 (TID 55)
2021-12-04 17:32:31,273 [Executor task launch worker for task 54] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/order_data.bcp:0+3442194
2021-12-04 17:32:31,273 [Executor task launch worker for task 55] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/order_data.bcp:3442194+3442195
2021-12-04 17:32:31,866 [Executor task launch worker for task 55] INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 36.0 (TID 55). 989 bytes result sent to driver
2021-12-04 17:32:31,866 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 36.0 (TID 55) in 595 ms on localhost (executor driver) (1/2)
2021-12-04 17:32:31,907 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 597
2021-12-04 17:32:31,907 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 571
2021-12-04 17:32:31,907 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 598
2021-12-04 17:32:31,908 [dispatcher-event-loop-5] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_24_piece0 on qb:60226 in memory (size: 2.2 KB, free: 1990.7 MB)
2021-12-04 17:32:31,909 [dispatcher-event-loop-3] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_23_piece0 on qb:60226 in memory (size: 55.4 KB, free: 1990.7 MB)
2021-12-04 17:32:31,909 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 564
2021-12-04 17:32:31,909 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 589
2021-12-04 17:32:31,909 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 563
2021-12-04 17:32:31,909 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 599
2021-12-04 17:32:31,909 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 554
2021-12-04 17:32:31,909 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 581
2021-12-04 17:32:31,909 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 585
2021-12-04 17:32:31,909 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 552
2021-12-04 17:32:31,909 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 584
2021-12-04 17:32:31,909 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 588
2021-12-04 17:32:31,909 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 559
2021-12-04 17:32:31,909 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 578
2021-12-04 17:32:31,909 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 567
2021-12-04 17:32:31,909 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 556
2021-12-04 17:32:31,909 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 579
2021-12-04 17:32:31,909 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 568
2021-12-04 17:32:31,909 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 596
2021-12-04 17:32:31,909 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 550
2021-12-04 17:32:31,909 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 576
2021-12-04 17:32:31,909 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 580
2021-12-04 17:32:31,909 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 570
2021-12-04 17:32:31,909 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 565
2021-12-04 17:32:31,909 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 587
2021-12-04 17:32:31,909 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 592
2021-12-04 17:32:31,909 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 553
2021-12-04 17:32:31,909 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 569
2021-12-04 17:32:31,909 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 573
2021-12-04 17:32:31,909 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 590
2021-12-04 17:32:31,909 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 595
2021-12-04 17:32:31,909 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 574
2021-12-04 17:32:31,909 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 555
2021-12-04 17:32:31,909 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 572
2021-12-04 17:32:31,909 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 577
2021-12-04 17:32:31,909 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 593
2021-12-04 17:32:31,909 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 562
2021-12-04 17:32:31,909 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 583
2021-12-04 17:32:31,909 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 594
2021-12-04 17:32:31,909 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 591
2021-12-04 17:32:31,909 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 561
2021-12-04 17:32:31,909 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 558
2021-12-04 17:32:31,909 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 575
2021-12-04 17:32:31,909 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 557
2021-12-04 17:32:31,909 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 566
2021-12-04 17:32:31,909 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 582
2021-12-04 17:32:31,909 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 551
2021-12-04 17:32:31,909 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 560
2021-12-04 17:32:31,909 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 586
2021-12-04 17:32:31,916 [Executor task launch worker for task 54] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 36.0 (TID 54). 1032 bytes result sent to driver
2021-12-04 17:32:31,916 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 36.0 (TID 54) in 646 ms on localhost (executor driver) (2/2)
2021-12-04 17:32:31,916 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 36.0, whose tasks have all completed, from pool 
2021-12-04 17:32:31,916 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ShuffleMapStage 36 (distinct at PaidPromotionAdjustParameter.scala:161) finished in 0.650 s
2021-12-04 17:32:31,916 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - looking for newly runnable stages
2021-12-04 17:32:31,916 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - running: Set()
2021-12-04 17:32:31,916 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - waiting: Set(ResultStage 37)
2021-12-04 17:32:31,916 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - failed: Set()
2021-12-04 17:32:31,916 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 37 (MapPartitionsRDD[43] at distinct at PaidPromotionAdjustParameter.scala:161), which has no missing parents
2021-12-04 17:32:31,917 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_26 stored as values in memory (estimated size 3.7 KB, free 1990.3 MB)
2021-12-04 17:32:31,918 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_26_piece0 stored as bytes in memory (estimated size 2.2 KB, free 1990.3 MB)
2021-12-04 17:32:31,919 [dispatcher-event-loop-7] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_26_piece0 in memory on qb:60226 (size: 2.2 KB, free: 1990.7 MB)
2021-12-04 17:32:31,919 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 26 from broadcast at DAGScheduler.scala:1039
2021-12-04 17:32:31,919 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from ResultStage 37 (MapPartitionsRDD[43] at distinct at PaidPromotionAdjustParameter.scala:161) (first 15 tasks are for partitions Vector(0, 1))
2021-12-04 17:32:31,919 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 37.0 with 2 tasks
2021-12-04 17:32:31,919 [dispatcher-event-loop-8] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 37.0 (TID 56, localhost, executor driver, partition 0, ANY, 7649 bytes)
2021-12-04 17:32:31,920 [dispatcher-event-loop-8] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 37.0 (TID 57, localhost, executor driver, partition 1, ANY, 7649 bytes)
2021-12-04 17:32:31,920 [Executor task launch worker for task 57] INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 37.0 (TID 57)
2021-12-04 17:32:31,920 [Executor task launch worker for task 56] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 37.0 (TID 56)
2021-12-04 17:32:31,920 [Executor task launch worker for task 56] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 2 non-empty blocks out of 2 blocks
2021-12-04 17:32:31,921 [Executor task launch worker for task 56] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 1 ms
2021-12-04 17:32:31,921 [Executor task launch worker for task 57] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 2 non-empty blocks out of 2 blocks
2021-12-04 17:32:31,921 [Executor task launch worker for task 57] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 1 ms
2021-12-04 17:32:31,936 [Executor task launch worker for task 56] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 37.0 (TID 56). 1011 bytes result sent to driver
2021-12-04 17:32:31,936 [Executor task launch worker for task 57] INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 37.0 (TID 57). 1011 bytes result sent to driver
2021-12-04 17:32:31,936 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 37.0 (TID 56) in 17 ms on localhost (executor driver) (1/2)
2021-12-04 17:32:31,936 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 37.0 (TID 57) in 17 ms on localhost (executor driver) (2/2)
2021-12-04 17:32:31,936 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 37.0, whose tasks have all completed, from pool 
2021-12-04 17:32:31,936 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 37 (count at PaidPromotionAdjustParameter.scala:170) finished in 0.019 s
2021-12-04 17:32:31,937 [main] INFO [org.apache.spark.scheduler.DAGScheduler] - Job 15 finished: count at PaidPromotionAdjustParameter.scala:170, took 0.671607 s
2021-12-04 17:32:31,937 [main] INFO [PaidPromotion$] - 最终验证集用户数 = 4238
2021-12-04 17:32:31,939 [main] INFO [org.apache.spark.SparkContext] - Starting job: count at PaidPromotionAdjustParameter.scala:171
2021-12-04 17:32:31,940 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 44 (intersection at PaidPromotionAdjustParameter.scala:162)
2021-12-04 17:32:31,940 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 45 (intersection at PaidPromotionAdjustParameter.scala:162)
2021-12-04 17:32:31,940 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 16 (count at PaidPromotionAdjustParameter.scala:171) with 4 output partitions
2021-12-04 17:32:31,940 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 42 (count at PaidPromotionAdjustParameter.scala:171)
2021-12-04 17:32:31,940 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 39, ShuffleMapStage 41)
2021-12-04 17:32:31,940 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List(ShuffleMapStage 39, ShuffleMapStage 41)
2021-12-04 17:32:31,940 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ShuffleMapStage 39 (MapPartitionsRDD[44] at intersection at PaidPromotionAdjustParameter.scala:162), which has no missing parents
2021-12-04 17:32:31,941 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_27 stored as values in memory (estimated size 4.0 KB, free 1990.3 MB)
2021-12-04 17:32:31,943 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_27_piece0 stored as bytes in memory (estimated size 2.3 KB, free 1990.3 MB)
2021-12-04 17:32:31,943 [dispatcher-event-loop-1] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_27_piece0 in memory on qb:60226 (size: 2.3 KB, free: 1990.7 MB)
2021-12-04 17:32:31,944 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 27 from broadcast at DAGScheduler.scala:1039
2021-12-04 17:32:31,944 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 4 missing tasks from ShuffleMapStage 39 (MapPartitionsRDD[44] at intersection at PaidPromotionAdjustParameter.scala:162) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
2021-12-04 17:32:31,944 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 39.0 with 4 tasks
2021-12-04 17:32:31,944 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ShuffleMapStage 41 (MapPartitionsRDD[45] at intersection at PaidPromotionAdjustParameter.scala:162), which has no missing parents
2021-12-04 17:32:31,944 [dispatcher-event-loop-5] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 39.0 (TID 58, localhost, executor driver, partition 0, ANY, 7638 bytes)
2021-12-04 17:32:31,944 [dispatcher-event-loop-5] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 39.0 (TID 59, localhost, executor driver, partition 1, ANY, 7638 bytes)
2021-12-04 17:32:31,944 [dispatcher-event-loop-5] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 2.0 in stage 39.0 (TID 60, localhost, executor driver, partition 2, ANY, 7638 bytes)
2021-12-04 17:32:31,944 [dispatcher-event-loop-5] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 3.0 in stage 39.0 (TID 61, localhost, executor driver, partition 3, ANY, 7638 bytes)
2021-12-04 17:32:31,945 [Executor task launch worker for task 59] INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 39.0 (TID 59)
2021-12-04 17:32:31,945 [Executor task launch worker for task 58] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 39.0 (TID 58)
2021-12-04 17:32:31,945 [Executor task launch worker for task 60] INFO [org.apache.spark.executor.Executor] - Running task 2.0 in stage 39.0 (TID 60)
2021-12-04 17:32:31,945 [Executor task launch worker for task 61] INFO [org.apache.spark.executor.Executor] - Running task 3.0 in stage 39.0 (TID 61)
2021-12-04 17:32:31,945 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_28 stored as values in memory (estimated size 4.0 KB, free 1990.2 MB)
2021-12-04 17:32:31,945 [Executor task launch worker for task 61] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 4 non-empty blocks out of 4 blocks
2021-12-04 17:32:31,945 [Executor task launch worker for task 61] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-04 17:32:31,945 [Executor task launch worker for task 58] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 4 non-empty blocks out of 4 blocks
2021-12-04 17:32:31,946 [Executor task launch worker for task 58] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 1 ms
2021-12-04 17:32:31,946 [Executor task launch worker for task 59] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 4 non-empty blocks out of 4 blocks
2021-12-04 17:32:31,946 [Executor task launch worker for task 60] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 4 non-empty blocks out of 4 blocks
2021-12-04 17:32:31,946 [Executor task launch worker for task 60] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 1 ms
2021-12-04 17:32:31,946 [Executor task launch worker for task 59] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 1 ms
2021-12-04 17:32:31,947 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_28_piece0 stored as bytes in memory (estimated size 2.3 KB, free 1990.2 MB)
2021-12-04 17:32:31,947 [dispatcher-event-loop-7] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_28_piece0 in memory on qb:60226 (size: 2.3 KB, free: 1990.7 MB)
2021-12-04 17:32:31,948 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 28 from broadcast at DAGScheduler.scala:1039
2021-12-04 17:32:31,948 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from ShuffleMapStage 41 (MapPartitionsRDD[45] at intersection at PaidPromotionAdjustParameter.scala:162) (first 15 tasks are for partitions Vector(0, 1))
2021-12-04 17:32:31,948 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 41.0 with 2 tasks
2021-12-04 17:32:31,948 [dispatcher-event-loop-8] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 41.0 (TID 62, localhost, executor driver, partition 0, ANY, 7638 bytes)
2021-12-04 17:32:31,948 [dispatcher-event-loop-8] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 41.0 (TID 63, localhost, executor driver, partition 1, ANY, 7638 bytes)
2021-12-04 17:32:31,949 [Executor task launch worker for task 62] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 41.0 (TID 62)
2021-12-04 17:32:31,950 [Executor task launch worker for task 63] INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 41.0 (TID 63)
2021-12-04 17:32:31,951 [Executor task launch worker for task 62] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 2 non-empty blocks out of 2 blocks
2021-12-04 17:32:31,951 [Executor task launch worker for task 63] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 2 non-empty blocks out of 2 blocks
2021-12-04 17:32:31,951 [Executor task launch worker for task 62] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-04 17:32:31,951 [Executor task launch worker for task 63] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-04 17:32:31,984 [Executor task launch worker for task 63] INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 41.0 (TID 63). 1163 bytes result sent to driver
2021-12-04 17:32:31,984 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 41.0 (TID 63) in 36 ms on localhost (executor driver) (1/2)
2021-12-04 17:32:31,987 [Executor task launch worker for task 62] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 41.0 (TID 62). 1206 bytes result sent to driver
2021-12-04 17:32:31,987 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 41.0 (TID 62) in 39 ms on localhost (executor driver) (2/2)
2021-12-04 17:32:31,987 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 41.0, whose tasks have all completed, from pool 
2021-12-04 17:32:31,987 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ShuffleMapStage 41 (intersection at PaidPromotionAdjustParameter.scala:162) finished in 0.043 s
2021-12-04 17:32:31,987 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - looking for newly runnable stages
2021-12-04 17:32:31,987 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - running: Set(ShuffleMapStage 39)
2021-12-04 17:32:31,987 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - waiting: Set(ResultStage 42)
2021-12-04 17:32:31,987 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - failed: Set()
2021-12-04 17:32:32,001 [Executor task launch worker for task 61] INFO [org.apache.spark.executor.Executor] - Finished task 3.0 in stage 39.0 (TID 61). 1206 bytes result sent to driver
2021-12-04 17:32:32,001 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 3.0 in stage 39.0 (TID 61) in 57 ms on localhost (executor driver) (1/4)
2021-12-04 17:32:32,002 [Executor task launch worker for task 58] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 39.0 (TID 58). 1163 bytes result sent to driver
2021-12-04 17:32:32,002 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 39.0 (TID 58) in 58 ms on localhost (executor driver) (2/4)
2021-12-04 17:32:32,002 [Executor task launch worker for task 60] INFO [org.apache.spark.executor.Executor] - Finished task 2.0 in stage 39.0 (TID 60). 1163 bytes result sent to driver
2021-12-04 17:32:32,002 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 2.0 in stage 39.0 (TID 60) in 58 ms on localhost (executor driver) (3/4)
2021-12-04 17:32:32,003 [Executor task launch worker for task 59] INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 39.0 (TID 59). 1163 bytes result sent to driver
2021-12-04 17:32:32,004 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 39.0 (TID 59) in 60 ms on localhost (executor driver) (4/4)
2021-12-04 17:32:32,004 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 39.0, whose tasks have all completed, from pool 
2021-12-04 17:32:32,004 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ShuffleMapStage 39 (intersection at PaidPromotionAdjustParameter.scala:162) finished in 0.063 s
2021-12-04 17:32:32,004 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - looking for newly runnable stages
2021-12-04 17:32:32,004 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - running: Set()
2021-12-04 17:32:32,004 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - waiting: Set(ResultStage 42)
2021-12-04 17:32:32,004 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - failed: Set()
2021-12-04 17:32:32,004 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 42 (MapPartitionsRDD[49] at intersection at PaidPromotionAdjustParameter.scala:162), which has no missing parents
2021-12-04 17:32:32,004 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_29 stored as values in memory (estimated size 3.6 KB, free 1990.2 MB)
2021-12-04 17:32:32,006 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_29_piece0 stored as bytes in memory (estimated size 2.1 KB, free 1990.2 MB)
2021-12-04 17:32:32,006 [dispatcher-event-loop-4] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_29_piece0 in memory on qb:60226 (size: 2.1 KB, free: 1990.7 MB)
2021-12-04 17:32:32,006 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 29 from broadcast at DAGScheduler.scala:1039
2021-12-04 17:32:32,006 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 4 missing tasks from ResultStage 42 (MapPartitionsRDD[49] at intersection at PaidPromotionAdjustParameter.scala:162) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
2021-12-04 17:32:32,006 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 42.0 with 4 tasks
2021-12-04 17:32:32,007 [dispatcher-event-loop-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 42.0 (TID 64, localhost, executor driver, partition 0, PROCESS_LOCAL, 7712 bytes)
2021-12-04 17:32:32,007 [dispatcher-event-loop-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 42.0 (TID 65, localhost, executor driver, partition 1, PROCESS_LOCAL, 7712 bytes)
2021-12-04 17:32:32,007 [dispatcher-event-loop-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 2.0 in stage 42.0 (TID 66, localhost, executor driver, partition 2, PROCESS_LOCAL, 7712 bytes)
2021-12-04 17:32:32,007 [dispatcher-event-loop-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 3.0 in stage 42.0 (TID 67, localhost, executor driver, partition 3, PROCESS_LOCAL, 7712 bytes)
2021-12-04 17:32:32,007 [Executor task launch worker for task 67] INFO [org.apache.spark.executor.Executor] - Running task 3.0 in stage 42.0 (TID 67)
2021-12-04 17:32:32,007 [Executor task launch worker for task 65] INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 42.0 (TID 65)
2021-12-04 17:32:32,007 [Executor task launch worker for task 64] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 42.0 (TID 64)
2021-12-04 17:32:32,007 [Executor task launch worker for task 66] INFO [org.apache.spark.executor.Executor] - Running task 2.0 in stage 42.0 (TID 66)
2021-12-04 17:32:32,008 [Executor task launch worker for task 67] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 4 blocks
2021-12-04 17:32:32,008 [Executor task launch worker for task 66] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 4 blocks
2021-12-04 17:32:32,008 [Executor task launch worker for task 67] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-04 17:32:32,008 [Executor task launch worker for task 64] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 4 blocks
2021-12-04 17:32:32,008 [Executor task launch worker for task 65] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 4 blocks
2021-12-04 17:32:32,008 [Executor task launch worker for task 64] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-04 17:32:32,009 [Executor task launch worker for task 65] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 1 ms
2021-12-04 17:32:32,008 [Executor task launch worker for task 66] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-04 17:32:32,010 [Executor task launch worker for task 65] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2021-12-04 17:32:32,010 [Executor task launch worker for task 64] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2021-12-04 17:32:32,010 [Executor task launch worker for task 65] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-04 17:32:32,010 [Executor task launch worker for task 66] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2021-12-04 17:32:32,010 [Executor task launch worker for task 67] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2021-12-04 17:32:32,010 [Executor task launch worker for task 64] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-04 17:32:32,010 [Executor task launch worker for task 67] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-04 17:32:32,010 [Executor task launch worker for task 66] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-04 17:32:32,056 [Executor task launch worker for task 66] INFO [org.apache.spark.executor.Executor] - Finished task 2.0 in stage 42.0 (TID 66). 1054 bytes result sent to driver
2021-12-04 17:32:32,056 [Executor task launch worker for task 67] INFO [org.apache.spark.executor.Executor] - Finished task 3.0 in stage 42.0 (TID 67). 1054 bytes result sent to driver
2021-12-04 17:32:32,056 [Executor task launch worker for task 64] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 42.0 (TID 64). 1054 bytes result sent to driver
2021-12-04 17:32:32,056 [Executor task launch worker for task 65] INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 42.0 (TID 65). 1054 bytes result sent to driver
2021-12-04 17:32:32,056 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 2.0 in stage 42.0 (TID 66) in 49 ms on localhost (executor driver) (1/4)
2021-12-04 17:32:32,057 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 3.0 in stage 42.0 (TID 67) in 50 ms on localhost (executor driver) (2/4)
2021-12-04 17:32:32,057 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 42.0 (TID 64) in 50 ms on localhost (executor driver) (3/4)
2021-12-04 17:32:32,057 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 42.0 (TID 65) in 50 ms on localhost (executor driver) (4/4)
2021-12-04 17:32:32,057 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 42.0, whose tasks have all completed, from pool 
2021-12-04 17:32:32,057 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 42 (count at PaidPromotionAdjustParameter.scala:171) finished in 0.053 s
2021-12-04 17:32:32,057 [main] INFO [org.apache.spark.scheduler.DAGScheduler] - Job 16 finished: count at PaidPromotionAdjustParameter.scala:171, took 0.117400 s
2021-12-04 17:32:32,058 [main] INFO [PaidPromotion$] - 最终共 同 用户数 = 4238
2021-12-04 17:32:32,059 [main] INFO [org.apache.spark.SparkContext] - Starting job: count at PaidPromotionAdjustParameter.scala:172
2021-12-04 17:32:32,060 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 51 (distinct at PaidPromotionAdjustParameter.scala:164)
2021-12-04 17:32:32,060 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 17 (count at PaidPromotionAdjustParameter.scala:172) with 4 output partitions
2021-12-04 17:32:32,060 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 44 (count at PaidPromotionAdjustParameter.scala:172)
2021-12-04 17:32:32,060 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 43)
2021-12-04 17:32:32,060 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List(ShuffleMapStage 43)
2021-12-04 17:32:32,060 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ShuffleMapStage 43 (MapPartitionsRDD[51] at distinct at PaidPromotionAdjustParameter.scala:164), which has no missing parents
2021-12-04 17:32:32,062 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_30 stored as values in memory (estimated size 154.2 KB, free 1990.1 MB)
2021-12-04 17:32:32,063 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_30_piece0 stored as bytes in memory (estimated size 55.4 KB, free 1990.0 MB)
2021-12-04 17:32:32,064 [dispatcher-event-loop-6] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_30_piece0 in memory on qb:60226 (size: 55.4 KB, free: 1990.7 MB)
2021-12-04 17:32:32,064 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 30 from broadcast at DAGScheduler.scala:1039
2021-12-04 17:32:32,064 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 4 missing tasks from ShuffleMapStage 43 (MapPartitionsRDD[51] at distinct at PaidPromotionAdjustParameter.scala:164) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
2021-12-04 17:32:32,064 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 43.0 with 4 tasks
2021-12-04 17:32:32,064 [dispatcher-event-loop-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 43.0 (TID 68, localhost, executor driver, partition 0, ANY, 7994 bytes)
2021-12-04 17:32:32,065 [dispatcher-event-loop-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 43.0 (TID 69, localhost, executor driver, partition 1, ANY, 7994 bytes)
2021-12-04 17:32:32,065 [dispatcher-event-loop-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 2.0 in stage 43.0 (TID 70, localhost, executor driver, partition 2, ANY, 7994 bytes)
2021-12-04 17:32:32,065 [dispatcher-event-loop-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 3.0 in stage 43.0 (TID 71, localhost, executor driver, partition 3, ANY, 7994 bytes)
2021-12-04 17:32:32,065 [Executor task launch worker for task 69] INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 43.0 (TID 69)
2021-12-04 17:32:32,065 [Executor task launch worker for task 71] INFO [org.apache.spark.executor.Executor] - Running task 3.0 in stage 43.0 (TID 71)
2021-12-04 17:32:32,065 [Executor task launch worker for task 70] INFO [org.apache.spark.executor.Executor] - Running task 2.0 in stage 43.0 (TID 70)
2021-12-04 17:32:32,065 [Executor task launch worker for task 68] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 43.0 (TID 68)
2021-12-04 17:32:32,067 [Executor task launch worker for task 68] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/order_data.bcp:0+3442194
2021-12-04 17:32:32,067 [Executor task launch worker for task 69] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/order_data.bcp:3442194+3442195
2021-12-04 17:32:32,067 [Executor task launch worker for task 71] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/order_data.bcp:3442194+3442195
2021-12-04 17:32:32,067 [Executor task launch worker for task 70] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/order_data.bcp:0+3442194
2021-12-04 17:32:32,515 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 633
2021-12-04 17:32:32,515 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 712
2021-12-04 17:32:32,515 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 722
2021-12-04 17:32:32,515 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 668
2021-12-04 17:32:32,515 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 693
2021-12-04 17:32:32,515 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 639
2021-12-04 17:32:32,515 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 649
2021-12-04 17:32:32,515 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 637
2021-12-04 17:32:32,516 [dispatcher-event-loop-11] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_29_piece0 on qb:60226 in memory (size: 2.1 KB, free: 1990.7 MB)
2021-12-04 17:32:32,516 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 610
2021-12-04 17:32:32,516 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 621
2021-12-04 17:32:32,516 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 702
2021-12-04 17:32:32,516 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 682
2021-12-04 17:32:32,516 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 692
2021-12-04 17:32:32,516 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 681
2021-12-04 17:32:32,516 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 687
2021-12-04 17:32:32,516 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 645
2021-12-04 17:32:32,516 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 615
2021-12-04 17:32:32,516 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 629
2021-12-04 17:32:32,516 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 708
2021-12-04 17:32:32,516 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 655
2021-12-04 17:32:32,516 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 664
2021-12-04 17:32:32,516 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 625
2021-12-04 17:32:32,516 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 642
2021-12-04 17:32:32,516 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 661
2021-12-04 17:32:32,516 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 622
2021-12-04 17:32:32,516 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 602
2021-12-04 17:32:32,516 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 705
2021-12-04 17:32:32,516 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 670
2021-12-04 17:32:32,516 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 662
2021-12-04 17:32:32,516 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 689
2021-12-04 17:32:32,516 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 656
2021-12-04 17:32:32,516 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 717
2021-12-04 17:32:32,516 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 723
2021-12-04 17:32:32,516 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 620
2021-12-04 17:32:32,516 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 652
2021-12-04 17:32:32,516 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 654
2021-12-04 17:32:32,516 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 701
2021-12-04 17:32:32,516 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 600
2021-12-04 17:32:32,516 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 716
2021-12-04 17:32:32,516 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 631
2021-12-04 17:32:32,516 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 678
2021-12-04 17:32:32,516 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 699
2021-12-04 17:32:32,516 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 606
2021-12-04 17:32:32,516 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 636
2021-12-04 17:32:32,516 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 619
2021-12-04 17:32:32,516 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 685
2021-12-04 17:32:32,516 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 616
2021-12-04 17:32:32,517 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 667
2021-12-04 17:32:32,517 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 632
2021-12-04 17:32:32,517 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 653
2021-12-04 17:32:32,517 [dispatcher-event-loop-9] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_27_piece0 on qb:60226 in memory (size: 2.3 KB, free: 1990.7 MB)
2021-12-04 17:32:32,517 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 607
2021-12-04 17:32:32,517 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 675
2021-12-04 17:32:32,517 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 614
2021-12-04 17:32:32,517 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 688
2021-12-04 17:32:32,517 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 714
2021-12-04 17:32:32,517 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 694
2021-12-04 17:32:32,517 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 627
2021-12-04 17:32:32,517 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 719
2021-12-04 17:32:32,517 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 663
2021-12-04 17:32:32,517 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 672
2021-12-04 17:32:32,517 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 713
2021-12-04 17:32:32,518 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 641
2021-12-04 17:32:32,518 [dispatcher-event-loop-3] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_26_piece0 on qb:60226 in memory (size: 2.2 KB, free: 1990.7 MB)
2021-12-04 17:32:32,518 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 628
2021-12-04 17:32:32,518 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 638
2021-12-04 17:32:32,518 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 659
2021-12-04 17:32:32,518 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 677
2021-12-04 17:32:32,518 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 704
2021-12-04 17:32:32,518 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 618
2021-12-04 17:32:32,518 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 683
2021-12-04 17:32:32,518 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 700
2021-12-04 17:32:32,518 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 624
2021-12-04 17:32:32,518 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 647
2021-12-04 17:32:32,518 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 721
2021-12-04 17:32:32,518 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 617
2021-12-04 17:32:32,518 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 696
2021-12-04 17:32:32,518 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 718
2021-12-04 17:32:32,518 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 669
2021-12-04 17:32:32,518 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 630
2021-12-04 17:32:32,518 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 651
2021-12-04 17:32:32,518 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 612
2021-12-04 17:32:32,518 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 635
2021-12-04 17:32:32,518 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 658
2021-12-04 17:32:32,518 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 643
2021-12-04 17:32:32,518 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 711
2021-12-04 17:32:32,518 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 640
2021-12-04 17:32:32,518 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 623
2021-12-04 17:32:32,519 [dispatcher-event-loop-7] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_28_piece0 on qb:60226 in memory (size: 2.3 KB, free: 1990.7 MB)
2021-12-04 17:32:32,519 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 601
2021-12-04 17:32:32,519 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 644
2021-12-04 17:32:32,519 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 679
2021-12-04 17:32:32,519 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 706
2021-12-04 17:32:32,519 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 720
2021-12-04 17:32:32,519 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 698
2021-12-04 17:32:32,519 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 626
2021-12-04 17:32:32,519 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 674
2021-12-04 17:32:32,519 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 690
2021-12-04 17:32:32,519 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 673
2021-12-04 17:32:32,519 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 608
2021-12-04 17:32:32,519 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 650
2021-12-04 17:32:32,519 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 671
2021-12-04 17:32:32,519 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 603
2021-12-04 17:32:32,519 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 611
2021-12-04 17:32:32,519 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 657
2021-12-04 17:32:32,519 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 609
2021-12-04 17:32:32,519 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 605
2021-12-04 17:32:32,519 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 691
2021-12-04 17:32:32,519 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 613
2021-12-04 17:32:32,519 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 684
2021-12-04 17:32:32,519 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 724
2021-12-04 17:32:32,519 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 715
2021-12-04 17:32:32,519 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 634
2021-12-04 17:32:32,519 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 676
2021-12-04 17:32:32,519 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 604
2021-12-04 17:32:32,519 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 666
2021-12-04 17:32:32,520 [dispatcher-event-loop-11] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_25_piece0 on qb:60226 in memory (size: 55.0 KB, free: 1990.7 MB)
2021-12-04 17:32:32,520 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 660
2021-12-04 17:32:32,520 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 710
2021-12-04 17:32:32,520 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 707
2021-12-04 17:32:32,520 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 648
2021-12-04 17:32:32,520 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 695
2021-12-04 17:32:32,520 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 646
2021-12-04 17:32:32,520 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 665
2021-12-04 17:32:32,520 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 697
2021-12-04 17:32:32,520 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 680
2021-12-04 17:32:32,520 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 709
2021-12-04 17:32:32,520 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 686
2021-12-04 17:32:32,520 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 703
2021-12-04 17:32:32,755 [Executor task launch worker for task 69] INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 43.0 (TID 69). 1034 bytes result sent to driver
2021-12-04 17:32:32,756 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 43.0 (TID 69) in 692 ms on localhost (executor driver) (1/4)
2021-12-04 17:32:32,965 [Executor task launch worker for task 68] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 43.0 (TID 68). 1034 bytes result sent to driver
2021-12-04 17:32:32,965 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 43.0 (TID 68) in 901 ms on localhost (executor driver) (2/4)
2021-12-04 17:32:33,260 [Executor task launch worker for task 71] INFO [org.apache.spark.executor.Executor] - Finished task 3.0 in stage 43.0 (TID 71). 1034 bytes result sent to driver
2021-12-04 17:32:33,261 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 3.0 in stage 43.0 (TID 71) in 1196 ms on localhost (executor driver) (3/4)
2021-12-04 17:32:33,371 [Executor task launch worker for task 70] INFO [org.apache.spark.executor.Executor] - Finished task 2.0 in stage 43.0 (TID 70). 1034 bytes result sent to driver
2021-12-04 17:32:33,371 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 2.0 in stage 43.0 (TID 70) in 1306 ms on localhost (executor driver) (4/4)
2021-12-04 17:32:33,371 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 43.0, whose tasks have all completed, from pool 
2021-12-04 17:32:33,371 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ShuffleMapStage 43 (distinct at PaidPromotionAdjustParameter.scala:164) finished in 1.310 s
2021-12-04 17:32:33,372 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - looking for newly runnable stages
2021-12-04 17:32:33,372 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - running: Set()
2021-12-04 17:32:33,372 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - waiting: Set(ResultStage 44)
2021-12-04 17:32:33,372 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - failed: Set()
2021-12-04 17:32:33,372 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 44 (MapPartitionsRDD[53] at distinct at PaidPromotionAdjustParameter.scala:164), which has no missing parents
2021-12-04 17:32:33,373 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_31 stored as values in memory (estimated size 3.7 KB, free 1990.3 MB)
2021-12-04 17:32:33,374 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_31_piece0 stored as bytes in memory (estimated size 2.2 KB, free 1990.3 MB)
2021-12-04 17:32:33,375 [dispatcher-event-loop-6] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_31_piece0 in memory on qb:60226 (size: 2.2 KB, free: 1990.7 MB)
2021-12-04 17:32:33,375 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 31 from broadcast at DAGScheduler.scala:1039
2021-12-04 17:32:33,375 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 4 missing tasks from ResultStage 44 (MapPartitionsRDD[53] at distinct at PaidPromotionAdjustParameter.scala:164) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
2021-12-04 17:32:33,375 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 44.0 with 4 tasks
2021-12-04 17:32:33,376 [dispatcher-event-loop-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 44.0 (TID 72, localhost, executor driver, partition 0, ANY, 7649 bytes)
2021-12-04 17:32:33,376 [dispatcher-event-loop-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 44.0 (TID 73, localhost, executor driver, partition 1, ANY, 7649 bytes)
2021-12-04 17:32:33,376 [dispatcher-event-loop-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 2.0 in stage 44.0 (TID 74, localhost, executor driver, partition 2, ANY, 7649 bytes)
2021-12-04 17:32:33,376 [dispatcher-event-loop-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 3.0 in stage 44.0 (TID 75, localhost, executor driver, partition 3, ANY, 7649 bytes)
2021-12-04 17:32:33,376 [Executor task launch worker for task 72] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 44.0 (TID 72)
2021-12-04 17:32:33,376 [Executor task launch worker for task 73] INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 44.0 (TID 73)
2021-12-04 17:32:33,376 [Executor task launch worker for task 74] INFO [org.apache.spark.executor.Executor] - Running task 2.0 in stage 44.0 (TID 74)
2021-12-04 17:32:33,376 [Executor task launch worker for task 75] INFO [org.apache.spark.executor.Executor] - Running task 3.0 in stage 44.0 (TID 75)
2021-12-04 17:32:33,377 [Executor task launch worker for task 74] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 4 non-empty blocks out of 4 blocks
2021-12-04 17:32:33,377 [Executor task launch worker for task 75] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 4 non-empty blocks out of 4 blocks
2021-12-04 17:32:33,377 [Executor task launch worker for task 74] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-04 17:32:33,377 [Executor task launch worker for task 75] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-04 17:32:33,377 [Executor task launch worker for task 73] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 4 non-empty blocks out of 4 blocks
2021-12-04 17:32:33,377 [Executor task launch worker for task 72] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 4 non-empty blocks out of 4 blocks
2021-12-04 17:32:33,377 [Executor task launch worker for task 72] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-04 17:32:33,377 [Executor task launch worker for task 73] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-04 17:32:33,396 [Executor task launch worker for task 75] INFO [org.apache.spark.executor.Executor] - Finished task 3.0 in stage 44.0 (TID 75). 1053 bytes result sent to driver
2021-12-04 17:32:33,396 [Executor task launch worker for task 74] INFO [org.apache.spark.executor.Executor] - Finished task 2.0 in stage 44.0 (TID 74). 1053 bytes result sent to driver
2021-12-04 17:32:33,396 [Executor task launch worker for task 72] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 44.0 (TID 72). 1053 bytes result sent to driver
2021-12-04 17:32:33,396 [Executor task launch worker for task 73] INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 44.0 (TID 73). 1053 bytes result sent to driver
2021-12-04 17:32:33,396 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 3.0 in stage 44.0 (TID 75) in 20 ms on localhost (executor driver) (1/4)
2021-12-04 17:32:33,397 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 2.0 in stage 44.0 (TID 74) in 20 ms on localhost (executor driver) (2/4)
2021-12-04 17:32:33,397 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 44.0 (TID 72) in 22 ms on localhost (executor driver) (3/4)
2021-12-04 17:32:33,397 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 44.0 (TID 73) in 21 ms on localhost (executor driver) (4/4)
2021-12-04 17:32:33,397 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 44.0, whose tasks have all completed, from pool 
2021-12-04 17:32:33,397 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 44 (count at PaidPromotionAdjustParameter.scala:172) finished in 0.025 s
2021-12-04 17:32:33,397 [main] INFO [org.apache.spark.scheduler.DAGScheduler] - Job 17 finished: count at PaidPromotionAdjustParameter.scala:172, took 1.337267 s
2021-12-04 17:32:33,398 [main] INFO [PaidPromotion$] - 最终训练集节目数 = 132
2021-12-04 17:32:33,400 [main] INFO [org.apache.spark.SparkContext] - Starting job: count at PaidPromotionAdjustParameter.scala:173
2021-12-04 17:32:33,400 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 55 (distinct at PaidPromotionAdjustParameter.scala:165)
2021-12-04 17:32:33,400 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 18 (count at PaidPromotionAdjustParameter.scala:173) with 2 output partitions
2021-12-04 17:32:33,400 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 46 (count at PaidPromotionAdjustParameter.scala:173)
2021-12-04 17:32:33,400 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 45)
2021-12-04 17:32:33,400 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List(ShuffleMapStage 45)
2021-12-04 17:32:33,400 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ShuffleMapStage 45 (MapPartitionsRDD[55] at distinct at PaidPromotionAdjustParameter.scala:165), which has no missing parents
2021-12-04 17:32:33,402 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_32 stored as values in memory (estimated size 153.6 KB, free 1990.1 MB)
2021-12-04 17:32:33,404 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_32_piece0 stored as bytes in memory (estimated size 55.0 KB, free 1990.1 MB)
2021-12-04 17:32:33,404 [dispatcher-event-loop-9] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_32_piece0 in memory on qb:60226 (size: 55.0 KB, free: 1990.7 MB)
2021-12-04 17:32:33,404 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 32 from broadcast at DAGScheduler.scala:1039
2021-12-04 17:32:33,404 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from ShuffleMapStage 45 (MapPartitionsRDD[55] at distinct at PaidPromotionAdjustParameter.scala:165) (first 15 tasks are for partitions Vector(0, 1))
2021-12-04 17:32:33,404 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 45.0 with 2 tasks
2021-12-04 17:32:33,405 [dispatcher-event-loop-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 45.0 (TID 76, localhost, executor driver, partition 0, ANY, 7885 bytes)
2021-12-04 17:32:33,405 [dispatcher-event-loop-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 45.0 (TID 77, localhost, executor driver, partition 1, ANY, 7885 bytes)
2021-12-04 17:32:33,405 [Executor task launch worker for task 76] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 45.0 (TID 76)
2021-12-04 17:32:33,405 [Executor task launch worker for task 77] INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 45.0 (TID 77)
2021-12-04 17:32:33,407 [Executor task launch worker for task 77] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/order_data.bcp:3442194+3442195
2021-12-04 17:32:33,407 [Executor task launch worker for task 76] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/order_data.bcp:0+3442194
2021-12-04 17:32:33,924 [Executor task launch worker for task 76] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 45.0 (TID 76). 989 bytes result sent to driver
2021-12-04 17:32:33,924 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 45.0 (TID 76) in 519 ms on localhost (executor driver) (1/2)
2021-12-04 17:32:34,310 [Executor task launch worker for task 77] INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 45.0 (TID 77). 989 bytes result sent to driver
2021-12-04 17:32:34,310 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 45.0 (TID 77) in 905 ms on localhost (executor driver) (2/2)
2021-12-04 17:32:34,310 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 45.0, whose tasks have all completed, from pool 
2021-12-04 17:32:34,311 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ShuffleMapStage 45 (distinct at PaidPromotionAdjustParameter.scala:165) finished in 0.909 s
2021-12-04 17:32:34,311 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - looking for newly runnable stages
2021-12-04 17:32:34,311 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - running: Set()
2021-12-04 17:32:34,311 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - waiting: Set(ResultStage 46)
2021-12-04 17:32:34,311 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - failed: Set()
2021-12-04 17:32:34,311 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 46 (MapPartitionsRDD[57] at distinct at PaidPromotionAdjustParameter.scala:165), which has no missing parents
2021-12-04 17:32:34,311 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_33 stored as values in memory (estimated size 3.7 KB, free 1990.1 MB)
2021-12-04 17:32:34,313 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_33_piece0 stored as bytes in memory (estimated size 2.2 KB, free 1990.0 MB)
2021-12-04 17:32:34,313 [dispatcher-event-loop-7] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_33_piece0 in memory on qb:60226 (size: 2.2 KB, free: 1990.7 MB)
2021-12-04 17:32:34,313 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 33 from broadcast at DAGScheduler.scala:1039
2021-12-04 17:32:34,313 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from ResultStage 46 (MapPartitionsRDD[57] at distinct at PaidPromotionAdjustParameter.scala:165) (first 15 tasks are for partitions Vector(0, 1))
2021-12-04 17:32:34,313 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 46.0 with 2 tasks
2021-12-04 17:32:34,314 [dispatcher-event-loop-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 46.0 (TID 78, localhost, executor driver, partition 0, ANY, 7649 bytes)
2021-12-04 17:32:34,314 [dispatcher-event-loop-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 46.0 (TID 79, localhost, executor driver, partition 1, ANY, 7649 bytes)
2021-12-04 17:32:34,314 [Executor task launch worker for task 79] INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 46.0 (TID 79)
2021-12-04 17:32:34,314 [Executor task launch worker for task 78] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 46.0 (TID 78)
2021-12-04 17:32:34,317 [Executor task launch worker for task 78] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 2 non-empty blocks out of 2 blocks
2021-12-04 17:32:34,317 [Executor task launch worker for task 78] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-04 17:32:34,317 [Executor task launch worker for task 79] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 2 non-empty blocks out of 2 blocks
2021-12-04 17:32:34,317 [Executor task launch worker for task 79] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-04 17:32:34,328 [Executor task launch worker for task 79] INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 46.0 (TID 79). 1010 bytes result sent to driver
2021-12-04 17:32:34,328 [Executor task launch worker for task 78] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 46.0 (TID 78). 1010 bytes result sent to driver
2021-12-04 17:32:34,329 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 46.0 (TID 79) in 15 ms on localhost (executor driver) (1/2)
2021-12-04 17:32:34,329 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 46.0 (TID 78) in 15 ms on localhost (executor driver) (2/2)
2021-12-04 17:32:34,329 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 46.0, whose tasks have all completed, from pool 
2021-12-04 17:32:34,329 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 46 (count at PaidPromotionAdjustParameter.scala:173) finished in 0.018 s
2021-12-04 17:32:34,329 [main] INFO [org.apache.spark.scheduler.DAGScheduler] - Job 18 finished: count at PaidPromotionAdjustParameter.scala:173, took 0.930101 s
2021-12-04 17:32:34,330 [main] INFO [PaidPromotion$] - 最终验证集节目数 = 78
2021-12-04 17:32:34,333 [main] INFO [org.apache.spark.SparkContext] - Starting job: count at PaidPromotionAdjustParameter.scala:174
2021-12-04 17:32:34,333 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 59 (intersection at PaidPromotionAdjustParameter.scala:166)
2021-12-04 17:32:34,333 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 58 (intersection at PaidPromotionAdjustParameter.scala:166)
2021-12-04 17:32:34,333 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 19 (count at PaidPromotionAdjustParameter.scala:174) with 4 output partitions
2021-12-04 17:32:34,333 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 51 (count at PaidPromotionAdjustParameter.scala:174)
2021-12-04 17:32:34,333 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 48, ShuffleMapStage 50)
2021-12-04 17:32:34,333 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List(ShuffleMapStage 48, ShuffleMapStage 50)
2021-12-04 17:32:34,333 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ShuffleMapStage 48 (MapPartitionsRDD[59] at intersection at PaidPromotionAdjustParameter.scala:166), which has no missing parents
2021-12-04 17:32:34,334 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_34 stored as values in memory (estimated size 4.0 KB, free 1990.0 MB)
2021-12-04 17:32:34,336 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_34_piece0 stored as bytes in memory (estimated size 2.3 KB, free 1990.0 MB)
2021-12-04 17:32:34,336 [dispatcher-event-loop-9] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_34_piece0 in memory on qb:60226 (size: 2.3 KB, free: 1990.7 MB)
2021-12-04 17:32:34,337 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 34 from broadcast at DAGScheduler.scala:1039
2021-12-04 17:32:34,337 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from ShuffleMapStage 48 (MapPartitionsRDD[59] at intersection at PaidPromotionAdjustParameter.scala:166) (first 15 tasks are for partitions Vector(0, 1))
2021-12-04 17:32:34,337 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 48.0 with 2 tasks
2021-12-04 17:32:34,337 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ShuffleMapStage 50 (MapPartitionsRDD[58] at intersection at PaidPromotionAdjustParameter.scala:166), which has no missing parents
2021-12-04 17:32:34,337 [dispatcher-event-loop-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 48.0 (TID 80, localhost, executor driver, partition 0, ANY, 7638 bytes)
2021-12-04 17:32:34,337 [dispatcher-event-loop-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 48.0 (TID 81, localhost, executor driver, partition 1, ANY, 7638 bytes)
2021-12-04 17:32:34,337 [Executor task launch worker for task 80] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 48.0 (TID 80)
2021-12-04 17:32:34,337 [Executor task launch worker for task 81] INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 48.0 (TID 81)
2021-12-04 17:32:34,338 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_35 stored as values in memory (estimated size 4.0 KB, free 1990.0 MB)
2021-12-04 17:32:34,338 [Executor task launch worker for task 80] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 2 non-empty blocks out of 2 blocks
2021-12-04 17:32:34,338 [Executor task launch worker for task 80] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-04 17:32:34,338 [Executor task launch worker for task 81] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 2 non-empty blocks out of 2 blocks
2021-12-04 17:32:34,338 [Executor task launch worker for task 81] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-04 17:32:34,339 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_35_piece0 stored as bytes in memory (estimated size 2.3 KB, free 1990.0 MB)
2021-12-04 17:32:34,340 [dispatcher-event-loop-4] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_35_piece0 in memory on qb:60226 (size: 2.3 KB, free: 1990.7 MB)
2021-12-04 17:32:34,340 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 35 from broadcast at DAGScheduler.scala:1039
2021-12-04 17:32:34,340 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 4 missing tasks from ShuffleMapStage 50 (MapPartitionsRDD[58] at intersection at PaidPromotionAdjustParameter.scala:166) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
2021-12-04 17:32:34,340 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 50.0 with 4 tasks
2021-12-04 17:32:34,341 [dispatcher-event-loop-8] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 50.0 (TID 82, localhost, executor driver, partition 0, ANY, 7638 bytes)
2021-12-04 17:32:34,341 [dispatcher-event-loop-8] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 50.0 (TID 83, localhost, executor driver, partition 1, ANY, 7638 bytes)
2021-12-04 17:32:34,341 [dispatcher-event-loop-8] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 2.0 in stage 50.0 (TID 84, localhost, executor driver, partition 2, ANY, 7638 bytes)
2021-12-04 17:32:34,341 [dispatcher-event-loop-8] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 3.0 in stage 50.0 (TID 85, localhost, executor driver, partition 3, ANY, 7638 bytes)
2021-12-04 17:32:34,341 [Executor task launch worker for task 82] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 50.0 (TID 82)
2021-12-04 17:32:34,341 [Executor task launch worker for task 85] INFO [org.apache.spark.executor.Executor] - Running task 3.0 in stage 50.0 (TID 85)
2021-12-04 17:32:34,341 [Executor task launch worker for task 84] INFO [org.apache.spark.executor.Executor] - Running task 2.0 in stage 50.0 (TID 84)
2021-12-04 17:32:34,341 [Executor task launch worker for task 83] INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 50.0 (TID 83)
2021-12-04 17:32:34,342 [Executor task launch worker for task 82] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 4 non-empty blocks out of 4 blocks
2021-12-04 17:32:34,342 [Executor task launch worker for task 82] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-04 17:32:34,342 [Executor task launch worker for task 83] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 4 non-empty blocks out of 4 blocks
2021-12-04 17:32:34,342 [Executor task launch worker for task 85] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 4 non-empty blocks out of 4 blocks
2021-12-04 17:32:34,342 [Executor task launch worker for task 85] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-04 17:32:34,342 [Executor task launch worker for task 83] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-04 17:32:34,342 [Executor task launch worker for task 84] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 4 non-empty blocks out of 4 blocks
2021-12-04 17:32:34,342 [Executor task launch worker for task 84] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-04 17:32:34,359 [Executor task launch worker for task 82] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 50.0 (TID 82). 1249 bytes result sent to driver
2021-12-04 17:32:34,359 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 50.0 (TID 82) in 18 ms on localhost (executor driver) (1/4)
2021-12-04 17:32:34,359 [Executor task launch worker for task 85] INFO [org.apache.spark.executor.Executor] - Finished task 3.0 in stage 50.0 (TID 85). 1206 bytes result sent to driver
2021-12-04 17:32:34,360 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 3.0 in stage 50.0 (TID 85) in 19 ms on localhost (executor driver) (2/4)
2021-12-04 17:32:34,361 [Executor task launch worker for task 80] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 48.0 (TID 80). 1206 bytes result sent to driver
2021-12-04 17:32:34,361 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 48.0 (TID 80) in 24 ms on localhost (executor driver) (1/2)
2021-12-04 17:32:34,362 [Executor task launch worker for task 81] INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 48.0 (TID 81). 1206 bytes result sent to driver
2021-12-04 17:32:34,362 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 48.0 (TID 81) in 25 ms on localhost (executor driver) (2/2)
2021-12-04 17:32:34,362 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 48.0, whose tasks have all completed, from pool 
2021-12-04 17:32:34,363 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ShuffleMapStage 48 (intersection at PaidPromotionAdjustParameter.scala:166) finished in 0.028 s
2021-12-04 17:32:34,363 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - looking for newly runnable stages
2021-12-04 17:32:34,363 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - running: Set(ShuffleMapStage 50)
2021-12-04 17:32:34,363 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - waiting: Set(ResultStage 51)
2021-12-04 17:32:34,363 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - failed: Set()
2021-12-04 17:32:34,363 [Executor task launch worker for task 84] INFO [org.apache.spark.executor.Executor] - Finished task 2.0 in stage 50.0 (TID 84). 1163 bytes result sent to driver
2021-12-04 17:32:34,363 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 2.0 in stage 50.0 (TID 84) in 22 ms on localhost (executor driver) (3/4)
2021-12-04 17:32:34,364 [Executor task launch worker for task 83] INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 50.0 (TID 83). 1206 bytes result sent to driver
2021-12-04 17:32:34,364 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 50.0 (TID 83) in 23 ms on localhost (executor driver) (4/4)
2021-12-04 17:32:34,364 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 50.0, whose tasks have all completed, from pool 
2021-12-04 17:32:34,364 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ShuffleMapStage 50 (intersection at PaidPromotionAdjustParameter.scala:166) finished in 0.026 s
2021-12-04 17:32:34,364 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - looking for newly runnable stages
2021-12-04 17:32:34,364 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - running: Set()
2021-12-04 17:32:34,364 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - waiting: Set(ResultStage 51)
2021-12-04 17:32:34,364 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - failed: Set()
2021-12-04 17:32:34,365 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 51 (MapPartitionsRDD[63] at intersection at PaidPromotionAdjustParameter.scala:166), which has no missing parents
2021-12-04 17:32:34,365 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_36 stored as values in memory (estimated size 3.6 KB, free 1990.0 MB)
2021-12-04 17:32:34,368 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_36_piece0 stored as bytes in memory (estimated size 2.1 KB, free 1990.0 MB)
2021-12-04 17:32:34,368 [dispatcher-event-loop-4] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_36_piece0 in memory on qb:60226 (size: 2.1 KB, free: 1990.7 MB)
2021-12-04 17:32:34,369 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 36 from broadcast at DAGScheduler.scala:1039
2021-12-04 17:32:34,369 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 4 missing tasks from ResultStage 51 (MapPartitionsRDD[63] at intersection at PaidPromotionAdjustParameter.scala:166) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
2021-12-04 17:32:34,369 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 51.0 with 4 tasks
2021-12-04 17:32:34,369 [dispatcher-event-loop-8] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 51.0 (TID 86, localhost, executor driver, partition 0, PROCESS_LOCAL, 7712 bytes)
2021-12-04 17:32:34,369 [dispatcher-event-loop-8] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 51.0 (TID 87, localhost, executor driver, partition 1, PROCESS_LOCAL, 7712 bytes)
2021-12-04 17:32:34,369 [dispatcher-event-loop-8] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 2.0 in stage 51.0 (TID 88, localhost, executor driver, partition 2, PROCESS_LOCAL, 7712 bytes)
2021-12-04 17:32:34,369 [dispatcher-event-loop-8] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 3.0 in stage 51.0 (TID 89, localhost, executor driver, partition 3, PROCESS_LOCAL, 7712 bytes)
2021-12-04 17:32:34,370 [Executor task launch worker for task 86] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 51.0 (TID 86)
2021-12-04 17:32:34,370 [Executor task launch worker for task 88] INFO [org.apache.spark.executor.Executor] - Running task 2.0 in stage 51.0 (TID 88)
2021-12-04 17:32:34,370 [Executor task launch worker for task 87] INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 51.0 (TID 87)
2021-12-04 17:32:34,370 [Executor task launch worker for task 89] INFO [org.apache.spark.executor.Executor] - Running task 3.0 in stage 51.0 (TID 89)
2021-12-04 17:32:34,371 [Executor task launch worker for task 86] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 4 blocks
2021-12-04 17:32:34,371 [Executor task launch worker for task 88] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 4 blocks
2021-12-04 17:32:34,371 [Executor task launch worker for task 89] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 4 blocks
2021-12-04 17:32:34,371 [Executor task launch worker for task 89] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-04 17:32:34,371 [Executor task launch worker for task 87] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 4 blocks
2021-12-04 17:32:34,371 [Executor task launch worker for task 86] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-04 17:32:34,371 [Executor task launch worker for task 87] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-04 17:32:34,371 [Executor task launch worker for task 88] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-04 17:32:34,372 [Executor task launch worker for task 86] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2021-12-04 17:32:34,372 [Executor task launch worker for task 86] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-04 17:32:34,372 [Executor task launch worker for task 89] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2021-12-04 17:32:34,372 [Executor task launch worker for task 88] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2021-12-04 17:32:34,372 [Executor task launch worker for task 87] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2021-12-04 17:32:34,372 [Executor task launch worker for task 89] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-04 17:32:34,372 [Executor task launch worker for task 87] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-04 17:32:34,372 [Executor task launch worker for task 88] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-04 17:32:34,380 [Executor task launch worker for task 86] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 51.0 (TID 86). 1010 bytes result sent to driver
2021-12-04 17:32:34,380 [Executor task launch worker for task 87] INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 51.0 (TID 87). 1010 bytes result sent to driver
2021-12-04 17:32:34,381 [Executor task launch worker for task 88] INFO [org.apache.spark.executor.Executor] - Finished task 2.0 in stage 51.0 (TID 88). 1010 bytes result sent to driver
2021-12-04 17:32:34,380 [Executor task launch worker for task 89] INFO [org.apache.spark.executor.Executor] - Finished task 3.0 in stage 51.0 (TID 89). 1010 bytes result sent to driver
2021-12-04 17:32:34,381 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 51.0 (TID 86) in 12 ms on localhost (executor driver) (1/4)
2021-12-04 17:32:34,381 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 51.0 (TID 87) in 12 ms on localhost (executor driver) (2/4)
2021-12-04 17:32:34,381 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 2.0 in stage 51.0 (TID 88) in 12 ms on localhost (executor driver) (3/4)
2021-12-04 17:32:34,381 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 3.0 in stage 51.0 (TID 89) in 12 ms on localhost (executor driver) (4/4)
2021-12-04 17:32:34,381 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 51.0, whose tasks have all completed, from pool 
2021-12-04 17:32:34,381 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 51 (count at PaidPromotionAdjustParameter.scala:174) finished in 0.016 s
2021-12-04 17:32:34,382 [main] INFO [org.apache.spark.scheduler.DAGScheduler] - Job 19 finished: count at PaidPromotionAdjustParameter.scala:174, took 0.048942 s
2021-12-04 17:32:34,382 [main] INFO [PaidPromotion$] - 最终共 同 节目数 = 78
2021-12-04 17:32:34,399 [main] INFO [org.apache.hadoop.conf.Configuration.deprecation] - mapred.output.dir is deprecated. Instead, use mapreduce.output.fileoutputformat.outputdir
2021-12-04 17:32:34,401 [main] INFO [org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter] - File Output Committer Algorithm version is 1
2021-12-04 17:32:34,437 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 826
2021-12-04 17:32:34,437 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 897
2021-12-04 17:32:34,437 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 833
2021-12-04 17:32:34,438 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 890
2021-12-04 17:32:34,438 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 871
2021-12-04 17:32:34,438 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 836
2021-12-04 17:32:34,438 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 782
2021-12-04 17:32:34,438 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 865
2021-12-04 17:32:34,438 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 889
2021-12-04 17:32:34,438 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 742
2021-12-04 17:32:34,438 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 769
2021-12-04 17:32:34,439 [dispatcher-event-loop-4] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_31_piece0 on qb:60226 in memory (size: 2.2 KB, free: 1990.7 MB)
2021-12-04 17:32:34,439 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 753
2021-12-04 17:32:34,439 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 741
2021-12-04 17:32:34,439 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 857
2021-12-04 17:32:34,439 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 802
2021-12-04 17:32:34,439 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 846
2021-12-04 17:32:34,439 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 874
2021-12-04 17:32:34,440 [dispatcher-event-loop-7] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_30_piece0 on qb:60226 in memory (size: 55.4 KB, free: 1990.7 MB)
2021-12-04 17:32:34,440 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 737
2021-12-04 17:32:34,440 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 814
2021-12-04 17:32:34,440 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 888
2021-12-04 17:32:34,440 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 760
2021-12-04 17:32:34,440 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 743
2021-12-04 17:32:34,440 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 783
2021-12-04 17:32:34,440 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 858
2021-12-04 17:32:34,440 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 805
2021-12-04 17:32:34,440 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 840
2021-12-04 17:32:34,440 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 744
2021-12-04 17:32:34,440 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 882
2021-12-04 17:32:34,440 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 796
2021-12-04 17:32:34,440 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 811
2021-12-04 17:32:34,440 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 848
2021-12-04 17:32:34,440 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 852
2021-12-04 17:32:34,440 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 887
2021-12-04 17:32:34,440 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 841
2021-12-04 17:32:34,440 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 843
2021-12-04 17:32:34,440 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 775
2021-12-04 17:32:34,440 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 728
2021-12-04 17:32:34,440 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 734
2021-12-04 17:32:34,440 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 770
2021-12-04 17:32:34,440 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 750
2021-12-04 17:32:34,440 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 830
2021-12-04 17:32:34,440 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 740
2021-12-04 17:32:34,440 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 838
2021-12-04 17:32:34,440 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 807
2021-12-04 17:32:34,440 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 794
2021-12-04 17:32:34,440 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 869
2021-12-04 17:32:34,440 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 842
2021-12-04 17:32:34,440 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 896
2021-12-04 17:32:34,440 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 817
2021-12-04 17:32:34,440 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 810
2021-12-04 17:32:34,440 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 793
2021-12-04 17:32:34,440 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 850
2021-12-04 17:32:34,441 [main] INFO [org.apache.spark.SparkContext] - Starting job: runJob at SparkHadoopWriter.scala:78
2021-12-04 17:32:34,441 [dispatcher-event-loop-5] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_35_piece0 on qb:60226 in memory (size: 2.3 KB, free: 1990.7 MB)
2021-12-04 17:32:34,441 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 752
2021-12-04 17:32:34,441 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 771
2021-12-04 17:32:34,441 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 818
2021-12-04 17:32:34,441 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 895
2021-12-04 17:32:34,441 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 899
2021-12-04 17:32:34,441 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 761
2021-12-04 17:32:34,441 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 735
2021-12-04 17:32:34,441 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 808
2021-12-04 17:32:34,441 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 815
2021-12-04 17:32:34,442 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 854
2021-12-04 17:32:34,442 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 870
2021-12-04 17:32:34,442 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 739
2021-12-04 17:32:34,442 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 772
2021-12-04 17:32:34,442 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 789
2021-12-04 17:32:34,442 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 800
2021-12-04 17:32:34,442 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 797
2021-12-04 17:32:34,442 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 859
2021-12-04 17:32:34,442 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 813
2021-12-04 17:32:34,442 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 749
2021-12-04 17:32:34,442 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 832
2021-12-04 17:32:34,442 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 844
2021-12-04 17:32:34,442 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 837
2021-12-04 17:32:34,442 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 751
2021-12-04 17:32:34,442 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 835
2021-12-04 17:32:34,442 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 876
2021-12-04 17:32:34,442 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 825
2021-12-04 17:32:34,442 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 883
2021-12-04 17:32:34,442 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 879
2021-12-04 17:32:34,442 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 20 (runJob at SparkHadoopWriter.scala:78) with 1 output partitions
2021-12-04 17:32:34,442 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 52 (runJob at SparkHadoopWriter.scala:78)
2021-12-04 17:32:34,442 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List()
2021-12-04 17:32:34,442 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2021-12-04 17:32:34,442 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 52 (MapPartitionsRDD[66] at saveAsTextFile at PaidPromotionAdjustParameter.scala:179), which has no missing parents
2021-12-04 17:32:34,443 [dispatcher-event-loop-10] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_33_piece0 on qb:60226 in memory (size: 2.2 KB, free: 1990.7 MB)
2021-12-04 17:32:34,443 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 762
2021-12-04 17:32:34,443 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 831
2021-12-04 17:32:34,443 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 787
2021-12-04 17:32:34,444 [dispatcher-event-loop-4] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_36_piece0 on qb:60226 in memory (size: 2.1 KB, free: 1990.7 MB)
2021-12-04 17:32:34,445 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 784
2021-12-04 17:32:34,445 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 820
2021-12-04 17:32:34,445 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 790
2021-12-04 17:32:34,445 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 824
2021-12-04 17:32:34,445 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 745
2021-12-04 17:32:34,445 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 872
2021-12-04 17:32:34,445 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 781
2021-12-04 17:32:34,445 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 878
2021-12-04 17:32:34,445 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 822
2021-12-04 17:32:34,445 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 866
2021-12-04 17:32:34,445 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 795
2021-12-04 17:32:34,445 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 812
2021-12-04 17:32:34,445 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 777
2021-12-04 17:32:34,445 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 766
2021-12-04 17:32:34,445 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 867
2021-12-04 17:32:34,445 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 779
2021-12-04 17:32:34,445 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 849
2021-12-04 17:32:34,445 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 892
2021-12-04 17:32:34,445 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 863
2021-12-04 17:32:34,445 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 725
2021-12-04 17:32:34,445 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 798
2021-12-04 17:32:34,445 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 834
2021-12-04 17:32:34,445 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 757
2021-12-04 17:32:34,445 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 885
2021-12-04 17:32:34,445 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 880
2021-12-04 17:32:34,445 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 873
2021-12-04 17:32:34,445 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 862
2021-12-04 17:32:34,445 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 754
2021-12-04 17:32:34,445 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 827
2021-12-04 17:32:34,445 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 829
2021-12-04 17:32:34,445 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 763
2021-12-04 17:32:34,445 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 847
2021-12-04 17:32:34,445 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 809
2021-12-04 17:32:34,445 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 877
2021-12-04 17:32:34,445 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 891
2021-12-04 17:32:34,445 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 894
2021-12-04 17:32:34,445 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 731
2021-12-04 17:32:34,445 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 738
2021-12-04 17:32:34,445 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 756
2021-12-04 17:32:34,445 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 801
2021-12-04 17:32:34,445 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 747
2021-12-04 17:32:34,445 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 804
2021-12-04 17:32:34,445 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 864
2021-12-04 17:32:34,445 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 778
2021-12-04 17:32:34,445 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 816
2021-12-04 17:32:34,446 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 780
2021-12-04 17:32:34,446 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 821
2021-12-04 17:32:34,446 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 875
2021-12-04 17:32:34,446 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 764
2021-12-04 17:32:34,446 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 851
2021-12-04 17:32:34,446 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 730
2021-12-04 17:32:34,446 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 799
2021-12-04 17:32:34,446 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 765
2021-12-04 17:32:34,446 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 868
2021-12-04 17:32:34,446 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 856
2021-12-04 17:32:34,446 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 792
2021-12-04 17:32:34,446 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 755
2021-12-04 17:32:34,446 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 785
2021-12-04 17:32:34,446 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 855
2021-12-04 17:32:34,446 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 860
2021-12-04 17:32:34,446 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 881
2021-12-04 17:32:34,446 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 806
2021-12-04 17:32:34,446 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 768
2021-12-04 17:32:34,446 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 774
2021-12-04 17:32:34,446 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 786
2021-12-04 17:32:34,447 [dispatcher-event-loop-7] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_32_piece0 on qb:60226 in memory (size: 55.0 KB, free: 1990.8 MB)
2021-12-04 17:32:34,448 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 803
2021-12-04 17:32:34,448 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 726
2021-12-04 17:32:34,448 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 758
2021-12-04 17:32:34,448 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 733
2021-12-04 17:32:34,448 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 839
2021-12-04 17:32:34,448 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 898
2021-12-04 17:32:34,448 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 732
2021-12-04 17:32:34,448 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 828
2021-12-04 17:32:34,448 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 886
2021-12-04 17:32:34,448 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 845
2021-12-04 17:32:34,448 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 791
2021-12-04 17:32:34,448 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 884
2021-12-04 17:32:34,448 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 729
2021-12-04 17:32:34,448 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 773
2021-12-04 17:32:34,448 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 861
2021-12-04 17:32:34,448 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 759
2021-12-04 17:32:34,448 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 819
2021-12-04 17:32:34,448 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 853
2021-12-04 17:32:34,448 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 746
2021-12-04 17:32:34,448 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 736
2021-12-04 17:32:34,448 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 748
2021-12-04 17:32:34,448 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 776
2021-12-04 17:32:34,448 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 823
2021-12-04 17:32:34,449 [dispatcher-event-loop-5] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_34_piece0 on qb:60226 in memory (size: 2.3 KB, free: 1990.8 MB)
2021-12-04 17:32:34,449 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 893
2021-12-04 17:32:34,449 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 788
2021-12-04 17:32:34,449 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 727
2021-12-04 17:32:34,449 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 767
2021-12-04 17:32:34,455 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_37 stored as values in memory (estimated size 229.3 KB, free 1990.2 MB)
2021-12-04 17:32:34,457 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_37_piece0 stored as bytes in memory (estimated size 83.5 KB, free 1990.2 MB)
2021-12-04 17:32:34,457 [dispatcher-event-loop-2] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_37_piece0 in memory on qb:60226 (size: 83.5 KB, free: 1990.7 MB)
2021-12-04 17:32:34,458 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 37 from broadcast at DAGScheduler.scala:1039
2021-12-04 17:32:34,458 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 52 (MapPartitionsRDD[66] at saveAsTextFile at PaidPromotionAdjustParameter.scala:179) (first 15 tasks are for partitions Vector(0))
2021-12-04 17:32:34,458 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 52.0 with 1 tasks
2021-12-04 17:32:34,461 [dispatcher-event-loop-9] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 52.0 (TID 90, localhost, executor driver, partition 0, ANY, 8509 bytes)
2021-12-04 17:32:34,461 [Executor task launch worker for task 90] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 52.0 (TID 90)
2021-12-04 17:32:34,478 [Executor task launch worker for task 90] INFO [org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter] - File Output Committer Algorithm version is 1
2021-12-04 17:32:34,506 [Executor task launch worker for task 90] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/order_data.bcp:0+3442194
2021-12-04 17:32:34,907 [Executor task launch worker for task 90] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/order_data.bcp:3442194+3442195
2021-12-04 17:32:35,333 [Executor task launch worker for task 90] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/order_data.bcp:0+3442194
2021-12-04 17:32:35,649 [Executor task launch worker for task 90] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/order_data.bcp:3442194+3442195
2021-12-04 17:32:36,143 [Executor task launch worker for task 90] INFO [org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter] - Saved output of task 'attempt_20211204173234_0066_m_000000_0' to hdfs://hdp1:8020/sk/chongqing/handle_data/set-train-device-production-data/_temporary/0/task_20211204173234_0066_m_000000
2021-12-04 17:32:36,143 [Executor task launch worker for task 90] INFO [org.apache.spark.mapred.SparkHadoopMapRedUtil] - attempt_20211204173234_0066_m_000000_0: Committed
2021-12-04 17:32:36,146 [Executor task launch worker for task 90] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 52.0 (TID 90). 1041 bytes result sent to driver
2021-12-04 17:32:36,152 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 52.0 (TID 90) in 1694 ms on localhost (executor driver) (1/1)
2021-12-04 17:32:36,152 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 52.0, whose tasks have all completed, from pool 
2021-12-04 17:32:36,153 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 52 (runJob at SparkHadoopWriter.scala:78) finished in 1.710 s
2021-12-04 17:32:36,153 [main] INFO [org.apache.spark.scheduler.DAGScheduler] - Job 20 finished: runJob at SparkHadoopWriter.scala:78, took 1.712453 s
2021-12-04 17:32:36,203 [main] INFO [org.apache.spark.internal.io.SparkHadoopWriter] - Job job_20211204173234_0066 committed.
2021-12-04 17:32:36,207 [main] INFO [org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter] - File Output Committer Algorithm version is 1
2021-12-04 17:32:36,224 [main] INFO [org.apache.spark.SparkContext] - Starting job: runJob at SparkHadoopWriter.scala:78
2021-12-04 17:32:36,224 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 21 (runJob at SparkHadoopWriter.scala:78) with 1 output partitions
2021-12-04 17:32:36,224 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 53 (runJob at SparkHadoopWriter.scala:78)
2021-12-04 17:32:36,224 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List()
2021-12-04 17:32:36,225 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2021-12-04 17:32:36,225 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 53 (MapPartitionsRDD[69] at saveAsTextFile at PaidPromotionAdjustParameter.scala:182), which has no missing parents
2021-12-04 17:32:36,234 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_38 stored as values in memory (estimated size 228.7 KB, free 1989.9 MB)
2021-12-04 17:32:36,235 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_38_piece0 stored as bytes in memory (estimated size 83.1 KB, free 1989.9 MB)
2021-12-04 17:32:36,236 [dispatcher-event-loop-4] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_38_piece0 in memory on qb:60226 (size: 83.1 KB, free: 1990.6 MB)
2021-12-04 17:32:36,236 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 38 from broadcast at DAGScheduler.scala:1039
2021-12-04 17:32:36,236 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 53 (MapPartitionsRDD[69] at saveAsTextFile at PaidPromotionAdjustParameter.scala:182) (first 15 tasks are for partitions Vector(0))
2021-12-04 17:32:36,236 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 53.0 with 1 tasks
2021-12-04 17:32:36,237 [dispatcher-event-loop-8] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 53.0 (TID 91, localhost, executor driver, partition 0, ANY, 8337 bytes)
2021-12-04 17:32:36,237 [Executor task launch worker for task 91] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 53.0 (TID 91)
2021-12-04 17:32:36,243 [Executor task launch worker for task 91] INFO [org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter] - File Output Committer Algorithm version is 1
2021-12-04 17:32:36,250 [Executor task launch worker for task 91] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/order_data.bcp:0+3442194
2021-12-04 17:32:36,740 [Executor task launch worker for task 91] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/order_data.bcp:3442194+3442195
2021-12-04 17:32:37,401 [Executor task launch worker for task 91] INFO [org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter] - Saved output of task 'attempt_20211204173236_0069_m_000000_0' to hdfs://hdp1:8020/sk/chongqing/handle_data/set-validation-device-production-data/_temporary/0/task_20211204173236_0069_m_000000
2021-12-04 17:32:37,401 [Executor task launch worker for task 91] INFO [org.apache.spark.mapred.SparkHadoopMapRedUtil] - attempt_20211204173236_0069_m_000000_0: Committed
2021-12-04 17:32:37,403 [Executor task launch worker for task 91] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 53.0 (TID 91). 912 bytes result sent to driver
2021-12-04 17:32:37,404 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 53.0 (TID 91) in 1167 ms on localhost (executor driver) (1/1)
2021-12-04 17:32:37,404 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 53.0, whose tasks have all completed, from pool 
2021-12-04 17:32:37,404 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 53 (runJob at SparkHadoopWriter.scala:78) finished in 1.179 s
2021-12-04 17:32:37,404 [main] INFO [org.apache.spark.scheduler.DAGScheduler] - Job 21 finished: runJob at SparkHadoopWriter.scala:78, took 1.179847 s
2021-12-04 17:32:37,460 [main] INFO [org.apache.spark.internal.io.SparkHadoopWriter] - Job job_20211204173236_0069 committed.
2021-12-04 17:32:37,470 [main] INFO [PaidPromotion$] - 验证集用户实际观看列表-----------------------------------
2021-12-04 17:32:37,471 [main] INFO [org.apache.spark.SparkContext] - Starting job: count at PaidPromotionAdjustParameter.scala:192
2021-12-04 17:32:37,472 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 33 (filter at PaidPromotionAdjustParameter.scala:150)
2021-12-04 17:32:37,472 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 22 (count at PaidPromotionAdjustParameter.scala:192) with 2 output partitions
2021-12-04 17:32:37,472 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 55 (count at PaidPromotionAdjustParameter.scala:192)
2021-12-04 17:32:37,472 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 54)
2021-12-04 17:32:37,472 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List(ShuffleMapStage 54)
2021-12-04 17:32:37,472 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ShuffleMapStage 54 (MapPartitionsRDD[33] at filter at PaidPromotionAdjustParameter.scala:150), which has no missing parents
2021-12-04 17:32:37,473 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_39 stored as values in memory (estimated size 154.1 KB, free 1989.7 MB)
2021-12-04 17:32:37,475 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_39_piece0 stored as bytes in memory (estimated size 55.1 KB, free 1989.7 MB)
2021-12-04 17:32:37,475 [dispatcher-event-loop-2] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_39_piece0 in memory on qb:60226 (size: 55.1 KB, free: 1990.6 MB)
2021-12-04 17:32:37,475 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 39 from broadcast at DAGScheduler.scala:1039
2021-12-04 17:32:37,476 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from ShuffleMapStage 54 (MapPartitionsRDD[33] at filter at PaidPromotionAdjustParameter.scala:150) (first 15 tasks are for partitions Vector(0, 1))
2021-12-04 17:32:37,476 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 54.0 with 2 tasks
2021-12-04 17:32:37,476 [dispatcher-event-loop-9] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 54.0 (TID 92, localhost, executor driver, partition 0, ANY, 7885 bytes)
2021-12-04 17:32:37,476 [dispatcher-event-loop-9] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 54.0 (TID 93, localhost, executor driver, partition 1, ANY, 7885 bytes)
2021-12-04 17:32:37,476 [Executor task launch worker for task 92] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 54.0 (TID 92)
2021-12-04 17:32:37,476 [Executor task launch worker for task 93] INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 54.0 (TID 93)
2021-12-04 17:32:37,478 [Executor task launch worker for task 93] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/order_data.bcp:3442194+3442195
2021-12-04 17:32:37,479 [Executor task launch worker for task 92] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/order_data.bcp:0+3442194
2021-12-04 17:32:38,039 [Executor task launch worker for task 92] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 54.0 (TID 92). 860 bytes result sent to driver
2021-12-04 17:32:38,039 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 54.0 (TID 92) in 563 ms on localhost (executor driver) (1/2)
2021-12-04 17:32:38,145 [Executor task launch worker for task 93] INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 54.0 (TID 93). 860 bytes result sent to driver
2021-12-04 17:32:38,145 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 54.0 (TID 93) in 669 ms on localhost (executor driver) (2/2)
2021-12-04 17:32:38,145 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 54.0, whose tasks have all completed, from pool 
2021-12-04 17:32:38,146 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ShuffleMapStage 54 (filter at PaidPromotionAdjustParameter.scala:150) finished in 0.673 s
2021-12-04 17:32:38,146 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - looking for newly runnable stages
2021-12-04 17:32:38,146 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - running: Set()
2021-12-04 17:32:38,146 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - waiting: Set(ResultStage 55)
2021-12-04 17:32:38,146 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - failed: Set()
2021-12-04 17:32:38,146 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 55 (MapPartitionsRDD[71] at map at PaidPromotionAdjustParameter.scala:186), which has no missing parents
2021-12-04 17:32:38,148 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_40 stored as values in memory (estimated size 155.0 KB, free 1989.5 MB)
2021-12-04 17:32:38,150 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_40_piece0 stored as bytes in memory (estimated size 55.6 KB, free 1989.4 MB)
2021-12-04 17:32:38,150 [dispatcher-event-loop-8] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_40_piece0 in memory on qb:60226 (size: 55.6 KB, free: 1990.5 MB)
2021-12-04 17:32:38,150 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 40 from broadcast at DAGScheduler.scala:1039
2021-12-04 17:32:38,150 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from ResultStage 55 (MapPartitionsRDD[71] at map at PaidPromotionAdjustParameter.scala:186) (first 15 tasks are for partitions Vector(0, 1))
2021-12-04 17:32:38,150 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 55.0 with 2 tasks
2021-12-04 17:32:38,151 [dispatcher-event-loop-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 55.0 (TID 94, localhost, executor driver, partition 0, ANY, 7649 bytes)
2021-12-04 17:32:38,151 [dispatcher-event-loop-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 55.0 (TID 95, localhost, executor driver, partition 1, ANY, 7649 bytes)
2021-12-04 17:32:38,151 [Executor task launch worker for task 94] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 55.0 (TID 94)
2021-12-04 17:32:38,151 [Executor task launch worker for task 95] INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 55.0 (TID 95)
2021-12-04 17:32:38,153 [Executor task launch worker for task 94] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 2 non-empty blocks out of 2 blocks
2021-12-04 17:32:38,153 [Executor task launch worker for task 95] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 2 non-empty blocks out of 2 blocks
2021-12-04 17:32:38,153 [Executor task launch worker for task 94] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-04 17:32:38,153 [Executor task launch worker for task 95] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-04 17:32:38,184 [Executor task launch worker for task 94] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 55.0 (TID 94). 1054 bytes result sent to driver
2021-12-04 17:32:38,184 [Executor task launch worker for task 95] INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 55.0 (TID 95). 1011 bytes result sent to driver
2021-12-04 17:32:38,184 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 55.0 (TID 94) in 33 ms on localhost (executor driver) (1/2)
2021-12-04 17:32:38,184 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 55.0 (TID 95) in 33 ms on localhost (executor driver) (2/2)
2021-12-04 17:32:38,184 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 55.0, whose tasks have all completed, from pool 
2021-12-04 17:32:38,184 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 55 (count at PaidPromotionAdjustParameter.scala:192) finished in 0.038 s
2021-12-04 17:32:38,185 [main] INFO [org.apache.spark.scheduler.DAGScheduler] - Job 22 finished: count at PaidPromotionAdjustParameter.scala:192, took 0.713161 s
2021-12-04 17:32:38,185 [main] INFO [PaidPromotion$] - 验证集用户列表数量：4238
2021-12-04 17:32:38,192 [main] INFO [org.apache.spark.SparkContext] - Starting job: take at PaidPromotionAdjustParameter.scala:193
2021-12-04 17:32:38,192 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 23 (take at PaidPromotionAdjustParameter.scala:193) with 1 output partitions
2021-12-04 17:32:38,192 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 57 (take at PaidPromotionAdjustParameter.scala:193)
2021-12-04 17:32:38,192 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 56)
2021-12-04 17:32:38,192 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2021-12-04 17:32:38,192 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 57 (MapPartitionsRDD[71] at map at PaidPromotionAdjustParameter.scala:186), which has no missing parents
2021-12-04 17:32:38,194 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_41 stored as values in memory (estimated size 155.2 KB, free 1989.3 MB)
2021-12-04 17:32:38,195 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_41_piece0 stored as bytes in memory (estimated size 55.7 KB, free 1989.2 MB)
2021-12-04 17:32:38,195 [dispatcher-event-loop-2] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_41_piece0 in memory on qb:60226 (size: 55.7 KB, free: 1990.4 MB)
2021-12-04 17:32:38,196 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 41 from broadcast at DAGScheduler.scala:1039
2021-12-04 17:32:38,196 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 57 (MapPartitionsRDD[71] at map at PaidPromotionAdjustParameter.scala:186) (first 15 tasks are for partitions Vector(0))
2021-12-04 17:32:38,196 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 57.0 with 1 tasks
2021-12-04 17:32:38,196 [dispatcher-event-loop-9] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 57.0 (TID 96, localhost, executor driver, partition 0, ANY, 7649 bytes)
2021-12-04 17:32:38,197 [Executor task launch worker for task 96] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 57.0 (TID 96)
2021-12-04 17:32:38,198 [Executor task launch worker for task 96] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 2 non-empty blocks out of 2 blocks
2021-12-04 17:32:38,198 [Executor task launch worker for task 96] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-04 17:32:38,211 [Executor task launch worker for task 96] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 57.0 (TID 96). 2514 bytes result sent to driver
2021-12-04 17:32:38,211 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 57.0 (TID 96) in 15 ms on localhost (executor driver) (1/1)
2021-12-04 17:32:38,211 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 57.0, whose tasks have all completed, from pool 
2021-12-04 17:32:38,211 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 57 (take at PaidPromotionAdjustParameter.scala:193) finished in 0.018 s
2021-12-04 17:32:38,212 [main] INFO [org.apache.spark.scheduler.DAGScheduler] - Job 23 finished: take at PaidPromotionAdjustParameter.scala:193, took 0.019553 s
2021-12-04 17:32:38,220 [main] INFO [PaidPromotion$] - 训练集用户实际观看列表-----------------------------------
2021-12-04 17:32:38,221 [main] INFO [org.apache.spark.SparkContext] - Starting job: count at PaidPromotionAdjustParameter.scala:203
2021-12-04 17:32:38,221 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 35 (union at PaidPromotionAdjustParameter.scala:154)
2021-12-04 17:32:38,222 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 24 (count at PaidPromotionAdjustParameter.scala:203) with 4 output partitions
2021-12-04 17:32:38,222 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 59 (count at PaidPromotionAdjustParameter.scala:203)
2021-12-04 17:32:38,222 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 58)
2021-12-04 17:32:38,222 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List(ShuffleMapStage 58)
2021-12-04 17:32:38,222 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ShuffleMapStage 58 (UnionRDD[35] at union at PaidPromotionAdjustParameter.scala:154), which has no missing parents
2021-12-04 17:32:38,223 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_42 stored as values in memory (estimated size 154.7 KB, free 1989.1 MB)
2021-12-04 17:32:38,225 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_42_piece0 stored as bytes in memory (estimated size 55.5 KB, free 1989.0 MB)
2021-12-04 17:32:38,225 [dispatcher-event-loop-6] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_42_piece0 in memory on qb:60226 (size: 55.5 KB, free: 1990.4 MB)
2021-12-04 17:32:38,225 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 42 from broadcast at DAGScheduler.scala:1039
2021-12-04 17:32:38,226 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 4 missing tasks from ShuffleMapStage 58 (UnionRDD[35] at union at PaidPromotionAdjustParameter.scala:154) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
2021-12-04 17:32:38,226 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 58.0 with 4 tasks
2021-12-04 17:32:38,226 [dispatcher-event-loop-4] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 58.0 (TID 97, localhost, executor driver, partition 0, ANY, 7994 bytes)
2021-12-04 17:32:38,226 [dispatcher-event-loop-4] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 58.0 (TID 98, localhost, executor driver, partition 1, ANY, 7994 bytes)
2021-12-04 17:32:38,226 [dispatcher-event-loop-4] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 2.0 in stage 58.0 (TID 99, localhost, executor driver, partition 2, ANY, 7994 bytes)
2021-12-04 17:32:38,226 [dispatcher-event-loop-4] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 3.0 in stage 58.0 (TID 100, localhost, executor driver, partition 3, ANY, 7994 bytes)
2021-12-04 17:32:38,226 [Executor task launch worker for task 98] INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 58.0 (TID 98)
2021-12-04 17:32:38,226 [Executor task launch worker for task 100] INFO [org.apache.spark.executor.Executor] - Running task 3.0 in stage 58.0 (TID 100)
2021-12-04 17:32:38,226 [Executor task launch worker for task 97] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 58.0 (TID 97)
2021-12-04 17:32:38,226 [Executor task launch worker for task 99] INFO [org.apache.spark.executor.Executor] - Running task 2.0 in stage 58.0 (TID 99)
2021-12-04 17:32:38,228 [Executor task launch worker for task 99] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/order_data.bcp:0+3442194
2021-12-04 17:32:38,228 [Executor task launch worker for task 97] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/order_data.bcp:0+3442194
2021-12-04 17:32:38,228 [Executor task launch worker for task 100] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/order_data.bcp:3442194+3442195
2021-12-04 17:32:38,228 [Executor task launch worker for task 98] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/order_data.bcp:3442194+3442195
2021-12-04 17:32:38,375 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 989
2021-12-04 17:32:38,375 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 950
2021-12-04 17:32:38,375 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 923
2021-12-04 17:32:38,375 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 929
2021-12-04 17:32:38,375 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1002
2021-12-04 17:32:38,375 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1003
2021-12-04 17:32:38,376 [dispatcher-event-loop-2] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_38_piece0 on qb:60226 in memory (size: 83.1 KB, free: 1990.5 MB)
2021-12-04 17:32:38,376 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 984
2021-12-04 17:32:38,376 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1009
2021-12-04 17:32:38,376 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1011
2021-12-04 17:32:38,376 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 922
2021-12-04 17:32:38,376 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 976
2021-12-04 17:32:38,376 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 931
2021-12-04 17:32:38,376 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 977
2021-12-04 17:32:38,376 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 954
2021-12-04 17:32:38,376 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 986
2021-12-04 17:32:38,376 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 937
2021-12-04 17:32:38,376 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 987
2021-12-04 17:32:38,376 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1020
2021-12-04 17:32:38,376 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1014
2021-12-04 17:32:38,376 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1004
2021-12-04 17:32:38,376 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 900
2021-12-04 17:32:38,377 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 958
2021-12-04 17:32:38,377 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 943
2021-12-04 17:32:38,377 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 935
2021-12-04 17:32:38,377 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 930
2021-12-04 17:32:38,377 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1023
2021-12-04 17:32:38,377 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 961
2021-12-04 17:32:38,377 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 992
2021-12-04 17:32:38,377 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 967
2021-12-04 17:32:38,377 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 910
2021-12-04 17:32:38,377 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 949
2021-12-04 17:32:38,377 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 925
2021-12-04 17:32:38,377 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1016
2021-12-04 17:32:38,377 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 974
2021-12-04 17:32:38,377 [dispatcher-event-loop-3] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_41_piece0 on qb:60226 in memory (size: 55.7 KB, free: 1990.5 MB)
2021-12-04 17:32:38,377 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 914
2021-12-04 17:32:38,377 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 997
2021-12-04 17:32:38,377 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 921
2021-12-04 17:32:38,377 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 920
2021-12-04 17:32:38,377 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 957
2021-12-04 17:32:38,377 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 962
2021-12-04 17:32:38,378 [dispatcher-event-loop-8] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_39_piece0 on qb:60226 in memory (size: 55.1 KB, free: 1990.6 MB)
2021-12-04 17:32:38,378 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 951
2021-12-04 17:32:38,378 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 936
2021-12-04 17:32:38,378 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 918
2021-12-04 17:32:38,378 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 941
2021-12-04 17:32:38,378 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1013
2021-12-04 17:32:38,378 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 963
2021-12-04 17:32:38,378 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 938
2021-12-04 17:32:38,378 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1012
2021-12-04 17:32:38,378 [dispatcher-event-loop-11] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_40_piece0 on qb:60226 in memory (size: 55.6 KB, free: 1990.6 MB)
2021-12-04 17:32:38,379 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 924
2021-12-04 17:32:38,379 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 973
2021-12-04 17:32:38,379 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1019
2021-12-04 17:32:38,379 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1006
2021-12-04 17:32:38,379 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 907
2021-12-04 17:32:38,379 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 915
2021-12-04 17:32:38,379 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 928
2021-12-04 17:32:38,379 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 993
2021-12-04 17:32:38,379 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 934
2021-12-04 17:32:38,379 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1024
2021-12-04 17:32:38,379 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 975
2021-12-04 17:32:38,379 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 945
2021-12-04 17:32:38,379 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 902
2021-12-04 17:32:38,379 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1000
2021-12-04 17:32:38,379 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 995
2021-12-04 17:32:38,379 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 919
2021-12-04 17:32:38,379 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 994
2021-12-04 17:32:38,379 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 983
2021-12-04 17:32:38,379 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 906
2021-12-04 17:32:38,379 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1022
2021-12-04 17:32:38,379 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 926
2021-12-04 17:32:38,379 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 972
2021-12-04 17:32:38,379 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 901
2021-12-04 17:32:38,379 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 960
2021-12-04 17:32:38,379 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 916
2021-12-04 17:32:38,379 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 952
2021-12-04 17:32:38,379 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 932
2021-12-04 17:32:38,379 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 959
2021-12-04 17:32:38,379 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 966
2021-12-04 17:32:38,379 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 964
2021-12-04 17:32:38,379 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1008
2021-12-04 17:32:38,379 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 911
2021-12-04 17:32:38,379 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 903
2021-12-04 17:32:38,379 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 944
2021-12-04 17:32:38,379 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 979
2021-12-04 17:32:38,379 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 985
2021-12-04 17:32:38,379 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 971
2021-12-04 17:32:38,379 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1010
2021-12-04 17:32:38,379 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 969
2021-12-04 17:32:38,379 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 982
2021-12-04 17:32:38,379 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 970
2021-12-04 17:32:38,379 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 956
2021-12-04 17:32:38,379 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 955
2021-12-04 17:32:38,379 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 908
2021-12-04 17:32:38,379 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 978
2021-12-04 17:32:38,379 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 999
2021-12-04 17:32:38,379 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 912
2021-12-04 17:32:38,379 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 939
2021-12-04 17:32:38,379 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 917
2021-12-04 17:32:38,379 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 990
2021-12-04 17:32:38,379 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 940
2021-12-04 17:32:38,379 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 968
2021-12-04 17:32:38,379 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 988
2021-12-04 17:32:38,379 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 947
2021-12-04 17:32:38,379 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 953
2021-12-04 17:32:38,379 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 965
2021-12-04 17:32:38,379 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 927
2021-12-04 17:32:38,379 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1017
2021-12-04 17:32:38,379 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 913
2021-12-04 17:32:38,379 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 942
2021-12-04 17:32:38,379 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 909
2021-12-04 17:32:38,379 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 946
2021-12-04 17:32:38,379 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 948
2021-12-04 17:32:38,379 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1018
2021-12-04 17:32:38,380 [dispatcher-event-loop-2] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_37_piece0 on qb:60226 in memory (size: 83.5 KB, free: 1990.7 MB)
2021-12-04 17:32:38,380 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1015
2021-12-04 17:32:38,380 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 905
2021-12-04 17:32:38,380 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1005
2021-12-04 17:32:38,380 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 991
2021-12-04 17:32:38,380 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 998
2021-12-04 17:32:38,380 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 904
2021-12-04 17:32:38,380 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 981
2021-12-04 17:32:38,380 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1001
2021-12-04 17:32:38,380 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 980
2021-12-04 17:32:38,380 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1007
2021-12-04 17:32:38,380 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1021
2021-12-04 17:32:38,380 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 933
2021-12-04 17:32:38,380 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 996
2021-12-04 17:32:38,953 [Executor task launch worker for task 97] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 58.0 (TID 97). 905 bytes result sent to driver
2021-12-04 17:32:38,953 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 58.0 (TID 97) in 727 ms on localhost (executor driver) (1/4)
2021-12-04 17:32:39,011 [Executor task launch worker for task 98] INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 58.0 (TID 98). 905 bytes result sent to driver
2021-12-04 17:32:39,011 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 58.0 (TID 98) in 785 ms on localhost (executor driver) (2/4)
2021-12-04 17:32:39,478 [Executor task launch worker for task 100] INFO [org.apache.spark.executor.Executor] - Finished task 3.0 in stage 58.0 (TID 100). 905 bytes result sent to driver
2021-12-04 17:32:39,479 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 3.0 in stage 58.0 (TID 100) in 1253 ms on localhost (executor driver) (3/4)
2021-12-04 17:32:39,520 [Executor task launch worker for task 99] INFO [org.apache.spark.executor.Executor] - Finished task 2.0 in stage 58.0 (TID 99). 905 bytes result sent to driver
2021-12-04 17:32:39,521 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 2.0 in stage 58.0 (TID 99) in 1295 ms on localhost (executor driver) (4/4)
2021-12-04 17:32:39,521 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 58.0, whose tasks have all completed, from pool 
2021-12-04 17:32:39,521 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ShuffleMapStage 58 (union at PaidPromotionAdjustParameter.scala:154) finished in 1.299 s
2021-12-04 17:32:39,521 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - looking for newly runnable stages
2021-12-04 17:32:39,521 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - running: Set()
2021-12-04 17:32:39,521 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - waiting: Set(ResultStage 59)
2021-12-04 17:32:39,521 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - failed: Set()
2021-12-04 17:32:39,521 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 59 (MapPartitionsRDD[73] at map at PaidPromotionAdjustParameter.scala:197), which has no missing parents
2021-12-04 17:32:39,522 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_43 stored as values in memory (estimated size 155.5 KB, free 1990.1 MB)
2021-12-04 17:32:39,524 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_43_piece0 stored as bytes in memory (estimated size 56.0 KB, free 1990.1 MB)
2021-12-04 17:32:39,524 [dispatcher-event-loop-6] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_43_piece0 in memory on qb:60226 (size: 56.0 KB, free: 1990.7 MB)
2021-12-04 17:32:39,524 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 43 from broadcast at DAGScheduler.scala:1039
2021-12-04 17:32:39,524 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 4 missing tasks from ResultStage 59 (MapPartitionsRDD[73] at map at PaidPromotionAdjustParameter.scala:197) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
2021-12-04 17:32:39,524 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 59.0 with 4 tasks
2021-12-04 17:32:39,525 [dispatcher-event-loop-8] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 59.0 (TID 101, localhost, executor driver, partition 0, ANY, 7649 bytes)
2021-12-04 17:32:39,525 [dispatcher-event-loop-8] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 59.0 (TID 102, localhost, executor driver, partition 1, ANY, 7649 bytes)
2021-12-04 17:32:39,525 [dispatcher-event-loop-8] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 2.0 in stage 59.0 (TID 103, localhost, executor driver, partition 2, ANY, 7649 bytes)
2021-12-04 17:32:39,525 [dispatcher-event-loop-8] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 3.0 in stage 59.0 (TID 104, localhost, executor driver, partition 3, ANY, 7649 bytes)
2021-12-04 17:32:39,525 [Executor task launch worker for task 101] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 59.0 (TID 101)
2021-12-04 17:32:39,525 [Executor task launch worker for task 104] INFO [org.apache.spark.executor.Executor] - Running task 3.0 in stage 59.0 (TID 104)
2021-12-04 17:32:39,525 [Executor task launch worker for task 103] INFO [org.apache.spark.executor.Executor] - Running task 2.0 in stage 59.0 (TID 103)
2021-12-04 17:32:39,525 [Executor task launch worker for task 102] INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 59.0 (TID 102)
2021-12-04 17:32:39,527 [Executor task launch worker for task 101] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 4 non-empty blocks out of 4 blocks
2021-12-04 17:32:39,527 [Executor task launch worker for task 102] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 4 non-empty blocks out of 4 blocks
2021-12-04 17:32:39,527 [Executor task launch worker for task 101] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-04 17:32:39,527 [Executor task launch worker for task 102] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-04 17:32:39,527 [Executor task launch worker for task 104] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 4 non-empty blocks out of 4 blocks
2021-12-04 17:32:39,527 [Executor task launch worker for task 104] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-04 17:32:39,527 [Executor task launch worker for task 103] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 4 non-empty blocks out of 4 blocks
2021-12-04 17:32:39,527 [Executor task launch worker for task 103] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-04 17:32:39,632 [dispatcher-event-loop-9] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_42_piece0 on qb:60226 in memory (size: 55.5 KB, free: 1990.7 MB)
2021-12-04 17:32:39,654 [Executor task launch worker for task 103] INFO [org.apache.spark.executor.Executor] - Finished task 2.0 in stage 59.0 (TID 103). 1098 bytes result sent to driver
2021-12-04 17:32:39,654 [Executor task launch worker for task 101] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 59.0 (TID 101). 1098 bytes result sent to driver
2021-12-04 17:32:39,654 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 2.0 in stage 59.0 (TID 103) in 129 ms on localhost (executor driver) (1/4)
2021-12-04 17:32:39,654 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 59.0 (TID 101) in 129 ms on localhost (executor driver) (2/4)
2021-12-04 17:32:39,655 [Executor task launch worker for task 102] INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 59.0 (TID 102). 1098 bytes result sent to driver
2021-12-04 17:32:39,655 [Executor task launch worker for task 104] INFO [org.apache.spark.executor.Executor] - Finished task 3.0 in stage 59.0 (TID 104). 1098 bytes result sent to driver
2021-12-04 17:32:39,655 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 59.0 (TID 102) in 130 ms on localhost (executor driver) (3/4)
2021-12-04 17:32:39,655 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 3.0 in stage 59.0 (TID 104) in 130 ms on localhost (executor driver) (4/4)
2021-12-04 17:32:39,655 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 59.0, whose tasks have all completed, from pool 
2021-12-04 17:32:39,656 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 59 (count at PaidPromotionAdjustParameter.scala:203) finished in 0.135 s
2021-12-04 17:32:39,656 [main] INFO [org.apache.spark.scheduler.DAGScheduler] - Job 24 finished: count at PaidPromotionAdjustParameter.scala:203, took 1.435173 s
2021-12-04 17:32:39,656 [main] INFO [PaidPromotion$] - 训练集用户列表数量：95323
2021-12-04 17:32:39,661 [main] INFO [org.apache.spark.SparkContext] - Starting job: take at PaidPromotionAdjustParameter.scala:204
2021-12-04 17:32:39,662 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 25 (take at PaidPromotionAdjustParameter.scala:204) with 1 output partitions
2021-12-04 17:32:39,662 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 61 (take at PaidPromotionAdjustParameter.scala:204)
2021-12-04 17:32:39,662 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 60)
2021-12-04 17:32:39,662 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2021-12-04 17:32:39,662 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 61 (MapPartitionsRDD[73] at map at PaidPromotionAdjustParameter.scala:197), which has no missing parents
2021-12-04 17:32:39,663 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_44 stored as values in memory (estimated size 155.7 KB, free 1990.1 MB)
2021-12-04 17:32:39,665 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_44_piece0 stored as bytes in memory (estimated size 56.1 KB, free 1990.1 MB)
2021-12-04 17:32:39,665 [dispatcher-event-loop-8] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_44_piece0 in memory on qb:60226 (size: 56.1 KB, free: 1990.7 MB)
2021-12-04 17:32:39,665 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 44 from broadcast at DAGScheduler.scala:1039
2021-12-04 17:32:39,665 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 61 (MapPartitionsRDD[73] at map at PaidPromotionAdjustParameter.scala:197) (first 15 tasks are for partitions Vector(0))
2021-12-04 17:32:39,665 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 61.0 with 1 tasks
2021-12-04 17:32:39,666 [dispatcher-event-loop-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 61.0 (TID 105, localhost, executor driver, partition 0, ANY, 7649 bytes)
2021-12-04 17:32:39,666 [Executor task launch worker for task 105] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 61.0 (TID 105)
2021-12-04 17:32:39,667 [Executor task launch worker for task 105] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 4 non-empty blocks out of 4 blocks
2021-12-04 17:32:39,667 [Executor task launch worker for task 105] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-04 17:32:39,700 [Executor task launch worker for task 105] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 61.0 (TID 105). 2405 bytes result sent to driver
2021-12-04 17:32:39,700 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 61.0 (TID 105) in 34 ms on localhost (executor driver) (1/1)
2021-12-04 17:32:39,700 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 61.0, whose tasks have all completed, from pool 
2021-12-04 17:32:39,701 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 61 (take at PaidPromotionAdjustParameter.scala:204) finished in 0.039 s
2021-12-04 17:32:39,701 [main] INFO [org.apache.spark.scheduler.DAGScheduler] - Job 25 finished: take at PaidPromotionAdjustParameter.scala:204, took 0.039181 s
2021-12-04 17:32:39,704 [main] INFO [org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter] - File Output Committer Algorithm version is 1
2021-12-04 17:32:39,725 [main] INFO [org.apache.spark.SparkContext] - Starting job: runJob at SparkHadoopWriter.scala:78
2021-12-04 17:32:39,725 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 26 (runJob at SparkHadoopWriter.scala:78) with 1 output partitions
2021-12-04 17:32:39,725 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 63 (runJob at SparkHadoopWriter.scala:78)
2021-12-04 17:32:39,725 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 62)
2021-12-04 17:32:39,725 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2021-12-04 17:32:39,725 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 63 (MapPartitionsRDD[75] at saveAsTextFile at PaidPromotionAdjustParameter.scala:206), which has no missing parents
2021-12-04 17:32:39,734 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_45 stored as values in memory (estimated size 231.4 KB, free 1989.8 MB)
2021-12-04 17:32:39,735 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_45_piece0 stored as bytes in memory (estimated size 84.4 KB, free 1989.7 MB)
2021-12-04 17:32:39,736 [dispatcher-event-loop-1] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_45_piece0 in memory on qb:60226 (size: 84.4 KB, free: 1990.6 MB)
2021-12-04 17:32:39,736 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 45 from broadcast at DAGScheduler.scala:1039
2021-12-04 17:32:39,736 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 63 (MapPartitionsRDD[75] at saveAsTextFile at PaidPromotionAdjustParameter.scala:206) (first 15 tasks are for partitions Vector(0))
2021-12-04 17:32:39,736 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 63.0 with 1 tasks
2021-12-04 17:32:39,736 [dispatcher-event-loop-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 63.0 (TID 106, localhost, executor driver, partition 0, ANY, 7943 bytes)
2021-12-04 17:32:39,737 [Executor task launch worker for task 106] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 63.0 (TID 106)
2021-12-04 17:32:39,742 [Executor task launch worker for task 106] INFO [org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter] - File Output Committer Algorithm version is 1
2021-12-04 17:32:39,750 [Executor task launch worker for task 106] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 2 non-empty blocks out of 2 blocks
2021-12-04 17:32:39,750 [Executor task launch worker for task 106] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-04 17:32:39,764 [Executor task launch worker for task 106] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 2 non-empty blocks out of 2 blocks
2021-12-04 17:32:39,764 [Executor task launch worker for task 106] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-04 17:32:39,850 [Executor task launch worker for task 106] INFO [org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter] - Saved output of task 'attempt_20211204173239_0075_m_000000_0' to hdfs://hdp1:8020/sk/chongqing/list/validation/_temporary/0/task_20211204173239_0075_m_000000
2021-12-04 17:32:39,851 [Executor task launch worker for task 106] INFO [org.apache.spark.mapred.SparkHadoopMapRedUtil] - attempt_20211204173239_0075_m_000000_0: Committed
2021-12-04 17:32:39,854 [Executor task launch worker for task 106] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 63.0 (TID 106). 1256 bytes result sent to driver
2021-12-04 17:32:39,855 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 63.0 (TID 106) in 118 ms on localhost (executor driver) (1/1)
2021-12-04 17:32:39,855 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 63.0, whose tasks have all completed, from pool 
2021-12-04 17:32:39,856 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 63 (runJob at SparkHadoopWriter.scala:78) finished in 0.129 s
2021-12-04 17:32:39,856 [main] INFO [org.apache.spark.scheduler.DAGScheduler] - Job 26 finished: runJob at SparkHadoopWriter.scala:78, took 0.130947 s
2021-12-04 17:32:39,902 [main] INFO [org.apache.spark.internal.io.SparkHadoopWriter] - Job job_20211204173239_0075 committed.
2021-12-04 17:32:39,904 [main] INFO [org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter] - File Output Committer Algorithm version is 1
2021-12-04 17:32:39,916 [main] INFO [org.apache.spark.SparkContext] - Starting job: runJob at SparkHadoopWriter.scala:78
2021-12-04 17:32:39,917 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 27 (runJob at SparkHadoopWriter.scala:78) with 1 output partitions
2021-12-04 17:32:39,917 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 65 (runJob at SparkHadoopWriter.scala:78)
2021-12-04 17:32:39,917 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 64)
2021-12-04 17:32:39,917 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2021-12-04 17:32:39,917 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 65 (MapPartitionsRDD[77] at saveAsTextFile at PaidPromotionAdjustParameter.scala:207), which has no missing parents
2021-12-04 17:32:39,925 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_46 stored as values in memory (estimated size 232.0 KB, free 1989.5 MB)
2021-12-04 17:32:39,927 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_46_piece0 stored as bytes in memory (estimated size 84.8 KB, free 1989.4 MB)
2021-12-04 17:32:39,927 [dispatcher-event-loop-10] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_46_piece0 in memory on qb:60226 (size: 84.8 KB, free: 1990.5 MB)
2021-12-04 17:32:39,928 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 46 from broadcast at DAGScheduler.scala:1039
2021-12-04 17:32:39,928 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 65 (MapPartitionsRDD[77] at saveAsTextFile at PaidPromotionAdjustParameter.scala:207) (first 15 tasks are for partitions Vector(0))
2021-12-04 17:32:39,928 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 65.0 with 1 tasks
2021-12-04 17:32:39,928 [dispatcher-event-loop-6] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 65.0 (TID 107, localhost, executor driver, partition 0, ANY, 7979 bytes)
2021-12-04 17:32:39,928 [Executor task launch worker for task 107] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 65.0 (TID 107)
2021-12-04 17:32:39,933 [Executor task launch worker for task 107] INFO [org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter] - File Output Committer Algorithm version is 1
2021-12-04 17:32:39,942 [Executor task launch worker for task 107] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 4 non-empty blocks out of 4 blocks
2021-12-04 17:32:39,943 [Executor task launch worker for task 107] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 1 ms
2021-12-04 17:32:39,998 [Executor task launch worker for task 107] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 4 non-empty blocks out of 4 blocks
2021-12-04 17:32:39,998 [Executor task launch worker for task 107] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-04 17:32:40,054 [Executor task launch worker for task 107] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 4 non-empty blocks out of 4 blocks
2021-12-04 17:32:40,054 [Executor task launch worker for task 107] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-04 17:32:40,110 [Executor task launch worker for task 107] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 4 non-empty blocks out of 4 blocks
2021-12-04 17:32:40,110 [Executor task launch worker for task 107] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-04 17:32:40,150 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1057
2021-12-04 17:32:40,150 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1044
2021-12-04 17:32:40,150 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1052
2021-12-04 17:32:40,150 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1097
2021-12-04 17:32:40,150 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1034
2021-12-04 17:32:40,150 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1054
2021-12-04 17:32:40,150 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1109
2021-12-04 17:32:40,150 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1111
2021-12-04 17:32:40,150 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1115
2021-12-04 17:32:40,150 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1103
2021-12-04 17:32:40,150 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1059
2021-12-04 17:32:40,150 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1105
2021-12-04 17:32:40,150 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1046
2021-12-04 17:32:40,150 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1027
2021-12-04 17:32:40,150 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1076
2021-12-04 17:32:40,150 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1043
2021-12-04 17:32:40,150 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1114
2021-12-04 17:32:40,150 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1117
2021-12-04 17:32:40,150 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1099
2021-12-04 17:32:40,150 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1065
2021-12-04 17:32:40,150 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1029
2021-12-04 17:32:40,150 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1075
2021-12-04 17:32:40,150 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1066
2021-12-04 17:32:40,150 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1045
2021-12-04 17:32:40,150 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1083
2021-12-04 17:32:40,150 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1040
2021-12-04 17:32:40,150 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1104
2021-12-04 17:32:40,150 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1053
2021-12-04 17:32:40,150 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1088
2021-12-04 17:32:40,150 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1112
2021-12-04 17:32:40,150 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1101
2021-12-04 17:32:40,150 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1056
2021-12-04 17:32:40,150 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1079
2021-12-04 17:32:40,150 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1051
2021-12-04 17:32:40,150 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1089
2021-12-04 17:32:40,151 [dispatcher-event-loop-7] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_45_piece0 on qb:60226 in memory (size: 84.4 KB, free: 1990.6 MB)
2021-12-04 17:32:40,152 [dispatcher-event-loop-2] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_44_piece0 on qb:60226 in memory (size: 56.1 KB, free: 1990.6 MB)
2021-12-04 17:32:40,152 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1061
2021-12-04 17:32:40,152 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1063
2021-12-04 17:32:40,152 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1090
2021-12-04 17:32:40,152 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1093
2021-12-04 17:32:40,152 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1026
2021-12-04 17:32:40,152 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1098
2021-12-04 17:32:40,152 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1049
2021-12-04 17:32:40,152 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1055
2021-12-04 17:32:40,152 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1074
2021-12-04 17:32:40,152 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1068
2021-12-04 17:32:40,152 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1062
2021-12-04 17:32:40,152 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1037
2021-12-04 17:32:40,152 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1080
2021-12-04 17:32:40,152 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1032
2021-12-04 17:32:40,152 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1039
2021-12-04 17:32:40,152 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1036
2021-12-04 17:32:40,152 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1116
2021-12-04 17:32:40,152 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1119
2021-12-04 17:32:40,152 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1108
2021-12-04 17:32:40,152 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1121
2021-12-04 17:32:40,152 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1077
2021-12-04 17:32:40,152 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1050
2021-12-04 17:32:40,152 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1118
2021-12-04 17:32:40,152 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1047
2021-12-04 17:32:40,152 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1031
2021-12-04 17:32:40,152 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1067
2021-12-04 17:32:40,152 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1072
2021-12-04 17:32:40,152 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1042
2021-12-04 17:32:40,152 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1084
2021-12-04 17:32:40,152 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1096
2021-12-04 17:32:40,152 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1085
2021-12-04 17:32:40,152 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1100
2021-12-04 17:32:40,153 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1091
2021-12-04 17:32:40,153 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1060
2021-12-04 17:32:40,153 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1058
2021-12-04 17:32:40,153 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1035
2021-12-04 17:32:40,153 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1113
2021-12-04 17:32:40,153 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1120
2021-12-04 17:32:40,153 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1123
2021-12-04 17:32:40,153 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1094
2021-12-04 17:32:40,153 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1071
2021-12-04 17:32:40,153 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1122
2021-12-04 17:32:40,153 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1033
2021-12-04 17:32:40,153 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1028
2021-12-04 17:32:40,153 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1064
2021-12-04 17:32:40,153 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1038
2021-12-04 17:32:40,153 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1102
2021-12-04 17:32:40,153 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1087
2021-12-04 17:32:40,153 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1073
2021-12-04 17:32:40,153 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1030
2021-12-04 17:32:40,153 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1078
2021-12-04 17:32:40,153 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1086
2021-12-04 17:32:40,153 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1106
2021-12-04 17:32:40,153 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1025
2021-12-04 17:32:40,153 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1081
2021-12-04 17:32:40,153 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1124
2021-12-04 17:32:40,153 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1082
2021-12-04 17:32:40,153 [dispatcher-event-loop-3] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_43_piece0 on qb:60226 in memory (size: 56.0 KB, free: 1990.7 MB)
2021-12-04 17:32:40,154 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1069
2021-12-04 17:32:40,154 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1041
2021-12-04 17:32:40,154 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1110
2021-12-04 17:32:40,154 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1070
2021-12-04 17:32:40,154 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1107
2021-12-04 17:32:40,154 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1095
2021-12-04 17:32:40,154 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1048
2021-12-04 17:32:40,154 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1092
2021-12-04 17:32:40,726 [Executor task launch worker for task 107] INFO [org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter] - Saved output of task 'attempt_20211204173239_0077_m_000000_0' to hdfs://hdp1:8020/sk/chongqing/list/train/_temporary/0/task_20211204173239_0077_m_000000
2021-12-04 17:32:40,726 [Executor task launch worker for task 107] INFO [org.apache.spark.mapred.SparkHadoopMapRedUtil] - attempt_20211204173239_0077_m_000000_0: Committed
2021-12-04 17:32:40,727 [Executor task launch worker for task 107] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 65.0 (TID 107). 1299 bytes result sent to driver
2021-12-04 17:32:40,727 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 65.0 (TID 107) in 799 ms on localhost (executor driver) (1/1)
2021-12-04 17:32:40,727 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 65.0, whose tasks have all completed, from pool 
2021-12-04 17:32:40,727 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 65 (runJob at SparkHadoopWriter.scala:78) finished in 0.810 s
2021-12-04 17:32:40,728 [main] INFO [org.apache.spark.scheduler.DAGScheduler] - Job 27 finished: runJob at SparkHadoopWriter.scala:78, took 0.810905 s
2021-12-04 17:32:40,770 [main] INFO [org.apache.spark.internal.io.SparkHadoopWriter] - Job job_20211204173239_0077 committed.
2021-12-04 17:32:40,778 [main] INFO [org.spark_project.jetty.server.AbstractConnector] - Stopped Spark@5b800468{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2021-12-04 17:32:40,780 [main] INFO [org.apache.spark.ui.SparkUI] - Stopped Spark web UI at http://qb:4040
2021-12-04 17:32:40,788 [dispatcher-event-loop-0] INFO [org.apache.spark.MapOutputTrackerMasterEndpoint] - MapOutputTrackerMasterEndpoint stopped!
2021-12-04 17:32:40,870 [main] INFO [org.apache.spark.storage.memory.MemoryStore] - MemoryStore cleared
2021-12-04 17:32:40,871 [main] INFO [org.apache.spark.storage.BlockManager] - BlockManager stopped
2021-12-04 17:32:40,871 [main] INFO [org.apache.spark.storage.BlockManagerMaster] - BlockManagerMaster stopped
2021-12-04 17:32:40,873 [dispatcher-event-loop-9] INFO [org.apache.spark.scheduler.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint] - OutputCommitCoordinator stopped!
2021-12-04 17:32:40,875 [main] INFO [org.apache.spark.SparkContext] - Successfully stopped SparkContext
2021-12-04 17:32:40,877 [Thread-1] INFO [org.apache.spark.util.ShutdownHookManager] - Shutdown hook called
2021-12-04 17:32:40,877 [Thread-1] INFO [org.apache.spark.util.ShutdownHookManager] - Deleting directory C:\Users\ACER\AppData\Local\Temp\spark-c87f74f0-ce7f-4c28-8c7d-0b929ea41954
2021-12-04 17:35:48,689 [main] INFO [org.apache.spark.SparkContext] - Running Spark version 2.3.0
2021-12-04 17:35:48,946 [main] INFO [org.apache.spark.SparkContext] - Submitted application: PaidPromotion
2021-12-04 17:35:48,990 [main] INFO [org.apache.spark.SecurityManager] - Changing view acls to: ACER,root
2021-12-04 17:35:48,990 [main] INFO [org.apache.spark.SecurityManager] - Changing modify acls to: ACER,root
2021-12-04 17:35:48,991 [main] INFO [org.apache.spark.SecurityManager] - Changing view acls groups to: 
2021-12-04 17:35:48,991 [main] INFO [org.apache.spark.SecurityManager] - Changing modify acls groups to: 
2021-12-04 17:35:48,991 [main] INFO [org.apache.spark.SecurityManager] - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(ACER, root); groups with view permissions: Set(); users  with modify permissions: Set(ACER, root); groups with modify permissions: Set()
2021-12-04 17:35:49,530 [main] INFO [org.apache.spark.util.Utils] - Successfully started service 'sparkDriver' on port 60418.
2021-12-04 17:35:49,545 [main] INFO [org.apache.spark.SparkEnv] - Registering MapOutputTracker
2021-12-04 17:35:49,559 [main] INFO [org.apache.spark.SparkEnv] - Registering BlockManagerMaster
2021-12-04 17:35:49,561 [main] INFO [org.apache.spark.storage.BlockManagerMasterEndpoint] - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2021-12-04 17:35:49,562 [main] INFO [org.apache.spark.storage.BlockManagerMasterEndpoint] - BlockManagerMasterEndpoint up
2021-12-04 17:35:49,570 [main] INFO [org.apache.spark.storage.DiskBlockManager] - Created local directory at C:\Users\ACER\AppData\Local\Temp\blockmgr-446f1f66-01f4-4fdb-9a50-1f5ade58c6dd
2021-12-04 17:35:49,584 [main] INFO [org.apache.spark.storage.memory.MemoryStore] - MemoryStore started with capacity 1990.8 MB
2021-12-04 17:35:49,593 [main] INFO [org.apache.spark.SparkEnv] - Registering OutputCommitCoordinator
2021-12-04 17:35:49,643 [main] INFO [org.spark_project.jetty.util.log] - Logging initialized @1770ms
2021-12-04 17:35:49,691 [main] INFO [org.spark_project.jetty.server.Server] - jetty-9.3.z-SNAPSHOT
2021-12-04 17:35:49,701 [main] INFO [org.spark_project.jetty.server.Server] - Started @1828ms
2021-12-04 17:35:49,725 [main] INFO [org.spark_project.jetty.server.AbstractConnector] - Started ServerConnector@5b800468{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2021-12-04 17:35:49,725 [main] INFO [org.apache.spark.util.Utils] - Successfully started service 'SparkUI' on port 4040.
2021-12-04 17:35:49,744 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@1568159{/jobs,null,AVAILABLE,@Spark}
2021-12-04 17:35:49,745 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@63cd604c{/jobs/json,null,AVAILABLE,@Spark}
2021-12-04 17:35:49,746 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@3954d008{/jobs/job,null,AVAILABLE,@Spark}
2021-12-04 17:35:49,747 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@6d8792db{/jobs/job/json,null,AVAILABLE,@Spark}
2021-12-04 17:35:49,749 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@3a1d593e{/stages,null,AVAILABLE,@Spark}
2021-12-04 17:35:49,750 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@285d851a{/stages/json,null,AVAILABLE,@Spark}
2021-12-04 17:35:49,750 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@7876d598{/stages/stage,null,AVAILABLE,@Spark}
2021-12-04 17:35:49,752 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@4985cbcb{/stages/stage/json,null,AVAILABLE,@Spark}
2021-12-04 17:35:49,753 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@54361a9{/stages/pool,null,AVAILABLE,@Spark}
2021-12-04 17:35:49,754 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@293bb8a5{/stages/pool/json,null,AVAILABLE,@Spark}
2021-12-04 17:35:49,755 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@290b1b2e{/storage,null,AVAILABLE,@Spark}
2021-12-04 17:35:49,756 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@5db4c359{/storage/json,null,AVAILABLE,@Spark}
2021-12-04 17:35:49,757 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@6fefce9e{/storage/rdd,null,AVAILABLE,@Spark}
2021-12-04 17:35:49,758 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@8a589a2{/storage/rdd/json,null,AVAILABLE,@Spark}
2021-12-04 17:35:49,759 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@5cc69cfe{/environment,null,AVAILABLE,@Spark}
2021-12-04 17:35:49,760 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@11dee337{/environment/json,null,AVAILABLE,@Spark}
2021-12-04 17:35:49,761 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@74bdc168{/executors,null,AVAILABLE,@Spark}
2021-12-04 17:35:49,763 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@7bb3a9fe{/executors/json,null,AVAILABLE,@Spark}
2021-12-04 17:35:49,764 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@f19c9d2{/executors/threadDump,null,AVAILABLE,@Spark}
2021-12-04 17:35:49,765 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@a77614d{/executors/threadDump/json,null,AVAILABLE,@Spark}
2021-12-04 17:35:49,772 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@523424b5{/static,null,AVAILABLE,@Spark}
2021-12-04 17:35:49,773 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@12cd9150{/,null,AVAILABLE,@Spark}
2021-12-04 17:35:49,774 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@32fe9d0a{/api,null,AVAILABLE,@Spark}
2021-12-04 17:35:49,775 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@59fc684e{/jobs/job/kill,null,AVAILABLE,@Spark}
2021-12-04 17:35:49,777 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@355e34c7{/stages/stage/kill,null,AVAILABLE,@Spark}
2021-12-04 17:35:49,779 [main] INFO [org.apache.spark.ui.SparkUI] - Bound SparkUI to 0.0.0.0, and started at http://qb:4040
2021-12-04 17:35:49,855 [main] INFO [org.apache.spark.executor.Executor] - Starting executor ID driver on host localhost
2021-12-04 17:35:49,905 [main] INFO [org.apache.spark.util.Utils] - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 60460.
2021-12-04 17:35:49,906 [main] INFO [org.apache.spark.network.netty.NettyBlockTransferService] - Server created on qb:60460
2021-12-04 17:35:49,907 [main] INFO [org.apache.spark.storage.BlockManager] - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2021-12-04 17:35:49,908 [main] INFO [org.apache.spark.storage.BlockManagerMaster] - Registering BlockManager BlockManagerId(driver, qb, 60460, None)
2021-12-04 17:35:49,910 [dispatcher-event-loop-10] INFO [org.apache.spark.storage.BlockManagerMasterEndpoint] - Registering block manager qb:60460 with 1990.8 MB RAM, BlockManagerId(driver, qb, 60460, None)
2021-12-04 17:35:49,912 [main] INFO [org.apache.spark.storage.BlockManagerMaster] - Registered BlockManager BlockManagerId(driver, qb, 60460, None)
2021-12-04 17:35:49,912 [main] INFO [org.apache.spark.storage.BlockManager] - Initialized BlockManager: BlockManagerId(driver, qb, 60460, None)
2021-12-04 17:35:50,049 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@6fe46b62{/metrics/json,null,AVAILABLE,@Spark}
2021-12-04 17:35:50,498 [main] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_0 stored as values in memory (estimated size 312.7 KB, free 1990.5 MB)
2021-12-04 17:35:50,687 [main] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_0_piece0 stored as bytes in memory (estimated size 27.3 KB, free 1990.5 MB)
2021-12-04 17:35:50,689 [dispatcher-event-loop-0] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_0_piece0 in memory on qb:60460 (size: 27.3 KB, free: 1990.8 MB)
2021-12-04 17:35:50,692 [main] INFO [org.apache.spark.SparkContext] - Created broadcast 0 from textFile at PaidPromotionAdjustParameter.scala:98
2021-12-04 17:35:51,013 [main] WARN [org.apache.hadoop.hdfs.shortcircuit.DomainSocketFactory] - The short-circuit local reads feature cannot be used because UNIX Domain sockets are not available on Windows.
2021-12-04 17:35:51,078 [main] INFO [org.apache.hadoop.mapred.FileInputFormat] - Total input paths to process : 1
2021-12-04 17:35:51,109 [main] INFO [org.apache.spark.SparkContext] - Starting job: count at PaidPromotionAdjustParameter.scala:100
2021-12-04 17:35:51,118 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 0 (count at PaidPromotionAdjustParameter.scala:100) with 2 output partitions
2021-12-04 17:35:51,118 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 0 (count at PaidPromotionAdjustParameter.scala:100)
2021-12-04 17:35:51,119 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List()
2021-12-04 17:35:51,119 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2021-12-04 17:35:51,125 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 0 (/sk/chongqing/data/order_data.bcp MapPartitionsRDD[1] at textFile at PaidPromotionAdjustParameter.scala:98), which has no missing parents
2021-12-04 17:35:51,152 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_1 stored as values in memory (estimated size 3.1 KB, free 1990.5 MB)
2021-12-04 17:35:51,157 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_1_piece0 stored as bytes in memory (estimated size 1900.0 B, free 1990.5 MB)
2021-12-04 17:35:51,157 [dispatcher-event-loop-1] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_1_piece0 in memory on qb:60460 (size: 1900.0 B, free: 1990.8 MB)
2021-12-04 17:35:51,157 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 1 from broadcast at DAGScheduler.scala:1039
2021-12-04 17:35:51,166 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from ResultStage 0 (/sk/chongqing/data/order_data.bcp MapPartitionsRDD[1] at textFile at PaidPromotionAdjustParameter.scala:98) (first 15 tasks are for partitions Vector(0, 1))
2021-12-04 17:35:51,167 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 0.0 with 2 tasks
2021-12-04 17:35:51,196 [dispatcher-event-loop-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 0.0 (TID 0, localhost, executor driver, partition 0, ANY, 7896 bytes)
2021-12-04 17:35:51,197 [dispatcher-event-loop-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 0.0 (TID 1, localhost, executor driver, partition 1, ANY, 7896 bytes)
2021-12-04 17:35:51,202 [Executor task launch worker for task 1] INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 0.0 (TID 1)
2021-12-04 17:35:51,202 [Executor task launch worker for task 0] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 0.0 (TID 0)
2021-12-04 17:35:51,234 [Executor task launch worker for task 1] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/order_data.bcp:3442194+3442195
2021-12-04 17:35:51,234 [Executor task launch worker for task 0] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/order_data.bcp:0+3442194
2021-12-04 17:35:51,674 [Executor task launch worker for task 1] INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 0.0 (TID 1). 754 bytes result sent to driver
2021-12-04 17:35:51,683 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 0.0 (TID 1) in 485 ms on localhost (executor driver) (1/2)
2021-12-04 17:35:52,114 [Executor task launch worker for task 0] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 0.0 (TID 0). 754 bytes result sent to driver
2021-12-04 17:35:52,117 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 0.0 (TID 0) in 929 ms on localhost (executor driver) (2/2)
2021-12-04 17:35:52,118 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 0.0, whose tasks have all completed, from pool 
2021-12-04 17:35:52,118 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 0 (count at PaidPromotionAdjustParameter.scala:100) finished in 0.981 s
2021-12-04 17:35:52,122 [main] INFO [org.apache.spark.scheduler.DAGScheduler] - Job 0 finished: count at PaidPromotionAdjustParameter.scala:100, took 1.012960 s
2021-12-04 17:35:52,123 [main] INFO [PaidPromotion$] - 订购总数107294
2021-12-04 17:35:52,128 [main] INFO [org.apache.spark.SparkContext] - Starting job: count at PaidPromotionAdjustParameter.scala:108
2021-12-04 17:35:52,128 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 1 (count at PaidPromotionAdjustParameter.scala:108) with 2 output partitions
2021-12-04 17:35:52,128 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 1 (count at PaidPromotionAdjustParameter.scala:108)
2021-12-04 17:35:52,128 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List()
2021-12-04 17:35:52,129 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2021-12-04 17:35:52,129 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 1 (MapPartitionsRDD[2] at map at PaidPromotionAdjustParameter.scala:104), which has no missing parents
2021-12-04 17:35:52,130 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_2 stored as values in memory (estimated size 3.3 KB, free 1990.5 MB)
2021-12-04 17:35:52,135 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_2_piece0 stored as bytes in memory (estimated size 1985.0 B, free 1990.5 MB)
2021-12-04 17:35:52,135 [dispatcher-event-loop-8] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_2_piece0 in memory on qb:60460 (size: 1985.0 B, free: 1990.8 MB)
2021-12-04 17:35:52,136 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 2 from broadcast at DAGScheduler.scala:1039
2021-12-04 17:35:52,137 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from ResultStage 1 (MapPartitionsRDD[2] at map at PaidPromotionAdjustParameter.scala:104) (first 15 tasks are for partitions Vector(0, 1))
2021-12-04 17:35:52,137 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 1.0 with 2 tasks
2021-12-04 17:35:52,137 [dispatcher-event-loop-7] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 1.0 (TID 2, localhost, executor driver, partition 0, ANY, 7896 bytes)
2021-12-04 17:35:52,138 [dispatcher-event-loop-7] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 1.0 (TID 3, localhost, executor driver, partition 1, ANY, 7896 bytes)
2021-12-04 17:35:52,138 [Executor task launch worker for task 2] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 1.0 (TID 2)
2021-12-04 17:35:52,138 [Executor task launch worker for task 3] INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 1.0 (TID 3)
2021-12-04 17:35:52,141 [Executor task launch worker for task 2] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/order_data.bcp:0+3442194
2021-12-04 17:35:52,141 [Executor task launch worker for task 3] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/order_data.bcp:3442194+3442195
2021-12-04 17:35:52,188 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 21
2021-12-04 17:35:52,188 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 6
2021-12-04 17:35:52,188 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1
2021-12-04 17:35:52,188 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 18
2021-12-04 17:35:52,188 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 7
2021-12-04 17:35:52,188 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 19
2021-12-04 17:35:52,188 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 22
2021-12-04 17:35:52,188 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 13
2021-12-04 17:35:52,188 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 17
2021-12-04 17:35:52,189 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 15
2021-12-04 17:35:52,189 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 0
2021-12-04 17:35:52,189 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 8
2021-12-04 17:35:52,189 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 3
2021-12-04 17:35:52,189 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 14
2021-12-04 17:35:52,189 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 23
2021-12-04 17:35:52,189 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 20
2021-12-04 17:35:52,189 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 2
2021-12-04 17:35:52,189 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 16
2021-12-04 17:35:52,189 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 10
2021-12-04 17:35:52,189 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 9
2021-12-04 17:35:52,201 [dispatcher-event-loop-1] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_1_piece0 on qb:60460 in memory (size: 1900.0 B, free: 1990.8 MB)
2021-12-04 17:35:52,202 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 12
2021-12-04 17:35:52,202 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 5
2021-12-04 17:35:52,203 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 4
2021-12-04 17:35:52,203 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 11
2021-12-04 17:35:52,203 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 24
2021-12-04 17:35:52,612 [Executor task launch worker for task 3] INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 1.0 (TID 3). 754 bytes result sent to driver
2021-12-04 17:35:52,615 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 1.0 (TID 3) in 478 ms on localhost (executor driver) (1/2)
2021-12-04 17:35:52,796 [Executor task launch worker for task 2] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 1.0 (TID 2). 754 bytes result sent to driver
2021-12-04 17:35:52,798 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 1.0 (TID 2) in 661 ms on localhost (executor driver) (2/2)
2021-12-04 17:35:52,798 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 1.0, whose tasks have all completed, from pool 
2021-12-04 17:35:52,798 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 1 (count at PaidPromotionAdjustParameter.scala:108) finished in 0.669 s
2021-12-04 17:35:52,798 [main] INFO [org.apache.spark.scheduler.DAGScheduler] - Job 1 finished: count at PaidPromotionAdjustParameter.scala:108, took 0.670239 s
2021-12-04 17:35:52,799 [main] INFO [PaidPromotion$] - 订购总数：107294
2021-12-04 17:35:52,812 [main] INFO [org.apache.spark.SparkContext] - Starting job: count at PaidPromotionAdjustParameter.scala:121
2021-12-04 17:35:52,812 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 2 (count at PaidPromotionAdjustParameter.scala:121) with 2 output partitions
2021-12-04 17:35:52,812 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 2 (count at PaidPromotionAdjustParameter.scala:121)
2021-12-04 17:35:52,812 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List()
2021-12-04 17:35:52,812 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2021-12-04 17:35:52,812 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 2 (MapPartitionsRDD[3] at randomSplit at PaidPromotionAdjustParameter.scala:114), which has no missing parents
2021-12-04 17:35:52,814 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_3 stored as values in memory (estimated size 3.6 KB, free 1990.5 MB)
2021-12-04 17:35:52,821 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 33
2021-12-04 17:35:52,821 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 46
2021-12-04 17:35:52,821 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 32
2021-12-04 17:35:52,821 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 47
2021-12-04 17:35:52,821 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 48
2021-12-04 17:35:52,821 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 41
2021-12-04 17:35:52,821 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_3_piece0 stored as bytes in memory (estimated size 2.1 KB, free 1990.5 MB)
2021-12-04 17:35:52,822 [dispatcher-event-loop-6] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_3_piece0 in memory on qb:60460 (size: 2.1 KB, free: 1990.8 MB)
2021-12-04 17:35:52,822 [dispatcher-event-loop-6] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_2_piece0 on qb:60460 in memory (size: 1985.0 B, free: 1990.8 MB)
2021-12-04 17:35:52,822 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 3 from broadcast at DAGScheduler.scala:1039
2021-12-04 17:35:52,822 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 43
2021-12-04 17:35:52,822 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 25
2021-12-04 17:35:52,822 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 38
2021-12-04 17:35:52,822 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 35
2021-12-04 17:35:52,822 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 26
2021-12-04 17:35:52,822 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 40
2021-12-04 17:35:52,822 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 39
2021-12-04 17:35:52,822 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 28
2021-12-04 17:35:52,822 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 30
2021-12-04 17:35:52,823 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 34
2021-12-04 17:35:52,823 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 37
2021-12-04 17:35:52,823 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 44
2021-12-04 17:35:52,823 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 42
2021-12-04 17:35:52,823 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 45
2021-12-04 17:35:52,823 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 36
2021-12-04 17:35:52,823 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 27
2021-12-04 17:35:52,823 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 49
2021-12-04 17:35:52,823 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 31
2021-12-04 17:35:52,823 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 29
2021-12-04 17:35:52,823 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from ResultStage 2 (MapPartitionsRDD[3] at randomSplit at PaidPromotionAdjustParameter.scala:114) (first 15 tasks are for partitions Vector(0, 1))
2021-12-04 17:35:52,823 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 2.0 with 2 tasks
2021-12-04 17:35:52,824 [dispatcher-event-loop-7] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 2.0 (TID 4, localhost, executor driver, partition 0, ANY, 7896 bytes)
2021-12-04 17:35:52,824 [dispatcher-event-loop-7] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 2.0 (TID 5, localhost, executor driver, partition 1, ANY, 7896 bytes)
2021-12-04 17:35:52,824 [Executor task launch worker for task 5] INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 2.0 (TID 5)
2021-12-04 17:35:52,824 [Executor task launch worker for task 4] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 2.0 (TID 4)
2021-12-04 17:35:52,828 [Executor task launch worker for task 4] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/order_data.bcp:0+3442194
2021-12-04 17:35:52,828 [Executor task launch worker for task 5] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/order_data.bcp:3442194+3442195
2021-12-04 17:35:53,377 [Executor task launch worker for task 5] INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 2.0 (TID 5). 711 bytes result sent to driver
2021-12-04 17:35:53,377 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 2.0 (TID 5) in 553 ms on localhost (executor driver) (1/2)
2021-12-04 17:35:53,562 [Executor task launch worker for task 4] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 2.0 (TID 4). 711 bytes result sent to driver
2021-12-04 17:35:53,562 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 2.0 (TID 4) in 738 ms on localhost (executor driver) (2/2)
2021-12-04 17:35:53,563 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 2.0, whose tasks have all completed, from pool 
2021-12-04 17:35:53,563 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 2 (count at PaidPromotionAdjustParameter.scala:121) finished in 0.750 s
2021-12-04 17:35:53,563 [main] INFO [org.apache.spark.scheduler.DAGScheduler] - Job 2 finished: count at PaidPromotionAdjustParameter.scala:121, took 0.752037 s
2021-12-04 17:35:53,563 [main] INFO [PaidPromotion$] - 初次切分训练集数量：67349
2021-12-04 17:35:53,566 [main] INFO [org.apache.spark.SparkContext] - Starting job: count at PaidPromotionAdjustParameter.scala:122
2021-12-04 17:35:53,566 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 3 (count at PaidPromotionAdjustParameter.scala:122) with 2 output partitions
2021-12-04 17:35:53,566 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 3 (count at PaidPromotionAdjustParameter.scala:122)
2021-12-04 17:35:53,566 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List()
2021-12-04 17:35:53,566 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2021-12-04 17:35:53,566 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 3 (MapPartitionsRDD[4] at randomSplit at PaidPromotionAdjustParameter.scala:114), which has no missing parents
2021-12-04 17:35:53,568 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_4 stored as values in memory (estimated size 3.6 KB, free 1990.5 MB)
2021-12-04 17:35:53,570 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_4_piece0 stored as bytes in memory (estimated size 2.1 KB, free 1990.5 MB)
2021-12-04 17:35:53,571 [dispatcher-event-loop-1] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_4_piece0 in memory on qb:60460 (size: 2.1 KB, free: 1990.8 MB)
2021-12-04 17:35:53,571 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 4 from broadcast at DAGScheduler.scala:1039
2021-12-04 17:35:53,572 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from ResultStage 3 (MapPartitionsRDD[4] at randomSplit at PaidPromotionAdjustParameter.scala:114) (first 15 tasks are for partitions Vector(0, 1))
2021-12-04 17:35:53,572 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 3.0 with 2 tasks
2021-12-04 17:35:53,573 [dispatcher-event-loop-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 3.0 (TID 6, localhost, executor driver, partition 0, ANY, 7896 bytes)
2021-12-04 17:35:53,573 [dispatcher-event-loop-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 3.0 (TID 7, localhost, executor driver, partition 1, ANY, 7896 bytes)
2021-12-04 17:35:53,573 [Executor task launch worker for task 6] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 3.0 (TID 6)
2021-12-04 17:35:53,573 [Executor task launch worker for task 7] INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 3.0 (TID 7)
2021-12-04 17:35:53,575 [Executor task launch worker for task 6] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/order_data.bcp:0+3442194
2021-12-04 17:35:53,575 [Executor task launch worker for task 7] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/order_data.bcp:3442194+3442195
2021-12-04 17:35:53,830 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 58
2021-12-04 17:35:53,830 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 59
2021-12-04 17:35:53,831 [dispatcher-event-loop-6] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_3_piece0 on qb:60460 in memory (size: 2.1 KB, free: 1990.8 MB)
2021-12-04 17:35:53,831 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 69
2021-12-04 17:35:53,831 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 71
2021-12-04 17:35:53,832 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 68
2021-12-04 17:35:53,832 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 56
2021-12-04 17:35:53,832 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 53
2021-12-04 17:35:53,832 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 60
2021-12-04 17:35:53,832 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 51
2021-12-04 17:35:53,832 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 57
2021-12-04 17:35:53,832 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 54
2021-12-04 17:35:53,832 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 50
2021-12-04 17:35:53,832 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 55
2021-12-04 17:35:53,832 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 70
2021-12-04 17:35:53,832 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 63
2021-12-04 17:35:53,832 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 61
2021-12-04 17:35:53,832 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 73
2021-12-04 17:35:53,832 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 62
2021-12-04 17:35:53,832 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 74
2021-12-04 17:35:53,832 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 65
2021-12-04 17:35:53,832 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 52
2021-12-04 17:35:53,832 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 67
2021-12-04 17:35:53,832 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 64
2021-12-04 17:35:53,832 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 72
2021-12-04 17:35:53,832 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 66
2021-12-04 17:35:54,039 [Executor task launch worker for task 7] INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 3.0 (TID 7). 797 bytes result sent to driver
2021-12-04 17:35:54,039 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 3.0 (TID 7) in 466 ms on localhost (executor driver) (1/2)
2021-12-04 17:35:54,255 [Executor task launch worker for task 6] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 3.0 (TID 6). 797 bytes result sent to driver
2021-12-04 17:35:54,255 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 3.0 (TID 6) in 683 ms on localhost (executor driver) (2/2)
2021-12-04 17:35:54,256 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 3.0, whose tasks have all completed, from pool 
2021-12-04 17:35:54,256 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 3 (count at PaidPromotionAdjustParameter.scala:122) finished in 0.689 s
2021-12-04 17:35:54,256 [main] INFO [org.apache.spark.scheduler.DAGScheduler] - Job 3 finished: count at PaidPromotionAdjustParameter.scala:122, took 0.690514 s
2021-12-04 17:35:54,256 [main] INFO [PaidPromotion$] - 初次切分验证集数量：39945
2021-12-04 17:35:54,308 [main] INFO [PaidPromotion$] - -----------------------------------
2021-12-04 17:35:54,310 [main] INFO [org.apache.spark.SparkContext] - Starting job: count at PaidPromotionAdjustParameter.scala:138
2021-12-04 17:35:54,315 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 6 (distinct at PaidPromotionAdjustParameter.scala:128)
2021-12-04 17:35:54,316 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 4 (count at PaidPromotionAdjustParameter.scala:138) with 2 output partitions
2021-12-04 17:35:54,316 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 5 (count at PaidPromotionAdjustParameter.scala:138)
2021-12-04 17:35:54,316 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 4)
2021-12-04 17:35:54,317 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List(ShuffleMapStage 4)
2021-12-04 17:35:54,317 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ShuffleMapStage 4 (MapPartitionsRDD[6] at distinct at PaidPromotionAdjustParameter.scala:128), which has no missing parents
2021-12-04 17:35:54,325 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_5 stored as values in memory (estimated size 5.2 KB, free 1990.5 MB)
2021-12-04 17:35:54,328 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_5_piece0 stored as bytes in memory (estimated size 2.9 KB, free 1990.5 MB)
2021-12-04 17:35:54,328 [dispatcher-event-loop-10] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_5_piece0 in memory on qb:60460 (size: 2.9 KB, free: 1990.8 MB)
2021-12-04 17:35:54,329 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 5 from broadcast at DAGScheduler.scala:1039
2021-12-04 17:35:54,330 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from ShuffleMapStage 4 (MapPartitionsRDD[6] at distinct at PaidPromotionAdjustParameter.scala:128) (first 15 tasks are for partitions Vector(0, 1))
2021-12-04 17:35:54,330 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 4.0 with 2 tasks
2021-12-04 17:35:54,331 [dispatcher-event-loop-11] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 4.0 (TID 8, localhost, executor driver, partition 0, ANY, 7885 bytes)
2021-12-04 17:35:54,332 [dispatcher-event-loop-11] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 4.0 (TID 9, localhost, executor driver, partition 1, ANY, 7885 bytes)
2021-12-04 17:35:54,332 [Executor task launch worker for task 9] INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 4.0 (TID 9)
2021-12-04 17:35:54,332 [Executor task launch worker for task 8] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 4.0 (TID 8)
2021-12-04 17:35:54,336 [Executor task launch worker for task 9] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/order_data.bcp:3442194+3442195
2021-12-04 17:35:54,336 [Executor task launch worker for task 8] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/order_data.bcp:0+3442194
2021-12-04 17:35:54,630 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 97
2021-12-04 17:35:54,630 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 78
2021-12-04 17:35:54,630 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 96
2021-12-04 17:35:54,630 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 93
2021-12-04 17:35:54,631 [dispatcher-event-loop-5] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_4_piece0 on qb:60460 in memory (size: 2.1 KB, free: 1990.8 MB)
2021-12-04 17:35:54,632 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 77
2021-12-04 17:35:54,632 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 82
2021-12-04 17:35:54,632 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 95
2021-12-04 17:35:54,632 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 86
2021-12-04 17:35:54,632 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 79
2021-12-04 17:35:54,632 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 76
2021-12-04 17:35:54,633 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 75
2021-12-04 17:35:54,633 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 88
2021-12-04 17:35:54,633 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 85
2021-12-04 17:35:54,633 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 92
2021-12-04 17:35:54,633 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 87
2021-12-04 17:35:54,633 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 83
2021-12-04 17:35:54,633 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 99
2021-12-04 17:35:54,633 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 98
2021-12-04 17:35:54,633 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 84
2021-12-04 17:35:54,633 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 80
2021-12-04 17:35:54,633 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 89
2021-12-04 17:35:54,633 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 81
2021-12-04 17:35:54,633 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 90
2021-12-04 17:35:54,633 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 94
2021-12-04 17:35:54,633 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 91
2021-12-04 17:35:54,897 [Executor task launch worker for task 8] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 4.0 (TID 8). 1032 bytes result sent to driver
2021-12-04 17:35:54,910 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 4.0 (TID 8) in 579 ms on localhost (executor driver) (1/2)
2021-12-04 17:35:55,091 [Executor task launch worker for task 9] INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 4.0 (TID 9). 1032 bytes result sent to driver
2021-12-04 17:35:55,092 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 4.0 (TID 9) in 761 ms on localhost (executor driver) (2/2)
2021-12-04 17:35:55,092 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 4.0, whose tasks have all completed, from pool 
2021-12-04 17:35:55,092 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ShuffleMapStage 4 (distinct at PaidPromotionAdjustParameter.scala:128) finished in 0.773 s
2021-12-04 17:35:55,093 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - looking for newly runnable stages
2021-12-04 17:35:55,093 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - running: Set()
2021-12-04 17:35:55,093 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - waiting: Set(ResultStage 5)
2021-12-04 17:35:55,094 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - failed: Set()
2021-12-04 17:35:55,096 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 5 (MapPartitionsRDD[8] at distinct at PaidPromotionAdjustParameter.scala:128), which has no missing parents
2021-12-04 17:35:55,100 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_6 stored as values in memory (estimated size 3.7 KB, free 1990.5 MB)
2021-12-04 17:35:55,102 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_6_piece0 stored as bytes in memory (estimated size 2.2 KB, free 1990.5 MB)
2021-12-04 17:35:55,103 [dispatcher-event-loop-6] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_6_piece0 in memory on qb:60460 (size: 2.2 KB, free: 1990.8 MB)
2021-12-04 17:35:55,103 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 6 from broadcast at DAGScheduler.scala:1039
2021-12-04 17:35:55,103 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from ResultStage 5 (MapPartitionsRDD[8] at distinct at PaidPromotionAdjustParameter.scala:128) (first 15 tasks are for partitions Vector(0, 1))
2021-12-04 17:35:55,103 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 5.0 with 2 tasks
2021-12-04 17:35:55,105 [dispatcher-event-loop-7] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 5.0 (TID 10, localhost, executor driver, partition 0, ANY, 7649 bytes)
2021-12-04 17:35:55,105 [dispatcher-event-loop-7] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 5.0 (TID 11, localhost, executor driver, partition 1, ANY, 7649 bytes)
2021-12-04 17:35:55,105 [Executor task launch worker for task 10] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 5.0 (TID 10)
2021-12-04 17:35:55,105 [Executor task launch worker for task 11] INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 5.0 (TID 11)
2021-12-04 17:35:55,115 [Executor task launch worker for task 11] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 2 non-empty blocks out of 2 blocks
2021-12-04 17:35:55,115 [Executor task launch worker for task 10] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 2 non-empty blocks out of 2 blocks
2021-12-04 17:35:55,117 [Executor task launch worker for task 10] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 5 ms
2021-12-04 17:35:55,117 [Executor task launch worker for task 11] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 5 ms
2021-12-04 17:35:55,258 [Executor task launch worker for task 10] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 5.0 (TID 10). 1012 bytes result sent to driver
2021-12-04 17:35:55,258 [Executor task launch worker for task 11] INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 5.0 (TID 11). 1098 bytes result sent to driver
2021-12-04 17:35:55,259 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 5.0 (TID 10) in 154 ms on localhost (executor driver) (1/2)
2021-12-04 17:35:55,259 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 5.0 (TID 11) in 154 ms on localhost (executor driver) (2/2)
2021-12-04 17:35:55,259 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 5.0, whose tasks have all completed, from pool 
2021-12-04 17:35:55,259 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 5 (count at PaidPromotionAdjustParameter.scala:138) finished in 0.162 s
2021-12-04 17:35:55,260 [main] INFO [org.apache.spark.scheduler.DAGScheduler] - Job 4 finished: count at PaidPromotionAdjustParameter.scala:138, took 0.949356 s
2021-12-04 17:35:55,260 [main] INFO [PaidPromotion$] - 训练集用户数 = 62203
2021-12-04 17:35:55,263 [main] INFO [org.apache.spark.SparkContext] - Starting job: count at PaidPromotionAdjustParameter.scala:139
2021-12-04 17:35:55,263 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 10 (distinct at PaidPromotionAdjustParameter.scala:129)
2021-12-04 17:35:55,263 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 5 (count at PaidPromotionAdjustParameter.scala:139) with 2 output partitions
2021-12-04 17:35:55,263 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 7 (count at PaidPromotionAdjustParameter.scala:139)
2021-12-04 17:35:55,263 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 6)
2021-12-04 17:35:55,263 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List(ShuffleMapStage 6)
2021-12-04 17:35:55,264 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ShuffleMapStage 6 (MapPartitionsRDD[10] at distinct at PaidPromotionAdjustParameter.scala:129), which has no missing parents
2021-12-04 17:35:55,265 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_7 stored as values in memory (estimated size 5.2 KB, free 1990.4 MB)
2021-12-04 17:35:55,268 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_7_piece0 stored as bytes in memory (estimated size 2.9 KB, free 1990.4 MB)
2021-12-04 17:35:55,269 [dispatcher-event-loop-0] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_7_piece0 in memory on qb:60460 (size: 2.9 KB, free: 1990.8 MB)
2021-12-04 17:35:55,269 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 7 from broadcast at DAGScheduler.scala:1039
2021-12-04 17:35:55,269 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from ShuffleMapStage 6 (MapPartitionsRDD[10] at distinct at PaidPromotionAdjustParameter.scala:129) (first 15 tasks are for partitions Vector(0, 1))
2021-12-04 17:35:55,269 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 6.0 with 2 tasks
2021-12-04 17:35:55,270 [dispatcher-event-loop-4] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 6.0 (TID 12, localhost, executor driver, partition 0, ANY, 7885 bytes)
2021-12-04 17:35:55,270 [dispatcher-event-loop-4] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 6.0 (TID 13, localhost, executor driver, partition 1, ANY, 7885 bytes)
2021-12-04 17:35:55,270 [Executor task launch worker for task 13] INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 6.0 (TID 13)
2021-12-04 17:35:55,270 [Executor task launch worker for task 12] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 6.0 (TID 12)
2021-12-04 17:35:55,272 [Executor task launch worker for task 12] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/order_data.bcp:0+3442194
2021-12-04 17:35:55,272 [Executor task launch worker for task 13] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/order_data.bcp:3442194+3442195
2021-12-04 17:35:55,602 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 111
2021-12-04 17:35:55,603 [dispatcher-event-loop-6] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_5_piece0 on qb:60460 in memory (size: 2.9 KB, free: 1990.8 MB)
2021-12-04 17:35:55,604 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 142
2021-12-04 17:35:55,604 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 136
2021-12-04 17:35:55,604 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 126
2021-12-04 17:35:55,604 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 129
2021-12-04 17:35:55,604 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 123
2021-12-04 17:35:55,604 [dispatcher-event-loop-9] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_6_piece0 on qb:60460 in memory (size: 2.2 KB, free: 1990.8 MB)
2021-12-04 17:35:55,605 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 133
2021-12-04 17:35:55,605 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 134
2021-12-04 17:35:55,605 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 110
2021-12-04 17:35:55,605 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 128
2021-12-04 17:35:55,605 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 148
2021-12-04 17:35:55,605 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 106
2021-12-04 17:35:55,605 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 124
2021-12-04 17:35:55,605 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 145
2021-12-04 17:35:55,605 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 105
2021-12-04 17:35:55,605 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 102
2021-12-04 17:35:55,605 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 117
2021-12-04 17:35:55,605 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 100
2021-12-04 17:35:55,605 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 143
2021-12-04 17:35:55,605 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 107
2021-12-04 17:35:55,605 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 137
2021-12-04 17:35:55,605 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 140
2021-12-04 17:35:55,605 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 121
2021-12-04 17:35:55,606 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 132
2021-12-04 17:35:55,606 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 112
2021-12-04 17:35:55,606 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 135
2021-12-04 17:35:55,606 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 147
2021-12-04 17:35:55,606 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 114
2021-12-04 17:35:55,606 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 130
2021-12-04 17:35:55,606 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 146
2021-12-04 17:35:55,606 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 116
2021-12-04 17:35:55,606 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 127
2021-12-04 17:35:55,606 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 108
2021-12-04 17:35:55,606 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 131
2021-12-04 17:35:55,606 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 138
2021-12-04 17:35:55,606 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 141
2021-12-04 17:35:55,606 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 119
2021-12-04 17:35:55,606 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 115
2021-12-04 17:35:55,606 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 120
2021-12-04 17:35:55,606 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 109
2021-12-04 17:35:55,606 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 118
2021-12-04 17:35:55,606 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 101
2021-12-04 17:35:55,606 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 149
2021-12-04 17:35:55,606 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 113
2021-12-04 17:35:55,606 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 144
2021-12-04 17:35:55,606 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 103
2021-12-04 17:35:55,606 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 104
2021-12-04 17:35:55,606 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 125
2021-12-04 17:35:55,606 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 139
2021-12-04 17:35:55,606 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 122
2021-12-04 17:35:55,666 [Executor task launch worker for task 13] INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 6.0 (TID 13). 1032 bytes result sent to driver
2021-12-04 17:35:55,667 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 6.0 (TID 13) in 397 ms on localhost (executor driver) (1/2)
2021-12-04 17:35:55,969 [Executor task launch worker for task 12] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 6.0 (TID 12). 1032 bytes result sent to driver
2021-12-04 17:35:55,970 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 6.0 (TID 12) in 700 ms on localhost (executor driver) (2/2)
2021-12-04 17:35:55,970 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 6.0, whose tasks have all completed, from pool 
2021-12-04 17:35:55,970 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ShuffleMapStage 6 (distinct at PaidPromotionAdjustParameter.scala:129) finished in 0.706 s
2021-12-04 17:35:55,970 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - looking for newly runnable stages
2021-12-04 17:35:55,970 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - running: Set()
2021-12-04 17:35:55,971 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - waiting: Set(ResultStage 7)
2021-12-04 17:35:55,971 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - failed: Set()
2021-12-04 17:35:55,971 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 7 (MapPartitionsRDD[12] at distinct at PaidPromotionAdjustParameter.scala:129), which has no missing parents
2021-12-04 17:35:55,972 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_8 stored as values in memory (estimated size 3.7 KB, free 1990.5 MB)
2021-12-04 17:35:55,974 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_8_piece0 stored as bytes in memory (estimated size 2.2 KB, free 1990.5 MB)
2021-12-04 17:35:55,974 [dispatcher-event-loop-0] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_8_piece0 in memory on qb:60460 (size: 2.2 KB, free: 1990.8 MB)
2021-12-04 17:35:55,975 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 8 from broadcast at DAGScheduler.scala:1039
2021-12-04 17:35:55,975 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from ResultStage 7 (MapPartitionsRDD[12] at distinct at PaidPromotionAdjustParameter.scala:129) (first 15 tasks are for partitions Vector(0, 1))
2021-12-04 17:35:55,975 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 7.0 with 2 tasks
2021-12-04 17:35:55,975 [dispatcher-event-loop-4] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 7.0 (TID 14, localhost, executor driver, partition 0, ANY, 7649 bytes)
2021-12-04 17:35:55,976 [dispatcher-event-loop-4] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 7.0 (TID 15, localhost, executor driver, partition 1, ANY, 7649 bytes)
2021-12-04 17:35:55,976 [Executor task launch worker for task 14] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 7.0 (TID 14)
2021-12-04 17:35:55,976 [Executor task launch worker for task 15] INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 7.0 (TID 15)
2021-12-04 17:35:55,977 [Executor task launch worker for task 14] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 2 non-empty blocks out of 2 blocks
2021-12-04 17:35:55,977 [Executor task launch worker for task 14] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-04 17:35:55,977 [Executor task launch worker for task 15] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 2 non-empty blocks out of 2 blocks
2021-12-04 17:35:55,977 [Executor task launch worker for task 15] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-04 17:35:56,015 [Executor task launch worker for task 14] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 7.0 (TID 14). 1055 bytes result sent to driver
2021-12-04 17:35:56,016 [Executor task launch worker for task 15] INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 7.0 (TID 15). 1055 bytes result sent to driver
2021-12-04 17:35:56,016 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 7.0 (TID 14) in 41 ms on localhost (executor driver) (1/2)
2021-12-04 17:35:56,016 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 7.0 (TID 15) in 41 ms on localhost (executor driver) (2/2)
2021-12-04 17:35:56,016 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 7.0, whose tasks have all completed, from pool 
2021-12-04 17:35:56,017 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 7 (count at PaidPromotionAdjustParameter.scala:139) finished in 0.046 s
2021-12-04 17:35:56,017 [main] INFO [org.apache.spark.scheduler.DAGScheduler] - Job 5 finished: count at PaidPromotionAdjustParameter.scala:139, took 0.754617 s
2021-12-04 17:35:56,017 [main] INFO [PaidPromotion$] - 验证集用户数 = 38030
2021-12-04 17:35:56,021 [main] INFO [org.apache.spark.SparkContext] - Starting job: count at PaidPromotionAdjustParameter.scala:140
2021-12-04 17:35:56,022 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 14 (intersection at PaidPromotionAdjustParameter.scala:130)
2021-12-04 17:35:56,022 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 13 (intersection at PaidPromotionAdjustParameter.scala:130)
2021-12-04 17:35:56,022 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 6 (count at PaidPromotionAdjustParameter.scala:140) with 2 output partitions
2021-12-04 17:35:56,022 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 12 (count at PaidPromotionAdjustParameter.scala:140)
2021-12-04 17:35:56,022 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 9, ShuffleMapStage 11)
2021-12-04 17:35:56,022 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List(ShuffleMapStage 9, ShuffleMapStage 11)
2021-12-04 17:35:56,023 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ShuffleMapStage 9 (MapPartitionsRDD[14] at intersection at PaidPromotionAdjustParameter.scala:130), which has no missing parents
2021-12-04 17:35:56,024 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_9 stored as values in memory (estimated size 4.0 KB, free 1990.5 MB)
2021-12-04 17:35:56,026 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_9_piece0 stored as bytes in memory (estimated size 2.3 KB, free 1990.4 MB)
2021-12-04 17:35:56,027 [dispatcher-event-loop-6] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_9_piece0 in memory on qb:60460 (size: 2.3 KB, free: 1990.8 MB)
2021-12-04 17:35:56,027 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 9 from broadcast at DAGScheduler.scala:1039
2021-12-04 17:35:56,027 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from ShuffleMapStage 9 (MapPartitionsRDD[14] at intersection at PaidPromotionAdjustParameter.scala:130) (first 15 tasks are for partitions Vector(0, 1))
2021-12-04 17:35:56,027 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 9.0 with 2 tasks
2021-12-04 17:35:56,028 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ShuffleMapStage 11 (MapPartitionsRDD[13] at intersection at PaidPromotionAdjustParameter.scala:130), which has no missing parents
2021-12-04 17:35:56,028 [dispatcher-event-loop-10] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 9.0 (TID 16, localhost, executor driver, partition 0, ANY, 7638 bytes)
2021-12-04 17:35:56,028 [dispatcher-event-loop-10] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 9.0 (TID 17, localhost, executor driver, partition 1, ANY, 7638 bytes)
2021-12-04 17:35:56,028 [Executor task launch worker for task 17] INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 9.0 (TID 17)
2021-12-04 17:35:56,028 [Executor task launch worker for task 16] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 9.0 (TID 16)
2021-12-04 17:35:56,029 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_10 stored as values in memory (estimated size 4.0 KB, free 1990.4 MB)
2021-12-04 17:35:56,030 [Executor task launch worker for task 17] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 2 non-empty blocks out of 2 blocks
2021-12-04 17:35:56,030 [Executor task launch worker for task 16] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 2 non-empty blocks out of 2 blocks
2021-12-04 17:35:56,030 [Executor task launch worker for task 17] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-04 17:35:56,030 [Executor task launch worker for task 16] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-04 17:35:56,031 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_10_piece0 stored as bytes in memory (estimated size 2.3 KB, free 1990.4 MB)
2021-12-04 17:35:56,032 [dispatcher-event-loop-1] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_10_piece0 in memory on qb:60460 (size: 2.3 KB, free: 1990.8 MB)
2021-12-04 17:35:56,032 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 10 from broadcast at DAGScheduler.scala:1039
2021-12-04 17:35:56,032 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from ShuffleMapStage 11 (MapPartitionsRDD[13] at intersection at PaidPromotionAdjustParameter.scala:130) (first 15 tasks are for partitions Vector(0, 1))
2021-12-04 17:35:56,032 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 11.0 with 2 tasks
2021-12-04 17:35:56,033 [dispatcher-event-loop-11] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 11.0 (TID 18, localhost, executor driver, partition 0, ANY, 7638 bytes)
2021-12-04 17:35:56,033 [dispatcher-event-loop-11] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 11.0 (TID 19, localhost, executor driver, partition 1, ANY, 7638 bytes)
2021-12-04 17:35:56,034 [Executor task launch worker for task 18] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 11.0 (TID 18)
2021-12-04 17:35:56,034 [Executor task launch worker for task 19] INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 11.0 (TID 19)
2021-12-04 17:35:56,035 [Executor task launch worker for task 19] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 2 non-empty blocks out of 2 blocks
2021-12-04 17:35:56,035 [Executor task launch worker for task 18] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 2 non-empty blocks out of 2 blocks
2021-12-04 17:35:56,035 [Executor task launch worker for task 18] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-04 17:35:56,035 [Executor task launch worker for task 19] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-04 17:35:56,100 [Executor task launch worker for task 16] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 9.0 (TID 16). 1204 bytes result sent to driver
2021-12-04 17:35:56,101 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 9.0 (TID 16) in 73 ms on localhost (executor driver) (1/2)
2021-12-04 17:35:56,111 [Executor task launch worker for task 17] INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 9.0 (TID 17). 1204 bytes result sent to driver
2021-12-04 17:35:56,111 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 9.0 (TID 17) in 83 ms on localhost (executor driver) (2/2)
2021-12-04 17:35:56,111 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 9.0, whose tasks have all completed, from pool 
2021-12-04 17:35:56,112 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ShuffleMapStage 9 (intersection at PaidPromotionAdjustParameter.scala:130) finished in 0.089 s
2021-12-04 17:35:56,112 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - looking for newly runnable stages
2021-12-04 17:35:56,112 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - running: Set(ShuffleMapStage 11)
2021-12-04 17:35:56,112 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - waiting: Set(ResultStage 12)
2021-12-04 17:35:56,112 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - failed: Set()
2021-12-04 17:35:56,114 [Executor task launch worker for task 18] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 11.0 (TID 18). 1161 bytes result sent to driver
2021-12-04 17:35:56,115 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 11.0 (TID 18) in 82 ms on localhost (executor driver) (1/2)
2021-12-04 17:35:56,117 [Executor task launch worker for task 19] INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 11.0 (TID 19). 1161 bytes result sent to driver
2021-12-04 17:35:56,117 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 11.0 (TID 19) in 84 ms on localhost (executor driver) (2/2)
2021-12-04 17:35:56,117 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 11.0, whose tasks have all completed, from pool 
2021-12-04 17:35:56,118 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ShuffleMapStage 11 (intersection at PaidPromotionAdjustParameter.scala:130) finished in 0.090 s
2021-12-04 17:35:56,118 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - looking for newly runnable stages
2021-12-04 17:35:56,118 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - running: Set()
2021-12-04 17:35:56,118 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - waiting: Set(ResultStage 12)
2021-12-04 17:35:56,118 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - failed: Set()
2021-12-04 17:35:56,118 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 12 (MapPartitionsRDD[18] at intersection at PaidPromotionAdjustParameter.scala:130), which has no missing parents
2021-12-04 17:35:56,120 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_11 stored as values in memory (estimated size 3.6 KB, free 1990.4 MB)
2021-12-04 17:35:56,122 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_11_piece0 stored as bytes in memory (estimated size 2.1 KB, free 1990.4 MB)
2021-12-04 17:35:56,123 [dispatcher-event-loop-6] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_11_piece0 in memory on qb:60460 (size: 2.1 KB, free: 1990.8 MB)
2021-12-04 17:35:56,123 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 11 from broadcast at DAGScheduler.scala:1039
2021-12-04 17:35:56,123 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from ResultStage 12 (MapPartitionsRDD[18] at intersection at PaidPromotionAdjustParameter.scala:130) (first 15 tasks are for partitions Vector(0, 1))
2021-12-04 17:35:56,123 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 12.0 with 2 tasks
2021-12-04 17:35:56,124 [dispatcher-event-loop-10] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 12.0 (TID 20, localhost, executor driver, partition 0, PROCESS_LOCAL, 7712 bytes)
2021-12-04 17:35:56,124 [dispatcher-event-loop-10] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 12.0 (TID 21, localhost, executor driver, partition 1, PROCESS_LOCAL, 7712 bytes)
2021-12-04 17:35:56,125 [Executor task launch worker for task 21] INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 12.0 (TID 21)
2021-12-04 17:35:56,125 [Executor task launch worker for task 20] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 12.0 (TID 20)
2021-12-04 17:35:56,127 [Executor task launch worker for task 21] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2021-12-04 17:35:56,127 [Executor task launch worker for task 20] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2021-12-04 17:35:56,128 [Executor task launch worker for task 21] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 1 ms
2021-12-04 17:35:56,128 [Executor task launch worker for task 20] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 1 ms
2021-12-04 17:35:56,131 [Executor task launch worker for task 21] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2021-12-04 17:35:56,131 [Executor task launch worker for task 20] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2021-12-04 17:35:56,131 [Executor task launch worker for task 21] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-04 17:35:56,131 [Executor task launch worker for task 20] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-04 17:35:56,213 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 170
2021-12-04 17:35:56,213 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 164
2021-12-04 17:35:56,214 [dispatcher-event-loop-0] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_10_piece0 on qb:60460 in memory (size: 2.3 KB, free: 1990.8 MB)
2021-12-04 17:35:56,215 [dispatcher-event-loop-2] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_7_piece0 on qb:60460 in memory (size: 2.9 KB, free: 1990.8 MB)
2021-12-04 17:35:56,215 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 186
2021-12-04 17:35:56,216 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 163
2021-12-04 17:35:56,216 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 151
2021-12-04 17:35:56,216 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 197
2021-12-04 17:35:56,216 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 191
2021-12-04 17:35:56,216 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 178
2021-12-04 17:35:56,216 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 189
2021-12-04 17:35:56,217 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 179
2021-12-04 17:35:56,217 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 159
2021-12-04 17:35:56,217 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 150
2021-12-04 17:35:56,217 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 184
2021-12-04 17:35:56,217 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 192
2021-12-04 17:35:56,217 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 168
2021-12-04 17:35:56,217 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 167
2021-12-04 17:35:56,217 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 156
2021-12-04 17:35:56,217 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 154
2021-12-04 17:35:56,217 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 177
2021-12-04 17:35:56,217 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 152
2021-12-04 17:35:56,217 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 173
2021-12-04 17:35:56,217 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 183
2021-12-04 17:35:56,217 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 199
2021-12-04 17:35:56,217 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 174
2021-12-04 17:35:56,217 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 188
2021-12-04 17:35:56,218 [dispatcher-event-loop-6] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_9_piece0 on qb:60460 in memory (size: 2.3 KB, free: 1990.8 MB)
2021-12-04 17:35:56,218 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 165
2021-12-04 17:35:56,218 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 160
2021-12-04 17:35:56,218 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 172
2021-12-04 17:35:56,218 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 187
2021-12-04 17:35:56,218 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 162
2021-12-04 17:35:56,218 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 182
2021-12-04 17:35:56,218 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 190
2021-12-04 17:35:56,218 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 158
2021-12-04 17:35:56,218 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 169
2021-12-04 17:35:56,218 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 196
2021-12-04 17:35:56,219 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 171
2021-12-04 17:35:56,219 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 180
2021-12-04 17:35:56,219 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 195
2021-12-04 17:35:56,219 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 153
2021-12-04 17:35:56,219 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 176
2021-12-04 17:35:56,219 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 161
2021-12-04 17:35:56,219 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 157
2021-12-04 17:35:56,219 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 175
2021-12-04 17:35:56,219 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 194
2021-12-04 17:35:56,219 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 198
2021-12-04 17:35:56,219 [dispatcher-event-loop-9] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_8_piece0 on qb:60460 in memory (size: 2.2 KB, free: 1990.8 MB)
2021-12-04 17:35:56,220 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 166
2021-12-04 17:35:56,220 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 181
2021-12-04 17:35:56,220 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 193
2021-12-04 17:35:56,220 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 185
2021-12-04 17:35:56,220 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 155
2021-12-04 17:35:56,309 [Executor task launch worker for task 21] INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 12.0 (TID 21). 1054 bytes result sent to driver
2021-12-04 17:35:56,309 [Executor task launch worker for task 20] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 12.0 (TID 20). 1054 bytes result sent to driver
2021-12-04 17:35:56,309 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 12.0 (TID 21) in 185 ms on localhost (executor driver) (1/2)
2021-12-04 17:35:56,310 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 12.0 (TID 20) in 186 ms on localhost (executor driver) (2/2)
2021-12-04 17:35:56,310 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 12.0, whose tasks have all completed, from pool 
2021-12-04 17:35:56,310 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 12 (count at PaidPromotionAdjustParameter.scala:140) finished in 0.192 s
2021-12-04 17:35:56,310 [main] INFO [org.apache.spark.scheduler.DAGScheduler] - Job 6 finished: count at PaidPromotionAdjustParameter.scala:140, took 0.288918 s
2021-12-04 17:35:56,311 [main] INFO [PaidPromotion$] - 共 同 用户数 = 4910
2021-12-04 17:35:56,313 [main] INFO [org.apache.spark.SparkContext] - Starting job: count at PaidPromotionAdjustParameter.scala:141
2021-12-04 17:35:56,314 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 20 (distinct at PaidPromotionAdjustParameter.scala:133)
2021-12-04 17:35:56,314 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 7 (count at PaidPromotionAdjustParameter.scala:141) with 2 output partitions
2021-12-04 17:35:56,314 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 14 (count at PaidPromotionAdjustParameter.scala:141)
2021-12-04 17:35:56,314 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 13)
2021-12-04 17:35:56,314 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List(ShuffleMapStage 13)
2021-12-04 17:35:56,314 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ShuffleMapStage 13 (MapPartitionsRDD[20] at distinct at PaidPromotionAdjustParameter.scala:133), which has no missing parents
2021-12-04 17:35:56,315 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_12 stored as values in memory (estimated size 5.2 KB, free 1990.5 MB)
2021-12-04 17:35:56,317 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_12_piece0 stored as bytes in memory (estimated size 2.9 KB, free 1990.5 MB)
2021-12-04 17:35:56,317 [dispatcher-event-loop-0] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_12_piece0 in memory on qb:60460 (size: 2.9 KB, free: 1990.8 MB)
2021-12-04 17:35:56,318 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 12 from broadcast at DAGScheduler.scala:1039
2021-12-04 17:35:56,318 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from ShuffleMapStage 13 (MapPartitionsRDD[20] at distinct at PaidPromotionAdjustParameter.scala:133) (first 15 tasks are for partitions Vector(0, 1))
2021-12-04 17:35:56,318 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 13.0 with 2 tasks
2021-12-04 17:35:56,319 [dispatcher-event-loop-5] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 13.0 (TID 22, localhost, executor driver, partition 0, ANY, 7885 bytes)
2021-12-04 17:35:56,319 [dispatcher-event-loop-5] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 13.0 (TID 23, localhost, executor driver, partition 1, ANY, 7885 bytes)
2021-12-04 17:35:56,319 [Executor task launch worker for task 23] INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 13.0 (TID 23)
2021-12-04 17:35:56,319 [Executor task launch worker for task 22] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 13.0 (TID 22)
2021-12-04 17:35:56,320 [Executor task launch worker for task 22] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/order_data.bcp:0+3442194
2021-12-04 17:35:56,320 [Executor task launch worker for task 23] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/order_data.bcp:3442194+3442195
2021-12-04 17:35:56,736 [Executor task launch worker for task 23] INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 13.0 (TID 23). 1032 bytes result sent to driver
2021-12-04 17:35:56,736 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 13.0 (TID 23) in 417 ms on localhost (executor driver) (1/2)
2021-12-04 17:35:56,986 [Executor task launch worker for task 22] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 13.0 (TID 22). 989 bytes result sent to driver
2021-12-04 17:35:56,986 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 13.0 (TID 22) in 668 ms on localhost (executor driver) (2/2)
2021-12-04 17:35:56,986 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 13.0, whose tasks have all completed, from pool 
2021-12-04 17:35:56,987 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ShuffleMapStage 13 (distinct at PaidPromotionAdjustParameter.scala:133) finished in 0.673 s
2021-12-04 17:35:56,987 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - looking for newly runnable stages
2021-12-04 17:35:56,987 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - running: Set()
2021-12-04 17:35:56,987 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - waiting: Set(ResultStage 14)
2021-12-04 17:35:56,987 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - failed: Set()
2021-12-04 17:35:56,987 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 14 (MapPartitionsRDD[22] at distinct at PaidPromotionAdjustParameter.scala:133), which has no missing parents
2021-12-04 17:35:56,988 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_13 stored as values in memory (estimated size 3.7 KB, free 1990.5 MB)
2021-12-04 17:35:56,990 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_13_piece0 stored as bytes in memory (estimated size 2.2 KB, free 1990.4 MB)
2021-12-04 17:35:56,990 [dispatcher-event-loop-6] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_13_piece0 in memory on qb:60460 (size: 2.2 KB, free: 1990.8 MB)
2021-12-04 17:35:56,991 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 13 from broadcast at DAGScheduler.scala:1039
2021-12-04 17:35:56,991 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from ResultStage 14 (MapPartitionsRDD[22] at distinct at PaidPromotionAdjustParameter.scala:133) (first 15 tasks are for partitions Vector(0, 1))
2021-12-04 17:35:56,991 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 14.0 with 2 tasks
2021-12-04 17:35:56,991 [dispatcher-event-loop-7] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 14.0 (TID 24, localhost, executor driver, partition 0, ANY, 7649 bytes)
2021-12-04 17:35:56,992 [dispatcher-event-loop-7] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 14.0 (TID 25, localhost, executor driver, partition 1, ANY, 7649 bytes)
2021-12-04 17:35:56,992 [Executor task launch worker for task 24] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 14.0 (TID 24)
2021-12-04 17:35:56,992 [Executor task launch worker for task 25] INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 14.0 (TID 25)
2021-12-04 17:35:56,993 [Executor task launch worker for task 24] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 2 non-empty blocks out of 2 blocks
2021-12-04 17:35:56,993 [Executor task launch worker for task 25] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 2 non-empty blocks out of 2 blocks
2021-12-04 17:35:56,993 [Executor task launch worker for task 24] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-04 17:35:56,993 [Executor task launch worker for task 25] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-04 17:35:57,005 [Executor task launch worker for task 24] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 14.0 (TID 24). 1011 bytes result sent to driver
2021-12-04 17:35:57,005 [Executor task launch worker for task 25] INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 14.0 (TID 25). 1011 bytes result sent to driver
2021-12-04 17:35:57,005 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 14.0 (TID 24) in 14 ms on localhost (executor driver) (1/2)
2021-12-04 17:35:57,005 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 14.0 (TID 25) in 14 ms on localhost (executor driver) (2/2)
2021-12-04 17:35:57,006 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 14.0, whose tasks have all completed, from pool 
2021-12-04 17:35:57,006 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 14 (count at PaidPromotionAdjustParameter.scala:141) finished in 0.019 s
2021-12-04 17:35:57,006 [main] INFO [org.apache.spark.scheduler.DAGScheduler] - Job 7 finished: count at PaidPromotionAdjustParameter.scala:141, took 0.692127 s
2021-12-04 17:35:57,006 [main] INFO [PaidPromotion$] - 训练集节目数 = 128
2021-12-04 17:35:57,009 [main] INFO [org.apache.spark.SparkContext] - Starting job: count at PaidPromotionAdjustParameter.scala:142
2021-12-04 17:35:57,009 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 24 (distinct at PaidPromotionAdjustParameter.scala:134)
2021-12-04 17:35:57,009 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 8 (count at PaidPromotionAdjustParameter.scala:142) with 2 output partitions
2021-12-04 17:35:57,009 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 16 (count at PaidPromotionAdjustParameter.scala:142)
2021-12-04 17:35:57,009 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 15)
2021-12-04 17:35:57,009 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List(ShuffleMapStage 15)
2021-12-04 17:35:57,009 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ShuffleMapStage 15 (MapPartitionsRDD[24] at distinct at PaidPromotionAdjustParameter.scala:134), which has no missing parents
2021-12-04 17:35:57,010 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_14 stored as values in memory (estimated size 5.2 KB, free 1990.4 MB)
2021-12-04 17:35:57,012 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_14_piece0 stored as bytes in memory (estimated size 2.9 KB, free 1990.4 MB)
2021-12-04 17:35:57,012 [dispatcher-event-loop-0] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_14_piece0 in memory on qb:60460 (size: 2.9 KB, free: 1990.8 MB)
2021-12-04 17:35:57,012 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 14 from broadcast at DAGScheduler.scala:1039
2021-12-04 17:35:57,013 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from ShuffleMapStage 15 (MapPartitionsRDD[24] at distinct at PaidPromotionAdjustParameter.scala:134) (first 15 tasks are for partitions Vector(0, 1))
2021-12-04 17:35:57,013 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 15.0 with 2 tasks
2021-12-04 17:35:57,013 [dispatcher-event-loop-5] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 15.0 (TID 26, localhost, executor driver, partition 0, ANY, 7885 bytes)
2021-12-04 17:35:57,013 [dispatcher-event-loop-5] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 15.0 (TID 27, localhost, executor driver, partition 1, ANY, 7885 bytes)
2021-12-04 17:35:57,014 [Executor task launch worker for task 27] INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 15.0 (TID 27)
2021-12-04 17:35:57,014 [Executor task launch worker for task 26] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 15.0 (TID 26)
2021-12-04 17:35:57,015 [Executor task launch worker for task 26] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/order_data.bcp:0+3442194
2021-12-04 17:35:57,015 [Executor task launch worker for task 27] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/order_data.bcp:3442194+3442195
2021-12-04 17:35:57,107 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 313
2021-12-04 17:35:57,107 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 303
2021-12-04 17:35:57,108 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 218
2021-12-04 17:35:57,108 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 297
2021-12-04 17:35:57,108 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 252
2021-12-04 17:35:57,108 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 207
2021-12-04 17:35:57,108 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 300
2021-12-04 17:35:57,108 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 244
2021-12-04 17:35:57,108 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 271
2021-12-04 17:35:57,108 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 319
2021-12-04 17:35:57,108 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 321
2021-12-04 17:35:57,108 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 245
2021-12-04 17:35:57,108 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 305
2021-12-04 17:35:57,108 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 219
2021-12-04 17:35:57,108 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 238
2021-12-04 17:35:57,108 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 310
2021-12-04 17:35:57,108 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 269
2021-12-04 17:35:57,108 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 257
2021-12-04 17:35:57,108 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 240
2021-12-04 17:35:57,108 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 254
2021-12-04 17:35:57,108 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 315
2021-12-04 17:35:57,108 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 215
2021-12-04 17:35:57,108 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 233
2021-12-04 17:35:57,108 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 299
2021-12-04 17:35:57,108 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 317
2021-12-04 17:35:57,108 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 296
2021-12-04 17:35:57,108 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 239
2021-12-04 17:35:57,108 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 231
2021-12-04 17:35:57,108 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 256
2021-12-04 17:35:57,108 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 202
2021-12-04 17:35:57,108 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 208
2021-12-04 17:35:57,108 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 316
2021-12-04 17:35:57,108 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 243
2021-12-04 17:35:57,108 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 241
2021-12-04 17:35:57,108 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 308
2021-12-04 17:35:57,108 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 212
2021-12-04 17:35:57,108 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 242
2021-12-04 17:35:57,108 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 255
2021-12-04 17:35:57,108 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 290
2021-12-04 17:35:57,108 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 304
2021-12-04 17:35:57,108 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 201
2021-12-04 17:35:57,108 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 249
2021-12-04 17:35:57,108 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 265
2021-12-04 17:35:57,108 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 253
2021-12-04 17:35:57,108 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 205
2021-12-04 17:35:57,108 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 283
2021-12-04 17:35:57,108 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 278
2021-12-04 17:35:57,108 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 229
2021-12-04 17:35:57,108 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 210
2021-12-04 17:35:57,108 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 291
2021-12-04 17:35:57,108 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 213
2021-12-04 17:35:57,108 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 262
2021-12-04 17:35:57,108 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 318
2021-12-04 17:35:57,108 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 236
2021-12-04 17:35:57,109 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 270
2021-12-04 17:35:57,109 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 258
2021-12-04 17:35:57,109 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 274
2021-12-04 17:35:57,109 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 226
2021-12-04 17:35:57,109 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 276
2021-12-04 17:35:57,109 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 292
2021-12-04 17:35:57,109 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 272
2021-12-04 17:35:57,109 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 280
2021-12-04 17:35:57,109 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 250
2021-12-04 17:35:57,109 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 267
2021-12-04 17:35:57,109 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 261
2021-12-04 17:35:57,109 [dispatcher-event-loop-6] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_13_piece0 on qb:60460 in memory (size: 2.2 KB, free: 1990.8 MB)
2021-12-04 17:35:57,110 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 260
2021-12-04 17:35:57,110 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 203
2021-12-04 17:35:57,110 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 235
2021-12-04 17:35:57,110 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 301
2021-12-04 17:35:57,110 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 221
2021-12-04 17:35:57,110 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 282
2021-12-04 17:35:57,110 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 225
2021-12-04 17:35:57,110 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 324
2021-12-04 17:35:57,110 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 273
2021-12-04 17:35:57,110 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 298
2021-12-04 17:35:57,110 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 228
2021-12-04 17:35:57,110 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 246
2021-12-04 17:35:57,110 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 277
2021-12-04 17:35:57,110 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 323
2021-12-04 17:35:57,110 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 209
2021-12-04 17:35:57,110 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 295
2021-12-04 17:35:57,110 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 309
2021-12-04 17:35:57,110 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 311
2021-12-04 17:35:57,110 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 294
2021-12-04 17:35:57,110 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 227
2021-12-04 17:35:57,111 [dispatcher-event-loop-10] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_11_piece0 on qb:60460 in memory (size: 2.1 KB, free: 1990.8 MB)
2021-12-04 17:35:57,111 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 286
2021-12-04 17:35:57,111 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 224
2021-12-04 17:35:57,111 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 234
2021-12-04 17:35:57,111 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 248
2021-12-04 17:35:57,111 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 268
2021-12-04 17:35:57,111 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 281
2021-12-04 17:35:57,111 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 222
2021-12-04 17:35:57,111 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 288
2021-12-04 17:35:57,111 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 217
2021-12-04 17:35:57,111 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 206
2021-12-04 17:35:57,111 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 266
2021-12-04 17:35:57,111 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 320
2021-12-04 17:35:57,111 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 220
2021-12-04 17:35:57,111 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 284
2021-12-04 17:35:57,111 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 216
2021-12-04 17:35:57,111 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 275
2021-12-04 17:35:57,111 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 204
2021-12-04 17:35:57,111 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 293
2021-12-04 17:35:57,111 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 307
2021-12-04 17:35:57,111 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 237
2021-12-04 17:35:57,111 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 322
2021-12-04 17:35:57,111 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 223
2021-12-04 17:35:57,111 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 251
2021-12-04 17:35:57,111 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 306
2021-12-04 17:35:57,111 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 312
2021-12-04 17:35:57,111 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 232
2021-12-04 17:35:57,111 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 279
2021-12-04 17:35:57,111 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 285
2021-12-04 17:35:57,111 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 289
2021-12-04 17:35:57,111 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 302
2021-12-04 17:35:57,111 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 214
2021-12-04 17:35:57,111 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 287
2021-12-04 17:35:57,112 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 247
2021-12-04 17:35:57,112 [dispatcher-event-loop-0] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_12_piece0 on qb:60460 in memory (size: 2.9 KB, free: 1990.8 MB)
2021-12-04 17:35:57,113 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 259
2021-12-04 17:35:57,113 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 314
2021-12-04 17:35:57,113 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 263
2021-12-04 17:35:57,113 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 230
2021-12-04 17:35:57,113 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 211
2021-12-04 17:35:57,113 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 200
2021-12-04 17:35:57,113 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 264
2021-12-04 17:35:57,700 [Executor task launch worker for task 27] INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 15.0 (TID 27). 1032 bytes result sent to driver
2021-12-04 17:35:57,700 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 15.0 (TID 27) in 687 ms on localhost (executor driver) (1/2)
2021-12-04 17:35:57,709 [Executor task launch worker for task 26] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 15.0 (TID 26). 1032 bytes result sent to driver
2021-12-04 17:35:57,709 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 15.0 (TID 26) in 696 ms on localhost (executor driver) (2/2)
2021-12-04 17:35:57,709 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 15.0, whose tasks have all completed, from pool 
2021-12-04 17:35:57,710 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ShuffleMapStage 15 (distinct at PaidPromotionAdjustParameter.scala:134) finished in 0.699 s
2021-12-04 17:35:57,710 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - looking for newly runnable stages
2021-12-04 17:35:57,710 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - running: Set()
2021-12-04 17:35:57,710 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - waiting: Set(ResultStage 16)
2021-12-04 17:35:57,710 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - failed: Set()
2021-12-04 17:35:57,710 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 16 (MapPartitionsRDD[26] at distinct at PaidPromotionAdjustParameter.scala:134), which has no missing parents
2021-12-04 17:35:57,711 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_15 stored as values in memory (estimated size 3.7 KB, free 1990.5 MB)
2021-12-04 17:35:57,713 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_15_piece0 stored as bytes in memory (estimated size 2.2 KB, free 1990.5 MB)
2021-12-04 17:35:57,713 [dispatcher-event-loop-4] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_15_piece0 in memory on qb:60460 (size: 2.2 KB, free: 1990.8 MB)
2021-12-04 17:35:57,713 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 15 from broadcast at DAGScheduler.scala:1039
2021-12-04 17:35:57,714 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from ResultStage 16 (MapPartitionsRDD[26] at distinct at PaidPromotionAdjustParameter.scala:134) (first 15 tasks are for partitions Vector(0, 1))
2021-12-04 17:35:57,714 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 16.0 with 2 tasks
2021-12-04 17:35:57,714 [dispatcher-event-loop-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 16.0 (TID 28, localhost, executor driver, partition 0, ANY, 7649 bytes)
2021-12-04 17:35:57,714 [dispatcher-event-loop-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 16.0 (TID 29, localhost, executor driver, partition 1, ANY, 7649 bytes)
2021-12-04 17:35:57,714 [Executor task launch worker for task 28] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 16.0 (TID 28)
2021-12-04 17:35:57,714 [Executor task launch worker for task 29] INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 16.0 (TID 29)
2021-12-04 17:35:57,716 [Executor task launch worker for task 29] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 2 non-empty blocks out of 2 blocks
2021-12-04 17:35:57,716 [Executor task launch worker for task 28] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 2 non-empty blocks out of 2 blocks
2021-12-04 17:35:57,716 [Executor task launch worker for task 29] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-04 17:35:57,716 [Executor task launch worker for task 28] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-04 17:35:57,729 [Executor task launch worker for task 28] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 16.0 (TID 28). 1053 bytes result sent to driver
2021-12-04 17:35:57,729 [Executor task launch worker for task 29] INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 16.0 (TID 29). 1053 bytes result sent to driver
2021-12-04 17:35:57,729 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 16.0 (TID 28) in 15 ms on localhost (executor driver) (1/2)
2021-12-04 17:35:57,729 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 16.0 (TID 29) in 15 ms on localhost (executor driver) (2/2)
2021-12-04 17:35:57,729 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 16.0, whose tasks have all completed, from pool 
2021-12-04 17:35:57,729 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 16 (count at PaidPromotionAdjustParameter.scala:142) finished in 0.019 s
2021-12-04 17:35:57,730 [main] INFO [org.apache.spark.scheduler.DAGScheduler] - Job 8 finished: count at PaidPromotionAdjustParameter.scala:142, took 0.721337 s
2021-12-04 17:35:57,730 [main] INFO [PaidPromotion$] - 验证集节目数 = 116
2021-12-04 17:35:57,733 [main] INFO [org.apache.spark.SparkContext] - Starting job: count at PaidPromotionAdjustParameter.scala:143
2021-12-04 17:35:57,733 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 27 (intersection at PaidPromotionAdjustParameter.scala:135)
2021-12-04 17:35:57,733 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 28 (intersection at PaidPromotionAdjustParameter.scala:135)
2021-12-04 17:35:57,734 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 9 (count at PaidPromotionAdjustParameter.scala:143) with 2 output partitions
2021-12-04 17:35:57,734 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 21 (count at PaidPromotionAdjustParameter.scala:143)
2021-12-04 17:35:57,734 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 20, ShuffleMapStage 18)
2021-12-04 17:35:57,734 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List(ShuffleMapStage 20, ShuffleMapStage 18)
2021-12-04 17:35:57,734 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ShuffleMapStage 18 (MapPartitionsRDD[27] at intersection at PaidPromotionAdjustParameter.scala:135), which has no missing parents
2021-12-04 17:35:57,735 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_16 stored as values in memory (estimated size 4.0 KB, free 1990.5 MB)
2021-12-04 17:35:57,737 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_16_piece0 stored as bytes in memory (estimated size 2.3 KB, free 1990.4 MB)
2021-12-04 17:35:57,737 [dispatcher-event-loop-10] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_16_piece0 in memory on qb:60460 (size: 2.3 KB, free: 1990.8 MB)
2021-12-04 17:35:57,738 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 16 from broadcast at DAGScheduler.scala:1039
2021-12-04 17:35:57,738 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from ShuffleMapStage 18 (MapPartitionsRDD[27] at intersection at PaidPromotionAdjustParameter.scala:135) (first 15 tasks are for partitions Vector(0, 1))
2021-12-04 17:35:57,738 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 18.0 with 2 tasks
2021-12-04 17:35:57,739 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ShuffleMapStage 20 (MapPartitionsRDD[28] at intersection at PaidPromotionAdjustParameter.scala:135), which has no missing parents
2021-12-04 17:35:57,739 [dispatcher-event-loop-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 18.0 (TID 30, localhost, executor driver, partition 0, ANY, 7638 bytes)
2021-12-04 17:35:57,739 [dispatcher-event-loop-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 18.0 (TID 31, localhost, executor driver, partition 1, ANY, 7638 bytes)
2021-12-04 17:35:57,739 [Executor task launch worker for task 30] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 18.0 (TID 30)
2021-12-04 17:35:57,739 [Executor task launch worker for task 31] INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 18.0 (TID 31)
2021-12-04 17:35:57,740 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_17 stored as values in memory (estimated size 4.0 KB, free 1990.4 MB)
2021-12-04 17:35:57,740 [Executor task launch worker for task 30] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 2 non-empty blocks out of 2 blocks
2021-12-04 17:35:57,740 [Executor task launch worker for task 31] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 2 non-empty blocks out of 2 blocks
2021-12-04 17:35:57,740 [Executor task launch worker for task 30] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-04 17:35:57,741 [Executor task launch worker for task 31] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 1 ms
2021-12-04 17:35:57,742 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_17_piece0 stored as bytes in memory (estimated size 2.3 KB, free 1990.4 MB)
2021-12-04 17:35:57,742 [dispatcher-event-loop-5] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_17_piece0 in memory on qb:60460 (size: 2.3 KB, free: 1990.8 MB)
2021-12-04 17:35:57,743 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 17 from broadcast at DAGScheduler.scala:1039
2021-12-04 17:35:57,743 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from ShuffleMapStage 20 (MapPartitionsRDD[28] at intersection at PaidPromotionAdjustParameter.scala:135) (first 15 tasks are for partitions Vector(0, 1))
2021-12-04 17:35:57,743 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 20.0 with 2 tasks
2021-12-04 17:35:57,744 [dispatcher-event-loop-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 20.0 (TID 32, localhost, executor driver, partition 0, ANY, 7638 bytes)
2021-12-04 17:35:57,744 [dispatcher-event-loop-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 20.0 (TID 33, localhost, executor driver, partition 1, ANY, 7638 bytes)
2021-12-04 17:35:57,744 [Executor task launch worker for task 32] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 20.0 (TID 32)
2021-12-04 17:35:57,744 [Executor task launch worker for task 33] INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 20.0 (TID 33)
2021-12-04 17:35:57,745 [Executor task launch worker for task 32] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 2 non-empty blocks out of 2 blocks
2021-12-04 17:35:57,745 [Executor task launch worker for task 32] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-04 17:35:57,745 [Executor task launch worker for task 33] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 2 non-empty blocks out of 2 blocks
2021-12-04 17:35:57,745 [Executor task launch worker for task 33] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-04 17:35:57,756 [Executor task launch worker for task 30] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 18.0 (TID 30). 1161 bytes result sent to driver
2021-12-04 17:35:57,756 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 18.0 (TID 30) in 17 ms on localhost (executor driver) (1/2)
2021-12-04 17:35:57,757 [Executor task launch worker for task 31] INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 18.0 (TID 31). 1161 bytes result sent to driver
2021-12-04 17:35:57,757 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 18.0 (TID 31) in 18 ms on localhost (executor driver) (2/2)
2021-12-04 17:35:57,758 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 18.0, whose tasks have all completed, from pool 
2021-12-04 17:35:57,758 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ShuffleMapStage 18 (intersection at PaidPromotionAdjustParameter.scala:135) finished in 0.024 s
2021-12-04 17:35:57,758 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - looking for newly runnable stages
2021-12-04 17:35:57,758 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - running: Set(ShuffleMapStage 20)
2021-12-04 17:35:57,758 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - waiting: Set(ResultStage 21)
2021-12-04 17:35:57,758 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - failed: Set()
2021-12-04 17:35:57,762 [Executor task launch worker for task 33] INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 20.0 (TID 33). 1247 bytes result sent to driver
2021-12-04 17:35:57,762 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 20.0 (TID 33) in 18 ms on localhost (executor driver) (1/2)
2021-12-04 17:35:57,763 [Executor task launch worker for task 32] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 20.0 (TID 32). 1204 bytes result sent to driver
2021-12-04 17:35:57,763 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 20.0 (TID 32) in 20 ms on localhost (executor driver) (2/2)
2021-12-04 17:35:57,763 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 20.0, whose tasks have all completed, from pool 
2021-12-04 17:35:57,763 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ShuffleMapStage 20 (intersection at PaidPromotionAdjustParameter.scala:135) finished in 0.024 s
2021-12-04 17:35:57,763 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - looking for newly runnable stages
2021-12-04 17:35:57,763 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - running: Set()
2021-12-04 17:35:57,763 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - waiting: Set(ResultStage 21)
2021-12-04 17:35:57,764 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - failed: Set()
2021-12-04 17:35:57,764 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 21 (MapPartitionsRDD[32] at intersection at PaidPromotionAdjustParameter.scala:135), which has no missing parents
2021-12-04 17:35:57,764 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_18 stored as values in memory (estimated size 3.6 KB, free 1990.4 MB)
2021-12-04 17:35:57,766 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_18_piece0 stored as bytes in memory (estimated size 2.1 KB, free 1990.4 MB)
2021-12-04 17:35:57,766 [dispatcher-event-loop-10] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_18_piece0 in memory on qb:60460 (size: 2.1 KB, free: 1990.8 MB)
2021-12-04 17:35:57,767 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 18 from broadcast at DAGScheduler.scala:1039
2021-12-04 17:35:57,767 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from ResultStage 21 (MapPartitionsRDD[32] at intersection at PaidPromotionAdjustParameter.scala:135) (first 15 tasks are for partitions Vector(0, 1))
2021-12-04 17:35:57,767 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 21.0 with 2 tasks
2021-12-04 17:35:57,767 [dispatcher-event-loop-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 21.0 (TID 34, localhost, executor driver, partition 0, PROCESS_LOCAL, 7712 bytes)
2021-12-04 17:35:57,768 [dispatcher-event-loop-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 21.0 (TID 35, localhost, executor driver, partition 1, PROCESS_LOCAL, 7712 bytes)
2021-12-04 17:35:57,768 [Executor task launch worker for task 35] INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 21.0 (TID 35)
2021-12-04 17:35:57,768 [Executor task launch worker for task 34] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 21.0 (TID 34)
2021-12-04 17:35:57,769 [Executor task launch worker for task 35] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2021-12-04 17:35:57,769 [Executor task launch worker for task 34] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2021-12-04 17:35:57,769 [Executor task launch worker for task 35] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-04 17:35:57,769 [Executor task launch worker for task 34] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-04 17:35:57,771 [Executor task launch worker for task 34] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2021-12-04 17:35:57,771 [Executor task launch worker for task 35] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2021-12-04 17:35:57,771 [Executor task launch worker for task 34] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-04 17:35:57,771 [Executor task launch worker for task 35] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-04 17:35:57,778 [Executor task launch worker for task 34] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 21.0 (TID 34). 1010 bytes result sent to driver
2021-12-04 17:35:57,778 [Executor task launch worker for task 35] INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 21.0 (TID 35). 1010 bytes result sent to driver
2021-12-04 17:35:57,778 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 21.0 (TID 34) in 11 ms on localhost (executor driver) (1/2)
2021-12-04 17:35:57,778 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 21.0 (TID 35) in 11 ms on localhost (executor driver) (2/2)
2021-12-04 17:35:57,778 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 21.0, whose tasks have all completed, from pool 
2021-12-04 17:35:57,778 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 21 (count at PaidPromotionAdjustParameter.scala:143) finished in 0.014 s
2021-12-04 17:35:57,779 [main] INFO [org.apache.spark.scheduler.DAGScheduler] - Job 9 finished: count at PaidPromotionAdjustParameter.scala:143, took 0.045855 s
2021-12-04 17:35:57,780 [main] INFO [PaidPromotion$] - 共 同 节目数 = 112
2021-12-04 17:35:57,789 [main] INFO [org.apache.spark.SparkContext] - Starting job: collect at PaidPromotionAdjustParameter.scala:146
2021-12-04 17:35:57,790 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 10 (collect at PaidPromotionAdjustParameter.scala:146) with 2 output partitions
2021-12-04 17:35:57,790 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 26 (collect at PaidPromotionAdjustParameter.scala:146)
2021-12-04 17:35:57,790 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 25, ShuffleMapStage 23)
2021-12-04 17:35:57,790 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2021-12-04 17:35:57,790 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 26 (MapPartitionsRDD[18] at intersection at PaidPromotionAdjustParameter.scala:130), which has no missing parents
2021-12-04 17:35:57,791 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_19 stored as values in memory (estimated size 3.8 KB, free 1990.4 MB)
2021-12-04 17:35:57,793 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_19_piece0 stored as bytes in memory (estimated size 2.2 KB, free 1990.4 MB)
2021-12-04 17:35:57,794 [dispatcher-event-loop-3] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_19_piece0 in memory on qb:60460 (size: 2.2 KB, free: 1990.8 MB)
2021-12-04 17:35:57,795 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 19 from broadcast at DAGScheduler.scala:1039
2021-12-04 17:35:57,795 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from ResultStage 26 (MapPartitionsRDD[18] at intersection at PaidPromotionAdjustParameter.scala:130) (first 15 tasks are for partitions Vector(0, 1))
2021-12-04 17:35:57,795 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 26.0 with 2 tasks
2021-12-04 17:35:57,795 [dispatcher-event-loop-4] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 26.0 (TID 36, localhost, executor driver, partition 0, PROCESS_LOCAL, 7712 bytes)
2021-12-04 17:35:57,796 [dispatcher-event-loop-4] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 26.0 (TID 37, localhost, executor driver, partition 1, PROCESS_LOCAL, 7712 bytes)
2021-12-04 17:35:57,796 [Executor task launch worker for task 36] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 26.0 (TID 36)
2021-12-04 17:35:57,796 [Executor task launch worker for task 37] INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 26.0 (TID 37)
2021-12-04 17:35:57,797 [Executor task launch worker for task 36] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2021-12-04 17:35:57,797 [Executor task launch worker for task 37] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2021-12-04 17:35:57,797 [Executor task launch worker for task 36] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-04 17:35:57,797 [Executor task launch worker for task 37] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-04 17:35:57,798 [Executor task launch worker for task 37] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2021-12-04 17:35:57,799 [Executor task launch worker for task 37] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 1 ms
2021-12-04 17:35:57,799 [Executor task launch worker for task 36] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2021-12-04 17:35:57,799 [Executor task launch worker for task 36] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-04 17:35:57,877 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 382
2021-12-04 17:35:57,877 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 417
2021-12-04 17:35:57,877 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 365
2021-12-04 17:35:57,877 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 366
2021-12-04 17:35:57,877 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 372
2021-12-04 17:35:57,877 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 389
2021-12-04 17:35:57,877 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 342
2021-12-04 17:35:57,877 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 399
2021-12-04 17:35:57,877 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 396
2021-12-04 17:35:57,877 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 329
2021-12-04 17:35:57,877 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 330
2021-12-04 17:35:57,877 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 344
2021-12-04 17:35:57,877 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 409
2021-12-04 17:35:57,877 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 443
2021-12-04 17:35:57,878 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 435
2021-12-04 17:35:57,878 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 421
2021-12-04 17:35:57,878 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 328
2021-12-04 17:35:57,878 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 448
2021-12-04 17:35:57,878 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 358
2021-12-04 17:35:57,878 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 346
2021-12-04 17:35:57,878 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 403
2021-12-04 17:35:57,878 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 414
2021-12-04 17:35:57,878 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 425
2021-12-04 17:35:57,878 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 333
2021-12-04 17:35:57,878 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 384
2021-12-04 17:35:57,878 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 427
2021-12-04 17:35:57,878 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 437
2021-12-04 17:35:57,878 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 345
2021-12-04 17:35:57,878 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 376
2021-12-04 17:35:57,878 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 395
2021-12-04 17:35:57,878 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 374
2021-12-04 17:35:57,878 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 444
2021-12-04 17:35:57,878 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 431
2021-12-04 17:35:57,878 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 418
2021-12-04 17:35:57,878 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 449
2021-12-04 17:35:57,878 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 402
2021-12-04 17:35:57,878 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 377
2021-12-04 17:35:57,878 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 373
2021-12-04 17:35:57,878 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 400
2021-12-04 17:35:57,878 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 446
2021-12-04 17:35:57,878 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 351
2021-12-04 17:35:57,878 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 349
2021-12-04 17:35:57,878 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 383
2021-12-04 17:35:57,878 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 411
2021-12-04 17:35:57,878 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 336
2021-12-04 17:35:57,878 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 357
2021-12-04 17:35:57,878 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 369
2021-12-04 17:35:57,878 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 442
2021-12-04 17:35:57,878 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 386
2021-12-04 17:35:57,878 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 361
2021-12-04 17:35:57,878 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 338
2021-12-04 17:35:57,878 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 354
2021-12-04 17:35:57,878 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 364
2021-12-04 17:35:57,878 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 407
2021-12-04 17:35:57,878 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 406
2021-12-04 17:35:57,878 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 334
2021-12-04 17:35:57,878 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 410
2021-12-04 17:35:57,878 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 438
2021-12-04 17:35:57,878 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 428
2021-12-04 17:35:57,879 [dispatcher-event-loop-10] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_15_piece0 on qb:60460 in memory (size: 2.2 KB, free: 1990.8 MB)
2021-12-04 17:35:57,880 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 429
2021-12-04 17:35:57,880 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 348
2021-12-04 17:35:57,880 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 331
2021-12-04 17:35:57,880 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 440
2021-12-04 17:35:57,880 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 350
2021-12-04 17:35:57,880 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 398
2021-12-04 17:35:57,881 [dispatcher-event-loop-0] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_18_piece0 on qb:60460 in memory (size: 2.1 KB, free: 1990.8 MB)
2021-12-04 17:35:57,882 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 363
2021-12-04 17:35:57,882 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 393
2021-12-04 17:35:57,882 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 326
2021-12-04 17:35:57,882 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 404
2021-12-04 17:35:57,882 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 362
2021-12-04 17:35:57,882 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 405
2021-12-04 17:35:57,882 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 439
2021-12-04 17:35:57,882 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 343
2021-12-04 17:35:57,882 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 392
2021-12-04 17:35:57,882 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 385
2021-12-04 17:35:57,882 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 423
2021-12-04 17:35:57,882 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 337
2021-12-04 17:35:57,882 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 397
2021-12-04 17:35:57,882 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 341
2021-12-04 17:35:57,882 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 420
2021-12-04 17:35:57,882 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 388
2021-12-04 17:35:57,882 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 325
2021-12-04 17:35:57,882 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 368
2021-12-04 17:35:57,882 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 371
2021-12-04 17:35:57,882 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 335
2021-12-04 17:35:57,882 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 353
2021-12-04 17:35:57,882 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 359
2021-12-04 17:35:57,882 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 419
2021-12-04 17:35:57,882 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 424
2021-12-04 17:35:57,882 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 327
2021-12-04 17:35:57,882 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 375
2021-12-04 17:35:57,882 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 432
2021-12-04 17:35:57,882 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 434
2021-12-04 17:35:57,882 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 339
2021-12-04 17:35:57,882 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 367
2021-12-04 17:35:57,882 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 370
2021-12-04 17:35:57,883 [dispatcher-event-loop-3] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_16_piece0 on qb:60460 in memory (size: 2.3 KB, free: 1990.8 MB)
2021-12-04 17:35:57,884 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 412
2021-12-04 17:35:57,884 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 415
2021-12-04 17:35:57,884 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 447
2021-12-04 17:35:57,885 [dispatcher-event-loop-8] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_17_piece0 on qb:60460 in memory (size: 2.3 KB, free: 1990.8 MB)
2021-12-04 17:35:57,885 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 430
2021-12-04 17:35:57,885 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 347
2021-12-04 17:35:57,885 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 340
2021-12-04 17:35:57,886 [dispatcher-event-loop-10] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_14_piece0 on qb:60460 in memory (size: 2.9 KB, free: 1990.8 MB)
2021-12-04 17:35:57,886 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 380
2021-12-04 17:35:57,886 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 379
2021-12-04 17:35:57,886 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 391
2021-12-04 17:35:57,886 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 401
2021-12-04 17:35:57,886 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 416
2021-12-04 17:35:57,886 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 436
2021-12-04 17:35:57,886 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 445
2021-12-04 17:35:57,886 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 378
2021-12-04 17:35:57,886 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 441
2021-12-04 17:35:57,886 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 390
2021-12-04 17:35:57,886 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 394
2021-12-04 17:35:57,886 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 408
2021-12-04 17:35:57,887 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 433
2021-12-04 17:35:57,887 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 422
2021-12-04 17:35:57,887 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 352
2021-12-04 17:35:57,887 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 360
2021-12-04 17:35:57,887 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 355
2021-12-04 17:35:57,887 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 413
2021-12-04 17:35:57,887 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 426
2021-12-04 17:35:57,887 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 356
2021-12-04 17:35:57,887 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 381
2021-12-04 17:35:57,887 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 332
2021-12-04 17:35:57,887 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 387
2021-12-04 17:35:57,890 [Executor task launch worker for task 37] INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 26.0 (TID 37). 83879 bytes result sent to driver
2021-12-04 17:35:57,891 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 26.0 (TID 37) in 96 ms on localhost (executor driver) (1/2)
2021-12-04 17:35:57,893 [Executor task launch worker for task 36] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 26.0 (TID 36). 81224 bytes result sent to driver
2021-12-04 17:35:57,894 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 26.0 (TID 36) in 99 ms on localhost (executor driver) (2/2)
2021-12-04 17:35:57,894 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 26.0, whose tasks have all completed, from pool 
2021-12-04 17:35:57,894 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 26 (collect at PaidPromotionAdjustParameter.scala:146) finished in 0.104 s
2021-12-04 17:35:57,895 [main] INFO [org.apache.spark.scheduler.DAGScheduler] - Job 10 finished: collect at PaidPromotionAdjustParameter.scala:146, took 0.105416 s
2021-12-04 17:35:57,900 [main] INFO [org.apache.spark.SparkContext] - Starting job: collect at PaidPromotionAdjustParameter.scala:147
2021-12-04 17:35:57,901 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 11 (collect at PaidPromotionAdjustParameter.scala:147) with 2 output partitions
2021-12-04 17:35:57,901 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 31 (collect at PaidPromotionAdjustParameter.scala:147)
2021-12-04 17:35:57,901 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 30, ShuffleMapStage 28)
2021-12-04 17:35:57,901 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2021-12-04 17:35:57,901 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 31 (MapPartitionsRDD[32] at intersection at PaidPromotionAdjustParameter.scala:135), which has no missing parents
2021-12-04 17:35:57,902 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_20 stored as values in memory (estimated size 3.8 KB, free 1990.5 MB)
2021-12-04 17:35:57,905 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_20_piece0 stored as bytes in memory (estimated size 2.2 KB, free 1990.5 MB)
2021-12-04 17:35:57,905 [dispatcher-event-loop-0] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_20_piece0 in memory on qb:60460 (size: 2.2 KB, free: 1990.8 MB)
2021-12-04 17:35:57,905 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 20 from broadcast at DAGScheduler.scala:1039
2021-12-04 17:35:57,906 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from ResultStage 31 (MapPartitionsRDD[32] at intersection at PaidPromotionAdjustParameter.scala:135) (first 15 tasks are for partitions Vector(0, 1))
2021-12-04 17:35:57,906 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 31.0 with 2 tasks
2021-12-04 17:35:57,906 [dispatcher-event-loop-5] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 31.0 (TID 38, localhost, executor driver, partition 0, PROCESS_LOCAL, 7712 bytes)
2021-12-04 17:35:57,906 [dispatcher-event-loop-5] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 31.0 (TID 39, localhost, executor driver, partition 1, PROCESS_LOCAL, 7712 bytes)
2021-12-04 17:35:57,906 [Executor task launch worker for task 38] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 31.0 (TID 38)
2021-12-04 17:35:57,906 [Executor task launch worker for task 39] INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 31.0 (TID 39)
2021-12-04 17:35:57,907 [Executor task launch worker for task 39] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2021-12-04 17:35:57,908 [Executor task launch worker for task 38] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2021-12-04 17:35:57,908 [Executor task launch worker for task 39] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 1 ms
2021-12-04 17:35:57,908 [Executor task launch worker for task 38] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 1 ms
2021-12-04 17:35:57,909 [Executor task launch worker for task 39] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2021-12-04 17:35:57,909 [Executor task launch worker for task 38] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2021-12-04 17:35:57,909 [Executor task launch worker for task 39] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-04 17:35:57,909 [Executor task launch worker for task 38] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-04 17:35:57,914 [Executor task launch worker for task 38] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 31.0 (TID 38). 2782 bytes result sent to driver
2021-12-04 17:35:57,915 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 31.0 (TID 38) in 9 ms on localhost (executor driver) (1/2)
2021-12-04 17:35:57,915 [Executor task launch worker for task 39] INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 31.0 (TID 39). 2585 bytes result sent to driver
2021-12-04 17:35:57,915 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 31.0 (TID 39) in 9 ms on localhost (executor driver) (2/2)
2021-12-04 17:35:57,915 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 31.0, whose tasks have all completed, from pool 
2021-12-04 17:35:57,915 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 31 (collect at PaidPromotionAdjustParameter.scala:147) finished in 0.013 s
2021-12-04 17:35:57,916 [main] INFO [org.apache.spark.scheduler.DAGScheduler] - Job 11 finished: collect at PaidPromotionAdjustParameter.scala:147, took 0.015462 s
2021-12-04 17:35:57,934 [main] INFO [org.apache.spark.SparkContext] - Starting job: count at PaidPromotionAdjustParameter.scala:156
2021-12-04 17:35:57,936 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 12 (count at PaidPromotionAdjustParameter.scala:156) with 4 output partitions
2021-12-04 17:35:57,936 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 32 (count at PaidPromotionAdjustParameter.scala:156)
2021-12-04 17:35:57,936 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List()
2021-12-04 17:35:57,936 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2021-12-04 17:35:57,936 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 32 (UnionRDD[35] at union at PaidPromotionAdjustParameter.scala:154), which has no missing parents
2021-12-04 17:35:57,943 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_21 stored as values in memory (estimated size 175.6 KB, free 1990.3 MB)
2021-12-04 17:35:57,945 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_21_piece0 stored as bytes in memory (estimated size 61.8 KB, free 1990.2 MB)
2021-12-04 17:35:57,946 [dispatcher-event-loop-8] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_21_piece0 in memory on qb:60460 (size: 61.8 KB, free: 1990.7 MB)
2021-12-04 17:35:57,946 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 21 from broadcast at DAGScheduler.scala:1039
2021-12-04 17:35:57,946 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 4 missing tasks from ResultStage 32 (UnionRDD[35] at union at PaidPromotionAdjustParameter.scala:154) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
2021-12-04 17:35:57,946 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 32.0 with 4 tasks
2021-12-04 17:35:57,948 [dispatcher-event-loop-7] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 32.0 (TID 40, localhost, executor driver, partition 0, ANY, 8005 bytes)
2021-12-04 17:35:57,948 [dispatcher-event-loop-7] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 32.0 (TID 41, localhost, executor driver, partition 1, ANY, 8005 bytes)
2021-12-04 17:35:57,948 [dispatcher-event-loop-7] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 2.0 in stage 32.0 (TID 42, localhost, executor driver, partition 2, ANY, 8005 bytes)
2021-12-04 17:35:57,948 [dispatcher-event-loop-7] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 3.0 in stage 32.0 (TID 43, localhost, executor driver, partition 3, ANY, 8005 bytes)
2021-12-04 17:35:57,948 [Executor task launch worker for task 40] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 32.0 (TID 40)
2021-12-04 17:35:57,948 [Executor task launch worker for task 42] INFO [org.apache.spark.executor.Executor] - Running task 2.0 in stage 32.0 (TID 42)
2021-12-04 17:35:57,948 [Executor task launch worker for task 43] INFO [org.apache.spark.executor.Executor] - Running task 3.0 in stage 32.0 (TID 43)
2021-12-04 17:35:57,948 [Executor task launch worker for task 41] INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 32.0 (TID 41)
2021-12-04 17:35:57,951 [Executor task launch worker for task 41] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/order_data.bcp:3442194+3442195
2021-12-04 17:35:57,952 [Executor task launch worker for task 40] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/order_data.bcp:0+3442194
2021-12-04 17:35:57,952 [Executor task launch worker for task 43] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/order_data.bcp:3442194+3442195
2021-12-04 17:35:57,952 [Executor task launch worker for task 42] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/order_data.bcp:0+3442194
2021-12-04 17:35:58,787 [Executor task launch worker for task 42] INFO [org.apache.spark.executor.Executor] - Finished task 2.0 in stage 32.0 (TID 42). 754 bytes result sent to driver
2021-12-04 17:35:58,788 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 2.0 in stage 32.0 (TID 42) in 840 ms on localhost (executor driver) (1/4)
2021-12-04 17:35:59,035 [Executor task launch worker for task 41] INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 32.0 (TID 41). 754 bytes result sent to driver
2021-12-04 17:35:59,036 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 32.0 (TID 41) in 1088 ms on localhost (executor driver) (2/4)
2021-12-04 17:35:59,095 [Executor task launch worker for task 43] INFO [org.apache.spark.executor.Executor] - Finished task 3.0 in stage 32.0 (TID 43). 754 bytes result sent to driver
2021-12-04 17:35:59,096 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 3.0 in stage 32.0 (TID 43) in 1148 ms on localhost (executor driver) (3/4)
2021-12-04 17:35:59,323 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 484
2021-12-04 17:35:59,323 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 489
2021-12-04 17:35:59,323 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 476
2021-12-04 17:35:59,323 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 495
2021-12-04 17:35:59,323 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 455
2021-12-04 17:35:59,323 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 487
2021-12-04 17:35:59,323 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 478
2021-12-04 17:35:59,323 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 467
2021-12-04 17:35:59,323 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 485
2021-12-04 17:35:59,323 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 486
2021-12-04 17:35:59,324 [dispatcher-event-loop-4] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_20_piece0 on qb:60460 in memory (size: 2.2 KB, free: 1990.7 MB)
2021-12-04 17:35:59,324 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 469
2021-12-04 17:35:59,324 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 497
2021-12-04 17:35:59,324 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 490
2021-12-04 17:35:59,324 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 496
2021-12-04 17:35:59,324 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 454
2021-12-04 17:35:59,324 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 458
2021-12-04 17:35:59,324 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 480
2021-12-04 17:35:59,324 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 459
2021-12-04 17:35:59,324 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 463
2021-12-04 17:35:59,324 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 456
2021-12-04 17:35:59,324 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 470
2021-12-04 17:35:59,324 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 451
2021-12-04 17:35:59,324 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 468
2021-12-04 17:35:59,324 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 465
2021-12-04 17:35:59,324 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 482
2021-12-04 17:35:59,324 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 493
2021-12-04 17:35:59,324 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 453
2021-12-04 17:35:59,324 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 472
2021-12-04 17:35:59,324 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 498
2021-12-04 17:35:59,324 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 460
2021-12-04 17:35:59,324 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 450
2021-12-04 17:35:59,324 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 471
2021-12-04 17:35:59,324 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 479
2021-12-04 17:35:59,324 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 473
2021-12-04 17:35:59,325 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 462
2021-12-04 17:35:59,325 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 466
2021-12-04 17:35:59,325 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 499
2021-12-04 17:35:59,325 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 457
2021-12-04 17:35:59,325 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 491
2021-12-04 17:35:59,325 [dispatcher-event-loop-9] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_19_piece0 on qb:60460 in memory (size: 2.2 KB, free: 1990.7 MB)
2021-12-04 17:35:59,325 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 464
2021-12-04 17:35:59,325 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 492
2021-12-04 17:35:59,325 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 477
2021-12-04 17:35:59,326 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 461
2021-12-04 17:35:59,326 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 474
2021-12-04 17:35:59,326 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 481
2021-12-04 17:35:59,326 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 494
2021-12-04 17:35:59,326 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 488
2021-12-04 17:35:59,326 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 452
2021-12-04 17:35:59,326 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 483
2021-12-04 17:35:59,326 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 475
2021-12-04 17:35:59,409 [Executor task launch worker for task 40] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 32.0 (TID 40). 797 bytes result sent to driver
2021-12-04 17:35:59,409 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 32.0 (TID 40) in 1463 ms on localhost (executor driver) (4/4)
2021-12-04 17:35:59,409 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 32.0, whose tasks have all completed, from pool 
2021-12-04 17:35:59,410 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 32 (count at PaidPromotionAdjustParameter.scala:156) finished in 1.472 s
2021-12-04 17:35:59,410 [main] INFO [org.apache.spark.scheduler.DAGScheduler] - Job 12 finished: count at PaidPromotionAdjustParameter.scala:156, took 1.475819 s
2021-12-04 17:35:59,410 [main] INFO [PaidPromotion$] - 最终训练集数量：101656
2021-12-04 17:35:59,412 [main] INFO [org.apache.spark.SparkContext] - Starting job: count at PaidPromotionAdjustParameter.scala:157
2021-12-04 17:35:59,412 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 13 (count at PaidPromotionAdjustParameter.scala:157) with 2 output partitions
2021-12-04 17:35:59,412 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 33 (count at PaidPromotionAdjustParameter.scala:157)
2021-12-04 17:35:59,412 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List()
2021-12-04 17:35:59,412 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2021-12-04 17:35:59,412 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 33 (MapPartitionsRDD[33] at filter at PaidPromotionAdjustParameter.scala:150), which has no missing parents
2021-12-04 17:35:59,414 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_22 stored as values in memory (estimated size 175.1 KB, free 1990.1 MB)
2021-12-04 17:35:59,416 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_22_piece0 stored as bytes in memory (estimated size 61.5 KB, free 1990.0 MB)
2021-12-04 17:35:59,416 [dispatcher-event-loop-11] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_22_piece0 in memory on qb:60460 (size: 61.5 KB, free: 1990.7 MB)
2021-12-04 17:35:59,416 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 22 from broadcast at DAGScheduler.scala:1039
2021-12-04 17:35:59,417 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from ResultStage 33 (MapPartitionsRDD[33] at filter at PaidPromotionAdjustParameter.scala:150) (first 15 tasks are for partitions Vector(0, 1))
2021-12-04 17:35:59,417 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 33.0 with 2 tasks
2021-12-04 17:35:59,418 [dispatcher-event-loop-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 33.0 (TID 44, localhost, executor driver, partition 0, ANY, 7896 bytes)
2021-12-04 17:35:59,418 [dispatcher-event-loop-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 33.0 (TID 45, localhost, executor driver, partition 1, ANY, 7896 bytes)
2021-12-04 17:35:59,418 [Executor task launch worker for task 44] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 33.0 (TID 44)
2021-12-04 17:35:59,418 [Executor task launch worker for task 45] INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 33.0 (TID 45)
2021-12-04 17:35:59,421 [Executor task launch worker for task 45] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/order_data.bcp:3442194+3442195
2021-12-04 17:35:59,421 [Executor task launch worker for task 44] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/order_data.bcp:0+3442194
2021-12-04 17:36:00,239 [Executor task launch worker for task 44] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 33.0 (TID 44). 753 bytes result sent to driver
2021-12-04 17:36:00,239 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 33.0 (TID 44) in 821 ms on localhost (executor driver) (1/2)
2021-12-04 17:36:00,387 [Executor task launch worker for task 45] INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 33.0 (TID 45). 753 bytes result sent to driver
2021-12-04 17:36:00,387 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 33.0 (TID 45) in 969 ms on localhost (executor driver) (2/2)
2021-12-04 17:36:00,387 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 33.0, whose tasks have all completed, from pool 
2021-12-04 17:36:00,388 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 33 (count at PaidPromotionAdjustParameter.scala:157) finished in 0.975 s
2021-12-04 17:36:00,388 [main] INFO [org.apache.spark.scheduler.DAGScheduler] - Job 13 finished: count at PaidPromotionAdjustParameter.scala:157, took 0.976690 s
2021-12-04 17:36:00,388 [main] INFO [PaidPromotion$] - 最终验证集数量：5638
2021-12-04 17:36:00,424 [main] INFO [PaidPromotion$] - -----------------------------------
2021-12-04 17:36:00,425 [main] INFO [org.apache.spark.SparkContext] - Starting job: count at PaidPromotionAdjustParameter.scala:169
2021-12-04 17:36:00,426 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 37 (distinct at PaidPromotionAdjustParameter.scala:160)
2021-12-04 17:36:00,426 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 14 (count at PaidPromotionAdjustParameter.scala:169) with 4 output partitions
2021-12-04 17:36:00,426 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 35 (count at PaidPromotionAdjustParameter.scala:169)
2021-12-04 17:36:00,427 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 34)
2021-12-04 17:36:00,427 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List(ShuffleMapStage 34)
2021-12-04 17:36:00,427 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ShuffleMapStage 34 (MapPartitionsRDD[37] at distinct at PaidPromotionAdjustParameter.scala:160), which has no missing parents
2021-12-04 17:36:00,429 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_23 stored as values in memory (estimated size 177.2 KB, free 1989.8 MB)
2021-12-04 17:36:00,431 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_23_piece0 stored as bytes in memory (estimated size 62.8 KB, free 1989.8 MB)
2021-12-04 17:36:00,431 [dispatcher-event-loop-3] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_23_piece0 in memory on qb:60460 (size: 62.8 KB, free: 1990.6 MB)
2021-12-04 17:36:00,432 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 23 from broadcast at DAGScheduler.scala:1039
2021-12-04 17:36:00,432 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 4 missing tasks from ShuffleMapStage 34 (MapPartitionsRDD[37] at distinct at PaidPromotionAdjustParameter.scala:160) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
2021-12-04 17:36:00,432 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 34.0 with 4 tasks
2021-12-04 17:36:00,432 [dispatcher-event-loop-4] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 34.0 (TID 46, localhost, executor driver, partition 0, ANY, 7994 bytes)
2021-12-04 17:36:00,433 [dispatcher-event-loop-4] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 34.0 (TID 47, localhost, executor driver, partition 1, ANY, 7994 bytes)
2021-12-04 17:36:00,433 [dispatcher-event-loop-4] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 2.0 in stage 34.0 (TID 48, localhost, executor driver, partition 2, ANY, 7994 bytes)
2021-12-04 17:36:00,433 [dispatcher-event-loop-4] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 3.0 in stage 34.0 (TID 49, localhost, executor driver, partition 3, ANY, 7994 bytes)
2021-12-04 17:36:00,433 [Executor task launch worker for task 46] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 34.0 (TID 46)
2021-12-04 17:36:00,433 [Executor task launch worker for task 47] INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 34.0 (TID 47)
2021-12-04 17:36:00,433 [Executor task launch worker for task 49] INFO [org.apache.spark.executor.Executor] - Running task 3.0 in stage 34.0 (TID 49)
2021-12-04 17:36:00,433 [Executor task launch worker for task 48] INFO [org.apache.spark.executor.Executor] - Running task 2.0 in stage 34.0 (TID 48)
2021-12-04 17:36:00,436 [Executor task launch worker for task 49] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/order_data.bcp:3442194+3442195
2021-12-04 17:36:00,436 [Executor task launch worker for task 48] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/order_data.bcp:0+3442194
2021-12-04 17:36:00,436 [Executor task launch worker for task 46] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/order_data.bcp:0+3442194
2021-12-04 17:36:00,436 [Executor task launch worker for task 47] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/order_data.bcp:3442194+3442195
2021-12-04 17:36:00,893 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 526
2021-12-04 17:36:00,893 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 505
2021-12-04 17:36:00,893 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 523
2021-12-04 17:36:00,893 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 519
2021-12-04 17:36:00,893 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 543
2021-12-04 17:36:00,893 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 525
2021-12-04 17:36:00,893 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 508
2021-12-04 17:36:00,893 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 502
2021-12-04 17:36:00,893 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 518
2021-12-04 17:36:00,893 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 541
2021-12-04 17:36:00,893 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 500
2021-12-04 17:36:00,893 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 503
2021-12-04 17:36:00,893 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 507
2021-12-04 17:36:00,893 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 544
2021-12-04 17:36:00,893 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 533
2021-12-04 17:36:00,893 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 517
2021-12-04 17:36:00,893 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 542
2021-12-04 17:36:00,893 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 512
2021-12-04 17:36:00,893 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 548
2021-12-04 17:36:00,893 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 510
2021-12-04 17:36:00,894 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 537
2021-12-04 17:36:00,894 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 546
2021-12-04 17:36:00,894 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 522
2021-12-04 17:36:00,894 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 513
2021-12-04 17:36:00,894 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 536
2021-12-04 17:36:00,894 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 524
2021-12-04 17:36:00,894 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 516
2021-12-04 17:36:00,894 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 501
2021-12-04 17:36:00,894 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 529
2021-12-04 17:36:00,894 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 515
2021-12-04 17:36:00,894 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 539
2021-12-04 17:36:00,894 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 521
2021-12-04 17:36:00,894 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 532
2021-12-04 17:36:00,894 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 535
2021-12-04 17:36:00,895 [dispatcher-event-loop-5] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_21_piece0 on qb:60460 in memory (size: 61.8 KB, free: 1990.7 MB)
2021-12-04 17:36:00,896 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 528
2021-12-04 17:36:00,897 [dispatcher-event-loop-6] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_22_piece0 on qb:60460 in memory (size: 61.5 KB, free: 1990.7 MB)
2021-12-04 17:36:00,897 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 509
2021-12-04 17:36:00,897 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 534
2021-12-04 17:36:00,897 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 520
2021-12-04 17:36:00,897 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 514
2021-12-04 17:36:00,897 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 538
2021-12-04 17:36:00,897 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 527
2021-12-04 17:36:00,897 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 549
2021-12-04 17:36:00,897 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 506
2021-12-04 17:36:00,897 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 531
2021-12-04 17:36:00,897 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 504
2021-12-04 17:36:00,897 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 547
2021-12-04 17:36:00,897 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 545
2021-12-04 17:36:00,897 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 511
2021-12-04 17:36:00,897 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 530
2021-12-04 17:36:00,897 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 540
2021-12-04 17:36:01,208 [Executor task launch worker for task 48] INFO [org.apache.spark.executor.Executor] - Finished task 2.0 in stage 34.0 (TID 48). 1077 bytes result sent to driver
2021-12-04 17:36:01,208 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 2.0 in stage 34.0 (TID 48) in 775 ms on localhost (executor driver) (1/4)
2021-12-04 17:36:01,420 [Executor task launch worker for task 46] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 34.0 (TID 46). 1077 bytes result sent to driver
2021-12-04 17:36:01,420 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 34.0 (TID 46) in 988 ms on localhost (executor driver) (2/4)
2021-12-04 17:36:01,691 [Executor task launch worker for task 47] INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 34.0 (TID 47). 1077 bytes result sent to driver
2021-12-04 17:36:01,692 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 34.0 (TID 47) in 1260 ms on localhost (executor driver) (3/4)
2021-12-04 17:36:01,741 [Executor task launch worker for task 49] INFO [org.apache.spark.executor.Executor] - Finished task 3.0 in stage 34.0 (TID 49). 1077 bytes result sent to driver
2021-12-04 17:36:01,741 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 3.0 in stage 34.0 (TID 49) in 1308 ms on localhost (executor driver) (4/4)
2021-12-04 17:36:01,741 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 34.0, whose tasks have all completed, from pool 
2021-12-04 17:36:01,741 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ShuffleMapStage 34 (distinct at PaidPromotionAdjustParameter.scala:160) finished in 1.313 s
2021-12-04 17:36:01,741 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - looking for newly runnable stages
2021-12-04 17:36:01,741 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - running: Set()
2021-12-04 17:36:01,741 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - waiting: Set(ResultStage 35)
2021-12-04 17:36:01,741 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - failed: Set()
2021-12-04 17:36:01,741 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 35 (MapPartitionsRDD[39] at distinct at PaidPromotionAdjustParameter.scala:160), which has no missing parents
2021-12-04 17:36:01,742 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_24 stored as values in memory (estimated size 3.7 KB, free 1990.2 MB)
2021-12-04 17:36:01,743 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_24_piece0 stored as bytes in memory (estimated size 2.2 KB, free 1990.2 MB)
2021-12-04 17:36:01,744 [dispatcher-event-loop-9] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_24_piece0 in memory on qb:60460 (size: 2.2 KB, free: 1990.7 MB)
2021-12-04 17:36:01,744 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 24 from broadcast at DAGScheduler.scala:1039
2021-12-04 17:36:01,744 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 4 missing tasks from ResultStage 35 (MapPartitionsRDD[39] at distinct at PaidPromotionAdjustParameter.scala:160) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
2021-12-04 17:36:01,744 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 35.0 with 4 tasks
2021-12-04 17:36:01,745 [dispatcher-event-loop-10] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 35.0 (TID 50, localhost, executor driver, partition 0, ANY, 7649 bytes)
2021-12-04 17:36:01,745 [dispatcher-event-loop-10] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 35.0 (TID 51, localhost, executor driver, partition 1, ANY, 7649 bytes)
2021-12-04 17:36:01,745 [dispatcher-event-loop-10] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 2.0 in stage 35.0 (TID 52, localhost, executor driver, partition 2, ANY, 7649 bytes)
2021-12-04 17:36:01,745 [dispatcher-event-loop-10] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 3.0 in stage 35.0 (TID 53, localhost, executor driver, partition 3, ANY, 7649 bytes)
2021-12-04 17:36:01,745 [Executor task launch worker for task 51] INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 35.0 (TID 51)
2021-12-04 17:36:01,745 [Executor task launch worker for task 52] INFO [org.apache.spark.executor.Executor] - Running task 2.0 in stage 35.0 (TID 52)
2021-12-04 17:36:01,745 [Executor task launch worker for task 50] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 35.0 (TID 50)
2021-12-04 17:36:01,745 [Executor task launch worker for task 53] INFO [org.apache.spark.executor.Executor] - Running task 3.0 in stage 35.0 (TID 53)
2021-12-04 17:36:01,746 [Executor task launch worker for task 52] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 4 non-empty blocks out of 4 blocks
2021-12-04 17:36:01,746 [Executor task launch worker for task 51] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 4 non-empty blocks out of 4 blocks
2021-12-04 17:36:01,746 [Executor task launch worker for task 51] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-04 17:36:01,746 [Executor task launch worker for task 52] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-04 17:36:01,746 [Executor task launch worker for task 53] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 4 non-empty blocks out of 4 blocks
2021-12-04 17:36:01,746 [Executor task launch worker for task 50] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 4 non-empty blocks out of 4 blocks
2021-12-04 17:36:01,746 [Executor task launch worker for task 53] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-04 17:36:01,746 [Executor task launch worker for task 50] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-04 17:36:01,789 [Executor task launch worker for task 50] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 35.0 (TID 50). 1055 bytes result sent to driver
2021-12-04 17:36:01,789 [Executor task launch worker for task 51] INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 35.0 (TID 51). 1055 bytes result sent to driver
2021-12-04 17:36:01,789 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 35.0 (TID 51) in 44 ms on localhost (executor driver) (1/4)
2021-12-04 17:36:01,789 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 35.0 (TID 50) in 45 ms on localhost (executor driver) (2/4)
2021-12-04 17:36:01,792 [Executor task launch worker for task 53] INFO [org.apache.spark.executor.Executor] - Finished task 3.0 in stage 35.0 (TID 53). 1055 bytes result sent to driver
2021-12-04 17:36:01,792 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 3.0 in stage 35.0 (TID 53) in 47 ms on localhost (executor driver) (3/4)
2021-12-04 17:36:01,792 [Executor task launch worker for task 52] INFO [org.apache.spark.executor.Executor] - Finished task 2.0 in stage 35.0 (TID 52). 1055 bytes result sent to driver
2021-12-04 17:36:01,793 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 2.0 in stage 35.0 (TID 52) in 48 ms on localhost (executor driver) (4/4)
2021-12-04 17:36:01,793 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 35.0, whose tasks have all completed, from pool 
2021-12-04 17:36:01,793 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 35 (count at PaidPromotionAdjustParameter.scala:169) finished in 0.051 s
2021-12-04 17:36:01,793 [main] INFO [org.apache.spark.scheduler.DAGScheduler] - Job 14 finished: count at PaidPromotionAdjustParameter.scala:169, took 1.367656 s
2021-12-04 17:36:01,793 [main] INFO [PaidPromotion$] - 最终训练集用户数 = 95323
2021-12-04 17:36:01,796 [main] INFO [org.apache.spark.SparkContext] - Starting job: count at PaidPromotionAdjustParameter.scala:170
2021-12-04 17:36:01,796 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 41 (distinct at PaidPromotionAdjustParameter.scala:161)
2021-12-04 17:36:01,796 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 15 (count at PaidPromotionAdjustParameter.scala:170) with 2 output partitions
2021-12-04 17:36:01,796 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 37 (count at PaidPromotionAdjustParameter.scala:170)
2021-12-04 17:36:01,796 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 36)
2021-12-04 17:36:01,796 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List(ShuffleMapStage 36)
2021-12-04 17:36:01,796 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ShuffleMapStage 36 (MapPartitionsRDD[41] at distinct at PaidPromotionAdjustParameter.scala:161), which has no missing parents
2021-12-04 17:36:01,798 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_25 stored as values in memory (estimated size 176.6 KB, free 1990.1 MB)
2021-12-04 17:36:01,800 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_25_piece0 stored as bytes in memory (estimated size 62.4 KB, free 1990.0 MB)
2021-12-04 17:36:01,800 [dispatcher-event-loop-8] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_25_piece0 in memory on qb:60460 (size: 62.4 KB, free: 1990.6 MB)
2021-12-04 17:36:01,801 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 25 from broadcast at DAGScheduler.scala:1039
2021-12-04 17:36:01,801 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from ShuffleMapStage 36 (MapPartitionsRDD[41] at distinct at PaidPromotionAdjustParameter.scala:161) (first 15 tasks are for partitions Vector(0, 1))
2021-12-04 17:36:01,801 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 36.0 with 2 tasks
2021-12-04 17:36:01,801 [dispatcher-event-loop-7] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 36.0 (TID 54, localhost, executor driver, partition 0, ANY, 7885 bytes)
2021-12-04 17:36:01,801 [dispatcher-event-loop-7] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 36.0 (TID 55, localhost, executor driver, partition 1, ANY, 7885 bytes)
2021-12-04 17:36:01,802 [Executor task launch worker for task 55] INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 36.0 (TID 55)
2021-12-04 17:36:01,802 [Executor task launch worker for task 54] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 36.0 (TID 54)
2021-12-04 17:36:01,804 [Executor task launch worker for task 54] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/order_data.bcp:0+3442194
2021-12-04 17:36:01,804 [Executor task launch worker for task 55] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/order_data.bcp:3442194+3442195
2021-12-04 17:36:02,446 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 589
2021-12-04 17:36:02,446 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 555
2021-12-04 17:36:02,446 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 552
2021-12-04 17:36:02,446 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 566
2021-12-04 17:36:02,446 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 557
2021-12-04 17:36:02,446 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 558
2021-12-04 17:36:02,446 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 565
2021-12-04 17:36:02,446 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 590
2021-12-04 17:36:02,446 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 574
2021-12-04 17:36:02,446 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 579
2021-12-04 17:36:02,446 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 567
2021-12-04 17:36:02,446 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 568
2021-12-04 17:36:02,446 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 595
2021-12-04 17:36:02,446 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 583
2021-12-04 17:36:02,446 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 559
2021-12-04 17:36:02,446 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 580
2021-12-04 17:36:02,446 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 560
2021-12-04 17:36:02,446 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 578
2021-12-04 17:36:02,446 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 572
2021-12-04 17:36:02,446 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 569
2021-12-04 17:36:02,446 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 573
2021-12-04 17:36:02,446 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 598
2021-12-04 17:36:02,446 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 588
2021-12-04 17:36:02,446 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 584
2021-12-04 17:36:02,446 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 576
2021-12-04 17:36:02,446 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 591
2021-12-04 17:36:02,446 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 577
2021-12-04 17:36:02,446 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 551
2021-12-04 17:36:02,446 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 581
2021-12-04 17:36:02,446 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 563
2021-12-04 17:36:02,446 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 561
2021-12-04 17:36:02,446 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 554
2021-12-04 17:36:02,446 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 553
2021-12-04 17:36:02,446 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 562
2021-12-04 17:36:02,446 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 587
2021-12-04 17:36:02,446 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 597
2021-12-04 17:36:02,447 [dispatcher-event-loop-2] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_24_piece0 on qb:60460 in memory (size: 2.2 KB, free: 1990.7 MB)
2021-12-04 17:36:02,447 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 582
2021-12-04 17:36:02,447 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 593
2021-12-04 17:36:02,447 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 599
2021-12-04 17:36:02,447 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 550
2021-12-04 17:36:02,448 [dispatcher-event-loop-0] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_23_piece0 on qb:60460 in memory (size: 62.8 KB, free: 1990.7 MB)
2021-12-04 17:36:02,448 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 585
2021-12-04 17:36:02,448 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 586
2021-12-04 17:36:02,448 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 596
2021-12-04 17:36:02,448 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 571
2021-12-04 17:36:02,448 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 594
2021-12-04 17:36:02,448 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 556
2021-12-04 17:36:02,448 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 570
2021-12-04 17:36:02,448 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 592
2021-12-04 17:36:02,448 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 575
2021-12-04 17:36:02,448 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 564
2021-12-04 17:36:02,632 [Executor task launch worker for task 55] INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 36.0 (TID 55). 1032 bytes result sent to driver
2021-12-04 17:36:02,632 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 36.0 (TID 55) in 831 ms on localhost (executor driver) (1/2)
2021-12-04 17:36:02,689 [Executor task launch worker for task 54] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 36.0 (TID 54). 1032 bytes result sent to driver
2021-12-04 17:36:02,689 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 36.0 (TID 54) in 888 ms on localhost (executor driver) (2/2)
2021-12-04 17:36:02,689 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 36.0, whose tasks have all completed, from pool 
2021-12-04 17:36:02,689 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ShuffleMapStage 36 (distinct at PaidPromotionAdjustParameter.scala:161) finished in 0.892 s
2021-12-04 17:36:02,689 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - looking for newly runnable stages
2021-12-04 17:36:02,689 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - running: Set()
2021-12-04 17:36:02,690 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - waiting: Set(ResultStage 37)
2021-12-04 17:36:02,690 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - failed: Set()
2021-12-04 17:36:02,690 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 37 (MapPartitionsRDD[43] at distinct at PaidPromotionAdjustParameter.scala:161), which has no missing parents
2021-12-04 17:36:02,691 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_26 stored as values in memory (estimated size 3.7 KB, free 1990.2 MB)
2021-12-04 17:36:02,692 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_26_piece0 stored as bytes in memory (estimated size 2.2 KB, free 1990.2 MB)
2021-12-04 17:36:02,692 [dispatcher-event-loop-8] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_26_piece0 in memory on qb:60460 (size: 2.2 KB, free: 1990.7 MB)
2021-12-04 17:36:02,693 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 26 from broadcast at DAGScheduler.scala:1039
2021-12-04 17:36:02,693 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from ResultStage 37 (MapPartitionsRDD[43] at distinct at PaidPromotionAdjustParameter.scala:161) (first 15 tasks are for partitions Vector(0, 1))
2021-12-04 17:36:02,693 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 37.0 with 2 tasks
2021-12-04 17:36:02,693 [dispatcher-event-loop-7] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 37.0 (TID 56, localhost, executor driver, partition 0, ANY, 7649 bytes)
2021-12-04 17:36:02,693 [dispatcher-event-loop-7] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 37.0 (TID 57, localhost, executor driver, partition 1, ANY, 7649 bytes)
2021-12-04 17:36:02,693 [Executor task launch worker for task 56] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 37.0 (TID 56)
2021-12-04 17:36:02,694 [Executor task launch worker for task 57] INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 37.0 (TID 57)
2021-12-04 17:36:02,695 [Executor task launch worker for task 57] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 2 non-empty blocks out of 2 blocks
2021-12-04 17:36:02,695 [Executor task launch worker for task 56] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 2 non-empty blocks out of 2 blocks
2021-12-04 17:36:02,695 [Executor task launch worker for task 57] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-04 17:36:02,695 [Executor task launch worker for task 56] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-04 17:36:02,712 [Executor task launch worker for task 57] INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 37.0 (TID 57). 968 bytes result sent to driver
2021-12-04 17:36:02,712 [Executor task launch worker for task 56] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 37.0 (TID 56). 1011 bytes result sent to driver
2021-12-04 17:36:02,712 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 37.0 (TID 57) in 19 ms on localhost (executor driver) (1/2)
2021-12-04 17:36:02,713 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 37.0 (TID 56) in 19 ms on localhost (executor driver) (2/2)
2021-12-04 17:36:02,713 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 37.0, whose tasks have all completed, from pool 
2021-12-04 17:36:02,713 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 37 (count at PaidPromotionAdjustParameter.scala:170) finished in 0.023 s
2021-12-04 17:36:02,713 [main] INFO [org.apache.spark.scheduler.DAGScheduler] - Job 15 finished: count at PaidPromotionAdjustParameter.scala:170, took 0.916687 s
2021-12-04 17:36:02,713 [main] INFO [PaidPromotion$] - 最终验证集用户数 = 4910
2021-12-04 17:36:02,716 [main] INFO [org.apache.spark.SparkContext] - Starting job: count at PaidPromotionAdjustParameter.scala:171
2021-12-04 17:36:02,716 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 45 (intersection at PaidPromotionAdjustParameter.scala:162)
2021-12-04 17:36:02,717 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 44 (intersection at PaidPromotionAdjustParameter.scala:162)
2021-12-04 17:36:02,717 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 16 (count at PaidPromotionAdjustParameter.scala:171) with 4 output partitions
2021-12-04 17:36:02,717 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 42 (count at PaidPromotionAdjustParameter.scala:171)
2021-12-04 17:36:02,717 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 39, ShuffleMapStage 41)
2021-12-04 17:36:02,717 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List(ShuffleMapStage 39, ShuffleMapStage 41)
2021-12-04 17:36:02,717 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ShuffleMapStage 39 (MapPartitionsRDD[45] at intersection at PaidPromotionAdjustParameter.scala:162), which has no missing parents
2021-12-04 17:36:02,718 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_27 stored as values in memory (estimated size 4.0 KB, free 1990.2 MB)
2021-12-04 17:36:02,720 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_27_piece0 stored as bytes in memory (estimated size 2.3 KB, free 1990.2 MB)
2021-12-04 17:36:02,720 [dispatcher-event-loop-2] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_27_piece0 in memory on qb:60460 (size: 2.3 KB, free: 1990.7 MB)
2021-12-04 17:36:02,720 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 27 from broadcast at DAGScheduler.scala:1039
2021-12-04 17:36:02,720 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from ShuffleMapStage 39 (MapPartitionsRDD[45] at intersection at PaidPromotionAdjustParameter.scala:162) (first 15 tasks are for partitions Vector(0, 1))
2021-12-04 17:36:02,720 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 39.0 with 2 tasks
2021-12-04 17:36:02,721 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ShuffleMapStage 41 (MapPartitionsRDD[44] at intersection at PaidPromotionAdjustParameter.scala:162), which has no missing parents
2021-12-04 17:36:02,721 [dispatcher-event-loop-6] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 39.0 (TID 58, localhost, executor driver, partition 0, ANY, 7638 bytes)
2021-12-04 17:36:02,721 [dispatcher-event-loop-6] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 39.0 (TID 59, localhost, executor driver, partition 1, ANY, 7638 bytes)
2021-12-04 17:36:02,721 [Executor task launch worker for task 59] INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 39.0 (TID 59)
2021-12-04 17:36:02,721 [Executor task launch worker for task 58] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 39.0 (TID 58)
2021-12-04 17:36:02,722 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_28 stored as values in memory (estimated size 4.0 KB, free 1990.2 MB)
2021-12-04 17:36:02,722 [Executor task launch worker for task 59] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 2 non-empty blocks out of 2 blocks
2021-12-04 17:36:02,722 [Executor task launch worker for task 59] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-04 17:36:02,722 [Executor task launch worker for task 58] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 2 non-empty blocks out of 2 blocks
2021-12-04 17:36:02,722 [Executor task launch worker for task 58] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-04 17:36:02,724 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_28_piece0 stored as bytes in memory (estimated size 2.3 KB, free 1990.2 MB)
2021-12-04 17:36:02,724 [dispatcher-event-loop-3] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_28_piece0 in memory on qb:60460 (size: 2.3 KB, free: 1990.7 MB)
2021-12-04 17:36:02,724 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 28 from broadcast at DAGScheduler.scala:1039
2021-12-04 17:36:02,724 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 4 missing tasks from ShuffleMapStage 41 (MapPartitionsRDD[44] at intersection at PaidPromotionAdjustParameter.scala:162) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
2021-12-04 17:36:02,724 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 41.0 with 4 tasks
2021-12-04 17:36:02,725 [dispatcher-event-loop-4] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 41.0 (TID 60, localhost, executor driver, partition 0, ANY, 7638 bytes)
2021-12-04 17:36:02,725 [dispatcher-event-loop-4] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 41.0 (TID 61, localhost, executor driver, partition 1, ANY, 7638 bytes)
2021-12-04 17:36:02,725 [dispatcher-event-loop-4] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 2.0 in stage 41.0 (TID 62, localhost, executor driver, partition 2, ANY, 7638 bytes)
2021-12-04 17:36:02,725 [dispatcher-event-loop-4] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 3.0 in stage 41.0 (TID 63, localhost, executor driver, partition 3, ANY, 7638 bytes)
2021-12-04 17:36:02,725 [Executor task launch worker for task 60] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 41.0 (TID 60)
2021-12-04 17:36:02,725 [Executor task launch worker for task 61] INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 41.0 (TID 61)
2021-12-04 17:36:02,726 [Executor task launch worker for task 62] INFO [org.apache.spark.executor.Executor] - Running task 2.0 in stage 41.0 (TID 62)
2021-12-04 17:36:02,726 [Executor task launch worker for task 63] INFO [org.apache.spark.executor.Executor] - Running task 3.0 in stage 41.0 (TID 63)
2021-12-04 17:36:02,727 [Executor task launch worker for task 61] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 4 non-empty blocks out of 4 blocks
2021-12-04 17:36:02,727 [Executor task launch worker for task 62] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 4 non-empty blocks out of 4 blocks
2021-12-04 17:36:02,727 [Executor task launch worker for task 60] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 4 non-empty blocks out of 4 blocks
2021-12-04 17:36:02,727 [Executor task launch worker for task 62] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-04 17:36:02,727 [Executor task launch worker for task 61] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 1 ms
2021-12-04 17:36:02,727 [Executor task launch worker for task 60] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-04 17:36:02,727 [Executor task launch worker for task 63] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 4 non-empty blocks out of 4 blocks
2021-12-04 17:36:02,727 [Executor task launch worker for task 63] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-04 17:36:02,754 [Executor task launch worker for task 58] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 39.0 (TID 58). 1163 bytes result sent to driver
2021-12-04 17:36:02,755 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 39.0 (TID 58) in 34 ms on localhost (executor driver) (1/2)
2021-12-04 17:36:02,758 [Executor task launch worker for task 59] INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 39.0 (TID 59). 1163 bytes result sent to driver
2021-12-04 17:36:02,759 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 39.0 (TID 59) in 38 ms on localhost (executor driver) (2/2)
2021-12-04 17:36:02,759 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 39.0, whose tasks have all completed, from pool 
2021-12-04 17:36:02,759 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ShuffleMapStage 39 (intersection at PaidPromotionAdjustParameter.scala:162) finished in 0.042 s
2021-12-04 17:36:02,759 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - looking for newly runnable stages
2021-12-04 17:36:02,759 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - running: Set(ShuffleMapStage 41)
2021-12-04 17:36:02,759 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - waiting: Set(ResultStage 42)
2021-12-04 17:36:02,759 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - failed: Set()
2021-12-04 17:36:02,782 [Executor task launch worker for task 60] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 41.0 (TID 60). 1163 bytes result sent to driver
2021-12-04 17:36:02,782 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 41.0 (TID 60) in 57 ms on localhost (executor driver) (1/4)
2021-12-04 17:36:02,783 [Executor task launch worker for task 61] INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 41.0 (TID 61). 1163 bytes result sent to driver
2021-12-04 17:36:02,784 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 41.0 (TID 61) in 59 ms on localhost (executor driver) (2/4)
2021-12-04 17:36:02,784 [Executor task launch worker for task 63] INFO [org.apache.spark.executor.Executor] - Finished task 3.0 in stage 41.0 (TID 63). 1206 bytes result sent to driver
2021-12-04 17:36:02,785 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 3.0 in stage 41.0 (TID 63) in 60 ms on localhost (executor driver) (3/4)
2021-12-04 17:36:02,788 [Executor task launch worker for task 62] INFO [org.apache.spark.executor.Executor] - Finished task 2.0 in stage 41.0 (TID 62). 1163 bytes result sent to driver
2021-12-04 17:36:02,788 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 2.0 in stage 41.0 (TID 62) in 63 ms on localhost (executor driver) (4/4)
2021-12-04 17:36:02,788 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 41.0, whose tasks have all completed, from pool 
2021-12-04 17:36:02,789 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ShuffleMapStage 41 (intersection at PaidPromotionAdjustParameter.scala:162) finished in 0.068 s
2021-12-04 17:36:02,789 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - looking for newly runnable stages
2021-12-04 17:36:02,789 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - running: Set()
2021-12-04 17:36:02,789 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - waiting: Set(ResultStage 42)
2021-12-04 17:36:02,789 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - failed: Set()
2021-12-04 17:36:02,789 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 42 (MapPartitionsRDD[49] at intersection at PaidPromotionAdjustParameter.scala:162), which has no missing parents
2021-12-04 17:36:02,790 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_29 stored as values in memory (estimated size 3.6 KB, free 1990.2 MB)
2021-12-04 17:36:02,791 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_29_piece0 stored as bytes in memory (estimated size 2.1 KB, free 1990.2 MB)
2021-12-04 17:36:02,792 [dispatcher-event-loop-3] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_29_piece0 in memory on qb:60460 (size: 2.1 KB, free: 1990.7 MB)
2021-12-04 17:36:02,792 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 29 from broadcast at DAGScheduler.scala:1039
2021-12-04 17:36:02,792 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 4 missing tasks from ResultStage 42 (MapPartitionsRDD[49] at intersection at PaidPromotionAdjustParameter.scala:162) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
2021-12-04 17:36:02,792 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 42.0 with 4 tasks
2021-12-04 17:36:02,793 [dispatcher-event-loop-8] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 42.0 (TID 64, localhost, executor driver, partition 0, PROCESS_LOCAL, 7712 bytes)
2021-12-04 17:36:02,793 [dispatcher-event-loop-8] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 42.0 (TID 65, localhost, executor driver, partition 1, PROCESS_LOCAL, 7712 bytes)
2021-12-04 17:36:02,793 [dispatcher-event-loop-8] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 2.0 in stage 42.0 (TID 66, localhost, executor driver, partition 2, PROCESS_LOCAL, 7712 bytes)
2021-12-04 17:36:02,793 [dispatcher-event-loop-8] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 3.0 in stage 42.0 (TID 67, localhost, executor driver, partition 3, PROCESS_LOCAL, 7712 bytes)
2021-12-04 17:36:02,793 [Executor task launch worker for task 66] INFO [org.apache.spark.executor.Executor] - Running task 2.0 in stage 42.0 (TID 66)
2021-12-04 17:36:02,793 [Executor task launch worker for task 67] INFO [org.apache.spark.executor.Executor] - Running task 3.0 in stage 42.0 (TID 67)
2021-12-04 17:36:02,793 [Executor task launch worker for task 64] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 42.0 (TID 64)
2021-12-04 17:36:02,793 [Executor task launch worker for task 65] INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 42.0 (TID 65)
2021-12-04 17:36:02,794 [Executor task launch worker for task 64] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 4 blocks
2021-12-04 17:36:02,794 [Executor task launch worker for task 67] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 4 blocks
2021-12-04 17:36:02,794 [Executor task launch worker for task 64] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-04 17:36:02,794 [Executor task launch worker for task 67] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-04 17:36:02,794 [Executor task launch worker for task 66] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 4 blocks
2021-12-04 17:36:02,794 [Executor task launch worker for task 65] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 4 blocks
2021-12-04 17:36:02,794 [Executor task launch worker for task 66] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-04 17:36:02,795 [Executor task launch worker for task 65] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 1 ms
2021-12-04 17:36:02,796 [Executor task launch worker for task 66] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2021-12-04 17:36:02,796 [Executor task launch worker for task 64] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2021-12-04 17:36:02,796 [Executor task launch worker for task 66] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-04 17:36:02,796 [Executor task launch worker for task 65] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2021-12-04 17:36:02,796 [Executor task launch worker for task 65] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-04 17:36:02,796 [Executor task launch worker for task 64] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-04 17:36:02,796 [Executor task launch worker for task 67] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2021-12-04 17:36:02,796 [Executor task launch worker for task 67] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-04 17:36:02,847 [Executor task launch worker for task 65] INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 42.0 (TID 65). 1054 bytes result sent to driver
2021-12-04 17:36:02,847 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 42.0 (TID 65) in 54 ms on localhost (executor driver) (1/4)
2021-12-04 17:36:02,848 [Executor task launch worker for task 67] INFO [org.apache.spark.executor.Executor] - Finished task 3.0 in stage 42.0 (TID 67). 1097 bytes result sent to driver
2021-12-04 17:36:02,848 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 3.0 in stage 42.0 (TID 67) in 55 ms on localhost (executor driver) (2/4)
2021-12-04 17:36:02,849 [Executor task launch worker for task 66] INFO [org.apache.spark.executor.Executor] - Finished task 2.0 in stage 42.0 (TID 66). 1054 bytes result sent to driver
2021-12-04 17:36:02,849 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 2.0 in stage 42.0 (TID 66) in 56 ms on localhost (executor driver) (3/4)
2021-12-04 17:36:02,849 [Executor task launch worker for task 64] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 42.0 (TID 64). 1054 bytes result sent to driver
2021-12-04 17:36:02,849 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 42.0 (TID 64) in 56 ms on localhost (executor driver) (4/4)
2021-12-04 17:36:02,849 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 42.0, whose tasks have all completed, from pool 
2021-12-04 17:36:02,849 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 42 (count at PaidPromotionAdjustParameter.scala:171) finished in 0.060 s
2021-12-04 17:36:02,850 [main] INFO [org.apache.spark.scheduler.DAGScheduler] - Job 16 finished: count at PaidPromotionAdjustParameter.scala:171, took 0.133217 s
2021-12-04 17:36:02,850 [main] INFO [PaidPromotion$] - 最终共 同 用户数 = 4910
2021-12-04 17:36:02,852 [main] INFO [org.apache.spark.SparkContext] - Starting job: count at PaidPromotionAdjustParameter.scala:172
2021-12-04 17:36:02,853 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 51 (distinct at PaidPromotionAdjustParameter.scala:164)
2021-12-04 17:36:02,853 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 17 (count at PaidPromotionAdjustParameter.scala:172) with 4 output partitions
2021-12-04 17:36:02,853 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 44 (count at PaidPromotionAdjustParameter.scala:172)
2021-12-04 17:36:02,853 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 43)
2021-12-04 17:36:02,853 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List(ShuffleMapStage 43)
2021-12-04 17:36:02,853 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ShuffleMapStage 43 (MapPartitionsRDD[51] at distinct at PaidPromotionAdjustParameter.scala:164), which has no missing parents
2021-12-04 17:36:02,854 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_30 stored as values in memory (estimated size 177.2 KB, free 1990.0 MB)
2021-12-04 17:36:02,856 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_30_piece0 stored as bytes in memory (estimated size 62.8 KB, free 1990.0 MB)
2021-12-04 17:36:02,857 [dispatcher-event-loop-0] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_30_piece0 in memory on qb:60460 (size: 62.8 KB, free: 1990.6 MB)
2021-12-04 17:36:02,857 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 30 from broadcast at DAGScheduler.scala:1039
2021-12-04 17:36:02,857 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 4 missing tasks from ShuffleMapStage 43 (MapPartitionsRDD[51] at distinct at PaidPromotionAdjustParameter.scala:164) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
2021-12-04 17:36:02,857 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 43.0 with 4 tasks
2021-12-04 17:36:02,858 [dispatcher-event-loop-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 43.0 (TID 68, localhost, executor driver, partition 0, ANY, 7994 bytes)
2021-12-04 17:36:02,858 [dispatcher-event-loop-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 43.0 (TID 69, localhost, executor driver, partition 1, ANY, 7994 bytes)
2021-12-04 17:36:02,858 [dispatcher-event-loop-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 2.0 in stage 43.0 (TID 70, localhost, executor driver, partition 2, ANY, 7994 bytes)
2021-12-04 17:36:02,858 [dispatcher-event-loop-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 3.0 in stage 43.0 (TID 71, localhost, executor driver, partition 3, ANY, 7994 bytes)
2021-12-04 17:36:02,858 [Executor task launch worker for task 68] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 43.0 (TID 68)
2021-12-04 17:36:02,858 [Executor task launch worker for task 71] INFO [org.apache.spark.executor.Executor] - Running task 3.0 in stage 43.0 (TID 71)
2021-12-04 17:36:02,858 [Executor task launch worker for task 70] INFO [org.apache.spark.executor.Executor] - Running task 2.0 in stage 43.0 (TID 70)
2021-12-04 17:36:02,858 [Executor task launch worker for task 69] INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 43.0 (TID 69)
2021-12-04 17:36:02,860 [Executor task launch worker for task 70] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/order_data.bcp:0+3442194
2021-12-04 17:36:02,860 [Executor task launch worker for task 71] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/order_data.bcp:3442194+3442195
2021-12-04 17:36:02,860 [Executor task launch worker for task 69] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/order_data.bcp:3442194+3442195
2021-12-04 17:36:02,860 [Executor task launch worker for task 68] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/order_data.bcp:0+3442194
2021-12-04 17:36:03,097 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 711
2021-12-04 17:36:03,097 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 628
2021-12-04 17:36:03,097 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 671
2021-12-04 17:36:03,097 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 623
2021-12-04 17:36:03,097 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 666
2021-12-04 17:36:03,097 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 714
2021-12-04 17:36:03,097 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 690
2021-12-04 17:36:03,097 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 616
2021-12-04 17:36:03,097 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 632
2021-12-04 17:36:03,097 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 689
2021-12-04 17:36:03,097 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 715
2021-12-04 17:36:03,097 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 693
2021-12-04 17:36:03,097 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 622
2021-12-04 17:36:03,097 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 718
2021-12-04 17:36:03,097 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 626
2021-12-04 17:36:03,097 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 603
2021-12-04 17:36:03,097 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 703
2021-12-04 17:36:03,097 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 649
2021-12-04 17:36:03,097 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 631
2021-12-04 17:36:03,097 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 677
2021-12-04 17:36:03,097 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 706
2021-12-04 17:36:03,097 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 710
2021-12-04 17:36:03,098 [dispatcher-event-loop-11] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_29_piece0 on qb:60460 in memory (size: 2.1 KB, free: 1990.6 MB)
2021-12-04 17:36:03,098 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 672
2021-12-04 17:36:03,098 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 708
2021-12-04 17:36:03,098 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 641
2021-12-04 17:36:03,098 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 611
2021-12-04 17:36:03,098 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 612
2021-12-04 17:36:03,098 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 647
2021-12-04 17:36:03,098 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 673
2021-12-04 17:36:03,098 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 680
2021-12-04 17:36:03,098 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 661
2021-12-04 17:36:03,098 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 691
2021-12-04 17:36:03,099 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 646
2021-12-04 17:36:03,099 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 609
2021-12-04 17:36:03,099 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 621
2021-12-04 17:36:03,099 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 660
2021-12-04 17:36:03,099 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 709
2021-12-04 17:36:03,099 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 637
2021-12-04 17:36:03,099 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 600
2021-12-04 17:36:03,099 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 674
2021-12-04 17:36:03,099 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 635
2021-12-04 17:36:03,099 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 643
2021-12-04 17:36:03,099 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 659
2021-12-04 17:36:03,099 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 615
2021-12-04 17:36:03,099 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 638
2021-12-04 17:36:03,099 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 645
2021-12-04 17:36:03,099 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 601
2021-12-04 17:36:03,099 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 688
2021-12-04 17:36:03,099 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 687
2021-12-04 17:36:03,099 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 640
2021-12-04 17:36:03,099 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 694
2021-12-04 17:36:03,099 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 620
2021-12-04 17:36:03,099 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 667
2021-12-04 17:36:03,099 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 698
2021-12-04 17:36:03,099 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 663
2021-12-04 17:36:03,099 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 648
2021-12-04 17:36:03,099 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 702
2021-12-04 17:36:03,099 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 662
2021-12-04 17:36:03,099 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 651
2021-12-04 17:36:03,099 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 636
2021-12-04 17:36:03,099 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 679
2021-12-04 17:36:03,099 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 650
2021-12-04 17:36:03,099 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 656
2021-12-04 17:36:03,099 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 675
2021-12-04 17:36:03,099 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 683
2021-12-04 17:36:03,099 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 704
2021-12-04 17:36:03,099 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 700
2021-12-04 17:36:03,099 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 608
2021-12-04 17:36:03,099 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 681
2021-12-04 17:36:03,099 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 624
2021-12-04 17:36:03,099 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 604
2021-12-04 17:36:03,099 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 654
2021-12-04 17:36:03,099 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 629
2021-12-04 17:36:03,099 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 717
2021-12-04 17:36:03,099 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 719
2021-12-04 17:36:03,099 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 657
2021-12-04 17:36:03,099 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 613
2021-12-04 17:36:03,099 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 634
2021-12-04 17:36:03,099 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 684
2021-12-04 17:36:03,099 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 669
2021-12-04 17:36:03,099 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 697
2021-12-04 17:36:03,099 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 605
2021-12-04 17:36:03,099 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 682
2021-12-04 17:36:03,099 [dispatcher-event-loop-6] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_28_piece0 on qb:60460 in memory (size: 2.3 KB, free: 1990.6 MB)
2021-12-04 17:36:03,100 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 610
2021-12-04 17:36:03,100 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 713
2021-12-04 17:36:03,100 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 633
2021-12-04 17:36:03,100 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 678
2021-12-04 17:36:03,100 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 723
2021-12-04 17:36:03,100 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 618
2021-12-04 17:36:03,100 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 712
2021-12-04 17:36:03,100 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 724
2021-12-04 17:36:03,100 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 606
2021-12-04 17:36:03,100 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 695
2021-12-04 17:36:03,100 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 644
2021-12-04 17:36:03,100 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 652
2021-12-04 17:36:03,100 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 653
2021-12-04 17:36:03,100 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 614
2021-12-04 17:36:03,100 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 721
2021-12-04 17:36:03,100 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 630
2021-12-04 17:36:03,100 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 602
2021-12-04 17:36:03,100 [dispatcher-event-loop-3] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_25_piece0 on qb:60460 in memory (size: 62.4 KB, free: 1990.7 MB)
2021-12-04 17:36:03,101 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 668
2021-12-04 17:36:03,101 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 685
2021-12-04 17:36:03,101 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 720
2021-12-04 17:36:03,101 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 639
2021-12-04 17:36:03,101 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 642
2021-12-04 17:36:03,101 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 625
2021-12-04 17:36:03,101 [dispatcher-event-loop-4] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_27_piece0 on qb:60460 in memory (size: 2.3 KB, free: 1990.7 MB)
2021-12-04 17:36:03,101 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 607
2021-12-04 17:36:03,101 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 722
2021-12-04 17:36:03,101 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 705
2021-12-04 17:36:03,101 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 699
2021-12-04 17:36:03,101 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 676
2021-12-04 17:36:03,101 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 617
2021-12-04 17:36:03,102 [dispatcher-event-loop-11] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_26_piece0 on qb:60460 in memory (size: 2.2 KB, free: 1990.7 MB)
2021-12-04 17:36:03,102 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 619
2021-12-04 17:36:03,102 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 664
2021-12-04 17:36:03,102 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 670
2021-12-04 17:36:03,102 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 686
2021-12-04 17:36:03,102 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 627
2021-12-04 17:36:03,102 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 701
2021-12-04 17:36:03,102 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 716
2021-12-04 17:36:03,102 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 655
2021-12-04 17:36:03,102 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 658
2021-12-04 17:36:03,102 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 696
2021-12-04 17:36:03,102 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 692
2021-12-04 17:36:03,102 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 707
2021-12-04 17:36:03,102 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 665
2021-12-04 17:36:03,507 [Executor task launch worker for task 71] INFO [org.apache.spark.executor.Executor] - Finished task 3.0 in stage 43.0 (TID 71). 1034 bytes result sent to driver
2021-12-04 17:36:03,507 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 3.0 in stage 43.0 (TID 71) in 649 ms on localhost (executor driver) (1/4)
2021-12-04 17:36:03,848 [Executor task launch worker for task 69] INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 43.0 (TID 69). 1034 bytes result sent to driver
2021-12-04 17:36:03,848 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 43.0 (TID 69) in 990 ms on localhost (executor driver) (2/4)
2021-12-04 17:36:04,158 [Executor task launch worker for task 70] INFO [org.apache.spark.executor.Executor] - Finished task 2.0 in stage 43.0 (TID 70). 1034 bytes result sent to driver
2021-12-04 17:36:04,159 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 2.0 in stage 43.0 (TID 70) in 1301 ms on localhost (executor driver) (3/4)
2021-12-04 17:36:04,254 [Executor task launch worker for task 68] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 43.0 (TID 68). 1034 bytes result sent to driver
2021-12-04 17:36:04,255 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 43.0 (TID 68) in 1397 ms on localhost (executor driver) (4/4)
2021-12-04 17:36:04,255 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 43.0, whose tasks have all completed, from pool 
2021-12-04 17:36:04,255 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ShuffleMapStage 43 (distinct at PaidPromotionAdjustParameter.scala:164) finished in 1.402 s
2021-12-04 17:36:04,255 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - looking for newly runnable stages
2021-12-04 17:36:04,255 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - running: Set()
2021-12-04 17:36:04,255 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - waiting: Set(ResultStage 44)
2021-12-04 17:36:04,255 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - failed: Set()
2021-12-04 17:36:04,255 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 44 (MapPartitionsRDD[53] at distinct at PaidPromotionAdjustParameter.scala:164), which has no missing parents
2021-12-04 17:36:04,256 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_31 stored as values in memory (estimated size 3.7 KB, free 1990.2 MB)
2021-12-04 17:36:04,258 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_31_piece0 stored as bytes in memory (estimated size 2.2 KB, free 1990.2 MB)
2021-12-04 17:36:04,258 [dispatcher-event-loop-0] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_31_piece0 in memory on qb:60460 (size: 2.2 KB, free: 1990.7 MB)
2021-12-04 17:36:04,258 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 31 from broadcast at DAGScheduler.scala:1039
2021-12-04 17:36:04,258 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 4 missing tasks from ResultStage 44 (MapPartitionsRDD[53] at distinct at PaidPromotionAdjustParameter.scala:164) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
2021-12-04 17:36:04,258 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 44.0 with 4 tasks
2021-12-04 17:36:04,259 [dispatcher-event-loop-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 44.0 (TID 72, localhost, executor driver, partition 0, ANY, 7649 bytes)
2021-12-04 17:36:04,259 [dispatcher-event-loop-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 44.0 (TID 73, localhost, executor driver, partition 1, ANY, 7649 bytes)
2021-12-04 17:36:04,259 [dispatcher-event-loop-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 2.0 in stage 44.0 (TID 74, localhost, executor driver, partition 2, ANY, 7649 bytes)
2021-12-04 17:36:04,259 [dispatcher-event-loop-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 3.0 in stage 44.0 (TID 75, localhost, executor driver, partition 3, ANY, 7649 bytes)
2021-12-04 17:36:04,259 [Executor task launch worker for task 74] INFO [org.apache.spark.executor.Executor] - Running task 2.0 in stage 44.0 (TID 74)
2021-12-04 17:36:04,259 [Executor task launch worker for task 73] INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 44.0 (TID 73)
2021-12-04 17:36:04,259 [Executor task launch worker for task 72] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 44.0 (TID 72)
2021-12-04 17:36:04,259 [Executor task launch worker for task 75] INFO [org.apache.spark.executor.Executor] - Running task 3.0 in stage 44.0 (TID 75)
2021-12-04 17:36:04,260 [Executor task launch worker for task 75] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 4 non-empty blocks out of 4 blocks
2021-12-04 17:36:04,260 [Executor task launch worker for task 74] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 4 non-empty blocks out of 4 blocks
2021-12-04 17:36:04,260 [Executor task launch worker for task 75] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-04 17:36:04,261 [Executor task launch worker for task 74] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 1 ms
2021-12-04 17:36:04,261 [Executor task launch worker for task 73] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 4 non-empty blocks out of 4 blocks
2021-12-04 17:36:04,261 [Executor task launch worker for task 72] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 4 non-empty blocks out of 4 blocks
2021-12-04 17:36:04,261 [Executor task launch worker for task 73] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 1 ms
2021-12-04 17:36:04,261 [Executor task launch worker for task 72] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 1 ms
2021-12-04 17:36:04,281 [Executor task launch worker for task 74] INFO [org.apache.spark.executor.Executor] - Finished task 2.0 in stage 44.0 (TID 74). 1053 bytes result sent to driver
2021-12-04 17:36:04,281 [Executor task launch worker for task 75] INFO [org.apache.spark.executor.Executor] - Finished task 3.0 in stage 44.0 (TID 75). 1053 bytes result sent to driver
2021-12-04 17:36:04,281 [Executor task launch worker for task 72] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 44.0 (TID 72). 1053 bytes result sent to driver
2021-12-04 17:36:04,281 [Executor task launch worker for task 73] INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 44.0 (TID 73). 1053 bytes result sent to driver
2021-12-04 17:36:04,281 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 2.0 in stage 44.0 (TID 74) in 22 ms on localhost (executor driver) (1/4)
2021-12-04 17:36:04,281 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 3.0 in stage 44.0 (TID 75) in 22 ms on localhost (executor driver) (2/4)
2021-12-04 17:36:04,281 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 44.0 (TID 72) in 22 ms on localhost (executor driver) (3/4)
2021-12-04 17:36:04,281 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 44.0 (TID 73) in 22 ms on localhost (executor driver) (4/4)
2021-12-04 17:36:04,282 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 44.0, whose tasks have all completed, from pool 
2021-12-04 17:36:04,282 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 44 (count at PaidPromotionAdjustParameter.scala:172) finished in 0.026 s
2021-12-04 17:36:04,282 [main] INFO [org.apache.spark.scheduler.DAGScheduler] - Job 17 finished: count at PaidPromotionAdjustParameter.scala:172, took 1.430159 s
2021-12-04 17:36:04,282 [main] INFO [PaidPromotion$] - 最终训练集节目数 = 132
2021-12-04 17:36:04,284 [main] INFO [org.apache.spark.SparkContext] - Starting job: count at PaidPromotionAdjustParameter.scala:173
2021-12-04 17:36:04,284 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 55 (distinct at PaidPromotionAdjustParameter.scala:165)
2021-12-04 17:36:04,284 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 18 (count at PaidPromotionAdjustParameter.scala:173) with 2 output partitions
2021-12-04 17:36:04,284 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 46 (count at PaidPromotionAdjustParameter.scala:173)
2021-12-04 17:36:04,285 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 45)
2021-12-04 17:36:04,285 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List(ShuffleMapStage 45)
2021-12-04 17:36:04,285 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ShuffleMapStage 45 (MapPartitionsRDD[55] at distinct at PaidPromotionAdjustParameter.scala:165), which has no missing parents
2021-12-04 17:36:04,286 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_32 stored as values in memory (estimated size 176.6 KB, free 1990.1 MB)
2021-12-04 17:36:04,288 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_32_piece0 stored as bytes in memory (estimated size 62.4 KB, free 1990.0 MB)
2021-12-04 17:36:04,288 [dispatcher-event-loop-6] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_32_piece0 in memory on qb:60460 (size: 62.4 KB, free: 1990.6 MB)
2021-12-04 17:36:04,288 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 32 from broadcast at DAGScheduler.scala:1039
2021-12-04 17:36:04,289 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from ShuffleMapStage 45 (MapPartitionsRDD[55] at distinct at PaidPromotionAdjustParameter.scala:165) (first 15 tasks are for partitions Vector(0, 1))
2021-12-04 17:36:04,289 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 45.0 with 2 tasks
2021-12-04 17:36:04,289 [dispatcher-event-loop-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 45.0 (TID 76, localhost, executor driver, partition 0, ANY, 7885 bytes)
2021-12-04 17:36:04,289 [dispatcher-event-loop-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 45.0 (TID 77, localhost, executor driver, partition 1, ANY, 7885 bytes)
2021-12-04 17:36:04,289 [Executor task launch worker for task 77] INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 45.0 (TID 77)
2021-12-04 17:36:04,289 [Executor task launch worker for task 76] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 45.0 (TID 76)
2021-12-04 17:36:04,291 [Executor task launch worker for task 77] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/order_data.bcp:3442194+3442195
2021-12-04 17:36:04,291 [Executor task launch worker for task 76] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/order_data.bcp:0+3442194
2021-12-04 17:36:05,094 [Executor task launch worker for task 77] INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 45.0 (TID 77). 989 bytes result sent to driver
2021-12-04 17:36:05,094 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 45.0 (TID 77) in 805 ms on localhost (executor driver) (1/2)
2021-12-04 17:36:05,125 [Executor task launch worker for task 76] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 45.0 (TID 76). 989 bytes result sent to driver
2021-12-04 17:36:05,125 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 45.0 (TID 76) in 836 ms on localhost (executor driver) (2/2)
2021-12-04 17:36:05,125 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 45.0, whose tasks have all completed, from pool 
2021-12-04 17:36:05,126 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ShuffleMapStage 45 (distinct at PaidPromotionAdjustParameter.scala:165) finished in 0.841 s
2021-12-04 17:36:05,126 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - looking for newly runnable stages
2021-12-04 17:36:05,126 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - running: Set()
2021-12-04 17:36:05,126 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - waiting: Set(ResultStage 46)
2021-12-04 17:36:05,126 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - failed: Set()
2021-12-04 17:36:05,126 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 46 (MapPartitionsRDD[57] at distinct at PaidPromotionAdjustParameter.scala:165), which has no missing parents
2021-12-04 17:36:05,126 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_33 stored as values in memory (estimated size 3.7 KB, free 1990.0 MB)
2021-12-04 17:36:05,128 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_33_piece0 stored as bytes in memory (estimated size 2.2 KB, free 1990.0 MB)
2021-12-04 17:36:05,128 [dispatcher-event-loop-9] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_33_piece0 in memory on qb:60460 (size: 2.2 KB, free: 1990.6 MB)
2021-12-04 17:36:05,128 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 33 from broadcast at DAGScheduler.scala:1039
2021-12-04 17:36:05,128 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from ResultStage 46 (MapPartitionsRDD[57] at distinct at PaidPromotionAdjustParameter.scala:165) (first 15 tasks are for partitions Vector(0, 1))
2021-12-04 17:36:05,128 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 46.0 with 2 tasks
2021-12-04 17:36:05,129 [dispatcher-event-loop-7] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 46.0 (TID 78, localhost, executor driver, partition 0, ANY, 7649 bytes)
2021-12-04 17:36:05,129 [dispatcher-event-loop-7] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 46.0 (TID 79, localhost, executor driver, partition 1, ANY, 7649 bytes)
2021-12-04 17:36:05,129 [Executor task launch worker for task 78] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 46.0 (TID 78)
2021-12-04 17:36:05,132 [Executor task launch worker for task 79] INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 46.0 (TID 79)
2021-12-04 17:36:05,132 [Executor task launch worker for task 78] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 2 non-empty blocks out of 2 blocks
2021-12-04 17:36:05,132 [Executor task launch worker for task 78] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-04 17:36:05,132 [Executor task launch worker for task 79] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 2 non-empty blocks out of 2 blocks
2021-12-04 17:36:05,132 [Executor task launch worker for task 79] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-04 17:36:05,142 [Executor task launch worker for task 79] INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 46.0 (TID 79). 1053 bytes result sent to driver
2021-12-04 17:36:05,142 [Executor task launch worker for task 78] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 46.0 (TID 78). 1053 bytes result sent to driver
2021-12-04 17:36:05,143 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 46.0 (TID 79) in 13 ms on localhost (executor driver) (1/2)
2021-12-04 17:36:05,143 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 46.0 (TID 78) in 15 ms on localhost (executor driver) (2/2)
2021-12-04 17:36:05,143 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 46.0, whose tasks have all completed, from pool 
2021-12-04 17:36:05,143 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 46 (count at PaidPromotionAdjustParameter.scala:173) finished in 0.017 s
2021-12-04 17:36:05,143 [main] INFO [org.apache.spark.scheduler.DAGScheduler] - Job 18 finished: count at PaidPromotionAdjustParameter.scala:173, took 0.858599 s
2021-12-04 17:36:05,143 [main] INFO [PaidPromotion$] - 最终验证集节目数 = 84
2021-12-04 17:36:05,146 [main] INFO [org.apache.spark.SparkContext] - Starting job: count at PaidPromotionAdjustParameter.scala:174
2021-12-04 17:36:05,146 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 59 (intersection at PaidPromotionAdjustParameter.scala:166)
2021-12-04 17:36:05,146 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 58 (intersection at PaidPromotionAdjustParameter.scala:166)
2021-12-04 17:36:05,146 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 19 (count at PaidPromotionAdjustParameter.scala:174) with 4 output partitions
2021-12-04 17:36:05,146 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 51 (count at PaidPromotionAdjustParameter.scala:174)
2021-12-04 17:36:05,146 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 48, ShuffleMapStage 50)
2021-12-04 17:36:05,146 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List(ShuffleMapStage 48, ShuffleMapStage 50)
2021-12-04 17:36:05,147 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ShuffleMapStage 48 (MapPartitionsRDD[59] at intersection at PaidPromotionAdjustParameter.scala:166), which has no missing parents
2021-12-04 17:36:05,147 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_34 stored as values in memory (estimated size 4.0 KB, free 1990.0 MB)
2021-12-04 17:36:05,151 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 810
2021-12-04 17:36:05,152 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 735
2021-12-04 17:36:05,152 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 791
2021-12-04 17:36:05,152 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 804
2021-12-04 17:36:05,152 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_34_piece0 stored as bytes in memory (estimated size 2.3 KB, free 1990.0 MB)
2021-12-04 17:36:05,152 [dispatcher-event-loop-0] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_34_piece0 in memory on qb:60460 (size: 2.3 KB, free: 1990.6 MB)
2021-12-04 17:36:05,152 [dispatcher-event-loop-0] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_31_piece0 on qb:60460 in memory (size: 2.2 KB, free: 1990.6 MB)
2021-12-04 17:36:05,152 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 34 from broadcast at DAGScheduler.scala:1039
2021-12-04 17:36:05,152 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 789
2021-12-04 17:36:05,153 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 744
2021-12-04 17:36:05,153 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 734
2021-12-04 17:36:05,153 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 787
2021-12-04 17:36:05,153 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 773
2021-12-04 17:36:05,153 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 777
2021-12-04 17:36:05,153 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 798
2021-12-04 17:36:05,153 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 797
2021-12-04 17:36:05,153 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 729
2021-12-04 17:36:05,153 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 750
2021-12-04 17:36:05,153 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 749
2021-12-04 17:36:05,153 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 751
2021-12-04 17:36:05,153 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 813
2021-12-04 17:36:05,153 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from ShuffleMapStage 48 (MapPartitionsRDD[59] at intersection at PaidPromotionAdjustParameter.scala:166) (first 15 tasks are for partitions Vector(0, 1))
2021-12-04 17:36:05,153 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 48.0 with 2 tasks
2021-12-04 17:36:05,153 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 781
2021-12-04 17:36:05,153 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 754
2021-12-04 17:36:05,153 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 757
2021-12-04 17:36:05,153 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 742
2021-12-04 17:36:05,153 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ShuffleMapStage 50 (MapPartitionsRDD[58] at intersection at PaidPromotionAdjustParameter.scala:166), which has no missing parents
2021-12-04 17:36:05,153 [dispatcher-event-loop-9] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 48.0 (TID 80, localhost, executor driver, partition 0, ANY, 7638 bytes)
2021-12-04 17:36:05,153 [dispatcher-event-loop-7] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_32_piece0 on qb:60460 in memory (size: 62.4 KB, free: 1990.7 MB)
2021-12-04 17:36:05,153 [dispatcher-event-loop-9] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 48.0 (TID 81, localhost, executor driver, partition 1, ANY, 7638 bytes)
2021-12-04 17:36:05,153 [Executor task launch worker for task 81] INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 48.0 (TID 81)
2021-12-04 17:36:05,153 [Executor task launch worker for task 80] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 48.0 (TID 80)
2021-12-04 17:36:05,153 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 806
2021-12-04 17:36:05,154 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 823
2021-12-04 17:36:05,154 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_35 stored as values in memory (estimated size 4.0 KB, free 1990.2 MB)
2021-12-04 17:36:05,154 [dispatcher-event-loop-1] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_33_piece0 on qb:60460 in memory (size: 2.2 KB, free: 1990.7 MB)
2021-12-04 17:36:05,154 [Executor task launch worker for task 80] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 2 non-empty blocks out of 2 blocks
2021-12-04 17:36:05,154 [Executor task launch worker for task 81] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 2 non-empty blocks out of 2 blocks
2021-12-04 17:36:05,154 [Executor task launch worker for task 80] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-04 17:36:05,154 [Executor task launch worker for task 81] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-04 17:36:05,154 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 799
2021-12-04 17:36:05,154 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 807
2021-12-04 17:36:05,154 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 764
2021-12-04 17:36:05,154 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 801
2021-12-04 17:36:05,154 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 793
2021-12-04 17:36:05,154 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 820
2021-12-04 17:36:05,154 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 748
2021-12-04 17:36:05,154 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 779
2021-12-04 17:36:05,154 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 808
2021-12-04 17:36:05,154 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 770
2021-12-04 17:36:05,154 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 765
2021-12-04 17:36:05,155 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 766
2021-12-04 17:36:05,155 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 824
2021-12-04 17:36:05,155 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 736
2021-12-04 17:36:05,155 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 817
2021-12-04 17:36:05,155 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 794
2021-12-04 17:36:05,155 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 809
2021-12-04 17:36:05,155 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 815
2021-12-04 17:36:05,155 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 792
2021-12-04 17:36:05,155 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 756
2021-12-04 17:36:05,155 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 755
2021-12-04 17:36:05,155 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 743
2021-12-04 17:36:05,155 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 745
2021-12-04 17:36:05,155 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 818
2021-12-04 17:36:05,155 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 761
2021-12-04 17:36:05,155 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 753
2021-12-04 17:36:05,155 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 730
2021-12-04 17:36:05,155 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 788
2021-12-04 17:36:05,155 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 768
2021-12-04 17:36:05,155 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 763
2021-12-04 17:36:05,155 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 741
2021-12-04 17:36:05,155 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 778
2021-12-04 17:36:05,155 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 780
2021-12-04 17:36:05,155 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 727
2021-12-04 17:36:05,155 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 758
2021-12-04 17:36:05,155 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 805
2021-12-04 17:36:05,155 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 769
2021-12-04 17:36:05,155 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 739
2021-12-04 17:36:05,155 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 728
2021-12-04 17:36:05,155 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 802
2021-12-04 17:36:05,155 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 814
2021-12-04 17:36:05,155 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 726
2021-12-04 17:36:05,155 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 760
2021-12-04 17:36:05,155 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 737
2021-12-04 17:36:05,155 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 759
2021-12-04 17:36:05,155 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 762
2021-12-04 17:36:05,155 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 795
2021-12-04 17:36:05,155 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 775
2021-12-04 17:36:05,155 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 767
2021-12-04 17:36:05,155 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 811
2021-12-04 17:36:05,155 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 822
2021-12-04 17:36:05,155 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 776
2021-12-04 17:36:05,155 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 785
2021-12-04 17:36:05,155 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 796
2021-12-04 17:36:05,155 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 816
2021-12-04 17:36:05,155 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 733
2021-12-04 17:36:05,155 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 746
2021-12-04 17:36:05,155 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 774
2021-12-04 17:36:05,155 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 782
2021-12-04 17:36:05,155 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 731
2021-12-04 17:36:05,155 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 821
2021-12-04 17:36:05,155 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 784
2021-12-04 17:36:05,155 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 800
2021-12-04 17:36:05,155 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 747
2021-12-04 17:36:05,155 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_35_piece0 stored as bytes in memory (estimated size 2.3 KB, free 1990.3 MB)
2021-12-04 17:36:05,156 [dispatcher-event-loop-0] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_30_piece0 on qb:60460 in memory (size: 62.8 KB, free: 1990.8 MB)
2021-12-04 17:36:05,156 [dispatcher-event-loop-0] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_35_piece0 in memory on qb:60460 (size: 2.3 KB, free: 1990.8 MB)
2021-12-04 17:36:05,156 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 819
2021-12-04 17:36:05,156 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 725
2021-12-04 17:36:05,156 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 752
2021-12-04 17:36:05,156 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 732
2021-12-04 17:36:05,156 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 803
2021-12-04 17:36:05,156 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 740
2021-12-04 17:36:05,156 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 812
2021-12-04 17:36:05,156 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 35 from broadcast at DAGScheduler.scala:1039
2021-12-04 17:36:05,156 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 771
2021-12-04 17:36:05,156 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 786
2021-12-04 17:36:05,156 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 738
2021-12-04 17:36:05,156 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 772
2021-12-04 17:36:05,156 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 783
2021-12-04 17:36:05,156 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 790
2021-12-04 17:36:05,156 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 4 missing tasks from ShuffleMapStage 50 (MapPartitionsRDD[58] at intersection at PaidPromotionAdjustParameter.scala:166) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
2021-12-04 17:36:05,156 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 50.0 with 4 tasks
2021-12-04 17:36:05,157 [dispatcher-event-loop-8] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 50.0 (TID 82, localhost, executor driver, partition 0, ANY, 7638 bytes)
2021-12-04 17:36:05,157 [dispatcher-event-loop-8] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 50.0 (TID 83, localhost, executor driver, partition 1, ANY, 7638 bytes)
2021-12-04 17:36:05,157 [dispatcher-event-loop-8] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 2.0 in stage 50.0 (TID 84, localhost, executor driver, partition 2, ANY, 7638 bytes)
2021-12-04 17:36:05,157 [dispatcher-event-loop-8] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 3.0 in stage 50.0 (TID 85, localhost, executor driver, partition 3, ANY, 7638 bytes)
2021-12-04 17:36:05,157 [Executor task launch worker for task 82] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 50.0 (TID 82)
2021-12-04 17:36:05,157 [Executor task launch worker for task 85] INFO [org.apache.spark.executor.Executor] - Running task 3.0 in stage 50.0 (TID 85)
2021-12-04 17:36:05,157 [Executor task launch worker for task 83] INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 50.0 (TID 83)
2021-12-04 17:36:05,157 [Executor task launch worker for task 84] INFO [org.apache.spark.executor.Executor] - Running task 2.0 in stage 50.0 (TID 84)
2021-12-04 17:36:05,158 [Executor task launch worker for task 84] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 4 non-empty blocks out of 4 blocks
2021-12-04 17:36:05,158 [Executor task launch worker for task 82] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 4 non-empty blocks out of 4 blocks
2021-12-04 17:36:05,158 [Executor task launch worker for task 85] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 4 non-empty blocks out of 4 blocks
2021-12-04 17:36:05,158 [Executor task launch worker for task 84] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-04 17:36:05,158 [Executor task launch worker for task 85] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-04 17:36:05,158 [Executor task launch worker for task 83] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 4 non-empty blocks out of 4 blocks
2021-12-04 17:36:05,158 [Executor task launch worker for task 82] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-04 17:36:05,158 [Executor task launch worker for task 83] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-04 17:36:05,171 [Executor task launch worker for task 85] INFO [org.apache.spark.executor.Executor] - Finished task 3.0 in stage 50.0 (TID 85). 1163 bytes result sent to driver
2021-12-04 17:36:05,172 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 3.0 in stage 50.0 (TID 85) in 15 ms on localhost (executor driver) (1/4)
2021-12-04 17:36:05,176 [Executor task launch worker for task 82] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 50.0 (TID 82). 1120 bytes result sent to driver
2021-12-04 17:36:05,177 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 50.0 (TID 82) in 20 ms on localhost (executor driver) (2/4)
2021-12-04 17:36:05,177 [Executor task launch worker for task 83] INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 50.0 (TID 83). 1120 bytes result sent to driver
2021-12-04 17:36:05,177 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 50.0 (TID 83) in 20 ms on localhost (executor driver) (3/4)
2021-12-04 17:36:05,178 [Executor task launch worker for task 84] INFO [org.apache.spark.executor.Executor] - Finished task 2.0 in stage 50.0 (TID 84). 1120 bytes result sent to driver
2021-12-04 17:36:05,179 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 2.0 in stage 50.0 (TID 84) in 22 ms on localhost (executor driver) (4/4)
2021-12-04 17:36:05,179 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 50.0, whose tasks have all completed, from pool 
2021-12-04 17:36:05,179 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ShuffleMapStage 50 (intersection at PaidPromotionAdjustParameter.scala:166) finished in 0.026 s
2021-12-04 17:36:05,179 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - looking for newly runnable stages
2021-12-04 17:36:05,179 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - running: Set(ShuffleMapStage 48)
2021-12-04 17:36:05,179 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - waiting: Set(ResultStage 51)
2021-12-04 17:36:05,179 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - failed: Set()
2021-12-04 17:36:05,179 [Executor task launch worker for task 80] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 48.0 (TID 80). 1163 bytes result sent to driver
2021-12-04 17:36:05,180 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 48.0 (TID 80) in 27 ms on localhost (executor driver) (1/2)
2021-12-04 17:36:05,181 [Executor task launch worker for task 81] INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 48.0 (TID 81). 1206 bytes result sent to driver
2021-12-04 17:36:05,181 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 48.0 (TID 81) in 28 ms on localhost (executor driver) (2/2)
2021-12-04 17:36:05,181 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 48.0, whose tasks have all completed, from pool 
2021-12-04 17:36:05,181 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ShuffleMapStage 48 (intersection at PaidPromotionAdjustParameter.scala:166) finished in 0.034 s
2021-12-04 17:36:05,181 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - looking for newly runnable stages
2021-12-04 17:36:05,181 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - running: Set()
2021-12-04 17:36:05,181 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - waiting: Set(ResultStage 51)
2021-12-04 17:36:05,181 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - failed: Set()
2021-12-04 17:36:05,181 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 51 (MapPartitionsRDD[63] at intersection at PaidPromotionAdjustParameter.scala:166), which has no missing parents
2021-12-04 17:36:05,182 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_36 stored as values in memory (estimated size 3.6 KB, free 1990.5 MB)
2021-12-04 17:36:05,184 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_36_piece0 stored as bytes in memory (estimated size 2.1 KB, free 1990.5 MB)
2021-12-04 17:36:05,184 [dispatcher-event-loop-0] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_36_piece0 in memory on qb:60460 (size: 2.1 KB, free: 1990.8 MB)
2021-12-04 17:36:05,184 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 36 from broadcast at DAGScheduler.scala:1039
2021-12-04 17:36:05,185 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 4 missing tasks from ResultStage 51 (MapPartitionsRDD[63] at intersection at PaidPromotionAdjustParameter.scala:166) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
2021-12-04 17:36:05,185 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 51.0 with 4 tasks
2021-12-04 17:36:05,185 [dispatcher-event-loop-8] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 51.0 (TID 86, localhost, executor driver, partition 0, PROCESS_LOCAL, 7712 bytes)
2021-12-04 17:36:05,185 [dispatcher-event-loop-8] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 51.0 (TID 87, localhost, executor driver, partition 1, PROCESS_LOCAL, 7712 bytes)
2021-12-04 17:36:05,185 [dispatcher-event-loop-8] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 2.0 in stage 51.0 (TID 88, localhost, executor driver, partition 2, PROCESS_LOCAL, 7712 bytes)
2021-12-04 17:36:05,185 [dispatcher-event-loop-8] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 3.0 in stage 51.0 (TID 89, localhost, executor driver, partition 3, PROCESS_LOCAL, 7712 bytes)
2021-12-04 17:36:05,185 [Executor task launch worker for task 86] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 51.0 (TID 86)
2021-12-04 17:36:05,185 [Executor task launch worker for task 89] INFO [org.apache.spark.executor.Executor] - Running task 3.0 in stage 51.0 (TID 89)
2021-12-04 17:36:05,185 [Executor task launch worker for task 88] INFO [org.apache.spark.executor.Executor] - Running task 2.0 in stage 51.0 (TID 88)
2021-12-04 17:36:05,185 [Executor task launch worker for task 87] INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 51.0 (TID 87)
2021-12-04 17:36:05,186 [Executor task launch worker for task 86] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 4 blocks
2021-12-04 17:36:05,186 [Executor task launch worker for task 89] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 4 blocks
2021-12-04 17:36:05,186 [Executor task launch worker for task 86] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-04 17:36:05,186 [Executor task launch worker for task 89] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-04 17:36:05,186 [Executor task launch worker for task 87] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 4 blocks
2021-12-04 17:36:05,186 [Executor task launch worker for task 88] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 4 blocks
2021-12-04 17:36:05,186 [Executor task launch worker for task 87] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-04 17:36:05,186 [Executor task launch worker for task 88] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-04 17:36:05,190 [Executor task launch worker for task 87] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2021-12-04 17:36:05,190 [Executor task launch worker for task 88] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2021-12-04 17:36:05,190 [Executor task launch worker for task 87] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-04 17:36:05,190 [Executor task launch worker for task 88] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-04 17:36:05,190 [Executor task launch worker for task 86] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2021-12-04 17:36:05,190 [Executor task launch worker for task 86] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-04 17:36:05,190 [Executor task launch worker for task 89] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2021-12-04 17:36:05,190 [Executor task launch worker for task 89] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-04 17:36:05,197 [Executor task launch worker for task 89] INFO [org.apache.spark.executor.Executor] - Finished task 3.0 in stage 51.0 (TID 89). 1010 bytes result sent to driver
2021-12-04 17:36:05,197 [Executor task launch worker for task 88] INFO [org.apache.spark.executor.Executor] - Finished task 2.0 in stage 51.0 (TID 88). 1010 bytes result sent to driver
2021-12-04 17:36:05,197 [Executor task launch worker for task 87] INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 51.0 (TID 87). 1010 bytes result sent to driver
2021-12-04 17:36:05,197 [Executor task launch worker for task 86] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 51.0 (TID 86). 1010 bytes result sent to driver
2021-12-04 17:36:05,198 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 3.0 in stage 51.0 (TID 89) in 13 ms on localhost (executor driver) (1/4)
2021-12-04 17:36:05,198 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 2.0 in stage 51.0 (TID 88) in 13 ms on localhost (executor driver) (2/4)
2021-12-04 17:36:05,198 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 51.0 (TID 87) in 13 ms on localhost (executor driver) (3/4)
2021-12-04 17:36:05,198 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 51.0 (TID 86) in 13 ms on localhost (executor driver) (4/4)
2021-12-04 17:36:05,198 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 51.0, whose tasks have all completed, from pool 
2021-12-04 17:36:05,198 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 51 (count at PaidPromotionAdjustParameter.scala:174) finished in 0.016 s
2021-12-04 17:36:05,198 [main] INFO [org.apache.spark.scheduler.DAGScheduler] - Job 19 finished: count at PaidPromotionAdjustParameter.scala:174, took 0.052282 s
2021-12-04 17:36:05,199 [main] INFO [PaidPromotion$] - 最终共 同 节目数 = 84
2021-12-04 17:36:05,215 [main] INFO [org.apache.hadoop.conf.Configuration.deprecation] - mapred.output.dir is deprecated. Instead, use mapreduce.output.fileoutputformat.outputdir
2021-12-04 17:36:05,217 [main] INFO [org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter] - File Output Committer Algorithm version is 1
2021-12-04 17:36:05,263 [main] INFO [org.apache.spark.SparkContext] - Starting job: runJob at SparkHadoopWriter.scala:78
2021-12-04 17:36:05,264 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 20 (runJob at SparkHadoopWriter.scala:78) with 1 output partitions
2021-12-04 17:36:05,264 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 52 (runJob at SparkHadoopWriter.scala:78)
2021-12-04 17:36:05,264 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List()
2021-12-04 17:36:05,264 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2021-12-04 17:36:05,264 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 52 (MapPartitionsRDD[66] at saveAsTextFile at PaidPromotionAdjustParameter.scala:179), which has no missing parents
2021-12-04 17:36:05,274 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_37 stored as values in memory (estimated size 252.3 KB, free 1990.2 MB)
2021-12-04 17:36:05,276 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_37_piece0 stored as bytes in memory (estimated size 90.6 KB, free 1990.1 MB)
2021-12-04 17:36:05,276 [dispatcher-event-loop-0] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_37_piece0 in memory on qb:60460 (size: 90.6 KB, free: 1990.7 MB)
2021-12-04 17:36:05,277 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 37 from broadcast at DAGScheduler.scala:1039
2021-12-04 17:36:05,277 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 52 (MapPartitionsRDD[66] at saveAsTextFile at PaidPromotionAdjustParameter.scala:179) (first 15 tasks are for partitions Vector(0))
2021-12-04 17:36:05,277 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 52.0 with 1 tasks
2021-12-04 17:36:05,279 [dispatcher-event-loop-8] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 52.0 (TID 90, localhost, executor driver, partition 0, ANY, 8509 bytes)
2021-12-04 17:36:05,279 [Executor task launch worker for task 90] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 52.0 (TID 90)
2021-12-04 17:36:05,293 [Executor task launch worker for task 90] INFO [org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter] - File Output Committer Algorithm version is 1
2021-12-04 17:36:05,313 [Executor task launch worker for task 90] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/order_data.bcp:0+3442194
2021-12-04 17:36:05,888 [Executor task launch worker for task 90] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/order_data.bcp:3442194+3442195
2021-12-04 17:36:06,464 [Executor task launch worker for task 90] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/order_data.bcp:0+3442194
2021-12-04 17:36:06,961 [Executor task launch worker for task 90] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/order_data.bcp:3442194+3442195
2021-12-04 17:36:07,163 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 859
2021-12-04 17:36:07,163 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 895
2021-12-04 17:36:07,164 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 830
2021-12-04 17:36:07,164 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 867
2021-12-04 17:36:07,164 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 898
2021-12-04 17:36:07,164 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 845
2021-12-04 17:36:07,164 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 852
2021-12-04 17:36:07,164 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 882
2021-12-04 17:36:07,164 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 860
2021-12-04 17:36:07,164 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 871
2021-12-04 17:36:07,164 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 899
2021-12-04 17:36:07,164 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 833
2021-12-04 17:36:07,164 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 876
2021-12-04 17:36:07,164 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 879
2021-12-04 17:36:07,164 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 883
2021-12-04 17:36:07,164 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 841
2021-12-04 17:36:07,164 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 847
2021-12-04 17:36:07,164 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 849
2021-12-04 17:36:07,164 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 873
2021-12-04 17:36:07,165 [dispatcher-event-loop-2] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_34_piece0 on qb:60460 in memory (size: 2.3 KB, free: 1990.7 MB)
2021-12-04 17:36:07,165 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 864
2021-12-04 17:36:07,165 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 855
2021-12-04 17:36:07,165 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 887
2021-12-04 17:36:07,165 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 839
2021-12-04 17:36:07,165 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 857
2021-12-04 17:36:07,165 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 858
2021-12-04 17:36:07,165 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 834
2021-12-04 17:36:07,165 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 835
2021-12-04 17:36:07,165 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 869
2021-12-04 17:36:07,165 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 881
2021-12-04 17:36:07,165 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 848
2021-12-04 17:36:07,165 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 865
2021-12-04 17:36:07,165 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 862
2021-12-04 17:36:07,165 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 884
2021-12-04 17:36:07,165 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 897
2021-12-04 17:36:07,166 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 838
2021-12-04 17:36:07,166 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 832
2021-12-04 17:36:07,166 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 844
2021-12-04 17:36:07,166 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 893
2021-12-04 17:36:07,166 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 870
2021-12-04 17:36:07,166 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 863
2021-12-04 17:36:07,166 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 827
2021-12-04 17:36:07,166 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 866
2021-12-04 17:36:07,166 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 829
2021-12-04 17:36:07,166 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 825
2021-12-04 17:36:07,166 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 889
2021-12-04 17:36:07,166 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 840
2021-12-04 17:36:07,166 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 880
2021-12-04 17:36:07,166 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 875
2021-12-04 17:36:07,166 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 878
2021-12-04 17:36:07,166 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 846
2021-12-04 17:36:07,166 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 836
2021-12-04 17:36:07,166 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 854
2021-12-04 17:36:07,166 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 896
2021-12-04 17:36:07,166 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 892
2021-12-04 17:36:07,166 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 886
2021-12-04 17:36:07,166 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 877
2021-12-04 17:36:07,166 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 837
2021-12-04 17:36:07,166 [dispatcher-event-loop-3] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_35_piece0 on qb:60460 in memory (size: 2.3 KB, free: 1990.7 MB)
2021-12-04 17:36:07,166 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 890
2021-12-04 17:36:07,166 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 888
2021-12-04 17:36:07,166 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 861
2021-12-04 17:36:07,166 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 894
2021-12-04 17:36:07,166 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 843
2021-12-04 17:36:07,166 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 828
2021-12-04 17:36:07,166 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 826
2021-12-04 17:36:07,166 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 850
2021-12-04 17:36:07,167 [dispatcher-event-loop-4] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_36_piece0 on qb:60460 in memory (size: 2.1 KB, free: 1990.7 MB)
2021-12-04 17:36:07,167 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 885
2021-12-04 17:36:07,167 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 868
2021-12-04 17:36:07,167 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 891
2021-12-04 17:36:07,167 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 874
2021-12-04 17:36:07,167 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 831
2021-12-04 17:36:07,167 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 872
2021-12-04 17:36:07,167 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 853
2021-12-04 17:36:07,167 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 842
2021-12-04 17:36:07,167 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 856
2021-12-04 17:36:07,167 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 851
2021-12-04 17:36:07,406 [Executor task launch worker for task 90] INFO [org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter] - Saved output of task 'attempt_20211204173605_0066_m_000000_0' to hdfs://hdp1:8020/sk/chongqing/handle_data/set-train-device-production-data/_temporary/0/task_20211204173605_0066_m_000000
2021-12-04 17:36:07,407 [Executor task launch worker for task 90] INFO [org.apache.spark.mapred.SparkHadoopMapRedUtil] - attempt_20211204173605_0066_m_000000_0: Committed
2021-12-04 17:36:07,408 [Executor task launch worker for task 90] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 52.0 (TID 90). 955 bytes result sent to driver
2021-12-04 17:36:07,411 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 52.0 (TID 90) in 2134 ms on localhost (executor driver) (1/1)
2021-12-04 17:36:07,411 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 52.0, whose tasks have all completed, from pool 
2021-12-04 17:36:07,411 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 52 (runJob at SparkHadoopWriter.scala:78) finished in 2.147 s
2021-12-04 17:36:07,412 [main] INFO [org.apache.spark.scheduler.DAGScheduler] - Job 20 finished: runJob at SparkHadoopWriter.scala:78, took 2.148080 s
2021-12-04 17:36:07,491 [main] INFO [org.apache.spark.internal.io.SparkHadoopWriter] - Job job_20211204173605_0066 committed.
2021-12-04 17:36:07,504 [main] INFO [org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter] - File Output Committer Algorithm version is 1
2021-12-04 17:36:07,521 [main] INFO [org.apache.spark.SparkContext] - Starting job: runJob at SparkHadoopWriter.scala:78
2021-12-04 17:36:07,521 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 21 (runJob at SparkHadoopWriter.scala:78) with 1 output partitions
2021-12-04 17:36:07,521 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 53 (runJob at SparkHadoopWriter.scala:78)
2021-12-04 17:36:07,521 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List()
2021-12-04 17:36:07,521 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2021-12-04 17:36:07,521 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 53 (MapPartitionsRDD[69] at saveAsTextFile at PaidPromotionAdjustParameter.scala:182), which has no missing parents
2021-12-04 17:36:07,530 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_38 stored as values in memory (estimated size 251.7 KB, free 1989.9 MB)
2021-12-04 17:36:07,532 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_38_piece0 stored as bytes in memory (estimated size 90.2 KB, free 1989.8 MB)
2021-12-04 17:36:07,532 [dispatcher-event-loop-7] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_38_piece0 in memory on qb:60460 (size: 90.2 KB, free: 1990.6 MB)
2021-12-04 17:36:07,532 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 38 from broadcast at DAGScheduler.scala:1039
2021-12-04 17:36:07,533 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 53 (MapPartitionsRDD[69] at saveAsTextFile at PaidPromotionAdjustParameter.scala:182) (first 15 tasks are for partitions Vector(0))
2021-12-04 17:36:07,533 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 53.0 with 1 tasks
2021-12-04 17:36:07,533 [dispatcher-event-loop-5] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 53.0 (TID 91, localhost, executor driver, partition 0, ANY, 8337 bytes)
2021-12-04 17:36:07,533 [Executor task launch worker for task 91] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 53.0 (TID 91)
2021-12-04 17:36:07,538 [Executor task launch worker for task 91] INFO [org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter] - File Output Committer Algorithm version is 1
2021-12-04 17:36:07,546 [Executor task launch worker for task 91] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/order_data.bcp:0+3442194
2021-12-04 17:36:08,277 [Executor task launch worker for task 91] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/order_data.bcp:3442194+3442195
2021-12-04 17:36:09,056 [Executor task launch worker for task 91] INFO [org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter] - Saved output of task 'attempt_20211204173607_0069_m_000000_0' to hdfs://hdp1:8020/sk/chongqing/handle_data/set-validation-device-production-data/_temporary/0/task_20211204173607_0069_m_000000
2021-12-04 17:36:09,056 [Executor task launch worker for task 91] INFO [org.apache.spark.mapred.SparkHadoopMapRedUtil] - attempt_20211204173607_0069_m_000000_0: Committed
2021-12-04 17:36:09,058 [Executor task launch worker for task 91] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 53.0 (TID 91). 955 bytes result sent to driver
2021-12-04 17:36:09,060 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 53.0 (TID 91) in 1527 ms on localhost (executor driver) (1/1)
2021-12-04 17:36:09,060 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 53.0, whose tasks have all completed, from pool 
2021-12-04 17:36:09,060 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 53 (runJob at SparkHadoopWriter.scala:78) finished in 1.538 s
2021-12-04 17:36:09,060 [main] INFO [org.apache.spark.scheduler.DAGScheduler] - Job 21 finished: runJob at SparkHadoopWriter.scala:78, took 1.538492 s
2021-12-04 17:36:09,107 [main] INFO [org.apache.spark.internal.io.SparkHadoopWriter] - Job job_20211204173607_0069 committed.
2021-12-04 17:36:09,121 [main] INFO [PaidPromotion$] - 验证集用户实际观看列表-----------------------------------
2021-12-04 17:36:09,122 [main] INFO [org.apache.spark.SparkContext] - Starting job: count at PaidPromotionAdjustParameter.scala:192
2021-12-04 17:36:09,123 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 33 (filter at PaidPromotionAdjustParameter.scala:150)
2021-12-04 17:36:09,123 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 22 (count at PaidPromotionAdjustParameter.scala:192) with 2 output partitions
2021-12-04 17:36:09,123 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 55 (count at PaidPromotionAdjustParameter.scala:192)
2021-12-04 17:36:09,123 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 54)
2021-12-04 17:36:09,123 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List(ShuffleMapStage 54)
2021-12-04 17:36:09,123 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ShuffleMapStage 54 (MapPartitionsRDD[33] at filter at PaidPromotionAdjustParameter.scala:150), which has no missing parents
2021-12-04 17:36:09,125 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_39 stored as values in memory (estimated size 177.1 KB, free 1989.6 MB)
2021-12-04 17:36:09,127 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_39_piece0 stored as bytes in memory (estimated size 62.5 KB, free 1989.6 MB)
2021-12-04 17:36:09,127 [dispatcher-event-loop-10] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_39_piece0 in memory on qb:60460 (size: 62.5 KB, free: 1990.5 MB)
2021-12-04 17:36:09,127 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 39 from broadcast at DAGScheduler.scala:1039
2021-12-04 17:36:09,128 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from ShuffleMapStage 54 (MapPartitionsRDD[33] at filter at PaidPromotionAdjustParameter.scala:150) (first 15 tasks are for partitions Vector(0, 1))
2021-12-04 17:36:09,128 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 54.0 with 2 tasks
2021-12-04 17:36:09,128 [dispatcher-event-loop-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 54.0 (TID 92, localhost, executor driver, partition 0, ANY, 7885 bytes)
2021-12-04 17:36:09,128 [dispatcher-event-loop-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 54.0 (TID 93, localhost, executor driver, partition 1, ANY, 7885 bytes)
2021-12-04 17:36:09,128 [Executor task launch worker for task 92] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 54.0 (TID 92)
2021-12-04 17:36:09,128 [Executor task launch worker for task 93] INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 54.0 (TID 93)
2021-12-04 17:36:09,131 [Executor task launch worker for task 93] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/order_data.bcp:3442194+3442195
2021-12-04 17:36:09,131 [Executor task launch worker for task 92] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/order_data.bcp:0+3442194
2021-12-04 17:36:09,895 [Executor task launch worker for task 93] INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 54.0 (TID 93). 860 bytes result sent to driver
2021-12-04 17:36:09,895 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 54.0 (TID 93) in 767 ms on localhost (executor driver) (1/2)
2021-12-04 17:36:10,056 [Executor task launch worker for task 92] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 54.0 (TID 92). 860 bytes result sent to driver
2021-12-04 17:36:10,057 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 54.0 (TID 92) in 929 ms on localhost (executor driver) (2/2)
2021-12-04 17:36:10,057 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 54.0, whose tasks have all completed, from pool 
2021-12-04 17:36:10,057 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ShuffleMapStage 54 (filter at PaidPromotionAdjustParameter.scala:150) finished in 0.933 s
2021-12-04 17:36:10,057 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - looking for newly runnable stages
2021-12-04 17:36:10,057 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - running: Set()
2021-12-04 17:36:10,057 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - waiting: Set(ResultStage 55)
2021-12-04 17:36:10,057 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - failed: Set()
2021-12-04 17:36:10,057 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 55 (MapPartitionsRDD[71] at map at PaidPromotionAdjustParameter.scala:186), which has no missing parents
2021-12-04 17:36:10,059 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_40 stored as values in memory (estimated size 178.0 KB, free 1989.4 MB)
2021-12-04 17:36:10,061 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_40_piece0 stored as bytes in memory (estimated size 62.9 KB, free 1989.3 MB)
2021-12-04 17:36:10,061 [dispatcher-event-loop-8] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_40_piece0 in memory on qb:60460 (size: 62.9 KB, free: 1990.5 MB)
2021-12-04 17:36:10,061 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 40 from broadcast at DAGScheduler.scala:1039
2021-12-04 17:36:10,062 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from ResultStage 55 (MapPartitionsRDD[71] at map at PaidPromotionAdjustParameter.scala:186) (first 15 tasks are for partitions Vector(0, 1))
2021-12-04 17:36:10,062 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 55.0 with 2 tasks
2021-12-04 17:36:10,062 [dispatcher-event-loop-7] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 55.0 (TID 94, localhost, executor driver, partition 0, ANY, 7649 bytes)
2021-12-04 17:36:10,062 [dispatcher-event-loop-7] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 55.0 (TID 95, localhost, executor driver, partition 1, ANY, 7649 bytes)
2021-12-04 17:36:10,062 [Executor task launch worker for task 95] INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 55.0 (TID 95)
2021-12-04 17:36:10,062 [Executor task launch worker for task 94] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 55.0 (TID 94)
2021-12-04 17:36:10,064 [Executor task launch worker for task 94] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 2 non-empty blocks out of 2 blocks
2021-12-04 17:36:10,064 [Executor task launch worker for task 95] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 2 non-empty blocks out of 2 blocks
2021-12-04 17:36:10,064 [Executor task launch worker for task 94] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-04 17:36:10,064 [Executor task launch worker for task 95] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-04 17:36:10,097 [Executor task launch worker for task 95] INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 55.0 (TID 95). 1054 bytes result sent to driver
2021-12-04 17:36:10,097 [Executor task launch worker for task 94] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 55.0 (TID 94). 1054 bytes result sent to driver
2021-12-04 17:36:10,097 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 55.0 (TID 95) in 35 ms on localhost (executor driver) (1/2)
2021-12-04 17:36:10,097 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 55.0 (TID 94) in 35 ms on localhost (executor driver) (2/2)
2021-12-04 17:36:10,097 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 55.0, whose tasks have all completed, from pool 
2021-12-04 17:36:10,098 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 55 (count at PaidPromotionAdjustParameter.scala:192) finished in 0.041 s
2021-12-04 17:36:10,098 [main] INFO [org.apache.spark.scheduler.DAGScheduler] - Job 22 finished: count at PaidPromotionAdjustParameter.scala:192, took 0.974587 s
2021-12-04 17:36:10,098 [main] INFO [PaidPromotion$] - 验证集用户列表数量：4910
2021-12-04 17:36:10,106 [main] INFO [org.apache.spark.SparkContext] - Starting job: take at PaidPromotionAdjustParameter.scala:193
2021-12-04 17:36:10,107 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 23 (take at PaidPromotionAdjustParameter.scala:193) with 1 output partitions
2021-12-04 17:36:10,107 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 57 (take at PaidPromotionAdjustParameter.scala:193)
2021-12-04 17:36:10,107 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 56)
2021-12-04 17:36:10,107 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2021-12-04 17:36:10,107 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 57 (MapPartitionsRDD[71] at map at PaidPromotionAdjustParameter.scala:186), which has no missing parents
2021-12-04 17:36:10,108 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_41 stored as values in memory (estimated size 178.1 KB, free 1989.2 MB)
2021-12-04 17:36:10,110 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_41_piece0 stored as bytes in memory (estimated size 63.0 KB, free 1989.1 MB)
2021-12-04 17:36:10,110 [dispatcher-event-loop-10] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_41_piece0 in memory on qb:60460 (size: 63.0 KB, free: 1990.4 MB)
2021-12-04 17:36:10,110 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 41 from broadcast at DAGScheduler.scala:1039
2021-12-04 17:36:10,110 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 57 (MapPartitionsRDD[71] at map at PaidPromotionAdjustParameter.scala:186) (first 15 tasks are for partitions Vector(0))
2021-12-04 17:36:10,110 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 57.0 with 1 tasks
2021-12-04 17:36:10,111 [dispatcher-event-loop-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 57.0 (TID 96, localhost, executor driver, partition 0, ANY, 7649 bytes)
2021-12-04 17:36:10,111 [Executor task launch worker for task 96] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 57.0 (TID 96)
2021-12-04 17:36:10,113 [Executor task launch worker for task 96] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 2 non-empty blocks out of 2 blocks
2021-12-04 17:36:10,113 [Executor task launch worker for task 96] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-04 17:36:10,128 [Executor task launch worker for task 96] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 57.0 (TID 96). 2622 bytes result sent to driver
2021-12-04 17:36:10,129 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 57.0 (TID 96) in 18 ms on localhost (executor driver) (1/1)
2021-12-04 17:36:10,129 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 57.0, whose tasks have all completed, from pool 
2021-12-04 17:36:10,129 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 57 (take at PaidPromotionAdjustParameter.scala:193) finished in 0.022 s
2021-12-04 17:36:10,129 [main] INFO [org.apache.spark.scheduler.DAGScheduler] - Job 23 finished: take at PaidPromotionAdjustParameter.scala:193, took 0.022533 s
2021-12-04 17:36:10,138 [main] INFO [PaidPromotion$] - 训练集用户实际观看列表-----------------------------------
2021-12-04 17:36:10,139 [main] INFO [org.apache.spark.SparkContext] - Starting job: count at PaidPromotionAdjustParameter.scala:203
2021-12-04 17:36:10,139 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 35 (union at PaidPromotionAdjustParameter.scala:154)
2021-12-04 17:36:10,139 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 24 (count at PaidPromotionAdjustParameter.scala:203) with 4 output partitions
2021-12-04 17:36:10,139 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 59 (count at PaidPromotionAdjustParameter.scala:203)
2021-12-04 17:36:10,139 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 58)
2021-12-04 17:36:10,139 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List(ShuffleMapStage 58)
2021-12-04 17:36:10,139 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ShuffleMapStage 58 (UnionRDD[35] at union at PaidPromotionAdjustParameter.scala:154), which has no missing parents
2021-12-04 17:36:10,141 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_42 stored as values in memory (estimated size 177.6 KB, free 1988.9 MB)
2021-12-04 17:36:10,142 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_42_piece0 stored as bytes in memory (estimated size 62.9 KB, free 1988.9 MB)
2021-12-04 17:36:10,142 [dispatcher-event-loop-4] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_42_piece0 in memory on qb:60460 (size: 62.9 KB, free: 1990.4 MB)
2021-12-04 17:36:10,142 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 42 from broadcast at DAGScheduler.scala:1039
2021-12-04 17:36:10,143 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 4 missing tasks from ShuffleMapStage 58 (UnionRDD[35] at union at PaidPromotionAdjustParameter.scala:154) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
2021-12-04 17:36:10,143 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 58.0 with 4 tasks
2021-12-04 17:36:10,143 [dispatcher-event-loop-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 58.0 (TID 97, localhost, executor driver, partition 0, ANY, 7994 bytes)
2021-12-04 17:36:10,143 [dispatcher-event-loop-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 58.0 (TID 98, localhost, executor driver, partition 1, ANY, 7994 bytes)
2021-12-04 17:36:10,143 [dispatcher-event-loop-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 2.0 in stage 58.0 (TID 99, localhost, executor driver, partition 2, ANY, 7994 bytes)
2021-12-04 17:36:10,144 [dispatcher-event-loop-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 3.0 in stage 58.0 (TID 100, localhost, executor driver, partition 3, ANY, 7994 bytes)
2021-12-04 17:36:10,144 [Executor task launch worker for task 98] INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 58.0 (TID 98)
2021-12-04 17:36:10,144 [Executor task launch worker for task 99] INFO [org.apache.spark.executor.Executor] - Running task 2.0 in stage 58.0 (TID 99)
2021-12-04 17:36:10,144 [Executor task launch worker for task 100] INFO [org.apache.spark.executor.Executor] - Running task 3.0 in stage 58.0 (TID 100)
2021-12-04 17:36:10,144 [Executor task launch worker for task 97] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 58.0 (TID 97)
2021-12-04 17:36:10,153 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 972
2021-12-04 17:36:10,153 [Executor task launch worker for task 97] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/order_data.bcp:0+3442194
2021-12-04 17:36:10,153 [Executor task launch worker for task 99] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/order_data.bcp:0+3442194
2021-12-04 17:36:10,153 [Executor task launch worker for task 98] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/order_data.bcp:3442194+3442195
2021-12-04 17:36:10,154 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 926
2021-12-04 17:36:10,154 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1010
2021-12-04 17:36:10,154 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1012
2021-12-04 17:36:10,154 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 959
2021-12-04 17:36:10,154 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1018
2021-12-04 17:36:10,154 [Executor task launch worker for task 100] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/order_data.bcp:3442194+3442195
2021-12-04 17:36:10,154 [dispatcher-event-loop-10] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_38_piece0 on qb:60460 in memory (size: 90.2 KB, free: 1990.4 MB)
2021-12-04 17:36:10,154 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1019
2021-12-04 17:36:10,154 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 901
2021-12-04 17:36:10,154 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 964
2021-12-04 17:36:10,154 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 951
2021-12-04 17:36:10,154 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 998
2021-12-04 17:36:10,154 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 910
2021-12-04 17:36:10,154 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 942
2021-12-04 17:36:10,154 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 991
2021-12-04 17:36:10,155 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 911
2021-12-04 17:36:10,155 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 963
2021-12-04 17:36:10,155 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1017
2021-12-04 17:36:10,155 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 935
2021-12-04 17:36:10,155 [dispatcher-event-loop-6] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_37_piece0 on qb:60460 in memory (size: 90.6 KB, free: 1990.5 MB)
2021-12-04 17:36:10,155 [dispatcher-event-loop-8] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_40_piece0 on qb:60460 in memory (size: 62.9 KB, free: 1990.6 MB)
2021-12-04 17:36:10,155 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 903
2021-12-04 17:36:10,155 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 929
2021-12-04 17:36:10,155 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 960
2021-12-04 17:36:10,155 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 979
2021-12-04 17:36:10,156 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1013
2021-12-04 17:36:10,156 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 983
2021-12-04 17:36:10,156 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1023
2021-12-04 17:36:10,156 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 949
2021-12-04 17:36:10,156 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1009
2021-12-04 17:36:10,156 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 974
2021-12-04 17:36:10,156 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 955
2021-12-04 17:36:10,156 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 984
2021-12-04 17:36:10,156 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 931
2021-12-04 17:36:10,156 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 976
2021-12-04 17:36:10,156 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 938
2021-12-04 17:36:10,156 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 906
2021-12-04 17:36:10,156 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 995
2021-12-04 17:36:10,156 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 946
2021-12-04 17:36:10,156 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 919
2021-12-04 17:36:10,156 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 909
2021-12-04 17:36:10,156 [dispatcher-event-loop-5] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_39_piece0 on qb:60460 in memory (size: 62.5 KB, free: 1990.7 MB)
2021-12-04 17:36:10,156 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 930
2021-12-04 17:36:10,156 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 978
2021-12-04 17:36:10,156 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 981
2021-12-04 17:36:10,156 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1021
2021-12-04 17:36:10,156 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 962
2021-12-04 17:36:10,156 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 908
2021-12-04 17:36:10,156 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 925
2021-12-04 17:36:10,156 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 969
2021-12-04 17:36:10,157 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 992
2021-12-04 17:36:10,157 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 961
2021-12-04 17:36:10,157 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 920
2021-12-04 17:36:10,157 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 947
2021-12-04 17:36:10,157 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 956
2021-12-04 17:36:10,157 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 922
2021-12-04 17:36:10,157 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1006
2021-12-04 17:36:10,157 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 980
2021-12-04 17:36:10,157 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 934
2021-12-04 17:36:10,157 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1000
2021-12-04 17:36:10,157 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 970
2021-12-04 17:36:10,157 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 905
2021-12-04 17:36:10,157 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 988
2021-12-04 17:36:10,157 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1007
2021-12-04 17:36:10,157 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1016
2021-12-04 17:36:10,157 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1020
2021-12-04 17:36:10,157 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 971
2021-12-04 17:36:10,157 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1024
2021-12-04 17:36:10,157 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 939
2021-12-04 17:36:10,157 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 987
2021-12-04 17:36:10,157 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 977
2021-12-04 17:36:10,157 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 950
2021-12-04 17:36:10,157 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 986
2021-12-04 17:36:10,157 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 904
2021-12-04 17:36:10,157 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 968
2021-12-04 17:36:10,157 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1005
2021-12-04 17:36:10,157 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 921
2021-12-04 17:36:10,157 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 953
2021-12-04 17:36:10,157 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 902
2021-12-04 17:36:10,157 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 937
2021-12-04 17:36:10,157 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 900
2021-12-04 17:36:10,157 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 914
2021-12-04 17:36:10,157 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 916
2021-12-04 17:36:10,157 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 913
2021-12-04 17:36:10,157 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1008
2021-12-04 17:36:10,157 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1004
2021-12-04 17:36:10,157 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 975
2021-12-04 17:36:10,157 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1015
2021-12-04 17:36:10,157 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 907
2021-12-04 17:36:10,157 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 973
2021-12-04 17:36:10,157 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 993
2021-12-04 17:36:10,157 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1022
2021-12-04 17:36:10,157 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1002
2021-12-04 17:36:10,157 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 999
2021-12-04 17:36:10,157 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 985
2021-12-04 17:36:10,157 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 915
2021-12-04 17:36:10,157 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1001
2021-12-04 17:36:10,157 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 957
2021-12-04 17:36:10,157 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 928
2021-12-04 17:36:10,157 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 952
2021-12-04 17:36:10,157 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 945
2021-12-04 17:36:10,157 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 966
2021-12-04 17:36:10,157 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 997
2021-12-04 17:36:10,157 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 936
2021-12-04 17:36:10,157 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 943
2021-12-04 17:36:10,157 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 996
2021-12-04 17:36:10,157 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 917
2021-12-04 17:36:10,157 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 924
2021-12-04 17:36:10,157 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 948
2021-12-04 17:36:10,157 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 927
2021-12-04 17:36:10,157 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 933
2021-12-04 17:36:10,157 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 958
2021-12-04 17:36:10,158 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1014
2021-12-04 17:36:10,158 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 912
2021-12-04 17:36:10,158 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 967
2021-12-04 17:36:10,158 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 990
2021-12-04 17:36:10,158 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1011
2021-12-04 17:36:10,158 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 965
2021-12-04 17:36:10,158 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 940
2021-12-04 17:36:10,158 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 923
2021-12-04 17:36:10,158 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 954
2021-12-04 17:36:10,158 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 982
2021-12-04 17:36:10,158 [dispatcher-event-loop-10] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_41_piece0 on qb:60460 in memory (size: 63.0 KB, free: 1990.7 MB)
2021-12-04 17:36:10,159 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 989
2021-12-04 17:36:10,159 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 944
2021-12-04 17:36:10,159 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1003
2021-12-04 17:36:10,159 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 941
2021-12-04 17:36:10,159 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 932
2021-12-04 17:36:10,159 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 918
2021-12-04 17:36:10,159 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 994
2021-12-04 17:36:10,688 [Executor task launch worker for task 97] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 58.0 (TID 97). 905 bytes result sent to driver
2021-12-04 17:36:10,688 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 58.0 (TID 97) in 545 ms on localhost (executor driver) (1/4)
2021-12-04 17:36:11,388 [Executor task launch worker for task 98] INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 58.0 (TID 98). 905 bytes result sent to driver
2021-12-04 17:36:11,388 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 58.0 (TID 98) in 1245 ms on localhost (executor driver) (2/4)
2021-12-04 17:36:11,430 [Executor task launch worker for task 99] INFO [org.apache.spark.executor.Executor] - Finished task 2.0 in stage 58.0 (TID 99). 905 bytes result sent to driver
2021-12-04 17:36:11,430 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 2.0 in stage 58.0 (TID 99) in 1287 ms on localhost (executor driver) (3/4)
2021-12-04 17:36:11,481 [Executor task launch worker for task 100] INFO [org.apache.spark.executor.Executor] - Finished task 3.0 in stage 58.0 (TID 100). 905 bytes result sent to driver
2021-12-04 17:36:11,481 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 3.0 in stage 58.0 (TID 100) in 1338 ms on localhost (executor driver) (4/4)
2021-12-04 17:36:11,481 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 58.0, whose tasks have all completed, from pool 
2021-12-04 17:36:11,481 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ShuffleMapStage 58 (union at PaidPromotionAdjustParameter.scala:154) finished in 1.342 s
2021-12-04 17:36:11,481 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - looking for newly runnable stages
2021-12-04 17:36:11,482 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - running: Set()
2021-12-04 17:36:11,482 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - waiting: Set(ResultStage 59)
2021-12-04 17:36:11,482 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - failed: Set()
2021-12-04 17:36:11,482 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 59 (MapPartitionsRDD[73] at map at PaidPromotionAdjustParameter.scala:197), which has no missing parents
2021-12-04 17:36:11,483 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_43 stored as values in memory (estimated size 178.5 KB, free 1990.1 MB)
2021-12-04 17:36:11,484 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_43_piece0 stored as bytes in memory (estimated size 63.3 KB, free 1990.0 MB)
2021-12-04 17:36:11,485 [dispatcher-event-loop-4] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_43_piece0 in memory on qb:60460 (size: 63.3 KB, free: 1990.7 MB)
2021-12-04 17:36:11,485 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 43 from broadcast at DAGScheduler.scala:1039
2021-12-04 17:36:11,485 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 4 missing tasks from ResultStage 59 (MapPartitionsRDD[73] at map at PaidPromotionAdjustParameter.scala:197) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
2021-12-04 17:36:11,485 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 59.0 with 4 tasks
2021-12-04 17:36:11,485 [dispatcher-event-loop-8] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 59.0 (TID 101, localhost, executor driver, partition 0, ANY, 7649 bytes)
2021-12-04 17:36:11,485 [dispatcher-event-loop-8] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 59.0 (TID 102, localhost, executor driver, partition 1, ANY, 7649 bytes)
2021-12-04 17:36:11,485 [dispatcher-event-loop-8] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 2.0 in stage 59.0 (TID 103, localhost, executor driver, partition 2, ANY, 7649 bytes)
2021-12-04 17:36:11,486 [dispatcher-event-loop-8] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 3.0 in stage 59.0 (TID 104, localhost, executor driver, partition 3, ANY, 7649 bytes)
2021-12-04 17:36:11,486 [Executor task launch worker for task 102] INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 59.0 (TID 102)
2021-12-04 17:36:11,486 [Executor task launch worker for task 101] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 59.0 (TID 101)
2021-12-04 17:36:11,486 [Executor task launch worker for task 103] INFO [org.apache.spark.executor.Executor] - Running task 2.0 in stage 59.0 (TID 103)
2021-12-04 17:36:11,486 [Executor task launch worker for task 104] INFO [org.apache.spark.executor.Executor] - Running task 3.0 in stage 59.0 (TID 104)
2021-12-04 17:36:11,488 [Executor task launch worker for task 104] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 4 non-empty blocks out of 4 blocks
2021-12-04 17:36:11,488 [Executor task launch worker for task 103] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 4 non-empty blocks out of 4 blocks
2021-12-04 17:36:11,488 [Executor task launch worker for task 104] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-04 17:36:11,488 [Executor task launch worker for task 103] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-04 17:36:11,488 [Executor task launch worker for task 102] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 4 non-empty blocks out of 4 blocks
2021-12-04 17:36:11,488 [Executor task launch worker for task 101] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 4 non-empty blocks out of 4 blocks
2021-12-04 17:36:11,488 [Executor task launch worker for task 102] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-04 17:36:11,488 [Executor task launch worker for task 101] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-04 17:36:11,581 [dispatcher-event-loop-11] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_42_piece0 on qb:60460 in memory (size: 62.9 KB, free: 1990.7 MB)
2021-12-04 17:36:11,610 [Executor task launch worker for task 101] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 59.0 (TID 101). 1141 bytes result sent to driver
2021-12-04 17:36:11,610 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 59.0 (TID 101) in 125 ms on localhost (executor driver) (1/4)
2021-12-04 17:36:11,610 [Executor task launch worker for task 104] INFO [org.apache.spark.executor.Executor] - Finished task 3.0 in stage 59.0 (TID 104). 1098 bytes result sent to driver
2021-12-04 17:36:11,611 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 3.0 in stage 59.0 (TID 104) in 125 ms on localhost (executor driver) (2/4)
2021-12-04 17:36:11,612 [Executor task launch worker for task 103] INFO [org.apache.spark.executor.Executor] - Finished task 2.0 in stage 59.0 (TID 103). 1098 bytes result sent to driver
2021-12-04 17:36:11,612 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 2.0 in stage 59.0 (TID 103) in 127 ms on localhost (executor driver) (3/4)
2021-12-04 17:36:11,612 [Executor task launch worker for task 102] INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 59.0 (TID 102). 1098 bytes result sent to driver
2021-12-04 17:36:11,612 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 59.0 (TID 102) in 127 ms on localhost (executor driver) (4/4)
2021-12-04 17:36:11,612 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 59.0, whose tasks have all completed, from pool 
2021-12-04 17:36:11,613 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 59 (count at PaidPromotionAdjustParameter.scala:203) finished in 0.131 s
2021-12-04 17:36:11,613 [main] INFO [org.apache.spark.scheduler.DAGScheduler] - Job 24 finished: count at PaidPromotionAdjustParameter.scala:203, took 1.474560 s
2021-12-04 17:36:11,613 [main] INFO [PaidPromotion$] - 训练集用户列表数量：95323
2021-12-04 17:36:11,619 [main] INFO [org.apache.spark.SparkContext] - Starting job: take at PaidPromotionAdjustParameter.scala:204
2021-12-04 17:36:11,620 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 25 (take at PaidPromotionAdjustParameter.scala:204) with 1 output partitions
2021-12-04 17:36:11,620 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 61 (take at PaidPromotionAdjustParameter.scala:204)
2021-12-04 17:36:11,620 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 60)
2021-12-04 17:36:11,620 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2021-12-04 17:36:11,620 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 61 (MapPartitionsRDD[73] at map at PaidPromotionAdjustParameter.scala:197), which has no missing parents
2021-12-04 17:36:11,621 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_44 stored as values in memory (estimated size 178.7 KB, free 1990.1 MB)
2021-12-04 17:36:11,623 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_44_piece0 stored as bytes in memory (estimated size 63.4 KB, free 1990.0 MB)
2021-12-04 17:36:11,623 [dispatcher-event-loop-8] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_44_piece0 in memory on qb:60460 (size: 63.4 KB, free: 1990.6 MB)
2021-12-04 17:36:11,623 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 44 from broadcast at DAGScheduler.scala:1039
2021-12-04 17:36:11,623 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 61 (MapPartitionsRDD[73] at map at PaidPromotionAdjustParameter.scala:197) (first 15 tasks are for partitions Vector(0))
2021-12-04 17:36:11,623 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 61.0 with 1 tasks
2021-12-04 17:36:11,624 [dispatcher-event-loop-9] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 61.0 (TID 105, localhost, executor driver, partition 0, ANY, 7649 bytes)
2021-12-04 17:36:11,624 [Executor task launch worker for task 105] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 61.0 (TID 105)
2021-12-04 17:36:11,625 [Executor task launch worker for task 105] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 4 non-empty blocks out of 4 blocks
2021-12-04 17:36:11,625 [Executor task launch worker for task 105] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-04 17:36:11,656 [Executor task launch worker for task 105] WARN [org.apache.spark.executor.Executor] - Managed memory leak detected; size = 5253912 bytes, TID = 105
2021-12-04 17:36:11,657 [Executor task launch worker for task 105] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 61.0 (TID 105). 2414 bytes result sent to driver
2021-12-04 17:36:11,657 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 61.0 (TID 105) in 34 ms on localhost (executor driver) (1/1)
2021-12-04 17:36:11,657 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 61.0, whose tasks have all completed, from pool 
2021-12-04 17:36:11,657 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 61 (take at PaidPromotionAdjustParameter.scala:204) finished in 0.037 s
2021-12-04 17:36:11,657 [main] INFO [org.apache.spark.scheduler.DAGScheduler] - Job 25 finished: take at PaidPromotionAdjustParameter.scala:204, took 0.037581 s
2021-12-04 17:36:11,660 [main] INFO [org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter] - File Output Committer Algorithm version is 1
2021-12-04 17:36:11,703 [main] INFO [org.apache.spark.SparkContext] - Starting job: runJob at SparkHadoopWriter.scala:78
2021-12-04 17:36:11,703 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 26 (runJob at SparkHadoopWriter.scala:78) with 1 output partitions
2021-12-04 17:36:11,703 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 63 (runJob at SparkHadoopWriter.scala:78)
2021-12-04 17:36:11,703 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 62)
2021-12-04 17:36:11,703 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2021-12-04 17:36:11,703 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 63 (MapPartitionsRDD[75] at saveAsTextFile at PaidPromotionAdjustParameter.scala:206), which has no missing parents
2021-12-04 17:36:11,715 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_45 stored as values in memory (estimated size 254.4 KB, free 1989.7 MB)
2021-12-04 17:36:11,717 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_45_piece0 stored as bytes in memory (estimated size 91.6 KB, free 1989.7 MB)
2021-12-04 17:36:11,717 [dispatcher-event-loop-1] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_45_piece0 in memory on qb:60460 (size: 91.6 KB, free: 1990.6 MB)
2021-12-04 17:36:11,718 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 45 from broadcast at DAGScheduler.scala:1039
2021-12-04 17:36:11,718 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 63 (MapPartitionsRDD[75] at saveAsTextFile at PaidPromotionAdjustParameter.scala:206) (first 15 tasks are for partitions Vector(0))
2021-12-04 17:36:11,718 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 63.0 with 1 tasks
2021-12-04 17:36:11,718 [dispatcher-event-loop-10] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 63.0 (TID 106, localhost, executor driver, partition 0, ANY, 7943 bytes)
2021-12-04 17:36:11,718 [Executor task launch worker for task 106] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 63.0 (TID 106)
2021-12-04 17:36:11,724 [Executor task launch worker for task 106] INFO [org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter] - File Output Committer Algorithm version is 1
2021-12-04 17:36:11,731 [Executor task launch worker for task 106] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 2 non-empty blocks out of 2 blocks
2021-12-04 17:36:11,731 [Executor task launch worker for task 106] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-04 17:36:11,745 [Executor task launch worker for task 106] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 2 non-empty blocks out of 2 blocks
2021-12-04 17:36:11,745 [Executor task launch worker for task 106] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-04 17:36:11,848 [Executor task launch worker for task 106] INFO [org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter] - Saved output of task 'attempt_20211204173611_0075_m_000000_0' to hdfs://hdp1:8020/sk/chongqing/list/validation/_temporary/0/task_20211204173611_0075_m_000000
2021-12-04 17:36:11,848 [Executor task launch worker for task 106] INFO [org.apache.spark.mapred.SparkHadoopMapRedUtil] - attempt_20211204173611_0075_m_000000_0: Committed
2021-12-04 17:36:11,849 [Executor task launch worker for task 106] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 63.0 (TID 106). 1256 bytes result sent to driver
2021-12-04 17:36:11,850 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 63.0 (TID 106) in 131 ms on localhost (executor driver) (1/1)
2021-12-04 17:36:11,850 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 63.0, whose tasks have all completed, from pool 
2021-12-04 17:36:11,850 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 63 (runJob at SparkHadoopWriter.scala:78) finished in 0.146 s
2021-12-04 17:36:11,850 [main] INFO [org.apache.spark.scheduler.DAGScheduler] - Job 26 finished: runJob at SparkHadoopWriter.scala:78, took 0.147230 s
2021-12-04 17:36:11,900 [main] INFO [org.apache.spark.internal.io.SparkHadoopWriter] - Job job_20211204173611_0075 committed.
2021-12-04 17:36:11,903 [main] INFO [org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter] - File Output Committer Algorithm version is 1
2021-12-04 17:36:11,931 [main] INFO [org.apache.spark.SparkContext] - Starting job: runJob at SparkHadoopWriter.scala:78
2021-12-04 17:36:11,931 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 27 (runJob at SparkHadoopWriter.scala:78) with 1 output partitions
2021-12-04 17:36:11,931 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 65 (runJob at SparkHadoopWriter.scala:78)
2021-12-04 17:36:11,931 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 64)
2021-12-04 17:36:11,931 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2021-12-04 17:36:11,932 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 65 (MapPartitionsRDD[77] at saveAsTextFile at PaidPromotionAdjustParameter.scala:207), which has no missing parents
2021-12-04 17:36:11,943 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_46 stored as values in memory (estimated size 255.0 KB, free 1989.4 MB)
2021-12-04 17:36:11,945 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_46_piece0 stored as bytes in memory (estimated size 92.0 KB, free 1989.3 MB)
2021-12-04 17:36:11,945 [dispatcher-event-loop-6] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_46_piece0 in memory on qb:60460 (size: 92.0 KB, free: 1990.5 MB)
2021-12-04 17:36:11,945 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 46 from broadcast at DAGScheduler.scala:1039
2021-12-04 17:36:11,945 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 65 (MapPartitionsRDD[77] at saveAsTextFile at PaidPromotionAdjustParameter.scala:207) (first 15 tasks are for partitions Vector(0))
2021-12-04 17:36:11,945 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 65.0 with 1 tasks
2021-12-04 17:36:11,946 [dispatcher-event-loop-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 65.0 (TID 107, localhost, executor driver, partition 0, ANY, 7979 bytes)
2021-12-04 17:36:11,946 [Executor task launch worker for task 107] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 65.0 (TID 107)
2021-12-04 17:36:11,951 [Executor task launch worker for task 107] INFO [org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter] - File Output Committer Algorithm version is 1
2021-12-04 17:36:11,956 [Executor task launch worker for task 107] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 4 non-empty blocks out of 4 blocks
2021-12-04 17:36:11,956 [Executor task launch worker for task 107] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-04 17:36:12,013 [Executor task launch worker for task 107] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 4 non-empty blocks out of 4 blocks
2021-12-04 17:36:12,013 [Executor task launch worker for task 107] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-04 17:36:12,065 [Executor task launch worker for task 107] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 4 non-empty blocks out of 4 blocks
2021-12-04 17:36:12,065 [Executor task launch worker for task 107] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-04 17:36:12,129 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1063
2021-12-04 17:36:12,129 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1056
2021-12-04 17:36:12,129 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1058
2021-12-04 17:36:12,129 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1112
2021-12-04 17:36:12,129 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1078
2021-12-04 17:36:12,129 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1034
2021-12-04 17:36:12,129 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1044
2021-12-04 17:36:12,129 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1081
2021-12-04 17:36:12,129 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1051
2021-12-04 17:36:12,130 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1030
2021-12-04 17:36:12,130 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1053
2021-12-04 17:36:12,130 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1031
2021-12-04 17:36:12,130 [Executor task launch worker for task 107] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 4 non-empty blocks out of 4 blocks
2021-12-04 17:36:12,130 [Executor task launch worker for task 107] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-04 17:36:12,130 [dispatcher-event-loop-7] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_44_piece0 on qb:60460 in memory (size: 63.4 KB, free: 1990.5 MB)
2021-12-04 17:36:12,130 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1046
2021-12-04 17:36:12,131 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1076
2021-12-04 17:36:12,131 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1120
2021-12-04 17:36:12,131 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1080
2021-12-04 17:36:12,131 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1059
2021-12-04 17:36:12,131 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1096
2021-12-04 17:36:12,131 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1048
2021-12-04 17:36:12,131 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1093
2021-12-04 17:36:12,131 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1073
2021-12-04 17:36:12,131 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1094
2021-12-04 17:36:12,131 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1050
2021-12-04 17:36:12,131 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1091
2021-12-04 17:36:12,131 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1090
2021-12-04 17:36:12,131 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1075
2021-12-04 17:36:12,131 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1102
2021-12-04 17:36:12,131 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1100
2021-12-04 17:36:12,131 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1026
2021-12-04 17:36:12,131 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1068
2021-12-04 17:36:12,131 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1079
2021-12-04 17:36:12,131 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1042
2021-12-04 17:36:12,131 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1062
2021-12-04 17:36:12,131 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1084
2021-12-04 17:36:12,131 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1113
2021-12-04 17:36:12,131 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1055
2021-12-04 17:36:12,131 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1028
2021-12-04 17:36:12,131 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1109
2021-12-04 17:36:12,131 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1105
2021-12-04 17:36:12,131 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1106
2021-12-04 17:36:12,131 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1104
2021-12-04 17:36:12,131 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1111
2021-12-04 17:36:12,131 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1027
2021-12-04 17:36:12,131 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1045
2021-12-04 17:36:12,131 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1067
2021-12-04 17:36:12,131 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1057
2021-12-04 17:36:12,131 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1116
2021-12-04 17:36:12,131 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1069
2021-12-04 17:36:12,131 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1074
2021-12-04 17:36:12,131 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1040
2021-12-04 17:36:12,131 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1043
2021-12-04 17:36:12,131 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1099
2021-12-04 17:36:12,131 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1123
2021-12-04 17:36:12,131 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1083
2021-12-04 17:36:12,131 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1122
2021-12-04 17:36:12,131 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1036
2021-12-04 17:36:12,131 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1071
2021-12-04 17:36:12,131 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1115
2021-12-04 17:36:12,131 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1097
2021-12-04 17:36:12,131 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1065
2021-12-04 17:36:12,131 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1114
2021-12-04 17:36:12,131 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1033
2021-12-04 17:36:12,131 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1061
2021-12-04 17:36:12,131 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1077
2021-12-04 17:36:12,131 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1029
2021-12-04 17:36:12,131 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1121
2021-12-04 17:36:12,131 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1041
2021-12-04 17:36:12,131 [dispatcher-event-loop-10] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_45_piece0 on qb:60460 in memory (size: 91.6 KB, free: 1990.6 MB)
2021-12-04 17:36:12,132 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1082
2021-12-04 17:36:12,132 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1066
2021-12-04 17:36:12,132 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1124
2021-12-04 17:36:12,132 [dispatcher-event-loop-3] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_43_piece0 on qb:60460 in memory (size: 63.3 KB, free: 1990.7 MB)
2021-12-04 17:36:12,132 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1052
2021-12-04 17:36:12,132 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1092
2021-12-04 17:36:12,132 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1095
2021-12-04 17:36:12,132 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1025
2021-12-04 17:36:12,132 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1032
2021-12-04 17:36:12,132 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1037
2021-12-04 17:36:12,132 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1060
2021-12-04 17:36:12,132 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1039
2021-12-04 17:36:12,132 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1103
2021-12-04 17:36:12,133 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1054
2021-12-04 17:36:12,133 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1110
2021-12-04 17:36:12,133 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1064
2021-12-04 17:36:12,133 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1047
2021-12-04 17:36:12,133 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1085
2021-12-04 17:36:12,133 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1117
2021-12-04 17:36:12,133 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1070
2021-12-04 17:36:12,133 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1086
2021-12-04 17:36:12,133 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1108
2021-12-04 17:36:12,133 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1119
2021-12-04 17:36:12,133 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1088
2021-12-04 17:36:12,133 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1089
2021-12-04 17:36:12,133 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1038
2021-12-04 17:36:12,133 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1118
2021-12-04 17:36:12,133 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1098
2021-12-04 17:36:12,133 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1087
2021-12-04 17:36:12,133 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1107
2021-12-04 17:36:12,133 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1049
2021-12-04 17:36:12,133 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1072
2021-12-04 17:36:12,133 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1035
2021-12-04 17:36:12,133 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1101
2021-12-04 17:36:12,623 [Executor task launch worker for task 107] INFO [org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter] - Saved output of task 'attempt_20211204173611_0077_m_000000_0' to hdfs://hdp1:8020/sk/chongqing/list/train/_temporary/0/task_20211204173611_0077_m_000000
2021-12-04 17:36:12,623 [Executor task launch worker for task 107] INFO [org.apache.spark.mapred.SparkHadoopMapRedUtil] - attempt_20211204173611_0077_m_000000_0: Committed
2021-12-04 17:36:12,624 [Executor task launch worker for task 107] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 65.0 (TID 107). 1342 bytes result sent to driver
2021-12-04 17:36:12,624 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 65.0 (TID 107) in 678 ms on localhost (executor driver) (1/1)
2021-12-04 17:36:12,624 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 65.0, whose tasks have all completed, from pool 
2021-12-04 17:36:12,625 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 65 (runJob at SparkHadoopWriter.scala:78) finished in 0.693 s
2021-12-04 17:36:12,625 [main] INFO [org.apache.spark.scheduler.DAGScheduler] - Job 27 finished: runJob at SparkHadoopWriter.scala:78, took 0.693893 s
2021-12-04 17:36:12,700 [main] INFO [org.apache.spark.internal.io.SparkHadoopWriter] - Job job_20211204173611_0077 committed.
2021-12-04 17:36:12,708 [main] INFO [org.spark_project.jetty.server.AbstractConnector] - Stopped Spark@5b800468{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2021-12-04 17:36:12,710 [main] INFO [org.apache.spark.ui.SparkUI] - Stopped Spark web UI at http://qb:4040
2021-12-04 17:36:12,717 [dispatcher-event-loop-9] INFO [org.apache.spark.MapOutputTrackerMasterEndpoint] - MapOutputTrackerMasterEndpoint stopped!
2021-12-04 17:36:12,793 [main] INFO [org.apache.spark.storage.memory.MemoryStore] - MemoryStore cleared
2021-12-04 17:36:12,793 [main] INFO [org.apache.spark.storage.BlockManager] - BlockManager stopped
2021-12-04 17:36:12,794 [main] INFO [org.apache.spark.storage.BlockManagerMaster] - BlockManagerMaster stopped
2021-12-04 17:36:12,795 [dispatcher-event-loop-11] INFO [org.apache.spark.scheduler.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint] - OutputCommitCoordinator stopped!
2021-12-04 17:36:12,798 [main] INFO [org.apache.spark.SparkContext] - Successfully stopped SparkContext
2021-12-04 17:36:12,800 [Thread-1] INFO [org.apache.spark.util.ShutdownHookManager] - Shutdown hook called
2021-12-04 17:36:12,800 [Thread-1] INFO [org.apache.spark.util.ShutdownHookManager] - Deleting directory C:\Users\ACER\AppData\Local\Temp\spark-1b30c5d5-0b58-4f3c-94ee-1a28c10eb92b
2021-12-04 17:38:07,546 [main] INFO [org.apache.spark.SparkContext] - Running Spark version 2.3.0
2021-12-04 17:38:07,797 [main] INFO [org.apache.spark.SparkContext] - Submitted application: PaidPromotion
2021-12-04 17:38:07,841 [main] INFO [org.apache.spark.SecurityManager] - Changing view acls to: ACER,root
2021-12-04 17:38:07,842 [main] INFO [org.apache.spark.SecurityManager] - Changing modify acls to: ACER,root
2021-12-04 17:38:07,842 [main] INFO [org.apache.spark.SecurityManager] - Changing view acls groups to: 
2021-12-04 17:38:07,842 [main] INFO [org.apache.spark.SecurityManager] - Changing modify acls groups to: 
2021-12-04 17:38:07,843 [main] INFO [org.apache.spark.SecurityManager] - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(ACER, root); groups with view permissions: Set(); users  with modify permissions: Set(ACER, root); groups with modify permissions: Set()
2021-12-04 17:38:08,391 [main] INFO [org.apache.spark.util.Utils] - Successfully started service 'sparkDriver' on port 60622.
2021-12-04 17:38:08,408 [main] INFO [org.apache.spark.SparkEnv] - Registering MapOutputTracker
2021-12-04 17:38:08,422 [main] INFO [org.apache.spark.SparkEnv] - Registering BlockManagerMaster
2021-12-04 17:38:08,425 [main] INFO [org.apache.spark.storage.BlockManagerMasterEndpoint] - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2021-12-04 17:38:08,425 [main] INFO [org.apache.spark.storage.BlockManagerMasterEndpoint] - BlockManagerMasterEndpoint up
2021-12-04 17:38:08,432 [main] INFO [org.apache.spark.storage.DiskBlockManager] - Created local directory at C:\Users\ACER\AppData\Local\Temp\blockmgr-43946d68-bcda-4baf-bf3c-65c0ccddf4a2
2021-12-04 17:38:08,445 [main] INFO [org.apache.spark.storage.memory.MemoryStore] - MemoryStore started with capacity 1990.8 MB
2021-12-04 17:38:08,455 [main] INFO [org.apache.spark.SparkEnv] - Registering OutputCommitCoordinator
2021-12-04 17:38:08,509 [main] INFO [org.spark_project.jetty.util.log] - Logging initialized @1754ms
2021-12-04 17:38:08,557 [main] INFO [org.spark_project.jetty.server.Server] - jetty-9.3.z-SNAPSHOT
2021-12-04 17:38:08,568 [main] INFO [org.spark_project.jetty.server.Server] - Started @1814ms
2021-12-04 17:38:08,591 [main] INFO [org.spark_project.jetty.server.AbstractConnector] - Started ServerConnector@5f7f2382{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2021-12-04 17:38:08,592 [main] INFO [org.apache.spark.util.Utils] - Successfully started service 'SparkUI' on port 4040.
2021-12-04 17:38:08,609 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@3af17be2{/jobs,null,AVAILABLE,@Spark}
2021-12-04 17:38:08,610 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@6a1d204a{/jobs/json,null,AVAILABLE,@Spark}
2021-12-04 17:38:08,611 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@72ccd81a{/jobs/job,null,AVAILABLE,@Spark}
2021-12-04 17:38:08,612 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@5d25e6bb{/jobs/job/json,null,AVAILABLE,@Spark}
2021-12-04 17:38:08,613 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@7859e786{/stages,null,AVAILABLE,@Spark}
2021-12-04 17:38:08,614 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@5118388b{/stages/json,null,AVAILABLE,@Spark}
2021-12-04 17:38:08,615 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@71104a4{/stages/stage,null,AVAILABLE,@Spark}
2021-12-04 17:38:08,617 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@332a7fce{/stages/stage/json,null,AVAILABLE,@Spark}
2021-12-04 17:38:08,618 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@37ebc9d8{/stages/pool,null,AVAILABLE,@Spark}
2021-12-04 17:38:08,619 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@6e9319f{/stages/pool/json,null,AVAILABLE,@Spark}
2021-12-04 17:38:08,620 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@2c177f9e{/storage,null,AVAILABLE,@Spark}
2021-12-04 17:38:08,621 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@f9b7332{/storage/json,null,AVAILABLE,@Spark}
2021-12-04 17:38:08,622 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@192f2f27{/storage/rdd,null,AVAILABLE,@Spark}
2021-12-04 17:38:08,622 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@b672aa8{/storage/rdd/json,null,AVAILABLE,@Spark}
2021-12-04 17:38:08,624 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@7997b197{/environment,null,AVAILABLE,@Spark}
2021-12-04 17:38:08,625 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@11acdc30{/environment/json,null,AVAILABLE,@Spark}
2021-12-04 17:38:08,626 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@611f8234{/executors,null,AVAILABLE,@Spark}
2021-12-04 17:38:08,627 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@62923ee6{/executors/json,null,AVAILABLE,@Spark}
2021-12-04 17:38:08,629 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@4b6166aa{/executors/threadDump,null,AVAILABLE,@Spark}
2021-12-04 17:38:08,630 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@a1217f9{/executors/threadDump/json,null,AVAILABLE,@Spark}
2021-12-04 17:38:08,636 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@791cbf87{/static,null,AVAILABLE,@Spark}
2021-12-04 17:38:08,637 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@cf65451{/,null,AVAILABLE,@Spark}
2021-12-04 17:38:08,638 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@46074492{/api,null,AVAILABLE,@Spark}
2021-12-04 17:38:08,639 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@5ae76500{/jobs/job/kill,null,AVAILABLE,@Spark}
2021-12-04 17:38:08,641 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@24f360b2{/stages/stage/kill,null,AVAILABLE,@Spark}
2021-12-04 17:38:08,643 [main] INFO [org.apache.spark.ui.SparkUI] - Bound SparkUI to 0.0.0.0, and started at http://qb:4040
2021-12-04 17:38:08,722 [main] INFO [org.apache.spark.executor.Executor] - Starting executor ID driver on host localhost
2021-12-04 17:38:08,775 [main] INFO [org.apache.spark.util.Utils] - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 60666.
2021-12-04 17:38:08,776 [main] INFO [org.apache.spark.network.netty.NettyBlockTransferService] - Server created on qb:60666
2021-12-04 17:38:08,777 [main] INFO [org.apache.spark.storage.BlockManager] - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2021-12-04 17:38:08,778 [main] INFO [org.apache.spark.storage.BlockManagerMaster] - Registering BlockManager BlockManagerId(driver, qb, 60666, None)
2021-12-04 17:38:08,780 [dispatcher-event-loop-6] INFO [org.apache.spark.storage.BlockManagerMasterEndpoint] - Registering block manager qb:60666 with 1990.8 MB RAM, BlockManagerId(driver, qb, 60666, None)
2021-12-04 17:38:08,782 [main] INFO [org.apache.spark.storage.BlockManagerMaster] - Registered BlockManager BlockManagerId(driver, qb, 60666, None)
2021-12-04 17:38:08,783 [main] INFO [org.apache.spark.storage.BlockManager] - Initialized BlockManager: BlockManagerId(driver, qb, 60666, None)
2021-12-04 17:38:08,922 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@7c9b78e3{/metrics/json,null,AVAILABLE,@Spark}
2021-12-04 17:38:09,378 [main] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_0 stored as values in memory (estimated size 312.7 KB, free 1990.5 MB)
2021-12-04 17:38:09,566 [main] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_0_piece0 stored as bytes in memory (estimated size 27.3 KB, free 1990.5 MB)
2021-12-04 17:38:09,567 [dispatcher-event-loop-0] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_0_piece0 in memory on qb:60666 (size: 27.3 KB, free: 1990.8 MB)
2021-12-04 17:38:09,570 [main] INFO [org.apache.spark.SparkContext] - Created broadcast 0 from textFile at PaidPromotionAdjustParameter.scala:98
2021-12-04 17:38:09,892 [main] WARN [org.apache.hadoop.hdfs.shortcircuit.DomainSocketFactory] - The short-circuit local reads feature cannot be used because UNIX Domain sockets are not available on Windows.
2021-12-04 17:38:09,956 [main] INFO [org.apache.hadoop.mapred.FileInputFormat] - Total input paths to process : 1
2021-12-04 17:38:09,987 [main] INFO [org.apache.spark.SparkContext] - Starting job: count at PaidPromotionAdjustParameter.scala:100
2021-12-04 17:38:09,996 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 0 (count at PaidPromotionAdjustParameter.scala:100) with 2 output partitions
2021-12-04 17:38:09,997 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 0 (count at PaidPromotionAdjustParameter.scala:100)
2021-12-04 17:38:09,997 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List()
2021-12-04 17:38:09,998 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2021-12-04 17:38:10,003 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 0 (/sk/chongqing/data/order_data.bcp MapPartitionsRDD[1] at textFile at PaidPromotionAdjustParameter.scala:98), which has no missing parents
2021-12-04 17:38:10,032 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_1 stored as values in memory (estimated size 3.1 KB, free 1990.5 MB)
2021-12-04 17:38:10,037 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_1_piece0 stored as bytes in memory (estimated size 1900.0 B, free 1990.5 MB)
2021-12-04 17:38:10,038 [dispatcher-event-loop-1] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_1_piece0 in memory on qb:60666 (size: 1900.0 B, free: 1990.8 MB)
2021-12-04 17:38:10,038 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 1 from broadcast at DAGScheduler.scala:1039
2021-12-04 17:38:10,048 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from ResultStage 0 (/sk/chongqing/data/order_data.bcp MapPartitionsRDD[1] at textFile at PaidPromotionAdjustParameter.scala:98) (first 15 tasks are for partitions Vector(0, 1))
2021-12-04 17:38:10,049 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 0.0 with 2 tasks
2021-12-04 17:38:10,078 [dispatcher-event-loop-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 0.0 (TID 0, localhost, executor driver, partition 0, ANY, 7896 bytes)
2021-12-04 17:38:10,080 [dispatcher-event-loop-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 0.0 (TID 1, localhost, executor driver, partition 1, ANY, 7896 bytes)
2021-12-04 17:38:10,084 [Executor task launch worker for task 1] INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 0.0 (TID 1)
2021-12-04 17:38:10,084 [Executor task launch worker for task 0] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 0.0 (TID 0)
2021-12-04 17:38:10,119 [Executor task launch worker for task 0] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/order_data.bcp:0+3442194
2021-12-04 17:38:10,119 [Executor task launch worker for task 1] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/order_data.bcp:3442194+3442195
2021-12-04 17:38:10,834 [Executor task launch worker for task 1] INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 0.0 (TID 1). 711 bytes result sent to driver
2021-12-04 17:38:10,841 [Executor task launch worker for task 0] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 0.0 (TID 0). 711 bytes result sent to driver
2021-12-04 17:38:10,843 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 0.0 (TID 1) in 763 ms on localhost (executor driver) (1/2)
2021-12-04 17:38:10,845 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 0.0 (TID 0) in 775 ms on localhost (executor driver) (2/2)
2021-12-04 17:38:10,846 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 0.0, whose tasks have all completed, from pool 
2021-12-04 17:38:10,848 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 0 (count at PaidPromotionAdjustParameter.scala:100) finished in 0.833 s
2021-12-04 17:38:10,852 [main] INFO [org.apache.spark.scheduler.DAGScheduler] - Job 0 finished: count at PaidPromotionAdjustParameter.scala:100, took 0.864610 s
2021-12-04 17:38:10,853 [main] INFO [PaidPromotion$] - 订购总数107294
2021-12-04 17:38:10,858 [main] INFO [org.apache.spark.SparkContext] - Starting job: count at PaidPromotionAdjustParameter.scala:108
2021-12-04 17:38:10,858 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 1 (count at PaidPromotionAdjustParameter.scala:108) with 2 output partitions
2021-12-04 17:38:10,859 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 1 (count at PaidPromotionAdjustParameter.scala:108)
2021-12-04 17:38:10,859 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List()
2021-12-04 17:38:10,859 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2021-12-04 17:38:10,859 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 1 (MapPartitionsRDD[2] at map at PaidPromotionAdjustParameter.scala:104), which has no missing parents
2021-12-04 17:38:10,860 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_2 stored as values in memory (estimated size 3.3 KB, free 1990.5 MB)
2021-12-04 17:38:10,865 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_2_piece0 stored as bytes in memory (estimated size 1985.0 B, free 1990.5 MB)
2021-12-04 17:38:10,865 [dispatcher-event-loop-9] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_2_piece0 in memory on qb:60666 (size: 1985.0 B, free: 1990.8 MB)
2021-12-04 17:38:10,866 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 2 from broadcast at DAGScheduler.scala:1039
2021-12-04 17:38:10,866 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from ResultStage 1 (MapPartitionsRDD[2] at map at PaidPromotionAdjustParameter.scala:104) (first 15 tasks are for partitions Vector(0, 1))
2021-12-04 17:38:10,866 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 1.0 with 2 tasks
2021-12-04 17:38:10,867 [dispatcher-event-loop-10] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 1.0 (TID 2, localhost, executor driver, partition 0, ANY, 7896 bytes)
2021-12-04 17:38:10,867 [dispatcher-event-loop-10] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 1.0 (TID 3, localhost, executor driver, partition 1, ANY, 7896 bytes)
2021-12-04 17:38:10,868 [Executor task launch worker for task 2] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 1.0 (TID 2)
2021-12-04 17:38:10,868 [Executor task launch worker for task 3] INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 1.0 (TID 3)
2021-12-04 17:38:10,871 [Executor task launch worker for task 2] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/order_data.bcp:0+3442194
2021-12-04 17:38:10,871 [Executor task launch worker for task 3] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/order_data.bcp:3442194+3442195
2021-12-04 17:38:10,916 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 23
2021-12-04 17:38:10,916 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 18
2021-12-04 17:38:10,916 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 20
2021-12-04 17:38:10,916 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 24
2021-12-04 17:38:10,916 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 2
2021-12-04 17:38:10,916 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 21
2021-12-04 17:38:10,929 [dispatcher-event-loop-1] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_1_piece0 on qb:60666 in memory (size: 1900.0 B, free: 1990.8 MB)
2021-12-04 17:38:10,931 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 15
2021-12-04 17:38:10,931 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1
2021-12-04 17:38:10,931 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 9
2021-12-04 17:38:10,931 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 3
2021-12-04 17:38:10,931 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 19
2021-12-04 17:38:10,932 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 10
2021-12-04 17:38:10,932 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 7
2021-12-04 17:38:10,932 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 13
2021-12-04 17:38:10,932 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 16
2021-12-04 17:38:10,932 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 11
2021-12-04 17:38:10,932 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 0
2021-12-04 17:38:10,932 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 5
2021-12-04 17:38:10,932 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 14
2021-12-04 17:38:10,932 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 8
2021-12-04 17:38:10,932 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 17
2021-12-04 17:38:10,932 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 22
2021-12-04 17:38:10,932 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 6
2021-12-04 17:38:10,932 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 4
2021-12-04 17:38:10,932 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 12
2021-12-04 17:38:11,248 [Executor task launch worker for task 3] INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 1.0 (TID 3). 754 bytes result sent to driver
2021-12-04 17:38:11,251 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 1.0 (TID 3) in 384 ms on localhost (executor driver) (1/2)
2021-12-04 17:38:11,518 [Executor task launch worker for task 2] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 1.0 (TID 2). 754 bytes result sent to driver
2021-12-04 17:38:11,521 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 1.0 (TID 2) in 654 ms on localhost (executor driver) (2/2)
2021-12-04 17:38:11,521 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 1.0, whose tasks have all completed, from pool 
2021-12-04 17:38:11,521 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 1 (count at PaidPromotionAdjustParameter.scala:108) finished in 0.662 s
2021-12-04 17:38:11,522 [main] INFO [org.apache.spark.scheduler.DAGScheduler] - Job 1 finished: count at PaidPromotionAdjustParameter.scala:108, took 0.663307 s
2021-12-04 17:38:11,522 [main] INFO [PaidPromotion$] - 订购总数：107294
2021-12-04 17:38:11,534 [main] INFO [org.apache.spark.SparkContext] - Starting job: count at PaidPromotionAdjustParameter.scala:121
2021-12-04 17:38:11,535 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 2 (count at PaidPromotionAdjustParameter.scala:121) with 2 output partitions
2021-12-04 17:38:11,535 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 2 (count at PaidPromotionAdjustParameter.scala:121)
2021-12-04 17:38:11,535 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List()
2021-12-04 17:38:11,535 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2021-12-04 17:38:11,535 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 2 (MapPartitionsRDD[3] at randomSplit at PaidPromotionAdjustParameter.scala:114), which has no missing parents
2021-12-04 17:38:11,537 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_3 stored as values in memory (estimated size 3.6 KB, free 1990.5 MB)
2021-12-04 17:38:11,541 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_3_piece0 stored as bytes in memory (estimated size 2.1 KB, free 1990.5 MB)
2021-12-04 17:38:11,541 [dispatcher-event-loop-3] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_3_piece0 in memory on qb:60666 (size: 2.1 KB, free: 1990.8 MB)
2021-12-04 17:38:11,542 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 3 from broadcast at DAGScheduler.scala:1039
2021-12-04 17:38:11,543 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from ResultStage 2 (MapPartitionsRDD[3] at randomSplit at PaidPromotionAdjustParameter.scala:114) (first 15 tasks are for partitions Vector(0, 1))
2021-12-04 17:38:11,543 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 2.0 with 2 tasks
2021-12-04 17:38:11,543 [dispatcher-event-loop-4] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 2.0 (TID 4, localhost, executor driver, partition 0, ANY, 7896 bytes)
2021-12-04 17:38:11,544 [dispatcher-event-loop-4] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 2.0 (TID 5, localhost, executor driver, partition 1, ANY, 7896 bytes)
2021-12-04 17:38:11,544 [Executor task launch worker for task 5] INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 2.0 (TID 5)
2021-12-04 17:38:11,544 [Executor task launch worker for task 4] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 2.0 (TID 4)
2021-12-04 17:38:11,547 [Executor task launch worker for task 5] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/order_data.bcp:3442194+3442195
2021-12-04 17:38:11,547 [Executor task launch worker for task 4] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/order_data.bcp:0+3442194
2021-12-04 17:38:11,573 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 37
2021-12-04 17:38:11,573 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 27
2021-12-04 17:38:11,573 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 26
2021-12-04 17:38:11,573 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 33
2021-12-04 17:38:11,573 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 28
2021-12-04 17:38:11,573 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 41
2021-12-04 17:38:11,573 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 30
2021-12-04 17:38:11,573 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 46
2021-12-04 17:38:11,573 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 40
2021-12-04 17:38:11,573 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 36
2021-12-04 17:38:11,573 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 38
2021-12-04 17:38:11,573 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 49
2021-12-04 17:38:11,573 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 45
2021-12-04 17:38:11,573 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 43
2021-12-04 17:38:11,573 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 31
2021-12-04 17:38:11,573 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 32
2021-12-04 17:38:11,573 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 34
2021-12-04 17:38:11,573 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 25
2021-12-04 17:38:11,573 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 44
2021-12-04 17:38:11,573 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 48
2021-12-04 17:38:11,574 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 35
2021-12-04 17:38:11,574 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 39
2021-12-04 17:38:11,574 [dispatcher-event-loop-6] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_2_piece0 on qb:60666 in memory (size: 1985.0 B, free: 1990.8 MB)
2021-12-04 17:38:11,575 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 29
2021-12-04 17:38:11,575 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 42
2021-12-04 17:38:11,575 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 47
2021-12-04 17:38:11,962 [Executor task launch worker for task 4] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 2.0 (TID 4). 797 bytes result sent to driver
2021-12-04 17:38:11,962 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 2.0 (TID 4) in 419 ms on localhost (executor driver) (1/2)
2021-12-04 17:38:12,246 [Executor task launch worker for task 5] INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 2.0 (TID 5). 797 bytes result sent to driver
2021-12-04 17:38:12,247 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 2.0 (TID 5) in 704 ms on localhost (executor driver) (2/2)
2021-12-04 17:38:12,247 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 2.0, whose tasks have all completed, from pool 
2021-12-04 17:38:12,247 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 2 (count at PaidPromotionAdjustParameter.scala:121) finished in 0.711 s
2021-12-04 17:38:12,247 [main] INFO [org.apache.spark.scheduler.DAGScheduler] - Job 2 finished: count at PaidPromotionAdjustParameter.scala:121, took 0.713394 s
2021-12-04 17:38:12,248 [main] INFO [PaidPromotion$] - 初次切分训练集数量：57590
2021-12-04 17:38:12,249 [main] INFO [org.apache.spark.SparkContext] - Starting job: count at PaidPromotionAdjustParameter.scala:122
2021-12-04 17:38:12,250 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 3 (count at PaidPromotionAdjustParameter.scala:122) with 2 output partitions
2021-12-04 17:38:12,250 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 3 (count at PaidPromotionAdjustParameter.scala:122)
2021-12-04 17:38:12,250 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List()
2021-12-04 17:38:12,250 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2021-12-04 17:38:12,250 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 3 (MapPartitionsRDD[4] at randomSplit at PaidPromotionAdjustParameter.scala:114), which has no missing parents
2021-12-04 17:38:12,251 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_4 stored as values in memory (estimated size 3.6 KB, free 1990.5 MB)
2021-12-04 17:38:12,254 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_4_piece0 stored as bytes in memory (estimated size 2.1 KB, free 1990.5 MB)
2021-12-04 17:38:12,255 [dispatcher-event-loop-1] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_4_piece0 in memory on qb:60666 (size: 2.1 KB, free: 1990.8 MB)
2021-12-04 17:38:12,255 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 4 from broadcast at DAGScheduler.scala:1039
2021-12-04 17:38:12,255 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from ResultStage 3 (MapPartitionsRDD[4] at randomSplit at PaidPromotionAdjustParameter.scala:114) (first 15 tasks are for partitions Vector(0, 1))
2021-12-04 17:38:12,256 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 3.0 with 2 tasks
2021-12-04 17:38:12,256 [dispatcher-event-loop-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 3.0 (TID 6, localhost, executor driver, partition 0, ANY, 7896 bytes)
2021-12-04 17:38:12,256 [dispatcher-event-loop-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 3.0 (TID 7, localhost, executor driver, partition 1, ANY, 7896 bytes)
2021-12-04 17:38:12,257 [Executor task launch worker for task 6] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 3.0 (TID 6)
2021-12-04 17:38:12,257 [Executor task launch worker for task 7] INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 3.0 (TID 7)
2021-12-04 17:38:12,259 [Executor task launch worker for task 6] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/order_data.bcp:0+3442194
2021-12-04 17:38:12,259 [Executor task launch worker for task 7] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/order_data.bcp:3442194+3442195
2021-12-04 17:38:12,570 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 72
2021-12-04 17:38:12,570 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 69
2021-12-04 17:38:12,570 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 68
2021-12-04 17:38:12,570 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 62
2021-12-04 17:38:12,571 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 54
2021-12-04 17:38:12,571 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 52
2021-12-04 17:38:12,571 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 51
2021-12-04 17:38:12,571 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 73
2021-12-04 17:38:12,571 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 65
2021-12-04 17:38:12,571 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 55
2021-12-04 17:38:12,571 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 56
2021-12-04 17:38:12,571 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 74
2021-12-04 17:38:12,571 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 64
2021-12-04 17:38:12,571 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 61
2021-12-04 17:38:12,571 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 57
2021-12-04 17:38:12,571 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 66
2021-12-04 17:38:12,571 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 50
2021-12-04 17:38:12,571 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 71
2021-12-04 17:38:12,571 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 53
2021-12-04 17:38:12,571 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 59
2021-12-04 17:38:12,571 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 63
2021-12-04 17:38:12,571 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 58
2021-12-04 17:38:12,571 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 60
2021-12-04 17:38:12,571 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 67
2021-12-04 17:38:12,572 [dispatcher-event-loop-9] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_3_piece0 on qb:60666 in memory (size: 2.1 KB, free: 1990.8 MB)
2021-12-04 17:38:12,573 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 70
2021-12-04 17:38:12,906 [Executor task launch worker for task 6] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 3.0 (TID 6). 711 bytes result sent to driver
2021-12-04 17:38:12,906 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 3.0 (TID 6) in 650 ms on localhost (executor driver) (1/2)
2021-12-04 17:38:12,926 [Executor task launch worker for task 7] INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 3.0 (TID 7). 754 bytes result sent to driver
2021-12-04 17:38:12,927 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 3.0 (TID 7) in 671 ms on localhost (executor driver) (2/2)
2021-12-04 17:38:12,927 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 3.0, whose tasks have all completed, from pool 
2021-12-04 17:38:12,927 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 3 (count at PaidPromotionAdjustParameter.scala:122) finished in 0.676 s
2021-12-04 17:38:12,927 [main] INFO [org.apache.spark.scheduler.DAGScheduler] - Job 3 finished: count at PaidPromotionAdjustParameter.scala:122, took 0.677465 s
2021-12-04 17:38:12,928 [main] INFO [PaidPromotion$] - 初次切分验证集数量：49704
2021-12-04 17:38:12,978 [main] INFO [PaidPromotion$] - -----------------------------------
2021-12-04 17:38:12,980 [main] INFO [org.apache.spark.SparkContext] - Starting job: count at PaidPromotionAdjustParameter.scala:138
2021-12-04 17:38:12,986 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 6 (distinct at PaidPromotionAdjustParameter.scala:128)
2021-12-04 17:38:12,986 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 4 (count at PaidPromotionAdjustParameter.scala:138) with 2 output partitions
2021-12-04 17:38:12,986 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 5 (count at PaidPromotionAdjustParameter.scala:138)
2021-12-04 17:38:12,986 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 4)
2021-12-04 17:38:12,987 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List(ShuffleMapStage 4)
2021-12-04 17:38:12,988 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ShuffleMapStage 4 (MapPartitionsRDD[6] at distinct at PaidPromotionAdjustParameter.scala:128), which has no missing parents
2021-12-04 17:38:12,996 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_5 stored as values in memory (estimated size 5.2 KB, free 1990.5 MB)
2021-12-04 17:38:12,999 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_5_piece0 stored as bytes in memory (estimated size 2.9 KB, free 1990.5 MB)
2021-12-04 17:38:12,999 [dispatcher-event-loop-6] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_5_piece0 in memory on qb:60666 (size: 2.9 KB, free: 1990.8 MB)
2021-12-04 17:38:12,999 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 5 from broadcast at DAGScheduler.scala:1039
2021-12-04 17:38:13,001 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from ShuffleMapStage 4 (MapPartitionsRDD[6] at distinct at PaidPromotionAdjustParameter.scala:128) (first 15 tasks are for partitions Vector(0, 1))
2021-12-04 17:38:13,001 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 4.0 with 2 tasks
2021-12-04 17:38:13,003 [dispatcher-event-loop-7] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 4.0 (TID 8, localhost, executor driver, partition 0, ANY, 7885 bytes)
2021-12-04 17:38:13,003 [dispatcher-event-loop-7] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 4.0 (TID 9, localhost, executor driver, partition 1, ANY, 7885 bytes)
2021-12-04 17:38:13,003 [Executor task launch worker for task 8] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 4.0 (TID 8)
2021-12-04 17:38:13,003 [Executor task launch worker for task 9] INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 4.0 (TID 9)
2021-12-04 17:38:13,006 [Executor task launch worker for task 9] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/order_data.bcp:3442194+3442195
2021-12-04 17:38:13,006 [Executor task launch worker for task 8] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/order_data.bcp:0+3442194
2021-12-04 17:38:13,375 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 76
2021-12-04 17:38:13,376 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 85
2021-12-04 17:38:13,376 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 81
2021-12-04 17:38:13,376 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 93
2021-12-04 17:38:13,376 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 79
2021-12-04 17:38:13,376 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 92
2021-12-04 17:38:13,376 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 88
2021-12-04 17:38:13,376 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 75
2021-12-04 17:38:13,376 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 89
2021-12-04 17:38:13,376 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 87
2021-12-04 17:38:13,376 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 80
2021-12-04 17:38:13,376 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 82
2021-12-04 17:38:13,377 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 83
2021-12-04 17:38:13,377 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 95
2021-12-04 17:38:13,377 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 98
2021-12-04 17:38:13,377 [dispatcher-event-loop-3] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_4_piece0 on qb:60666 in memory (size: 2.1 KB, free: 1990.8 MB)
2021-12-04 17:38:13,378 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 78
2021-12-04 17:38:13,378 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 97
2021-12-04 17:38:13,378 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 99
2021-12-04 17:38:13,378 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 84
2021-12-04 17:38:13,378 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 77
2021-12-04 17:38:13,378 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 86
2021-12-04 17:38:13,378 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 96
2021-12-04 17:38:13,378 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 94
2021-12-04 17:38:13,378 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 90
2021-12-04 17:38:13,378 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 91
2021-12-04 17:38:13,482 [Executor task launch worker for task 9] INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 4.0 (TID 9). 1032 bytes result sent to driver
2021-12-04 17:38:13,496 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 4.0 (TID 9) in 493 ms on localhost (executor driver) (1/2)
2021-12-04 17:38:13,677 [Executor task launch worker for task 8] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 4.0 (TID 8). 1032 bytes result sent to driver
2021-12-04 17:38:13,678 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 4.0 (TID 8) in 677 ms on localhost (executor driver) (2/2)
2021-12-04 17:38:13,678 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 4.0, whose tasks have all completed, from pool 
2021-12-04 17:38:13,678 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ShuffleMapStage 4 (distinct at PaidPromotionAdjustParameter.scala:128) finished in 0.688 s
2021-12-04 17:38:13,678 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - looking for newly runnable stages
2021-12-04 17:38:13,679 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - running: Set()
2021-12-04 17:38:13,679 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - waiting: Set(ResultStage 5)
2021-12-04 17:38:13,679 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - failed: Set()
2021-12-04 17:38:13,682 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 5 (MapPartitionsRDD[8] at distinct at PaidPromotionAdjustParameter.scala:128), which has no missing parents
2021-12-04 17:38:13,687 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_6 stored as values in memory (estimated size 3.7 KB, free 1990.5 MB)
2021-12-04 17:38:13,690 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_6_piece0 stored as bytes in memory (estimated size 2.2 KB, free 1990.5 MB)
2021-12-04 17:38:13,691 [dispatcher-event-loop-9] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_6_piece0 in memory on qb:60666 (size: 2.2 KB, free: 1990.8 MB)
2021-12-04 17:38:13,691 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 6 from broadcast at DAGScheduler.scala:1039
2021-12-04 17:38:13,691 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from ResultStage 5 (MapPartitionsRDD[8] at distinct at PaidPromotionAdjustParameter.scala:128) (first 15 tasks are for partitions Vector(0, 1))
2021-12-04 17:38:13,691 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 5.0 with 2 tasks
2021-12-04 17:38:13,693 [dispatcher-event-loop-11] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 5.0 (TID 10, localhost, executor driver, partition 0, ANY, 7649 bytes)
2021-12-04 17:38:13,693 [dispatcher-event-loop-11] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 5.0 (TID 11, localhost, executor driver, partition 1, ANY, 7649 bytes)
2021-12-04 17:38:13,693 [Executor task launch worker for task 11] INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 5.0 (TID 11)
2021-12-04 17:38:13,693 [Executor task launch worker for task 10] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 5.0 (TID 10)
2021-12-04 17:38:13,705 [Executor task launch worker for task 10] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 2 non-empty blocks out of 2 blocks
2021-12-04 17:38:13,705 [Executor task launch worker for task 11] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 2 non-empty blocks out of 2 blocks
2021-12-04 17:38:13,706 [Executor task launch worker for task 10] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 5 ms
2021-12-04 17:38:13,706 [Executor task launch worker for task 11] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 5 ms
2021-12-04 17:38:13,818 [Executor task launch worker for task 11] INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 5.0 (TID 11). 1055 bytes result sent to driver
2021-12-04 17:38:13,818 [Executor task launch worker for task 10] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 5.0 (TID 10). 1055 bytes result sent to driver
2021-12-04 17:38:13,818 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 5.0 (TID 11) in 125 ms on localhost (executor driver) (1/2)
2021-12-04 17:38:13,818 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 5.0 (TID 10) in 126 ms on localhost (executor driver) (2/2)
2021-12-04 17:38:13,818 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 5.0, whose tasks have all completed, from pool 
2021-12-04 17:38:13,819 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 5 (count at PaidPromotionAdjustParameter.scala:138) finished in 0.135 s
2021-12-04 17:38:13,820 [main] INFO [org.apache.spark.scheduler.DAGScheduler] - Job 4 finished: count at PaidPromotionAdjustParameter.scala:138, took 0.840533 s
2021-12-04 17:38:13,820 [main] INFO [PaidPromotion$] - 训练集用户数 = 53690
2021-12-04 17:38:13,822 [main] INFO [org.apache.spark.SparkContext] - Starting job: count at PaidPromotionAdjustParameter.scala:139
2021-12-04 17:38:13,823 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 10 (distinct at PaidPromotionAdjustParameter.scala:129)
2021-12-04 17:38:13,823 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 5 (count at PaidPromotionAdjustParameter.scala:139) with 2 output partitions
2021-12-04 17:38:13,823 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 7 (count at PaidPromotionAdjustParameter.scala:139)
2021-12-04 17:38:13,823 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 6)
2021-12-04 17:38:13,823 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List(ShuffleMapStage 6)
2021-12-04 17:38:13,824 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ShuffleMapStage 6 (MapPartitionsRDD[10] at distinct at PaidPromotionAdjustParameter.scala:129), which has no missing parents
2021-12-04 17:38:13,825 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_7 stored as values in memory (estimated size 5.2 KB, free 1990.4 MB)
2021-12-04 17:38:13,827 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_7_piece0 stored as bytes in memory (estimated size 2.9 KB, free 1990.4 MB)
2021-12-04 17:38:13,828 [dispatcher-event-loop-0] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_7_piece0 in memory on qb:60666 (size: 2.9 KB, free: 1990.8 MB)
2021-12-04 17:38:13,828 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 7 from broadcast at DAGScheduler.scala:1039
2021-12-04 17:38:13,829 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from ShuffleMapStage 6 (MapPartitionsRDD[10] at distinct at PaidPromotionAdjustParameter.scala:129) (first 15 tasks are for partitions Vector(0, 1))
2021-12-04 17:38:13,829 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 6.0 with 2 tasks
2021-12-04 17:38:13,829 [dispatcher-event-loop-5] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 6.0 (TID 12, localhost, executor driver, partition 0, ANY, 7885 bytes)
2021-12-04 17:38:13,830 [dispatcher-event-loop-5] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 6.0 (TID 13, localhost, executor driver, partition 1, ANY, 7885 bytes)
2021-12-04 17:38:13,830 [Executor task launch worker for task 12] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 6.0 (TID 12)
2021-12-04 17:38:13,830 [Executor task launch worker for task 13] INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 6.0 (TID 13)
2021-12-04 17:38:13,831 [Executor task launch worker for task 12] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/order_data.bcp:0+3442194
2021-12-04 17:38:13,831 [Executor task launch worker for task 13] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/order_data.bcp:3442194+3442195
2021-12-04 17:38:14,309 [Executor task launch worker for task 12] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 6.0 (TID 12). 989 bytes result sent to driver
2021-12-04 17:38:14,310 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 6.0 (TID 12) in 481 ms on localhost (executor driver) (1/2)
2021-12-04 17:38:14,355 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 149
2021-12-04 17:38:14,355 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 106
2021-12-04 17:38:14,355 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 139
2021-12-04 17:38:14,355 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 126
2021-12-04 17:38:14,355 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 146
2021-12-04 17:38:14,356 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 102
2021-12-04 17:38:14,356 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 148
2021-12-04 17:38:14,356 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 132
2021-12-04 17:38:14,356 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 116
2021-12-04 17:38:14,356 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 136
2021-12-04 17:38:14,356 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 119
2021-12-04 17:38:14,356 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 134
2021-12-04 17:38:14,356 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 145
2021-12-04 17:38:14,356 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 124
2021-12-04 17:38:14,356 [dispatcher-event-loop-11] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_6_piece0 on qb:60666 in memory (size: 2.2 KB, free: 1990.8 MB)
2021-12-04 17:38:14,357 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 113
2021-12-04 17:38:14,357 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 110
2021-12-04 17:38:14,357 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 118
2021-12-04 17:38:14,357 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 103
2021-12-04 17:38:14,357 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 120
2021-12-04 17:38:14,357 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 121
2021-12-04 17:38:14,357 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 127
2021-12-04 17:38:14,357 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 111
2021-12-04 17:38:14,357 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 131
2021-12-04 17:38:14,357 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 141
2021-12-04 17:38:14,357 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 107
2021-12-04 17:38:14,358 [dispatcher-event-loop-1] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_5_piece0 on qb:60666 in memory (size: 2.9 KB, free: 1990.8 MB)
2021-12-04 17:38:14,358 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 143
2021-12-04 17:38:14,358 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 123
2021-12-04 17:38:14,358 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 142
2021-12-04 17:38:14,358 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 129
2021-12-04 17:38:14,358 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 117
2021-12-04 17:38:14,358 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 100
2021-12-04 17:38:14,358 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 125
2021-12-04 17:38:14,358 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 140
2021-12-04 17:38:14,358 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 128
2021-12-04 17:38:14,358 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 144
2021-12-04 17:38:14,358 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 138
2021-12-04 17:38:14,358 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 112
2021-12-04 17:38:14,358 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 137
2021-12-04 17:38:14,358 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 101
2021-12-04 17:38:14,358 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 109
2021-12-04 17:38:14,358 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 104
2021-12-04 17:38:14,358 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 147
2021-12-04 17:38:14,358 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 115
2021-12-04 17:38:14,358 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 135
2021-12-04 17:38:14,358 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 105
2021-12-04 17:38:14,358 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 122
2021-12-04 17:38:14,358 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 114
2021-12-04 17:38:14,358 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 133
2021-12-04 17:38:14,358 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 108
2021-12-04 17:38:14,358 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 130
2021-12-04 17:38:14,575 [Executor task launch worker for task 13] INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 6.0 (TID 13). 1032 bytes result sent to driver
2021-12-04 17:38:14,575 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 6.0 (TID 13) in 746 ms on localhost (executor driver) (2/2)
2021-12-04 17:38:14,575 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 6.0, whose tasks have all completed, from pool 
2021-12-04 17:38:14,576 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ShuffleMapStage 6 (distinct at PaidPromotionAdjustParameter.scala:129) finished in 0.752 s
2021-12-04 17:38:14,576 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - looking for newly runnable stages
2021-12-04 17:38:14,576 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - running: Set()
2021-12-04 17:38:14,576 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - waiting: Set(ResultStage 7)
2021-12-04 17:38:14,576 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - failed: Set()
2021-12-04 17:38:14,576 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 7 (MapPartitionsRDD[12] at distinct at PaidPromotionAdjustParameter.scala:129), which has no missing parents
2021-12-04 17:38:14,577 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_8 stored as values in memory (estimated size 3.7 KB, free 1990.5 MB)
2021-12-04 17:38:14,579 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_8_piece0 stored as bytes in memory (estimated size 2.2 KB, free 1990.5 MB)
2021-12-04 17:38:14,580 [dispatcher-event-loop-0] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_8_piece0 in memory on qb:60666 (size: 2.2 KB, free: 1990.8 MB)
2021-12-04 17:38:14,580 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 8 from broadcast at DAGScheduler.scala:1039
2021-12-04 17:38:14,580 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from ResultStage 7 (MapPartitionsRDD[12] at distinct at PaidPromotionAdjustParameter.scala:129) (first 15 tasks are for partitions Vector(0, 1))
2021-12-04 17:38:14,581 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 7.0 with 2 tasks
2021-12-04 17:38:14,581 [dispatcher-event-loop-5] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 7.0 (TID 14, localhost, executor driver, partition 0, ANY, 7649 bytes)
2021-12-04 17:38:14,581 [dispatcher-event-loop-5] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 7.0 (TID 15, localhost, executor driver, partition 1, ANY, 7649 bytes)
2021-12-04 17:38:14,581 [Executor task launch worker for task 14] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 7.0 (TID 14)
2021-12-04 17:38:14,581 [Executor task launch worker for task 15] INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 7.0 (TID 15)
2021-12-04 17:38:14,583 [Executor task launch worker for task 15] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 2 non-empty blocks out of 2 blocks
2021-12-04 17:38:14,583 [Executor task launch worker for task 14] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 2 non-empty blocks out of 2 blocks
2021-12-04 17:38:14,583 [Executor task launch worker for task 15] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 1 ms
2021-12-04 17:38:14,583 [Executor task launch worker for task 14] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-04 17:38:14,634 [Executor task launch worker for task 15] INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 7.0 (TID 15). 1012 bytes result sent to driver
2021-12-04 17:38:14,635 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 7.0 (TID 15) in 54 ms on localhost (executor driver) (1/2)
2021-12-04 17:38:14,638 [Executor task launch worker for task 14] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 7.0 (TID 14). 1012 bytes result sent to driver
2021-12-04 17:38:14,639 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 7.0 (TID 14) in 58 ms on localhost (executor driver) (2/2)
2021-12-04 17:38:14,639 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 7.0, whose tasks have all completed, from pool 
2021-12-04 17:38:14,639 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 7 (count at PaidPromotionAdjustParameter.scala:139) finished in 0.062 s
2021-12-04 17:38:14,640 [main] INFO [org.apache.spark.scheduler.DAGScheduler] - Job 5 finished: count at PaidPromotionAdjustParameter.scala:139, took 0.816392 s
2021-12-04 17:38:14,640 [main] INFO [PaidPromotion$] - 验证集用户数 = 46818
2021-12-04 17:38:14,644 [main] INFO [org.apache.spark.SparkContext] - Starting job: count at PaidPromotionAdjustParameter.scala:140
2021-12-04 17:38:14,645 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 13 (intersection at PaidPromotionAdjustParameter.scala:130)
2021-12-04 17:38:14,645 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 14 (intersection at PaidPromotionAdjustParameter.scala:130)
2021-12-04 17:38:14,645 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 6 (count at PaidPromotionAdjustParameter.scala:140) with 2 output partitions
2021-12-04 17:38:14,645 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 12 (count at PaidPromotionAdjustParameter.scala:140)
2021-12-04 17:38:14,645 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 9, ShuffleMapStage 11)
2021-12-04 17:38:14,645 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List(ShuffleMapStage 9, ShuffleMapStage 11)
2021-12-04 17:38:14,646 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ShuffleMapStage 9 (MapPartitionsRDD[13] at intersection at PaidPromotionAdjustParameter.scala:130), which has no missing parents
2021-12-04 17:38:14,647 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_9 stored as values in memory (estimated size 4.0 KB, free 1990.5 MB)
2021-12-04 17:38:14,649 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_9_piece0 stored as bytes in memory (estimated size 2.3 KB, free 1990.4 MB)
2021-12-04 17:38:14,650 [dispatcher-event-loop-4] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_9_piece0 in memory on qb:60666 (size: 2.3 KB, free: 1990.8 MB)
2021-12-04 17:38:14,650 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 9 from broadcast at DAGScheduler.scala:1039
2021-12-04 17:38:14,650 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from ShuffleMapStage 9 (MapPartitionsRDD[13] at intersection at PaidPromotionAdjustParameter.scala:130) (first 15 tasks are for partitions Vector(0, 1))
2021-12-04 17:38:14,650 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 9.0 with 2 tasks
2021-12-04 17:38:14,651 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ShuffleMapStage 11 (MapPartitionsRDD[14] at intersection at PaidPromotionAdjustParameter.scala:130), which has no missing parents
2021-12-04 17:38:14,651 [dispatcher-event-loop-11] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 9.0 (TID 16, localhost, executor driver, partition 0, ANY, 7638 bytes)
2021-12-04 17:38:14,651 [dispatcher-event-loop-11] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 9.0 (TID 17, localhost, executor driver, partition 1, ANY, 7638 bytes)
2021-12-04 17:38:14,651 [Executor task launch worker for task 17] INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 9.0 (TID 17)
2021-12-04 17:38:14,651 [Executor task launch worker for task 16] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 9.0 (TID 16)
2021-12-04 17:38:14,652 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_10 stored as values in memory (estimated size 4.0 KB, free 1990.4 MB)
2021-12-04 17:38:14,654 [Executor task launch worker for task 17] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 2 non-empty blocks out of 2 blocks
2021-12-04 17:38:14,654 [Executor task launch worker for task 17] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 1 ms
2021-12-04 17:38:14,654 [Executor task launch worker for task 16] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 2 non-empty blocks out of 2 blocks
2021-12-04 17:38:14,654 [Executor task launch worker for task 16] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-04 17:38:14,655 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_10_piece0 stored as bytes in memory (estimated size 2.3 KB, free 1990.4 MB)
2021-12-04 17:38:14,655 [dispatcher-event-loop-1] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_10_piece0 in memory on qb:60666 (size: 2.3 KB, free: 1990.8 MB)
2021-12-04 17:38:14,656 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 10 from broadcast at DAGScheduler.scala:1039
2021-12-04 17:38:14,656 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from ShuffleMapStage 11 (MapPartitionsRDD[14] at intersection at PaidPromotionAdjustParameter.scala:130) (first 15 tasks are for partitions Vector(0, 1))
2021-12-04 17:38:14,656 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 11.0 with 2 tasks
2021-12-04 17:38:14,657 [dispatcher-event-loop-7] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 11.0 (TID 18, localhost, executor driver, partition 0, ANY, 7638 bytes)
2021-12-04 17:38:14,657 [dispatcher-event-loop-7] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 11.0 (TID 19, localhost, executor driver, partition 1, ANY, 7638 bytes)
2021-12-04 17:38:14,658 [Executor task launch worker for task 18] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 11.0 (TID 18)
2021-12-04 17:38:14,658 [Executor task launch worker for task 19] INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 11.0 (TID 19)
2021-12-04 17:38:14,660 [Executor task launch worker for task 18] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 2 non-empty blocks out of 2 blocks
2021-12-04 17:38:14,660 [Executor task launch worker for task 19] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 2 non-empty blocks out of 2 blocks
2021-12-04 17:38:14,660 [Executor task launch worker for task 19] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-04 17:38:14,660 [Executor task launch worker for task 18] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 1 ms
2021-12-04 17:38:14,737 [Executor task launch worker for task 18] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 11.0 (TID 18). 1161 bytes result sent to driver
2021-12-04 17:38:14,737 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 11.0 (TID 18) in 80 ms on localhost (executor driver) (1/2)
2021-12-04 17:38:14,739 [Executor task launch worker for task 17] INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 9.0 (TID 17). 1204 bytes result sent to driver
2021-12-04 17:38:14,740 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 9.0 (TID 17) in 89 ms on localhost (executor driver) (1/2)
2021-12-04 17:38:14,740 [Executor task launch worker for task 19] INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 11.0 (TID 19). 1161 bytes result sent to driver
2021-12-04 17:38:14,741 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 11.0 (TID 19) in 84 ms on localhost (executor driver) (2/2)
2021-12-04 17:38:14,741 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 11.0, whose tasks have all completed, from pool 
2021-12-04 17:38:14,741 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ShuffleMapStage 11 (intersection at PaidPromotionAdjustParameter.scala:130) finished in 0.090 s
2021-12-04 17:38:14,741 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - looking for newly runnable stages
2021-12-04 17:38:14,741 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - running: Set(ShuffleMapStage 9)
2021-12-04 17:38:14,741 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - waiting: Set(ResultStage 12)
2021-12-04 17:38:14,741 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - failed: Set()
2021-12-04 17:38:14,746 [Executor task launch worker for task 16] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 9.0 (TID 16). 1247 bytes result sent to driver
2021-12-04 17:38:14,746 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 9.0 (TID 16) in 95 ms on localhost (executor driver) (2/2)
2021-12-04 17:38:14,747 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 9.0, whose tasks have all completed, from pool 
2021-12-04 17:38:14,747 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ShuffleMapStage 9 (intersection at PaidPromotionAdjustParameter.scala:130) finished in 0.101 s
2021-12-04 17:38:14,747 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - looking for newly runnable stages
2021-12-04 17:38:14,747 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - running: Set()
2021-12-04 17:38:14,747 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - waiting: Set(ResultStage 12)
2021-12-04 17:38:14,747 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - failed: Set()
2021-12-04 17:38:14,747 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 12 (MapPartitionsRDD[18] at intersection at PaidPromotionAdjustParameter.scala:130), which has no missing parents
2021-12-04 17:38:14,749 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_11 stored as values in memory (estimated size 3.6 KB, free 1990.4 MB)
2021-12-04 17:38:14,751 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_11_piece0 stored as bytes in memory (estimated size 2.1 KB, free 1990.4 MB)
2021-12-04 17:38:14,752 [dispatcher-event-loop-4] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_11_piece0 in memory on qb:60666 (size: 2.1 KB, free: 1990.8 MB)
2021-12-04 17:38:14,752 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 11 from broadcast at DAGScheduler.scala:1039
2021-12-04 17:38:14,752 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from ResultStage 12 (MapPartitionsRDD[18] at intersection at PaidPromotionAdjustParameter.scala:130) (first 15 tasks are for partitions Vector(0, 1))
2021-12-04 17:38:14,752 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 12.0 with 2 tasks
2021-12-04 17:38:14,753 [dispatcher-event-loop-11] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 12.0 (TID 20, localhost, executor driver, partition 0, PROCESS_LOCAL, 7712 bytes)
2021-12-04 17:38:14,753 [dispatcher-event-loop-11] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 12.0 (TID 21, localhost, executor driver, partition 1, PROCESS_LOCAL, 7712 bytes)
2021-12-04 17:38:14,754 [Executor task launch worker for task 21] INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 12.0 (TID 21)
2021-12-04 17:38:14,754 [Executor task launch worker for task 20] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 12.0 (TID 20)
2021-12-04 17:38:14,756 [Executor task launch worker for task 21] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2021-12-04 17:38:14,756 [Executor task launch worker for task 20] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2021-12-04 17:38:14,756 [Executor task launch worker for task 21] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-04 17:38:14,756 [Executor task launch worker for task 20] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-04 17:38:14,758 [Executor task launch worker for task 21] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2021-12-04 17:38:14,758 [Executor task launch worker for task 20] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2021-12-04 17:38:14,758 [Executor task launch worker for task 21] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-04 17:38:14,758 [Executor task launch worker for task 20] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-04 17:38:14,890 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 165
2021-12-04 17:38:14,890 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 151
2021-12-04 17:38:14,891 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 159
2021-12-04 17:38:14,891 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 187
2021-12-04 17:38:14,891 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 155
2021-12-04 17:38:14,891 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 162
2021-12-04 17:38:14,891 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 168
2021-12-04 17:38:14,892 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 152
2021-12-04 17:38:14,892 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 177
2021-12-04 17:38:14,892 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 198
2021-12-04 17:38:14,892 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 192
2021-12-04 17:38:14,892 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 186
2021-12-04 17:38:14,892 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 153
2021-12-04 17:38:14,892 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 160
2021-12-04 17:38:14,892 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 181
2021-12-04 17:38:14,892 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 173
2021-12-04 17:38:14,892 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 184
2021-12-04 17:38:14,892 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 154
2021-12-04 17:38:14,892 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 197
2021-12-04 17:38:14,893 [dispatcher-event-loop-0] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_10_piece0 on qb:60666 in memory (size: 2.3 KB, free: 1990.8 MB)
2021-12-04 17:38:14,893 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 150
2021-12-04 17:38:14,894 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 158
2021-12-04 17:38:14,894 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 175
2021-12-04 17:38:14,894 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 156
2021-12-04 17:38:14,894 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 171
2021-12-04 17:38:14,894 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 195
2021-12-04 17:38:14,894 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 161
2021-12-04 17:38:14,894 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 182
2021-12-04 17:38:14,894 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 170
2021-12-04 17:38:14,894 [dispatcher-event-loop-3] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_9_piece0 on qb:60666 in memory (size: 2.3 KB, free: 1990.8 MB)
2021-12-04 17:38:14,895 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 199
2021-12-04 17:38:14,895 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 180
2021-12-04 17:38:14,895 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 193
2021-12-04 17:38:14,895 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 185
2021-12-04 17:38:14,895 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 194
2021-12-04 17:38:14,895 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 167
2021-12-04 17:38:14,895 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 176
2021-12-04 17:38:14,896 [dispatcher-event-loop-4] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_7_piece0 on qb:60666 in memory (size: 2.9 KB, free: 1990.8 MB)
2021-12-04 17:38:14,896 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 189
2021-12-04 17:38:14,896 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 163
2021-12-04 17:38:14,896 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 164
2021-12-04 17:38:14,896 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 190
2021-12-04 17:38:14,896 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 188
2021-12-04 17:38:14,896 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 178
2021-12-04 17:38:14,897 [dispatcher-event-loop-6] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_8_piece0 on qb:60666 in memory (size: 2.2 KB, free: 1990.8 MB)
2021-12-04 17:38:14,897 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 179
2021-12-04 17:38:14,897 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 166
2021-12-04 17:38:14,897 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 174
2021-12-04 17:38:14,897 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 157
2021-12-04 17:38:14,897 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 172
2021-12-04 17:38:14,898 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 196
2021-12-04 17:38:14,898 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 183
2021-12-04 17:38:14,898 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 191
2021-12-04 17:38:14,898 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 169
2021-12-04 17:38:14,926 [Executor task launch worker for task 20] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 12.0 (TID 20). 1054 bytes result sent to driver
2021-12-04 17:38:14,927 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 12.0 (TID 20) in 174 ms on localhost (executor driver) (1/2)
2021-12-04 17:38:14,929 [Executor task launch worker for task 21] INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 12.0 (TID 21). 1054 bytes result sent to driver
2021-12-04 17:38:14,929 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 12.0 (TID 21) in 176 ms on localhost (executor driver) (2/2)
2021-12-04 17:38:14,929 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 12.0, whose tasks have all completed, from pool 
2021-12-04 17:38:14,929 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 12 (count at PaidPromotionAdjustParameter.scala:140) finished in 0.182 s
2021-12-04 17:38:14,929 [main] INFO [org.apache.spark.scheduler.DAGScheduler] - Job 6 finished: count at PaidPromotionAdjustParameter.scala:140, took 0.285126 s
2021-12-04 17:38:14,930 [main] INFO [PaidPromotion$] - 共 同 用户数 = 5185
2021-12-04 17:38:14,932 [main] INFO [org.apache.spark.SparkContext] - Starting job: count at PaidPromotionAdjustParameter.scala:141
2021-12-04 17:38:14,932 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 20 (distinct at PaidPromotionAdjustParameter.scala:133)
2021-12-04 17:38:14,933 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 7 (count at PaidPromotionAdjustParameter.scala:141) with 2 output partitions
2021-12-04 17:38:14,933 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 14 (count at PaidPromotionAdjustParameter.scala:141)
2021-12-04 17:38:14,933 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 13)
2021-12-04 17:38:14,933 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List(ShuffleMapStage 13)
2021-12-04 17:38:14,933 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ShuffleMapStage 13 (MapPartitionsRDD[20] at distinct at PaidPromotionAdjustParameter.scala:133), which has no missing parents
2021-12-04 17:38:14,934 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_12 stored as values in memory (estimated size 5.2 KB, free 1990.5 MB)
2021-12-04 17:38:14,936 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_12_piece0 stored as bytes in memory (estimated size 2.9 KB, free 1990.5 MB)
2021-12-04 17:38:14,936 [dispatcher-event-loop-0] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_12_piece0 in memory on qb:60666 (size: 2.9 KB, free: 1990.8 MB)
2021-12-04 17:38:14,936 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 12 from broadcast at DAGScheduler.scala:1039
2021-12-04 17:38:14,937 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from ShuffleMapStage 13 (MapPartitionsRDD[20] at distinct at PaidPromotionAdjustParameter.scala:133) (first 15 tasks are for partitions Vector(0, 1))
2021-12-04 17:38:14,937 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 13.0 with 2 tasks
2021-12-04 17:38:14,937 [dispatcher-event-loop-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 13.0 (TID 22, localhost, executor driver, partition 0, ANY, 7885 bytes)
2021-12-04 17:38:14,937 [dispatcher-event-loop-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 13.0 (TID 23, localhost, executor driver, partition 1, ANY, 7885 bytes)
2021-12-04 17:38:14,937 [Executor task launch worker for task 22] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 13.0 (TID 22)
2021-12-04 17:38:14,937 [Executor task launch worker for task 23] INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 13.0 (TID 23)
2021-12-04 17:38:14,939 [Executor task launch worker for task 22] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/order_data.bcp:0+3442194
2021-12-04 17:38:14,939 [Executor task launch worker for task 23] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/order_data.bcp:3442194+3442195
2021-12-04 17:38:15,319 [Executor task launch worker for task 23] INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 13.0 (TID 23). 989 bytes result sent to driver
2021-12-04 17:38:15,319 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 13.0 (TID 23) in 382 ms on localhost (executor driver) (1/2)
2021-12-04 17:38:15,588 [Executor task launch worker for task 22] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 13.0 (TID 22). 989 bytes result sent to driver
2021-12-04 17:38:15,588 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 13.0 (TID 22) in 651 ms on localhost (executor driver) (2/2)
2021-12-04 17:38:15,588 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 13.0, whose tasks have all completed, from pool 
2021-12-04 17:38:15,589 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ShuffleMapStage 13 (distinct at PaidPromotionAdjustParameter.scala:133) finished in 0.656 s
2021-12-04 17:38:15,589 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - looking for newly runnable stages
2021-12-04 17:38:15,589 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - running: Set()
2021-12-04 17:38:15,589 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - waiting: Set(ResultStage 14)
2021-12-04 17:38:15,589 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - failed: Set()
2021-12-04 17:38:15,589 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 14 (MapPartitionsRDD[22] at distinct at PaidPromotionAdjustParameter.scala:133), which has no missing parents
2021-12-04 17:38:15,590 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_13 stored as values in memory (estimated size 3.7 KB, free 1990.5 MB)
2021-12-04 17:38:15,592 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_13_piece0 stored as bytes in memory (estimated size 2.2 KB, free 1990.4 MB)
2021-12-04 17:38:15,592 [dispatcher-event-loop-4] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_13_piece0 in memory on qb:60666 (size: 2.2 KB, free: 1990.8 MB)
2021-12-04 17:38:15,592 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 13 from broadcast at DAGScheduler.scala:1039
2021-12-04 17:38:15,593 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from ResultStage 14 (MapPartitionsRDD[22] at distinct at PaidPromotionAdjustParameter.scala:133) (first 15 tasks are for partitions Vector(0, 1))
2021-12-04 17:38:15,593 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 14.0 with 2 tasks
2021-12-04 17:38:15,593 [dispatcher-event-loop-10] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 14.0 (TID 24, localhost, executor driver, partition 0, ANY, 7649 bytes)
2021-12-04 17:38:15,593 [dispatcher-event-loop-10] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 14.0 (TID 25, localhost, executor driver, partition 1, ANY, 7649 bytes)
2021-12-04 17:38:15,593 [Executor task launch worker for task 24] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 14.0 (TID 24)
2021-12-04 17:38:15,593 [Executor task launch worker for task 25] INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 14.0 (TID 25)
2021-12-04 17:38:15,594 [Executor task launch worker for task 25] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 2 non-empty blocks out of 2 blocks
2021-12-04 17:38:15,594 [Executor task launch worker for task 24] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 2 non-empty blocks out of 2 blocks
2021-12-04 17:38:15,594 [Executor task launch worker for task 25] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-04 17:38:15,594 [Executor task launch worker for task 24] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-04 17:38:15,606 [Executor task launch worker for task 24] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 14.0 (TID 24). 967 bytes result sent to driver
2021-12-04 17:38:15,606 [Executor task launch worker for task 25] INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 14.0 (TID 25). 967 bytes result sent to driver
2021-12-04 17:38:15,607 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 14.0 (TID 24) in 14 ms on localhost (executor driver) (1/2)
2021-12-04 17:38:15,607 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 14.0 (TID 25) in 14 ms on localhost (executor driver) (2/2)
2021-12-04 17:38:15,607 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 14.0, whose tasks have all completed, from pool 
2021-12-04 17:38:15,607 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 14 (count at PaidPromotionAdjustParameter.scala:141) finished in 0.018 s
2021-12-04 17:38:15,607 [main] INFO [org.apache.spark.scheduler.DAGScheduler] - Job 7 finished: count at PaidPromotionAdjustParameter.scala:141, took 0.674670 s
2021-12-04 17:38:15,607 [main] INFO [PaidPromotion$] - 训练集节目数 = 121
2021-12-04 17:38:15,610 [main] INFO [org.apache.spark.SparkContext] - Starting job: count at PaidPromotionAdjustParameter.scala:142
2021-12-04 17:38:15,610 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 24 (distinct at PaidPromotionAdjustParameter.scala:134)
2021-12-04 17:38:15,610 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 8 (count at PaidPromotionAdjustParameter.scala:142) with 2 output partitions
2021-12-04 17:38:15,610 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 16 (count at PaidPromotionAdjustParameter.scala:142)
2021-12-04 17:38:15,610 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 15)
2021-12-04 17:38:15,610 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List(ShuffleMapStage 15)
2021-12-04 17:38:15,611 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ShuffleMapStage 15 (MapPartitionsRDD[24] at distinct at PaidPromotionAdjustParameter.scala:134), which has no missing parents
2021-12-04 17:38:15,612 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_14 stored as values in memory (estimated size 5.2 KB, free 1990.4 MB)
2021-12-04 17:38:15,614 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_14_piece0 stored as bytes in memory (estimated size 2.9 KB, free 1990.4 MB)
2021-12-04 17:38:15,615 [dispatcher-event-loop-0] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_14_piece0 in memory on qb:60666 (size: 2.9 KB, free: 1990.8 MB)
2021-12-04 17:38:15,615 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 14 from broadcast at DAGScheduler.scala:1039
2021-12-04 17:38:15,615 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from ShuffleMapStage 15 (MapPartitionsRDD[24] at distinct at PaidPromotionAdjustParameter.scala:134) (first 15 tasks are for partitions Vector(0, 1))
2021-12-04 17:38:15,615 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 15.0 with 2 tasks
2021-12-04 17:38:15,616 [dispatcher-event-loop-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 15.0 (TID 26, localhost, executor driver, partition 0, ANY, 7885 bytes)
2021-12-04 17:38:15,616 [dispatcher-event-loop-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 15.0 (TID 27, localhost, executor driver, partition 1, ANY, 7885 bytes)
2021-12-04 17:38:15,616 [Executor task launch worker for task 26] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 15.0 (TID 26)
2021-12-04 17:38:15,616 [Executor task launch worker for task 27] INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 15.0 (TID 27)
2021-12-04 17:38:15,617 [Executor task launch worker for task 27] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/order_data.bcp:3442194+3442195
2021-12-04 17:38:15,617 [Executor task launch worker for task 26] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/order_data.bcp:0+3442194
2021-12-04 17:38:15,942 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 313
2021-12-04 17:38:15,942 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 295
2021-12-04 17:38:15,942 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 218
2021-12-04 17:38:15,942 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 212
2021-12-04 17:38:15,942 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 259
2021-12-04 17:38:15,943 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 277
2021-12-04 17:38:15,943 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 306
2021-12-04 17:38:15,943 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 291
2021-12-04 17:38:15,943 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 224
2021-12-04 17:38:15,943 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 320
2021-12-04 17:38:15,943 [dispatcher-event-loop-4] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_11_piece0 on qb:60666 in memory (size: 2.1 KB, free: 1990.8 MB)
2021-12-04 17:38:15,944 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 286
2021-12-04 17:38:15,944 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 283
2021-12-04 17:38:15,944 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 215
2021-12-04 17:38:15,944 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 248
2021-12-04 17:38:15,944 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 251
2021-12-04 17:38:15,944 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 317
2021-12-04 17:38:15,944 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 280
2021-12-04 17:38:15,944 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 319
2021-12-04 17:38:15,944 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 228
2021-12-04 17:38:15,944 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 274
2021-12-04 17:38:15,944 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 276
2021-12-04 17:38:15,944 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 268
2021-12-04 17:38:15,944 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 255
2021-12-04 17:38:15,944 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 216
2021-12-04 17:38:15,944 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 219
2021-12-04 17:38:15,944 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 250
2021-12-04 17:38:15,944 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 272
2021-12-04 17:38:15,944 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 314
2021-12-04 17:38:15,944 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 230
2021-12-04 17:38:15,944 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 278
2021-12-04 17:38:15,944 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 254
2021-12-04 17:38:15,944 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 305
2021-12-04 17:38:15,944 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 201
2021-12-04 17:38:15,944 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 232
2021-12-04 17:38:15,944 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 322
2021-12-04 17:38:15,944 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 318
2021-12-04 17:38:15,944 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 205
2021-12-04 17:38:15,944 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 264
2021-12-04 17:38:15,944 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 225
2021-12-04 17:38:15,944 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 275
2021-12-04 17:38:15,944 [dispatcher-event-loop-11] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_13_piece0 on qb:60666 in memory (size: 2.2 KB, free: 1990.8 MB)
2021-12-04 17:38:15,945 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 207
2021-12-04 17:38:15,945 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 271
2021-12-04 17:38:15,945 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 214
2021-12-04 17:38:15,945 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 252
2021-12-04 17:38:15,945 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 260
2021-12-04 17:38:15,945 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 265
2021-12-04 17:38:15,945 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 301
2021-12-04 17:38:15,945 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 231
2021-12-04 17:38:15,945 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 303
2021-12-04 17:38:15,945 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 263
2021-12-04 17:38:15,945 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 297
2021-12-04 17:38:15,945 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 269
2021-12-04 17:38:15,945 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 296
2021-12-04 17:38:15,945 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 237
2021-12-04 17:38:15,945 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 298
2021-12-04 17:38:15,945 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 200
2021-12-04 17:38:15,945 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 210
2021-12-04 17:38:15,945 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 300
2021-12-04 17:38:15,945 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 246
2021-12-04 17:38:15,945 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 308
2021-12-04 17:38:15,945 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 240
2021-12-04 17:38:15,945 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 249
2021-12-04 17:38:15,945 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 293
2021-12-04 17:38:15,945 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 241
2021-12-04 17:38:15,945 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 290
2021-12-04 17:38:15,945 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 309
2021-12-04 17:38:15,945 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 273
2021-12-04 17:38:15,945 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 229
2021-12-04 17:38:15,945 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 266
2021-12-04 17:38:15,945 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 323
2021-12-04 17:38:15,945 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 223
2021-12-04 17:38:15,945 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 281
2021-12-04 17:38:15,945 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 324
2021-12-04 17:38:15,945 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 221
2021-12-04 17:38:15,945 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 244
2021-12-04 17:38:15,945 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 238
2021-12-04 17:38:15,945 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 243
2021-12-04 17:38:15,945 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 321
2021-12-04 17:38:15,945 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 287
2021-12-04 17:38:15,945 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 311
2021-12-04 17:38:15,945 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 247
2021-12-04 17:38:15,945 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 213
2021-12-04 17:38:15,945 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 310
2021-12-04 17:38:15,945 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 261
2021-12-04 17:38:15,945 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 292
2021-12-04 17:38:15,945 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 242
2021-12-04 17:38:15,945 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 217
2021-12-04 17:38:15,945 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 316
2021-12-04 17:38:15,946 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 234
2021-12-04 17:38:15,946 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 302
2021-12-04 17:38:15,946 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 258
2021-12-04 17:38:15,946 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 282
2021-12-04 17:38:15,946 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 312
2021-12-04 17:38:15,946 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 315
2021-12-04 17:38:15,946 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 304
2021-12-04 17:38:15,946 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 299
2021-12-04 17:38:15,946 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 236
2021-12-04 17:38:15,946 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 220
2021-12-04 17:38:15,946 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 206
2021-12-04 17:38:15,946 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 288
2021-12-04 17:38:15,946 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 270
2021-12-04 17:38:15,946 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 202
2021-12-04 17:38:15,946 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 209
2021-12-04 17:38:15,946 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 267
2021-12-04 17:38:15,946 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 245
2021-12-04 17:38:15,946 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 203
2021-12-04 17:38:15,946 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 235
2021-12-04 17:38:15,946 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 208
2021-12-04 17:38:15,946 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 222
2021-12-04 17:38:15,946 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 289
2021-12-04 17:38:15,946 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 204
2021-12-04 17:38:15,946 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 257
2021-12-04 17:38:15,946 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 262
2021-12-04 17:38:15,946 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 294
2021-12-04 17:38:15,946 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 227
2021-12-04 17:38:15,946 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 253
2021-12-04 17:38:15,946 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 307
2021-12-04 17:38:15,946 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 211
2021-12-04 17:38:15,946 [dispatcher-event-loop-0] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_12_piece0 on qb:60666 in memory (size: 2.9 KB, free: 1990.8 MB)
2021-12-04 17:38:15,947 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 285
2021-12-04 17:38:15,947 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 279
2021-12-04 17:38:15,947 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 226
2021-12-04 17:38:15,947 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 239
2021-12-04 17:38:15,947 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 233
2021-12-04 17:38:15,947 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 284
2021-12-04 17:38:15,947 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 256
2021-12-04 17:38:16,026 [Executor task launch worker for task 26] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 15.0 (TID 26). 989 bytes result sent to driver
2021-12-04 17:38:16,026 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 15.0 (TID 26) in 410 ms on localhost (executor driver) (1/2)
2021-12-04 17:38:16,354 [Executor task launch worker for task 27] INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 15.0 (TID 27). 1032 bytes result sent to driver
2021-12-04 17:38:16,354 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 15.0 (TID 27) in 738 ms on localhost (executor driver) (2/2)
2021-12-04 17:38:16,354 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 15.0, whose tasks have all completed, from pool 
2021-12-04 17:38:16,355 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ShuffleMapStage 15 (distinct at PaidPromotionAdjustParameter.scala:134) finished in 0.744 s
2021-12-04 17:38:16,355 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - looking for newly runnable stages
2021-12-04 17:38:16,355 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - running: Set()
2021-12-04 17:38:16,355 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - waiting: Set(ResultStage 16)
2021-12-04 17:38:16,355 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - failed: Set()
2021-12-04 17:38:16,355 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 16 (MapPartitionsRDD[26] at distinct at PaidPromotionAdjustParameter.scala:134), which has no missing parents
2021-12-04 17:38:16,356 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_15 stored as values in memory (estimated size 3.7 KB, free 1990.5 MB)
2021-12-04 17:38:16,357 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_15_piece0 stored as bytes in memory (estimated size 2.2 KB, free 1990.5 MB)
2021-12-04 17:38:16,358 [dispatcher-event-loop-3] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_15_piece0 in memory on qb:60666 (size: 2.2 KB, free: 1990.8 MB)
2021-12-04 17:38:16,358 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 15 from broadcast at DAGScheduler.scala:1039
2021-12-04 17:38:16,358 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from ResultStage 16 (MapPartitionsRDD[26] at distinct at PaidPromotionAdjustParameter.scala:134) (first 15 tasks are for partitions Vector(0, 1))
2021-12-04 17:38:16,358 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 16.0 with 2 tasks
2021-12-04 17:38:16,359 [dispatcher-event-loop-8] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 16.0 (TID 28, localhost, executor driver, partition 0, ANY, 7649 bytes)
2021-12-04 17:38:16,359 [dispatcher-event-loop-8] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 16.0 (TID 29, localhost, executor driver, partition 1, ANY, 7649 bytes)
2021-12-04 17:38:16,359 [Executor task launch worker for task 29] INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 16.0 (TID 29)
2021-12-04 17:38:16,359 [Executor task launch worker for task 28] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 16.0 (TID 28)
2021-12-04 17:38:16,360 [Executor task launch worker for task 29] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 2 non-empty blocks out of 2 blocks
2021-12-04 17:38:16,360 [Executor task launch worker for task 28] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 2 non-empty blocks out of 2 blocks
2021-12-04 17:38:16,360 [Executor task launch worker for task 29] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-04 17:38:16,360 [Executor task launch worker for task 28] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-04 17:38:16,371 [Executor task launch worker for task 29] INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 16.0 (TID 29). 967 bytes result sent to driver
2021-12-04 17:38:16,371 [Executor task launch worker for task 28] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 16.0 (TID 28). 967 bytes result sent to driver
2021-12-04 17:38:16,372 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 16.0 (TID 29) in 13 ms on localhost (executor driver) (1/2)
2021-12-04 17:38:16,372 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 16.0 (TID 28) in 13 ms on localhost (executor driver) (2/2)
2021-12-04 17:38:16,372 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 16.0, whose tasks have all completed, from pool 
2021-12-04 17:38:16,372 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 16 (count at PaidPromotionAdjustParameter.scala:142) finished in 0.017 s
2021-12-04 17:38:16,372 [main] INFO [org.apache.spark.scheduler.DAGScheduler] - Job 8 finished: count at PaidPromotionAdjustParameter.scala:142, took 0.762762 s
2021-12-04 17:38:16,373 [main] INFO [PaidPromotion$] - 验证集节目数 = 120
2021-12-04 17:38:16,375 [main] INFO [org.apache.spark.SparkContext] - Starting job: count at PaidPromotionAdjustParameter.scala:143
2021-12-04 17:38:16,375 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 27 (intersection at PaidPromotionAdjustParameter.scala:135)
2021-12-04 17:38:16,376 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 28 (intersection at PaidPromotionAdjustParameter.scala:135)
2021-12-04 17:38:16,376 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 9 (count at PaidPromotionAdjustParameter.scala:143) with 2 output partitions
2021-12-04 17:38:16,376 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 21 (count at PaidPromotionAdjustParameter.scala:143)
2021-12-04 17:38:16,376 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 20, ShuffleMapStage 18)
2021-12-04 17:38:16,376 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List(ShuffleMapStage 20, ShuffleMapStage 18)
2021-12-04 17:38:16,376 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ShuffleMapStage 18 (MapPartitionsRDD[27] at intersection at PaidPromotionAdjustParameter.scala:135), which has no missing parents
2021-12-04 17:38:16,377 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_16 stored as values in memory (estimated size 4.0 KB, free 1990.5 MB)
2021-12-04 17:38:16,379 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_16_piece0 stored as bytes in memory (estimated size 2.3 KB, free 1990.4 MB)
2021-12-04 17:38:16,379 [dispatcher-event-loop-11] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_16_piece0 in memory on qb:60666 (size: 2.3 KB, free: 1990.8 MB)
2021-12-04 17:38:16,379 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 16 from broadcast at DAGScheduler.scala:1039
2021-12-04 17:38:16,380 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from ShuffleMapStage 18 (MapPartitionsRDD[27] at intersection at PaidPromotionAdjustParameter.scala:135) (first 15 tasks are for partitions Vector(0, 1))
2021-12-04 17:38:16,380 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 18.0 with 2 tasks
2021-12-04 17:38:16,380 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ShuffleMapStage 20 (MapPartitionsRDD[28] at intersection at PaidPromotionAdjustParameter.scala:135), which has no missing parents
2021-12-04 17:38:16,381 [dispatcher-event-loop-7] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 18.0 (TID 30, localhost, executor driver, partition 0, ANY, 7638 bytes)
2021-12-04 17:38:16,381 [dispatcher-event-loop-7] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 18.0 (TID 31, localhost, executor driver, partition 1, ANY, 7638 bytes)
2021-12-04 17:38:16,381 [Executor task launch worker for task 31] INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 18.0 (TID 31)
2021-12-04 17:38:16,381 [Executor task launch worker for task 30] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 18.0 (TID 30)
2021-12-04 17:38:16,381 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_17 stored as values in memory (estimated size 4.0 KB, free 1990.4 MB)
2021-12-04 17:38:16,382 [Executor task launch worker for task 31] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 2 non-empty blocks out of 2 blocks
2021-12-04 17:38:16,382 [Executor task launch worker for task 30] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 2 non-empty blocks out of 2 blocks
2021-12-04 17:38:16,382 [Executor task launch worker for task 31] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-04 17:38:16,382 [Executor task launch worker for task 30] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-04 17:38:16,383 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_17_piece0 stored as bytes in memory (estimated size 2.3 KB, free 1990.4 MB)
2021-12-04 17:38:16,383 [dispatcher-event-loop-2] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_17_piece0 in memory on qb:60666 (size: 2.3 KB, free: 1990.8 MB)
2021-12-04 17:38:16,383 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 17 from broadcast at DAGScheduler.scala:1039
2021-12-04 17:38:16,384 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from ShuffleMapStage 20 (MapPartitionsRDD[28] at intersection at PaidPromotionAdjustParameter.scala:135) (first 15 tasks are for partitions Vector(0, 1))
2021-12-04 17:38:16,384 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 20.0 with 2 tasks
2021-12-04 17:38:16,384 [dispatcher-event-loop-5] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 20.0 (TID 32, localhost, executor driver, partition 0, ANY, 7638 bytes)
2021-12-04 17:38:16,384 [dispatcher-event-loop-5] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 20.0 (TID 33, localhost, executor driver, partition 1, ANY, 7638 bytes)
2021-12-04 17:38:16,384 [Executor task launch worker for task 32] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 20.0 (TID 32)
2021-12-04 17:38:16,384 [Executor task launch worker for task 33] INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 20.0 (TID 33)
2021-12-04 17:38:16,386 [Executor task launch worker for task 32] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 2 non-empty blocks out of 2 blocks
2021-12-04 17:38:16,386 [Executor task launch worker for task 33] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 2 non-empty blocks out of 2 blocks
2021-12-04 17:38:16,386 [Executor task launch worker for task 32] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-04 17:38:16,386 [Executor task launch worker for task 33] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-04 17:38:16,396 [Executor task launch worker for task 31] INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 18.0 (TID 31). 1204 bytes result sent to driver
2021-12-04 17:38:16,397 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 18.0 (TID 31) in 16 ms on localhost (executor driver) (1/2)
2021-12-04 17:38:16,398 [Executor task launch worker for task 30] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 18.0 (TID 30). 1161 bytes result sent to driver
2021-12-04 17:38:16,398 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 18.0 (TID 30) in 18 ms on localhost (executor driver) (2/2)
2021-12-04 17:38:16,399 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 18.0, whose tasks have all completed, from pool 
2021-12-04 17:38:16,399 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ShuffleMapStage 18 (intersection at PaidPromotionAdjustParameter.scala:135) finished in 0.023 s
2021-12-04 17:38:16,399 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - looking for newly runnable stages
2021-12-04 17:38:16,399 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - running: Set(ShuffleMapStage 20)
2021-12-04 17:38:16,399 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - waiting: Set(ResultStage 21)
2021-12-04 17:38:16,399 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - failed: Set()
2021-12-04 17:38:16,402 [Executor task launch worker for task 32] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 20.0 (TID 32). 1204 bytes result sent to driver
2021-12-04 17:38:16,402 [Executor task launch worker for task 33] INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 20.0 (TID 33). 1204 bytes result sent to driver
2021-12-04 17:38:16,402 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 20.0 (TID 32) in 18 ms on localhost (executor driver) (1/2)
2021-12-04 17:38:16,402 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 20.0 (TID 33) in 18 ms on localhost (executor driver) (2/2)
2021-12-04 17:38:16,402 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 20.0, whose tasks have all completed, from pool 
2021-12-04 17:38:16,403 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ShuffleMapStage 20 (intersection at PaidPromotionAdjustParameter.scala:135) finished in 0.021 s
2021-12-04 17:38:16,403 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - looking for newly runnable stages
2021-12-04 17:38:16,403 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - running: Set()
2021-12-04 17:38:16,403 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - waiting: Set(ResultStage 21)
2021-12-04 17:38:16,403 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - failed: Set()
2021-12-04 17:38:16,403 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 21 (MapPartitionsRDD[32] at intersection at PaidPromotionAdjustParameter.scala:135), which has no missing parents
2021-12-04 17:38:16,404 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_18 stored as values in memory (estimated size 3.6 KB, free 1990.4 MB)
2021-12-04 17:38:16,405 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_18_piece0 stored as bytes in memory (estimated size 2.1 KB, free 1990.4 MB)
2021-12-04 17:38:16,406 [dispatcher-event-loop-11] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_18_piece0 in memory on qb:60666 (size: 2.1 KB, free: 1990.8 MB)
2021-12-04 17:38:16,406 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 18 from broadcast at DAGScheduler.scala:1039
2021-12-04 17:38:16,406 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from ResultStage 21 (MapPartitionsRDD[32] at intersection at PaidPromotionAdjustParameter.scala:135) (first 15 tasks are for partitions Vector(0, 1))
2021-12-04 17:38:16,406 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 21.0 with 2 tasks
2021-12-04 17:38:16,407 [dispatcher-event-loop-7] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 21.0 (TID 34, localhost, executor driver, partition 0, PROCESS_LOCAL, 7712 bytes)
2021-12-04 17:38:16,407 [dispatcher-event-loop-7] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 21.0 (TID 35, localhost, executor driver, partition 1, PROCESS_LOCAL, 7712 bytes)
2021-12-04 17:38:16,407 [Executor task launch worker for task 34] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 21.0 (TID 34)
2021-12-04 17:38:16,407 [Executor task launch worker for task 35] INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 21.0 (TID 35)
2021-12-04 17:38:16,408 [Executor task launch worker for task 35] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2021-12-04 17:38:16,408 [Executor task launch worker for task 34] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2021-12-04 17:38:16,408 [Executor task launch worker for task 35] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-04 17:38:16,408 [Executor task launch worker for task 34] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-04 17:38:16,410 [Executor task launch worker for task 34] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2021-12-04 17:38:16,410 [Executor task launch worker for task 35] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2021-12-04 17:38:16,410 [Executor task launch worker for task 34] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-04 17:38:16,410 [Executor task launch worker for task 35] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-04 17:38:16,416 [Executor task launch worker for task 35] INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 21.0 (TID 35). 1010 bytes result sent to driver
2021-12-04 17:38:16,416 [Executor task launch worker for task 34] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 21.0 (TID 34). 1010 bytes result sent to driver
2021-12-04 17:38:16,416 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 21.0 (TID 35) in 9 ms on localhost (executor driver) (1/2)
2021-12-04 17:38:16,417 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 21.0 (TID 34) in 10 ms on localhost (executor driver) (2/2)
2021-12-04 17:38:16,417 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 21.0, whose tasks have all completed, from pool 
2021-12-04 17:38:16,417 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 21 (count at PaidPromotionAdjustParameter.scala:143) finished in 0.014 s
2021-12-04 17:38:16,417 [main] INFO [org.apache.spark.scheduler.DAGScheduler] - Job 9 finished: count at PaidPromotionAdjustParameter.scala:143, took 0.041839 s
2021-12-04 17:38:16,418 [main] INFO [PaidPromotion$] - 共 同 节目数 = 109
2021-12-04 17:38:16,426 [main] INFO [org.apache.spark.SparkContext] - Starting job: collect at PaidPromotionAdjustParameter.scala:146
2021-12-04 17:38:16,426 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 10 (collect at PaidPromotionAdjustParameter.scala:146) with 2 output partitions
2021-12-04 17:38:16,426 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 26 (collect at PaidPromotionAdjustParameter.scala:146)
2021-12-04 17:38:16,426 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 25, ShuffleMapStage 23)
2021-12-04 17:38:16,426 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2021-12-04 17:38:16,427 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 26 (MapPartitionsRDD[18] at intersection at PaidPromotionAdjustParameter.scala:130), which has no missing parents
2021-12-04 17:38:16,427 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_19 stored as values in memory (estimated size 3.8 KB, free 1990.4 MB)
2021-12-04 17:38:16,429 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_19_piece0 stored as bytes in memory (estimated size 2.2 KB, free 1990.4 MB)
2021-12-04 17:38:16,430 [dispatcher-event-loop-8] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_19_piece0 in memory on qb:60666 (size: 2.2 KB, free: 1990.8 MB)
2021-12-04 17:38:16,430 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 19 from broadcast at DAGScheduler.scala:1039
2021-12-04 17:38:16,431 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from ResultStage 26 (MapPartitionsRDD[18] at intersection at PaidPromotionAdjustParameter.scala:130) (first 15 tasks are for partitions Vector(0, 1))
2021-12-04 17:38:16,431 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 26.0 with 2 tasks
2021-12-04 17:38:16,431 [dispatcher-event-loop-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 26.0 (TID 36, localhost, executor driver, partition 0, PROCESS_LOCAL, 7712 bytes)
2021-12-04 17:38:16,431 [dispatcher-event-loop-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 26.0 (TID 37, localhost, executor driver, partition 1, PROCESS_LOCAL, 7712 bytes)
2021-12-04 17:38:16,431 [Executor task launch worker for task 37] INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 26.0 (TID 37)
2021-12-04 17:38:16,431 [Executor task launch worker for task 36] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 26.0 (TID 36)
2021-12-04 17:38:16,432 [Executor task launch worker for task 37] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2021-12-04 17:38:16,432 [Executor task launch worker for task 37] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-04 17:38:16,432 [Executor task launch worker for task 36] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2021-12-04 17:38:16,432 [Executor task launch worker for task 36] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-04 17:38:16,434 [Executor task launch worker for task 36] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2021-12-04 17:38:16,434 [Executor task launch worker for task 36] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-04 17:38:16,434 [Executor task launch worker for task 37] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2021-12-04 17:38:16,434 [Executor task launch worker for task 37] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-04 17:38:16,512 [Executor task launch worker for task 36] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 26.0 (TID 36). 85915 bytes result sent to driver
2021-12-04 17:38:16,512 [Executor task launch worker for task 37] INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 26.0 (TID 37). 88136 bytes result sent to driver
2021-12-04 17:38:16,513 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 26.0 (TID 36) in 82 ms on localhost (executor driver) (1/2)
2021-12-04 17:38:16,513 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 26.0 (TID 37) in 82 ms on localhost (executor driver) (2/2)
2021-12-04 17:38:16,513 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 26.0, whose tasks have all completed, from pool 
2021-12-04 17:38:16,514 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 26 (collect at PaidPromotionAdjustParameter.scala:146) finished in 0.086 s
2021-12-04 17:38:16,514 [main] INFO [org.apache.spark.scheduler.DAGScheduler] - Job 10 finished: collect at PaidPromotionAdjustParameter.scala:146, took 0.087963 s
2021-12-04 17:38:16,518 [main] INFO [org.apache.spark.SparkContext] - Starting job: collect at PaidPromotionAdjustParameter.scala:147
2021-12-04 17:38:16,519 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 11 (collect at PaidPromotionAdjustParameter.scala:147) with 2 output partitions
2021-12-04 17:38:16,519 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 31 (collect at PaidPromotionAdjustParameter.scala:147)
2021-12-04 17:38:16,519 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 30, ShuffleMapStage 28)
2021-12-04 17:38:16,519 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2021-12-04 17:38:16,519 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 31 (MapPartitionsRDD[32] at intersection at PaidPromotionAdjustParameter.scala:135), which has no missing parents
2021-12-04 17:38:16,520 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_20 stored as values in memory (estimated size 3.8 KB, free 1990.4 MB)
2021-12-04 17:38:16,522 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_20_piece0 stored as bytes in memory (estimated size 2.2 KB, free 1990.4 MB)
2021-12-04 17:38:16,523 [dispatcher-event-loop-11] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_20_piece0 in memory on qb:60666 (size: 2.2 KB, free: 1990.8 MB)
2021-12-04 17:38:16,523 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 20 from broadcast at DAGScheduler.scala:1039
2021-12-04 17:38:16,523 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from ResultStage 31 (MapPartitionsRDD[32] at intersection at PaidPromotionAdjustParameter.scala:135) (first 15 tasks are for partitions Vector(0, 1))
2021-12-04 17:38:16,523 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 31.0 with 2 tasks
2021-12-04 17:38:16,523 [dispatcher-event-loop-7] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 31.0 (TID 38, localhost, executor driver, partition 0, PROCESS_LOCAL, 7712 bytes)
2021-12-04 17:38:16,524 [dispatcher-event-loop-7] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 31.0 (TID 39, localhost, executor driver, partition 1, PROCESS_LOCAL, 7712 bytes)
2021-12-04 17:38:16,524 [Executor task launch worker for task 38] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 31.0 (TID 38)
2021-12-04 17:38:16,524 [Executor task launch worker for task 39] INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 31.0 (TID 39)
2021-12-04 17:38:16,525 [Executor task launch worker for task 38] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2021-12-04 17:38:16,525 [Executor task launch worker for task 39] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2021-12-04 17:38:16,525 [Executor task launch worker for task 38] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-04 17:38:16,525 [Executor task launch worker for task 39] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-04 17:38:16,526 [Executor task launch worker for task 38] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2021-12-04 17:38:16,526 [Executor task launch worker for task 38] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-04 17:38:16,526 [Executor task launch worker for task 39] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2021-12-04 17:38:16,526 [Executor task launch worker for task 39] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-04 17:38:16,531 [Executor task launch worker for task 38] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 31.0 (TID 38). 2734 bytes result sent to driver
2021-12-04 17:38:16,531 [Executor task launch worker for task 39] INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 31.0 (TID 39). 2602 bytes result sent to driver
2021-12-04 17:38:16,532 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 31.0 (TID 38) in 9 ms on localhost (executor driver) (1/2)
2021-12-04 17:38:16,532 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 31.0 (TID 39) in 9 ms on localhost (executor driver) (2/2)
2021-12-04 17:38:16,532 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 31.0, whose tasks have all completed, from pool 
2021-12-04 17:38:16,532 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 31 (collect at PaidPromotionAdjustParameter.scala:147) finished in 0.013 s
2021-12-04 17:38:16,532 [main] INFO [org.apache.spark.scheduler.DAGScheduler] - Job 11 finished: collect at PaidPromotionAdjustParameter.scala:147, took 0.013681 s
2021-12-04 17:38:16,547 [main] INFO [org.apache.spark.SparkContext] - Starting job: count at PaidPromotionAdjustParameter.scala:156
2021-12-04 17:38:16,549 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 12 (count at PaidPromotionAdjustParameter.scala:156) with 4 output partitions
2021-12-04 17:38:16,549 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 32 (count at PaidPromotionAdjustParameter.scala:156)
2021-12-04 17:38:16,549 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List()
2021-12-04 17:38:16,549 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2021-12-04 17:38:16,549 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 32 (UnionRDD[35] at union at PaidPromotionAdjustParameter.scala:154), which has no missing parents
2021-12-04 17:38:16,556 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_21 stored as values in memory (estimated size 185.0 KB, free 1990.2 MB)
2021-12-04 17:38:16,558 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_21_piece0 stored as bytes in memory (estimated size 65.3 KB, free 1990.2 MB)
2021-12-04 17:38:16,558 [dispatcher-event-loop-8] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_21_piece0 in memory on qb:60666 (size: 65.3 KB, free: 1990.7 MB)
2021-12-04 17:38:16,559 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 21 from broadcast at DAGScheduler.scala:1039
2021-12-04 17:38:16,559 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 4 missing tasks from ResultStage 32 (UnionRDD[35] at union at PaidPromotionAdjustParameter.scala:154) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
2021-12-04 17:38:16,559 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 32.0 with 4 tasks
2021-12-04 17:38:16,561 [dispatcher-event-loop-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 32.0 (TID 40, localhost, executor driver, partition 0, ANY, 8005 bytes)
2021-12-04 17:38:16,561 [dispatcher-event-loop-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 32.0 (TID 41, localhost, executor driver, partition 1, ANY, 8005 bytes)
2021-12-04 17:38:16,561 [dispatcher-event-loop-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 2.0 in stage 32.0 (TID 42, localhost, executor driver, partition 2, ANY, 8005 bytes)
2021-12-04 17:38:16,561 [dispatcher-event-loop-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 3.0 in stage 32.0 (TID 43, localhost, executor driver, partition 3, ANY, 8005 bytes)
2021-12-04 17:38:16,561 [Executor task launch worker for task 40] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 32.0 (TID 40)
2021-12-04 17:38:16,561 [Executor task launch worker for task 42] INFO [org.apache.spark.executor.Executor] - Running task 2.0 in stage 32.0 (TID 42)
2021-12-04 17:38:16,561 [Executor task launch worker for task 43] INFO [org.apache.spark.executor.Executor] - Running task 3.0 in stage 32.0 (TID 43)
2021-12-04 17:38:16,561 [Executor task launch worker for task 41] INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 32.0 (TID 41)
2021-12-04 17:38:16,567 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 346
2021-12-04 17:38:16,567 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 462
2021-12-04 17:38:16,567 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 471
2021-12-04 17:38:16,567 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 385
2021-12-04 17:38:16,567 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 446
2021-12-04 17:38:16,567 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 472
2021-12-04 17:38:16,567 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 343
2021-12-04 17:38:16,567 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 377
2021-12-04 17:38:16,567 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 395
2021-12-04 17:38:16,567 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 370
2021-12-04 17:38:16,568 [dispatcher-event-loop-1] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_14_piece0 on qb:60666 in memory (size: 2.9 KB, free: 1990.7 MB)
2021-12-04 17:38:16,568 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 406
2021-12-04 17:38:16,568 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 409
2021-12-04 17:38:16,568 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 439
2021-12-04 17:38:16,569 [dispatcher-event-loop-5] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_16_piece0 on qb:60666 in memory (size: 2.3 KB, free: 1990.7 MB)
2021-12-04 17:38:16,569 [Executor task launch worker for task 40] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/order_data.bcp:0+3442194
2021-12-04 17:38:16,569 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 332
2021-12-04 17:38:16,569 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 428
2021-12-04 17:38:16,569 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 325
2021-12-04 17:38:16,569 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 369
2021-12-04 17:38:16,569 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 408
2021-12-04 17:38:16,569 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 467
2021-12-04 17:38:16,569 [Executor task launch worker for task 41] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/order_data.bcp:3442194+3442195
2021-12-04 17:38:16,569 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 353
2021-12-04 17:38:16,569 [Executor task launch worker for task 43] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/order_data.bcp:3442194+3442195
2021-12-04 17:38:16,569 [Executor task launch worker for task 42] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/order_data.bcp:0+3442194
2021-12-04 17:38:16,569 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 396
2021-12-04 17:38:16,569 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 489
2021-12-04 17:38:16,569 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 367
2021-12-04 17:38:16,569 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 452
2021-12-04 17:38:16,569 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 483
2021-12-04 17:38:16,569 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 478
2021-12-04 17:38:16,569 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 491
2021-12-04 17:38:16,569 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 381
2021-12-04 17:38:16,569 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 419
2021-12-04 17:38:16,569 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 336
2021-12-04 17:38:16,570 [dispatcher-event-loop-4] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_19_piece0 on qb:60666 in memory (size: 2.2 KB, free: 1990.7 MB)
2021-12-04 17:38:16,571 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 387
2021-12-04 17:38:16,571 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 490
2021-12-04 17:38:16,571 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 424
2021-12-04 17:38:16,571 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 426
2021-12-04 17:38:16,571 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 450
2021-12-04 17:38:16,571 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 421
2021-12-04 17:38:16,571 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 398
2021-12-04 17:38:16,571 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 355
2021-12-04 17:38:16,571 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 411
2021-12-04 17:38:16,571 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 333
2021-12-04 17:38:16,571 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 371
2021-12-04 17:38:16,571 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 386
2021-12-04 17:38:16,571 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 461
2021-12-04 17:38:16,571 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 423
2021-12-04 17:38:16,571 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 329
2021-12-04 17:38:16,571 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 376
2021-12-04 17:38:16,571 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 342
2021-12-04 17:38:16,571 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 434
2021-12-04 17:38:16,572 [dispatcher-event-loop-6] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_15_piece0 on qb:60666 in memory (size: 2.2 KB, free: 1990.7 MB)
2021-12-04 17:38:16,572 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 350
2021-12-04 17:38:16,572 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 379
2021-12-04 17:38:16,572 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 497
2021-12-04 17:38:16,572 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 338
2021-12-04 17:38:16,572 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 356
2021-12-04 17:38:16,572 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 438
2021-12-04 17:38:16,572 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 456
2021-12-04 17:38:16,572 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 496
2021-12-04 17:38:16,572 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 488
2021-12-04 17:38:16,572 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 422
2021-12-04 17:38:16,572 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 394
2021-12-04 17:38:16,572 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 410
2021-12-04 17:38:16,572 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 466
2021-12-04 17:38:16,572 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 407
2021-12-04 17:38:16,572 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 430
2021-12-04 17:38:16,572 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 374
2021-12-04 17:38:16,572 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 464
2021-12-04 17:38:16,572 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 399
2021-12-04 17:38:16,572 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 340
2021-12-04 17:38:16,572 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 436
2021-12-04 17:38:16,572 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 397
2021-12-04 17:38:16,572 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 487
2021-12-04 17:38:16,573 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 400
2021-12-04 17:38:16,573 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 327
2021-12-04 17:38:16,573 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 453
2021-12-04 17:38:16,573 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 393
2021-12-04 17:38:16,573 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 352
2021-12-04 17:38:16,573 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 418
2021-12-04 17:38:16,573 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 380
2021-12-04 17:38:16,573 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 335
2021-12-04 17:38:16,573 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 468
2021-12-04 17:38:16,573 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 357
2021-12-04 17:38:16,573 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 469
2021-12-04 17:38:16,573 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 474
2021-12-04 17:38:16,573 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 495
2021-12-04 17:38:16,573 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 373
2021-12-04 17:38:16,573 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 484
2021-12-04 17:38:16,573 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 331
2021-12-04 17:38:16,573 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 390
2021-12-04 17:38:16,573 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 366
2021-12-04 17:38:16,573 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 441
2021-12-04 17:38:16,573 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 476
2021-12-04 17:38:16,574 [dispatcher-event-loop-1] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_20_piece0 on qb:60666 in memory (size: 2.2 KB, free: 1990.7 MB)
2021-12-04 17:38:16,574 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 388
2021-12-04 17:38:16,574 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 413
2021-12-04 17:38:16,574 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 417
2021-12-04 17:38:16,574 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 420
2021-12-04 17:38:16,574 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 463
2021-12-04 17:38:16,574 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 482
2021-12-04 17:38:16,574 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 454
2021-12-04 17:38:16,574 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 401
2021-12-04 17:38:16,574 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 328
2021-12-04 17:38:16,574 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 348
2021-12-04 17:38:16,574 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 391
2021-12-04 17:38:16,574 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 326
2021-12-04 17:38:16,574 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 362
2021-12-04 17:38:16,574 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 363
2021-12-04 17:38:16,574 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 457
2021-12-04 17:38:16,574 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 458
2021-12-04 17:38:16,574 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 405
2021-12-04 17:38:16,575 [dispatcher-event-loop-5] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_18_piece0 on qb:60666 in memory (size: 2.1 KB, free: 1990.7 MB)
2021-12-04 17:38:16,576 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 494
2021-12-04 17:38:16,576 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 477
2021-12-04 17:38:16,576 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 414
2021-12-04 17:38:16,576 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 354
2021-12-04 17:38:16,576 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 465
2021-12-04 17:38:16,576 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 365
2021-12-04 17:38:16,576 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 341
2021-12-04 17:38:16,576 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 492
2021-12-04 17:38:16,576 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 455
2021-12-04 17:38:16,576 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 498
2021-12-04 17:38:16,576 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 334
2021-12-04 17:38:16,576 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 481
2021-12-04 17:38:16,576 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 470
2021-12-04 17:38:16,576 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 447
2021-12-04 17:38:16,576 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 339
2021-12-04 17:38:16,576 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 475
2021-12-04 17:38:16,576 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 384
2021-12-04 17:38:16,577 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 425
2021-12-04 17:38:16,577 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 364
2021-12-04 17:38:16,577 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 404
2021-12-04 17:38:16,577 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 416
2021-12-04 17:38:16,577 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 449
2021-12-04 17:38:16,577 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 460
2021-12-04 17:38:16,577 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 479
2021-12-04 17:38:16,577 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 358
2021-12-04 17:38:16,577 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 403
2021-12-04 17:38:16,577 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 432
2021-12-04 17:38:16,577 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 337
2021-12-04 17:38:16,577 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 448
2021-12-04 17:38:16,577 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 402
2021-12-04 17:38:16,577 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 431
2021-12-04 17:38:16,577 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 344
2021-12-04 17:38:16,577 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 383
2021-12-04 17:38:16,577 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 433
2021-12-04 17:38:16,577 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 378
2021-12-04 17:38:16,577 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 437
2021-12-04 17:38:16,577 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 442
2021-12-04 17:38:16,578 [dispatcher-event-loop-4] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_17_piece0 on qb:60666 in memory (size: 2.3 KB, free: 1990.7 MB)
2021-12-04 17:38:16,578 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 330
2021-12-04 17:38:16,578 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 372
2021-12-04 17:38:16,578 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 361
2021-12-04 17:38:16,578 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 459
2021-12-04 17:38:16,578 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 473
2021-12-04 17:38:16,578 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 412
2021-12-04 17:38:16,578 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 389
2021-12-04 17:38:16,578 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 486
2021-12-04 17:38:16,578 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 429
2021-12-04 17:38:16,578 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 435
2021-12-04 17:38:16,578 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 382
2021-12-04 17:38:16,578 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 445
2021-12-04 17:38:16,578 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 368
2021-12-04 17:38:16,578 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 351
2021-12-04 17:38:16,578 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 480
2021-12-04 17:38:16,578 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 345
2021-12-04 17:38:16,578 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 499
2021-12-04 17:38:16,578 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 347
2021-12-04 17:38:16,578 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 440
2021-12-04 17:38:16,578 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 359
2021-12-04 17:38:16,578 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 375
2021-12-04 17:38:16,578 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 427
2021-12-04 17:38:16,578 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 392
2021-12-04 17:38:16,578 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 415
2021-12-04 17:38:16,579 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 444
2021-12-04 17:38:16,579 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 360
2021-12-04 17:38:16,579 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 493
2021-12-04 17:38:16,579 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 485
2021-12-04 17:38:16,579 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 349
2021-12-04 17:38:16,579 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 451
2021-12-04 17:38:16,579 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 443
2021-12-04 17:38:17,530 [Executor task launch worker for task 41] INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 32.0 (TID 41). 754 bytes result sent to driver
2021-12-04 17:38:17,530 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 32.0 (TID 41) in 969 ms on localhost (executor driver) (1/4)
2021-12-04 17:38:17,813 [Executor task launch worker for task 43] INFO [org.apache.spark.executor.Executor] - Finished task 3.0 in stage 32.0 (TID 43). 754 bytes result sent to driver
2021-12-04 17:38:17,813 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 3.0 in stage 32.0 (TID 43) in 1252 ms on localhost (executor driver) (2/4)
2021-12-04 17:38:17,831 [Executor task launch worker for task 42] INFO [org.apache.spark.executor.Executor] - Finished task 2.0 in stage 32.0 (TID 42). 754 bytes result sent to driver
2021-12-04 17:38:17,832 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 2.0 in stage 32.0 (TID 42) in 1270 ms on localhost (executor driver) (3/4)
2021-12-04 17:38:17,943 [Executor task launch worker for task 40] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 32.0 (TID 40). 754 bytes result sent to driver
2021-12-04 17:38:17,944 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 32.0 (TID 40) in 1385 ms on localhost (executor driver) (4/4)
2021-12-04 17:38:17,944 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 32.0, whose tasks have all completed, from pool 
2021-12-04 17:38:17,944 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 32 (count at PaidPromotionAdjustParameter.scala:156) finished in 1.395 s
2021-12-04 17:38:17,944 [main] INFO [org.apache.spark.scheduler.DAGScheduler] - Job 12 finished: count at PaidPromotionAdjustParameter.scala:156, took 1.396332 s
2021-12-04 17:38:17,945 [main] INFO [PaidPromotion$] - 最终训练集数量：101177
2021-12-04 17:38:17,946 [main] INFO [org.apache.spark.SparkContext] - Starting job: count at PaidPromotionAdjustParameter.scala:157
2021-12-04 17:38:17,946 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 13 (count at PaidPromotionAdjustParameter.scala:157) with 2 output partitions
2021-12-04 17:38:17,946 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 33 (count at PaidPromotionAdjustParameter.scala:157)
2021-12-04 17:38:17,946 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List()
2021-12-04 17:38:17,946 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2021-12-04 17:38:17,947 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 33 (MapPartitionsRDD[33] at filter at PaidPromotionAdjustParameter.scala:150), which has no missing parents
2021-12-04 17:38:17,949 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_22 stored as values in memory (estimated size 184.4 KB, free 1990.0 MB)
2021-12-04 17:38:17,952 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_22_piece0 stored as bytes in memory (estimated size 65.0 KB, free 1990.0 MB)
2021-12-04 17:38:17,952 [dispatcher-event-loop-7] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_22_piece0 in memory on qb:60666 (size: 65.0 KB, free: 1990.6 MB)
2021-12-04 17:38:17,953 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 22 from broadcast at DAGScheduler.scala:1039
2021-12-04 17:38:17,954 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from ResultStage 33 (MapPartitionsRDD[33] at filter at PaidPromotionAdjustParameter.scala:150) (first 15 tasks are for partitions Vector(0, 1))
2021-12-04 17:38:17,954 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 33.0 with 2 tasks
2021-12-04 17:38:17,954 [dispatcher-event-loop-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 33.0 (TID 44, localhost, executor driver, partition 0, ANY, 7896 bytes)
2021-12-04 17:38:17,954 [dispatcher-event-loop-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 33.0 (TID 45, localhost, executor driver, partition 1, ANY, 7896 bytes)
2021-12-04 17:38:17,955 [Executor task launch worker for task 44] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 33.0 (TID 44)
2021-12-04 17:38:17,955 [Executor task launch worker for task 45] INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 33.0 (TID 45)
2021-12-04 17:38:17,957 [Executor task launch worker for task 45] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/order_data.bcp:3442194+3442195
2021-12-04 17:38:17,957 [Executor task launch worker for task 44] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/order_data.bcp:0+3442194
2021-12-04 17:38:18,328 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 514
2021-12-04 17:38:18,328 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 512
2021-12-04 17:38:18,328 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 503
2021-12-04 17:38:18,328 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 515
2021-12-04 17:38:18,328 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 517
2021-12-04 17:38:18,328 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 501
2021-12-04 17:38:18,328 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 504
2021-12-04 17:38:18,328 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 502
2021-12-04 17:38:18,328 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 508
2021-12-04 17:38:18,329 [dispatcher-event-loop-3] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_21_piece0 on qb:60666 in memory (size: 65.3 KB, free: 1990.7 MB)
2021-12-04 17:38:18,329 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 520
2021-12-04 17:38:18,329 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 516
2021-12-04 17:38:18,329 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 513
2021-12-04 17:38:18,329 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 510
2021-12-04 17:38:18,329 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 511
2021-12-04 17:38:18,329 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 519
2021-12-04 17:38:18,329 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 500
2021-12-04 17:38:18,329 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 507
2021-12-04 17:38:18,329 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 524
2021-12-04 17:38:18,329 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 521
2021-12-04 17:38:18,329 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 506
2021-12-04 17:38:18,329 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 518
2021-12-04 17:38:18,329 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 509
2021-12-04 17:38:18,329 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 522
2021-12-04 17:38:18,329 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 505
2021-12-04 17:38:18,329 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 523
2021-12-04 17:38:18,845 [Executor task launch worker for task 44] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 33.0 (TID 44). 753 bytes result sent to driver
2021-12-04 17:38:18,845 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 33.0 (TID 44) in 891 ms on localhost (executor driver) (1/2)
2021-12-04 17:38:18,862 [Executor task launch worker for task 45] INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 33.0 (TID 45). 753 bytes result sent to driver
2021-12-04 17:38:18,862 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 33.0 (TID 45) in 908 ms on localhost (executor driver) (2/2)
2021-12-04 17:38:18,862 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 33.0, whose tasks have all completed, from pool 
2021-12-04 17:38:18,862 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 33 (count at PaidPromotionAdjustParameter.scala:157) finished in 0.915 s
2021-12-04 17:38:18,862 [main] INFO [org.apache.spark.scheduler.DAGScheduler] - Job 13 finished: count at PaidPromotionAdjustParameter.scala:157, took 0.916895 s
2021-12-04 17:38:18,863 [main] INFO [PaidPromotion$] - 最终验证集数量：6117
2021-12-04 17:38:18,893 [main] INFO [PaidPromotion$] - -----------------------------------
2021-12-04 17:38:18,895 [main] INFO [org.apache.spark.SparkContext] - Starting job: count at PaidPromotionAdjustParameter.scala:169
2021-12-04 17:38:18,895 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 37 (distinct at PaidPromotionAdjustParameter.scala:160)
2021-12-04 17:38:18,895 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 14 (count at PaidPromotionAdjustParameter.scala:169) with 4 output partitions
2021-12-04 17:38:18,895 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 35 (count at PaidPromotionAdjustParameter.scala:169)
2021-12-04 17:38:18,895 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 34)
2021-12-04 17:38:18,895 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List(ShuffleMapStage 34)
2021-12-04 17:38:18,896 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ShuffleMapStage 34 (MapPartitionsRDD[37] at distinct at PaidPromotionAdjustParameter.scala:160), which has no missing parents
2021-12-04 17:38:18,898 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_23 stored as values in memory (estimated size 186.6 KB, free 1990.0 MB)
2021-12-04 17:38:18,900 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_23_piece0 stored as bytes in memory (estimated size 66.3 KB, free 1990.0 MB)
2021-12-04 17:38:18,900 [dispatcher-event-loop-9] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_23_piece0 in memory on qb:60666 (size: 66.3 KB, free: 1990.6 MB)
2021-12-04 17:38:18,901 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 23 from broadcast at DAGScheduler.scala:1039
2021-12-04 17:38:18,901 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 4 missing tasks from ShuffleMapStage 34 (MapPartitionsRDD[37] at distinct at PaidPromotionAdjustParameter.scala:160) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
2021-12-04 17:38:18,901 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 34.0 with 4 tasks
2021-12-04 17:38:18,901 [dispatcher-event-loop-6] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 34.0 (TID 46, localhost, executor driver, partition 0, ANY, 7994 bytes)
2021-12-04 17:38:18,901 [dispatcher-event-loop-6] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 34.0 (TID 47, localhost, executor driver, partition 1, ANY, 7994 bytes)
2021-12-04 17:38:18,902 [dispatcher-event-loop-6] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 2.0 in stage 34.0 (TID 48, localhost, executor driver, partition 2, ANY, 7994 bytes)
2021-12-04 17:38:18,902 [dispatcher-event-loop-6] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 3.0 in stage 34.0 (TID 49, localhost, executor driver, partition 3, ANY, 7994 bytes)
2021-12-04 17:38:18,902 [Executor task launch worker for task 47] INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 34.0 (TID 47)
2021-12-04 17:38:18,902 [Executor task launch worker for task 48] INFO [org.apache.spark.executor.Executor] - Running task 2.0 in stage 34.0 (TID 48)
2021-12-04 17:38:18,902 [Executor task launch worker for task 46] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 34.0 (TID 46)
2021-12-04 17:38:18,902 [Executor task launch worker for task 49] INFO [org.apache.spark.executor.Executor] - Running task 3.0 in stage 34.0 (TID 49)
2021-12-04 17:38:18,905 [Executor task launch worker for task 48] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/order_data.bcp:0+3442194
2021-12-04 17:38:18,905 [Executor task launch worker for task 46] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/order_data.bcp:0+3442194
2021-12-04 17:38:18,905 [Executor task launch worker for task 49] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/order_data.bcp:3442194+3442195
2021-12-04 17:38:18,905 [Executor task launch worker for task 47] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/order_data.bcp:3442194+3442195
2021-12-04 17:38:19,504 [Executor task launch worker for task 49] INFO [org.apache.spark.executor.Executor] - Finished task 3.0 in stage 34.0 (TID 49). 991 bytes result sent to driver
2021-12-04 17:38:19,505 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 3.0 in stage 34.0 (TID 49) in 603 ms on localhost (executor driver) (1/4)
2021-12-04 17:38:19,838 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 535
2021-12-04 17:38:19,838 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 544
2021-12-04 17:38:19,838 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 530
2021-12-04 17:38:19,838 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 542
2021-12-04 17:38:19,838 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 529
2021-12-04 17:38:19,838 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 527
2021-12-04 17:38:19,838 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 541
2021-12-04 17:38:19,838 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 533
2021-12-04 17:38:19,838 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 548
2021-12-04 17:38:19,838 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 546
2021-12-04 17:38:19,838 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 549
2021-12-04 17:38:19,839 [dispatcher-event-loop-3] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_22_piece0 on qb:60666 in memory (size: 65.0 KB, free: 1990.7 MB)
2021-12-04 17:38:19,839 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 539
2021-12-04 17:38:19,839 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 538
2021-12-04 17:38:19,839 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 540
2021-12-04 17:38:19,839 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 532
2021-12-04 17:38:19,839 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 525
2021-12-04 17:38:19,839 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 537
2021-12-04 17:38:19,839 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 543
2021-12-04 17:38:19,839 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 528
2021-12-04 17:38:19,839 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 531
2021-12-04 17:38:19,839 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 526
2021-12-04 17:38:19,839 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 547
2021-12-04 17:38:19,839 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 536
2021-12-04 17:38:19,839 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 534
2021-12-04 17:38:19,839 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 545
2021-12-04 17:38:19,954 [Executor task launch worker for task 47] INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 34.0 (TID 47). 1034 bytes result sent to driver
2021-12-04 17:38:19,954 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 34.0 (TID 47) in 1053 ms on localhost (executor driver) (2/4)
2021-12-04 17:38:20,272 [Executor task launch worker for task 48] INFO [org.apache.spark.executor.Executor] - Finished task 2.0 in stage 34.0 (TID 48). 1077 bytes result sent to driver
2021-12-04 17:38:20,272 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 2.0 in stage 34.0 (TID 48) in 1371 ms on localhost (executor driver) (3/4)
2021-12-04 17:38:20,313 [Executor task launch worker for task 46] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 34.0 (TID 46). 1077 bytes result sent to driver
2021-12-04 17:38:20,314 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 34.0 (TID 46) in 1413 ms on localhost (executor driver) (4/4)
2021-12-04 17:38:20,314 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 34.0, whose tasks have all completed, from pool 
2021-12-04 17:38:20,314 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ShuffleMapStage 34 (distinct at PaidPromotionAdjustParameter.scala:160) finished in 1.418 s
2021-12-04 17:38:20,314 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - looking for newly runnable stages
2021-12-04 17:38:20,314 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - running: Set()
2021-12-04 17:38:20,314 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - waiting: Set(ResultStage 35)
2021-12-04 17:38:20,314 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - failed: Set()
2021-12-04 17:38:20,314 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 35 (MapPartitionsRDD[39] at distinct at PaidPromotionAdjustParameter.scala:160), which has no missing parents
2021-12-04 17:38:20,315 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_24 stored as values in memory (estimated size 3.7 KB, free 1990.2 MB)
2021-12-04 17:38:20,317 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_24_piece0 stored as bytes in memory (estimated size 2.2 KB, free 1990.2 MB)
2021-12-04 17:38:20,318 [dispatcher-event-loop-6] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_24_piece0 in memory on qb:60666 (size: 2.2 KB, free: 1990.7 MB)
2021-12-04 17:38:20,318 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 24 from broadcast at DAGScheduler.scala:1039
2021-12-04 17:38:20,318 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 4 missing tasks from ResultStage 35 (MapPartitionsRDD[39] at distinct at PaidPromotionAdjustParameter.scala:160) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
2021-12-04 17:38:20,318 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 35.0 with 4 tasks
2021-12-04 17:38:20,318 [dispatcher-event-loop-11] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 35.0 (TID 50, localhost, executor driver, partition 0, ANY, 7649 bytes)
2021-12-04 17:38:20,318 [dispatcher-event-loop-11] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 35.0 (TID 51, localhost, executor driver, partition 1, ANY, 7649 bytes)
2021-12-04 17:38:20,318 [dispatcher-event-loop-11] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 2.0 in stage 35.0 (TID 52, localhost, executor driver, partition 2, ANY, 7649 bytes)
2021-12-04 17:38:20,318 [dispatcher-event-loop-11] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 3.0 in stage 35.0 (TID 53, localhost, executor driver, partition 3, ANY, 7649 bytes)
2021-12-04 17:38:20,318 [Executor task launch worker for task 51] INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 35.0 (TID 51)
2021-12-04 17:38:20,318 [Executor task launch worker for task 52] INFO [org.apache.spark.executor.Executor] - Running task 2.0 in stage 35.0 (TID 52)
2021-12-04 17:38:20,318 [Executor task launch worker for task 53] INFO [org.apache.spark.executor.Executor] - Running task 3.0 in stage 35.0 (TID 53)
2021-12-04 17:38:20,318 [Executor task launch worker for task 50] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 35.0 (TID 50)
2021-12-04 17:38:20,320 [Executor task launch worker for task 52] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 4 non-empty blocks out of 4 blocks
2021-12-04 17:38:20,320 [Executor task launch worker for task 50] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 4 non-empty blocks out of 4 blocks
2021-12-04 17:38:20,320 [Executor task launch worker for task 52] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-04 17:38:20,320 [Executor task launch worker for task 50] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-04 17:38:20,320 [Executor task launch worker for task 51] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 4 non-empty blocks out of 4 blocks
2021-12-04 17:38:20,320 [Executor task launch worker for task 53] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 4 non-empty blocks out of 4 blocks
2021-12-04 17:38:20,320 [Executor task launch worker for task 53] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-04 17:38:20,320 [Executor task launch worker for task 51] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-04 17:38:20,368 [Executor task launch worker for task 50] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 35.0 (TID 50). 1055 bytes result sent to driver
2021-12-04 17:38:20,368 [Executor task launch worker for task 51] INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 35.0 (TID 51). 1055 bytes result sent to driver
2021-12-04 17:38:20,368 [Executor task launch worker for task 52] INFO [org.apache.spark.executor.Executor] - Finished task 2.0 in stage 35.0 (TID 52). 1055 bytes result sent to driver
2021-12-04 17:38:20,368 [Executor task launch worker for task 53] INFO [org.apache.spark.executor.Executor] - Finished task 3.0 in stage 35.0 (TID 53). 1055 bytes result sent to driver
2021-12-04 17:38:20,369 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 35.0 (TID 51) in 51 ms on localhost (executor driver) (1/4)
2021-12-04 17:38:20,369 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 35.0 (TID 50) in 51 ms on localhost (executor driver) (2/4)
2021-12-04 17:38:20,369 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 3.0 in stage 35.0 (TID 53) in 51 ms on localhost (executor driver) (3/4)
2021-12-04 17:38:20,369 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 2.0 in stage 35.0 (TID 52) in 51 ms on localhost (executor driver) (4/4)
2021-12-04 17:38:20,369 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 35.0, whose tasks have all completed, from pool 
2021-12-04 17:38:20,369 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 35 (count at PaidPromotionAdjustParameter.scala:169) finished in 0.054 s
2021-12-04 17:38:20,369 [main] INFO [org.apache.spark.scheduler.DAGScheduler] - Job 14 finished: count at PaidPromotionAdjustParameter.scala:169, took 1.474673 s
2021-12-04 17:38:20,370 [main] INFO [PaidPromotion$] - 最终训练集用户数 = 95323
2021-12-04 17:38:20,372 [main] INFO [org.apache.spark.SparkContext] - Starting job: count at PaidPromotionAdjustParameter.scala:170
2021-12-04 17:38:20,372 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 41 (distinct at PaidPromotionAdjustParameter.scala:161)
2021-12-04 17:38:20,372 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 15 (count at PaidPromotionAdjustParameter.scala:170) with 2 output partitions
2021-12-04 17:38:20,372 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 37 (count at PaidPromotionAdjustParameter.scala:170)
2021-12-04 17:38:20,372 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 36)
2021-12-04 17:38:20,372 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List(ShuffleMapStage 36)
2021-12-04 17:38:20,372 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ShuffleMapStage 36 (MapPartitionsRDD[41] at distinct at PaidPromotionAdjustParameter.scala:161), which has no missing parents
2021-12-04 17:38:20,374 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_25 stored as values in memory (estimated size 186.0 KB, free 1990.0 MB)
2021-12-04 17:38:20,376 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_25_piece0 stored as bytes in memory (estimated size 66.0 KB, free 1990.0 MB)
2021-12-04 17:38:20,376 [dispatcher-event-loop-6] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_25_piece0 in memory on qb:60666 (size: 66.0 KB, free: 1990.6 MB)
2021-12-04 17:38:20,377 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 25 from broadcast at DAGScheduler.scala:1039
2021-12-04 17:38:20,377 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from ShuffleMapStage 36 (MapPartitionsRDD[41] at distinct at PaidPromotionAdjustParameter.scala:161) (first 15 tasks are for partitions Vector(0, 1))
2021-12-04 17:38:20,377 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 36.0 with 2 tasks
2021-12-04 17:38:20,377 [dispatcher-event-loop-11] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 36.0 (TID 54, localhost, executor driver, partition 0, ANY, 7885 bytes)
2021-12-04 17:38:20,377 [dispatcher-event-loop-11] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 36.0 (TID 55, localhost, executor driver, partition 1, ANY, 7885 bytes)
2021-12-04 17:38:20,377 [Executor task launch worker for task 54] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 36.0 (TID 54)
2021-12-04 17:38:20,377 [Executor task launch worker for task 55] INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 36.0 (TID 55)
2021-12-04 17:38:20,380 [Executor task launch worker for task 54] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/order_data.bcp:0+3442194
2021-12-04 17:38:20,380 [Executor task launch worker for task 55] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/order_data.bcp:3442194+3442195
2021-12-04 17:38:21,341 [Executor task launch worker for task 55] INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 36.0 (TID 55). 989 bytes result sent to driver
2021-12-04 17:38:21,341 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 36.0 (TID 55) in 964 ms on localhost (executor driver) (1/2)
2021-12-04 17:38:21,386 [Executor task launch worker for task 54] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 36.0 (TID 54). 989 bytes result sent to driver
2021-12-04 17:38:21,386 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 36.0 (TID 54) in 1009 ms on localhost (executor driver) (2/2)
2021-12-04 17:38:21,386 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 36.0, whose tasks have all completed, from pool 
2021-12-04 17:38:21,387 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ShuffleMapStage 36 (distinct at PaidPromotionAdjustParameter.scala:161) finished in 1.013 s
2021-12-04 17:38:21,387 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - looking for newly runnable stages
2021-12-04 17:38:21,387 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - running: Set()
2021-12-04 17:38:21,387 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - waiting: Set(ResultStage 37)
2021-12-04 17:38:21,387 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - failed: Set()
2021-12-04 17:38:21,387 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 37 (MapPartitionsRDD[43] at distinct at PaidPromotionAdjustParameter.scala:161), which has no missing parents
2021-12-04 17:38:21,388 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_26 stored as values in memory (estimated size 3.7 KB, free 1990.0 MB)
2021-12-04 17:38:21,389 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_26_piece0 stored as bytes in memory (estimated size 2.2 KB, free 1990.0 MB)
2021-12-04 17:38:21,389 [dispatcher-event-loop-5] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_26_piece0 in memory on qb:60666 (size: 2.2 KB, free: 1990.6 MB)
2021-12-04 17:38:21,390 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 26 from broadcast at DAGScheduler.scala:1039
2021-12-04 17:38:21,390 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from ResultStage 37 (MapPartitionsRDD[43] at distinct at PaidPromotionAdjustParameter.scala:161) (first 15 tasks are for partitions Vector(0, 1))
2021-12-04 17:38:21,390 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 37.0 with 2 tasks
2021-12-04 17:38:21,390 [dispatcher-event-loop-8] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 37.0 (TID 56, localhost, executor driver, partition 0, ANY, 7649 bytes)
2021-12-04 17:38:21,390 [dispatcher-event-loop-8] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 37.0 (TID 57, localhost, executor driver, partition 1, ANY, 7649 bytes)
2021-12-04 17:38:21,390 [Executor task launch worker for task 57] INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 37.0 (TID 57)
2021-12-04 17:38:21,390 [Executor task launch worker for task 56] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 37.0 (TID 56)
2021-12-04 17:38:21,392 [Executor task launch worker for task 57] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 2 non-empty blocks out of 2 blocks
2021-12-04 17:38:21,392 [Executor task launch worker for task 56] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 2 non-empty blocks out of 2 blocks
2021-12-04 17:38:21,392 [Executor task launch worker for task 57] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-04 17:38:21,392 [Executor task launch worker for task 56] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-04 17:38:21,408 [Executor task launch worker for task 57] INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 37.0 (TID 57). 1011 bytes result sent to driver
2021-12-04 17:38:21,408 [Executor task launch worker for task 56] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 37.0 (TID 56). 1011 bytes result sent to driver
2021-12-04 17:38:21,408 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 37.0 (TID 56) in 18 ms on localhost (executor driver) (1/2)
2021-12-04 17:38:21,408 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 37.0 (TID 57) in 18 ms on localhost (executor driver) (2/2)
2021-12-04 17:38:21,408 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 37.0, whose tasks have all completed, from pool 
2021-12-04 17:38:21,409 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 37 (count at PaidPromotionAdjustParameter.scala:170) finished in 0.022 s
2021-12-04 17:38:21,409 [main] INFO [org.apache.spark.scheduler.DAGScheduler] - Job 15 finished: count at PaidPromotionAdjustParameter.scala:170, took 1.036143 s
2021-12-04 17:38:21,409 [main] INFO [PaidPromotion$] - 最终验证集用户数 = 5184
2021-12-04 17:38:21,411 [main] INFO [org.apache.spark.SparkContext] - Starting job: count at PaidPromotionAdjustParameter.scala:171
2021-12-04 17:38:21,412 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 45 (intersection at PaidPromotionAdjustParameter.scala:162)
2021-12-04 17:38:21,412 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 44 (intersection at PaidPromotionAdjustParameter.scala:162)
2021-12-04 17:38:21,412 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 16 (count at PaidPromotionAdjustParameter.scala:171) with 4 output partitions
2021-12-04 17:38:21,412 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 42 (count at PaidPromotionAdjustParameter.scala:171)
2021-12-04 17:38:21,412 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 39, ShuffleMapStage 41)
2021-12-04 17:38:21,412 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List(ShuffleMapStage 39, ShuffleMapStage 41)
2021-12-04 17:38:21,412 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ShuffleMapStage 39 (MapPartitionsRDD[45] at intersection at PaidPromotionAdjustParameter.scala:162), which has no missing parents
2021-12-04 17:38:21,413 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_27 stored as values in memory (estimated size 4.0 KB, free 1990.0 MB)
2021-12-04 17:38:21,414 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_27_piece0 stored as bytes in memory (estimated size 2.3 KB, free 1990.0 MB)
2021-12-04 17:38:21,415 [dispatcher-event-loop-6] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_27_piece0 in memory on qb:60666 (size: 2.3 KB, free: 1990.6 MB)
2021-12-04 17:38:21,415 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 27 from broadcast at DAGScheduler.scala:1039
2021-12-04 17:38:21,415 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from ShuffleMapStage 39 (MapPartitionsRDD[45] at intersection at PaidPromotionAdjustParameter.scala:162) (first 15 tasks are for partitions Vector(0, 1))
2021-12-04 17:38:21,415 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 39.0 with 2 tasks
2021-12-04 17:38:21,415 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ShuffleMapStage 41 (MapPartitionsRDD[44] at intersection at PaidPromotionAdjustParameter.scala:162), which has no missing parents
2021-12-04 17:38:21,416 [dispatcher-event-loop-11] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 39.0 (TID 58, localhost, executor driver, partition 0, ANY, 7638 bytes)
2021-12-04 17:38:21,416 [dispatcher-event-loop-11] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 39.0 (TID 59, localhost, executor driver, partition 1, ANY, 7638 bytes)
2021-12-04 17:38:21,416 [Executor task launch worker for task 58] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 39.0 (TID 58)
2021-12-04 17:38:21,416 [Executor task launch worker for task 59] INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 39.0 (TID 59)
2021-12-04 17:38:21,416 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_28 stored as values in memory (estimated size 4.0 KB, free 1990.0 MB)
2021-12-04 17:38:21,417 [Executor task launch worker for task 58] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 2 non-empty blocks out of 2 blocks
2021-12-04 17:38:21,417 [Executor task launch worker for task 59] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 2 non-empty blocks out of 2 blocks
2021-12-04 17:38:21,417 [Executor task launch worker for task 58] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 1 ms
2021-12-04 17:38:21,417 [Executor task launch worker for task 59] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 1 ms
2021-12-04 17:38:21,419 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_28_piece0 stored as bytes in memory (estimated size 2.3 KB, free 1990.0 MB)
2021-12-04 17:38:21,419 [dispatcher-event-loop-2] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_28_piece0 in memory on qb:60666 (size: 2.3 KB, free: 1990.6 MB)
2021-12-04 17:38:21,419 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 28 from broadcast at DAGScheduler.scala:1039
2021-12-04 17:38:21,420 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 4 missing tasks from ShuffleMapStage 41 (MapPartitionsRDD[44] at intersection at PaidPromotionAdjustParameter.scala:162) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
2021-12-04 17:38:21,420 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 41.0 with 4 tasks
2021-12-04 17:38:21,420 [dispatcher-event-loop-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 41.0 (TID 60, localhost, executor driver, partition 0, ANY, 7638 bytes)
2021-12-04 17:38:21,420 [dispatcher-event-loop-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 41.0 (TID 61, localhost, executor driver, partition 1, ANY, 7638 bytes)
2021-12-04 17:38:21,420 [dispatcher-event-loop-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 2.0 in stage 41.0 (TID 62, localhost, executor driver, partition 2, ANY, 7638 bytes)
2021-12-04 17:38:21,420 [dispatcher-event-loop-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 3.0 in stage 41.0 (TID 63, localhost, executor driver, partition 3, ANY, 7638 bytes)
2021-12-04 17:38:21,420 [Executor task launch worker for task 60] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 41.0 (TID 60)
2021-12-04 17:38:21,420 [Executor task launch worker for task 61] INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 41.0 (TID 61)
2021-12-04 17:38:21,421 [Executor task launch worker for task 62] INFO [org.apache.spark.executor.Executor] - Running task 2.0 in stage 41.0 (TID 62)
2021-12-04 17:38:21,421 [Executor task launch worker for task 63] INFO [org.apache.spark.executor.Executor] - Running task 3.0 in stage 41.0 (TID 63)
2021-12-04 17:38:21,422 [Executor task launch worker for task 60] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 4 non-empty blocks out of 4 blocks
2021-12-04 17:38:21,422 [Executor task launch worker for task 63] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 4 non-empty blocks out of 4 blocks
2021-12-04 17:38:21,422 [Executor task launch worker for task 61] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 4 non-empty blocks out of 4 blocks
2021-12-04 17:38:21,422 [Executor task launch worker for task 60] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-04 17:38:21,422 [Executor task launch worker for task 61] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-04 17:38:21,422 [Executor task launch worker for task 63] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-04 17:38:21,422 [Executor task launch worker for task 62] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 4 non-empty blocks out of 4 blocks
2021-12-04 17:38:21,422 [Executor task launch worker for task 62] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-04 17:38:21,447 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 624
2021-12-04 17:38:21,447 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 559
2021-12-04 17:38:21,447 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 557
2021-12-04 17:38:21,447 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 562
2021-12-04 17:38:21,447 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 639
2021-12-04 17:38:21,447 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 601
2021-12-04 17:38:21,447 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 606
2021-12-04 17:38:21,447 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 592
2021-12-04 17:38:21,448 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 616
2021-12-04 17:38:21,448 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 591
2021-12-04 17:38:21,448 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 554
2021-12-04 17:38:21,448 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 567
2021-12-04 17:38:21,448 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 571
2021-12-04 17:38:21,448 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 626
2021-12-04 17:38:21,448 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 614
2021-12-04 17:38:21,448 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 558
2021-12-04 17:38:21,448 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 574
2021-12-04 17:38:21,448 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 630
2021-12-04 17:38:21,448 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 631
2021-12-04 17:38:21,448 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 590
2021-12-04 17:38:21,448 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 609
2021-12-04 17:38:21,448 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 608
2021-12-04 17:38:21,448 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 564
2021-12-04 17:38:21,448 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 575
2021-12-04 17:38:21,448 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 569
2021-12-04 17:38:21,448 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 597
2021-12-04 17:38:21,448 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 622
2021-12-04 17:38:21,448 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 570
2021-12-04 17:38:21,448 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 572
2021-12-04 17:38:21,448 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 588
2021-12-04 17:38:21,448 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 595
2021-12-04 17:38:21,448 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 579
2021-12-04 17:38:21,448 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 638
2021-12-04 17:38:21,448 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 585
2021-12-04 17:38:21,450 [dispatcher-event-loop-6] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_23_piece0 on qb:60666 in memory (size: 66.3 KB, free: 1990.7 MB)
2021-12-04 17:38:21,450 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 607
2021-12-04 17:38:21,450 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 560
2021-12-04 17:38:21,450 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 582
2021-12-04 17:38:21,450 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 643
2021-12-04 17:38:21,450 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 640
2021-12-04 17:38:21,450 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 605
2021-12-04 17:38:21,450 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 600
2021-12-04 17:38:21,450 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 552
2021-12-04 17:38:21,450 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 635
2021-12-04 17:38:21,450 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 633
2021-12-04 17:38:21,450 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 648
2021-12-04 17:38:21,450 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 602
2021-12-04 17:38:21,450 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 553
2021-12-04 17:38:21,450 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 634
2021-12-04 17:38:21,450 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 637
2021-12-04 17:38:21,450 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 594
2021-12-04 17:38:21,450 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 566
2021-12-04 17:38:21,451 [dispatcher-event-loop-1] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_26_piece0 on qb:60666 in memory (size: 2.2 KB, free: 1990.7 MB)
2021-12-04 17:38:21,452 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 563
2021-12-04 17:38:21,452 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 561
2021-12-04 17:38:21,452 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 632
2021-12-04 17:38:21,452 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 573
2021-12-04 17:38:21,452 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 625
2021-12-04 17:38:21,452 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 577
2021-12-04 17:38:21,452 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 615
2021-12-04 17:38:21,452 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 604
2021-12-04 17:38:21,452 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 627
2021-12-04 17:38:21,452 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 636
2021-12-04 17:38:21,452 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 576
2021-12-04 17:38:21,452 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 646
2021-12-04 17:38:21,452 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 617
2021-12-04 17:38:21,452 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 642
2021-12-04 17:38:21,452 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 647
2021-12-04 17:38:21,452 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 578
2021-12-04 17:38:21,452 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 621
2021-12-04 17:38:21,452 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 629
2021-12-04 17:38:21,452 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 649
2021-12-04 17:38:21,452 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 555
2021-12-04 17:38:21,452 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 620
2021-12-04 17:38:21,452 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 583
2021-12-04 17:38:21,452 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 623
2021-12-04 17:38:21,452 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 586
2021-12-04 17:38:21,452 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 599
2021-12-04 17:38:21,452 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 589
2021-12-04 17:38:21,452 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 550
2021-12-04 17:38:21,452 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 584
2021-12-04 17:38:21,452 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 580
2021-12-04 17:38:21,452 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 612
2021-12-04 17:38:21,452 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 565
2021-12-04 17:38:21,453 [dispatcher-event-loop-8] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_24_piece0 on qb:60666 in memory (size: 2.2 KB, free: 1990.7 MB)
2021-12-04 17:38:21,454 [dispatcher-event-loop-10] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_25_piece0 on qb:60666 in memory (size: 66.0 KB, free: 1990.8 MB)
2021-12-04 17:38:21,455 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 644
2021-12-04 17:38:21,455 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 603
2021-12-04 17:38:21,455 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 598
2021-12-04 17:38:21,455 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 593
2021-12-04 17:38:21,455 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 611
2021-12-04 17:38:21,455 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 645
2021-12-04 17:38:21,455 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 628
2021-12-04 17:38:21,455 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 568
2021-12-04 17:38:21,455 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 581
2021-12-04 17:38:21,455 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 551
2021-12-04 17:38:21,455 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 619
2021-12-04 17:38:21,455 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 641
2021-12-04 17:38:21,455 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 613
2021-12-04 17:38:21,455 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 587
2021-12-04 17:38:21,455 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 618
2021-12-04 17:38:21,455 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 610
2021-12-04 17:38:21,455 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 596
2021-12-04 17:38:21,455 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 556
2021-12-04 17:38:21,461 [Executor task launch worker for task 59] INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 39.0 (TID 59). 1206 bytes result sent to driver
2021-12-04 17:38:21,461 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 39.0 (TID 59) in 45 ms on localhost (executor driver) (1/2)
2021-12-04 17:38:21,461 [Executor task launch worker for task 58] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 39.0 (TID 58). 1206 bytes result sent to driver
2021-12-04 17:38:21,462 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 39.0 (TID 58) in 47 ms on localhost (executor driver) (2/2)
2021-12-04 17:38:21,462 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 39.0, whose tasks have all completed, from pool 
2021-12-04 17:38:21,462 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ShuffleMapStage 39 (intersection at PaidPromotionAdjustParameter.scala:162) finished in 0.050 s
2021-12-04 17:38:21,462 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - looking for newly runnable stages
2021-12-04 17:38:21,462 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - running: Set(ShuffleMapStage 41)
2021-12-04 17:38:21,462 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - waiting: Set(ResultStage 42)
2021-12-04 17:38:21,462 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - failed: Set()
2021-12-04 17:38:21,486 [Executor task launch worker for task 60] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 41.0 (TID 60). 1249 bytes result sent to driver
2021-12-04 17:38:21,487 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 41.0 (TID 60) in 67 ms on localhost (executor driver) (1/4)
2021-12-04 17:38:21,487 [Executor task launch worker for task 63] INFO [org.apache.spark.executor.Executor] - Finished task 3.0 in stage 41.0 (TID 63). 1206 bytes result sent to driver
2021-12-04 17:38:21,487 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 3.0 in stage 41.0 (TID 63) in 67 ms on localhost (executor driver) (2/4)
2021-12-04 17:38:21,489 [Executor task launch worker for task 61] INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 41.0 (TID 61). 1249 bytes result sent to driver
2021-12-04 17:38:21,489 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 41.0 (TID 61) in 69 ms on localhost (executor driver) (3/4)
2021-12-04 17:38:21,489 [Executor task launch worker for task 62] INFO [org.apache.spark.executor.Executor] - Finished task 2.0 in stage 41.0 (TID 62). 1249 bytes result sent to driver
2021-12-04 17:38:21,490 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 2.0 in stage 41.0 (TID 62) in 70 ms on localhost (executor driver) (4/4)
2021-12-04 17:38:21,490 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 41.0, whose tasks have all completed, from pool 
2021-12-04 17:38:21,490 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ShuffleMapStage 41 (intersection at PaidPromotionAdjustParameter.scala:162) finished in 0.074 s
2021-12-04 17:38:21,490 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - looking for newly runnable stages
2021-12-04 17:38:21,490 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - running: Set()
2021-12-04 17:38:21,490 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - waiting: Set(ResultStage 42)
2021-12-04 17:38:21,490 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - failed: Set()
2021-12-04 17:38:21,490 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 42 (MapPartitionsRDD[49] at intersection at PaidPromotionAdjustParameter.scala:162), which has no missing parents
2021-12-04 17:38:21,491 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_29 stored as values in memory (estimated size 3.6 KB, free 1990.5 MB)
2021-12-04 17:38:21,492 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_29_piece0 stored as bytes in memory (estimated size 2.1 KB, free 1990.5 MB)
2021-12-04 17:38:21,492 [dispatcher-event-loop-5] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_29_piece0 in memory on qb:60666 (size: 2.1 KB, free: 1990.8 MB)
2021-12-04 17:38:21,493 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 29 from broadcast at DAGScheduler.scala:1039
2021-12-04 17:38:21,493 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 4 missing tasks from ResultStage 42 (MapPartitionsRDD[49] at intersection at PaidPromotionAdjustParameter.scala:162) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
2021-12-04 17:38:21,493 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 42.0 with 4 tasks
2021-12-04 17:38:21,493 [dispatcher-event-loop-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 42.0 (TID 64, localhost, executor driver, partition 0, PROCESS_LOCAL, 7712 bytes)
2021-12-04 17:38:21,493 [dispatcher-event-loop-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 42.0 (TID 65, localhost, executor driver, partition 1, PROCESS_LOCAL, 7712 bytes)
2021-12-04 17:38:21,493 [dispatcher-event-loop-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 2.0 in stage 42.0 (TID 66, localhost, executor driver, partition 2, PROCESS_LOCAL, 7712 bytes)
2021-12-04 17:38:21,493 [dispatcher-event-loop-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 3.0 in stage 42.0 (TID 67, localhost, executor driver, partition 3, PROCESS_LOCAL, 7712 bytes)
2021-12-04 17:38:21,494 [Executor task launch worker for task 64] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 42.0 (TID 64)
2021-12-04 17:38:21,494 [Executor task launch worker for task 67] INFO [org.apache.spark.executor.Executor] - Running task 3.0 in stage 42.0 (TID 67)
2021-12-04 17:38:21,494 [Executor task launch worker for task 66] INFO [org.apache.spark.executor.Executor] - Running task 2.0 in stage 42.0 (TID 66)
2021-12-04 17:38:21,494 [Executor task launch worker for task 65] INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 42.0 (TID 65)
2021-12-04 17:38:21,496 [Executor task launch worker for task 65] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 4 blocks
2021-12-04 17:38:21,496 [Executor task launch worker for task 65] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-04 17:38:21,496 [Executor task launch worker for task 67] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 4 blocks
2021-12-04 17:38:21,496 [Executor task launch worker for task 67] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-04 17:38:21,496 [Executor task launch worker for task 64] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 4 blocks
2021-12-04 17:38:21,496 [Executor task launch worker for task 66] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 4 blocks
2021-12-04 17:38:21,496 [Executor task launch worker for task 66] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-04 17:38:21,496 [Executor task launch worker for task 64] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-04 17:38:21,497 [Executor task launch worker for task 64] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2021-12-04 17:38:21,497 [Executor task launch worker for task 66] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2021-12-04 17:38:21,497 [Executor task launch worker for task 66] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-04 17:38:21,497 [Executor task launch worker for task 65] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2021-12-04 17:38:21,497 [Executor task launch worker for task 65] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-04 17:38:21,497 [Executor task launch worker for task 64] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-04 17:38:21,497 [Executor task launch worker for task 67] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2021-12-04 17:38:21,497 [Executor task launch worker for task 67] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-04 17:38:21,543 [Executor task launch worker for task 67] INFO [org.apache.spark.executor.Executor] - Finished task 3.0 in stage 42.0 (TID 67). 1054 bytes result sent to driver
2021-12-04 17:38:21,543 [Executor task launch worker for task 66] INFO [org.apache.spark.executor.Executor] - Finished task 2.0 in stage 42.0 (TID 66). 1054 bytes result sent to driver
2021-12-04 17:38:21,543 [Executor task launch worker for task 64] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 42.0 (TID 64). 1054 bytes result sent to driver
2021-12-04 17:38:21,544 [Executor task launch worker for task 65] INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 42.0 (TID 65). 1054 bytes result sent to driver
2021-12-04 17:38:21,544 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 3.0 in stage 42.0 (TID 67) in 51 ms on localhost (executor driver) (1/4)
2021-12-04 17:38:21,544 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 2.0 in stage 42.0 (TID 66) in 51 ms on localhost (executor driver) (2/4)
2021-12-04 17:38:21,544 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 42.0 (TID 64) in 51 ms on localhost (executor driver) (3/4)
2021-12-04 17:38:21,544 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 42.0 (TID 65) in 51 ms on localhost (executor driver) (4/4)
2021-12-04 17:38:21,544 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 42.0, whose tasks have all completed, from pool 
2021-12-04 17:38:21,544 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 42 (count at PaidPromotionAdjustParameter.scala:171) finished in 0.054 s
2021-12-04 17:38:21,545 [main] INFO [org.apache.spark.scheduler.DAGScheduler] - Job 16 finished: count at PaidPromotionAdjustParameter.scala:171, took 0.133903 s
2021-12-04 17:38:21,545 [main] INFO [PaidPromotion$] - 最终共 同 用户数 = 5184
2021-12-04 17:38:21,547 [main] INFO [org.apache.spark.SparkContext] - Starting job: count at PaidPromotionAdjustParameter.scala:172
2021-12-04 17:38:21,547 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 51 (distinct at PaidPromotionAdjustParameter.scala:164)
2021-12-04 17:38:21,547 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 17 (count at PaidPromotionAdjustParameter.scala:172) with 4 output partitions
2021-12-04 17:38:21,547 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 44 (count at PaidPromotionAdjustParameter.scala:172)
2021-12-04 17:38:21,547 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 43)
2021-12-04 17:38:21,547 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List(ShuffleMapStage 43)
2021-12-04 17:38:21,548 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ShuffleMapStage 43 (MapPartitionsRDD[51] at distinct at PaidPromotionAdjustParameter.scala:164), which has no missing parents
2021-12-04 17:38:21,549 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_30 stored as values in memory (estimated size 186.6 KB, free 1990.3 MB)
2021-12-04 17:38:21,551 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_30_piece0 stored as bytes in memory (estimated size 66.3 KB, free 1990.2 MB)
2021-12-04 17:38:21,551 [dispatcher-event-loop-11] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_30_piece0 in memory on qb:60666 (size: 66.3 KB, free: 1990.7 MB)
2021-12-04 17:38:21,552 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 30 from broadcast at DAGScheduler.scala:1039
2021-12-04 17:38:21,552 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 4 missing tasks from ShuffleMapStage 43 (MapPartitionsRDD[51] at distinct at PaidPromotionAdjustParameter.scala:164) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
2021-12-04 17:38:21,552 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 43.0 with 4 tasks
2021-12-04 17:38:21,552 [dispatcher-event-loop-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 43.0 (TID 68, localhost, executor driver, partition 0, ANY, 7994 bytes)
2021-12-04 17:38:21,552 [dispatcher-event-loop-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 43.0 (TID 69, localhost, executor driver, partition 1, ANY, 7994 bytes)
2021-12-04 17:38:21,552 [dispatcher-event-loop-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 2.0 in stage 43.0 (TID 70, localhost, executor driver, partition 2, ANY, 7994 bytes)
2021-12-04 17:38:21,553 [dispatcher-event-loop-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 3.0 in stage 43.0 (TID 71, localhost, executor driver, partition 3, ANY, 7994 bytes)
2021-12-04 17:38:21,553 [Executor task launch worker for task 69] INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 43.0 (TID 69)
2021-12-04 17:38:21,553 [Executor task launch worker for task 71] INFO [org.apache.spark.executor.Executor] - Running task 3.0 in stage 43.0 (TID 71)
2021-12-04 17:38:21,553 [Executor task launch worker for task 70] INFO [org.apache.spark.executor.Executor] - Running task 2.0 in stage 43.0 (TID 70)
2021-12-04 17:38:21,553 [Executor task launch worker for task 68] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 43.0 (TID 68)
2021-12-04 17:38:21,555 [Executor task launch worker for task 69] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/order_data.bcp:3442194+3442195
2021-12-04 17:38:21,556 [Executor task launch worker for task 68] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/order_data.bcp:0+3442194
2021-12-04 17:38:21,556 [Executor task launch worker for task 71] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/order_data.bcp:3442194+3442195
2021-12-04 17:38:21,556 [Executor task launch worker for task 70] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/order_data.bcp:0+3442194
2021-12-04 17:38:22,424 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 687
2021-12-04 17:38:22,424 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 707
2021-12-04 17:38:22,424 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 689
2021-12-04 17:38:22,424 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 713
2021-12-04 17:38:22,424 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 675
2021-12-04 17:38:22,424 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 720
2021-12-04 17:38:22,424 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 657
2021-12-04 17:38:22,424 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 665
2021-12-04 17:38:22,425 [dispatcher-event-loop-3] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_29_piece0 on qb:60666 in memory (size: 2.1 KB, free: 1990.7 MB)
2021-12-04 17:38:22,425 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 684
2021-12-04 17:38:22,425 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 721
2021-12-04 17:38:22,425 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 652
2021-12-04 17:38:22,425 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 695
2021-12-04 17:38:22,425 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 724
2021-12-04 17:38:22,425 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 668
2021-12-04 17:38:22,425 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 688
2021-12-04 17:38:22,425 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 663
2021-12-04 17:38:22,425 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 694
2021-12-04 17:38:22,425 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 674
2021-12-04 17:38:22,425 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 700
2021-12-04 17:38:22,425 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 710
2021-12-04 17:38:22,425 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 679
2021-12-04 17:38:22,425 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 686
2021-12-04 17:38:22,425 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 650
2021-12-04 17:38:22,425 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 703
2021-12-04 17:38:22,426 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 685
2021-12-04 17:38:22,426 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 708
2021-12-04 17:38:22,426 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 723
2021-12-04 17:38:22,426 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 709
2021-12-04 17:38:22,426 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 671
2021-12-04 17:38:22,426 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 662
2021-12-04 17:38:22,426 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 659
2021-12-04 17:38:22,426 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 704
2021-12-04 17:38:22,426 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 693
2021-12-04 17:38:22,426 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 660
2021-12-04 17:38:22,426 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 672
2021-12-04 17:38:22,426 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 717
2021-12-04 17:38:22,426 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 702
2021-12-04 17:38:22,426 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 698
2021-12-04 17:38:22,426 [dispatcher-event-loop-9] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_27_piece0 on qb:60666 in memory (size: 2.3 KB, free: 1990.7 MB)
2021-12-04 17:38:22,426 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 714
2021-12-04 17:38:22,426 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 696
2021-12-04 17:38:22,426 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 653
2021-12-04 17:38:22,426 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 655
2021-12-04 17:38:22,426 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 670
2021-12-04 17:38:22,426 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 667
2021-12-04 17:38:22,426 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 666
2021-12-04 17:38:22,426 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 669
2021-12-04 17:38:22,426 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 678
2021-12-04 17:38:22,426 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 706
2021-12-04 17:38:22,426 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 701
2021-12-04 17:38:22,426 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 691
2021-12-04 17:38:22,426 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 656
2021-12-04 17:38:22,426 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 673
2021-12-04 17:38:22,426 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 651
2021-12-04 17:38:22,426 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 716
2021-12-04 17:38:22,426 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 722
2021-12-04 17:38:22,426 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 712
2021-12-04 17:38:22,426 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 680
2021-12-04 17:38:22,426 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 692
2021-12-04 17:38:22,426 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 681
2021-12-04 17:38:22,426 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 658
2021-12-04 17:38:22,426 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 654
2021-12-04 17:38:22,426 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 683
2021-12-04 17:38:22,426 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 661
2021-12-04 17:38:22,426 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 664
2021-12-04 17:38:22,426 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 711
2021-12-04 17:38:22,426 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 690
2021-12-04 17:38:22,427 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 699
2021-12-04 17:38:22,427 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 697
2021-12-04 17:38:22,427 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 719
2021-12-04 17:38:22,427 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 682
2021-12-04 17:38:22,427 [dispatcher-event-loop-5] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_28_piece0 on qb:60666 in memory (size: 2.3 KB, free: 1990.7 MB)
2021-12-04 17:38:22,427 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 718
2021-12-04 17:38:22,427 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 677
2021-12-04 17:38:22,427 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 676
2021-12-04 17:38:22,427 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 705
2021-12-04 17:38:22,427 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 715
2021-12-04 17:38:22,506 [Executor task launch worker for task 69] INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 43.0 (TID 69). 1034 bytes result sent to driver
2021-12-04 17:38:22,506 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 43.0 (TID 69) in 954 ms on localhost (executor driver) (1/4)
2021-12-04 17:38:22,560 [Executor task launch worker for task 70] INFO [org.apache.spark.executor.Executor] - Finished task 2.0 in stage 43.0 (TID 70). 1034 bytes result sent to driver
2021-12-04 17:38:22,560 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 2.0 in stage 43.0 (TID 70) in 1008 ms on localhost (executor driver) (2/4)
2021-12-04 17:38:22,800 [Executor task launch worker for task 71] INFO [org.apache.spark.executor.Executor] - Finished task 3.0 in stage 43.0 (TID 71). 1034 bytes result sent to driver
2021-12-04 17:38:22,801 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 3.0 in stage 43.0 (TID 71) in 1249 ms on localhost (executor driver) (3/4)
2021-12-04 17:38:22,886 [Executor task launch worker for task 68] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 43.0 (TID 68). 1034 bytes result sent to driver
2021-12-04 17:38:22,887 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 43.0 (TID 68) in 1335 ms on localhost (executor driver) (4/4)
2021-12-04 17:38:22,887 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 43.0, whose tasks have all completed, from pool 
2021-12-04 17:38:22,887 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ShuffleMapStage 43 (distinct at PaidPromotionAdjustParameter.scala:164) finished in 1.339 s
2021-12-04 17:38:22,887 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - looking for newly runnable stages
2021-12-04 17:38:22,887 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - running: Set()
2021-12-04 17:38:22,887 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - waiting: Set(ResultStage 44)
2021-12-04 17:38:22,887 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - failed: Set()
2021-12-04 17:38:22,887 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 44 (MapPartitionsRDD[53] at distinct at PaidPromotionAdjustParameter.scala:164), which has no missing parents
2021-12-04 17:38:22,888 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_31 stored as values in memory (estimated size 3.7 KB, free 1990.2 MB)
2021-12-04 17:38:22,889 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_31_piece0 stored as bytes in memory (estimated size 2.2 KB, free 1990.2 MB)
2021-12-04 17:38:22,889 [dispatcher-event-loop-10] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_31_piece0 in memory on qb:60666 (size: 2.2 KB, free: 1990.7 MB)
2021-12-04 17:38:22,890 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 31 from broadcast at DAGScheduler.scala:1039
2021-12-04 17:38:22,890 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 4 missing tasks from ResultStage 44 (MapPartitionsRDD[53] at distinct at PaidPromotionAdjustParameter.scala:164) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
2021-12-04 17:38:22,890 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 44.0 with 4 tasks
2021-12-04 17:38:22,890 [dispatcher-event-loop-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 44.0 (TID 72, localhost, executor driver, partition 0, ANY, 7649 bytes)
2021-12-04 17:38:22,890 [dispatcher-event-loop-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 44.0 (TID 73, localhost, executor driver, partition 1, ANY, 7649 bytes)
2021-12-04 17:38:22,890 [dispatcher-event-loop-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 2.0 in stage 44.0 (TID 74, localhost, executor driver, partition 2, ANY, 7649 bytes)
2021-12-04 17:38:22,890 [dispatcher-event-loop-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 3.0 in stage 44.0 (TID 75, localhost, executor driver, partition 3, ANY, 7649 bytes)
2021-12-04 17:38:22,891 [Executor task launch worker for task 73] INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 44.0 (TID 73)
2021-12-04 17:38:22,891 [Executor task launch worker for task 72] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 44.0 (TID 72)
2021-12-04 17:38:22,891 [Executor task launch worker for task 74] INFO [org.apache.spark.executor.Executor] - Running task 2.0 in stage 44.0 (TID 74)
2021-12-04 17:38:22,891 [Executor task launch worker for task 75] INFO [org.apache.spark.executor.Executor] - Running task 3.0 in stage 44.0 (TID 75)
2021-12-04 17:38:22,892 [Executor task launch worker for task 74] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 4 non-empty blocks out of 4 blocks
2021-12-04 17:38:22,892 [Executor task launch worker for task 75] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 4 non-empty blocks out of 4 blocks
2021-12-04 17:38:22,892 [Executor task launch worker for task 75] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-04 17:38:22,892 [Executor task launch worker for task 72] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 4 non-empty blocks out of 4 blocks
2021-12-04 17:38:22,892 [Executor task launch worker for task 74] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-04 17:38:22,892 [Executor task launch worker for task 72] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-04 17:38:22,892 [Executor task launch worker for task 73] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 4 non-empty blocks out of 4 blocks
2021-12-04 17:38:22,892 [Executor task launch worker for task 73] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-04 17:38:22,910 [Executor task launch worker for task 72] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 44.0 (TID 72). 1010 bytes result sent to driver
2021-12-04 17:38:22,910 [Executor task launch worker for task 75] INFO [org.apache.spark.executor.Executor] - Finished task 3.0 in stage 44.0 (TID 75). 967 bytes result sent to driver
2021-12-04 17:38:22,910 [Executor task launch worker for task 73] INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 44.0 (TID 73). 1010 bytes result sent to driver
2021-12-04 17:38:22,910 [Executor task launch worker for task 74] INFO [org.apache.spark.executor.Executor] - Finished task 2.0 in stage 44.0 (TID 74). 967 bytes result sent to driver
2021-12-04 17:38:22,911 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 44.0 (TID 72) in 21 ms on localhost (executor driver) (1/4)
2021-12-04 17:38:22,911 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 3.0 in stage 44.0 (TID 75) in 21 ms on localhost (executor driver) (2/4)
2021-12-04 17:38:22,911 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 44.0 (TID 73) in 21 ms on localhost (executor driver) (3/4)
2021-12-04 17:38:22,911 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 2.0 in stage 44.0 (TID 74) in 21 ms on localhost (executor driver) (4/4)
2021-12-04 17:38:22,911 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 44.0, whose tasks have all completed, from pool 
2021-12-04 17:38:22,911 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 44 (count at PaidPromotionAdjustParameter.scala:172) finished in 0.024 s
2021-12-04 17:38:22,911 [main] INFO [org.apache.spark.scheduler.DAGScheduler] - Job 17 finished: count at PaidPromotionAdjustParameter.scala:172, took 1.363650 s
2021-12-04 17:38:22,912 [main] INFO [PaidPromotion$] - 最终训练集节目数 = 132
2021-12-04 17:38:22,914 [main] INFO [org.apache.spark.SparkContext] - Starting job: count at PaidPromotionAdjustParameter.scala:173
2021-12-04 17:38:22,914 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 55 (distinct at PaidPromotionAdjustParameter.scala:165)
2021-12-04 17:38:22,914 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 18 (count at PaidPromotionAdjustParameter.scala:173) with 2 output partitions
2021-12-04 17:38:22,914 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 46 (count at PaidPromotionAdjustParameter.scala:173)
2021-12-04 17:38:22,914 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 45)
2021-12-04 17:38:22,914 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List(ShuffleMapStage 45)
2021-12-04 17:38:22,914 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ShuffleMapStage 45 (MapPartitionsRDD[55] at distinct at PaidPromotionAdjustParameter.scala:165), which has no missing parents
2021-12-04 17:38:22,916 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_32 stored as values in memory (estimated size 186.0 KB, free 1990.0 MB)
2021-12-04 17:38:22,918 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_32_piece0 stored as bytes in memory (estimated size 66.0 KB, free 1990.0 MB)
2021-12-04 17:38:22,918 [dispatcher-event-loop-4] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_32_piece0 in memory on qb:60666 (size: 66.0 KB, free: 1990.6 MB)
2021-12-04 17:38:22,918 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 32 from broadcast at DAGScheduler.scala:1039
2021-12-04 17:38:22,918 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from ShuffleMapStage 45 (MapPartitionsRDD[55] at distinct at PaidPromotionAdjustParameter.scala:165) (first 15 tasks are for partitions Vector(0, 1))
2021-12-04 17:38:22,918 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 45.0 with 2 tasks
2021-12-04 17:38:22,919 [dispatcher-event-loop-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 45.0 (TID 76, localhost, executor driver, partition 0, ANY, 7885 bytes)
2021-12-04 17:38:22,919 [dispatcher-event-loop-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 45.0 (TID 77, localhost, executor driver, partition 1, ANY, 7885 bytes)
2021-12-04 17:38:22,919 [Executor task launch worker for task 76] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 45.0 (TID 76)
2021-12-04 17:38:22,919 [Executor task launch worker for task 77] INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 45.0 (TID 77)
2021-12-04 17:38:22,922 [Executor task launch worker for task 77] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/order_data.bcp:3442194+3442195
2021-12-04 17:38:22,922 [Executor task launch worker for task 76] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/order_data.bcp:0+3442194
2021-12-04 17:38:23,847 [Executor task launch worker for task 76] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 45.0 (TID 76). 1032 bytes result sent to driver
2021-12-04 17:38:23,847 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 45.0 (TID 76) in 928 ms on localhost (executor driver) (1/2)
2021-12-04 17:38:24,194 [Executor task launch worker for task 77] INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 45.0 (TID 77). 1032 bytes result sent to driver
2021-12-04 17:38:24,195 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 45.0 (TID 77) in 1276 ms on localhost (executor driver) (2/2)
2021-12-04 17:38:24,195 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 45.0, whose tasks have all completed, from pool 
2021-12-04 17:38:24,195 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ShuffleMapStage 45 (distinct at PaidPromotionAdjustParameter.scala:165) finished in 1.280 s
2021-12-04 17:38:24,195 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - looking for newly runnable stages
2021-12-04 17:38:24,195 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - running: Set()
2021-12-04 17:38:24,195 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - waiting: Set(ResultStage 46)
2021-12-04 17:38:24,195 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - failed: Set()
2021-12-04 17:38:24,195 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 46 (MapPartitionsRDD[57] at distinct at PaidPromotionAdjustParameter.scala:165), which has no missing parents
2021-12-04 17:38:24,196 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_33 stored as values in memory (estimated size 3.7 KB, free 1990.0 MB)
2021-12-04 17:38:24,197 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_33_piece0 stored as bytes in memory (estimated size 2.2 KB, free 1990.0 MB)
2021-12-04 17:38:24,197 [dispatcher-event-loop-6] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_33_piece0 in memory on qb:60666 (size: 2.2 KB, free: 1990.6 MB)
2021-12-04 17:38:24,197 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 33 from broadcast at DAGScheduler.scala:1039
2021-12-04 17:38:24,198 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from ResultStage 46 (MapPartitionsRDD[57] at distinct at PaidPromotionAdjustParameter.scala:165) (first 15 tasks are for partitions Vector(0, 1))
2021-12-04 17:38:24,198 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 46.0 with 2 tasks
2021-12-04 17:38:24,198 [dispatcher-event-loop-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 46.0 (TID 78, localhost, executor driver, partition 0, ANY, 7649 bytes)
2021-12-04 17:38:24,198 [dispatcher-event-loop-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 46.0 (TID 79, localhost, executor driver, partition 1, ANY, 7649 bytes)
2021-12-04 17:38:24,198 [Executor task launch worker for task 79] INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 46.0 (TID 79)
2021-12-04 17:38:24,198 [Executor task launch worker for task 78] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 46.0 (TID 78)
2021-12-04 17:38:24,202 [Executor task launch worker for task 79] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 2 non-empty blocks out of 2 blocks
2021-12-04 17:38:24,202 [Executor task launch worker for task 78] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 2 non-empty blocks out of 2 blocks
2021-12-04 17:38:24,202 [Executor task launch worker for task 79] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-04 17:38:24,202 [Executor task launch worker for task 78] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-04 17:38:24,213 [Executor task launch worker for task 78] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 46.0 (TID 78). 1010 bytes result sent to driver
2021-12-04 17:38:24,213 [Executor task launch worker for task 79] INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 46.0 (TID 79). 967 bytes result sent to driver
2021-12-04 17:38:24,214 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 46.0 (TID 78) in 16 ms on localhost (executor driver) (1/2)
2021-12-04 17:38:24,214 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 46.0 (TID 79) in 16 ms on localhost (executor driver) (2/2)
2021-12-04 17:38:24,214 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 46.0, whose tasks have all completed, from pool 
2021-12-04 17:38:24,214 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 46 (count at PaidPromotionAdjustParameter.scala:173) finished in 0.019 s
2021-12-04 17:38:24,214 [main] INFO [org.apache.spark.scheduler.DAGScheduler] - Job 18 finished: count at PaidPromotionAdjustParameter.scala:173, took 1.300876 s
2021-12-04 17:38:24,214 [main] INFO [PaidPromotion$] - 最终验证集节目数 = 81
2021-12-04 17:38:24,217 [main] INFO [org.apache.spark.SparkContext] - Starting job: count at PaidPromotionAdjustParameter.scala:174
2021-12-04 17:38:24,217 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 58 (intersection at PaidPromotionAdjustParameter.scala:166)
2021-12-04 17:38:24,217 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 59 (intersection at PaidPromotionAdjustParameter.scala:166)
2021-12-04 17:38:24,217 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 19 (count at PaidPromotionAdjustParameter.scala:174) with 4 output partitions
2021-12-04 17:38:24,217 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 51 (count at PaidPromotionAdjustParameter.scala:174)
2021-12-04 17:38:24,217 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 48, ShuffleMapStage 50)
2021-12-04 17:38:24,217 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List(ShuffleMapStage 48, ShuffleMapStage 50)
2021-12-04 17:38:24,217 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ShuffleMapStage 48 (MapPartitionsRDD[58] at intersection at PaidPromotionAdjustParameter.scala:166), which has no missing parents
2021-12-04 17:38:24,218 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_34 stored as values in memory (estimated size 4.0 KB, free 1990.0 MB)
2021-12-04 17:38:24,220 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_34_piece0 stored as bytes in memory (estimated size 2.3 KB, free 1990.0 MB)
2021-12-04 17:38:24,220 [dispatcher-event-loop-4] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_34_piece0 in memory on qb:60666 (size: 2.3 KB, free: 1990.6 MB)
2021-12-04 17:38:24,221 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 34 from broadcast at DAGScheduler.scala:1039
2021-12-04 17:38:24,221 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 4 missing tasks from ShuffleMapStage 48 (MapPartitionsRDD[58] at intersection at PaidPromotionAdjustParameter.scala:166) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
2021-12-04 17:38:24,221 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 48.0 with 4 tasks
2021-12-04 17:38:24,221 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ShuffleMapStage 50 (MapPartitionsRDD[59] at intersection at PaidPromotionAdjustParameter.scala:166), which has no missing parents
2021-12-04 17:38:24,221 [dispatcher-event-loop-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 48.0 (TID 80, localhost, executor driver, partition 0, ANY, 7638 bytes)
2021-12-04 17:38:24,221 [dispatcher-event-loop-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 48.0 (TID 81, localhost, executor driver, partition 1, ANY, 7638 bytes)
2021-12-04 17:38:24,221 [dispatcher-event-loop-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 2.0 in stage 48.0 (TID 82, localhost, executor driver, partition 2, ANY, 7638 bytes)
2021-12-04 17:38:24,221 [dispatcher-event-loop-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 3.0 in stage 48.0 (TID 83, localhost, executor driver, partition 3, ANY, 7638 bytes)
2021-12-04 17:38:24,222 [Executor task launch worker for task 80] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 48.0 (TID 80)
2021-12-04 17:38:24,222 [Executor task launch worker for task 83] INFO [org.apache.spark.executor.Executor] - Running task 3.0 in stage 48.0 (TID 83)
2021-12-04 17:38:24,222 [Executor task launch worker for task 81] INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 48.0 (TID 81)
2021-12-04 17:38:24,222 [Executor task launch worker for task 82] INFO [org.apache.spark.executor.Executor] - Running task 2.0 in stage 48.0 (TID 82)
2021-12-04 17:38:24,222 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_35 stored as values in memory (estimated size 4.0 KB, free 1990.0 MB)
2021-12-04 17:38:24,223 [Executor task launch worker for task 80] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 4 non-empty blocks out of 4 blocks
2021-12-04 17:38:24,223 [Executor task launch worker for task 82] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 4 non-empty blocks out of 4 blocks
2021-12-04 17:38:24,223 [Executor task launch worker for task 81] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 4 non-empty blocks out of 4 blocks
2021-12-04 17:38:24,223 [Executor task launch worker for task 80] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-04 17:38:24,223 [Executor task launch worker for task 83] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 4 non-empty blocks out of 4 blocks
2021-12-04 17:38:24,223 [Executor task launch worker for task 82] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-04 17:38:24,223 [Executor task launch worker for task 83] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-04 17:38:24,223 [Executor task launch worker for task 81] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-04 17:38:24,223 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_35_piece0 stored as bytes in memory (estimated size 2.3 KB, free 1990.0 MB)
2021-12-04 17:38:24,224 [dispatcher-event-loop-6] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_35_piece0 in memory on qb:60666 (size: 2.3 KB, free: 1990.6 MB)
2021-12-04 17:38:24,224 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 35 from broadcast at DAGScheduler.scala:1039
2021-12-04 17:38:24,224 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from ShuffleMapStage 50 (MapPartitionsRDD[59] at intersection at PaidPromotionAdjustParameter.scala:166) (first 15 tasks are for partitions Vector(0, 1))
2021-12-04 17:38:24,224 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 50.0 with 2 tasks
2021-12-04 17:38:24,225 [dispatcher-event-loop-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 50.0 (TID 84, localhost, executor driver, partition 0, ANY, 7638 bytes)
2021-12-04 17:38:24,225 [dispatcher-event-loop-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 50.0 (TID 85, localhost, executor driver, partition 1, ANY, 7638 bytes)
2021-12-04 17:38:24,225 [Executor task launch worker for task 85] INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 50.0 (TID 85)
2021-12-04 17:38:24,225 [Executor task launch worker for task 84] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 50.0 (TID 84)
2021-12-04 17:38:24,226 [Executor task launch worker for task 84] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 2 non-empty blocks out of 2 blocks
2021-12-04 17:38:24,226 [Executor task launch worker for task 85] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 2 non-empty blocks out of 2 blocks
2021-12-04 17:38:24,226 [Executor task launch worker for task 84] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-04 17:38:24,226 [Executor task launch worker for task 85] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-04 17:38:24,236 [Executor task launch worker for task 80] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 48.0 (TID 80). 1163 bytes result sent to driver
2021-12-04 17:38:24,237 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 48.0 (TID 80) in 16 ms on localhost (executor driver) (1/4)
2021-12-04 17:38:24,238 [Executor task launch worker for task 81] INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 48.0 (TID 81). 1120 bytes result sent to driver
2021-12-04 17:38:24,238 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 48.0 (TID 81) in 17 ms on localhost (executor driver) (2/4)
2021-12-04 17:38:24,240 [Executor task launch worker for task 82] INFO [org.apache.spark.executor.Executor] - Finished task 2.0 in stage 48.0 (TID 82). 1120 bytes result sent to driver
2021-12-04 17:38:24,241 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 2.0 in stage 48.0 (TID 82) in 20 ms on localhost (executor driver) (3/4)
2021-12-04 17:38:24,241 [Executor task launch worker for task 83] INFO [org.apache.spark.executor.Executor] - Finished task 3.0 in stage 48.0 (TID 83). 1120 bytes result sent to driver
2021-12-04 17:38:24,242 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 3.0 in stage 48.0 (TID 83) in 21 ms on localhost (executor driver) (4/4)
2021-12-04 17:38:24,242 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 48.0, whose tasks have all completed, from pool 
2021-12-04 17:38:24,242 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ShuffleMapStage 48 (intersection at PaidPromotionAdjustParameter.scala:166) finished in 0.024 s
2021-12-04 17:38:24,242 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - looking for newly runnable stages
2021-12-04 17:38:24,242 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - running: Set(ShuffleMapStage 50)
2021-12-04 17:38:24,242 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - waiting: Set(ResultStage 51)
2021-12-04 17:38:24,242 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - failed: Set()
2021-12-04 17:38:24,249 [Executor task launch worker for task 85] INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 50.0 (TID 85). 1206 bytes result sent to driver
2021-12-04 17:38:24,250 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 50.0 (TID 85) in 25 ms on localhost (executor driver) (1/2)
2021-12-04 17:38:24,250 [Executor task launch worker for task 84] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 50.0 (TID 84). 1206 bytes result sent to driver
2021-12-04 17:38:24,250 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 50.0 (TID 84) in 26 ms on localhost (executor driver) (2/2)
2021-12-04 17:38:24,250 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 50.0, whose tasks have all completed, from pool 
2021-12-04 17:38:24,250 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ShuffleMapStage 50 (intersection at PaidPromotionAdjustParameter.scala:166) finished in 0.029 s
2021-12-04 17:38:24,250 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - looking for newly runnable stages
2021-12-04 17:38:24,250 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - running: Set()
2021-12-04 17:38:24,250 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - waiting: Set(ResultStage 51)
2021-12-04 17:38:24,250 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - failed: Set()
2021-12-04 17:38:24,250 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 51 (MapPartitionsRDD[63] at intersection at PaidPromotionAdjustParameter.scala:166), which has no missing parents
2021-12-04 17:38:24,251 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_36 stored as values in memory (estimated size 3.6 KB, free 1989.9 MB)
2021-12-04 17:38:24,253 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_36_piece0 stored as bytes in memory (estimated size 2.1 KB, free 1989.9 MB)
2021-12-04 17:38:24,253 [dispatcher-event-loop-7] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_36_piece0 in memory on qb:60666 (size: 2.1 KB, free: 1990.6 MB)
2021-12-04 17:38:24,253 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 36 from broadcast at DAGScheduler.scala:1039
2021-12-04 17:38:24,254 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 4 missing tasks from ResultStage 51 (MapPartitionsRDD[63] at intersection at PaidPromotionAdjustParameter.scala:166) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
2021-12-04 17:38:24,254 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 51.0 with 4 tasks
2021-12-04 17:38:24,254 [dispatcher-event-loop-9] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 51.0 (TID 86, localhost, executor driver, partition 0, PROCESS_LOCAL, 7712 bytes)
2021-12-04 17:38:24,254 [dispatcher-event-loop-9] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 51.0 (TID 87, localhost, executor driver, partition 1, PROCESS_LOCAL, 7712 bytes)
2021-12-04 17:38:24,254 [dispatcher-event-loop-9] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 2.0 in stage 51.0 (TID 88, localhost, executor driver, partition 2, PROCESS_LOCAL, 7712 bytes)
2021-12-04 17:38:24,254 [dispatcher-event-loop-9] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 3.0 in stage 51.0 (TID 89, localhost, executor driver, partition 3, PROCESS_LOCAL, 7712 bytes)
2021-12-04 17:38:24,255 [Executor task launch worker for task 88] INFO [org.apache.spark.executor.Executor] - Running task 2.0 in stage 51.0 (TID 88)
2021-12-04 17:38:24,255 [Executor task launch worker for task 87] INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 51.0 (TID 87)
2021-12-04 17:38:24,255 [Executor task launch worker for task 89] INFO [org.apache.spark.executor.Executor] - Running task 3.0 in stage 51.0 (TID 89)
2021-12-04 17:38:24,255 [Executor task launch worker for task 86] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 51.0 (TID 86)
2021-12-04 17:38:24,256 [Executor task launch worker for task 86] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 4 blocks
2021-12-04 17:38:24,256 [Executor task launch worker for task 87] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 4 blocks
2021-12-04 17:38:24,256 [Executor task launch worker for task 89] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 4 blocks
2021-12-04 17:38:24,256 [Executor task launch worker for task 87] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-04 17:38:24,256 [Executor task launch worker for task 86] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-04 17:38:24,256 [Executor task launch worker for task 88] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 4 blocks
2021-12-04 17:38:24,256 [Executor task launch worker for task 89] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-04 17:38:24,256 [Executor task launch worker for task 88] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-04 17:38:24,257 [Executor task launch worker for task 88] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2021-12-04 17:38:24,257 [Executor task launch worker for task 89] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2021-12-04 17:38:24,258 [Executor task launch worker for task 88] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 1 ms
2021-12-04 17:38:24,257 [Executor task launch worker for task 87] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2021-12-04 17:38:24,258 [Executor task launch worker for task 89] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 1 ms
2021-12-04 17:38:24,258 [Executor task launch worker for task 86] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2021-12-04 17:38:24,258 [Executor task launch worker for task 87] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 1 ms
2021-12-04 17:38:24,258 [Executor task launch worker for task 86] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 1 ms
2021-12-04 17:38:24,265 [Executor task launch worker for task 89] INFO [org.apache.spark.executor.Executor] - Finished task 3.0 in stage 51.0 (TID 89). 967 bytes result sent to driver
2021-12-04 17:38:24,265 [Executor task launch worker for task 88] INFO [org.apache.spark.executor.Executor] - Finished task 2.0 in stage 51.0 (TID 88). 967 bytes result sent to driver
2021-12-04 17:38:24,265 [Executor task launch worker for task 86] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 51.0 (TID 86). 967 bytes result sent to driver
2021-12-04 17:38:24,266 [Executor task launch worker for task 87] INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 51.0 (TID 87). 967 bytes result sent to driver
2021-12-04 17:38:24,266 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 3.0 in stage 51.0 (TID 89) in 12 ms on localhost (executor driver) (1/4)
2021-12-04 17:38:24,266 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 2.0 in stage 51.0 (TID 88) in 12 ms on localhost (executor driver) (2/4)
2021-12-04 17:38:24,266 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 51.0 (TID 87) in 12 ms on localhost (executor driver) (3/4)
2021-12-04 17:38:24,266 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 51.0 (TID 86) in 12 ms on localhost (executor driver) (4/4)
2021-12-04 17:38:24,266 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 51.0, whose tasks have all completed, from pool 
2021-12-04 17:38:24,266 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 51 (count at PaidPromotionAdjustParameter.scala:174) finished in 0.015 s
2021-12-04 17:38:24,267 [main] INFO [org.apache.spark.scheduler.DAGScheduler] - Job 19 finished: count at PaidPromotionAdjustParameter.scala:174, took 0.049989 s
2021-12-04 17:38:24,267 [main] INFO [PaidPromotion$] - 最终共 同 节目数 = 81
2021-12-04 17:38:24,283 [main] INFO [org.apache.hadoop.conf.Configuration.deprecation] - mapred.output.dir is deprecated. Instead, use mapreduce.output.fileoutputformat.outputdir
2021-12-04 17:38:24,285 [main] INFO [org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter] - File Output Committer Algorithm version is 1
2021-12-04 17:38:24,322 [main] INFO [org.apache.spark.SparkContext] - Starting job: runJob at SparkHadoopWriter.scala:78
2021-12-04 17:38:24,322 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 20 (runJob at SparkHadoopWriter.scala:78) with 1 output partitions
2021-12-04 17:38:24,322 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 52 (runJob at SparkHadoopWriter.scala:78)
2021-12-04 17:38:24,322 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List()
2021-12-04 17:38:24,322 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2021-12-04 17:38:24,323 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 52 (MapPartitionsRDD[66] at saveAsTextFile at PaidPromotionAdjustParameter.scala:179), which has no missing parents
2021-12-04 17:38:24,332 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_37 stored as values in memory (estimated size 261.6 KB, free 1989.7 MB)
2021-12-04 17:38:24,334 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_37_piece0 stored as bytes in memory (estimated size 94.4 KB, free 1989.6 MB)
2021-12-04 17:38:24,334 [dispatcher-event-loop-10] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_37_piece0 in memory on qb:60666 (size: 94.4 KB, free: 1990.5 MB)
2021-12-04 17:38:24,335 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 37 from broadcast at DAGScheduler.scala:1039
2021-12-04 17:38:24,335 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 52 (MapPartitionsRDD[66] at saveAsTextFile at PaidPromotionAdjustParameter.scala:179) (first 15 tasks are for partitions Vector(0))
2021-12-04 17:38:24,335 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 52.0 with 1 tasks
2021-12-04 17:38:24,337 [dispatcher-event-loop-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 52.0 (TID 90, localhost, executor driver, partition 0, ANY, 8509 bytes)
2021-12-04 17:38:24,337 [Executor task launch worker for task 90] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 52.0 (TID 90)
2021-12-04 17:38:24,352 [Executor task launch worker for task 90] INFO [org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter] - File Output Committer Algorithm version is 1
2021-12-04 17:38:24,377 [Executor task launch worker for task 90] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/order_data.bcp:0+3442194
2021-12-04 17:38:25,275 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 865
2021-12-04 17:38:25,275 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 880
2021-12-04 17:38:25,275 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 867
2021-12-04 17:38:25,276 [dispatcher-event-loop-6] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_36_piece0 on qb:60666 in memory (size: 2.1 KB, free: 1990.5 MB)
2021-12-04 17:38:25,277 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 842
2021-12-04 17:38:25,277 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 767
2021-12-04 17:38:25,277 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 772
2021-12-04 17:38:25,277 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 895
2021-12-04 17:38:25,277 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 777
2021-12-04 17:38:25,277 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 854
2021-12-04 17:38:25,277 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 862
2021-12-04 17:38:25,277 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 882
2021-12-04 17:38:25,277 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 789
2021-12-04 17:38:25,277 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 857
2021-12-04 17:38:25,277 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 828
2021-12-04 17:38:25,277 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 814
2021-12-04 17:38:25,277 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 863
2021-12-04 17:38:25,277 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 769
2021-12-04 17:38:25,277 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 885
2021-12-04 17:38:25,277 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 825
2021-12-04 17:38:25,277 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 753
2021-12-04 17:38:25,277 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 726
2021-12-04 17:38:25,277 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 759
2021-12-04 17:38:25,277 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 790
2021-12-04 17:38:25,277 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 771
2021-12-04 17:38:25,277 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 851
2021-12-04 17:38:25,277 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 743
2021-12-04 17:38:25,277 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 763
2021-12-04 17:38:25,277 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 841
2021-12-04 17:38:25,277 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 852
2021-12-04 17:38:25,277 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 795
2021-12-04 17:38:25,277 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 866
2021-12-04 17:38:25,277 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 839
2021-12-04 17:38:25,277 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 775
2021-12-04 17:38:25,277 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 808
2021-12-04 17:38:25,277 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 818
2021-12-04 17:38:25,277 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 837
2021-12-04 17:38:25,277 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 843
2021-12-04 17:38:25,277 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 797
2021-12-04 17:38:25,277 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 815
2021-12-04 17:38:25,277 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 746
2021-12-04 17:38:25,277 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 785
2021-12-04 17:38:25,277 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 742
2021-12-04 17:38:25,278 [dispatcher-event-loop-8] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_32_piece0 on qb:60666 in memory (size: 66.0 KB, free: 1990.6 MB)
2021-12-04 17:38:25,278 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 798
2021-12-04 17:38:25,278 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 725
2021-12-04 17:38:25,278 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 739
2021-12-04 17:38:25,278 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 813
2021-12-04 17:38:25,278 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 796
2021-12-04 17:38:25,278 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 824
2021-12-04 17:38:25,278 [dispatcher-event-loop-11] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_33_piece0 on qb:60666 in memory (size: 2.2 KB, free: 1990.6 MB)
2021-12-04 17:38:25,278 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 803
2021-12-04 17:38:25,278 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 734
2021-12-04 17:38:25,278 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 831
2021-12-04 17:38:25,278 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 792
2021-12-04 17:38:25,278 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 770
2021-12-04 17:38:25,278 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 737
2021-12-04 17:38:25,278 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 805
2021-12-04 17:38:25,278 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 762
2021-12-04 17:38:25,279 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 823
2021-12-04 17:38:25,279 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 821
2021-12-04 17:38:25,279 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 744
2021-12-04 17:38:25,279 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 858
2021-12-04 17:38:25,279 [dispatcher-event-loop-7] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_31_piece0 on qb:60666 in memory (size: 2.2 KB, free: 1990.6 MB)
2021-12-04 17:38:25,279 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 745
2021-12-04 17:38:25,279 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 781
2021-12-04 17:38:25,279 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 899
2021-12-04 17:38:25,279 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 887
2021-12-04 17:38:25,279 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 806
2021-12-04 17:38:25,279 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 879
2021-12-04 17:38:25,279 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 860
2021-12-04 17:38:25,279 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 868
2021-12-04 17:38:25,279 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 836
2021-12-04 17:38:25,279 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 893
2021-12-04 17:38:25,279 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 794
2021-12-04 17:38:25,279 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 755
2021-12-04 17:38:25,279 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 898
2021-12-04 17:38:25,279 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 838
2021-12-04 17:38:25,279 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 848
2021-12-04 17:38:25,279 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 859
2021-12-04 17:38:25,279 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 832
2021-12-04 17:38:25,279 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 756
2021-12-04 17:38:25,279 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 812
2021-12-04 17:38:25,279 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 760
2021-12-04 17:38:25,279 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 776
2021-12-04 17:38:25,279 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 891
2021-12-04 17:38:25,279 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 728
2021-12-04 17:38:25,279 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 758
2021-12-04 17:38:25,279 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 784
2021-12-04 17:38:25,279 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 822
2021-12-04 17:38:25,280 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 881
2021-12-04 17:38:25,280 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 869
2021-12-04 17:38:25,280 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 853
2021-12-04 17:38:25,280 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 845
2021-12-04 17:38:25,280 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 875
2021-12-04 17:38:25,280 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 751
2021-12-04 17:38:25,280 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 856
2021-12-04 17:38:25,280 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 829
2021-12-04 17:38:25,280 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 783
2021-12-04 17:38:25,280 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 834
2021-12-04 17:38:25,280 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 878
2021-12-04 17:38:25,280 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 817
2021-12-04 17:38:25,280 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 809
2021-12-04 17:38:25,280 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 754
2021-12-04 17:38:25,280 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 730
2021-12-04 17:38:25,280 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 827
2021-12-04 17:38:25,280 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 748
2021-12-04 17:38:25,280 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 733
2021-12-04 17:38:25,280 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 799
2021-12-04 17:38:25,280 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 883
2021-12-04 17:38:25,280 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 732
2021-12-04 17:38:25,280 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 736
2021-12-04 17:38:25,280 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 793
2021-12-04 17:38:25,280 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 738
2021-12-04 17:38:25,280 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 855
2021-12-04 17:38:25,280 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 861
2021-12-04 17:38:25,280 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 761
2021-12-04 17:38:25,280 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 786
2021-12-04 17:38:25,280 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 788
2021-12-04 17:38:25,280 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 870
2021-12-04 17:38:25,280 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 819
2021-12-04 17:38:25,280 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 864
2021-12-04 17:38:25,280 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 840
2021-12-04 17:38:25,280 [dispatcher-event-loop-6] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_34_piece0 on qb:60666 in memory (size: 2.3 KB, free: 1990.6 MB)
2021-12-04 17:38:25,280 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 752
2021-12-04 17:38:25,280 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 873
2021-12-04 17:38:25,280 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 811
2021-12-04 17:38:25,280 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 773
2021-12-04 17:38:25,280 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 830
2021-12-04 17:38:25,280 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 820
2021-12-04 17:38:25,280 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 849
2021-12-04 17:38:25,280 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 896
2021-12-04 17:38:25,280 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 884
2021-12-04 17:38:25,280 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 765
2021-12-04 17:38:25,280 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 768
2021-12-04 17:38:25,280 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 740
2021-12-04 17:38:25,281 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 807
2021-12-04 17:38:25,281 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 757
2021-12-04 17:38:25,281 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 810
2021-12-04 17:38:25,281 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 894
2021-12-04 17:38:25,281 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 897
2021-12-04 17:38:25,281 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 835
2021-12-04 17:38:25,281 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 735
2021-12-04 17:38:25,281 [dispatcher-event-loop-8] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_30_piece0 on qb:60666 in memory (size: 66.3 KB, free: 1990.7 MB)
2021-12-04 17:38:25,281 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 877
2021-12-04 17:38:25,281 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 847
2021-12-04 17:38:25,281 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 741
2021-12-04 17:38:25,281 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 886
2021-12-04 17:38:25,281 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 747
2021-12-04 17:38:25,281 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 766
2021-12-04 17:38:25,281 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 731
2021-12-04 17:38:25,281 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 889
2021-12-04 17:38:25,281 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 802
2021-12-04 17:38:25,281 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 833
2021-12-04 17:38:25,281 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 850
2021-12-04 17:38:25,281 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 876
2021-12-04 17:38:25,281 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 749
2021-12-04 17:38:25,281 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 844
2021-12-04 17:38:25,281 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 804
2021-12-04 17:38:25,281 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 779
2021-12-04 17:38:25,281 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 727
2021-12-04 17:38:25,281 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 801
2021-12-04 17:38:25,281 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 826
2021-12-04 17:38:25,281 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 778
2021-12-04 17:38:25,281 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 800
2021-12-04 17:38:25,281 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 782
2021-12-04 17:38:25,281 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 816
2021-12-04 17:38:25,281 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 874
2021-12-04 17:38:25,281 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 750
2021-12-04 17:38:25,281 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 888
2021-12-04 17:38:25,281 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 890
2021-12-04 17:38:25,281 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 791
2021-12-04 17:38:25,281 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 892
2021-12-04 17:38:25,281 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 872
2021-12-04 17:38:25,281 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 787
2021-12-04 17:38:25,281 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 846
2021-12-04 17:38:25,281 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 764
2021-12-04 17:38:25,281 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 780
2021-12-04 17:38:25,281 [dispatcher-event-loop-11] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_35_piece0 on qb:60666 in memory (size: 2.3 KB, free: 1990.7 MB)
2021-12-04 17:38:25,281 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 729
2021-12-04 17:38:25,281 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 774
2021-12-04 17:38:25,281 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 871
2021-12-04 17:38:25,329 [Executor task launch worker for task 90] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/order_data.bcp:3442194+3442195
2021-12-04 17:38:26,169 [Executor task launch worker for task 90] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/order_data.bcp:0+3442194
2021-12-04 17:38:26,686 [Executor task launch worker for task 90] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/order_data.bcp:3442194+3442195
2021-12-04 17:38:27,337 [Executor task launch worker for task 90] INFO [org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter] - Saved output of task 'attempt_20211204173824_0066_m_000000_0' to hdfs://hdp1:8020/sk/chongqing/handle_data/set-train-device-production-data/_temporary/0/task_20211204173824_0066_m_000000
2021-12-04 17:38:27,337 [Executor task launch worker for task 90] INFO [org.apache.spark.mapred.SparkHadoopMapRedUtil] - attempt_20211204173824_0066_m_000000_0: Committed
2021-12-04 17:38:27,339 [Executor task launch worker for task 90] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 52.0 (TID 90). 1041 bytes result sent to driver
2021-12-04 17:38:27,342 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 52.0 (TID 90) in 3007 ms on localhost (executor driver) (1/1)
2021-12-04 17:38:27,342 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 52.0, whose tasks have all completed, from pool 
2021-12-04 17:38:27,342 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 52 (runJob at SparkHadoopWriter.scala:78) finished in 3.019 s
2021-12-04 17:38:27,342 [main] INFO [org.apache.spark.scheduler.DAGScheduler] - Job 20 finished: runJob at SparkHadoopWriter.scala:78, took 3.020655 s
2021-12-04 17:38:27,426 [main] INFO [org.apache.spark.internal.io.SparkHadoopWriter] - Job job_20211204173824_0066 committed.
2021-12-04 17:38:27,430 [main] INFO [org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter] - File Output Committer Algorithm version is 1
2021-12-04 17:38:27,453 [main] INFO [org.apache.spark.SparkContext] - Starting job: runJob at SparkHadoopWriter.scala:78
2021-12-04 17:38:27,453 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 21 (runJob at SparkHadoopWriter.scala:78) with 1 output partitions
2021-12-04 17:38:27,453 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 53 (runJob at SparkHadoopWriter.scala:78)
2021-12-04 17:38:27,453 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List()
2021-12-04 17:38:27,453 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2021-12-04 17:38:27,453 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 53 (MapPartitionsRDD[69] at saveAsTextFile at PaidPromotionAdjustParameter.scala:182), which has no missing parents
2021-12-04 17:38:27,462 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_38 stored as values in memory (estimated size 261.1 KB, free 1989.9 MB)
2021-12-04 17:38:27,464 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_38_piece0 stored as bytes in memory (estimated size 94.0 KB, free 1989.8 MB)
2021-12-04 17:38:27,464 [dispatcher-event-loop-7] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_38_piece0 in memory on qb:60666 (size: 94.0 KB, free: 1990.6 MB)
2021-12-04 17:38:27,465 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 38 from broadcast at DAGScheduler.scala:1039
2021-12-04 17:38:27,466 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 53 (MapPartitionsRDD[69] at saveAsTextFile at PaidPromotionAdjustParameter.scala:182) (first 15 tasks are for partitions Vector(0))
2021-12-04 17:38:27,466 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 53.0 with 1 tasks
2021-12-04 17:38:27,466 [dispatcher-event-loop-9] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 53.0 (TID 91, localhost, executor driver, partition 0, ANY, 8337 bytes)
2021-12-04 17:38:27,466 [Executor task launch worker for task 91] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 53.0 (TID 91)
2021-12-04 17:38:27,472 [Executor task launch worker for task 91] INFO [org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter] - File Output Committer Algorithm version is 1
2021-12-04 17:38:27,478 [Executor task launch worker for task 91] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/order_data.bcp:0+3442194
2021-12-04 17:38:28,383 [Executor task launch worker for task 91] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/order_data.bcp:3442194+3442195
2021-12-04 17:38:29,043 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 919
2021-12-04 17:38:29,044 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 920
2021-12-04 17:38:29,045 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 900
2021-12-04 17:38:29,045 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 916
2021-12-04 17:38:29,045 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 913
2021-12-04 17:38:29,045 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 912
2021-12-04 17:38:29,045 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 917
2021-12-04 17:38:29,045 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 910
2021-12-04 17:38:29,045 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 906
2021-12-04 17:38:29,045 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 904
2021-12-04 17:38:29,045 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 909
2021-12-04 17:38:29,047 [dispatcher-event-loop-2] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_37_piece0 on qb:60666 in memory (size: 94.4 KB, free: 1990.7 MB)
2021-12-04 17:38:29,047 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 923
2021-12-04 17:38:29,047 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 915
2021-12-04 17:38:29,047 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 901
2021-12-04 17:38:29,047 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 914
2021-12-04 17:38:29,047 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 922
2021-12-04 17:38:29,047 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 908
2021-12-04 17:38:29,047 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 905
2021-12-04 17:38:29,047 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 911
2021-12-04 17:38:29,047 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 924
2021-12-04 17:38:29,047 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 907
2021-12-04 17:38:29,047 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 903
2021-12-04 17:38:29,047 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 918
2021-12-04 17:38:29,047 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 902
2021-12-04 17:38:29,047 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 921
2021-12-04 17:38:29,319 [Executor task launch worker for task 91] INFO [org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter] - Saved output of task 'attempt_20211204173827_0069_m_000000_0' to hdfs://hdp1:8020/sk/chongqing/handle_data/set-validation-device-production-data/_temporary/0/task_20211204173827_0069_m_000000
2021-12-04 17:38:29,320 [Executor task launch worker for task 91] INFO [org.apache.spark.mapred.SparkHadoopMapRedUtil] - attempt_20211204173827_0069_m_000000_0: Committed
2021-12-04 17:38:29,321 [Executor task launch worker for task 91] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 53.0 (TID 91). 998 bytes result sent to driver
2021-12-04 17:38:29,322 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 53.0 (TID 91) in 1856 ms on localhost (executor driver) (1/1)
2021-12-04 17:38:29,322 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 53.0, whose tasks have all completed, from pool 
2021-12-04 17:38:29,322 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 53 (runJob at SparkHadoopWriter.scala:78) finished in 1.868 s
2021-12-04 17:38:29,322 [main] INFO [org.apache.spark.scheduler.DAGScheduler] - Job 21 finished: runJob at SparkHadoopWriter.scala:78, took 1.869817 s
2021-12-04 17:38:29,371 [main] INFO [org.apache.spark.internal.io.SparkHadoopWriter] - Job job_20211204173827_0069 committed.
2021-12-04 17:38:29,381 [main] INFO [PaidPromotion$] - 验证集用户实际观看列表-----------------------------------
2021-12-04 17:38:29,382 [main] INFO [org.apache.spark.SparkContext] - Starting job: count at PaidPromotionAdjustParameter.scala:192
2021-12-04 17:38:29,383 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 33 (filter at PaidPromotionAdjustParameter.scala:150)
2021-12-04 17:38:29,383 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 22 (count at PaidPromotionAdjustParameter.scala:192) with 2 output partitions
2021-12-04 17:38:29,383 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 55 (count at PaidPromotionAdjustParameter.scala:192)
2021-12-04 17:38:29,383 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 54)
2021-12-04 17:38:29,383 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List(ShuffleMapStage 54)
2021-12-04 17:38:29,383 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ShuffleMapStage 54 (MapPartitionsRDD[33] at filter at PaidPromotionAdjustParameter.scala:150), which has no missing parents
2021-12-04 17:38:29,384 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_39 stored as values in memory (estimated size 186.5 KB, free 1989.9 MB)
2021-12-04 17:38:29,386 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_39_piece0 stored as bytes in memory (estimated size 66.1 KB, free 1989.9 MB)
2021-12-04 17:38:29,386 [dispatcher-event-loop-0] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_39_piece0 in memory on qb:60666 (size: 66.1 KB, free: 1990.6 MB)
2021-12-04 17:38:29,387 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 39 from broadcast at DAGScheduler.scala:1039
2021-12-04 17:38:29,387 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from ShuffleMapStage 54 (MapPartitionsRDD[33] at filter at PaidPromotionAdjustParameter.scala:150) (first 15 tasks are for partitions Vector(0, 1))
2021-12-04 17:38:29,387 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 54.0 with 2 tasks
2021-12-04 17:38:29,387 [dispatcher-event-loop-11] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 54.0 (TID 92, localhost, executor driver, partition 0, ANY, 7885 bytes)
2021-12-04 17:38:29,387 [dispatcher-event-loop-11] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 54.0 (TID 93, localhost, executor driver, partition 1, ANY, 7885 bytes)
2021-12-04 17:38:29,387 [Executor task launch worker for task 92] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 54.0 (TID 92)
2021-12-04 17:38:29,387 [Executor task launch worker for task 93] INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 54.0 (TID 93)
2021-12-04 17:38:29,389 [Executor task launch worker for task 92] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/order_data.bcp:0+3442194
2021-12-04 17:38:29,390 [Executor task launch worker for task 93] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/order_data.bcp:3442194+3442195
2021-12-04 17:38:30,354 [Executor task launch worker for task 92] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 54.0 (TID 92). 903 bytes result sent to driver
2021-12-04 17:38:30,354 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 54.0 (TID 92) in 967 ms on localhost (executor driver) (1/2)
2021-12-04 17:38:30,388 [Executor task launch worker for task 93] INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 54.0 (TID 93). 903 bytes result sent to driver
2021-12-04 17:38:30,388 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 54.0 (TID 93) in 1001 ms on localhost (executor driver) (2/2)
2021-12-04 17:38:30,388 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 54.0, whose tasks have all completed, from pool 
2021-12-04 17:38:30,389 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ShuffleMapStage 54 (filter at PaidPromotionAdjustParameter.scala:150) finished in 1.005 s
2021-12-04 17:38:30,389 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - looking for newly runnable stages
2021-12-04 17:38:30,389 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - running: Set()
2021-12-04 17:38:30,389 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - waiting: Set(ResultStage 55)
2021-12-04 17:38:30,389 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - failed: Set()
2021-12-04 17:38:30,389 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 55 (MapPartitionsRDD[71] at map at PaidPromotionAdjustParameter.scala:186), which has no missing parents
2021-12-04 17:38:30,391 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_40 stored as values in memory (estimated size 187.4 KB, free 1989.7 MB)
2021-12-04 17:38:30,393 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_40_piece0 stored as bytes in memory (estimated size 66.5 KB, free 1989.6 MB)
2021-12-04 17:38:30,394 [dispatcher-event-loop-6] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_40_piece0 in memory on qb:60666 (size: 66.5 KB, free: 1990.6 MB)
2021-12-04 17:38:30,394 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 40 from broadcast at DAGScheduler.scala:1039
2021-12-04 17:38:30,394 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from ResultStage 55 (MapPartitionsRDD[71] at map at PaidPromotionAdjustParameter.scala:186) (first 15 tasks are for partitions Vector(0, 1))
2021-12-04 17:38:30,394 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 55.0 with 2 tasks
2021-12-04 17:38:30,394 [dispatcher-event-loop-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 55.0 (TID 94, localhost, executor driver, partition 0, ANY, 7649 bytes)
2021-12-04 17:38:30,394 [dispatcher-event-loop-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 55.0 (TID 95, localhost, executor driver, partition 1, ANY, 7649 bytes)
2021-12-04 17:38:30,394 [Executor task launch worker for task 94] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 55.0 (TID 94)
2021-12-04 17:38:30,394 [Executor task launch worker for task 95] INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 55.0 (TID 95)
2021-12-04 17:38:30,396 [Executor task launch worker for task 95] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 2 non-empty blocks out of 2 blocks
2021-12-04 17:38:30,396 [Executor task launch worker for task 94] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 2 non-empty blocks out of 2 blocks
2021-12-04 17:38:30,396 [Executor task launch worker for task 94] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-04 17:38:30,396 [Executor task launch worker for task 95] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-04 17:38:30,431 [Executor task launch worker for task 95] INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 55.0 (TID 95). 1054 bytes result sent to driver
2021-12-04 17:38:30,431 [Executor task launch worker for task 94] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 55.0 (TID 94). 1054 bytes result sent to driver
2021-12-04 17:38:30,431 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 55.0 (TID 95) in 37 ms on localhost (executor driver) (1/2)
2021-12-04 17:38:30,431 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 55.0 (TID 94) in 37 ms on localhost (executor driver) (2/2)
2021-12-04 17:38:30,431 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 55.0, whose tasks have all completed, from pool 
2021-12-04 17:38:30,432 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 55 (count at PaidPromotionAdjustParameter.scala:192) finished in 0.042 s
2021-12-04 17:38:30,432 [main] INFO [org.apache.spark.scheduler.DAGScheduler] - Job 22 finished: count at PaidPromotionAdjustParameter.scala:192, took 1.049547 s
2021-12-04 17:38:30,432 [main] INFO [PaidPromotion$] - 验证集用户列表数量：5184
2021-12-04 17:38:30,440 [main] INFO [org.apache.spark.SparkContext] - Starting job: take at PaidPromotionAdjustParameter.scala:193
2021-12-04 17:38:30,440 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 23 (take at PaidPromotionAdjustParameter.scala:193) with 1 output partitions
2021-12-04 17:38:30,440 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 57 (take at PaidPromotionAdjustParameter.scala:193)
2021-12-04 17:38:30,440 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 56)
2021-12-04 17:38:30,440 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2021-12-04 17:38:30,440 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 57 (MapPartitionsRDD[71] at map at PaidPromotionAdjustParameter.scala:186), which has no missing parents
2021-12-04 17:38:30,442 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_41 stored as values in memory (estimated size 187.5 KB, free 1989.4 MB)
2021-12-04 17:38:30,443 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_41_piece0 stored as bytes in memory (estimated size 66.6 KB, free 1989.4 MB)
2021-12-04 17:38:30,444 [dispatcher-event-loop-10] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_41_piece0 in memory on qb:60666 (size: 66.6 KB, free: 1990.5 MB)
2021-12-04 17:38:30,444 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 41 from broadcast at DAGScheduler.scala:1039
2021-12-04 17:38:30,444 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 57 (MapPartitionsRDD[71] at map at PaidPromotionAdjustParameter.scala:186) (first 15 tasks are for partitions Vector(0))
2021-12-04 17:38:30,444 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 57.0 with 1 tasks
2021-12-04 17:38:30,444 [dispatcher-event-loop-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 57.0 (TID 96, localhost, executor driver, partition 0, ANY, 7649 bytes)
2021-12-04 17:38:30,444 [Executor task launch worker for task 96] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 57.0 (TID 96)
2021-12-04 17:38:30,446 [Executor task launch worker for task 96] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 2 non-empty blocks out of 2 blocks
2021-12-04 17:38:30,446 [Executor task launch worker for task 96] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-04 17:38:30,460 [Executor task launch worker for task 96] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 57.0 (TID 96). 2468 bytes result sent to driver
2021-12-04 17:38:30,460 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 57.0 (TID 96) in 16 ms on localhost (executor driver) (1/1)
2021-12-04 17:38:30,460 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 57.0, whose tasks have all completed, from pool 
2021-12-04 17:38:30,460 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 57 (take at PaidPromotionAdjustParameter.scala:193) finished in 0.019 s
2021-12-04 17:38:30,461 [main] INFO [org.apache.spark.scheduler.DAGScheduler] - Job 23 finished: take at PaidPromotionAdjustParameter.scala:193, took 0.020696 s
2021-12-04 17:38:30,469 [main] INFO [PaidPromotion$] - 训练集用户实际观看列表-----------------------------------
2021-12-04 17:38:30,470 [main] INFO [org.apache.spark.SparkContext] - Starting job: count at PaidPromotionAdjustParameter.scala:203
2021-12-04 17:38:30,470 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 35 (union at PaidPromotionAdjustParameter.scala:154)
2021-12-04 17:38:30,470 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 24 (count at PaidPromotionAdjustParameter.scala:203) with 4 output partitions
2021-12-04 17:38:30,470 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 59 (count at PaidPromotionAdjustParameter.scala:203)
2021-12-04 17:38:30,470 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 58)
2021-12-04 17:38:30,470 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List(ShuffleMapStage 58)
2021-12-04 17:38:30,470 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ShuffleMapStage 58 (UnionRDD[35] at union at PaidPromotionAdjustParameter.scala:154), which has no missing parents
2021-12-04 17:38:30,472 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_42 stored as values in memory (estimated size 187.0 KB, free 1989.2 MB)
2021-12-04 17:38:30,474 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_42_piece0 stored as bytes in memory (estimated size 66.4 KB, free 1989.1 MB)
2021-12-04 17:38:30,474 [dispatcher-event-loop-1] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_42_piece0 in memory on qb:60666 (size: 66.4 KB, free: 1990.4 MB)
2021-12-04 17:38:30,474 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 42 from broadcast at DAGScheduler.scala:1039
2021-12-04 17:38:30,474 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 4 missing tasks from ShuffleMapStage 58 (UnionRDD[35] at union at PaidPromotionAdjustParameter.scala:154) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
2021-12-04 17:38:30,474 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 58.0 with 4 tasks
2021-12-04 17:38:30,475 [dispatcher-event-loop-5] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 58.0 (TID 97, localhost, executor driver, partition 0, ANY, 7994 bytes)
2021-12-04 17:38:30,475 [dispatcher-event-loop-5] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 58.0 (TID 98, localhost, executor driver, partition 1, ANY, 7994 bytes)
2021-12-04 17:38:30,475 [dispatcher-event-loop-5] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 2.0 in stage 58.0 (TID 99, localhost, executor driver, partition 2, ANY, 7994 bytes)
2021-12-04 17:38:30,475 [dispatcher-event-loop-5] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 3.0 in stage 58.0 (TID 100, localhost, executor driver, partition 3, ANY, 7994 bytes)
2021-12-04 17:38:30,475 [Executor task launch worker for task 97] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 58.0 (TID 97)
2021-12-04 17:38:30,475 [Executor task launch worker for task 100] INFO [org.apache.spark.executor.Executor] - Running task 3.0 in stage 58.0 (TID 100)
2021-12-04 17:38:30,475 [Executor task launch worker for task 99] INFO [org.apache.spark.executor.Executor] - Running task 2.0 in stage 58.0 (TID 99)
2021-12-04 17:38:30,475 [Executor task launch worker for task 98] INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 58.0 (TID 98)
2021-12-04 17:38:30,477 [Executor task launch worker for task 97] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/order_data.bcp:0+3442194
2021-12-04 17:38:30,477 [Executor task launch worker for task 99] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/order_data.bcp:0+3442194
2021-12-04 17:38:30,478 [Executor task launch worker for task 98] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/order_data.bcp:3442194+3442195
2021-12-04 17:38:30,478 [Executor task launch worker for task 100] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/order_data.bcp:3442194+3442195
2021-12-04 17:38:31,238 [Executor task launch worker for task 99] INFO [org.apache.spark.executor.Executor] - Finished task 2.0 in stage 58.0 (TID 99). 862 bytes result sent to driver
2021-12-04 17:38:31,238 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 2.0 in stage 58.0 (TID 99) in 763 ms on localhost (executor driver) (1/4)
2021-12-04 17:38:31,647 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1023
2021-12-04 17:38:31,647 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 981
2021-12-04 17:38:31,647 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 931
2021-12-04 17:38:31,647 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 992
2021-12-04 17:38:31,647 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 993
2021-12-04 17:38:31,647 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 961
2021-12-04 17:38:31,647 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 959
2021-12-04 17:38:31,648 [dispatcher-event-loop-3] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_41_piece0 on qb:60666 in memory (size: 66.6 KB, free: 1990.5 MB)
2021-12-04 17:38:31,648 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1014
2021-12-04 17:38:31,648 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1015
2021-12-04 17:38:31,648 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1006
2021-12-04 17:38:31,648 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1008
2021-12-04 17:38:31,648 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 925
2021-12-04 17:38:31,648 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1018
2021-12-04 17:38:31,648 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1005
2021-12-04 17:38:31,648 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 994
2021-12-04 17:38:31,648 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1017
2021-12-04 17:38:31,648 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 951
2021-12-04 17:38:31,648 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1024
2021-12-04 17:38:31,648 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 995
2021-12-04 17:38:31,648 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 964
2021-12-04 17:38:31,648 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 953
2021-12-04 17:38:31,648 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 952
2021-12-04 17:38:31,648 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 970
2021-12-04 17:38:31,648 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 938
2021-12-04 17:38:31,648 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1004
2021-12-04 17:38:31,648 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 954
2021-12-04 17:38:31,648 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 976
2021-12-04 17:38:31,648 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 996
2021-12-04 17:38:31,648 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1001
2021-12-04 17:38:31,648 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1011
2021-12-04 17:38:31,648 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 974
2021-12-04 17:38:31,648 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 956
2021-12-04 17:38:31,648 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 957
2021-12-04 17:38:31,648 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 968
2021-12-04 17:38:31,648 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 958
2021-12-04 17:38:31,648 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 990
2021-12-04 17:38:31,648 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 969
2021-12-04 17:38:31,648 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 950
2021-12-04 17:38:31,648 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1000
2021-12-04 17:38:31,648 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 947
2021-12-04 17:38:31,648 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 962
2021-12-04 17:38:31,648 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1021
2021-12-04 17:38:31,648 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 939
2021-12-04 17:38:31,648 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 983
2021-12-04 17:38:31,648 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 929
2021-12-04 17:38:31,648 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 960
2021-12-04 17:38:31,648 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1003
2021-12-04 17:38:31,648 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1010
2021-12-04 17:38:31,648 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 945
2021-12-04 17:38:31,648 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 955
2021-12-04 17:38:31,648 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 948
2021-12-04 17:38:31,648 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 932
2021-12-04 17:38:31,648 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 979
2021-12-04 17:38:31,648 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 985
2021-12-04 17:38:31,649 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 928
2021-12-04 17:38:31,649 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 980
2021-12-04 17:38:31,649 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 997
2021-12-04 17:38:31,649 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 941
2021-12-04 17:38:31,649 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 989
2021-12-04 17:38:31,649 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1020
2021-12-04 17:38:31,649 [dispatcher-event-loop-1] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_38_piece0 on qb:60666 in memory (size: 94.0 KB, free: 1990.6 MB)
2021-12-04 17:38:31,649 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 972
2021-12-04 17:38:31,649 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 943
2021-12-04 17:38:31,649 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 934
2021-12-04 17:38:31,649 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 940
2021-12-04 17:38:31,649 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1007
2021-12-04 17:38:31,649 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 937
2021-12-04 17:38:31,649 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 975
2021-12-04 17:38:31,649 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 984
2021-12-04 17:38:31,649 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 933
2021-12-04 17:38:31,649 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1009
2021-12-04 17:38:31,649 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 963
2021-12-04 17:38:31,649 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 971
2021-12-04 17:38:31,649 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 991
2021-12-04 17:38:31,650 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 946
2021-12-04 17:38:31,650 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 944
2021-12-04 17:38:31,650 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 927
2021-12-04 17:38:31,650 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1013
2021-12-04 17:38:31,650 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1016
2021-12-04 17:38:31,650 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 977
2021-12-04 17:38:31,650 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1019
2021-12-04 17:38:31,650 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 998
2021-12-04 17:38:31,650 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 967
2021-12-04 17:38:31,650 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 982
2021-12-04 17:38:31,650 [dispatcher-event-loop-2] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_40_piece0 on qb:60666 in memory (size: 66.5 KB, free: 1990.6 MB)
2021-12-04 17:38:31,650 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 986
2021-12-04 17:38:31,650 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 935
2021-12-04 17:38:31,651 [dispatcher-event-loop-11] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_39_piece0 on qb:60666 in memory (size: 66.1 KB, free: 1990.7 MB)
2021-12-04 17:38:31,651 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 973
2021-12-04 17:38:31,651 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 988
2021-12-04 17:38:31,651 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 949
2021-12-04 17:38:31,651 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 987
2021-12-04 17:38:31,651 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1012
2021-12-04 17:38:31,651 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1022
2021-12-04 17:38:31,651 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 942
2021-12-04 17:38:31,651 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 999
2021-12-04 17:38:31,651 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 965
2021-12-04 17:38:31,651 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 936
2021-12-04 17:38:31,651 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 926
2021-12-04 17:38:31,651 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 966
2021-12-04 17:38:31,651 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 930
2021-12-04 17:38:31,651 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1002
2021-12-04 17:38:31,651 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 978
2021-12-04 17:38:31,894 [Executor task launch worker for task 100] INFO [org.apache.spark.executor.Executor] - Finished task 3.0 in stage 58.0 (TID 100). 948 bytes result sent to driver
2021-12-04 17:38:31,894 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 3.0 in stage 58.0 (TID 100) in 1419 ms on localhost (executor driver) (2/4)
2021-12-04 17:38:31,927 [Executor task launch worker for task 98] INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 58.0 (TID 98). 905 bytes result sent to driver
2021-12-04 17:38:31,928 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 58.0 (TID 98) in 1453 ms on localhost (executor driver) (3/4)
2021-12-04 17:38:32,090 [Executor task launch worker for task 97] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 58.0 (TID 97). 905 bytes result sent to driver
2021-12-04 17:38:32,090 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 58.0 (TID 97) in 1615 ms on localhost (executor driver) (4/4)
2021-12-04 17:38:32,090 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 58.0, whose tasks have all completed, from pool 
2021-12-04 17:38:32,090 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ShuffleMapStage 58 (union at PaidPromotionAdjustParameter.scala:154) finished in 1.619 s
2021-12-04 17:38:32,090 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - looking for newly runnable stages
2021-12-04 17:38:32,090 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - running: Set()
2021-12-04 17:38:32,090 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - waiting: Set(ResultStage 59)
2021-12-04 17:38:32,090 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - failed: Set()
2021-12-04 17:38:32,090 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 59 (MapPartitionsRDD[73] at map at PaidPromotionAdjustParameter.scala:197), which has no missing parents
2021-12-04 17:38:32,092 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_43 stored as values in memory (estimated size 187.9 KB, free 1990.0 MB)
2021-12-04 17:38:32,093 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_43_piece0 stored as bytes in memory (estimated size 66.8 KB, free 1990.0 MB)
2021-12-04 17:38:32,094 [dispatcher-event-loop-9] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_43_piece0 in memory on qb:60666 (size: 66.8 KB, free: 1990.6 MB)
2021-12-04 17:38:32,094 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 43 from broadcast at DAGScheduler.scala:1039
2021-12-04 17:38:32,094 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 4 missing tasks from ResultStage 59 (MapPartitionsRDD[73] at map at PaidPromotionAdjustParameter.scala:197) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
2021-12-04 17:38:32,094 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 59.0 with 4 tasks
2021-12-04 17:38:32,094 [dispatcher-event-loop-7] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 59.0 (TID 101, localhost, executor driver, partition 0, ANY, 7649 bytes)
2021-12-04 17:38:32,094 [dispatcher-event-loop-7] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 59.0 (TID 102, localhost, executor driver, partition 1, ANY, 7649 bytes)
2021-12-04 17:38:32,094 [dispatcher-event-loop-7] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 2.0 in stage 59.0 (TID 103, localhost, executor driver, partition 2, ANY, 7649 bytes)
2021-12-04 17:38:32,094 [dispatcher-event-loop-7] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 3.0 in stage 59.0 (TID 104, localhost, executor driver, partition 3, ANY, 7649 bytes)
2021-12-04 17:38:32,095 [Executor task launch worker for task 101] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 59.0 (TID 101)
2021-12-04 17:38:32,095 [Executor task launch worker for task 103] INFO [org.apache.spark.executor.Executor] - Running task 2.0 in stage 59.0 (TID 103)
2021-12-04 17:38:32,095 [Executor task launch worker for task 102] INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 59.0 (TID 102)
2021-12-04 17:38:32,095 [Executor task launch worker for task 104] INFO [org.apache.spark.executor.Executor] - Running task 3.0 in stage 59.0 (TID 104)
2021-12-04 17:38:32,097 [Executor task launch worker for task 104] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 4 non-empty blocks out of 4 blocks
2021-12-04 17:38:32,097 [Executor task launch worker for task 103] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 4 non-empty blocks out of 4 blocks
2021-12-04 17:38:32,097 [Executor task launch worker for task 104] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 1 ms
2021-12-04 17:38:32,097 [Executor task launch worker for task 102] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 4 non-empty blocks out of 4 blocks
2021-12-04 17:38:32,097 [Executor task launch worker for task 101] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 4 non-empty blocks out of 4 blocks
2021-12-04 17:38:32,097 [Executor task launch worker for task 102] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-04 17:38:32,097 [Executor task launch worker for task 103] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 1 ms
2021-12-04 17:38:32,097 [Executor task launch worker for task 101] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-04 17:38:32,221 [Executor task launch worker for task 104] INFO [org.apache.spark.executor.Executor] - Finished task 3.0 in stage 59.0 (TID 104). 1055 bytes result sent to driver
2021-12-04 17:38:32,221 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 3.0 in stage 59.0 (TID 104) in 127 ms on localhost (executor driver) (1/4)
2021-12-04 17:38:32,222 [Executor task launch worker for task 102] INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 59.0 (TID 102). 1055 bytes result sent to driver
2021-12-04 17:38:32,222 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 59.0 (TID 102) in 128 ms on localhost (executor driver) (2/4)
2021-12-04 17:38:32,224 [Executor task launch worker for task 103] INFO [org.apache.spark.executor.Executor] - Finished task 2.0 in stage 59.0 (TID 103). 1055 bytes result sent to driver
2021-12-04 17:38:32,224 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 2.0 in stage 59.0 (TID 103) in 130 ms on localhost (executor driver) (3/4)
2021-12-04 17:38:32,227 [Executor task launch worker for task 101] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 59.0 (TID 101). 1055 bytes result sent to driver
2021-12-04 17:38:32,227 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 59.0 (TID 101) in 133 ms on localhost (executor driver) (4/4)
2021-12-04 17:38:32,227 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 59.0, whose tasks have all completed, from pool 
2021-12-04 17:38:32,227 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 59 (count at PaidPromotionAdjustParameter.scala:203) finished in 0.136 s
2021-12-04 17:38:32,228 [main] INFO [org.apache.spark.scheduler.DAGScheduler] - Job 24 finished: count at PaidPromotionAdjustParameter.scala:203, took 1.757189 s
2021-12-04 17:38:32,228 [main] INFO [PaidPromotion$] - 训练集用户列表数量：95323
2021-12-04 17:38:32,233 [main] INFO [org.apache.spark.SparkContext] - Starting job: take at PaidPromotionAdjustParameter.scala:204
2021-12-04 17:38:32,234 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 25 (take at PaidPromotionAdjustParameter.scala:204) with 1 output partitions
2021-12-04 17:38:32,234 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 61 (take at PaidPromotionAdjustParameter.scala:204)
2021-12-04 17:38:32,234 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 60)
2021-12-04 17:38:32,234 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2021-12-04 17:38:32,234 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 61 (MapPartitionsRDD[73] at map at PaidPromotionAdjustParameter.scala:197), which has no missing parents
2021-12-04 17:38:32,235 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_44 stored as values in memory (estimated size 188.1 KB, free 1989.8 MB)
2021-12-04 17:38:32,237 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_44_piece0 stored as bytes in memory (estimated size 66.9 KB, free 1989.7 MB)
2021-12-04 17:38:32,237 [dispatcher-event-loop-0] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_44_piece0 in memory on qb:60666 (size: 66.9 KB, free: 1990.6 MB)
2021-12-04 17:38:32,237 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 44 from broadcast at DAGScheduler.scala:1039
2021-12-04 17:38:32,237 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 61 (MapPartitionsRDD[73] at map at PaidPromotionAdjustParameter.scala:197) (first 15 tasks are for partitions Vector(0))
2021-12-04 17:38:32,238 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 61.0 with 1 tasks
2021-12-04 17:38:32,238 [dispatcher-event-loop-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 61.0 (TID 105, localhost, executor driver, partition 0, ANY, 7649 bytes)
2021-12-04 17:38:32,238 [Executor task launch worker for task 105] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 61.0 (TID 105)
2021-12-04 17:38:32,240 [Executor task launch worker for task 105] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 4 non-empty blocks out of 4 blocks
2021-12-04 17:38:32,240 [Executor task launch worker for task 105] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-04 17:38:32,272 [Executor task launch worker for task 105] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 61.0 (TID 105). 2431 bytes result sent to driver
2021-12-04 17:38:32,272 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 61.0 (TID 105) in 34 ms on localhost (executor driver) (1/1)
2021-12-04 17:38:32,272 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 61.0, whose tasks have all completed, from pool 
2021-12-04 17:38:32,272 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 61 (take at PaidPromotionAdjustParameter.scala:204) finished in 0.038 s
2021-12-04 17:38:32,272 [main] INFO [org.apache.spark.scheduler.DAGScheduler] - Job 25 finished: take at PaidPromotionAdjustParameter.scala:204, took 0.038870 s
2021-12-04 17:38:32,276 [main] INFO [org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter] - File Output Committer Algorithm version is 1
2021-12-04 17:38:32,303 [main] INFO [org.apache.spark.SparkContext] - Starting job: runJob at SparkHadoopWriter.scala:78
2021-12-04 17:38:32,304 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 26 (runJob at SparkHadoopWriter.scala:78) with 1 output partitions
2021-12-04 17:38:32,304 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 63 (runJob at SparkHadoopWriter.scala:78)
2021-12-04 17:38:32,304 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 62)
2021-12-04 17:38:32,304 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2021-12-04 17:38:32,304 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 63 (MapPartitionsRDD[75] at saveAsTextFile at PaidPromotionAdjustParameter.scala:206), which has no missing parents
2021-12-04 17:38:32,315 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_45 stored as values in memory (estimated size 263.8 KB, free 1989.5 MB)
2021-12-04 17:38:32,317 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_45_piece0 stored as bytes in memory (estimated size 95.3 KB, free 1989.4 MB)
2021-12-04 17:38:32,317 [dispatcher-event-loop-6] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_45_piece0 in memory on qb:60666 (size: 95.3 KB, free: 1990.5 MB)
2021-12-04 17:38:32,317 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 45 from broadcast at DAGScheduler.scala:1039
2021-12-04 17:38:32,317 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 63 (MapPartitionsRDD[75] at saveAsTextFile at PaidPromotionAdjustParameter.scala:206) (first 15 tasks are for partitions Vector(0))
2021-12-04 17:38:32,317 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 63.0 with 1 tasks
2021-12-04 17:38:32,318 [dispatcher-event-loop-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 63.0 (TID 106, localhost, executor driver, partition 0, ANY, 7943 bytes)
2021-12-04 17:38:32,318 [Executor task launch worker for task 106] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 63.0 (TID 106)
2021-12-04 17:38:32,323 [Executor task launch worker for task 106] INFO [org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter] - File Output Committer Algorithm version is 1
2021-12-04 17:38:32,330 [Executor task launch worker for task 106] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 2 non-empty blocks out of 2 blocks
2021-12-04 17:38:32,330 [Executor task launch worker for task 106] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 1 ms
2021-12-04 17:38:32,344 [Executor task launch worker for task 106] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 2 non-empty blocks out of 2 blocks
2021-12-04 17:38:32,344 [Executor task launch worker for task 106] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-04 17:38:32,487 [Executor task launch worker for task 106] INFO [org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter] - Saved output of task 'attempt_20211204173832_0075_m_000000_0' to hdfs://hdp1:8020/sk/chongqing/list/validation/_temporary/0/task_20211204173832_0075_m_000000
2021-12-04 17:38:32,487 [Executor task launch worker for task 106] INFO [org.apache.spark.mapred.SparkHadoopMapRedUtil] - attempt_20211204173832_0075_m_000000_0: Committed
2021-12-04 17:38:32,489 [Executor task launch worker for task 106] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 63.0 (TID 106). 1299 bytes result sent to driver
2021-12-04 17:38:32,489 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 63.0 (TID 106) in 171 ms on localhost (executor driver) (1/1)
2021-12-04 17:38:32,489 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 63.0, whose tasks have all completed, from pool 
2021-12-04 17:38:32,489 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 63 (runJob at SparkHadoopWriter.scala:78) finished in 0.185 s
2021-12-04 17:38:32,490 [main] INFO [org.apache.spark.scheduler.DAGScheduler] - Job 26 finished: runJob at SparkHadoopWriter.scala:78, took 0.186376 s
2021-12-04 17:38:32,539 [main] INFO [org.apache.spark.internal.io.SparkHadoopWriter] - Job job_20211204173832_0075 committed.
2021-12-04 17:38:32,541 [main] INFO [org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter] - File Output Committer Algorithm version is 1
2021-12-04 17:38:32,555 [main] INFO [org.apache.spark.SparkContext] - Starting job: runJob at SparkHadoopWriter.scala:78
2021-12-04 17:38:32,556 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 27 (runJob at SparkHadoopWriter.scala:78) with 1 output partitions
2021-12-04 17:38:32,556 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 65 (runJob at SparkHadoopWriter.scala:78)
2021-12-04 17:38:32,556 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 64)
2021-12-04 17:38:32,556 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2021-12-04 17:38:32,556 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 65 (MapPartitionsRDD[77] at saveAsTextFile at PaidPromotionAdjustParameter.scala:207), which has no missing parents
2021-12-04 17:38:32,566 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_46 stored as values in memory (estimated size 264.4 KB, free 1989.1 MB)
2021-12-04 17:38:32,567 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_46_piece0 stored as bytes in memory (estimated size 95.7 KB, free 1989.0 MB)
2021-12-04 17:38:32,568 [dispatcher-event-loop-4] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_46_piece0 in memory on qb:60666 (size: 95.7 KB, free: 1990.4 MB)
2021-12-04 17:38:32,568 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 46 from broadcast at DAGScheduler.scala:1039
2021-12-04 17:38:32,568 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 65 (MapPartitionsRDD[77] at saveAsTextFile at PaidPromotionAdjustParameter.scala:207) (first 15 tasks are for partitions Vector(0))
2021-12-04 17:38:32,568 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 65.0 with 1 tasks
2021-12-04 17:38:32,568 [dispatcher-event-loop-11] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 65.0 (TID 107, localhost, executor driver, partition 0, ANY, 7979 bytes)
2021-12-04 17:38:32,568 [Executor task launch worker for task 107] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 65.0 (TID 107)
2021-12-04 17:38:32,580 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1045
2021-12-04 17:38:32,580 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1068
2021-12-04 17:38:32,581 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1104
2021-12-04 17:38:32,581 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1041
2021-12-04 17:38:32,581 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1089
2021-12-04 17:38:32,581 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1070
2021-12-04 17:38:32,581 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1072
2021-12-04 17:38:32,581 [Executor task launch worker for task 107] INFO [org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter] - File Output Committer Algorithm version is 1
2021-12-04 17:38:32,581 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1105
2021-12-04 17:38:32,581 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1062
2021-12-04 17:38:32,581 [dispatcher-event-loop-9] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_44_piece0 on qb:60666 in memory (size: 66.9 KB, free: 1990.5 MB)
2021-12-04 17:38:32,582 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1078
2021-12-04 17:38:32,582 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1095
2021-12-04 17:38:32,582 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1116
2021-12-04 17:38:32,582 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1037
2021-12-04 17:38:32,582 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1103
2021-12-04 17:38:32,582 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1106
2021-12-04 17:38:32,582 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1026
2021-12-04 17:38:32,582 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1029
2021-12-04 17:38:32,582 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1035
2021-12-04 17:38:32,582 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1039
2021-12-04 17:38:32,582 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1028
2021-12-04 17:38:32,582 [dispatcher-event-loop-1] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_45_piece0 on qb:60666 in memory (size: 95.3 KB, free: 1990.5 MB)
2021-12-04 17:38:32,583 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1031
2021-12-04 17:38:32,583 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1044
2021-12-04 17:38:32,583 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1080
2021-12-04 17:38:32,584 [dispatcher-event-loop-8] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_42_piece0 on qb:60666 in memory (size: 66.4 KB, free: 1990.6 MB)
2021-12-04 17:38:32,584 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1113
2021-12-04 17:38:32,584 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1030
2021-12-04 17:38:32,584 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1081
2021-12-04 17:38:32,584 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1109
2021-12-04 17:38:32,584 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1093
2021-12-04 17:38:32,584 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1051
2021-12-04 17:38:32,584 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1053
2021-12-04 17:38:32,584 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1064
2021-12-04 17:38:32,584 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1079
2021-12-04 17:38:32,584 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1096
2021-12-04 17:38:32,584 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1040
2021-12-04 17:38:32,584 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1120
2021-12-04 17:38:32,584 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1097
2021-12-04 17:38:32,584 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1058
2021-12-04 17:38:32,584 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1123
2021-12-04 17:38:32,584 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1119
2021-12-04 17:38:32,584 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1047
2021-12-04 17:38:32,584 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1083
2021-12-04 17:38:32,584 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1074
2021-12-04 17:38:32,584 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1124
2021-12-04 17:38:32,584 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1054
2021-12-04 17:38:32,584 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1090
2021-12-04 17:38:32,584 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1066
2021-12-04 17:38:32,584 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1082
2021-12-04 17:38:32,584 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1059
2021-12-04 17:38:32,585 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1108
2021-12-04 17:38:32,585 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1117
2021-12-04 17:38:32,585 [dispatcher-event-loop-10] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_43_piece0 on qb:60666 in memory (size: 66.8 KB, free: 1990.7 MB)
2021-12-04 17:38:32,585 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1069
2021-12-04 17:38:32,585 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1099
2021-12-04 17:38:32,585 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1112
2021-12-04 17:38:32,585 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1091
2021-12-04 17:38:32,586 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1075
2021-12-04 17:38:32,586 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1076
2021-12-04 17:38:32,586 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1071
2021-12-04 17:38:32,586 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1050
2021-12-04 17:38:32,586 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1098
2021-12-04 17:38:32,586 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1027
2021-12-04 17:38:32,586 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1100
2021-12-04 17:38:32,586 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1087
2021-12-04 17:38:32,586 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1052
2021-12-04 17:38:32,586 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1107
2021-12-04 17:38:32,586 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1063
2021-12-04 17:38:32,586 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1061
2021-12-04 17:38:32,586 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1101
2021-12-04 17:38:32,586 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1092
2021-12-04 17:38:32,586 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1036
2021-12-04 17:38:32,586 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1073
2021-12-04 17:38:32,586 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1057
2021-12-04 17:38:32,586 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1110
2021-12-04 17:38:32,586 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1043
2021-12-04 17:38:32,586 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1025
2021-12-04 17:38:32,586 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1048
2021-12-04 17:38:32,586 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1118
2021-12-04 17:38:32,586 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1046
2021-12-04 17:38:32,586 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1111
2021-12-04 17:38:32,586 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1032
2021-12-04 17:38:32,586 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1038
2021-12-04 17:38:32,586 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1056
2021-12-04 17:38:32,586 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1055
2021-12-04 17:38:32,586 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1034
2021-12-04 17:38:32,586 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1114
2021-12-04 17:38:32,586 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1085
2021-12-04 17:38:32,586 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1065
2021-12-04 17:38:32,586 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1115
2021-12-04 17:38:32,586 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1060
2021-12-04 17:38:32,586 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1084
2021-12-04 17:38:32,586 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1042
2021-12-04 17:38:32,586 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1049
2021-12-04 17:38:32,586 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1121
2021-12-04 17:38:32,586 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1088
2021-12-04 17:38:32,586 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1067
2021-12-04 17:38:32,586 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1077
2021-12-04 17:38:32,586 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1033
2021-12-04 17:38:32,586 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1094
2021-12-04 17:38:32,586 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1122
2021-12-04 17:38:32,586 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1102
2021-12-04 17:38:32,586 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1086
2021-12-04 17:38:32,588 [Executor task launch worker for task 107] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 4 non-empty blocks out of 4 blocks
2021-12-04 17:38:32,588 [Executor task launch worker for task 107] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-04 17:38:32,640 [Executor task launch worker for task 107] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 4 non-empty blocks out of 4 blocks
2021-12-04 17:38:32,640 [Executor task launch worker for task 107] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-04 17:38:32,690 [Executor task launch worker for task 107] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 4 non-empty blocks out of 4 blocks
2021-12-04 17:38:32,690 [Executor task launch worker for task 107] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-04 17:38:32,744 [Executor task launch worker for task 107] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 4 non-empty blocks out of 4 blocks
2021-12-04 17:38:32,744 [Executor task launch worker for task 107] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-04 17:38:33,263 [Executor task launch worker for task 107] INFO [org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter] - Saved output of task 'attempt_20211204173832_0077_m_000000_0' to hdfs://hdp1:8020/sk/chongqing/list/train/_temporary/0/task_20211204173832_0077_m_000000
2021-12-04 17:38:33,263 [Executor task launch worker for task 107] INFO [org.apache.spark.mapred.SparkHadoopMapRedUtil] - attempt_20211204173832_0077_m_000000_0: Committed
2021-12-04 17:38:33,263 [Executor task launch worker for task 107] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 65.0 (TID 107). 1299 bytes result sent to driver
2021-12-04 17:38:33,263 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 65.0 (TID 107) in 695 ms on localhost (executor driver) (1/1)
2021-12-04 17:38:33,263 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 65.0, whose tasks have all completed, from pool 
2021-12-04 17:38:33,263 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 65 (runJob at SparkHadoopWriter.scala:78) finished in 0.707 s
2021-12-04 17:38:33,263 [main] INFO [org.apache.spark.scheduler.DAGScheduler] - Job 27 finished: runJob at SparkHadoopWriter.scala:78, took 0.708908 s
2021-12-04 17:38:33,314 [main] INFO [org.apache.spark.internal.io.SparkHadoopWriter] - Job job_20211204173832_0077 committed.
2021-12-04 17:38:33,319 [main] INFO [org.spark_project.jetty.server.AbstractConnector] - Stopped Spark@5f7f2382{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2021-12-04 17:38:33,321 [main] INFO [org.apache.spark.ui.SparkUI] - Stopped Spark web UI at http://qb:4040
2021-12-04 17:38:33,329 [dispatcher-event-loop-6] INFO [org.apache.spark.MapOutputTrackerMasterEndpoint] - MapOutputTrackerMasterEndpoint stopped!
2021-12-04 17:38:33,407 [main] INFO [org.apache.spark.storage.memory.MemoryStore] - MemoryStore cleared
2021-12-04 17:38:33,408 [main] INFO [org.apache.spark.storage.BlockManager] - BlockManager stopped
2021-12-04 17:38:33,408 [main] INFO [org.apache.spark.storage.BlockManagerMaster] - BlockManagerMaster stopped
2021-12-04 17:38:33,410 [dispatcher-event-loop-11] INFO [org.apache.spark.scheduler.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint] - OutputCommitCoordinator stopped!
2021-12-04 17:38:33,412 [main] INFO [org.apache.spark.SparkContext] - Successfully stopped SparkContext
2021-12-04 17:38:33,414 [Thread-1] INFO [org.apache.spark.util.ShutdownHookManager] - Shutdown hook called
2021-12-04 17:38:33,414 [Thread-1] INFO [org.apache.spark.util.ShutdownHookManager] - Deleting directory C:\Users\ACER\AppData\Local\Temp\spark-352ff625-afae-4046-8c4f-e2a06bbe6ffc
2021-12-04 17:40:13,950 [main] INFO [org.apache.spark.SparkContext] - Running Spark version 2.3.0
2021-12-04 17:40:14,199 [main] INFO [org.apache.spark.SparkContext] - Submitted application: PaidPromotion
2021-12-04 17:40:14,243 [main] INFO [org.apache.spark.SecurityManager] - Changing view acls to: ACER,root
2021-12-04 17:40:14,244 [main] INFO [org.apache.spark.SecurityManager] - Changing modify acls to: ACER,root
2021-12-04 17:40:14,244 [main] INFO [org.apache.spark.SecurityManager] - Changing view acls groups to: 
2021-12-04 17:40:14,244 [main] INFO [org.apache.spark.SecurityManager] - Changing modify acls groups to: 
2021-12-04 17:40:14,245 [main] INFO [org.apache.spark.SecurityManager] - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(ACER, root); groups with view permissions: Set(); users  with modify permissions: Set(ACER, root); groups with modify permissions: Set()
2021-12-04 17:40:14,797 [main] INFO [org.apache.spark.util.Utils] - Successfully started service 'sparkDriver' on port 51904.
2021-12-04 17:40:14,813 [main] INFO [org.apache.spark.SparkEnv] - Registering MapOutputTracker
2021-12-04 17:40:14,827 [main] INFO [org.apache.spark.SparkEnv] - Registering BlockManagerMaster
2021-12-04 17:40:14,830 [main] INFO [org.apache.spark.storage.BlockManagerMasterEndpoint] - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2021-12-04 17:40:14,830 [main] INFO [org.apache.spark.storage.BlockManagerMasterEndpoint] - BlockManagerMasterEndpoint up
2021-12-04 17:40:14,838 [main] INFO [org.apache.spark.storage.DiskBlockManager] - Created local directory at C:\Users\ACER\AppData\Local\Temp\blockmgr-a18d3dd6-3da0-4a5b-a557-814a8e85f2fc
2021-12-04 17:40:14,852 [main] INFO [org.apache.spark.storage.memory.MemoryStore] - MemoryStore started with capacity 1990.8 MB
2021-12-04 17:40:14,861 [main] INFO [org.apache.spark.SparkEnv] - Registering OutputCommitCoordinator
2021-12-04 17:40:14,911 [main] INFO [org.spark_project.jetty.util.log] - Logging initialized @1759ms
2021-12-04 17:40:14,956 [main] INFO [org.spark_project.jetty.server.Server] - jetty-9.3.z-SNAPSHOT
2021-12-04 17:40:14,966 [main] INFO [org.spark_project.jetty.server.Server] - Started @1815ms
2021-12-04 17:40:14,990 [main] INFO [org.spark_project.jetty.server.AbstractConnector] - Started ServerConnector@5f7f2382{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2021-12-04 17:40:14,990 [main] INFO [org.apache.spark.util.Utils] - Successfully started service 'SparkUI' on port 4040.
2021-12-04 17:40:15,009 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@3af17be2{/jobs,null,AVAILABLE,@Spark}
2021-12-04 17:40:15,010 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@6a1d204a{/jobs/json,null,AVAILABLE,@Spark}
2021-12-04 17:40:15,010 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@72ccd81a{/jobs/job,null,AVAILABLE,@Spark}
2021-12-04 17:40:15,012 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@5d25e6bb{/jobs/job/json,null,AVAILABLE,@Spark}
2021-12-04 17:40:15,013 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@7859e786{/stages,null,AVAILABLE,@Spark}
2021-12-04 17:40:15,013 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@5118388b{/stages/json,null,AVAILABLE,@Spark}
2021-12-04 17:40:15,014 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@71104a4{/stages/stage,null,AVAILABLE,@Spark}
2021-12-04 17:40:15,016 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@332a7fce{/stages/stage/json,null,AVAILABLE,@Spark}
2021-12-04 17:40:15,017 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@37ebc9d8{/stages/pool,null,AVAILABLE,@Spark}
2021-12-04 17:40:15,018 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@6e9319f{/stages/pool/json,null,AVAILABLE,@Spark}
2021-12-04 17:40:15,019 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@2c177f9e{/storage,null,AVAILABLE,@Spark}
2021-12-04 17:40:15,020 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@f9b7332{/storage/json,null,AVAILABLE,@Spark}
2021-12-04 17:40:15,021 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@192f2f27{/storage/rdd,null,AVAILABLE,@Spark}
2021-12-04 17:40:15,022 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@b672aa8{/storage/rdd/json,null,AVAILABLE,@Spark}
2021-12-04 17:40:15,023 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@7997b197{/environment,null,AVAILABLE,@Spark}
2021-12-04 17:40:15,024 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@11acdc30{/environment/json,null,AVAILABLE,@Spark}
2021-12-04 17:40:15,026 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@611f8234{/executors,null,AVAILABLE,@Spark}
2021-12-04 17:40:15,027 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@62923ee6{/executors/json,null,AVAILABLE,@Spark}
2021-12-04 17:40:15,028 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@4b6166aa{/executors/threadDump,null,AVAILABLE,@Spark}
2021-12-04 17:40:15,029 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@a1217f9{/executors/threadDump/json,null,AVAILABLE,@Spark}
2021-12-04 17:40:15,035 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@791cbf87{/static,null,AVAILABLE,@Spark}
2021-12-04 17:40:15,036 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@cf65451{/,null,AVAILABLE,@Spark}
2021-12-04 17:40:15,038 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@46074492{/api,null,AVAILABLE,@Spark}
2021-12-04 17:40:15,039 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@5ae76500{/jobs/job/kill,null,AVAILABLE,@Spark}
2021-12-04 17:40:15,040 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@24f360b2{/stages/stage/kill,null,AVAILABLE,@Spark}
2021-12-04 17:40:15,042 [main] INFO [org.apache.spark.ui.SparkUI] - Bound SparkUI to 0.0.0.0, and started at http://qb:4040
2021-12-04 17:40:15,129 [main] INFO [org.apache.spark.executor.Executor] - Starting executor ID driver on host localhost
2021-12-04 17:40:15,177 [main] INFO [org.apache.spark.util.Utils] - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 51947.
2021-12-04 17:40:15,177 [main] INFO [org.apache.spark.network.netty.NettyBlockTransferService] - Server created on qb:51947
2021-12-04 17:40:15,179 [main] INFO [org.apache.spark.storage.BlockManager] - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2021-12-04 17:40:15,179 [main] INFO [org.apache.spark.storage.BlockManagerMaster] - Registering BlockManager BlockManagerId(driver, qb, 51947, None)
2021-12-04 17:40:15,181 [dispatcher-event-loop-10] INFO [org.apache.spark.storage.BlockManagerMasterEndpoint] - Registering block manager qb:51947 with 1990.8 MB RAM, BlockManagerId(driver, qb, 51947, None)
2021-12-04 17:40:15,183 [main] INFO [org.apache.spark.storage.BlockManagerMaster] - Registered BlockManager BlockManagerId(driver, qb, 51947, None)
2021-12-04 17:40:15,183 [main] INFO [org.apache.spark.storage.BlockManager] - Initialized BlockManager: BlockManagerId(driver, qb, 51947, None)
2021-12-04 17:40:15,303 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@7c9b78e3{/metrics/json,null,AVAILABLE,@Spark}
2021-12-04 17:40:15,754 [main] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_0 stored as values in memory (estimated size 312.7 KB, free 1990.5 MB)
2021-12-04 17:40:15,940 [main] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_0_piece0 stored as bytes in memory (estimated size 27.3 KB, free 1990.5 MB)
2021-12-04 17:40:15,942 [dispatcher-event-loop-0] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_0_piece0 in memory on qb:51947 (size: 27.3 KB, free: 1990.8 MB)
2021-12-04 17:40:15,944 [main] INFO [org.apache.spark.SparkContext] - Created broadcast 0 from textFile at PaidPromotionAdjustParameter.scala:98
2021-12-04 17:40:16,250 [main] WARN [org.apache.hadoop.hdfs.shortcircuit.DomainSocketFactory] - The short-circuit local reads feature cannot be used because UNIX Domain sockets are not available on Windows.
2021-12-04 17:40:16,317 [main] INFO [org.apache.hadoop.mapred.FileInputFormat] - Total input paths to process : 1
2021-12-04 17:40:16,357 [main] INFO [org.apache.spark.SparkContext] - Starting job: count at PaidPromotionAdjustParameter.scala:100
2021-12-04 17:40:16,366 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 0 (count at PaidPromotionAdjustParameter.scala:100) with 2 output partitions
2021-12-04 17:40:16,366 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 0 (count at PaidPromotionAdjustParameter.scala:100)
2021-12-04 17:40:16,366 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List()
2021-12-04 17:40:16,367 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2021-12-04 17:40:16,372 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 0 (/sk/chongqing/data/order_data.bcp MapPartitionsRDD[1] at textFile at PaidPromotionAdjustParameter.scala:98), which has no missing parents
2021-12-04 17:40:16,400 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_1 stored as values in memory (estimated size 3.1 KB, free 1990.5 MB)
2021-12-04 17:40:16,404 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_1_piece0 stored as bytes in memory (estimated size 1900.0 B, free 1990.5 MB)
2021-12-04 17:40:16,405 [dispatcher-event-loop-1] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_1_piece0 in memory on qb:51947 (size: 1900.0 B, free: 1990.8 MB)
2021-12-04 17:40:16,405 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 1 from broadcast at DAGScheduler.scala:1039
2021-12-04 17:40:16,414 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from ResultStage 0 (/sk/chongqing/data/order_data.bcp MapPartitionsRDD[1] at textFile at PaidPromotionAdjustParameter.scala:98) (first 15 tasks are for partitions Vector(0, 1))
2021-12-04 17:40:16,414 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 0.0 with 2 tasks
2021-12-04 17:40:16,444 [dispatcher-event-loop-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 0.0 (TID 0, localhost, executor driver, partition 0, ANY, 7896 bytes)
2021-12-04 17:40:16,445 [dispatcher-event-loop-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 0.0 (TID 1, localhost, executor driver, partition 1, ANY, 7896 bytes)
2021-12-04 17:40:16,450 [Executor task launch worker for task 1] INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 0.0 (TID 1)
2021-12-04 17:40:16,450 [Executor task launch worker for task 0] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 0.0 (TID 0)
2021-12-04 17:40:16,482 [Executor task launch worker for task 0] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/order_data.bcp:0+3442194
2021-12-04 17:40:16,482 [Executor task launch worker for task 1] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/order_data.bcp:3442194+3442195
2021-12-04 17:40:17,129 [Executor task launch worker for task 0] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 0.0 (TID 0). 711 bytes result sent to driver
2021-12-04 17:40:17,139 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 0.0 (TID 0) in 702 ms on localhost (executor driver) (1/2)
2021-12-04 17:40:17,167 [Executor task launch worker for task 1] INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 0.0 (TID 1). 711 bytes result sent to driver
2021-12-04 17:40:17,171 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 0.0 (TID 1) in 726 ms on localhost (executor driver) (2/2)
2021-12-04 17:40:17,172 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 0.0, whose tasks have all completed, from pool 
2021-12-04 17:40:17,172 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 0 (count at PaidPromotionAdjustParameter.scala:100) finished in 0.787 s
2021-12-04 17:40:17,176 [main] INFO [org.apache.spark.scheduler.DAGScheduler] - Job 0 finished: count at PaidPromotionAdjustParameter.scala:100, took 0.818831 s
2021-12-04 17:40:17,177 [main] INFO [PaidPromotion$] - 订购总数107294
2021-12-04 17:40:17,181 [main] INFO [org.apache.spark.SparkContext] - Starting job: count at PaidPromotionAdjustParameter.scala:108
2021-12-04 17:40:17,182 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 1 (count at PaidPromotionAdjustParameter.scala:108) with 2 output partitions
2021-12-04 17:40:17,182 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 1 (count at PaidPromotionAdjustParameter.scala:108)
2021-12-04 17:40:17,182 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List()
2021-12-04 17:40:17,182 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2021-12-04 17:40:17,182 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 1 (MapPartitionsRDD[2] at map at PaidPromotionAdjustParameter.scala:104), which has no missing parents
2021-12-04 17:40:17,183 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_2 stored as values in memory (estimated size 3.3 KB, free 1990.5 MB)
2021-12-04 17:40:17,188 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_2_piece0 stored as bytes in memory (estimated size 1985.0 B, free 1990.5 MB)
2021-12-04 17:40:17,188 [dispatcher-event-loop-7] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_2_piece0 in memory on qb:51947 (size: 1985.0 B, free: 1990.8 MB)
2021-12-04 17:40:17,189 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 2 from broadcast at DAGScheduler.scala:1039
2021-12-04 17:40:17,189 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from ResultStage 1 (MapPartitionsRDD[2] at map at PaidPromotionAdjustParameter.scala:104) (first 15 tasks are for partitions Vector(0, 1))
2021-12-04 17:40:17,189 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 1.0 with 2 tasks
2021-12-04 17:40:17,190 [dispatcher-event-loop-8] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 1.0 (TID 2, localhost, executor driver, partition 0, ANY, 7896 bytes)
2021-12-04 17:40:17,190 [dispatcher-event-loop-8] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 1.0 (TID 3, localhost, executor driver, partition 1, ANY, 7896 bytes)
2021-12-04 17:40:17,191 [Executor task launch worker for task 2] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 1.0 (TID 2)
2021-12-04 17:40:17,191 [Executor task launch worker for task 3] INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 1.0 (TID 3)
2021-12-04 17:40:17,193 [Executor task launch worker for task 2] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/order_data.bcp:0+3442194
2021-12-04 17:40:17,193 [Executor task launch worker for task 3] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/order_data.bcp:3442194+3442195
2021-12-04 17:40:17,312 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 7
2021-12-04 17:40:17,313 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 8
2021-12-04 17:40:17,313 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 0
2021-12-04 17:40:17,313 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 5
2021-12-04 17:40:17,313 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 10
2021-12-04 17:40:17,313 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 12
2021-12-04 17:40:17,313 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 22
2021-12-04 17:40:17,313 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 2
2021-12-04 17:40:17,313 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 23
2021-12-04 17:40:17,313 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 16
2021-12-04 17:40:17,313 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 20
2021-12-04 17:40:17,313 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 4
2021-12-04 17:40:17,313 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 6
2021-12-04 17:40:17,313 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 3
2021-12-04 17:40:17,313 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 11
2021-12-04 17:40:17,313 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 24
2021-12-04 17:40:17,313 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 19
2021-12-04 17:40:17,313 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 14
2021-12-04 17:40:17,314 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 9
2021-12-04 17:40:17,314 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 15
2021-12-04 17:40:17,314 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 17
2021-12-04 17:40:17,314 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 13
2021-12-04 17:40:17,314 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 21
2021-12-04 17:40:17,314 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1
2021-12-04 17:40:17,314 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 18
2021-12-04 17:40:17,326 [dispatcher-event-loop-1] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_1_piece0 on qb:51947 in memory (size: 1900.0 B, free: 1990.8 MB)
2021-12-04 17:40:17,952 [Executor task launch worker for task 2] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 1.0 (TID 2). 754 bytes result sent to driver
2021-12-04 17:40:17,955 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 1.0 (TID 2) in 765 ms on localhost (executor driver) (1/2)
2021-12-04 17:40:18,126 [Executor task launch worker for task 3] INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 1.0 (TID 3). 754 bytes result sent to driver
2021-12-04 17:40:18,128 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 1.0 (TID 3) in 938 ms on localhost (executor driver) (2/2)
2021-12-04 17:40:18,128 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 1.0, whose tasks have all completed, from pool 
2021-12-04 17:40:18,128 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 1 (count at PaidPromotionAdjustParameter.scala:108) finished in 0.945 s
2021-12-04 17:40:18,128 [main] INFO [org.apache.spark.scheduler.DAGScheduler] - Job 1 finished: count at PaidPromotionAdjustParameter.scala:108, took 0.946230 s
2021-12-04 17:40:18,129 [main] INFO [PaidPromotion$] - 订购总数：107294
2021-12-04 17:40:18,141 [main] INFO [org.apache.spark.SparkContext] - Starting job: count at PaidPromotionAdjustParameter.scala:121
2021-12-04 17:40:18,142 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 2 (count at PaidPromotionAdjustParameter.scala:121) with 2 output partitions
2021-12-04 17:40:18,142 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 2 (count at PaidPromotionAdjustParameter.scala:121)
2021-12-04 17:40:18,142 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List()
2021-12-04 17:40:18,142 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2021-12-04 17:40:18,142 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 2 (MapPartitionsRDD[3] at randomSplit at PaidPromotionAdjustParameter.scala:114), which has no missing parents
2021-12-04 17:40:18,143 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_3 stored as values in memory (estimated size 3.6 KB, free 1990.5 MB)
2021-12-04 17:40:18,150 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 42
2021-12-04 17:40:18,150 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_3_piece0 stored as bytes in memory (estimated size 2.1 KB, free 1990.5 MB)
2021-12-04 17:40:18,150 [dispatcher-event-loop-6] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_3_piece0 in memory on qb:51947 (size: 2.1 KB, free: 1990.8 MB)
2021-12-04 17:40:18,151 [dispatcher-event-loop-6] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_2_piece0 on qb:51947 in memory (size: 1985.0 B, free: 1990.8 MB)
2021-12-04 17:40:18,151 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 3 from broadcast at DAGScheduler.scala:1039
2021-12-04 17:40:18,151 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 45
2021-12-04 17:40:18,151 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 31
2021-12-04 17:40:18,151 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 28
2021-12-04 17:40:18,151 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 46
2021-12-04 17:40:18,151 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 37
2021-12-04 17:40:18,151 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 29
2021-12-04 17:40:18,151 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 34
2021-12-04 17:40:18,151 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 41
2021-12-04 17:40:18,151 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 26
2021-12-04 17:40:18,151 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 49
2021-12-04 17:40:18,151 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 43
2021-12-04 17:40:18,151 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from ResultStage 2 (MapPartitionsRDD[3] at randomSplit at PaidPromotionAdjustParameter.scala:114) (first 15 tasks are for partitions Vector(0, 1))
2021-12-04 17:40:18,151 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 38
2021-12-04 17:40:18,151 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 2.0 with 2 tasks
2021-12-04 17:40:18,152 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 36
2021-12-04 17:40:18,152 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 47
2021-12-04 17:40:18,152 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 35
2021-12-04 17:40:18,152 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 44
2021-12-04 17:40:18,152 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 32
2021-12-04 17:40:18,152 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 40
2021-12-04 17:40:18,152 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 25
2021-12-04 17:40:18,152 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 39
2021-12-04 17:40:18,152 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 33
2021-12-04 17:40:18,152 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 30
2021-12-04 17:40:18,152 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 48
2021-12-04 17:40:18,152 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 27
2021-12-04 17:40:18,152 [dispatcher-event-loop-8] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 2.0 (TID 4, localhost, executor driver, partition 0, ANY, 7896 bytes)
2021-12-04 17:40:18,153 [dispatcher-event-loop-8] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 2.0 (TID 5, localhost, executor driver, partition 1, ANY, 7896 bytes)
2021-12-04 17:40:18,153 [Executor task launch worker for task 4] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 2.0 (TID 4)
2021-12-04 17:40:18,153 [Executor task launch worker for task 5] INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 2.0 (TID 5)
2021-12-04 17:40:18,156 [Executor task launch worker for task 5] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/order_data.bcp:3442194+3442195
2021-12-04 17:40:18,156 [Executor task launch worker for task 4] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/order_data.bcp:0+3442194
2021-12-04 17:40:18,643 [Executor task launch worker for task 4] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 2.0 (TID 4). 754 bytes result sent to driver
2021-12-04 17:40:18,643 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 2.0 (TID 4) in 491 ms on localhost (executor driver) (1/2)
2021-12-04 17:40:18,891 [Executor task launch worker for task 5] INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 2.0 (TID 5). 754 bytes result sent to driver
2021-12-04 17:40:18,892 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 2.0 (TID 5) in 740 ms on localhost (executor driver) (2/2)
2021-12-04 17:40:18,892 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 2.0, whose tasks have all completed, from pool 
2021-12-04 17:40:18,892 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 2 (count at PaidPromotionAdjustParameter.scala:121) finished in 0.750 s
2021-12-04 17:40:18,893 [main] INFO [org.apache.spark.scheduler.DAGScheduler] - Job 2 finished: count at PaidPromotionAdjustParameter.scala:121, took 0.752138 s
2021-12-04 17:40:18,893 [main] INFO [PaidPromotion$] - 初次切分训练集数量：47311
2021-12-04 17:40:18,895 [main] INFO [org.apache.spark.SparkContext] - Starting job: count at PaidPromotionAdjustParameter.scala:122
2021-12-04 17:40:18,895 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 3 (count at PaidPromotionAdjustParameter.scala:122) with 2 output partitions
2021-12-04 17:40:18,895 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 3 (count at PaidPromotionAdjustParameter.scala:122)
2021-12-04 17:40:18,895 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List()
2021-12-04 17:40:18,896 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2021-12-04 17:40:18,896 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 3 (MapPartitionsRDD[4] at randomSplit at PaidPromotionAdjustParameter.scala:114), which has no missing parents
2021-12-04 17:40:18,897 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_4 stored as values in memory (estimated size 3.6 KB, free 1990.5 MB)
2021-12-04 17:40:18,900 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_4_piece0 stored as bytes in memory (estimated size 2.1 KB, free 1990.5 MB)
2021-12-04 17:40:18,900 [dispatcher-event-loop-1] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_4_piece0 in memory on qb:51947 (size: 2.1 KB, free: 1990.8 MB)
2021-12-04 17:40:18,901 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 4 from broadcast at DAGScheduler.scala:1039
2021-12-04 17:40:18,901 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from ResultStage 3 (MapPartitionsRDD[4] at randomSplit at PaidPromotionAdjustParameter.scala:114) (first 15 tasks are for partitions Vector(0, 1))
2021-12-04 17:40:18,901 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 3.0 with 2 tasks
2021-12-04 17:40:18,902 [dispatcher-event-loop-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 3.0 (TID 6, localhost, executor driver, partition 0, ANY, 7896 bytes)
2021-12-04 17:40:18,902 [dispatcher-event-loop-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 3.0 (TID 7, localhost, executor driver, partition 1, ANY, 7896 bytes)
2021-12-04 17:40:18,902 [Executor task launch worker for task 6] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 3.0 (TID 6)
2021-12-04 17:40:18,902 [Executor task launch worker for task 7] INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 3.0 (TID 7)
2021-12-04 17:40:18,904 [Executor task launch worker for task 6] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/order_data.bcp:0+3442194
2021-12-04 17:40:18,904 [Executor task launch worker for task 7] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/order_data.bcp:3442194+3442195
2021-12-04 17:40:19,126 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 69
2021-12-04 17:40:19,127 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 63
2021-12-04 17:40:19,127 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 66
2021-12-04 17:40:19,127 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 57
2021-12-04 17:40:19,127 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 73
2021-12-04 17:40:19,127 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 62
2021-12-04 17:40:19,127 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 64
2021-12-04 17:40:19,127 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 50
2021-12-04 17:40:19,128 [dispatcher-event-loop-6] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_3_piece0 on qb:51947 in memory (size: 2.1 KB, free: 1990.8 MB)
2021-12-04 17:40:19,128 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 70
2021-12-04 17:40:19,129 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 56
2021-12-04 17:40:19,129 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 72
2021-12-04 17:40:19,129 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 51
2021-12-04 17:40:19,129 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 61
2021-12-04 17:40:19,129 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 59
2021-12-04 17:40:19,129 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 53
2021-12-04 17:40:19,129 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 54
2021-12-04 17:40:19,129 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 65
2021-12-04 17:40:19,129 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 52
2021-12-04 17:40:19,129 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 71
2021-12-04 17:40:19,129 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 67
2021-12-04 17:40:19,129 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 68
2021-12-04 17:40:19,129 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 74
2021-12-04 17:40:19,129 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 55
2021-12-04 17:40:19,129 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 60
2021-12-04 17:40:19,129 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 58
2021-12-04 17:40:19,350 [Executor task launch worker for task 6] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 3.0 (TID 6). 797 bytes result sent to driver
2021-12-04 17:40:19,350 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 3.0 (TID 6) in 448 ms on localhost (executor driver) (1/2)
2021-12-04 17:40:19,787 [Executor task launch worker for task 7] INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 3.0 (TID 7). 797 bytes result sent to driver
2021-12-04 17:40:19,788 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 3.0 (TID 7) in 886 ms on localhost (executor driver) (2/2)
2021-12-04 17:40:19,788 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 3.0, whose tasks have all completed, from pool 
2021-12-04 17:40:19,789 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 3 (count at PaidPromotionAdjustParameter.scala:122) finished in 0.892 s
2021-12-04 17:40:19,789 [main] INFO [org.apache.spark.scheduler.DAGScheduler] - Job 3 finished: count at PaidPromotionAdjustParameter.scala:122, took 0.893325 s
2021-12-04 17:40:19,789 [main] INFO [PaidPromotion$] - 初次切分验证集数量：59983
2021-12-04 17:40:19,841 [main] INFO [PaidPromotion$] - -----------------------------------
2021-12-04 17:40:19,842 [main] INFO [org.apache.spark.SparkContext] - Starting job: count at PaidPromotionAdjustParameter.scala:138
2021-12-04 17:40:19,848 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 6 (distinct at PaidPromotionAdjustParameter.scala:128)
2021-12-04 17:40:19,849 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 4 (count at PaidPromotionAdjustParameter.scala:138) with 2 output partitions
2021-12-04 17:40:19,849 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 5 (count at PaidPromotionAdjustParameter.scala:138)
2021-12-04 17:40:19,849 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 4)
2021-12-04 17:40:19,849 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List(ShuffleMapStage 4)
2021-12-04 17:40:19,850 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ShuffleMapStage 4 (MapPartitionsRDD[6] at distinct at PaidPromotionAdjustParameter.scala:128), which has no missing parents
2021-12-04 17:40:19,859 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_5 stored as values in memory (estimated size 5.2 KB, free 1990.5 MB)
2021-12-04 17:40:19,861 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_5_piece0 stored as bytes in memory (estimated size 2.9 KB, free 1990.5 MB)
2021-12-04 17:40:19,862 [dispatcher-event-loop-10] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_5_piece0 in memory on qb:51947 (size: 2.9 KB, free: 1990.8 MB)
2021-12-04 17:40:19,863 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 5 from broadcast at DAGScheduler.scala:1039
2021-12-04 17:40:19,864 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from ShuffleMapStage 4 (MapPartitionsRDD[6] at distinct at PaidPromotionAdjustParameter.scala:128) (first 15 tasks are for partitions Vector(0, 1))
2021-12-04 17:40:19,864 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 4.0 with 2 tasks
2021-12-04 17:40:19,865 [dispatcher-event-loop-11] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 4.0 (TID 8, localhost, executor driver, partition 0, ANY, 7885 bytes)
2021-12-04 17:40:19,866 [dispatcher-event-loop-11] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 4.0 (TID 9, localhost, executor driver, partition 1, ANY, 7885 bytes)
2021-12-04 17:40:19,866 [Executor task launch worker for task 9] INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 4.0 (TID 9)
2021-12-04 17:40:19,866 [Executor task launch worker for task 8] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 4.0 (TID 8)
2021-12-04 17:40:19,870 [Executor task launch worker for task 9] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/order_data.bcp:3442194+3442195
2021-12-04 17:40:19,870 [Executor task launch worker for task 8] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/order_data.bcp:0+3442194
2021-12-04 17:40:20,254 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 86
2021-12-04 17:40:20,257 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 90
2021-12-04 17:40:20,257 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 83
2021-12-04 17:40:20,257 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 96
2021-12-04 17:40:20,257 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 91
2021-12-04 17:40:20,257 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 80
2021-12-04 17:40:20,257 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 99
2021-12-04 17:40:20,258 [dispatcher-event-loop-4] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_4_piece0 on qb:51947 in memory (size: 2.1 KB, free: 1990.8 MB)
2021-12-04 17:40:20,258 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 76
2021-12-04 17:40:20,258 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 78
2021-12-04 17:40:20,258 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 82
2021-12-04 17:40:20,258 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 84
2021-12-04 17:40:20,258 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 85
2021-12-04 17:40:20,258 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 75
2021-12-04 17:40:20,258 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 93
2021-12-04 17:40:20,258 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 95
2021-12-04 17:40:20,259 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 87
2021-12-04 17:40:20,259 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 81
2021-12-04 17:40:20,259 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 77
2021-12-04 17:40:20,259 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 92
2021-12-04 17:40:20,259 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 98
2021-12-04 17:40:20,259 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 94
2021-12-04 17:40:20,259 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 79
2021-12-04 17:40:20,259 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 89
2021-12-04 17:40:20,259 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 97
2021-12-04 17:40:20,259 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 88
2021-12-04 17:40:20,729 [Executor task launch worker for task 8] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 4.0 (TID 8). 1032 bytes result sent to driver
2021-12-04 17:40:20,742 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 4.0 (TID 8) in 877 ms on localhost (executor driver) (1/2)
2021-12-04 17:40:20,748 [Executor task launch worker for task 9] INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 4.0 (TID 9). 1032 bytes result sent to driver
2021-12-04 17:40:20,749 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 4.0 (TID 9) in 884 ms on localhost (executor driver) (2/2)
2021-12-04 17:40:20,749 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 4.0, whose tasks have all completed, from pool 
2021-12-04 17:40:20,749 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ShuffleMapStage 4 (distinct at PaidPromotionAdjustParameter.scala:128) finished in 0.897 s
2021-12-04 17:40:20,750 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - looking for newly runnable stages
2021-12-04 17:40:20,750 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - running: Set()
2021-12-04 17:40:20,751 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - waiting: Set(ResultStage 5)
2021-12-04 17:40:20,751 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - failed: Set()
2021-12-04 17:40:20,753 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 5 (MapPartitionsRDD[8] at distinct at PaidPromotionAdjustParameter.scala:128), which has no missing parents
2021-12-04 17:40:20,758 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_6 stored as values in memory (estimated size 3.7 KB, free 1990.5 MB)
2021-12-04 17:40:20,760 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_6_piece0 stored as bytes in memory (estimated size 2.2 KB, free 1990.5 MB)
2021-12-04 17:40:20,761 [dispatcher-event-loop-6] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_6_piece0 in memory on qb:51947 (size: 2.2 KB, free: 1990.8 MB)
2021-12-04 17:40:20,761 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 6 from broadcast at DAGScheduler.scala:1039
2021-12-04 17:40:20,761 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from ResultStage 5 (MapPartitionsRDD[8] at distinct at PaidPromotionAdjustParameter.scala:128) (first 15 tasks are for partitions Vector(0, 1))
2021-12-04 17:40:20,761 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 5.0 with 2 tasks
2021-12-04 17:40:20,762 [dispatcher-event-loop-8] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 5.0 (TID 10, localhost, executor driver, partition 0, ANY, 7649 bytes)
2021-12-04 17:40:20,763 [dispatcher-event-loop-8] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 5.0 (TID 11, localhost, executor driver, partition 1, ANY, 7649 bytes)
2021-12-04 17:40:20,763 [Executor task launch worker for task 10] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 5.0 (TID 10)
2021-12-04 17:40:20,763 [Executor task launch worker for task 11] INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 5.0 (TID 11)
2021-12-04 17:40:20,774 [Executor task launch worker for task 11] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 2 non-empty blocks out of 2 blocks
2021-12-04 17:40:20,774 [Executor task launch worker for task 10] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 2 non-empty blocks out of 2 blocks
2021-12-04 17:40:20,775 [Executor task launch worker for task 10] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 4 ms
2021-12-04 17:40:20,775 [Executor task launch worker for task 11] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 4 ms
2021-12-04 17:40:20,888 [Executor task launch worker for task 11] INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 5.0 (TID 11). 1055 bytes result sent to driver
2021-12-04 17:40:20,888 [Executor task launch worker for task 10] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 5.0 (TID 10). 1055 bytes result sent to driver
2021-12-04 17:40:20,889 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 5.0 (TID 10) in 127 ms on localhost (executor driver) (1/2)
2021-12-04 17:40:20,889 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 5.0 (TID 11) in 127 ms on localhost (executor driver) (2/2)
2021-12-04 17:40:20,889 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 5.0, whose tasks have all completed, from pool 
2021-12-04 17:40:20,890 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 5 (count at PaidPromotionAdjustParameter.scala:138) finished in 0.135 s
2021-12-04 17:40:20,890 [main] INFO [org.apache.spark.scheduler.DAGScheduler] - Job 4 finished: count at PaidPromotionAdjustParameter.scala:138, took 1.047988 s
2021-12-04 17:40:20,891 [main] INFO [PaidPromotion$] - 训练集用户数 = 44630
2021-12-04 17:40:20,894 [main] INFO [org.apache.spark.SparkContext] - Starting job: count at PaidPromotionAdjustParameter.scala:139
2021-12-04 17:40:20,895 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 10 (distinct at PaidPromotionAdjustParameter.scala:129)
2021-12-04 17:40:20,895 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 5 (count at PaidPromotionAdjustParameter.scala:139) with 2 output partitions
2021-12-04 17:40:20,895 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 7 (count at PaidPromotionAdjustParameter.scala:139)
2021-12-04 17:40:20,895 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 6)
2021-12-04 17:40:20,895 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List(ShuffleMapStage 6)
2021-12-04 17:40:20,895 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ShuffleMapStage 6 (MapPartitionsRDD[10] at distinct at PaidPromotionAdjustParameter.scala:129), which has no missing parents
2021-12-04 17:40:20,897 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_7 stored as values in memory (estimated size 5.2 KB, free 1990.4 MB)
2021-12-04 17:40:20,901 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_7_piece0 stored as bytes in memory (estimated size 2.9 KB, free 1990.4 MB)
2021-12-04 17:40:20,902 [dispatcher-event-loop-0] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_7_piece0 in memory on qb:51947 (size: 2.9 KB, free: 1990.8 MB)
2021-12-04 17:40:20,902 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 7 from broadcast at DAGScheduler.scala:1039
2021-12-04 17:40:20,902 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from ShuffleMapStage 6 (MapPartitionsRDD[10] at distinct at PaidPromotionAdjustParameter.scala:129) (first 15 tasks are for partitions Vector(0, 1))
2021-12-04 17:40:20,902 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 6.0 with 2 tasks
2021-12-04 17:40:20,903 [dispatcher-event-loop-5] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 6.0 (TID 12, localhost, executor driver, partition 0, ANY, 7885 bytes)
2021-12-04 17:40:20,903 [dispatcher-event-loop-5] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 6.0 (TID 13, localhost, executor driver, partition 1, ANY, 7885 bytes)
2021-12-04 17:40:20,903 [Executor task launch worker for task 13] INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 6.0 (TID 13)
2021-12-04 17:40:20,903 [Executor task launch worker for task 12] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 6.0 (TID 12)
2021-12-04 17:40:20,905 [Executor task launch worker for task 13] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/order_data.bcp:3442194+3442195
2021-12-04 17:40:20,905 [Executor task launch worker for task 12] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/order_data.bcp:0+3442194
2021-12-04 17:40:21,332 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 112
2021-12-04 17:40:21,332 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 139
2021-12-04 17:40:21,332 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 143
2021-12-04 17:40:21,332 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 105
2021-12-04 17:40:21,332 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 145
2021-12-04 17:40:21,332 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 104
2021-12-04 17:40:21,332 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 107
2021-12-04 17:40:21,332 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 140
2021-12-04 17:40:21,333 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 102
2021-12-04 17:40:21,333 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 115
2021-12-04 17:40:21,333 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 106
2021-12-04 17:40:21,333 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 127
2021-12-04 17:40:21,333 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 131
2021-12-04 17:40:21,333 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 125
2021-12-04 17:40:21,333 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 109
2021-12-04 17:40:21,333 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 142
2021-12-04 17:40:21,333 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 148
2021-12-04 17:40:21,333 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 134
2021-12-04 17:40:21,333 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 136
2021-12-04 17:40:21,333 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 122
2021-12-04 17:40:21,333 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 124
2021-12-04 17:40:21,334 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 117
2021-12-04 17:40:21,334 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 149
2021-12-04 17:40:21,334 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 133
2021-12-04 17:40:21,334 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 100
2021-12-04 17:40:21,334 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 101
2021-12-04 17:40:21,334 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 111
2021-12-04 17:40:21,334 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 123
2021-12-04 17:40:21,334 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 116
2021-12-04 17:40:21,334 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 129
2021-12-04 17:40:21,335 [dispatcher-event-loop-6] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_5_piece0 on qb:51947 in memory (size: 2.9 KB, free: 1990.8 MB)
2021-12-04 17:40:21,335 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 135
2021-12-04 17:40:21,336 [dispatcher-event-loop-10] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_6_piece0 on qb:51947 in memory (size: 2.2 KB, free: 1990.8 MB)
2021-12-04 17:40:21,336 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 147
2021-12-04 17:40:21,336 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 138
2021-12-04 17:40:21,336 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 108
2021-12-04 17:40:21,336 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 141
2021-12-04 17:40:21,336 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 130
2021-12-04 17:40:21,336 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 128
2021-12-04 17:40:21,336 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 114
2021-12-04 17:40:21,336 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 103
2021-12-04 17:40:21,336 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 126
2021-12-04 17:40:21,336 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 144
2021-12-04 17:40:21,336 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 113
2021-12-04 17:40:21,336 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 146
2021-12-04 17:40:21,337 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 110
2021-12-04 17:40:21,337 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 121
2021-12-04 17:40:21,337 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 118
2021-12-04 17:40:21,337 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 132
2021-12-04 17:40:21,337 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 137
2021-12-04 17:40:21,337 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 119
2021-12-04 17:40:21,337 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 120
2021-12-04 17:40:21,696 [Executor task launch worker for task 12] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 6.0 (TID 12). 1075 bytes result sent to driver
2021-12-04 17:40:21,697 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 6.0 (TID 12) in 794 ms on localhost (executor driver) (1/2)
2021-12-04 17:40:21,716 [Executor task launch worker for task 13] INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 6.0 (TID 13). 1075 bytes result sent to driver
2021-12-04 17:40:21,716 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 6.0 (TID 13) in 813 ms on localhost (executor driver) (2/2)
2021-12-04 17:40:21,716 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 6.0, whose tasks have all completed, from pool 
2021-12-04 17:40:21,716 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ShuffleMapStage 6 (distinct at PaidPromotionAdjustParameter.scala:129) finished in 0.820 s
2021-12-04 17:40:21,717 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - looking for newly runnable stages
2021-12-04 17:40:21,717 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - running: Set()
2021-12-04 17:40:21,717 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - waiting: Set(ResultStage 7)
2021-12-04 17:40:21,717 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - failed: Set()
2021-12-04 17:40:21,717 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 7 (MapPartitionsRDD[12] at distinct at PaidPromotionAdjustParameter.scala:129), which has no missing parents
2021-12-04 17:40:21,718 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_8 stored as values in memory (estimated size 3.7 KB, free 1990.5 MB)
2021-12-04 17:40:21,721 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_8_piece0 stored as bytes in memory (estimated size 2.2 KB, free 1990.5 MB)
2021-12-04 17:40:21,722 [dispatcher-event-loop-0] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_8_piece0 in memory on qb:51947 (size: 2.2 KB, free: 1990.8 MB)
2021-12-04 17:40:21,722 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 8 from broadcast at DAGScheduler.scala:1039
2021-12-04 17:40:21,722 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from ResultStage 7 (MapPartitionsRDD[12] at distinct at PaidPromotionAdjustParameter.scala:129) (first 15 tasks are for partitions Vector(0, 1))
2021-12-04 17:40:21,722 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 7.0 with 2 tasks
2021-12-04 17:40:21,723 [dispatcher-event-loop-5] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 7.0 (TID 14, localhost, executor driver, partition 0, ANY, 7649 bytes)
2021-12-04 17:40:21,723 [dispatcher-event-loop-5] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 7.0 (TID 15, localhost, executor driver, partition 1, ANY, 7649 bytes)
2021-12-04 17:40:21,723 [Executor task launch worker for task 15] INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 7.0 (TID 15)
2021-12-04 17:40:21,723 [Executor task launch worker for task 14] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 7.0 (TID 14)
2021-12-04 17:40:21,725 [Executor task launch worker for task 15] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 2 non-empty blocks out of 2 blocks
2021-12-04 17:40:21,725 [Executor task launch worker for task 15] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-04 17:40:21,725 [Executor task launch worker for task 14] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 2 non-empty blocks out of 2 blocks
2021-12-04 17:40:21,725 [Executor task launch worker for task 14] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-04 17:40:21,801 [Executor task launch worker for task 15] INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 7.0 (TID 15). 1012 bytes result sent to driver
2021-12-04 17:40:21,801 [Executor task launch worker for task 14] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 7.0 (TID 14). 1055 bytes result sent to driver
2021-12-04 17:40:21,802 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 7.0 (TID 15) in 79 ms on localhost (executor driver) (1/2)
2021-12-04 17:40:21,802 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 7.0 (TID 14) in 79 ms on localhost (executor driver) (2/2)
2021-12-04 17:40:21,802 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 7.0, whose tasks have all completed, from pool 
2021-12-04 17:40:21,802 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 7 (count at PaidPromotionAdjustParameter.scala:139) finished in 0.085 s
2021-12-04 17:40:21,803 [main] INFO [org.apache.spark.scheduler.DAGScheduler] - Job 5 finished: count at PaidPromotionAdjustParameter.scala:139, took 0.908445 s
2021-12-04 17:40:21,803 [main] INFO [PaidPromotion$] - 验证集用户数 = 55799
2021-12-04 17:40:21,808 [main] INFO [org.apache.spark.SparkContext] - Starting job: count at PaidPromotionAdjustParameter.scala:140
2021-12-04 17:40:21,808 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 13 (intersection at PaidPromotionAdjustParameter.scala:130)
2021-12-04 17:40:21,808 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 14 (intersection at PaidPromotionAdjustParameter.scala:130)
2021-12-04 17:40:21,808 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 6 (count at PaidPromotionAdjustParameter.scala:140) with 2 output partitions
2021-12-04 17:40:21,808 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 12 (count at PaidPromotionAdjustParameter.scala:140)
2021-12-04 17:40:21,808 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 9, ShuffleMapStage 11)
2021-12-04 17:40:21,809 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List(ShuffleMapStage 9, ShuffleMapStage 11)
2021-12-04 17:40:21,809 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ShuffleMapStage 9 (MapPartitionsRDD[13] at intersection at PaidPromotionAdjustParameter.scala:130), which has no missing parents
2021-12-04 17:40:21,810 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_9 stored as values in memory (estimated size 4.0 KB, free 1990.5 MB)
2021-12-04 17:40:21,813 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_9_piece0 stored as bytes in memory (estimated size 2.3 KB, free 1990.4 MB)
2021-12-04 17:40:21,813 [dispatcher-event-loop-6] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_9_piece0 in memory on qb:51947 (size: 2.3 KB, free: 1990.8 MB)
2021-12-04 17:40:21,814 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 9 from broadcast at DAGScheduler.scala:1039
2021-12-04 17:40:21,814 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from ShuffleMapStage 9 (MapPartitionsRDD[13] at intersection at PaidPromotionAdjustParameter.scala:130) (first 15 tasks are for partitions Vector(0, 1))
2021-12-04 17:40:21,814 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 9.0 with 2 tasks
2021-12-04 17:40:21,814 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ShuffleMapStage 11 (MapPartitionsRDD[14] at intersection at PaidPromotionAdjustParameter.scala:130), which has no missing parents
2021-12-04 17:40:21,815 [dispatcher-event-loop-9] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 9.0 (TID 16, localhost, executor driver, partition 0, ANY, 7638 bytes)
2021-12-04 17:40:21,815 [dispatcher-event-loop-9] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 9.0 (TID 17, localhost, executor driver, partition 1, ANY, 7638 bytes)
2021-12-04 17:40:21,815 [Executor task launch worker for task 16] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 9.0 (TID 16)
2021-12-04 17:40:21,815 [Executor task launch worker for task 17] INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 9.0 (TID 17)
2021-12-04 17:40:21,816 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_10 stored as values in memory (estimated size 4.0 KB, free 1990.4 MB)
2021-12-04 17:40:21,818 [Executor task launch worker for task 17] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 2 non-empty blocks out of 2 blocks
2021-12-04 17:40:21,818 [Executor task launch worker for task 17] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-04 17:40:21,818 [Executor task launch worker for task 16] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 2 non-empty blocks out of 2 blocks
2021-12-04 17:40:21,819 [Executor task launch worker for task 16] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 1 ms
2021-12-04 17:40:21,820 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_10_piece0 stored as bytes in memory (estimated size 2.3 KB, free 1990.4 MB)
2021-12-04 17:40:21,820 [dispatcher-event-loop-1] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_10_piece0 in memory on qb:51947 (size: 2.3 KB, free: 1990.8 MB)
2021-12-04 17:40:21,821 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 10 from broadcast at DAGScheduler.scala:1039
2021-12-04 17:40:21,821 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from ShuffleMapStage 11 (MapPartitionsRDD[14] at intersection at PaidPromotionAdjustParameter.scala:130) (first 15 tasks are for partitions Vector(0, 1))
2021-12-04 17:40:21,821 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 11.0 with 2 tasks
2021-12-04 17:40:21,822 [dispatcher-event-loop-11] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 11.0 (TID 18, localhost, executor driver, partition 0, ANY, 7638 bytes)
2021-12-04 17:40:21,822 [dispatcher-event-loop-11] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 11.0 (TID 19, localhost, executor driver, partition 1, ANY, 7638 bytes)
2021-12-04 17:40:21,822 [Executor task launch worker for task 18] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 11.0 (TID 18)
2021-12-04 17:40:21,823 [Executor task launch worker for task 19] INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 11.0 (TID 19)
2021-12-04 17:40:21,824 [Executor task launch worker for task 18] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 2 non-empty blocks out of 2 blocks
2021-12-04 17:40:21,824 [Executor task launch worker for task 19] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 2 non-empty blocks out of 2 blocks
2021-12-04 17:40:21,824 [Executor task launch worker for task 18] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-04 17:40:21,824 [Executor task launch worker for task 19] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-04 17:40:21,904 [Executor task launch worker for task 17] INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 9.0 (TID 17). 1204 bytes result sent to driver
2021-12-04 17:40:21,905 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 9.0 (TID 17) in 90 ms on localhost (executor driver) (1/2)
2021-12-04 17:40:21,919 [Executor task launch worker for task 16] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 9.0 (TID 16). 1204 bytes result sent to driver
2021-12-04 17:40:21,919 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 9.0 (TID 16) in 105 ms on localhost (executor driver) (2/2)
2021-12-04 17:40:21,919 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 9.0, whose tasks have all completed, from pool 
2021-12-04 17:40:21,920 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ShuffleMapStage 9 (intersection at PaidPromotionAdjustParameter.scala:130) finished in 0.111 s
2021-12-04 17:40:21,920 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - looking for newly runnable stages
2021-12-04 17:40:21,920 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - running: Set(ShuffleMapStage 11)
2021-12-04 17:40:21,920 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - waiting: Set(ResultStage 12)
2021-12-04 17:40:21,920 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - failed: Set()
2021-12-04 17:40:21,928 [Executor task launch worker for task 19] INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 11.0 (TID 19). 1204 bytes result sent to driver
2021-12-04 17:40:21,929 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 11.0 (TID 19) in 107 ms on localhost (executor driver) (1/2)
2021-12-04 17:40:21,929 [Executor task launch worker for task 18] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 11.0 (TID 18). 1204 bytes result sent to driver
2021-12-04 17:40:21,930 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 11.0 (TID 18) in 109 ms on localhost (executor driver) (2/2)
2021-12-04 17:40:21,930 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 11.0, whose tasks have all completed, from pool 
2021-12-04 17:40:21,930 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ShuffleMapStage 11 (intersection at PaidPromotionAdjustParameter.scala:130) finished in 0.115 s
2021-12-04 17:40:21,930 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - looking for newly runnable stages
2021-12-04 17:40:21,930 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - running: Set()
2021-12-04 17:40:21,930 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - waiting: Set(ResultStage 12)
2021-12-04 17:40:21,930 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - failed: Set()
2021-12-04 17:40:21,930 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 12 (MapPartitionsRDD[18] at intersection at PaidPromotionAdjustParameter.scala:130), which has no missing parents
2021-12-04 17:40:21,932 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_11 stored as values in memory (estimated size 3.6 KB, free 1990.4 MB)
2021-12-04 17:40:21,934 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_11_piece0 stored as bytes in memory (estimated size 2.1 KB, free 1990.4 MB)
2021-12-04 17:40:21,935 [dispatcher-event-loop-6] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_11_piece0 in memory on qb:51947 (size: 2.1 KB, free: 1990.8 MB)
2021-12-04 17:40:21,935 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 11 from broadcast at DAGScheduler.scala:1039
2021-12-04 17:40:21,936 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from ResultStage 12 (MapPartitionsRDD[18] at intersection at PaidPromotionAdjustParameter.scala:130) (first 15 tasks are for partitions Vector(0, 1))
2021-12-04 17:40:21,936 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 12.0 with 2 tasks
2021-12-04 17:40:21,937 [dispatcher-event-loop-8] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 12.0 (TID 20, localhost, executor driver, partition 0, PROCESS_LOCAL, 7712 bytes)
2021-12-04 17:40:21,937 [dispatcher-event-loop-8] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 12.0 (TID 21, localhost, executor driver, partition 1, PROCESS_LOCAL, 7712 bytes)
2021-12-04 17:40:21,937 [Executor task launch worker for task 20] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 12.0 (TID 20)
2021-12-04 17:40:21,937 [Executor task launch worker for task 21] INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 12.0 (TID 21)
2021-12-04 17:40:21,940 [Executor task launch worker for task 21] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2021-12-04 17:40:21,940 [Executor task launch worker for task 20] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2021-12-04 17:40:21,940 [Executor task launch worker for task 21] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-04 17:40:21,940 [Executor task launch worker for task 20] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-04 17:40:21,942 [Executor task launch worker for task 20] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2021-12-04 17:40:21,942 [Executor task launch worker for task 21] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2021-12-04 17:40:21,942 [Executor task launch worker for task 20] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-04 17:40:21,942 [Executor task launch worker for task 21] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-04 17:40:21,989 [dispatcher-event-loop-0] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_7_piece0 on qb:51947 in memory (size: 2.9 KB, free: 1990.8 MB)
2021-12-04 17:40:21,989 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 168
2021-12-04 17:40:21,990 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 197
2021-12-04 17:40:21,990 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 178
2021-12-04 17:40:21,990 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 169
2021-12-04 17:40:21,990 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 181
2021-12-04 17:40:21,990 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 192
2021-12-04 17:40:21,990 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 153
2021-12-04 17:40:21,990 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 166
2021-12-04 17:40:21,991 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 191
2021-12-04 17:40:21,992 [dispatcher-event-loop-4] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_8_piece0 on qb:51947 in memory (size: 2.2 KB, free: 1990.8 MB)
2021-12-04 17:40:21,992 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 175
2021-12-04 17:40:21,992 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 167
2021-12-04 17:40:21,992 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 194
2021-12-04 17:40:21,993 [dispatcher-event-loop-6] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_9_piece0 on qb:51947 in memory (size: 2.3 KB, free: 1990.8 MB)
2021-12-04 17:40:21,993 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 160
2021-12-04 17:40:21,993 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 183
2021-12-04 17:40:21,993 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 184
2021-12-04 17:40:21,993 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 172
2021-12-04 17:40:21,994 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 188
2021-12-04 17:40:21,994 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 179
2021-12-04 17:40:21,994 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 190
2021-12-04 17:40:21,994 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 196
2021-12-04 17:40:21,994 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 187
2021-12-04 17:40:21,994 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 162
2021-12-04 17:40:21,994 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 170
2021-12-04 17:40:21,994 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 156
2021-12-04 17:40:21,994 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 177
2021-12-04 17:40:21,994 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 171
2021-12-04 17:40:21,994 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 158
2021-12-04 17:40:21,995 [dispatcher-event-loop-9] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_10_piece0 on qb:51947 in memory (size: 2.3 KB, free: 1990.8 MB)
2021-12-04 17:40:21,995 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 180
2021-12-04 17:40:21,995 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 150
2021-12-04 17:40:21,995 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 161
2021-12-04 17:40:21,995 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 164
2021-12-04 17:40:21,995 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 195
2021-12-04 17:40:21,995 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 155
2021-12-04 17:40:21,995 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 165
2021-12-04 17:40:21,995 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 182
2021-12-04 17:40:21,995 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 186
2021-12-04 17:40:21,995 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 198
2021-12-04 17:40:21,995 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 185
2021-12-04 17:40:21,995 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 163
2021-12-04 17:40:21,995 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 159
2021-12-04 17:40:21,995 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 152
2021-12-04 17:40:21,995 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 193
2021-12-04 17:40:21,995 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 199
2021-12-04 17:40:21,995 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 174
2021-12-04 17:40:21,995 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 157
2021-12-04 17:40:21,995 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 176
2021-12-04 17:40:21,995 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 173
2021-12-04 17:40:21,995 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 154
2021-12-04 17:40:21,995 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 151
2021-12-04 17:40:21,995 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 189
2021-12-04 17:40:22,087 [Executor task launch worker for task 21] INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 12.0 (TID 21). 1097 bytes result sent to driver
2021-12-04 17:40:22,087 [Executor task launch worker for task 20] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 12.0 (TID 20). 1097 bytes result sent to driver
2021-12-04 17:40:22,087 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 12.0 (TID 21) in 150 ms on localhost (executor driver) (1/2)
2021-12-04 17:40:22,088 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 12.0 (TID 20) in 152 ms on localhost (executor driver) (2/2)
2021-12-04 17:40:22,088 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 12.0, whose tasks have all completed, from pool 
2021-12-04 17:40:22,088 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 12 (count at PaidPromotionAdjustParameter.scala:140) finished in 0.157 s
2021-12-04 17:40:22,088 [main] INFO [org.apache.spark.scheduler.DAGScheduler] - Job 6 finished: count at PaidPromotionAdjustParameter.scala:140, took 0.280967 s
2021-12-04 17:40:22,089 [main] INFO [PaidPromotion$] - 共 同 用户数 = 5106
2021-12-04 17:40:22,091 [main] INFO [org.apache.spark.SparkContext] - Starting job: count at PaidPromotionAdjustParameter.scala:141
2021-12-04 17:40:22,092 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 20 (distinct at PaidPromotionAdjustParameter.scala:133)
2021-12-04 17:40:22,092 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 7 (count at PaidPromotionAdjustParameter.scala:141) with 2 output partitions
2021-12-04 17:40:22,092 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 14 (count at PaidPromotionAdjustParameter.scala:141)
2021-12-04 17:40:22,092 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 13)
2021-12-04 17:40:22,092 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List(ShuffleMapStage 13)
2021-12-04 17:40:22,092 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ShuffleMapStage 13 (MapPartitionsRDD[20] at distinct at PaidPromotionAdjustParameter.scala:133), which has no missing parents
2021-12-04 17:40:22,093 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_12 stored as values in memory (estimated size 5.2 KB, free 1990.5 MB)
2021-12-04 17:40:22,095 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_12_piece0 stored as bytes in memory (estimated size 2.9 KB, free 1990.5 MB)
2021-12-04 17:40:22,096 [dispatcher-event-loop-0] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_12_piece0 in memory on qb:51947 (size: 2.9 KB, free: 1990.8 MB)
2021-12-04 17:40:22,096 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 12 from broadcast at DAGScheduler.scala:1039
2021-12-04 17:40:22,097 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from ShuffleMapStage 13 (MapPartitionsRDD[20] at distinct at PaidPromotionAdjustParameter.scala:133) (first 15 tasks are for partitions Vector(0, 1))
2021-12-04 17:40:22,097 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 13.0 with 2 tasks
2021-12-04 17:40:22,097 [dispatcher-event-loop-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 13.0 (TID 22, localhost, executor driver, partition 0, ANY, 7885 bytes)
2021-12-04 17:40:22,097 [dispatcher-event-loop-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 13.0 (TID 23, localhost, executor driver, partition 1, ANY, 7885 bytes)
2021-12-04 17:40:22,097 [Executor task launch worker for task 23] INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 13.0 (TID 23)
2021-12-04 17:40:22,097 [Executor task launch worker for task 22] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 13.0 (TID 22)
2021-12-04 17:40:22,099 [Executor task launch worker for task 22] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/order_data.bcp:0+3442194
2021-12-04 17:40:22,099 [Executor task launch worker for task 23] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/order_data.bcp:3442194+3442195
2021-12-04 17:40:22,487 [Executor task launch worker for task 23] INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 13.0 (TID 23). 989 bytes result sent to driver
2021-12-04 17:40:22,488 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 13.0 (TID 23) in 391 ms on localhost (executor driver) (1/2)
2021-12-04 17:40:22,791 [Executor task launch worker for task 22] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 13.0 (TID 22). 989 bytes result sent to driver
2021-12-04 17:40:22,792 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 13.0 (TID 22) in 695 ms on localhost (executor driver) (2/2)
2021-12-04 17:40:22,792 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 13.0, whose tasks have all completed, from pool 
2021-12-04 17:40:22,792 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ShuffleMapStage 13 (distinct at PaidPromotionAdjustParameter.scala:133) finished in 0.700 s
2021-12-04 17:40:22,793 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - looking for newly runnable stages
2021-12-04 17:40:22,793 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - running: Set()
2021-12-04 17:40:22,793 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - waiting: Set(ResultStage 14)
2021-12-04 17:40:22,793 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - failed: Set()
2021-12-04 17:40:22,793 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 14 (MapPartitionsRDD[22] at distinct at PaidPromotionAdjustParameter.scala:133), which has no missing parents
2021-12-04 17:40:22,793 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_13 stored as values in memory (estimated size 3.7 KB, free 1990.5 MB)
2021-12-04 17:40:22,796 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_13_piece0 stored as bytes in memory (estimated size 2.2 KB, free 1990.4 MB)
2021-12-04 17:40:22,797 [dispatcher-event-loop-6] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_13_piece0 in memory on qb:51947 (size: 2.2 KB, free: 1990.8 MB)
2021-12-04 17:40:22,797 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 13 from broadcast at DAGScheduler.scala:1039
2021-12-04 17:40:22,797 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from ResultStage 14 (MapPartitionsRDD[22] at distinct at PaidPromotionAdjustParameter.scala:133) (first 15 tasks are for partitions Vector(0, 1))
2021-12-04 17:40:22,797 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 14.0 with 2 tasks
2021-12-04 17:40:22,798 [dispatcher-event-loop-10] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 14.0 (TID 24, localhost, executor driver, partition 0, ANY, 7649 bytes)
2021-12-04 17:40:22,798 [dispatcher-event-loop-10] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 14.0 (TID 25, localhost, executor driver, partition 1, ANY, 7649 bytes)
2021-12-04 17:40:22,798 [Executor task launch worker for task 25] INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 14.0 (TID 25)
2021-12-04 17:40:22,798 [Executor task launch worker for task 24] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 14.0 (TID 24)
2021-12-04 17:40:22,799 [Executor task launch worker for task 25] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 2 non-empty blocks out of 2 blocks
2021-12-04 17:40:22,800 [Executor task launch worker for task 24] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 2 non-empty blocks out of 2 blocks
2021-12-04 17:40:22,800 [Executor task launch worker for task 25] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 1 ms
2021-12-04 17:40:22,800 [Executor task launch worker for task 24] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 1 ms
2021-12-04 17:40:22,813 [Executor task launch worker for task 25] INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 14.0 (TID 25). 967 bytes result sent to driver
2021-12-04 17:40:22,813 [Executor task launch worker for task 24] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 14.0 (TID 24). 967 bytes result sent to driver
2021-12-04 17:40:22,814 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 14.0 (TID 25) in 16 ms on localhost (executor driver) (1/2)
2021-12-04 17:40:22,814 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 14.0 (TID 24) in 16 ms on localhost (executor driver) (2/2)
2021-12-04 17:40:22,814 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 14.0, whose tasks have all completed, from pool 
2021-12-04 17:40:22,814 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 14 (count at PaidPromotionAdjustParameter.scala:141) finished in 0.021 s
2021-12-04 17:40:22,815 [main] INFO [org.apache.spark.scheduler.DAGScheduler] - Job 7 finished: count at PaidPromotionAdjustParameter.scala:141, took 0.722999 s
2021-12-04 17:40:22,815 [main] INFO [PaidPromotion$] - 训练集节目数 = 118
2021-12-04 17:40:22,817 [main] INFO [org.apache.spark.SparkContext] - Starting job: count at PaidPromotionAdjustParameter.scala:142
2021-12-04 17:40:22,818 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 24 (distinct at PaidPromotionAdjustParameter.scala:134)
2021-12-04 17:40:22,818 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 8 (count at PaidPromotionAdjustParameter.scala:142) with 2 output partitions
2021-12-04 17:40:22,818 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 16 (count at PaidPromotionAdjustParameter.scala:142)
2021-12-04 17:40:22,818 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 15)
2021-12-04 17:40:22,818 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List(ShuffleMapStage 15)
2021-12-04 17:40:22,818 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ShuffleMapStage 15 (MapPartitionsRDD[24] at distinct at PaidPromotionAdjustParameter.scala:134), which has no missing parents
2021-12-04 17:40:22,819 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_14 stored as values in memory (estimated size 5.2 KB, free 1990.4 MB)
2021-12-04 17:40:22,824 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 236
2021-12-04 17:40:22,824 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 237
2021-12-04 17:40:22,824 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 217
2021-12-04 17:40:22,824 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 255
2021-12-04 17:40:22,824 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 259
2021-12-04 17:40:22,824 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 260
2021-12-04 17:40:22,824 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 229
2021-12-04 17:40:22,824 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 243
2021-12-04 17:40:22,824 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 225
2021-12-04 17:40:22,824 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_14_piece0 stored as bytes in memory (estimated size 2.9 KB, free 1990.4 MB)
2021-12-04 17:40:22,824 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 201
2021-12-04 17:40:22,825 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 301
2021-12-04 17:40:22,825 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 238
2021-12-04 17:40:22,825 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 244
2021-12-04 17:40:22,825 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 252
2021-12-04 17:40:22,825 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 292
2021-12-04 17:40:22,825 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 309
2021-12-04 17:40:22,825 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 274
2021-12-04 17:40:22,825 [dispatcher-event-loop-0] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_14_piece0 in memory on qb:51947 (size: 2.9 KB, free: 1990.8 MB)
2021-12-04 17:40:22,825 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 14 from broadcast at DAGScheduler.scala:1039
2021-12-04 17:40:22,825 [dispatcher-event-loop-4] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_13_piece0 on qb:51947 in memory (size: 2.2 KB, free: 1990.8 MB)
2021-12-04 17:40:22,825 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from ShuffleMapStage 15 (MapPartitionsRDD[24] at distinct at PaidPromotionAdjustParameter.scala:134) (first 15 tasks are for partitions Vector(0, 1))
2021-12-04 17:40:22,826 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 15.0 with 2 tasks
2021-12-04 17:40:22,826 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 232
2021-12-04 17:40:22,826 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 264
2021-12-04 17:40:22,826 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 313
2021-12-04 17:40:22,826 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 206
2021-12-04 17:40:22,826 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 278
2021-12-04 17:40:22,826 [dispatcher-event-loop-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 15.0 (TID 26, localhost, executor driver, partition 0, ANY, 7885 bytes)
2021-12-04 17:40:22,826 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 265
2021-12-04 17:40:22,826 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 318
2021-12-04 17:40:22,826 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 230
2021-12-04 17:40:22,826 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 231
2021-12-04 17:40:22,826 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 207
2021-12-04 17:40:22,826 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 273
2021-12-04 17:40:22,827 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 247
2021-12-04 17:40:22,827 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 270
2021-12-04 17:40:22,827 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 320
2021-12-04 17:40:22,827 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 295
2021-12-04 17:40:22,827 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 280
2021-12-04 17:40:22,827 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 321
2021-12-04 17:40:22,827 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 245
2021-12-04 17:40:22,827 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 291
2021-12-04 17:40:22,827 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 215
2021-12-04 17:40:22,827 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 293
2021-12-04 17:40:22,827 [dispatcher-event-loop-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 15.0 (TID 27, localhost, executor driver, partition 1, ANY, 7885 bytes)
2021-12-04 17:40:22,827 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 222
2021-12-04 17:40:22,827 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 269
2021-12-04 17:40:22,827 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 254
2021-12-04 17:40:22,827 [Executor task launch worker for task 27] INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 15.0 (TID 27)
2021-12-04 17:40:22,827 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 227
2021-12-04 17:40:22,827 [Executor task launch worker for task 26] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 15.0 (TID 26)
2021-12-04 17:40:22,827 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 314
2021-12-04 17:40:22,827 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 267
2021-12-04 17:40:22,827 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 216
2021-12-04 17:40:22,827 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 288
2021-12-04 17:40:22,827 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 218
2021-12-04 17:40:22,827 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 248
2021-12-04 17:40:22,827 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 268
2021-12-04 17:40:22,827 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 263
2021-12-04 17:40:22,827 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 306
2021-12-04 17:40:22,827 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 324
2021-12-04 17:40:22,827 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 305
2021-12-04 17:40:22,827 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 228
2021-12-04 17:40:22,827 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 202
2021-12-04 17:40:22,827 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 312
2021-12-04 17:40:22,828 [dispatcher-event-loop-9] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_11_piece0 on qb:51947 in memory (size: 2.1 KB, free: 1990.8 MB)
2021-12-04 17:40:22,828 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 251
2021-12-04 17:40:22,828 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 256
2021-12-04 17:40:22,828 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 234
2021-12-04 17:40:22,828 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 289
2021-12-04 17:40:22,828 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 239
2021-12-04 17:40:22,828 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 299
2021-12-04 17:40:22,828 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 223
2021-12-04 17:40:22,828 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 308
2021-12-04 17:40:22,828 [Executor task launch worker for task 27] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/order_data.bcp:3442194+3442195
2021-12-04 17:40:22,829 [Executor task launch worker for task 26] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/order_data.bcp:0+3442194
2021-12-04 17:40:22,829 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 271
2021-12-04 17:40:22,829 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 282
2021-12-04 17:40:22,829 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 294
2021-12-04 17:40:22,829 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 311
2021-12-04 17:40:22,829 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 310
2021-12-04 17:40:22,829 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 276
2021-12-04 17:40:22,829 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 224
2021-12-04 17:40:22,829 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 257
2021-12-04 17:40:22,829 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 298
2021-12-04 17:40:22,829 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 250
2021-12-04 17:40:22,829 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 286
2021-12-04 17:40:22,829 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 303
2021-12-04 17:40:22,829 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 221
2021-12-04 17:40:22,829 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 319
2021-12-04 17:40:22,829 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 300
2021-12-04 17:40:22,829 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 261
2021-12-04 17:40:22,829 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 279
2021-12-04 17:40:22,829 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 277
2021-12-04 17:40:22,829 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 203
2021-12-04 17:40:22,829 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 242
2021-12-04 17:40:22,829 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 249
2021-12-04 17:40:22,829 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 275
2021-12-04 17:40:22,829 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 210
2021-12-04 17:40:22,829 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 220
2021-12-04 17:40:22,829 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 214
2021-12-04 17:40:22,829 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 296
2021-12-04 17:40:22,829 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 200
2021-12-04 17:40:22,829 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 241
2021-12-04 17:40:22,829 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 233
2021-12-04 17:40:22,829 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 283
2021-12-04 17:40:22,829 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 304
2021-12-04 17:40:22,829 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 208
2021-12-04 17:40:22,829 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 323
2021-12-04 17:40:22,829 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 219
2021-12-04 17:40:22,829 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 235
2021-12-04 17:40:22,829 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 246
2021-12-04 17:40:22,829 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 285
2021-12-04 17:40:22,830 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 240
2021-12-04 17:40:22,830 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 209
2021-12-04 17:40:22,830 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 213
2021-12-04 17:40:22,830 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 322
2021-12-04 17:40:22,830 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 297
2021-12-04 17:40:22,830 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 266
2021-12-04 17:40:22,830 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 212
2021-12-04 17:40:22,830 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 205
2021-12-04 17:40:22,830 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 204
2021-12-04 17:40:22,830 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 284
2021-12-04 17:40:22,830 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 258
2021-12-04 17:40:22,830 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 211
2021-12-04 17:40:22,830 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 272
2021-12-04 17:40:22,830 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 316
2021-12-04 17:40:22,830 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 262
2021-12-04 17:40:22,830 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 281
2021-12-04 17:40:22,830 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 315
2021-12-04 17:40:22,830 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 226
2021-12-04 17:40:22,830 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 317
2021-12-04 17:40:22,830 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 302
2021-12-04 17:40:22,830 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 287
2021-12-04 17:40:22,830 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 253
2021-12-04 17:40:22,830 [dispatcher-event-loop-2] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_12_piece0 on qb:51947 in memory (size: 2.9 KB, free: 1990.8 MB)
2021-12-04 17:40:22,831 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 290
2021-12-04 17:40:22,831 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 307
2021-12-04 17:40:23,465 [Executor task launch worker for task 27] INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 15.0 (TID 27). 946 bytes result sent to driver
2021-12-04 17:40:23,466 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 15.0 (TID 27) in 640 ms on localhost (executor driver) (1/2)
2021-12-04 17:40:23,485 [Executor task launch worker for task 26] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 15.0 (TID 26). 946 bytes result sent to driver
2021-12-04 17:40:23,485 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 15.0 (TID 26) in 659 ms on localhost (executor driver) (2/2)
2021-12-04 17:40:23,485 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 15.0, whose tasks have all completed, from pool 
2021-12-04 17:40:23,485 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ShuffleMapStage 15 (distinct at PaidPromotionAdjustParameter.scala:134) finished in 0.666 s
2021-12-04 17:40:23,485 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - looking for newly runnable stages
2021-12-04 17:40:23,485 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - running: Set()
2021-12-04 17:40:23,485 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - waiting: Set(ResultStage 16)
2021-12-04 17:40:23,485 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - failed: Set()
2021-12-04 17:40:23,486 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 16 (MapPartitionsRDD[26] at distinct at PaidPromotionAdjustParameter.scala:134), which has no missing parents
2021-12-04 17:40:23,486 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_15 stored as values in memory (estimated size 3.7 KB, free 1990.5 MB)
2021-12-04 17:40:23,488 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_15_piece0 stored as bytes in memory (estimated size 2.2 KB, free 1990.5 MB)
2021-12-04 17:40:23,488 [dispatcher-event-loop-4] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_15_piece0 in memory on qb:51947 (size: 2.2 KB, free: 1990.8 MB)
2021-12-04 17:40:23,489 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 15 from broadcast at DAGScheduler.scala:1039
2021-12-04 17:40:23,489 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from ResultStage 16 (MapPartitionsRDD[26] at distinct at PaidPromotionAdjustParameter.scala:134) (first 15 tasks are for partitions Vector(0, 1))
2021-12-04 17:40:23,489 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 16.0 with 2 tasks
2021-12-04 17:40:23,489 [dispatcher-event-loop-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 16.0 (TID 28, localhost, executor driver, partition 0, ANY, 7649 bytes)
2021-12-04 17:40:23,489 [dispatcher-event-loop-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 16.0 (TID 29, localhost, executor driver, partition 1, ANY, 7649 bytes)
2021-12-04 17:40:23,489 [Executor task launch worker for task 29] INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 16.0 (TID 29)
2021-12-04 17:40:23,489 [Executor task launch worker for task 28] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 16.0 (TID 28)
2021-12-04 17:40:23,491 [Executor task launch worker for task 28] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 2 non-empty blocks out of 2 blocks
2021-12-04 17:40:23,491 [Executor task launch worker for task 29] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 2 non-empty blocks out of 2 blocks
2021-12-04 17:40:23,491 [Executor task launch worker for task 28] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-04 17:40:23,491 [Executor task launch worker for task 29] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-04 17:40:23,502 [Executor task launch worker for task 28] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 16.0 (TID 28). 1010 bytes result sent to driver
2021-12-04 17:40:23,502 [Executor task launch worker for task 29] INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 16.0 (TID 29). 1010 bytes result sent to driver
2021-12-04 17:40:23,503 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 16.0 (TID 28) in 14 ms on localhost (executor driver) (1/2)
2021-12-04 17:40:23,503 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 16.0 (TID 29) in 14 ms on localhost (executor driver) (2/2)
2021-12-04 17:40:23,503 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 16.0, whose tasks have all completed, from pool 
2021-12-04 17:40:23,503 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 16 (count at PaidPromotionAdjustParameter.scala:142) finished in 0.017 s
2021-12-04 17:40:23,503 [main] INFO [org.apache.spark.scheduler.DAGScheduler] - Job 8 finished: count at PaidPromotionAdjustParameter.scala:142, took 0.686325 s
2021-12-04 17:40:23,503 [main] INFO [PaidPromotion$] - 验证集节目数 = 124
2021-12-04 17:40:23,506 [main] INFO [org.apache.spark.SparkContext] - Starting job: count at PaidPromotionAdjustParameter.scala:143
2021-12-04 17:40:23,506 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 27 (intersection at PaidPromotionAdjustParameter.scala:135)
2021-12-04 17:40:23,506 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 28 (intersection at PaidPromotionAdjustParameter.scala:135)
2021-12-04 17:40:23,506 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 9 (count at PaidPromotionAdjustParameter.scala:143) with 2 output partitions
2021-12-04 17:40:23,506 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 21 (count at PaidPromotionAdjustParameter.scala:143)
2021-12-04 17:40:23,507 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 20, ShuffleMapStage 18)
2021-12-04 17:40:23,507 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List(ShuffleMapStage 20, ShuffleMapStage 18)
2021-12-04 17:40:23,507 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ShuffleMapStage 18 (MapPartitionsRDD[27] at intersection at PaidPromotionAdjustParameter.scala:135), which has no missing parents
2021-12-04 17:40:23,507 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_16 stored as values in memory (estimated size 4.0 KB, free 1990.5 MB)
2021-12-04 17:40:23,509 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_16_piece0 stored as bytes in memory (estimated size 2.3 KB, free 1990.4 MB)
2021-12-04 17:40:23,510 [dispatcher-event-loop-9] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_16_piece0 in memory on qb:51947 (size: 2.3 KB, free: 1990.8 MB)
2021-12-04 17:40:23,510 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 16 from broadcast at DAGScheduler.scala:1039
2021-12-04 17:40:23,510 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from ShuffleMapStage 18 (MapPartitionsRDD[27] at intersection at PaidPromotionAdjustParameter.scala:135) (first 15 tasks are for partitions Vector(0, 1))
2021-12-04 17:40:23,510 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 18.0 with 2 tasks
2021-12-04 17:40:23,511 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ShuffleMapStage 20 (MapPartitionsRDD[28] at intersection at PaidPromotionAdjustParameter.scala:135), which has no missing parents
2021-12-04 17:40:23,511 [dispatcher-event-loop-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 18.0 (TID 30, localhost, executor driver, partition 0, ANY, 7638 bytes)
2021-12-04 17:40:23,511 [dispatcher-event-loop-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 18.0 (TID 31, localhost, executor driver, partition 1, ANY, 7638 bytes)
2021-12-04 17:40:23,511 [Executor task launch worker for task 31] INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 18.0 (TID 31)
2021-12-04 17:40:23,511 [Executor task launch worker for task 30] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 18.0 (TID 30)
2021-12-04 17:40:23,512 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_17 stored as values in memory (estimated size 4.0 KB, free 1990.4 MB)
2021-12-04 17:40:23,512 [Executor task launch worker for task 30] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 2 non-empty blocks out of 2 blocks
2021-12-04 17:40:23,512 [Executor task launch worker for task 30] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-04 17:40:23,512 [Executor task launch worker for task 31] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 2 non-empty blocks out of 2 blocks
2021-12-04 17:40:23,512 [Executor task launch worker for task 31] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-04 17:40:23,514 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_17_piece0 stored as bytes in memory (estimated size 2.3 KB, free 1990.4 MB)
2021-12-04 17:40:23,514 [dispatcher-event-loop-5] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_17_piece0 in memory on qb:51947 (size: 2.3 KB, free: 1990.8 MB)
2021-12-04 17:40:23,514 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 17 from broadcast at DAGScheduler.scala:1039
2021-12-04 17:40:23,514 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from ShuffleMapStage 20 (MapPartitionsRDD[28] at intersection at PaidPromotionAdjustParameter.scala:135) (first 15 tasks are for partitions Vector(0, 1))
2021-12-04 17:40:23,515 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 20.0 with 2 tasks
2021-12-04 17:40:23,515 [dispatcher-event-loop-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 20.0 (TID 32, localhost, executor driver, partition 0, ANY, 7638 bytes)
2021-12-04 17:40:23,515 [dispatcher-event-loop-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 20.0 (TID 33, localhost, executor driver, partition 1, ANY, 7638 bytes)
2021-12-04 17:40:23,515 [Executor task launch worker for task 33] INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 20.0 (TID 33)
2021-12-04 17:40:23,515 [Executor task launch worker for task 32] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 20.0 (TID 32)
2021-12-04 17:40:23,516 [Executor task launch worker for task 32] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 2 non-empty blocks out of 2 blocks
2021-12-04 17:40:23,516 [Executor task launch worker for task 32] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-04 17:40:23,516 [Executor task launch worker for task 33] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 2 non-empty blocks out of 2 blocks
2021-12-04 17:40:23,516 [Executor task launch worker for task 33] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-04 17:40:23,528 [Executor task launch worker for task 30] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 18.0 (TID 30). 1204 bytes result sent to driver
2021-12-04 17:40:23,529 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 18.0 (TID 30) in 18 ms on localhost (executor driver) (1/2)
2021-12-04 17:40:23,529 [Executor task launch worker for task 31] INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 18.0 (TID 31). 1204 bytes result sent to driver
2021-12-04 17:40:23,530 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 18.0 (TID 31) in 19 ms on localhost (executor driver) (2/2)
2021-12-04 17:40:23,530 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 18.0, whose tasks have all completed, from pool 
2021-12-04 17:40:23,530 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ShuffleMapStage 18 (intersection at PaidPromotionAdjustParameter.scala:135) finished in 0.023 s
2021-12-04 17:40:23,530 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - looking for newly runnable stages
2021-12-04 17:40:23,530 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - running: Set(ShuffleMapStage 20)
2021-12-04 17:40:23,530 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - waiting: Set(ResultStage 21)
2021-12-04 17:40:23,530 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - failed: Set()
2021-12-04 17:40:23,531 [Executor task launch worker for task 32] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 20.0 (TID 32). 1161 bytes result sent to driver
2021-12-04 17:40:23,531 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 20.0 (TID 32) in 16 ms on localhost (executor driver) (1/2)
2021-12-04 17:40:23,531 [Executor task launch worker for task 33] INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 20.0 (TID 33). 1204 bytes result sent to driver
2021-12-04 17:40:23,532 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 20.0 (TID 33) in 17 ms on localhost (executor driver) (2/2)
2021-12-04 17:40:23,532 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 20.0, whose tasks have all completed, from pool 
2021-12-04 17:40:23,532 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ShuffleMapStage 20 (intersection at PaidPromotionAdjustParameter.scala:135) finished in 0.020 s
2021-12-04 17:40:23,532 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - looking for newly runnable stages
2021-12-04 17:40:23,532 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - running: Set()
2021-12-04 17:40:23,532 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - waiting: Set(ResultStage 21)
2021-12-04 17:40:23,532 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - failed: Set()
2021-12-04 17:40:23,532 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 21 (MapPartitionsRDD[32] at intersection at PaidPromotionAdjustParameter.scala:135), which has no missing parents
2021-12-04 17:40:23,533 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_18 stored as values in memory (estimated size 3.6 KB, free 1990.4 MB)
2021-12-04 17:40:23,534 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_18_piece0 stored as bytes in memory (estimated size 2.1 KB, free 1990.4 MB)
2021-12-04 17:40:23,535 [dispatcher-event-loop-9] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_18_piece0 in memory on qb:51947 (size: 2.1 KB, free: 1990.8 MB)
2021-12-04 17:40:23,535 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 18 from broadcast at DAGScheduler.scala:1039
2021-12-04 17:40:23,535 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from ResultStage 21 (MapPartitionsRDD[32] at intersection at PaidPromotionAdjustParameter.scala:135) (first 15 tasks are for partitions Vector(0, 1))
2021-12-04 17:40:23,535 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 21.0 with 2 tasks
2021-12-04 17:40:23,536 [dispatcher-event-loop-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 21.0 (TID 34, localhost, executor driver, partition 0, PROCESS_LOCAL, 7712 bytes)
2021-12-04 17:40:23,536 [dispatcher-event-loop-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 21.0 (TID 35, localhost, executor driver, partition 1, PROCESS_LOCAL, 7712 bytes)
2021-12-04 17:40:23,536 [Executor task launch worker for task 34] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 21.0 (TID 34)
2021-12-04 17:40:23,536 [Executor task launch worker for task 35] INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 21.0 (TID 35)
2021-12-04 17:40:23,537 [Executor task launch worker for task 35] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2021-12-04 17:40:23,537 [Executor task launch worker for task 34] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2021-12-04 17:40:23,537 [Executor task launch worker for task 35] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-04 17:40:23,537 [Executor task launch worker for task 34] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-04 17:40:23,539 [Executor task launch worker for task 34] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2021-12-04 17:40:23,539 [Executor task launch worker for task 35] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2021-12-04 17:40:23,539 [Executor task launch worker for task 34] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-04 17:40:23,539 [Executor task launch worker for task 35] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-04 17:40:23,544 [Executor task launch worker for task 35] INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 21.0 (TID 35). 1010 bytes result sent to driver
2021-12-04 17:40:23,544 [Executor task launch worker for task 34] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 21.0 (TID 34). 1010 bytes result sent to driver
2021-12-04 17:40:23,545 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 21.0 (TID 35) in 9 ms on localhost (executor driver) (1/2)
2021-12-04 17:40:23,545 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 21.0 (TID 34) in 10 ms on localhost (executor driver) (2/2)
2021-12-04 17:40:23,545 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 21.0, whose tasks have all completed, from pool 
2021-12-04 17:40:23,545 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 21 (count at PaidPromotionAdjustParameter.scala:143) finished in 0.013 s
2021-12-04 17:40:23,545 [main] INFO [org.apache.spark.scheduler.DAGScheduler] - Job 9 finished: count at PaidPromotionAdjustParameter.scala:143, took 0.039464 s
2021-12-04 17:40:23,546 [main] INFO [PaidPromotion$] - 共 同 节目数 = 110
2021-12-04 17:40:23,553 [main] INFO [org.apache.spark.SparkContext] - Starting job: collect at PaidPromotionAdjustParameter.scala:146
2021-12-04 17:40:23,553 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 10 (collect at PaidPromotionAdjustParameter.scala:146) with 2 output partitions
2021-12-04 17:40:23,553 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 26 (collect at PaidPromotionAdjustParameter.scala:146)
2021-12-04 17:40:23,553 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 25, ShuffleMapStage 23)
2021-12-04 17:40:23,553 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2021-12-04 17:40:23,554 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 26 (MapPartitionsRDD[18] at intersection at PaidPromotionAdjustParameter.scala:130), which has no missing parents
2021-12-04 17:40:23,554 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_19 stored as values in memory (estimated size 3.8 KB, free 1990.4 MB)
2021-12-04 17:40:23,557 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_19_piece0 stored as bytes in memory (estimated size 2.2 KB, free 1990.4 MB)
2021-12-04 17:40:23,557 [dispatcher-event-loop-4] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_19_piece0 in memory on qb:51947 (size: 2.2 KB, free: 1990.8 MB)
2021-12-04 17:40:23,557 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 19 from broadcast at DAGScheduler.scala:1039
2021-12-04 17:40:23,558 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from ResultStage 26 (MapPartitionsRDD[18] at intersection at PaidPromotionAdjustParameter.scala:130) (first 15 tasks are for partitions Vector(0, 1))
2021-12-04 17:40:23,558 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 26.0 with 2 tasks
2021-12-04 17:40:23,558 [dispatcher-event-loop-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 26.0 (TID 36, localhost, executor driver, partition 0, PROCESS_LOCAL, 7712 bytes)
2021-12-04 17:40:23,558 [dispatcher-event-loop-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 26.0 (TID 37, localhost, executor driver, partition 1, PROCESS_LOCAL, 7712 bytes)
2021-12-04 17:40:23,558 [Executor task launch worker for task 36] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 26.0 (TID 36)
2021-12-04 17:40:23,558 [Executor task launch worker for task 37] INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 26.0 (TID 37)
2021-12-04 17:40:23,559 [Executor task launch worker for task 37] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2021-12-04 17:40:23,559 [Executor task launch worker for task 36] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2021-12-04 17:40:23,559 [Executor task launch worker for task 37] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-04 17:40:23,559 [Executor task launch worker for task 36] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-04 17:40:23,561 [Executor task launch worker for task 36] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2021-12-04 17:40:23,561 [Executor task launch worker for task 37] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2021-12-04 17:40:23,561 [Executor task launch worker for task 36] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-04 17:40:23,561 [Executor task launch worker for task 37] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-04 17:40:23,624 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 348
2021-12-04 17:40:23,624 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 404
2021-12-04 17:40:23,625 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 383
2021-12-04 17:40:23,625 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 408
2021-12-04 17:40:23,625 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 355
2021-12-04 17:40:23,625 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 386
2021-12-04 17:40:23,625 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 387
2021-12-04 17:40:23,625 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 388
2021-12-04 17:40:23,625 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 448
2021-12-04 17:40:23,625 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 345
2021-12-04 17:40:23,625 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 333
2021-12-04 17:40:23,626 [dispatcher-event-loop-9] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_16_piece0 on qb:51947 in memory (size: 2.3 KB, free: 1990.8 MB)
2021-12-04 17:40:23,626 [dispatcher-event-loop-11] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_17_piece0 on qb:51947 in memory (size: 2.3 KB, free: 1990.8 MB)
2021-12-04 17:40:23,627 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 449
2021-12-04 17:40:23,627 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 371
2021-12-04 17:40:23,627 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 336
2021-12-04 17:40:23,627 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 401
2021-12-04 17:40:23,627 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 326
2021-12-04 17:40:23,627 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 442
2021-12-04 17:40:23,627 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 373
2021-12-04 17:40:23,627 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 429
2021-12-04 17:40:23,627 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 392
2021-12-04 17:40:23,627 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 423
2021-12-04 17:40:23,627 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 344
2021-12-04 17:40:23,627 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 390
2021-12-04 17:40:23,627 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 406
2021-12-04 17:40:23,627 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 352
2021-12-04 17:40:23,627 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 446
2021-12-04 17:40:23,627 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 357
2021-12-04 17:40:23,627 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 393
2021-12-04 17:40:23,627 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 440
2021-12-04 17:40:23,627 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 362
2021-12-04 17:40:23,627 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 359
2021-12-04 17:40:23,627 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 414
2021-12-04 17:40:23,627 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 422
2021-12-04 17:40:23,627 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 378
2021-12-04 17:40:23,627 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 329
2021-12-04 17:40:23,627 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 382
2021-12-04 17:40:23,628 [dispatcher-event-loop-4] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_14_piece0 on qb:51947 in memory (size: 2.9 KB, free: 1990.8 MB)
2021-12-04 17:40:23,628 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 335
2021-12-04 17:40:23,628 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 433
2021-12-04 17:40:23,628 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 426
2021-12-04 17:40:23,628 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 379
2021-12-04 17:40:23,628 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 328
2021-12-04 17:40:23,628 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 377
2021-12-04 17:40:23,628 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 366
2021-12-04 17:40:23,628 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 331
2021-12-04 17:40:23,628 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 437
2021-12-04 17:40:23,628 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 332
2021-12-04 17:40:23,628 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 417
2021-12-04 17:40:23,628 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 394
2021-12-04 17:40:23,628 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 415
2021-12-04 17:40:23,629 [dispatcher-event-loop-7] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_18_piece0 on qb:51947 in memory (size: 2.1 KB, free: 1990.8 MB)
2021-12-04 17:40:23,629 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 425
2021-12-04 17:40:23,629 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 341
2021-12-04 17:40:23,629 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 430
2021-12-04 17:40:23,629 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 368
2021-12-04 17:40:23,629 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 441
2021-12-04 17:40:23,629 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 380
2021-12-04 17:40:23,630 [dispatcher-event-loop-9] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_15_piece0 on qb:51947 in memory (size: 2.2 KB, free: 1990.8 MB)
2021-12-04 17:40:23,630 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 418
2021-12-04 17:40:23,630 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 445
2021-12-04 17:40:23,630 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 337
2021-12-04 17:40:23,630 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 438
2021-12-04 17:40:23,630 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 334
2021-12-04 17:40:23,630 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 376
2021-12-04 17:40:23,630 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 435
2021-12-04 17:40:23,630 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 338
2021-12-04 17:40:23,630 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 421
2021-12-04 17:40:23,630 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 407
2021-12-04 17:40:23,630 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 432
2021-12-04 17:40:23,630 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 351
2021-12-04 17:40:23,630 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 325
2021-12-04 17:40:23,630 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 356
2021-12-04 17:40:23,631 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 428
2021-12-04 17:40:23,631 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 385
2021-12-04 17:40:23,631 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 399
2021-12-04 17:40:23,631 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 395
2021-12-04 17:40:23,631 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 354
2021-12-04 17:40:23,631 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 361
2021-12-04 17:40:23,631 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 403
2021-12-04 17:40:23,631 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 413
2021-12-04 17:40:23,631 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 420
2021-12-04 17:40:23,631 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 358
2021-12-04 17:40:23,631 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 372
2021-12-04 17:40:23,631 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 434
2021-12-04 17:40:23,631 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 416
2021-12-04 17:40:23,631 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 431
2021-12-04 17:40:23,631 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 396
2021-12-04 17:40:23,631 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 444
2021-12-04 17:40:23,631 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 327
2021-12-04 17:40:23,631 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 402
2021-12-04 17:40:23,631 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 343
2021-12-04 17:40:23,631 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 419
2021-12-04 17:40:23,631 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 375
2021-12-04 17:40:23,631 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 353
2021-12-04 17:40:23,631 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 342
2021-12-04 17:40:23,631 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 369
2021-12-04 17:40:23,631 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 400
2021-12-04 17:40:23,631 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 370
2021-12-04 17:40:23,631 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 339
2021-12-04 17:40:23,631 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 391
2021-12-04 17:40:23,631 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 412
2021-12-04 17:40:23,631 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 367
2021-12-04 17:40:23,631 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 447
2021-12-04 17:40:23,631 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 365
2021-12-04 17:40:23,631 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 389
2021-12-04 17:40:23,631 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 384
2021-12-04 17:40:23,631 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 381
2021-12-04 17:40:23,631 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 330
2021-12-04 17:40:23,631 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 397
2021-12-04 17:40:23,631 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 398
2021-12-04 17:40:23,631 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 409
2021-12-04 17:40:23,631 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 405
2021-12-04 17:40:23,631 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 427
2021-12-04 17:40:23,631 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 410
2021-12-04 17:40:23,631 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 411
2021-12-04 17:40:23,631 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 346
2021-12-04 17:40:23,631 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 439
2021-12-04 17:40:23,631 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 360
2021-12-04 17:40:23,631 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 363
2021-12-04 17:40:23,631 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 374
2021-12-04 17:40:23,631 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 424
2021-12-04 17:40:23,631 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 349
2021-12-04 17:40:23,631 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 364
2021-12-04 17:40:23,631 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 443
2021-12-04 17:40:23,631 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 340
2021-12-04 17:40:23,631 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 347
2021-12-04 17:40:23,631 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 436
2021-12-04 17:40:23,631 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 350
2021-12-04 17:40:23,666 [Executor task launch worker for task 36] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 26.0 (TID 36). 85072 bytes result sent to driver
2021-12-04 17:40:23,668 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 26.0 (TID 36) in 109 ms on localhost (executor driver) (1/2)
2021-12-04 17:40:23,669 [Executor task launch worker for task 37] INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 26.0 (TID 37). 86529 bytes result sent to driver
2021-12-04 17:40:23,670 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 26.0 (TID 37) in 112 ms on localhost (executor driver) (2/2)
2021-12-04 17:40:23,670 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 26.0, whose tasks have all completed, from pool 
2021-12-04 17:40:23,670 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 26 (collect at PaidPromotionAdjustParameter.scala:146) finished in 0.116 s
2021-12-04 17:40:23,670 [main] INFO [org.apache.spark.scheduler.DAGScheduler] - Job 10 finished: collect at PaidPromotionAdjustParameter.scala:146, took 0.117393 s
2021-12-04 17:40:23,675 [main] INFO [org.apache.spark.SparkContext] - Starting job: collect at PaidPromotionAdjustParameter.scala:147
2021-12-04 17:40:23,675 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 11 (collect at PaidPromotionAdjustParameter.scala:147) with 2 output partitions
2021-12-04 17:40:23,676 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 31 (collect at PaidPromotionAdjustParameter.scala:147)
2021-12-04 17:40:23,676 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 30, ShuffleMapStage 28)
2021-12-04 17:40:23,676 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2021-12-04 17:40:23,676 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 31 (MapPartitionsRDD[32] at intersection at PaidPromotionAdjustParameter.scala:135), which has no missing parents
2021-12-04 17:40:23,676 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_20 stored as values in memory (estimated size 3.8 KB, free 1990.5 MB)
2021-12-04 17:40:23,679 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_20_piece0 stored as bytes in memory (estimated size 2.2 KB, free 1990.5 MB)
2021-12-04 17:40:23,679 [dispatcher-event-loop-11] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_20_piece0 in memory on qb:51947 (size: 2.2 KB, free: 1990.8 MB)
2021-12-04 17:40:23,679 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 20 from broadcast at DAGScheduler.scala:1039
2021-12-04 17:40:23,680 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from ResultStage 31 (MapPartitionsRDD[32] at intersection at PaidPromotionAdjustParameter.scala:135) (first 15 tasks are for partitions Vector(0, 1))
2021-12-04 17:40:23,680 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 31.0 with 2 tasks
2021-12-04 17:40:23,680 [dispatcher-event-loop-5] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 31.0 (TID 38, localhost, executor driver, partition 0, PROCESS_LOCAL, 7712 bytes)
2021-12-04 17:40:23,680 [dispatcher-event-loop-5] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 31.0 (TID 39, localhost, executor driver, partition 1, PROCESS_LOCAL, 7712 bytes)
2021-12-04 17:40:23,680 [Executor task launch worker for task 38] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 31.0 (TID 38)
2021-12-04 17:40:23,680 [Executor task launch worker for task 39] INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 31.0 (TID 39)
2021-12-04 17:40:23,681 [Executor task launch worker for task 38] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2021-12-04 17:40:23,681 [Executor task launch worker for task 39] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2021-12-04 17:40:23,681 [Executor task launch worker for task 38] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-04 17:40:23,681 [Executor task launch worker for task 39] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-04 17:40:23,683 [Executor task launch worker for task 38] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2021-12-04 17:40:23,683 [Executor task launch worker for task 39] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2021-12-04 17:40:23,683 [Executor task launch worker for task 38] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-04 17:40:23,683 [Executor task launch worker for task 39] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-04 17:40:23,689 [Executor task launch worker for task 39] INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 31.0 (TID 39). 2666 bytes result sent to driver
2021-12-04 17:40:23,689 [Executor task launch worker for task 38] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 31.0 (TID 38). 2694 bytes result sent to driver
2021-12-04 17:40:23,689 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 31.0 (TID 39) in 9 ms on localhost (executor driver) (1/2)
2021-12-04 17:40:23,689 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 31.0 (TID 38) in 9 ms on localhost (executor driver) (2/2)
2021-12-04 17:40:23,689 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 31.0, whose tasks have all completed, from pool 
2021-12-04 17:40:23,689 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 31 (collect at PaidPromotionAdjustParameter.scala:147) finished in 0.013 s
2021-12-04 17:40:23,690 [main] INFO [org.apache.spark.scheduler.DAGScheduler] - Job 11 finished: collect at PaidPromotionAdjustParameter.scala:147, took 0.014691 s
2021-12-04 17:40:23,711 [main] INFO [org.apache.spark.SparkContext] - Starting job: count at PaidPromotionAdjustParameter.scala:156
2021-12-04 17:40:23,712 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 12 (count at PaidPromotionAdjustParameter.scala:156) with 4 output partitions
2021-12-04 17:40:23,712 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 32 (count at PaidPromotionAdjustParameter.scala:156)
2021-12-04 17:40:23,712 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List()
2021-12-04 17:40:23,712 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2021-12-04 17:40:23,712 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 32 (UnionRDD[35] at union at PaidPromotionAdjustParameter.scala:154), which has no missing parents
2021-12-04 17:40:23,721 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_21 stored as values in memory (estimated size 182.3 KB, free 1990.3 MB)
2021-12-04 17:40:23,723 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_21_piece0 stored as bytes in memory (estimated size 64.2 KB, free 1990.2 MB)
2021-12-04 17:40:23,724 [dispatcher-event-loop-7] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_21_piece0 in memory on qb:51947 (size: 64.2 KB, free: 1990.7 MB)
2021-12-04 17:40:23,724 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 21 from broadcast at DAGScheduler.scala:1039
2021-12-04 17:40:23,724 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 4 missing tasks from ResultStage 32 (UnionRDD[35] at union at PaidPromotionAdjustParameter.scala:154) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
2021-12-04 17:40:23,724 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 32.0 with 4 tasks
2021-12-04 17:40:23,726 [dispatcher-event-loop-10] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 32.0 (TID 40, localhost, executor driver, partition 0, ANY, 8005 bytes)
2021-12-04 17:40:23,726 [dispatcher-event-loop-10] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 32.0 (TID 41, localhost, executor driver, partition 1, ANY, 8005 bytes)
2021-12-04 17:40:23,726 [dispatcher-event-loop-10] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 2.0 in stage 32.0 (TID 42, localhost, executor driver, partition 2, ANY, 8005 bytes)
2021-12-04 17:40:23,726 [dispatcher-event-loop-10] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 3.0 in stage 32.0 (TID 43, localhost, executor driver, partition 3, ANY, 8005 bytes)
2021-12-04 17:40:23,726 [Executor task launch worker for task 41] INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 32.0 (TID 41)
2021-12-04 17:40:23,726 [Executor task launch worker for task 40] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 32.0 (TID 40)
2021-12-04 17:40:23,726 [Executor task launch worker for task 43] INFO [org.apache.spark.executor.Executor] - Running task 3.0 in stage 32.0 (TID 43)
2021-12-04 17:40:23,726 [Executor task launch worker for task 42] INFO [org.apache.spark.executor.Executor] - Running task 2.0 in stage 32.0 (TID 42)
2021-12-04 17:40:23,733 [Executor task launch worker for task 43] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/order_data.bcp:3442194+3442195
2021-12-04 17:40:23,733 [Executor task launch worker for task 40] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/order_data.bcp:0+3442194
2021-12-04 17:40:23,733 [Executor task launch worker for task 42] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/order_data.bcp:0+3442194
2021-12-04 17:40:23,733 [Executor task launch worker for task 41] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/order_data.bcp:3442194+3442195
2021-12-04 17:40:24,283 [Executor task launch worker for task 42] INFO [org.apache.spark.executor.Executor] - Finished task 2.0 in stage 32.0 (TID 42). 754 bytes result sent to driver
2021-12-04 17:40:24,283 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 2.0 in stage 32.0 (TID 42) in 557 ms on localhost (executor driver) (1/4)
2021-12-04 17:40:24,629 [Executor task launch worker for task 43] INFO [org.apache.spark.executor.Executor] - Finished task 3.0 in stage 32.0 (TID 43). 754 bytes result sent to driver
2021-12-04 17:40:24,629 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 3.0 in stage 32.0 (TID 43) in 903 ms on localhost (executor driver) (2/4)
2021-12-04 17:40:24,773 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 499
2021-12-04 17:40:24,773 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 454
2021-12-04 17:40:24,773 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 485
2021-12-04 17:40:24,773 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 468
2021-12-04 17:40:24,773 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 484
2021-12-04 17:40:24,773 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 472
2021-12-04 17:40:24,773 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 475
2021-12-04 17:40:24,773 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 496
2021-12-04 17:40:24,773 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 494
2021-12-04 17:40:24,773 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 458
2021-12-04 17:40:24,773 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 470
2021-12-04 17:40:24,773 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 467
2021-12-04 17:40:24,773 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 452
2021-12-04 17:40:24,773 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 486
2021-12-04 17:40:24,773 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 450
2021-12-04 17:40:24,773 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 476
2021-12-04 17:40:24,773 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 466
2021-12-04 17:40:24,773 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 465
2021-12-04 17:40:24,773 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 459
2021-12-04 17:40:24,773 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 480
2021-12-04 17:40:24,773 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 473
2021-12-04 17:40:24,773 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 455
2021-12-04 17:40:24,773 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 492
2021-12-04 17:40:24,773 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 474
2021-12-04 17:40:24,773 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 461
2021-12-04 17:40:24,773 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 488
2021-12-04 17:40:24,773 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 491
2021-12-04 17:40:24,773 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 469
2021-12-04 17:40:24,773 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 457
2021-12-04 17:40:24,773 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 497
2021-12-04 17:40:24,773 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 482
2021-12-04 17:40:24,773 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 478
2021-12-04 17:40:24,773 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 479
2021-12-04 17:40:24,773 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 460
2021-12-04 17:40:24,773 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 471
2021-12-04 17:40:24,774 [dispatcher-event-loop-3] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_19_piece0 on qb:51947 in memory (size: 2.2 KB, free: 1990.7 MB)
2021-12-04 17:40:24,774 [dispatcher-event-loop-10] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_20_piece0 on qb:51947 in memory (size: 2.2 KB, free: 1990.7 MB)
2021-12-04 17:40:24,775 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 483
2021-12-04 17:40:24,775 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 487
2021-12-04 17:40:24,775 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 463
2021-12-04 17:40:24,775 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 462
2021-12-04 17:40:24,775 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 489
2021-12-04 17:40:24,775 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 495
2021-12-04 17:40:24,775 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 451
2021-12-04 17:40:24,775 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 453
2021-12-04 17:40:24,775 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 481
2021-12-04 17:40:24,775 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 477
2021-12-04 17:40:24,775 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 490
2021-12-04 17:40:24,775 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 456
2021-12-04 17:40:24,775 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 493
2021-12-04 17:40:24,775 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 464
2021-12-04 17:40:24,775 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 498
2021-12-04 17:40:25,173 [Executor task launch worker for task 41] INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 32.0 (TID 41). 797 bytes result sent to driver
2021-12-04 17:40:25,174 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 32.0 (TID 41) in 1448 ms on localhost (executor driver) (3/4)
2021-12-04 17:40:25,283 [Executor task launch worker for task 40] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 32.0 (TID 40). 797 bytes result sent to driver
2021-12-04 17:40:25,284 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 32.0 (TID 40) in 1559 ms on localhost (executor driver) (4/4)
2021-12-04 17:40:25,284 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 32.0, whose tasks have all completed, from pool 
2021-12-04 17:40:25,284 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 32 (count at PaidPromotionAdjustParameter.scala:156) finished in 1.571 s
2021-12-04 17:40:25,284 [main] INFO [org.apache.spark.scheduler.DAGScheduler] - Job 12 finished: count at PaidPromotionAdjustParameter.scala:156, took 1.573702 s
2021-12-04 17:40:25,285 [main] INFO [PaidPromotion$] - 最终训练集数量：100979
2021-12-04 17:40:25,286 [main] INFO [org.apache.spark.SparkContext] - Starting job: count at PaidPromotionAdjustParameter.scala:157
2021-12-04 17:40:25,287 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 13 (count at PaidPromotionAdjustParameter.scala:157) with 2 output partitions
2021-12-04 17:40:25,287 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 33 (count at PaidPromotionAdjustParameter.scala:157)
2021-12-04 17:40:25,287 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List()
2021-12-04 17:40:25,287 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2021-12-04 17:40:25,287 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 33 (MapPartitionsRDD[33] at filter at PaidPromotionAdjustParameter.scala:150), which has no missing parents
2021-12-04 17:40:25,288 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_22 stored as values in memory (estimated size 181.8 KB, free 1990.0 MB)
2021-12-04 17:40:25,290 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_22_piece0 stored as bytes in memory (estimated size 63.9 KB, free 1990.0 MB)
2021-12-04 17:40:25,291 [dispatcher-event-loop-2] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_22_piece0 in memory on qb:51947 (size: 63.9 KB, free: 1990.6 MB)
2021-12-04 17:40:25,291 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 22 from broadcast at DAGScheduler.scala:1039
2021-12-04 17:40:25,292 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from ResultStage 33 (MapPartitionsRDD[33] at filter at PaidPromotionAdjustParameter.scala:150) (first 15 tasks are for partitions Vector(0, 1))
2021-12-04 17:40:25,292 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 33.0 with 2 tasks
2021-12-04 17:40:25,292 [dispatcher-event-loop-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 33.0 (TID 44, localhost, executor driver, partition 0, ANY, 7896 bytes)
2021-12-04 17:40:25,292 [dispatcher-event-loop-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 33.0 (TID 45, localhost, executor driver, partition 1, ANY, 7896 bytes)
2021-12-04 17:40:25,293 [Executor task launch worker for task 45] INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 33.0 (TID 45)
2021-12-04 17:40:25,293 [Executor task launch worker for task 44] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 33.0 (TID 44)
2021-12-04 17:40:25,295 [Executor task launch worker for task 44] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/order_data.bcp:0+3442194
2021-12-04 17:40:25,295 [Executor task launch worker for task 45] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/order_data.bcp:3442194+3442195
2021-12-04 17:40:26,397 [Executor task launch worker for task 45] INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 33.0 (TID 45). 753 bytes result sent to driver
2021-12-04 17:40:26,397 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 33.0 (TID 45) in 1105 ms on localhost (executor driver) (1/2)
2021-12-04 17:40:26,540 [Executor task launch worker for task 44] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 33.0 (TID 44). 753 bytes result sent to driver
2021-12-04 17:40:26,540 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 33.0 (TID 44) in 1248 ms on localhost (executor driver) (2/2)
2021-12-04 17:40:26,540 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 33.0, whose tasks have all completed, from pool 
2021-12-04 17:40:26,540 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 33 (count at PaidPromotionAdjustParameter.scala:157) finished in 1.253 s
2021-12-04 17:40:26,540 [main] INFO [org.apache.spark.scheduler.DAGScheduler] - Job 13 finished: count at PaidPromotionAdjustParameter.scala:157, took 1.254577 s
2021-12-04 17:40:26,541 [main] INFO [PaidPromotion$] - 最终验证集数量：6315
2021-12-04 17:40:26,572 [main] INFO [PaidPromotion$] - -----------------------------------
2021-12-04 17:40:26,573 [main] INFO [org.apache.spark.SparkContext] - Starting job: count at PaidPromotionAdjustParameter.scala:169
2021-12-04 17:40:26,574 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 37 (distinct at PaidPromotionAdjustParameter.scala:160)
2021-12-04 17:40:26,574 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 14 (count at PaidPromotionAdjustParameter.scala:169) with 4 output partitions
2021-12-04 17:40:26,574 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 35 (count at PaidPromotionAdjustParameter.scala:169)
2021-12-04 17:40:26,574 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 34)
2021-12-04 17:40:26,574 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List(ShuffleMapStage 34)
2021-12-04 17:40:26,574 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ShuffleMapStage 34 (MapPartitionsRDD[37] at distinct at PaidPromotionAdjustParameter.scala:160), which has no missing parents
2021-12-04 17:40:26,576 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_23 stored as values in memory (estimated size 183.9 KB, free 1989.8 MB)
2021-12-04 17:40:26,578 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_23_piece0 stored as bytes in memory (estimated size 65.1 KB, free 1989.7 MB)
2021-12-04 17:40:26,579 [dispatcher-event-loop-3] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_23_piece0 in memory on qb:51947 (size: 65.1 KB, free: 1990.6 MB)
2021-12-04 17:40:26,579 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 23 from broadcast at DAGScheduler.scala:1039
2021-12-04 17:40:26,579 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 4 missing tasks from ShuffleMapStage 34 (MapPartitionsRDD[37] at distinct at PaidPromotionAdjustParameter.scala:160) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
2021-12-04 17:40:26,579 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 34.0 with 4 tasks
2021-12-04 17:40:26,580 [dispatcher-event-loop-7] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 34.0 (TID 46, localhost, executor driver, partition 0, ANY, 7994 bytes)
2021-12-04 17:40:26,580 [dispatcher-event-loop-7] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 34.0 (TID 47, localhost, executor driver, partition 1, ANY, 7994 bytes)
2021-12-04 17:40:26,580 [dispatcher-event-loop-7] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 2.0 in stage 34.0 (TID 48, localhost, executor driver, partition 2, ANY, 7994 bytes)
2021-12-04 17:40:26,580 [dispatcher-event-loop-7] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 3.0 in stage 34.0 (TID 49, localhost, executor driver, partition 3, ANY, 7994 bytes)
2021-12-04 17:40:26,580 [Executor task launch worker for task 46] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 34.0 (TID 46)
2021-12-04 17:40:26,580 [Executor task launch worker for task 48] INFO [org.apache.spark.executor.Executor] - Running task 2.0 in stage 34.0 (TID 48)
2021-12-04 17:40:26,580 [Executor task launch worker for task 47] INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 34.0 (TID 47)
2021-12-04 17:40:26,580 [Executor task launch worker for task 49] INFO [org.apache.spark.executor.Executor] - Running task 3.0 in stage 34.0 (TID 49)
2021-12-04 17:40:26,582 [Executor task launch worker for task 46] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/order_data.bcp:0+3442194
2021-12-04 17:40:26,582 [Executor task launch worker for task 48] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/order_data.bcp:0+3442194
2021-12-04 17:40:26,583 [Executor task launch worker for task 47] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/order_data.bcp:3442194+3442195
2021-12-04 17:40:26,583 [Executor task launch worker for task 49] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/order_data.bcp:3442194+3442195
2021-12-04 17:40:26,834 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 528
2021-12-04 17:40:26,834 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 535
2021-12-04 17:40:26,835 [dispatcher-event-loop-11] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_22_piece0 on qb:51947 in memory (size: 63.9 KB, free: 1990.6 MB)
2021-12-04 17:40:26,835 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 503
2021-12-04 17:40:26,836 [dispatcher-event-loop-4] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_21_piece0 on qb:51947 in memory (size: 64.2 KB, free: 1990.7 MB)
2021-12-04 17:40:26,836 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 501
2021-12-04 17:40:26,836 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 500
2021-12-04 17:40:26,836 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 508
2021-12-04 17:40:26,836 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 546
2021-12-04 17:40:26,836 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 527
2021-12-04 17:40:26,836 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 509
2021-12-04 17:40:26,836 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 507
2021-12-04 17:40:26,836 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 502
2021-12-04 17:40:26,836 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 533
2021-12-04 17:40:26,836 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 541
2021-12-04 17:40:26,836 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 523
2021-12-04 17:40:26,836 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 544
2021-12-04 17:40:26,836 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 517
2021-12-04 17:40:26,836 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 513
2021-12-04 17:40:26,836 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 532
2021-12-04 17:40:26,836 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 506
2021-12-04 17:40:26,836 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 518
2021-12-04 17:40:26,836 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 524
2021-12-04 17:40:26,836 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 525
2021-12-04 17:40:26,836 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 526
2021-12-04 17:40:26,836 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 514
2021-12-04 17:40:26,836 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 516
2021-12-04 17:40:26,836 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 538
2021-12-04 17:40:26,836 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 540
2021-12-04 17:40:26,836 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 548
2021-12-04 17:40:26,836 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 537
2021-12-04 17:40:26,836 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 539
2021-12-04 17:40:26,836 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 531
2021-12-04 17:40:26,836 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 545
2021-12-04 17:40:26,836 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 547
2021-12-04 17:40:26,836 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 515
2021-12-04 17:40:26,836 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 519
2021-12-04 17:40:26,836 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 512
2021-12-04 17:40:26,836 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 534
2021-12-04 17:40:26,836 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 511
2021-12-04 17:40:26,837 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 536
2021-12-04 17:40:26,837 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 542
2021-12-04 17:40:26,837 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 520
2021-12-04 17:40:26,837 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 510
2021-12-04 17:40:26,837 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 530
2021-12-04 17:40:26,837 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 549
2021-12-04 17:40:26,837 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 529
2021-12-04 17:40:26,837 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 505
2021-12-04 17:40:26,837 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 522
2021-12-04 17:40:26,837 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 543
2021-12-04 17:40:26,837 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 504
2021-12-04 17:40:26,837 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 521
2021-12-04 17:40:27,441 [Executor task launch worker for task 48] INFO [org.apache.spark.executor.Executor] - Finished task 2.0 in stage 34.0 (TID 48). 1034 bytes result sent to driver
2021-12-04 17:40:27,442 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 2.0 in stage 34.0 (TID 48) in 862 ms on localhost (executor driver) (1/4)
2021-12-04 17:40:27,608 [Executor task launch worker for task 47] INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 34.0 (TID 47). 1034 bytes result sent to driver
2021-12-04 17:40:27,608 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 34.0 (TID 47) in 1028 ms on localhost (executor driver) (2/4)
2021-12-04 17:40:27,830 [Executor task launch worker for task 49] INFO [org.apache.spark.executor.Executor] - Finished task 3.0 in stage 34.0 (TID 49). 1034 bytes result sent to driver
2021-12-04 17:40:27,831 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 3.0 in stage 34.0 (TID 49) in 1251 ms on localhost (executor driver) (3/4)
2021-12-04 17:40:28,086 [Executor task launch worker for task 46] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 34.0 (TID 46). 1034 bytes result sent to driver
2021-12-04 17:40:28,086 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 34.0 (TID 46) in 1507 ms on localhost (executor driver) (4/4)
2021-12-04 17:40:28,086 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 34.0, whose tasks have all completed, from pool 
2021-12-04 17:40:28,086 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ShuffleMapStage 34 (distinct at PaidPromotionAdjustParameter.scala:160) finished in 1.511 s
2021-12-04 17:40:28,086 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - looking for newly runnable stages
2021-12-04 17:40:28,086 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - running: Set()
2021-12-04 17:40:28,086 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - waiting: Set(ResultStage 35)
2021-12-04 17:40:28,086 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - failed: Set()
2021-12-04 17:40:28,087 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 35 (MapPartitionsRDD[39] at distinct at PaidPromotionAdjustParameter.scala:160), which has no missing parents
2021-12-04 17:40:28,087 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_24 stored as values in memory (estimated size 3.7 KB, free 1990.2 MB)
2021-12-04 17:40:28,089 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_24_piece0 stored as bytes in memory (estimated size 2.2 KB, free 1990.2 MB)
2021-12-04 17:40:28,089 [dispatcher-event-loop-9] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_24_piece0 in memory on qb:51947 (size: 2.2 KB, free: 1990.7 MB)
2021-12-04 17:40:28,089 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 24 from broadcast at DAGScheduler.scala:1039
2021-12-04 17:40:28,089 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 4 missing tasks from ResultStage 35 (MapPartitionsRDD[39] at distinct at PaidPromotionAdjustParameter.scala:160) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
2021-12-04 17:40:28,089 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 35.0 with 4 tasks
2021-12-04 17:40:28,090 [dispatcher-event-loop-8] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 35.0 (TID 50, localhost, executor driver, partition 0, ANY, 7649 bytes)
2021-12-04 17:40:28,090 [dispatcher-event-loop-8] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 35.0 (TID 51, localhost, executor driver, partition 1, ANY, 7649 bytes)
2021-12-04 17:40:28,090 [dispatcher-event-loop-8] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 2.0 in stage 35.0 (TID 52, localhost, executor driver, partition 2, ANY, 7649 bytes)
2021-12-04 17:40:28,090 [dispatcher-event-loop-8] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 3.0 in stage 35.0 (TID 53, localhost, executor driver, partition 3, ANY, 7649 bytes)
2021-12-04 17:40:28,090 [Executor task launch worker for task 50] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 35.0 (TID 50)
2021-12-04 17:40:28,090 [Executor task launch worker for task 51] INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 35.0 (TID 51)
2021-12-04 17:40:28,090 [Executor task launch worker for task 53] INFO [org.apache.spark.executor.Executor] - Running task 3.0 in stage 35.0 (TID 53)
2021-12-04 17:40:28,090 [Executor task launch worker for task 52] INFO [org.apache.spark.executor.Executor] - Running task 2.0 in stage 35.0 (TID 52)
2021-12-04 17:40:28,091 [Executor task launch worker for task 51] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 4 non-empty blocks out of 4 blocks
2021-12-04 17:40:28,091 [Executor task launch worker for task 50] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 4 non-empty blocks out of 4 blocks
2021-12-04 17:40:28,091 [Executor task launch worker for task 51] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-04 17:40:28,091 [Executor task launch worker for task 50] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-04 17:40:28,091 [Executor task launch worker for task 53] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 4 non-empty blocks out of 4 blocks
2021-12-04 17:40:28,091 [Executor task launch worker for task 53] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-04 17:40:28,091 [Executor task launch worker for task 52] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 4 non-empty blocks out of 4 blocks
2021-12-04 17:40:28,091 [Executor task launch worker for task 52] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-04 17:40:28,136 [Executor task launch worker for task 50] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 35.0 (TID 50). 1012 bytes result sent to driver
2021-12-04 17:40:28,136 [Executor task launch worker for task 52] INFO [org.apache.spark.executor.Executor] - Finished task 2.0 in stage 35.0 (TID 52). 1012 bytes result sent to driver
2021-12-04 17:40:28,136 [Executor task launch worker for task 53] INFO [org.apache.spark.executor.Executor] - Finished task 3.0 in stage 35.0 (TID 53). 1012 bytes result sent to driver
2021-12-04 17:40:28,137 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 35.0 (TID 50) in 47 ms on localhost (executor driver) (1/4)
2021-12-04 17:40:28,137 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 2.0 in stage 35.0 (TID 52) in 47 ms on localhost (executor driver) (2/4)
2021-12-04 17:40:28,137 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 3.0 in stage 35.0 (TID 53) in 47 ms on localhost (executor driver) (3/4)
2021-12-04 17:40:28,139 [Executor task launch worker for task 51] INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 35.0 (TID 51). 1012 bytes result sent to driver
2021-12-04 17:40:28,139 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 35.0 (TID 51) in 49 ms on localhost (executor driver) (4/4)
2021-12-04 17:40:28,139 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 35.0, whose tasks have all completed, from pool 
2021-12-04 17:40:28,139 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 35 (count at PaidPromotionAdjustParameter.scala:169) finished in 0.052 s
2021-12-04 17:40:28,139 [main] INFO [org.apache.spark.scheduler.DAGScheduler] - Job 14 finished: count at PaidPromotionAdjustParameter.scala:169, took 1.566065 s
2021-12-04 17:40:28,140 [main] INFO [PaidPromotion$] - 最终训练集用户数 = 95323
2021-12-04 17:40:28,142 [main] INFO [org.apache.spark.SparkContext] - Starting job: count at PaidPromotionAdjustParameter.scala:170
2021-12-04 17:40:28,142 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 41 (distinct at PaidPromotionAdjustParameter.scala:161)
2021-12-04 17:40:28,142 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 15 (count at PaidPromotionAdjustParameter.scala:170) with 2 output partitions
2021-12-04 17:40:28,142 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 37 (count at PaidPromotionAdjustParameter.scala:170)
2021-12-04 17:40:28,142 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 36)
2021-12-04 17:40:28,143 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List(ShuffleMapStage 36)
2021-12-04 17:40:28,143 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ShuffleMapStage 36 (MapPartitionsRDD[41] at distinct at PaidPromotionAdjustParameter.scala:161), which has no missing parents
2021-12-04 17:40:28,144 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_25 stored as values in memory (estimated size 183.3 KB, free 1990.0 MB)
2021-12-04 17:40:28,147 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_25_piece0 stored as bytes in memory (estimated size 64.8 KB, free 1990.0 MB)
2021-12-04 17:40:28,147 [dispatcher-event-loop-6] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_25_piece0 in memory on qb:51947 (size: 64.8 KB, free: 1990.6 MB)
2021-12-04 17:40:28,148 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 25 from broadcast at DAGScheduler.scala:1039
2021-12-04 17:40:28,148 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from ShuffleMapStage 36 (MapPartitionsRDD[41] at distinct at PaidPromotionAdjustParameter.scala:161) (first 15 tasks are for partitions Vector(0, 1))
2021-12-04 17:40:28,148 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 36.0 with 2 tasks
2021-12-04 17:40:28,148 [dispatcher-event-loop-10] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 36.0 (TID 54, localhost, executor driver, partition 0, ANY, 7885 bytes)
2021-12-04 17:40:28,148 [dispatcher-event-loop-10] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 36.0 (TID 55, localhost, executor driver, partition 1, ANY, 7885 bytes)
2021-12-04 17:40:28,148 [Executor task launch worker for task 55] INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 36.0 (TID 55)
2021-12-04 17:40:28,148 [Executor task launch worker for task 54] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 36.0 (TID 54)
2021-12-04 17:40:28,153 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 560
2021-12-04 17:40:28,153 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 598
2021-12-04 17:40:28,153 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 555
2021-12-04 17:40:28,153 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 578
2021-12-04 17:40:28,153 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 586
2021-12-04 17:40:28,153 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 590
2021-12-04 17:40:28,153 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 564
2021-12-04 17:40:28,153 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 591
2021-12-04 17:40:28,153 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 556
2021-12-04 17:40:28,153 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 568
2021-12-04 17:40:28,153 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 577
2021-12-04 17:40:28,153 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 579
2021-12-04 17:40:28,154 [Executor task launch worker for task 55] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/order_data.bcp:3442194+3442195
2021-12-04 17:40:28,154 [Executor task launch worker for task 54] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/order_data.bcp:0+3442194
2021-12-04 17:40:28,154 [dispatcher-event-loop-11] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_24_piece0 on qb:51947 in memory (size: 2.2 KB, free: 1990.6 MB)
2021-12-04 17:40:28,154 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 569
2021-12-04 17:40:28,154 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 573
2021-12-04 17:40:28,154 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 559
2021-12-04 17:40:28,154 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 583
2021-12-04 17:40:28,154 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 596
2021-12-04 17:40:28,154 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 563
2021-12-04 17:40:28,155 [dispatcher-event-loop-3] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_23_piece0 on qb:51947 in memory (size: 65.1 KB, free: 1990.7 MB)
2021-12-04 17:40:28,155 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 593
2021-12-04 17:40:28,155 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 551
2021-12-04 17:40:28,155 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 594
2021-12-04 17:40:28,155 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 557
2021-12-04 17:40:28,155 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 566
2021-12-04 17:40:28,155 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 589
2021-12-04 17:40:28,155 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 561
2021-12-04 17:40:28,155 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 592
2021-12-04 17:40:28,155 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 558
2021-12-04 17:40:28,155 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 597
2021-12-04 17:40:28,155 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 572
2021-12-04 17:40:28,155 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 574
2021-12-04 17:40:28,155 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 581
2021-12-04 17:40:28,155 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 584
2021-12-04 17:40:28,155 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 585
2021-12-04 17:40:28,155 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 552
2021-12-04 17:40:28,155 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 562
2021-12-04 17:40:28,155 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 588
2021-12-04 17:40:28,155 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 580
2021-12-04 17:40:28,155 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 576
2021-12-04 17:40:28,155 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 587
2021-12-04 17:40:28,155 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 567
2021-12-04 17:40:28,155 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 553
2021-12-04 17:40:28,155 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 565
2021-12-04 17:40:28,155 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 554
2021-12-04 17:40:28,155 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 570
2021-12-04 17:40:28,155 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 599
2021-12-04 17:40:28,155 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 595
2021-12-04 17:40:28,155 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 550
2021-12-04 17:40:28,155 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 582
2021-12-04 17:40:28,155 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 575
2021-12-04 17:40:28,155 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 571
2021-12-04 17:40:29,249 [Executor task launch worker for task 54] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 36.0 (TID 54). 1075 bytes result sent to driver
2021-12-04 17:40:29,249 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 36.0 (TID 54) in 1101 ms on localhost (executor driver) (1/2)
2021-12-04 17:40:29,263 [Executor task launch worker for task 55] INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 36.0 (TID 55). 1075 bytes result sent to driver
2021-12-04 17:40:29,263 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 36.0 (TID 55) in 1115 ms on localhost (executor driver) (2/2)
2021-12-04 17:40:29,263 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 36.0, whose tasks have all completed, from pool 
2021-12-04 17:40:29,263 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ShuffleMapStage 36 (distinct at PaidPromotionAdjustParameter.scala:161) finished in 1.120 s
2021-12-04 17:40:29,263 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - looking for newly runnable stages
2021-12-04 17:40:29,263 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - running: Set()
2021-12-04 17:40:29,263 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - waiting: Set(ResultStage 37)
2021-12-04 17:40:29,263 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - failed: Set()
2021-12-04 17:40:29,263 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 37 (MapPartitionsRDD[43] at distinct at PaidPromotionAdjustParameter.scala:161), which has no missing parents
2021-12-04 17:40:29,264 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_26 stored as values in memory (estimated size 3.7 KB, free 1990.2 MB)
2021-12-04 17:40:29,265 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_26_piece0 stored as bytes in memory (estimated size 2.2 KB, free 1990.2 MB)
2021-12-04 17:40:29,266 [dispatcher-event-loop-6] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_26_piece0 in memory on qb:51947 (size: 2.2 KB, free: 1990.7 MB)
2021-12-04 17:40:29,266 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 26 from broadcast at DAGScheduler.scala:1039
2021-12-04 17:40:29,266 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from ResultStage 37 (MapPartitionsRDD[43] at distinct at PaidPromotionAdjustParameter.scala:161) (first 15 tasks are for partitions Vector(0, 1))
2021-12-04 17:40:29,266 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 37.0 with 2 tasks
2021-12-04 17:40:29,266 [dispatcher-event-loop-10] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 37.0 (TID 56, localhost, executor driver, partition 0, ANY, 7649 bytes)
2021-12-04 17:40:29,266 [dispatcher-event-loop-10] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 37.0 (TID 57, localhost, executor driver, partition 1, ANY, 7649 bytes)
2021-12-04 17:40:29,267 [Executor task launch worker for task 56] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 37.0 (TID 56)
2021-12-04 17:40:29,267 [Executor task launch worker for task 57] INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 37.0 (TID 57)
2021-12-04 17:40:29,268 [Executor task launch worker for task 57] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 2 non-empty blocks out of 2 blocks
2021-12-04 17:40:29,268 [Executor task launch worker for task 56] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 2 non-empty blocks out of 2 blocks
2021-12-04 17:40:29,268 [Executor task launch worker for task 56] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-04 17:40:29,268 [Executor task launch worker for task 57] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 1 ms
2021-12-04 17:40:29,284 [Executor task launch worker for task 56] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 37.0 (TID 56). 968 bytes result sent to driver
2021-12-04 17:40:29,284 [Executor task launch worker for task 57] INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 37.0 (TID 57). 968 bytes result sent to driver
2021-12-04 17:40:29,284 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 37.0 (TID 56) in 18 ms on localhost (executor driver) (1/2)
2021-12-04 17:40:29,284 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 37.0 (TID 57) in 18 ms on localhost (executor driver) (2/2)
2021-12-04 17:40:29,284 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 37.0, whose tasks have all completed, from pool 
2021-12-04 17:40:29,284 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 37 (count at PaidPromotionAdjustParameter.scala:170) finished in 0.020 s
2021-12-04 17:40:29,284 [main] INFO [org.apache.spark.scheduler.DAGScheduler] - Job 15 finished: count at PaidPromotionAdjustParameter.scala:170, took 1.142284 s
2021-12-04 17:40:29,285 [main] INFO [PaidPromotion$] - 最终验证集用户数 = 5104
2021-12-04 17:40:29,287 [main] INFO [org.apache.spark.SparkContext] - Starting job: count at PaidPromotionAdjustParameter.scala:171
2021-12-04 17:40:29,287 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 45 (intersection at PaidPromotionAdjustParameter.scala:162)
2021-12-04 17:40:29,287 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 44 (intersection at PaidPromotionAdjustParameter.scala:162)
2021-12-04 17:40:29,287 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 16 (count at PaidPromotionAdjustParameter.scala:171) with 4 output partitions
2021-12-04 17:40:29,287 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 42 (count at PaidPromotionAdjustParameter.scala:171)
2021-12-04 17:40:29,287 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 39, ShuffleMapStage 41)
2021-12-04 17:40:29,287 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List(ShuffleMapStage 39, ShuffleMapStage 41)
2021-12-04 17:40:29,288 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ShuffleMapStage 39 (MapPartitionsRDD[45] at intersection at PaidPromotionAdjustParameter.scala:162), which has no missing parents
2021-12-04 17:40:29,288 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_27 stored as values in memory (estimated size 4.0 KB, free 1990.2 MB)
2021-12-04 17:40:29,289 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_27_piece0 stored as bytes in memory (estimated size 2.3 KB, free 1990.2 MB)
2021-12-04 17:40:29,290 [dispatcher-event-loop-11] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_27_piece0 in memory on qb:51947 (size: 2.3 KB, free: 1990.7 MB)
2021-12-04 17:40:29,290 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 27 from broadcast at DAGScheduler.scala:1039
2021-12-04 17:40:29,290 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from ShuffleMapStage 39 (MapPartitionsRDD[45] at intersection at PaidPromotionAdjustParameter.scala:162) (first 15 tasks are for partitions Vector(0, 1))
2021-12-04 17:40:29,290 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 39.0 with 2 tasks
2021-12-04 17:40:29,290 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ShuffleMapStage 41 (MapPartitionsRDD[44] at intersection at PaidPromotionAdjustParameter.scala:162), which has no missing parents
2021-12-04 17:40:29,290 [dispatcher-event-loop-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 39.0 (TID 58, localhost, executor driver, partition 0, ANY, 7638 bytes)
2021-12-04 17:40:29,291 [dispatcher-event-loop-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 39.0 (TID 59, localhost, executor driver, partition 1, ANY, 7638 bytes)
2021-12-04 17:40:29,291 [Executor task launch worker for task 59] INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 39.0 (TID 59)
2021-12-04 17:40:29,291 [Executor task launch worker for task 58] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 39.0 (TID 58)
2021-12-04 17:40:29,291 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_28 stored as values in memory (estimated size 4.0 KB, free 1990.2 MB)
2021-12-04 17:40:29,291 [Executor task launch worker for task 59] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 2 non-empty blocks out of 2 blocks
2021-12-04 17:40:29,291 [Executor task launch worker for task 58] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 2 non-empty blocks out of 2 blocks
2021-12-04 17:40:29,292 [Executor task launch worker for task 59] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 1 ms
2021-12-04 17:40:29,292 [Executor task launch worker for task 58] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 1 ms
2021-12-04 17:40:29,292 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_28_piece0 stored as bytes in memory (estimated size 2.3 KB, free 1990.2 MB)
2021-12-04 17:40:29,293 [dispatcher-event-loop-5] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_28_piece0 in memory on qb:51947 (size: 2.3 KB, free: 1990.7 MB)
2021-12-04 17:40:29,293 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 28 from broadcast at DAGScheduler.scala:1039
2021-12-04 17:40:29,293 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 4 missing tasks from ShuffleMapStage 41 (MapPartitionsRDD[44] at intersection at PaidPromotionAdjustParameter.scala:162) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
2021-12-04 17:40:29,293 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 41.0 with 4 tasks
2021-12-04 17:40:29,294 [dispatcher-event-loop-7] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 41.0 (TID 60, localhost, executor driver, partition 0, ANY, 7638 bytes)
2021-12-04 17:40:29,294 [dispatcher-event-loop-7] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 41.0 (TID 61, localhost, executor driver, partition 1, ANY, 7638 bytes)
2021-12-04 17:40:29,294 [dispatcher-event-loop-7] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 2.0 in stage 41.0 (TID 62, localhost, executor driver, partition 2, ANY, 7638 bytes)
2021-12-04 17:40:29,294 [dispatcher-event-loop-7] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 3.0 in stage 41.0 (TID 63, localhost, executor driver, partition 3, ANY, 7638 bytes)
2021-12-04 17:40:29,294 [Executor task launch worker for task 61] INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 41.0 (TID 61)
2021-12-04 17:40:29,294 [Executor task launch worker for task 60] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 41.0 (TID 60)
2021-12-04 17:40:29,295 [Executor task launch worker for task 62] INFO [org.apache.spark.executor.Executor] - Running task 2.0 in stage 41.0 (TID 62)
2021-12-04 17:40:29,295 [Executor task launch worker for task 63] INFO [org.apache.spark.executor.Executor] - Running task 3.0 in stage 41.0 (TID 63)
2021-12-04 17:40:29,295 [Executor task launch worker for task 63] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 4 non-empty blocks out of 4 blocks
2021-12-04 17:40:29,295 [Executor task launch worker for task 60] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 4 non-empty blocks out of 4 blocks
2021-12-04 17:40:29,295 [Executor task launch worker for task 63] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-04 17:40:29,295 [Executor task launch worker for task 60] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-04 17:40:29,296 [Executor task launch worker for task 62] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 4 non-empty blocks out of 4 blocks
2021-12-04 17:40:29,296 [Executor task launch worker for task 61] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 4 non-empty blocks out of 4 blocks
2021-12-04 17:40:29,296 [Executor task launch worker for task 61] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-04 17:40:29,296 [Executor task launch worker for task 62] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 1 ms
2021-12-04 17:40:29,323 [Executor task launch worker for task 58] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 39.0 (TID 58). 1206 bytes result sent to driver
2021-12-04 17:40:29,323 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 39.0 (TID 58) in 33 ms on localhost (executor driver) (1/2)
2021-12-04 17:40:29,323 [Executor task launch worker for task 59] INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 39.0 (TID 59). 1163 bytes result sent to driver
2021-12-04 17:40:29,323 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 39.0 (TID 59) in 33 ms on localhost (executor driver) (2/2)
2021-12-04 17:40:29,324 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 39.0, whose tasks have all completed, from pool 
2021-12-04 17:40:29,324 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ShuffleMapStage 39 (intersection at PaidPromotionAdjustParameter.scala:162) finished in 0.036 s
2021-12-04 17:40:29,324 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - looking for newly runnable stages
2021-12-04 17:40:29,324 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - running: Set(ShuffleMapStage 41)
2021-12-04 17:40:29,324 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - waiting: Set(ResultStage 42)
2021-12-04 17:40:29,324 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - failed: Set()
2021-12-04 17:40:29,349 [Executor task launch worker for task 60] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 41.0 (TID 60). 1163 bytes result sent to driver
2021-12-04 17:40:29,349 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 41.0 (TID 60) in 56 ms on localhost (executor driver) (1/4)
2021-12-04 17:40:29,349 [Executor task launch worker for task 61] INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 41.0 (TID 61). 1163 bytes result sent to driver
2021-12-04 17:40:29,349 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 41.0 (TID 61) in 55 ms on localhost (executor driver) (2/4)
2021-12-04 17:40:29,350 [Executor task launch worker for task 62] INFO [org.apache.spark.executor.Executor] - Finished task 2.0 in stage 41.0 (TID 62). 1163 bytes result sent to driver
2021-12-04 17:40:29,350 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 2.0 in stage 41.0 (TID 62) in 56 ms on localhost (executor driver) (3/4)
2021-12-04 17:40:29,351 [Executor task launch worker for task 63] INFO [org.apache.spark.executor.Executor] - Finished task 3.0 in stage 41.0 (TID 63). 1163 bytes result sent to driver
2021-12-04 17:40:29,351 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 3.0 in stage 41.0 (TID 63) in 57 ms on localhost (executor driver) (4/4)
2021-12-04 17:40:29,351 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 41.0, whose tasks have all completed, from pool 
2021-12-04 17:40:29,351 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ShuffleMapStage 41 (intersection at PaidPromotionAdjustParameter.scala:162) finished in 0.060 s
2021-12-04 17:40:29,351 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - looking for newly runnable stages
2021-12-04 17:40:29,351 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - running: Set()
2021-12-04 17:40:29,351 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - waiting: Set(ResultStage 42)
2021-12-04 17:40:29,351 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - failed: Set()
2021-12-04 17:40:29,352 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 42 (MapPartitionsRDD[49] at intersection at PaidPromotionAdjustParameter.scala:162), which has no missing parents
2021-12-04 17:40:29,352 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_29 stored as values in memory (estimated size 3.6 KB, free 1990.2 MB)
2021-12-04 17:40:29,353 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_29_piece0 stored as bytes in memory (estimated size 2.1 KB, free 1990.2 MB)
2021-12-04 17:40:29,354 [dispatcher-event-loop-5] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_29_piece0 in memory on qb:51947 (size: 2.1 KB, free: 1990.7 MB)
2021-12-04 17:40:29,354 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 29 from broadcast at DAGScheduler.scala:1039
2021-12-04 17:40:29,354 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 4 missing tasks from ResultStage 42 (MapPartitionsRDD[49] at intersection at PaidPromotionAdjustParameter.scala:162) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
2021-12-04 17:40:29,354 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 42.0 with 4 tasks
2021-12-04 17:40:29,354 [dispatcher-event-loop-6] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 42.0 (TID 64, localhost, executor driver, partition 0, PROCESS_LOCAL, 7712 bytes)
2021-12-04 17:40:29,354 [dispatcher-event-loop-6] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 42.0 (TID 65, localhost, executor driver, partition 1, PROCESS_LOCAL, 7712 bytes)
2021-12-04 17:40:29,354 [dispatcher-event-loop-6] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 2.0 in stage 42.0 (TID 66, localhost, executor driver, partition 2, PROCESS_LOCAL, 7712 bytes)
2021-12-04 17:40:29,354 [dispatcher-event-loop-6] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 3.0 in stage 42.0 (TID 67, localhost, executor driver, partition 3, PROCESS_LOCAL, 7712 bytes)
2021-12-04 17:40:29,355 [Executor task launch worker for task 65] INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 42.0 (TID 65)
2021-12-04 17:40:29,355 [Executor task launch worker for task 64] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 42.0 (TID 64)
2021-12-04 17:40:29,355 [Executor task launch worker for task 66] INFO [org.apache.spark.executor.Executor] - Running task 2.0 in stage 42.0 (TID 66)
2021-12-04 17:40:29,355 [Executor task launch worker for task 67] INFO [org.apache.spark.executor.Executor] - Running task 3.0 in stage 42.0 (TID 67)
2021-12-04 17:40:29,356 [Executor task launch worker for task 67] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 4 blocks
2021-12-04 17:40:29,356 [Executor task launch worker for task 65] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 4 blocks
2021-12-04 17:40:29,356 [Executor task launch worker for task 67] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-04 17:40:29,356 [Executor task launch worker for task 65] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-04 17:40:29,356 [Executor task launch worker for task 66] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 4 blocks
2021-12-04 17:40:29,356 [Executor task launch worker for task 64] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 4 blocks
2021-12-04 17:40:29,356 [Executor task launch worker for task 66] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-04 17:40:29,356 [Executor task launch worker for task 64] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-04 17:40:29,358 [Executor task launch worker for task 65] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2021-12-04 17:40:29,358 [Executor task launch worker for task 64] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2021-12-04 17:40:29,358 [Executor task launch worker for task 65] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-04 17:40:29,358 [Executor task launch worker for task 64] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-04 17:40:29,358 [Executor task launch worker for task 66] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2021-12-04 17:40:29,358 [Executor task launch worker for task 67] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2021-12-04 17:40:29,358 [Executor task launch worker for task 66] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-04 17:40:29,358 [Executor task launch worker for task 67] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-04 17:40:29,394 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 649
2021-12-04 17:40:29,394 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 612
2021-12-04 17:40:29,394 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 602
2021-12-04 17:40:29,394 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 625
2021-12-04 17:40:29,394 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 614
2021-12-04 17:40:29,394 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 638
2021-12-04 17:40:29,394 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 606
2021-12-04 17:40:29,394 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 611
2021-12-04 17:40:29,394 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 607
2021-12-04 17:40:29,394 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 609
2021-12-04 17:40:29,395 [dispatcher-event-loop-11] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_26_piece0 on qb:51947 in memory (size: 2.2 KB, free: 1990.7 MB)
2021-12-04 17:40:29,395 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 608
2021-12-04 17:40:29,395 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 648
2021-12-04 17:40:29,395 [dispatcher-event-loop-4] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_27_piece0 on qb:51947 in memory (size: 2.3 KB, free: 1990.7 MB)
2021-12-04 17:40:29,396 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 627
2021-12-04 17:40:29,396 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 633
2021-12-04 17:40:29,396 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 619
2021-12-04 17:40:29,396 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 603
2021-12-04 17:40:29,396 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 623
2021-12-04 17:40:29,396 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 629
2021-12-04 17:40:29,396 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 646
2021-12-04 17:40:29,396 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 605
2021-12-04 17:40:29,396 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 601
2021-12-04 17:40:29,396 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 635
2021-12-04 17:40:29,396 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 604
2021-12-04 17:40:29,396 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 616
2021-12-04 17:40:29,396 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 632
2021-12-04 17:40:29,396 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 600
2021-12-04 17:40:29,396 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 628
2021-12-04 17:40:29,396 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 610
2021-12-04 17:40:29,396 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 641
2021-12-04 17:40:29,396 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 615
2021-12-04 17:40:29,396 [dispatcher-event-loop-10] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_25_piece0 on qb:51947 in memory (size: 64.8 KB, free: 1990.8 MB)
2021-12-04 17:40:29,397 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 640
2021-12-04 17:40:29,397 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 636
2021-12-04 17:40:29,397 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 624
2021-12-04 17:40:29,397 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 639
2021-12-04 17:40:29,397 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 617
2021-12-04 17:40:29,397 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 613
2021-12-04 17:40:29,397 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 626
2021-12-04 17:40:29,397 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 643
2021-12-04 17:40:29,397 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 631
2021-12-04 17:40:29,397 [dispatcher-event-loop-9] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_28_piece0 on qb:51947 in memory (size: 2.3 KB, free: 1990.8 MB)
2021-12-04 17:40:29,397 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 637
2021-12-04 17:40:29,397 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 645
2021-12-04 17:40:29,397 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 618
2021-12-04 17:40:29,397 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 634
2021-12-04 17:40:29,397 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 644
2021-12-04 17:40:29,397 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 622
2021-12-04 17:40:29,397 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 630
2021-12-04 17:40:29,397 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 642
2021-12-04 17:40:29,397 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 620
2021-12-04 17:40:29,397 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 621
2021-12-04 17:40:29,398 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 647
2021-12-04 17:40:29,412 [Executor task launch worker for task 64] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 42.0 (TID 64). 1054 bytes result sent to driver
2021-12-04 17:40:29,412 [Executor task launch worker for task 65] INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 42.0 (TID 65). 1054 bytes result sent to driver
2021-12-04 17:40:29,412 [Executor task launch worker for task 66] INFO [org.apache.spark.executor.Executor] - Finished task 2.0 in stage 42.0 (TID 66). 1097 bytes result sent to driver
2021-12-04 17:40:29,412 [Executor task launch worker for task 67] INFO [org.apache.spark.executor.Executor] - Finished task 3.0 in stage 42.0 (TID 67). 1054 bytes result sent to driver
2021-12-04 17:40:29,413 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 42.0 (TID 64) in 59 ms on localhost (executor driver) (1/4)
2021-12-04 17:40:29,413 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 42.0 (TID 65) in 59 ms on localhost (executor driver) (2/4)
2021-12-04 17:40:29,413 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 2.0 in stage 42.0 (TID 66) in 59 ms on localhost (executor driver) (3/4)
2021-12-04 17:40:29,413 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 3.0 in stage 42.0 (TID 67) in 59 ms on localhost (executor driver) (4/4)
2021-12-04 17:40:29,413 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 42.0, whose tasks have all completed, from pool 
2021-12-04 17:40:29,413 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 42 (count at PaidPromotionAdjustParameter.scala:171) finished in 0.061 s
2021-12-04 17:40:29,413 [main] INFO [org.apache.spark.scheduler.DAGScheduler] - Job 16 finished: count at PaidPromotionAdjustParameter.scala:171, took 0.126235 s
2021-12-04 17:40:29,414 [main] INFO [PaidPromotion$] - 最终共 同 用户数 = 5104
2021-12-04 17:40:29,416 [main] INFO [org.apache.spark.SparkContext] - Starting job: count at PaidPromotionAdjustParameter.scala:172
2021-12-04 17:40:29,416 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 51 (distinct at PaidPromotionAdjustParameter.scala:164)
2021-12-04 17:40:29,416 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 17 (count at PaidPromotionAdjustParameter.scala:172) with 4 output partitions
2021-12-04 17:40:29,417 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 44 (count at PaidPromotionAdjustParameter.scala:172)
2021-12-04 17:40:29,417 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 43)
2021-12-04 17:40:29,417 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List(ShuffleMapStage 43)
2021-12-04 17:40:29,417 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ShuffleMapStage 43 (MapPartitionsRDD[51] at distinct at PaidPromotionAdjustParameter.scala:164), which has no missing parents
2021-12-04 17:40:29,419 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_30 stored as values in memory (estimated size 183.9 KB, free 1990.3 MB)
2021-12-04 17:40:29,421 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_30_piece0 stored as bytes in memory (estimated size 65.1 KB, free 1990.2 MB)
2021-12-04 17:40:29,422 [dispatcher-event-loop-0] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_30_piece0 in memory on qb:51947 (size: 65.1 KB, free: 1990.7 MB)
2021-12-04 17:40:29,422 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 30 from broadcast at DAGScheduler.scala:1039
2021-12-04 17:40:29,422 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 4 missing tasks from ShuffleMapStage 43 (MapPartitionsRDD[51] at distinct at PaidPromotionAdjustParameter.scala:164) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
2021-12-04 17:40:29,422 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 43.0 with 4 tasks
2021-12-04 17:40:29,423 [dispatcher-event-loop-4] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 43.0 (TID 68, localhost, executor driver, partition 0, ANY, 7994 bytes)
2021-12-04 17:40:29,423 [dispatcher-event-loop-4] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 43.0 (TID 69, localhost, executor driver, partition 1, ANY, 7994 bytes)
2021-12-04 17:40:29,423 [dispatcher-event-loop-4] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 2.0 in stage 43.0 (TID 70, localhost, executor driver, partition 2, ANY, 7994 bytes)
2021-12-04 17:40:29,423 [dispatcher-event-loop-4] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 3.0 in stage 43.0 (TID 71, localhost, executor driver, partition 3, ANY, 7994 bytes)
2021-12-04 17:40:29,423 [Executor task launch worker for task 71] INFO [org.apache.spark.executor.Executor] - Running task 3.0 in stage 43.0 (TID 71)
2021-12-04 17:40:29,423 [Executor task launch worker for task 68] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 43.0 (TID 68)
2021-12-04 17:40:29,423 [Executor task launch worker for task 70] INFO [org.apache.spark.executor.Executor] - Running task 2.0 in stage 43.0 (TID 70)
2021-12-04 17:40:29,423 [Executor task launch worker for task 69] INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 43.0 (TID 69)
2021-12-04 17:40:29,425 [Executor task launch worker for task 71] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/order_data.bcp:3442194+3442195
2021-12-04 17:40:29,425 [Executor task launch worker for task 70] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/order_data.bcp:0+3442194
2021-12-04 17:40:29,426 [Executor task launch worker for task 68] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/order_data.bcp:0+3442194
2021-12-04 17:40:29,426 [Executor task launch worker for task 69] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/order_data.bcp:3442194+3442195
2021-12-04 17:40:30,188 [Executor task launch worker for task 71] INFO [org.apache.spark.executor.Executor] - Finished task 3.0 in stage 43.0 (TID 71). 991 bytes result sent to driver
2021-12-04 17:40:30,188 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 3.0 in stage 43.0 (TID 71) in 765 ms on localhost (executor driver) (1/4)
2021-12-04 17:40:30,535 [Executor task launch worker for task 69] INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 43.0 (TID 69). 991 bytes result sent to driver
2021-12-04 17:40:30,535 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 43.0 (TID 69) in 1112 ms on localhost (executor driver) (2/4)
2021-12-04 17:40:30,764 [Executor task launch worker for task 70] INFO [org.apache.spark.executor.Executor] - Finished task 2.0 in stage 43.0 (TID 70). 991 bytes result sent to driver
2021-12-04 17:40:30,764 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 2.0 in stage 43.0 (TID 70) in 1341 ms on localhost (executor driver) (3/4)
2021-12-04 17:40:30,892 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 721
2021-12-04 17:40:30,892 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 677
2021-12-04 17:40:30,892 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 693
2021-12-04 17:40:30,892 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 669
2021-12-04 17:40:30,892 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 652
2021-12-04 17:40:30,892 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 720
2021-12-04 17:40:30,892 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 675
2021-12-04 17:40:30,892 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 656
2021-12-04 17:40:30,892 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 691
2021-12-04 17:40:30,892 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 696
2021-12-04 17:40:30,892 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 684
2021-12-04 17:40:30,892 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 668
2021-12-04 17:40:30,892 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 698
2021-12-04 17:40:30,892 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 666
2021-12-04 17:40:30,892 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 655
2021-12-04 17:40:30,892 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 724
2021-12-04 17:40:30,892 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 670
2021-12-04 17:40:30,892 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 709
2021-12-04 17:40:30,892 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 703
2021-12-04 17:40:30,892 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 723
2021-12-04 17:40:30,893 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 717
2021-12-04 17:40:30,893 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 708
2021-12-04 17:40:30,893 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 716
2021-12-04 17:40:30,893 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 653
2021-12-04 17:40:30,893 [dispatcher-event-loop-4] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_29_piece0 on qb:51947 in memory (size: 2.1 KB, free: 1990.7 MB)
2021-12-04 17:40:30,894 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 697
2021-12-04 17:40:30,894 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 661
2021-12-04 17:40:30,894 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 695
2021-12-04 17:40:30,894 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 662
2021-12-04 17:40:30,894 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 713
2021-12-04 17:40:30,894 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 659
2021-12-04 17:40:30,894 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 711
2021-12-04 17:40:30,894 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 707
2021-12-04 17:40:30,894 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 658
2021-12-04 17:40:30,894 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 673
2021-12-04 17:40:30,894 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 690
2021-12-04 17:40:30,894 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 714
2021-12-04 17:40:30,894 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 650
2021-12-04 17:40:30,894 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 705
2021-12-04 17:40:30,894 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 681
2021-12-04 17:40:30,894 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 712
2021-12-04 17:40:30,894 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 706
2021-12-04 17:40:30,894 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 672
2021-12-04 17:40:30,894 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 686
2021-12-04 17:40:30,894 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 682
2021-12-04 17:40:30,894 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 660
2021-12-04 17:40:30,894 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 688
2021-12-04 17:40:30,894 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 676
2021-12-04 17:40:30,894 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 701
2021-12-04 17:40:30,894 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 692
2021-12-04 17:40:30,894 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 699
2021-12-04 17:40:30,894 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 702
2021-12-04 17:40:30,894 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 719
2021-12-04 17:40:30,894 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 687
2021-12-04 17:40:30,894 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 651
2021-12-04 17:40:30,894 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 667
2021-12-04 17:40:30,894 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 685
2021-12-04 17:40:30,894 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 722
2021-12-04 17:40:30,894 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 683
2021-12-04 17:40:30,894 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 710
2021-12-04 17:40:30,894 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 664
2021-12-04 17:40:30,894 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 694
2021-12-04 17:40:30,894 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 718
2021-12-04 17:40:30,894 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 674
2021-12-04 17:40:30,894 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 665
2021-12-04 17:40:30,894 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 689
2021-12-04 17:40:30,894 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 715
2021-12-04 17:40:30,894 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 663
2021-12-04 17:40:30,894 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 680
2021-12-04 17:40:30,894 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 657
2021-12-04 17:40:30,894 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 700
2021-12-04 17:40:30,894 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 704
2021-12-04 17:40:30,894 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 678
2021-12-04 17:40:30,894 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 654
2021-12-04 17:40:30,894 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 679
2021-12-04 17:40:30,894 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 671
2021-12-04 17:40:30,950 [Executor task launch worker for task 68] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 43.0 (TID 68). 1034 bytes result sent to driver
2021-12-04 17:40:30,951 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 43.0 (TID 68) in 1529 ms on localhost (executor driver) (4/4)
2021-12-04 17:40:30,951 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 43.0, whose tasks have all completed, from pool 
2021-12-04 17:40:30,951 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ShuffleMapStage 43 (distinct at PaidPromotionAdjustParameter.scala:164) finished in 1.534 s
2021-12-04 17:40:30,951 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - looking for newly runnable stages
2021-12-04 17:40:30,951 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - running: Set()
2021-12-04 17:40:30,951 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - waiting: Set(ResultStage 44)
2021-12-04 17:40:30,951 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - failed: Set()
2021-12-04 17:40:30,951 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 44 (MapPartitionsRDD[53] at distinct at PaidPromotionAdjustParameter.scala:164), which has no missing parents
2021-12-04 17:40:30,952 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_31 stored as values in memory (estimated size 3.7 KB, free 1990.2 MB)
2021-12-04 17:40:30,953 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_31_piece0 stored as bytes in memory (estimated size 2.2 KB, free 1990.2 MB)
2021-12-04 17:40:30,954 [dispatcher-event-loop-6] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_31_piece0 in memory on qb:51947 (size: 2.2 KB, free: 1990.7 MB)
2021-12-04 17:40:30,954 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 31 from broadcast at DAGScheduler.scala:1039
2021-12-04 17:40:30,954 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 4 missing tasks from ResultStage 44 (MapPartitionsRDD[53] at distinct at PaidPromotionAdjustParameter.scala:164) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
2021-12-04 17:40:30,954 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 44.0 with 4 tasks
2021-12-04 17:40:30,954 [dispatcher-event-loop-10] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 44.0 (TID 72, localhost, executor driver, partition 0, ANY, 7649 bytes)
2021-12-04 17:40:30,954 [dispatcher-event-loop-10] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 44.0 (TID 73, localhost, executor driver, partition 1, ANY, 7649 bytes)
2021-12-04 17:40:30,954 [dispatcher-event-loop-10] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 2.0 in stage 44.0 (TID 74, localhost, executor driver, partition 2, ANY, 7649 bytes)
2021-12-04 17:40:30,954 [dispatcher-event-loop-10] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 3.0 in stage 44.0 (TID 75, localhost, executor driver, partition 3, ANY, 7649 bytes)
2021-12-04 17:40:30,955 [Executor task launch worker for task 73] INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 44.0 (TID 73)
2021-12-04 17:40:30,955 [Executor task launch worker for task 72] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 44.0 (TID 72)
2021-12-04 17:40:30,955 [Executor task launch worker for task 75] INFO [org.apache.spark.executor.Executor] - Running task 3.0 in stage 44.0 (TID 75)
2021-12-04 17:40:30,955 [Executor task launch worker for task 74] INFO [org.apache.spark.executor.Executor] - Running task 2.0 in stage 44.0 (TID 74)
2021-12-04 17:40:30,955 [Executor task launch worker for task 72] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 4 non-empty blocks out of 4 blocks
2021-12-04 17:40:30,955 [Executor task launch worker for task 74] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 4 non-empty blocks out of 4 blocks
2021-12-04 17:40:30,956 [Executor task launch worker for task 74] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 1 ms
2021-12-04 17:40:30,955 [Executor task launch worker for task 72] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-04 17:40:30,956 [Executor task launch worker for task 75] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 4 non-empty blocks out of 4 blocks
2021-12-04 17:40:30,955 [Executor task launch worker for task 73] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 4 non-empty blocks out of 4 blocks
2021-12-04 17:40:30,956 [Executor task launch worker for task 75] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 1 ms
2021-12-04 17:40:30,956 [Executor task launch worker for task 73] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 1 ms
2021-12-04 17:40:30,975 [Executor task launch worker for task 74] INFO [org.apache.spark.executor.Executor] - Finished task 2.0 in stage 44.0 (TID 74). 1010 bytes result sent to driver
2021-12-04 17:40:30,975 [Executor task launch worker for task 75] INFO [org.apache.spark.executor.Executor] - Finished task 3.0 in stage 44.0 (TID 75). 1010 bytes result sent to driver
2021-12-04 17:40:30,975 [Executor task launch worker for task 73] INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 44.0 (TID 73). 1010 bytes result sent to driver
2021-12-04 17:40:30,975 [Executor task launch worker for task 72] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 44.0 (TID 72). 1010 bytes result sent to driver
2021-12-04 17:40:30,975 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 2.0 in stage 44.0 (TID 74) in 21 ms on localhost (executor driver) (1/4)
2021-12-04 17:40:30,976 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 3.0 in stage 44.0 (TID 75) in 22 ms on localhost (executor driver) (2/4)
2021-12-04 17:40:30,976 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 44.0 (TID 73) in 22 ms on localhost (executor driver) (3/4)
2021-12-04 17:40:30,976 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 44.0 (TID 72) in 22 ms on localhost (executor driver) (4/4)
2021-12-04 17:40:30,976 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 44.0, whose tasks have all completed, from pool 
2021-12-04 17:40:30,976 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 44 (count at PaidPromotionAdjustParameter.scala:172) finished in 0.025 s
2021-12-04 17:40:30,976 [main] INFO [org.apache.spark.scheduler.DAGScheduler] - Job 17 finished: count at PaidPromotionAdjustParameter.scala:172, took 1.559944 s
2021-12-04 17:40:30,976 [main] INFO [PaidPromotion$] - 最终训练集节目数 = 132
2021-12-04 17:40:30,979 [main] INFO [org.apache.spark.SparkContext] - Starting job: count at PaidPromotionAdjustParameter.scala:173
2021-12-04 17:40:30,979 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 55 (distinct at PaidPromotionAdjustParameter.scala:165)
2021-12-04 17:40:30,979 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 18 (count at PaidPromotionAdjustParameter.scala:173) with 2 output partitions
2021-12-04 17:40:30,979 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 46 (count at PaidPromotionAdjustParameter.scala:173)
2021-12-04 17:40:30,979 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 45)
2021-12-04 17:40:30,979 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List(ShuffleMapStage 45)
2021-12-04 17:40:30,980 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ShuffleMapStage 45 (MapPartitionsRDD[55] at distinct at PaidPromotionAdjustParameter.scala:165), which has no missing parents
2021-12-04 17:40:30,981 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_32 stored as values in memory (estimated size 183.3 KB, free 1990.0 MB)
2021-12-04 17:40:30,983 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_32_piece0 stored as bytes in memory (estimated size 64.8 KB, free 1990.0 MB)
2021-12-04 17:40:30,984 [dispatcher-event-loop-4] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_32_piece0 in memory on qb:51947 (size: 64.8 KB, free: 1990.6 MB)
2021-12-04 17:40:30,984 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 32 from broadcast at DAGScheduler.scala:1039
2021-12-04 17:40:30,984 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from ShuffleMapStage 45 (MapPartitionsRDD[55] at distinct at PaidPromotionAdjustParameter.scala:165) (first 15 tasks are for partitions Vector(0, 1))
2021-12-04 17:40:30,984 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 45.0 with 2 tasks
2021-12-04 17:40:30,985 [dispatcher-event-loop-5] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 45.0 (TID 76, localhost, executor driver, partition 0, ANY, 7885 bytes)
2021-12-04 17:40:30,985 [dispatcher-event-loop-5] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 45.0 (TID 77, localhost, executor driver, partition 1, ANY, 7885 bytes)
2021-12-04 17:40:30,985 [Executor task launch worker for task 77] INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 45.0 (TID 77)
2021-12-04 17:40:30,985 [Executor task launch worker for task 76] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 45.0 (TID 76)
2021-12-04 17:40:30,987 [Executor task launch worker for task 77] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/order_data.bcp:3442194+3442195
2021-12-04 17:40:30,987 [Executor task launch worker for task 76] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/order_data.bcp:0+3442194
2021-12-04 17:40:32,090 [Executor task launch worker for task 77] INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 45.0 (TID 77). 989 bytes result sent to driver
2021-12-04 17:40:32,090 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 45.0 (TID 77) in 1105 ms on localhost (executor driver) (1/2)
2021-12-04 17:40:32,278 [Executor task launch worker for task 76] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 45.0 (TID 76). 989 bytes result sent to driver
2021-12-04 17:40:32,278 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 45.0 (TID 76) in 1294 ms on localhost (executor driver) (2/2)
2021-12-04 17:40:32,278 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 45.0, whose tasks have all completed, from pool 
2021-12-04 17:40:32,279 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ShuffleMapStage 45 (distinct at PaidPromotionAdjustParameter.scala:165) finished in 1.299 s
2021-12-04 17:40:32,279 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - looking for newly runnable stages
2021-12-04 17:40:32,279 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - running: Set()
2021-12-04 17:40:32,279 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - waiting: Set(ResultStage 46)
2021-12-04 17:40:32,279 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - failed: Set()
2021-12-04 17:40:32,279 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 46 (MapPartitionsRDD[57] at distinct at PaidPromotionAdjustParameter.scala:165), which has no missing parents
2021-12-04 17:40:32,279 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_33 stored as values in memory (estimated size 3.7 KB, free 1990.0 MB)
2021-12-04 17:40:32,281 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_33_piece0 stored as bytes in memory (estimated size 2.2 KB, free 1990.0 MB)
2021-12-04 17:40:32,281 [dispatcher-event-loop-9] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_33_piece0 in memory on qb:51947 (size: 2.2 KB, free: 1990.6 MB)
2021-12-04 17:40:32,281 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 33 from broadcast at DAGScheduler.scala:1039
2021-12-04 17:40:32,281 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from ResultStage 46 (MapPartitionsRDD[57] at distinct at PaidPromotionAdjustParameter.scala:165) (first 15 tasks are for partitions Vector(0, 1))
2021-12-04 17:40:32,281 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 46.0 with 2 tasks
2021-12-04 17:40:32,282 [dispatcher-event-loop-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 46.0 (TID 78, localhost, executor driver, partition 0, ANY, 7649 bytes)
2021-12-04 17:40:32,282 [dispatcher-event-loop-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 46.0 (TID 79, localhost, executor driver, partition 1, ANY, 7649 bytes)
2021-12-04 17:40:32,282 [Executor task launch worker for task 79] INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 46.0 (TID 79)
2021-12-04 17:40:32,282 [Executor task launch worker for task 78] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 46.0 (TID 78)
2021-12-04 17:40:32,283 [Executor task launch worker for task 79] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 2 non-empty blocks out of 2 blocks
2021-12-04 17:40:32,283 [Executor task launch worker for task 78] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 2 non-empty blocks out of 2 blocks
2021-12-04 17:40:32,283 [Executor task launch worker for task 79] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-04 17:40:32,283 [Executor task launch worker for task 78] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-04 17:40:32,293 [Executor task launch worker for task 79] INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 46.0 (TID 79). 1010 bytes result sent to driver
2021-12-04 17:40:32,293 [Executor task launch worker for task 78] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 46.0 (TID 78). 1010 bytes result sent to driver
2021-12-04 17:40:32,294 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 46.0 (TID 79) in 12 ms on localhost (executor driver) (1/2)
2021-12-04 17:40:32,294 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 46.0 (TID 78) in 12 ms on localhost (executor driver) (2/2)
2021-12-04 17:40:32,294 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 46.0, whose tasks have all completed, from pool 
2021-12-04 17:40:32,294 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 46 (count at PaidPromotionAdjustParameter.scala:173) finished in 0.015 s
2021-12-04 17:40:32,294 [main] INFO [org.apache.spark.scheduler.DAGScheduler] - Job 18 finished: count at PaidPromotionAdjustParameter.scala:173, took 1.315884 s
2021-12-04 17:40:32,295 [main] INFO [PaidPromotion$] - 最终验证集节目数 = 83
2021-12-04 17:40:32,297 [main] INFO [org.apache.spark.SparkContext] - Starting job: count at PaidPromotionAdjustParameter.scala:174
2021-12-04 17:40:32,297 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 58 (intersection at PaidPromotionAdjustParameter.scala:166)
2021-12-04 17:40:32,297 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 59 (intersection at PaidPromotionAdjustParameter.scala:166)
2021-12-04 17:40:32,297 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 19 (count at PaidPromotionAdjustParameter.scala:174) with 4 output partitions
2021-12-04 17:40:32,297 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 51 (count at PaidPromotionAdjustParameter.scala:174)
2021-12-04 17:40:32,297 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 48, ShuffleMapStage 50)
2021-12-04 17:40:32,297 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List(ShuffleMapStage 48, ShuffleMapStage 50)
2021-12-04 17:40:32,297 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ShuffleMapStage 48 (MapPartitionsRDD[58] at intersection at PaidPromotionAdjustParameter.scala:166), which has no missing parents
2021-12-04 17:40:32,298 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_34 stored as values in memory (estimated size 4.0 KB, free 1990.0 MB)
2021-12-04 17:40:32,299 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_34_piece0 stored as bytes in memory (estimated size 2.3 KB, free 1990.0 MB)
2021-12-04 17:40:32,300 [dispatcher-event-loop-4] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_34_piece0 in memory on qb:51947 (size: 2.3 KB, free: 1990.6 MB)
2021-12-04 17:40:32,300 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 34 from broadcast at DAGScheduler.scala:1039
2021-12-04 17:40:32,300 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 4 missing tasks from ShuffleMapStage 48 (MapPartitionsRDD[58] at intersection at PaidPromotionAdjustParameter.scala:166) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
2021-12-04 17:40:32,300 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 48.0 with 4 tasks
2021-12-04 17:40:32,301 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ShuffleMapStage 50 (MapPartitionsRDD[59] at intersection at PaidPromotionAdjustParameter.scala:166), which has no missing parents
2021-12-04 17:40:32,301 [dispatcher-event-loop-5] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 48.0 (TID 80, localhost, executor driver, partition 0, ANY, 7638 bytes)
2021-12-04 17:40:32,301 [dispatcher-event-loop-5] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 48.0 (TID 81, localhost, executor driver, partition 1, ANY, 7638 bytes)
2021-12-04 17:40:32,301 [dispatcher-event-loop-5] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 2.0 in stage 48.0 (TID 82, localhost, executor driver, partition 2, ANY, 7638 bytes)
2021-12-04 17:40:32,301 [dispatcher-event-loop-5] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 3.0 in stage 48.0 (TID 83, localhost, executor driver, partition 3, ANY, 7638 bytes)
2021-12-04 17:40:32,301 [Executor task launch worker for task 81] INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 48.0 (TID 81)
2021-12-04 17:40:32,301 [Executor task launch worker for task 82] INFO [org.apache.spark.executor.Executor] - Running task 2.0 in stage 48.0 (TID 82)
2021-12-04 17:40:32,301 [Executor task launch worker for task 83] INFO [org.apache.spark.executor.Executor] - Running task 3.0 in stage 48.0 (TID 83)
2021-12-04 17:40:32,301 [Executor task launch worker for task 80] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 48.0 (TID 80)
2021-12-04 17:40:32,301 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_35 stored as values in memory (estimated size 4.0 KB, free 1990.0 MB)
2021-12-04 17:40:32,302 [Executor task launch worker for task 83] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 4 non-empty blocks out of 4 blocks
2021-12-04 17:40:32,302 [Executor task launch worker for task 83] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-04 17:40:32,302 [Executor task launch worker for task 81] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 4 non-empty blocks out of 4 blocks
2021-12-04 17:40:32,302 [Executor task launch worker for task 82] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 4 non-empty blocks out of 4 blocks
2021-12-04 17:40:32,302 [Executor task launch worker for task 81] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-04 17:40:32,302 [Executor task launch worker for task 80] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 4 non-empty blocks out of 4 blocks
2021-12-04 17:40:32,302 [Executor task launch worker for task 82] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-04 17:40:32,302 [Executor task launch worker for task 80] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-04 17:40:32,304 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_35_piece0 stored as bytes in memory (estimated size 2.3 KB, free 1990.0 MB)
2021-12-04 17:40:32,304 [dispatcher-event-loop-9] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_35_piece0 in memory on qb:51947 (size: 2.3 KB, free: 1990.6 MB)
2021-12-04 17:40:32,304 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 35 from broadcast at DAGScheduler.scala:1039
2021-12-04 17:40:32,305 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from ShuffleMapStage 50 (MapPartitionsRDD[59] at intersection at PaidPromotionAdjustParameter.scala:166) (first 15 tasks are for partitions Vector(0, 1))
2021-12-04 17:40:32,305 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 50.0 with 2 tasks
2021-12-04 17:40:32,305 [dispatcher-event-loop-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 50.0 (TID 84, localhost, executor driver, partition 0, ANY, 7638 bytes)
2021-12-04 17:40:32,305 [dispatcher-event-loop-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 50.0 (TID 85, localhost, executor driver, partition 1, ANY, 7638 bytes)
2021-12-04 17:40:32,305 [Executor task launch worker for task 85] INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 50.0 (TID 85)
2021-12-04 17:40:32,305 [Executor task launch worker for task 84] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 50.0 (TID 84)
2021-12-04 17:40:32,306 [Executor task launch worker for task 85] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 2 non-empty blocks out of 2 blocks
2021-12-04 17:40:32,306 [Executor task launch worker for task 84] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 2 non-empty blocks out of 2 blocks
2021-12-04 17:40:32,306 [Executor task launch worker for task 85] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-04 17:40:32,306 [Executor task launch worker for task 84] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-04 17:40:32,315 [Executor task launch worker for task 82] INFO [org.apache.spark.executor.Executor] - Finished task 2.0 in stage 48.0 (TID 82). 1206 bytes result sent to driver
2021-12-04 17:40:32,315 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 2.0 in stage 48.0 (TID 82) in 14 ms on localhost (executor driver) (1/4)
2021-12-04 17:40:32,320 [Executor task launch worker for task 80] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 48.0 (TID 80). 1206 bytes result sent to driver
2021-12-04 17:40:32,321 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 48.0 (TID 80) in 20 ms on localhost (executor driver) (2/4)
2021-12-04 17:40:32,321 [Executor task launch worker for task 83] INFO [org.apache.spark.executor.Executor] - Finished task 3.0 in stage 48.0 (TID 83). 1206 bytes result sent to driver
2021-12-04 17:40:32,322 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 3.0 in stage 48.0 (TID 83) in 21 ms on localhost (executor driver) (3/4)
2021-12-04 17:40:32,323 [Executor task launch worker for task 81] INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 48.0 (TID 81). 1206 bytes result sent to driver
2021-12-04 17:40:32,323 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 48.0 (TID 81) in 22 ms on localhost (executor driver) (4/4)
2021-12-04 17:40:32,323 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 48.0, whose tasks have all completed, from pool 
2021-12-04 17:40:32,323 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ShuffleMapStage 48 (intersection at PaidPromotionAdjustParameter.scala:166) finished in 0.025 s
2021-12-04 17:40:32,323 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - looking for newly runnable stages
2021-12-04 17:40:32,323 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - running: Set(ShuffleMapStage 50)
2021-12-04 17:40:32,323 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - waiting: Set(ResultStage 51)
2021-12-04 17:40:32,323 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - failed: Set()
2021-12-04 17:40:32,328 [Executor task launch worker for task 85] INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 50.0 (TID 85). 1206 bytes result sent to driver
2021-12-04 17:40:32,328 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 50.0 (TID 85) in 23 ms on localhost (executor driver) (1/2)
2021-12-04 17:40:32,329 [Executor task launch worker for task 84] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 50.0 (TID 84). 1206 bytes result sent to driver
2021-12-04 17:40:32,329 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 50.0 (TID 84) in 24 ms on localhost (executor driver) (2/2)
2021-12-04 17:40:32,329 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 50.0, whose tasks have all completed, from pool 
2021-12-04 17:40:32,330 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ShuffleMapStage 50 (intersection at PaidPromotionAdjustParameter.scala:166) finished in 0.029 s
2021-12-04 17:40:32,330 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - looking for newly runnable stages
2021-12-04 17:40:32,330 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - running: Set()
2021-12-04 17:40:32,330 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - waiting: Set(ResultStage 51)
2021-12-04 17:40:32,330 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - failed: Set()
2021-12-04 17:40:32,330 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 51 (MapPartitionsRDD[63] at intersection at PaidPromotionAdjustParameter.scala:166), which has no missing parents
2021-12-04 17:40:32,331 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_36 stored as values in memory (estimated size 3.6 KB, free 1990.0 MB)
2021-12-04 17:40:32,333 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_36_piece0 stored as bytes in memory (estimated size 2.1 KB, free 1990.0 MB)
2021-12-04 17:40:32,333 [dispatcher-event-loop-8] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_36_piece0 in memory on qb:51947 (size: 2.1 KB, free: 1990.6 MB)
2021-12-04 17:40:32,333 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 36 from broadcast at DAGScheduler.scala:1039
2021-12-04 17:40:32,333 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 4 missing tasks from ResultStage 51 (MapPartitionsRDD[63] at intersection at PaidPromotionAdjustParameter.scala:166) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
2021-12-04 17:40:32,333 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 51.0 with 4 tasks
2021-12-04 17:40:32,334 [dispatcher-event-loop-7] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 51.0 (TID 86, localhost, executor driver, partition 0, PROCESS_LOCAL, 7712 bytes)
2021-12-04 17:40:32,334 [dispatcher-event-loop-7] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 51.0 (TID 87, localhost, executor driver, partition 1, PROCESS_LOCAL, 7712 bytes)
2021-12-04 17:40:32,334 [dispatcher-event-loop-7] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 2.0 in stage 51.0 (TID 88, localhost, executor driver, partition 2, PROCESS_LOCAL, 7712 bytes)
2021-12-04 17:40:32,334 [dispatcher-event-loop-7] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 3.0 in stage 51.0 (TID 89, localhost, executor driver, partition 3, PROCESS_LOCAL, 7712 bytes)
2021-12-04 17:40:32,334 [Executor task launch worker for task 87] INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 51.0 (TID 87)
2021-12-04 17:40:32,334 [Executor task launch worker for task 89] INFO [org.apache.spark.executor.Executor] - Running task 3.0 in stage 51.0 (TID 89)
2021-12-04 17:40:32,334 [Executor task launch worker for task 86] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 51.0 (TID 86)
2021-12-04 17:40:32,334 [Executor task launch worker for task 88] INFO [org.apache.spark.executor.Executor] - Running task 2.0 in stage 51.0 (TID 88)
2021-12-04 17:40:32,335 [Executor task launch worker for task 86] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 4 blocks
2021-12-04 17:40:32,335 [Executor task launch worker for task 87] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 4 blocks
2021-12-04 17:40:32,335 [Executor task launch worker for task 87] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-04 17:40:32,335 [Executor task launch worker for task 86] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-04 17:40:32,335 [Executor task launch worker for task 89] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 4 blocks
2021-12-04 17:40:32,335 [Executor task launch worker for task 88] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 4 blocks
2021-12-04 17:40:32,335 [Executor task launch worker for task 89] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-04 17:40:32,335 [Executor task launch worker for task 88] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-04 17:40:32,337 [Executor task launch worker for task 86] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2021-12-04 17:40:32,337 [Executor task launch worker for task 87] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2021-12-04 17:40:32,337 [Executor task launch worker for task 86] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-04 17:40:32,337 [Executor task launch worker for task 87] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-04 17:40:32,337 [Executor task launch worker for task 88] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2021-12-04 17:40:32,337 [Executor task launch worker for task 89] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2021-12-04 17:40:32,337 [Executor task launch worker for task 88] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-04 17:40:32,337 [Executor task launch worker for task 89] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-04 17:40:32,345 [Executor task launch worker for task 89] INFO [org.apache.spark.executor.Executor] - Finished task 3.0 in stage 51.0 (TID 89). 967 bytes result sent to driver
2021-12-04 17:40:32,345 [Executor task launch worker for task 88] INFO [org.apache.spark.executor.Executor] - Finished task 2.0 in stage 51.0 (TID 88). 967 bytes result sent to driver
2021-12-04 17:40:32,345 [Executor task launch worker for task 86] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 51.0 (TID 86). 967 bytes result sent to driver
2021-12-04 17:40:32,345 [Executor task launch worker for task 87] INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 51.0 (TID 87). 967 bytes result sent to driver
2021-12-04 17:40:32,346 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 3.0 in stage 51.0 (TID 89) in 12 ms on localhost (executor driver) (1/4)
2021-12-04 17:40:32,346 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 2.0 in stage 51.0 (TID 88) in 12 ms on localhost (executor driver) (2/4)
2021-12-04 17:40:32,346 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 51.0 (TID 87) in 12 ms on localhost (executor driver) (3/4)
2021-12-04 17:40:32,346 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 51.0 (TID 86) in 12 ms on localhost (executor driver) (4/4)
2021-12-04 17:40:32,346 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 51.0, whose tasks have all completed, from pool 
2021-12-04 17:40:32,346 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 51 (count at PaidPromotionAdjustParameter.scala:174) finished in 0.016 s
2021-12-04 17:40:32,347 [main] INFO [org.apache.spark.scheduler.DAGScheduler] - Job 19 finished: count at PaidPromotionAdjustParameter.scala:174, took 0.049751 s
2021-12-04 17:40:32,347 [main] INFO [PaidPromotion$] - 最终共 同 节目数 = 83
2021-12-04 17:40:32,365 [main] INFO [org.apache.hadoop.conf.Configuration.deprecation] - mapred.output.dir is deprecated. Instead, use mapreduce.output.fileoutputformat.outputdir
2021-12-04 17:40:32,368 [main] INFO [org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter] - File Output Committer Algorithm version is 1
2021-12-04 17:40:32,400 [main] INFO [org.apache.spark.SparkContext] - Starting job: runJob at SparkHadoopWriter.scala:78
2021-12-04 17:40:32,401 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 20 (runJob at SparkHadoopWriter.scala:78) with 1 output partitions
2021-12-04 17:40:32,401 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 52 (runJob at SparkHadoopWriter.scala:78)
2021-12-04 17:40:32,401 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List()
2021-12-04 17:40:32,401 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2021-12-04 17:40:32,401 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 52 (MapPartitionsRDD[66] at saveAsTextFile at PaidPromotionAdjustParameter.scala:179), which has no missing parents
2021-12-04 17:40:32,411 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_37 stored as values in memory (estimated size 258.9 KB, free 1989.7 MB)
2021-12-04 17:40:32,413 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_37_piece0 stored as bytes in memory (estimated size 93.3 KB, free 1989.6 MB)
2021-12-04 17:40:32,413 [dispatcher-event-loop-10] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_37_piece0 in memory on qb:51947 (size: 93.3 KB, free: 1990.5 MB)
2021-12-04 17:40:32,413 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 37 from broadcast at DAGScheduler.scala:1039
2021-12-04 17:40:32,413 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 52 (MapPartitionsRDD[66] at saveAsTextFile at PaidPromotionAdjustParameter.scala:179) (first 15 tasks are for partitions Vector(0))
2021-12-04 17:40:32,413 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 52.0 with 1 tasks
2021-12-04 17:40:32,416 [dispatcher-event-loop-6] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 52.0 (TID 90, localhost, executor driver, partition 0, ANY, 8509 bytes)
2021-12-04 17:40:32,416 [Executor task launch worker for task 90] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 52.0 (TID 90)
2021-12-04 17:40:32,430 [Executor task launch worker for task 90] INFO [org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter] - File Output Committer Algorithm version is 1
2021-12-04 17:40:32,463 [Executor task launch worker for task 90] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/order_data.bcp:0+3442194
2021-12-04 17:40:33,570 [Executor task launch worker for task 90] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/order_data.bcp:3442194+3442195
2021-12-04 17:40:33,677 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 888
2021-12-04 17:40:33,677 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 819
2021-12-04 17:40:33,677 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 851
2021-12-04 17:40:33,677 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 743
2021-12-04 17:40:33,677 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 860
2021-12-04 17:40:33,677 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 757
2021-12-04 17:40:33,677 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 778
2021-12-04 17:40:33,677 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 811
2021-12-04 17:40:33,677 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 773
2021-12-04 17:40:33,677 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 836
2021-12-04 17:40:33,677 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 884
2021-12-04 17:40:33,677 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 755
2021-12-04 17:40:33,677 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 862
2021-12-04 17:40:33,677 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 771
2021-12-04 17:40:33,677 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 831
2021-12-04 17:40:33,677 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 734
2021-12-04 17:40:33,677 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 890
2021-12-04 17:40:33,677 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 887
2021-12-04 17:40:33,677 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 864
2021-12-04 17:40:33,677 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 742
2021-12-04 17:40:33,677 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 737
2021-12-04 17:40:33,677 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 730
2021-12-04 17:40:33,678 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 841
2021-12-04 17:40:33,678 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 763
2021-12-04 17:40:33,678 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 786
2021-12-04 17:40:33,678 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 817
2021-12-04 17:40:33,678 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 845
2021-12-04 17:40:33,678 [dispatcher-event-loop-2] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_32_piece0 on qb:51947 in memory (size: 64.8 KB, free: 1990.6 MB)
2021-12-04 17:40:33,679 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 856
2021-12-04 17:40:33,679 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 767
2021-12-04 17:40:33,679 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 791
2021-12-04 17:40:33,679 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 882
2021-12-04 17:40:33,679 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 857
2021-12-04 17:40:33,679 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 756
2021-12-04 17:40:33,679 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 805
2021-12-04 17:40:33,679 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 843
2021-12-04 17:40:33,679 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 873
2021-12-04 17:40:33,679 [dispatcher-event-loop-1] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_30_piece0 on qb:51947 in memory (size: 65.1 KB, free: 1990.7 MB)
2021-12-04 17:40:33,679 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 807
2021-12-04 17:40:33,679 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 784
2021-12-04 17:40:33,679 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 877
2021-12-04 17:40:33,679 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 752
2021-12-04 17:40:33,679 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 758
2021-12-04 17:40:33,679 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 892
2021-12-04 17:40:33,679 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 802
2021-12-04 17:40:33,679 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 830
2021-12-04 17:40:33,679 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 842
2021-12-04 17:40:33,679 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 792
2021-12-04 17:40:33,679 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 781
2021-12-04 17:40:33,679 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 790
2021-12-04 17:40:33,679 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 821
2021-12-04 17:40:33,679 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 762
2021-12-04 17:40:33,680 [dispatcher-event-loop-11] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_34_piece0 on qb:51947 in memory (size: 2.3 KB, free: 1990.7 MB)
2021-12-04 17:40:33,680 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 810
2021-12-04 17:40:33,680 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 747
2021-12-04 17:40:33,680 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 870
2021-12-04 17:40:33,680 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 759
2021-12-04 17:40:33,680 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 861
2021-12-04 17:40:33,680 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 753
2021-12-04 17:40:33,680 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 733
2021-12-04 17:40:33,680 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 848
2021-12-04 17:40:33,680 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 894
2021-12-04 17:40:33,680 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 735
2021-12-04 17:40:33,680 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 785
2021-12-04 17:40:33,680 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 872
2021-12-04 17:40:33,680 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 776
2021-12-04 17:40:33,680 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 878
2021-12-04 17:40:33,680 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 849
2021-12-04 17:40:33,680 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 801
2021-12-04 17:40:33,680 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 818
2021-12-04 17:40:33,680 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 744
2021-12-04 17:40:33,680 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 893
2021-12-04 17:40:33,680 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 748
2021-12-04 17:40:33,680 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 741
2021-12-04 17:40:33,680 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 736
2021-12-04 17:40:33,680 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 808
2021-12-04 17:40:33,680 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 804
2021-12-04 17:40:33,680 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 772
2021-12-04 17:40:33,680 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 800
2021-12-04 17:40:33,680 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 869
2021-12-04 17:40:33,680 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 898
2021-12-04 17:40:33,680 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 812
2021-12-04 17:40:33,680 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 803
2021-12-04 17:40:33,680 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 725
2021-12-04 17:40:33,680 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 777
2021-12-04 17:40:33,680 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 797
2021-12-04 17:40:33,680 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 751
2021-12-04 17:40:33,680 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 850
2021-12-04 17:40:33,680 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 876
2021-12-04 17:40:33,680 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 739
2021-12-04 17:40:33,680 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 766
2021-12-04 17:40:33,680 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 799
2021-12-04 17:40:33,680 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 746
2021-12-04 17:40:33,680 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 770
2021-12-04 17:40:33,680 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 868
2021-12-04 17:40:33,680 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 782
2021-12-04 17:40:33,681 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 798
2021-12-04 17:40:33,681 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 764
2021-12-04 17:40:33,681 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 826
2021-12-04 17:40:33,681 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 874
2021-12-04 17:40:33,681 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 780
2021-12-04 17:40:33,681 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 765
2021-12-04 17:40:33,681 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 754
2021-12-04 17:40:33,681 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 738
2021-12-04 17:40:33,681 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 838
2021-12-04 17:40:33,681 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 794
2021-12-04 17:40:33,681 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 895
2021-12-04 17:40:33,681 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 889
2021-12-04 17:40:33,681 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 760
2021-12-04 17:40:33,681 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 835
2021-12-04 17:40:33,681 [dispatcher-event-loop-8] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_33_piece0 on qb:51947 in memory (size: 2.2 KB, free: 1990.7 MB)
2021-12-04 17:40:33,681 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 822
2021-12-04 17:40:33,681 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 867
2021-12-04 17:40:33,681 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 897
2021-12-04 17:40:33,681 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 891
2021-12-04 17:40:33,681 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 863
2021-12-04 17:40:33,681 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 774
2021-12-04 17:40:33,681 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 732
2021-12-04 17:40:33,681 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 726
2021-12-04 17:40:33,681 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 823
2021-12-04 17:40:33,681 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 896
2021-12-04 17:40:33,681 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 853
2021-12-04 17:40:33,681 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 844
2021-12-04 17:40:33,681 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 740
2021-12-04 17:40:33,681 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 880
2021-12-04 17:40:33,681 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 727
2021-12-04 17:40:33,681 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 750
2021-12-04 17:40:33,681 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 809
2021-12-04 17:40:33,681 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 855
2021-12-04 17:40:33,681 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 832
2021-12-04 17:40:33,681 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 728
2021-12-04 17:40:33,681 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 854
2021-12-04 17:40:33,681 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 858
2021-12-04 17:40:33,681 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 879
2021-12-04 17:40:33,681 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 885
2021-12-04 17:40:33,681 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 840
2021-12-04 17:40:33,681 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 834
2021-12-04 17:40:33,682 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 833
2021-12-04 17:40:33,682 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 796
2021-12-04 17:40:33,682 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 731
2021-12-04 17:40:33,682 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 846
2021-12-04 17:40:33,682 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 825
2021-12-04 17:40:33,682 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 815
2021-12-04 17:40:33,682 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 829
2021-12-04 17:40:33,682 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 749
2021-12-04 17:40:33,682 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 729
2021-12-04 17:40:33,682 [dispatcher-event-loop-2] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_31_piece0 on qb:51947 in memory (size: 2.2 KB, free: 1990.7 MB)
2021-12-04 17:40:33,682 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 793
2021-12-04 17:40:33,682 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 883
2021-12-04 17:40:33,682 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 866
2021-12-04 17:40:33,682 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 852
2021-12-04 17:40:33,682 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 779
2021-12-04 17:40:33,682 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 875
2021-12-04 17:40:33,682 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 769
2021-12-04 17:40:33,682 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 847
2021-12-04 17:40:33,682 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 788
2021-12-04 17:40:33,682 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 871
2021-12-04 17:40:33,682 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 795
2021-12-04 17:40:33,682 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 816
2021-12-04 17:40:33,682 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 820
2021-12-04 17:40:33,682 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 828
2021-12-04 17:40:33,682 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 775
2021-12-04 17:40:33,682 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 827
2021-12-04 17:40:33,682 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 813
2021-12-04 17:40:33,682 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 886
2021-12-04 17:40:33,682 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 768
2021-12-04 17:40:33,682 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 761
2021-12-04 17:40:33,682 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 745
2021-12-04 17:40:33,682 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 837
2021-12-04 17:40:33,682 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 787
2021-12-04 17:40:33,683 [dispatcher-event-loop-1] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_35_piece0 on qb:51947 in memory (size: 2.3 KB, free: 1990.7 MB)
2021-12-04 17:40:33,683 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 859
2021-12-04 17:40:33,683 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 899
2021-12-04 17:40:33,683 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 814
2021-12-04 17:40:33,683 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 824
2021-12-04 17:40:33,683 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 789
2021-12-04 17:40:33,683 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 839
2021-12-04 17:40:33,683 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 806
2021-12-04 17:40:33,683 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 865
2021-12-04 17:40:33,683 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 881
2021-12-04 17:40:33,683 [dispatcher-event-loop-11] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_36_piece0 on qb:51947 in memory (size: 2.1 KB, free: 1990.7 MB)
2021-12-04 17:40:33,684 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 783
2021-12-04 17:40:34,544 [Executor task launch worker for task 90] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/order_data.bcp:0+3442194
2021-12-04 17:40:34,937 [Executor task launch worker for task 90] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/order_data.bcp:3442194+3442195
2021-12-04 17:40:35,457 [Executor task launch worker for task 90] INFO [org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter] - Saved output of task 'attempt_20211204174032_0066_m_000000_0' to hdfs://hdp1:8020/sk/chongqing/handle_data/set-train-device-production-data/_temporary/0/task_20211204174032_0066_m_000000
2021-12-04 17:40:35,458 [Executor task launch worker for task 90] INFO [org.apache.spark.mapred.SparkHadoopMapRedUtil] - attempt_20211204174032_0066_m_000000_0: Committed
2021-12-04 17:40:35,459 [Executor task launch worker for task 90] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 52.0 (TID 90). 998 bytes result sent to driver
2021-12-04 17:40:35,462 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 52.0 (TID 90) in 3048 ms on localhost (executor driver) (1/1)
2021-12-04 17:40:35,462 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 52.0, whose tasks have all completed, from pool 
2021-12-04 17:40:35,462 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 52 (runJob at SparkHadoopWriter.scala:78) finished in 3.061 s
2021-12-04 17:40:35,463 [main] INFO [org.apache.spark.scheduler.DAGScheduler] - Job 20 finished: runJob at SparkHadoopWriter.scala:78, took 3.062373 s
2021-12-04 17:40:35,521 [main] INFO [org.apache.spark.internal.io.SparkHadoopWriter] - Job job_20211204174032_0066 committed.
2021-12-04 17:40:35,526 [main] INFO [org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter] - File Output Committer Algorithm version is 1
2021-12-04 17:40:35,539 [main] INFO [org.apache.spark.SparkContext] - Starting job: runJob at SparkHadoopWriter.scala:78
2021-12-04 17:40:35,539 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 21 (runJob at SparkHadoopWriter.scala:78) with 1 output partitions
2021-12-04 17:40:35,539 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 53 (runJob at SparkHadoopWriter.scala:78)
2021-12-04 17:40:35,539 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List()
2021-12-04 17:40:35,539 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2021-12-04 17:40:35,539 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 53 (MapPartitionsRDD[69] at saveAsTextFile at PaidPromotionAdjustParameter.scala:182), which has no missing parents
2021-12-04 17:40:35,548 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_38 stored as values in memory (estimated size 258.4 KB, free 1989.9 MB)
2021-12-04 17:40:35,550 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_38_piece0 stored as bytes in memory (estimated size 93.0 KB, free 1989.8 MB)
2021-12-04 17:40:35,550 [dispatcher-event-loop-8] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_38_piece0 in memory on qb:51947 (size: 93.0 KB, free: 1990.6 MB)
2021-12-04 17:40:35,550 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 38 from broadcast at DAGScheduler.scala:1039
2021-12-04 17:40:35,551 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 53 (MapPartitionsRDD[69] at saveAsTextFile at PaidPromotionAdjustParameter.scala:182) (first 15 tasks are for partitions Vector(0))
2021-12-04 17:40:35,551 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 53.0 with 1 tasks
2021-12-04 17:40:35,551 [dispatcher-event-loop-7] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 53.0 (TID 91, localhost, executor driver, partition 0, ANY, 8337 bytes)
2021-12-04 17:40:35,551 [Executor task launch worker for task 91] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 53.0 (TID 91)
2021-12-04 17:40:35,557 [Executor task launch worker for task 91] INFO [org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter] - File Output Committer Algorithm version is 1
2021-12-04 17:40:35,565 [Executor task launch worker for task 91] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/order_data.bcp:0+3442194
2021-12-04 17:40:36,637 [Executor task launch worker for task 91] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/order_data.bcp:3442194+3442195
2021-12-04 17:40:37,102 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 906
2021-12-04 17:40:37,104 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 924
2021-12-04 17:40:37,104 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 909
2021-12-04 17:40:37,104 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 907
2021-12-04 17:40:37,104 [dispatcher-event-loop-0] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_37_piece0 on qb:51947 in memory (size: 93.3 KB, free: 1990.7 MB)
2021-12-04 17:40:37,104 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 901
2021-12-04 17:40:37,104 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 903
2021-12-04 17:40:37,105 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 910
2021-12-04 17:40:37,105 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 918
2021-12-04 17:40:37,105 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 915
2021-12-04 17:40:37,105 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 920
2021-12-04 17:40:37,105 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 917
2021-12-04 17:40:37,105 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 919
2021-12-04 17:40:37,105 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 904
2021-12-04 17:40:37,105 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 902
2021-12-04 17:40:37,105 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 922
2021-12-04 17:40:37,105 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 908
2021-12-04 17:40:37,105 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 916
2021-12-04 17:40:37,105 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 923
2021-12-04 17:40:37,105 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 905
2021-12-04 17:40:37,105 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 900
2021-12-04 17:40:37,105 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 911
2021-12-04 17:40:37,105 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 912
2021-12-04 17:40:37,105 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 921
2021-12-04 17:40:37,105 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 914
2021-12-04 17:40:37,105 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 913
2021-12-04 17:40:37,732 [Executor task launch worker for task 91] INFO [org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter] - Saved output of task 'attempt_20211204174035_0069_m_000000_0' to hdfs://hdp1:8020/sk/chongqing/handle_data/set-validation-device-production-data/_temporary/0/task_20211204174035_0069_m_000000
2021-12-04 17:40:37,732 [Executor task launch worker for task 91] INFO [org.apache.spark.mapred.SparkHadoopMapRedUtil] - attempt_20211204174035_0069_m_000000_0: Committed
2021-12-04 17:40:37,733 [Executor task launch worker for task 91] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 53.0 (TID 91). 955 bytes result sent to driver
2021-12-04 17:40:37,734 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 53.0 (TID 91) in 2183 ms on localhost (executor driver) (1/1)
2021-12-04 17:40:37,734 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 53.0, whose tasks have all completed, from pool 
2021-12-04 17:40:37,734 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 53 (runJob at SparkHadoopWriter.scala:78) finished in 2.194 s
2021-12-04 17:40:37,734 [main] INFO [org.apache.spark.scheduler.DAGScheduler] - Job 21 finished: runJob at SparkHadoopWriter.scala:78, took 2.195835 s
2021-12-04 17:40:37,784 [main] INFO [org.apache.spark.internal.io.SparkHadoopWriter] - Job job_20211204174035_0069 committed.
2021-12-04 17:40:37,796 [main] INFO [PaidPromotion$] - 验证集用户实际观看列表-----------------------------------
2021-12-04 17:40:37,797 [main] INFO [org.apache.spark.SparkContext] - Starting job: count at PaidPromotionAdjustParameter.scala:192
2021-12-04 17:40:37,797 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 33 (filter at PaidPromotionAdjustParameter.scala:150)
2021-12-04 17:40:37,797 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 22 (count at PaidPromotionAdjustParameter.scala:192) with 2 output partitions
2021-12-04 17:40:37,797 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 55 (count at PaidPromotionAdjustParameter.scala:192)
2021-12-04 17:40:37,797 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 54)
2021-12-04 17:40:37,798 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List(ShuffleMapStage 54)
2021-12-04 17:40:37,798 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ShuffleMapStage 54 (MapPartitionsRDD[33] at filter at PaidPromotionAdjustParameter.scala:150), which has no missing parents
2021-12-04 17:40:37,799 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_39 stored as values in memory (estimated size 183.8 KB, free 1989.9 MB)
2021-12-04 17:40:37,801 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_39_piece0 stored as bytes in memory (estimated size 65.0 KB, free 1989.9 MB)
2021-12-04 17:40:37,801 [dispatcher-event-loop-5] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_39_piece0 in memory on qb:51947 (size: 65.0 KB, free: 1990.6 MB)
2021-12-04 17:40:37,801 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 39 from broadcast at DAGScheduler.scala:1039
2021-12-04 17:40:37,801 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from ShuffleMapStage 54 (MapPartitionsRDD[33] at filter at PaidPromotionAdjustParameter.scala:150) (first 15 tasks are for partitions Vector(0, 1))
2021-12-04 17:40:37,801 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 54.0 with 2 tasks
2021-12-04 17:40:37,802 [dispatcher-event-loop-11] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 54.0 (TID 92, localhost, executor driver, partition 0, ANY, 7885 bytes)
2021-12-04 17:40:37,802 [dispatcher-event-loop-11] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 54.0 (TID 93, localhost, executor driver, partition 1, ANY, 7885 bytes)
2021-12-04 17:40:37,802 [Executor task launch worker for task 92] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 54.0 (TID 92)
2021-12-04 17:40:37,802 [Executor task launch worker for task 93] INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 54.0 (TID 93)
2021-12-04 17:40:37,804 [Executor task launch worker for task 92] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/order_data.bcp:0+3442194
2021-12-04 17:40:37,805 [Executor task launch worker for task 93] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/order_data.bcp:3442194+3442195
2021-12-04 17:40:38,930 [Executor task launch worker for task 93] INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 54.0 (TID 93). 860 bytes result sent to driver
2021-12-04 17:40:38,930 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 54.0 (TID 93) in 1128 ms on localhost (executor driver) (1/2)
2021-12-04 17:40:38,968 [Executor task launch worker for task 92] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 54.0 (TID 92). 860 bytes result sent to driver
2021-12-04 17:40:38,968 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 54.0 (TID 92) in 1166 ms on localhost (executor driver) (2/2)
2021-12-04 17:40:38,968 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 54.0, whose tasks have all completed, from pool 
2021-12-04 17:40:38,968 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ShuffleMapStage 54 (filter at PaidPromotionAdjustParameter.scala:150) finished in 1.170 s
2021-12-04 17:40:38,968 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - looking for newly runnable stages
2021-12-04 17:40:38,968 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - running: Set()
2021-12-04 17:40:38,968 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - waiting: Set(ResultStage 55)
2021-12-04 17:40:38,968 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - failed: Set()
2021-12-04 17:40:38,968 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 55 (MapPartitionsRDD[71] at map at PaidPromotionAdjustParameter.scala:186), which has no missing parents
2021-12-04 17:40:38,971 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_40 stored as values in memory (estimated size 184.7 KB, free 1989.7 MB)
2021-12-04 17:40:38,973 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_40_piece0 stored as bytes in memory (estimated size 65.3 KB, free 1989.6 MB)
2021-12-04 17:40:38,973 [dispatcher-event-loop-9] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_40_piece0 in memory on qb:51947 (size: 65.3 KB, free: 1990.6 MB)
2021-12-04 17:40:38,973 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 40 from broadcast at DAGScheduler.scala:1039
2021-12-04 17:40:38,973 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from ResultStage 55 (MapPartitionsRDD[71] at map at PaidPromotionAdjustParameter.scala:186) (first 15 tasks are for partitions Vector(0, 1))
2021-12-04 17:40:38,973 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 55.0 with 2 tasks
2021-12-04 17:40:38,974 [dispatcher-event-loop-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 55.0 (TID 94, localhost, executor driver, partition 0, ANY, 7649 bytes)
2021-12-04 17:40:38,974 [dispatcher-event-loop-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 55.0 (TID 95, localhost, executor driver, partition 1, ANY, 7649 bytes)
2021-12-04 17:40:38,974 [Executor task launch worker for task 95] INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 55.0 (TID 95)
2021-12-04 17:40:38,974 [Executor task launch worker for task 94] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 55.0 (TID 94)
2021-12-04 17:40:38,976 [Executor task launch worker for task 95] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 2 non-empty blocks out of 2 blocks
2021-12-04 17:40:38,976 [Executor task launch worker for task 94] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 2 non-empty blocks out of 2 blocks
2021-12-04 17:40:38,976 [Executor task launch worker for task 95] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-04 17:40:38,976 [Executor task launch worker for task 94] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-04 17:40:39,009 [Executor task launch worker for task 94] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 55.0 (TID 94). 1054 bytes result sent to driver
2021-12-04 17:40:39,009 [Executor task launch worker for task 95] INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 55.0 (TID 95). 1054 bytes result sent to driver
2021-12-04 17:40:39,009 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 55.0 (TID 94) in 35 ms on localhost (executor driver) (1/2)
2021-12-04 17:40:39,009 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 55.0 (TID 95) in 35 ms on localhost (executor driver) (2/2)
2021-12-04 17:40:39,009 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 55.0, whose tasks have all completed, from pool 
2021-12-04 17:40:39,010 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 55 (count at PaidPromotionAdjustParameter.scala:192) finished in 0.041 s
2021-12-04 17:40:39,010 [main] INFO [org.apache.spark.scheduler.DAGScheduler] - Job 22 finished: count at PaidPromotionAdjustParameter.scala:192, took 1.213417 s
2021-12-04 17:40:39,010 [main] INFO [PaidPromotion$] - 验证集用户列表数量：5104
2021-12-04 17:40:39,017 [main] INFO [org.apache.spark.SparkContext] - Starting job: take at PaidPromotionAdjustParameter.scala:193
2021-12-04 17:40:39,018 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 23 (take at PaidPromotionAdjustParameter.scala:193) with 1 output partitions
2021-12-04 17:40:39,018 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 57 (take at PaidPromotionAdjustParameter.scala:193)
2021-12-04 17:40:39,018 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 56)
2021-12-04 17:40:39,018 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2021-12-04 17:40:39,018 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 57 (MapPartitionsRDD[71] at map at PaidPromotionAdjustParameter.scala:186), which has no missing parents
2021-12-04 17:40:39,019 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_41 stored as values in memory (estimated size 184.8 KB, free 1989.5 MB)
2021-12-04 17:40:39,021 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_41_piece0 stored as bytes in memory (estimated size 65.3 KB, free 1989.4 MB)
2021-12-04 17:40:39,021 [dispatcher-event-loop-5] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_41_piece0 in memory on qb:51947 (size: 65.3 KB, free: 1990.5 MB)
2021-12-04 17:40:39,022 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 41 from broadcast at DAGScheduler.scala:1039
2021-12-04 17:40:39,022 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 57 (MapPartitionsRDD[71] at map at PaidPromotionAdjustParameter.scala:186) (first 15 tasks are for partitions Vector(0))
2021-12-04 17:40:39,022 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 57.0 with 1 tasks
2021-12-04 17:40:39,022 [dispatcher-event-loop-11] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 57.0 (TID 96, localhost, executor driver, partition 0, ANY, 7649 bytes)
2021-12-04 17:40:39,022 [Executor task launch worker for task 96] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 57.0 (TID 96)
2021-12-04 17:40:39,024 [Executor task launch worker for task 96] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 2 non-empty blocks out of 2 blocks
2021-12-04 17:40:39,024 [Executor task launch worker for task 96] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-04 17:40:39,038 [Executor task launch worker for task 96] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 57.0 (TID 96). 2653 bytes result sent to driver
2021-12-04 17:40:39,038 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 57.0 (TID 96) in 16 ms on localhost (executor driver) (1/1)
2021-12-04 17:40:39,038 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 57.0, whose tasks have all completed, from pool 
2021-12-04 17:40:39,039 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 57 (take at PaidPromotionAdjustParameter.scala:193) finished in 0.021 s
2021-12-04 17:40:39,039 [main] INFO [org.apache.spark.scheduler.DAGScheduler] - Job 23 finished: take at PaidPromotionAdjustParameter.scala:193, took 0.021281 s
2021-12-04 17:40:39,047 [main] INFO [PaidPromotion$] - 训练集用户实际观看列表-----------------------------------
2021-12-04 17:40:39,049 [main] INFO [org.apache.spark.SparkContext] - Starting job: count at PaidPromotionAdjustParameter.scala:203
2021-12-04 17:40:39,049 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 35 (union at PaidPromotionAdjustParameter.scala:154)
2021-12-04 17:40:39,049 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 24 (count at PaidPromotionAdjustParameter.scala:203) with 4 output partitions
2021-12-04 17:40:39,049 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 59 (count at PaidPromotionAdjustParameter.scala:203)
2021-12-04 17:40:39,049 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 58)
2021-12-04 17:40:39,049 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List(ShuffleMapStage 58)
2021-12-04 17:40:39,049 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ShuffleMapStage 58 (UnionRDD[35] at union at PaidPromotionAdjustParameter.scala:154), which has no missing parents
2021-12-04 17:40:39,051 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_42 stored as values in memory (estimated size 184.3 KB, free 1989.2 MB)
2021-12-04 17:40:39,052 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_42_piece0 stored as bytes in memory (estimated size 65.3 KB, free 1989.1 MB)
2021-12-04 17:40:39,053 [dispatcher-event-loop-8] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_42_piece0 in memory on qb:51947 (size: 65.3 KB, free: 1990.4 MB)
2021-12-04 17:40:39,053 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 42 from broadcast at DAGScheduler.scala:1039
2021-12-04 17:40:39,054 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 4 missing tasks from ShuffleMapStage 58 (UnionRDD[35] at union at PaidPromotionAdjustParameter.scala:154) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
2021-12-04 17:40:39,054 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 58.0 with 4 tasks
2021-12-04 17:40:39,054 [dispatcher-event-loop-7] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 58.0 (TID 97, localhost, executor driver, partition 0, ANY, 7994 bytes)
2021-12-04 17:40:39,054 [dispatcher-event-loop-7] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 58.0 (TID 98, localhost, executor driver, partition 1, ANY, 7994 bytes)
2021-12-04 17:40:39,054 [dispatcher-event-loop-7] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 2.0 in stage 58.0 (TID 99, localhost, executor driver, partition 2, ANY, 7994 bytes)
2021-12-04 17:40:39,054 [dispatcher-event-loop-7] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 3.0 in stage 58.0 (TID 100, localhost, executor driver, partition 3, ANY, 7994 bytes)
2021-12-04 17:40:39,054 [Executor task launch worker for task 97] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 58.0 (TID 97)
2021-12-04 17:40:39,054 [Executor task launch worker for task 99] INFO [org.apache.spark.executor.Executor] - Running task 2.0 in stage 58.0 (TID 99)
2021-12-04 17:40:39,054 [Executor task launch worker for task 100] INFO [org.apache.spark.executor.Executor] - Running task 3.0 in stage 58.0 (TID 100)
2021-12-04 17:40:39,054 [Executor task launch worker for task 98] INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 58.0 (TID 98)
2021-12-04 17:40:39,056 [Executor task launch worker for task 97] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/order_data.bcp:0+3442194
2021-12-04 17:40:39,056 [Executor task launch worker for task 100] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/order_data.bcp:3442194+3442195
2021-12-04 17:40:39,056 [Executor task launch worker for task 98] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/order_data.bcp:3442194+3442195
2021-12-04 17:40:39,056 [Executor task launch worker for task 99] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/order_data.bcp:0+3442194
2021-12-04 17:40:39,713 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 942
2021-12-04 17:40:39,713 [dispatcher-event-loop-5] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_41_piece0 on qb:51947 in memory (size: 65.3 KB, free: 1990.5 MB)
2021-12-04 17:40:39,714 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 946
2021-12-04 17:40:39,714 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 996
2021-12-04 17:40:39,714 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 969
2021-12-04 17:40:39,714 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 958
2021-12-04 17:40:39,714 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1021
2021-12-04 17:40:39,714 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 926
2021-12-04 17:40:39,714 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 970
2021-12-04 17:40:39,714 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 988
2021-12-04 17:40:39,714 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1015
2021-12-04 17:40:39,714 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1007
2021-12-04 17:40:39,714 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 992
2021-12-04 17:40:39,714 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1003
2021-12-04 17:40:39,714 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 999
2021-12-04 17:40:39,714 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 990
2021-12-04 17:40:39,714 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1011
2021-12-04 17:40:39,714 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 957
2021-12-04 17:40:39,714 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 963
2021-12-04 17:40:39,714 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 981
2021-12-04 17:40:39,714 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 935
2021-12-04 17:40:39,714 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 979
2021-12-04 17:40:39,714 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 952
2021-12-04 17:40:39,714 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 938
2021-12-04 17:40:39,714 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 937
2021-12-04 17:40:39,714 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1013
2021-12-04 17:40:39,714 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 932
2021-12-04 17:40:39,714 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 954
2021-12-04 17:40:39,714 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 931
2021-12-04 17:40:39,714 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1012
2021-12-04 17:40:39,714 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 968
2021-12-04 17:40:39,714 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 925
2021-12-04 17:40:39,714 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 936
2021-12-04 17:40:39,714 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 943
2021-12-04 17:40:39,714 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 941
2021-12-04 17:40:39,714 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 989
2021-12-04 17:40:39,714 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1000
2021-12-04 17:40:39,714 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 944
2021-12-04 17:40:39,714 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 973
2021-12-04 17:40:39,714 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 960
2021-12-04 17:40:39,714 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 994
2021-12-04 17:40:39,714 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 934
2021-12-04 17:40:39,714 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1020
2021-12-04 17:40:39,714 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 951
2021-12-04 17:40:39,714 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 965
2021-12-04 17:40:39,714 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1016
2021-12-04 17:40:39,715 [dispatcher-event-loop-6] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_40_piece0 on qb:51947 in memory (size: 65.3 KB, free: 1990.6 MB)
2021-12-04 17:40:39,715 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1023
2021-12-04 17:40:39,715 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 956
2021-12-04 17:40:39,715 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 971
2021-12-04 17:40:39,715 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 980
2021-12-04 17:40:39,715 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1008
2021-12-04 17:40:39,715 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 991
2021-12-04 17:40:39,715 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 940
2021-12-04 17:40:39,715 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 950
2021-12-04 17:40:39,715 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 978
2021-12-04 17:40:39,715 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 993
2021-12-04 17:40:39,715 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 975
2021-12-04 17:40:39,715 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 945
2021-12-04 17:40:39,715 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 933
2021-12-04 17:40:39,715 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 939
2021-12-04 17:40:39,715 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 959
2021-12-04 17:40:39,715 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1001
2021-12-04 17:40:39,715 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1009
2021-12-04 17:40:39,716 [dispatcher-event-loop-9] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_39_piece0 on qb:51947 in memory (size: 65.0 KB, free: 1990.6 MB)
2021-12-04 17:40:39,716 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1006
2021-12-04 17:40:39,716 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 997
2021-12-04 17:40:39,716 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 955
2021-12-04 17:40:39,716 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 972
2021-12-04 17:40:39,716 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 947
2021-12-04 17:40:39,716 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 967
2021-12-04 17:40:39,716 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 995
2021-12-04 17:40:39,716 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1018
2021-12-04 17:40:39,716 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 953
2021-12-04 17:40:39,716 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 974
2021-12-04 17:40:39,716 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 987
2021-12-04 17:40:39,716 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1024
2021-12-04 17:40:39,716 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 964
2021-12-04 17:40:39,716 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 948
2021-12-04 17:40:39,716 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 984
2021-12-04 17:40:39,716 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1019
2021-12-04 17:40:39,716 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 949
2021-12-04 17:40:39,716 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 985
2021-12-04 17:40:39,716 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1005
2021-12-04 17:40:39,716 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 928
2021-12-04 17:40:39,716 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1022
2021-12-04 17:40:39,716 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 927
2021-12-04 17:40:39,716 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 977
2021-12-04 17:40:39,716 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1017
2021-12-04 17:40:39,716 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1010
2021-12-04 17:40:39,716 [dispatcher-event-loop-0] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_38_piece0 on qb:51947 in memory (size: 93.0 KB, free: 1990.7 MB)
2021-12-04 17:40:39,717 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 983
2021-12-04 17:40:39,717 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 998
2021-12-04 17:40:39,717 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 929
2021-12-04 17:40:39,717 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 966
2021-12-04 17:40:39,717 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 930
2021-12-04 17:40:39,717 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 976
2021-12-04 17:40:39,717 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1014
2021-12-04 17:40:39,717 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 961
2021-12-04 17:40:39,717 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 986
2021-12-04 17:40:39,717 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1002
2021-12-04 17:40:39,717 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1004
2021-12-04 17:40:39,717 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 982
2021-12-04 17:40:39,717 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 962
2021-12-04 17:40:40,045 [Executor task launch worker for task 99] INFO [org.apache.spark.executor.Executor] - Finished task 2.0 in stage 58.0 (TID 99). 905 bytes result sent to driver
2021-12-04 17:40:40,046 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 2.0 in stage 58.0 (TID 99) in 992 ms on localhost (executor driver) (1/4)
2021-12-04 17:40:40,203 [Executor task launch worker for task 98] INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 58.0 (TID 98). 905 bytes result sent to driver
2021-12-04 17:40:40,204 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 58.0 (TID 98) in 1150 ms on localhost (executor driver) (2/4)
2021-12-04 17:40:40,293 [Executor task launch worker for task 97] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 58.0 (TID 97). 905 bytes result sent to driver
2021-12-04 17:40:40,293 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 58.0 (TID 97) in 1239 ms on localhost (executor driver) (3/4)
2021-12-04 17:40:40,343 [Executor task launch worker for task 100] INFO [org.apache.spark.executor.Executor] - Finished task 3.0 in stage 58.0 (TID 100). 905 bytes result sent to driver
2021-12-04 17:40:40,344 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 3.0 in stage 58.0 (TID 100) in 1290 ms on localhost (executor driver) (4/4)
2021-12-04 17:40:40,344 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 58.0, whose tasks have all completed, from pool 
2021-12-04 17:40:40,344 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ShuffleMapStage 58 (union at PaidPromotionAdjustParameter.scala:154) finished in 1.294 s
2021-12-04 17:40:40,344 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - looking for newly runnable stages
2021-12-04 17:40:40,344 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - running: Set()
2021-12-04 17:40:40,344 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - waiting: Set(ResultStage 59)
2021-12-04 17:40:40,344 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - failed: Set()
2021-12-04 17:40:40,344 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 59 (MapPartitionsRDD[73] at map at PaidPromotionAdjustParameter.scala:197), which has no missing parents
2021-12-04 17:40:40,345 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_43 stored as values in memory (estimated size 185.2 KB, free 1990.0 MB)
2021-12-04 17:40:40,347 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_43_piece0 stored as bytes in memory (estimated size 65.7 KB, free 1990.0 MB)
2021-12-04 17:40:40,347 [dispatcher-event-loop-7] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_43_piece0 in memory on qb:51947 (size: 65.7 KB, free: 1990.6 MB)
2021-12-04 17:40:40,347 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 43 from broadcast at DAGScheduler.scala:1039
2021-12-04 17:40:40,348 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 4 missing tasks from ResultStage 59 (MapPartitionsRDD[73] at map at PaidPromotionAdjustParameter.scala:197) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
2021-12-04 17:40:40,348 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 59.0 with 4 tasks
2021-12-04 17:40:40,348 [dispatcher-event-loop-8] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 59.0 (TID 101, localhost, executor driver, partition 0, ANY, 7649 bytes)
2021-12-04 17:40:40,348 [dispatcher-event-loop-8] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 59.0 (TID 102, localhost, executor driver, partition 1, ANY, 7649 bytes)
2021-12-04 17:40:40,348 [dispatcher-event-loop-8] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 2.0 in stage 59.0 (TID 103, localhost, executor driver, partition 2, ANY, 7649 bytes)
2021-12-04 17:40:40,348 [dispatcher-event-loop-8] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 3.0 in stage 59.0 (TID 104, localhost, executor driver, partition 3, ANY, 7649 bytes)
2021-12-04 17:40:40,348 [Executor task launch worker for task 102] INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 59.0 (TID 102)
2021-12-04 17:40:40,348 [Executor task launch worker for task 103] INFO [org.apache.spark.executor.Executor] - Running task 2.0 in stage 59.0 (TID 103)
2021-12-04 17:40:40,348 [Executor task launch worker for task 101] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 59.0 (TID 101)
2021-12-04 17:40:40,348 [Executor task launch worker for task 104] INFO [org.apache.spark.executor.Executor] - Running task 3.0 in stage 59.0 (TID 104)
2021-12-04 17:40:40,350 [Executor task launch worker for task 103] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 4 non-empty blocks out of 4 blocks
2021-12-04 17:40:40,350 [Executor task launch worker for task 101] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 4 non-empty blocks out of 4 blocks
2021-12-04 17:40:40,350 [Executor task launch worker for task 102] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 4 non-empty blocks out of 4 blocks
2021-12-04 17:40:40,350 [Executor task launch worker for task 101] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-04 17:40:40,350 [Executor task launch worker for task 103] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-04 17:40:40,350 [Executor task launch worker for task 102] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-04 17:40:40,351 [Executor task launch worker for task 104] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 4 non-empty blocks out of 4 blocks
2021-12-04 17:40:40,351 [Executor task launch worker for task 104] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-04 17:40:40,456 [dispatcher-event-loop-5] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_42_piece0 on qb:51947 in memory (size: 65.3 KB, free: 1990.7 MB)
2021-12-04 17:40:40,472 [Executor task launch worker for task 101] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 59.0 (TID 101). 1098 bytes result sent to driver
2021-12-04 17:40:40,472 [Executor task launch worker for task 104] INFO [org.apache.spark.executor.Executor] - Finished task 3.0 in stage 59.0 (TID 104). 1098 bytes result sent to driver
2021-12-04 17:40:40,472 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 59.0 (TID 101) in 124 ms on localhost (executor driver) (1/4)
2021-12-04 17:40:40,472 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 3.0 in stage 59.0 (TID 104) in 124 ms on localhost (executor driver) (2/4)
2021-12-04 17:40:40,473 [Executor task launch worker for task 103] INFO [org.apache.spark.executor.Executor] - Finished task 2.0 in stage 59.0 (TID 103). 1098 bytes result sent to driver
2021-12-04 17:40:40,473 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 2.0 in stage 59.0 (TID 103) in 125 ms on localhost (executor driver) (3/4)
2021-12-04 17:40:40,474 [Executor task launch worker for task 102] INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 59.0 (TID 102). 1098 bytes result sent to driver
2021-12-04 17:40:40,474 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 59.0 (TID 102) in 126 ms on localhost (executor driver) (4/4)
2021-12-04 17:40:40,474 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 59.0, whose tasks have all completed, from pool 
2021-12-04 17:40:40,474 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 59 (count at PaidPromotionAdjustParameter.scala:203) finished in 0.130 s
2021-12-04 17:40:40,474 [main] INFO [org.apache.spark.scheduler.DAGScheduler] - Job 24 finished: count at PaidPromotionAdjustParameter.scala:203, took 1.424628 s
2021-12-04 17:40:40,474 [main] INFO [PaidPromotion$] - 训练集用户列表数量：95323
2021-12-04 17:40:40,480 [main] INFO [org.apache.spark.SparkContext] - Starting job: take at PaidPromotionAdjustParameter.scala:204
2021-12-04 17:40:40,480 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 25 (take at PaidPromotionAdjustParameter.scala:204) with 1 output partitions
2021-12-04 17:40:40,480 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 61 (take at PaidPromotionAdjustParameter.scala:204)
2021-12-04 17:40:40,480 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 60)
2021-12-04 17:40:40,480 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2021-12-04 17:40:40,481 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 61 (MapPartitionsRDD[73] at map at PaidPromotionAdjustParameter.scala:197), which has no missing parents
2021-12-04 17:40:40,482 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_44 stored as values in memory (estimated size 185.4 KB, free 1990.0 MB)
2021-12-04 17:40:40,483 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_44_piece0 stored as bytes in memory (estimated size 65.8 KB, free 1990.0 MB)
2021-12-04 17:40:40,484 [dispatcher-event-loop-8] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_44_piece0 in memory on qb:51947 (size: 65.8 KB, free: 1990.6 MB)
2021-12-04 17:40:40,484 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 44 from broadcast at DAGScheduler.scala:1039
2021-12-04 17:40:40,484 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 61 (MapPartitionsRDD[73] at map at PaidPromotionAdjustParameter.scala:197) (first 15 tasks are for partitions Vector(0))
2021-12-04 17:40:40,484 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 61.0 with 1 tasks
2021-12-04 17:40:40,484 [dispatcher-event-loop-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 61.0 (TID 105, localhost, executor driver, partition 0, ANY, 7649 bytes)
2021-12-04 17:40:40,485 [Executor task launch worker for task 105] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 61.0 (TID 105)
2021-12-04 17:40:40,486 [Executor task launch worker for task 105] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 4 non-empty blocks out of 4 blocks
2021-12-04 17:40:40,486 [Executor task launch worker for task 105] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-04 17:40:40,517 [Executor task launch worker for task 105] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 61.0 (TID 105). 2386 bytes result sent to driver
2021-12-04 17:40:40,518 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 61.0 (TID 105) in 34 ms on localhost (executor driver) (1/1)
2021-12-04 17:40:40,518 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 61.0, whose tasks have all completed, from pool 
2021-12-04 17:40:40,518 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 61 (take at PaidPromotionAdjustParameter.scala:204) finished in 0.037 s
2021-12-04 17:40:40,518 [main] INFO [org.apache.spark.scheduler.DAGScheduler] - Job 25 finished: take at PaidPromotionAdjustParameter.scala:204, took 0.038867 s
2021-12-04 17:40:40,521 [main] INFO [org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter] - File Output Committer Algorithm version is 1
2021-12-04 17:40:40,548 [main] INFO [org.apache.spark.SparkContext] - Starting job: runJob at SparkHadoopWriter.scala:78
2021-12-04 17:40:40,549 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 26 (runJob at SparkHadoopWriter.scala:78) with 1 output partitions
2021-12-04 17:40:40,549 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 63 (runJob at SparkHadoopWriter.scala:78)
2021-12-04 17:40:40,549 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 62)
2021-12-04 17:40:40,549 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2021-12-04 17:40:40,549 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 63 (MapPartitionsRDD[75] at saveAsTextFile at PaidPromotionAdjustParameter.scala:206), which has no missing parents
2021-12-04 17:40:40,557 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_45 stored as values in memory (estimated size 261.1 KB, free 1989.7 MB)
2021-12-04 17:40:40,560 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_45_piece0 stored as bytes in memory (estimated size 94.2 KB, free 1989.6 MB)
2021-12-04 17:40:40,560 [dispatcher-event-loop-0] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_45_piece0 in memory on qb:51947 (size: 94.2 KB, free: 1990.6 MB)
2021-12-04 17:40:40,560 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 45 from broadcast at DAGScheduler.scala:1039
2021-12-04 17:40:40,561 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 63 (MapPartitionsRDD[75] at saveAsTextFile at PaidPromotionAdjustParameter.scala:206) (first 15 tasks are for partitions Vector(0))
2021-12-04 17:40:40,561 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 63.0 with 1 tasks
2021-12-04 17:40:40,561 [dispatcher-event-loop-4] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 63.0 (TID 106, localhost, executor driver, partition 0, ANY, 7943 bytes)
2021-12-04 17:40:40,561 [Executor task launch worker for task 106] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 63.0 (TID 106)
2021-12-04 17:40:40,567 [Executor task launch worker for task 106] INFO [org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter] - File Output Committer Algorithm version is 1
2021-12-04 17:40:40,574 [Executor task launch worker for task 106] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 2 non-empty blocks out of 2 blocks
2021-12-04 17:40:40,574 [Executor task launch worker for task 106] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-04 17:40:40,590 [Executor task launch worker for task 106] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 2 non-empty blocks out of 2 blocks
2021-12-04 17:40:40,590 [Executor task launch worker for task 106] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-04 17:40:40,740 [Executor task launch worker for task 106] INFO [org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter] - Saved output of task 'attempt_20211204174040_0075_m_000000_0' to hdfs://hdp1:8020/sk/chongqing/list/validation/_temporary/0/task_20211204174040_0075_m_000000
2021-12-04 17:40:40,740 [Executor task launch worker for task 106] INFO [org.apache.spark.mapred.SparkHadoopMapRedUtil] - attempt_20211204174040_0075_m_000000_0: Committed
2021-12-04 17:40:40,742 [Executor task launch worker for task 106] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 63.0 (TID 106). 1213 bytes result sent to driver
2021-12-04 17:40:40,742 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 63.0 (TID 106) in 181 ms on localhost (executor driver) (1/1)
2021-12-04 17:40:40,742 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 63.0, whose tasks have all completed, from pool 
2021-12-04 17:40:40,742 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 63 (runJob at SparkHadoopWriter.scala:78) finished in 0.193 s
2021-12-04 17:40:40,742 [main] INFO [org.apache.spark.scheduler.DAGScheduler] - Job 26 finished: runJob at SparkHadoopWriter.scala:78, took 0.193748 s
2021-12-04 17:40:40,792 [main] INFO [org.apache.spark.internal.io.SparkHadoopWriter] - Job job_20211204174040_0075 committed.
2021-12-04 17:40:40,794 [main] INFO [org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter] - File Output Committer Algorithm version is 1
2021-12-04 17:40:40,806 [main] INFO [org.apache.spark.SparkContext] - Starting job: runJob at SparkHadoopWriter.scala:78
2021-12-04 17:40:40,807 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 27 (runJob at SparkHadoopWriter.scala:78) with 1 output partitions
2021-12-04 17:40:40,807 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 65 (runJob at SparkHadoopWriter.scala:78)
2021-12-04 17:40:40,807 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 64)
2021-12-04 17:40:40,807 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2021-12-04 17:40:40,807 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 65 (MapPartitionsRDD[77] at saveAsTextFile at PaidPromotionAdjustParameter.scala:207), which has no missing parents
2021-12-04 17:40:40,815 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_46 stored as values in memory (estimated size 261.7 KB, free 1989.4 MB)
2021-12-04 17:40:40,817 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_46_piece0 stored as bytes in memory (estimated size 94.6 KB, free 1989.3 MB)
2021-12-04 17:40:40,817 [dispatcher-event-loop-11] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_46_piece0 in memory on qb:51947 (size: 94.6 KB, free: 1990.5 MB)
2021-12-04 17:40:40,817 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 46 from broadcast at DAGScheduler.scala:1039
2021-12-04 17:40:40,818 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 65 (MapPartitionsRDD[77] at saveAsTextFile at PaidPromotionAdjustParameter.scala:207) (first 15 tasks are for partitions Vector(0))
2021-12-04 17:40:40,818 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 65.0 with 1 tasks
2021-12-04 17:40:40,818 [dispatcher-event-loop-6] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 65.0 (TID 107, localhost, executor driver, partition 0, ANY, 7979 bytes)
2021-12-04 17:40:40,818 [Executor task launch worker for task 107] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 65.0 (TID 107)
2021-12-04 17:40:40,823 [Executor task launch worker for task 107] INFO [org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter] - File Output Committer Algorithm version is 1
2021-12-04 17:40:40,833 [Executor task launch worker for task 107] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 4 non-empty blocks out of 4 blocks
2021-12-04 17:40:40,833 [Executor task launch worker for task 107] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-04 17:40:40,887 [Executor task launch worker for task 107] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 4 non-empty blocks out of 4 blocks
2021-12-04 17:40:40,887 [Executor task launch worker for task 107] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-04 17:40:40,942 [Executor task launch worker for task 107] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 4 non-empty blocks out of 4 blocks
2021-12-04 17:40:40,942 [Executor task launch worker for task 107] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-04 17:40:41,000 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1049
2021-12-04 17:40:41,000 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1067
2021-12-04 17:40:41,000 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1068
2021-12-04 17:40:41,000 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1085
2021-12-04 17:40:41,000 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1109
2021-12-04 17:40:41,000 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1115
2021-12-04 17:40:41,000 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1073
2021-12-04 17:40:41,000 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1107
2021-12-04 17:40:41,000 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1048
2021-12-04 17:40:41,000 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1063
2021-12-04 17:40:41,000 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1051
2021-12-04 17:40:41,000 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1120
2021-12-04 17:40:41,000 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1095
2021-12-04 17:40:41,000 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1097
2021-12-04 17:40:41,000 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1104
2021-12-04 17:40:41,000 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1052
2021-12-04 17:40:41,000 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1079
2021-12-04 17:40:41,000 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1114
2021-12-04 17:40:41,000 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1103
2021-12-04 17:40:41,000 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1076
2021-12-04 17:40:41,000 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1118
2021-12-04 17:40:41,000 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1060
2021-12-04 17:40:41,000 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1087
2021-12-04 17:40:41,000 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1088
2021-12-04 17:40:41,000 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1039
2021-12-04 17:40:41,000 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1053
2021-12-04 17:40:41,000 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1070
2021-12-04 17:40:41,000 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1065
2021-12-04 17:40:41,000 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1059
2021-12-04 17:40:41,000 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1112
2021-12-04 17:40:41,000 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1090
2021-12-04 17:40:41,000 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1034
2021-12-04 17:40:41,000 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1025
2021-12-04 17:40:41,000 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1100
2021-12-04 17:40:41,000 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1054
2021-12-04 17:40:41,001 [dispatcher-event-loop-9] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_44_piece0 on qb:51947 in memory (size: 65.8 KB, free: 1990.5 MB)
2021-12-04 17:40:41,001 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1042
2021-12-04 17:40:41,001 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1031
2021-12-04 17:40:41,001 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1037
2021-12-04 17:40:41,001 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1040
2021-12-04 17:40:41,001 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1030
2021-12-04 17:40:41,001 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1123
2021-12-04 17:40:41,001 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1096
2021-12-04 17:40:41,001 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1044
2021-12-04 17:40:41,001 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1083
2021-12-04 17:40:41,001 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1099
2021-12-04 17:40:41,001 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1124
2021-12-04 17:40:41,001 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1035
2021-12-04 17:40:41,001 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1029
2021-12-04 17:40:41,001 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1026
2021-12-04 17:40:41,001 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1033
2021-12-04 17:40:41,001 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1110
2021-12-04 17:40:41,001 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1043
2021-12-04 17:40:41,001 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1117
2021-12-04 17:40:41,001 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1061
2021-12-04 17:40:41,001 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1089
2021-12-04 17:40:41,001 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1056
2021-12-04 17:40:41,001 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1105
2021-12-04 17:40:41,001 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1116
2021-12-04 17:40:41,002 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1032
2021-12-04 17:40:41,002 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1091
2021-12-04 17:40:41,002 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1081
2021-12-04 17:40:41,002 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1098
2021-12-04 17:40:41,002 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1047
2021-12-04 17:40:41,002 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1072
2021-12-04 17:40:41,002 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1075
2021-12-04 17:40:41,002 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1113
2021-12-04 17:40:41,002 [dispatcher-event-loop-4] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_45_piece0 on qb:51947 in memory (size: 94.2 KB, free: 1990.6 MB)
2021-12-04 17:40:41,002 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1057
2021-12-04 17:40:41,002 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1082
2021-12-04 17:40:41,002 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1086
2021-12-04 17:40:41,002 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1092
2021-12-04 17:40:41,002 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1119
2021-12-04 17:40:41,002 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1111
2021-12-04 17:40:41,002 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1106
2021-12-04 17:40:41,002 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1041
2021-12-04 17:40:41,002 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1062
2021-12-04 17:40:41,002 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1050
2021-12-04 17:40:41,002 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1058
2021-12-04 17:40:41,002 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1046
2021-12-04 17:40:41,002 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1077
2021-12-04 17:40:41,002 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1074
2021-12-04 17:40:41,003 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1064
2021-12-04 17:40:41,003 [dispatcher-event-loop-10] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_43_piece0 on qb:51947 in memory (size: 65.7 KB, free: 1990.7 MB)
2021-12-04 17:40:41,003 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1027
2021-12-04 17:40:41,003 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1078
2021-12-04 17:40:41,003 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1066
2021-12-04 17:40:41,003 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1122
2021-12-04 17:40:41,003 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1080
2021-12-04 17:40:41,003 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1093
2021-12-04 17:40:41,003 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1121
2021-12-04 17:40:41,003 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1069
2021-12-04 17:40:41,003 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1038
2021-12-04 17:40:41,003 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1084
2021-12-04 17:40:41,003 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1045
2021-12-04 17:40:41,003 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1036
2021-12-04 17:40:41,003 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1055
2021-12-04 17:40:41,003 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1108
2021-12-04 17:40:41,003 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1094
2021-12-04 17:40:41,003 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1071
2021-12-04 17:40:41,003 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1102
2021-12-04 17:40:41,003 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1101
2021-12-04 17:40:41,003 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1028
2021-12-04 17:40:41,004 [Executor task launch worker for task 107] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 4 non-empty blocks out of 4 blocks
2021-12-04 17:40:41,004 [Executor task launch worker for task 107] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-04 17:40:42,241 [Executor task launch worker for task 107] INFO [org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter] - Saved output of task 'attempt_20211204174040_0077_m_000000_0' to hdfs://hdp1:8020/sk/chongqing/list/train/_temporary/0/task_20211204174040_0077_m_000000
2021-12-04 17:40:42,241 [Executor task launch worker for task 107] INFO [org.apache.spark.mapred.SparkHadoopMapRedUtil] - attempt_20211204174040_0077_m_000000_0: Committed
2021-12-04 17:40:42,242 [Executor task launch worker for task 107] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 65.0 (TID 107). 1299 bytes result sent to driver
2021-12-04 17:40:42,242 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 65.0 (TID 107) in 1424 ms on localhost (executor driver) (1/1)
2021-12-04 17:40:42,242 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 65.0, whose tasks have all completed, from pool 
2021-12-04 17:40:42,242 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 65 (runJob at SparkHadoopWriter.scala:78) finished in 1.435 s
2021-12-04 17:40:42,243 [main] INFO [org.apache.spark.scheduler.DAGScheduler] - Job 27 finished: runJob at SparkHadoopWriter.scala:78, took 1.436051 s
2021-12-04 17:40:42,293 [main] INFO [org.apache.spark.internal.io.SparkHadoopWriter] - Job job_20211204174040_0077 committed.
2021-12-04 17:40:42,300 [main] INFO [org.spark_project.jetty.server.AbstractConnector] - Stopped Spark@5f7f2382{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2021-12-04 17:40:42,302 [main] INFO [org.apache.spark.ui.SparkUI] - Stopped Spark web UI at http://qb:4040
2021-12-04 17:40:42,309 [dispatcher-event-loop-8] INFO [org.apache.spark.MapOutputTrackerMasterEndpoint] - MapOutputTrackerMasterEndpoint stopped!
2021-12-04 17:40:42,388 [main] INFO [org.apache.spark.storage.memory.MemoryStore] - MemoryStore cleared
2021-12-04 17:40:42,388 [main] INFO [org.apache.spark.storage.BlockManager] - BlockManager stopped
2021-12-04 17:40:42,388 [main] INFO [org.apache.spark.storage.BlockManagerMaster] - BlockManagerMaster stopped
2021-12-04 17:40:42,390 [dispatcher-event-loop-5] INFO [org.apache.spark.scheduler.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint] - OutputCommitCoordinator stopped!
2021-12-04 17:40:42,393 [main] INFO [org.apache.spark.SparkContext] - Successfully stopped SparkContext
2021-12-04 17:40:42,394 [Thread-1] INFO [org.apache.spark.util.ShutdownHookManager] - Shutdown hook called
2021-12-04 17:40:42,395 [Thread-1] INFO [org.apache.spark.util.ShutdownHookManager] - Deleting directory C:\Users\ACER\AppData\Local\Temp\spark-c3aa98a9-ad8a-4e3a-9830-9cce1a485fcf
2021-12-04 22:43:09,454 [main] INFO [org.apache.spark.SparkContext] - Running Spark version 2.3.0
2021-12-04 22:43:09,755 [main] INFO [org.apache.spark.SparkContext] - Submitted application: PaidPromotion
2021-12-04 22:43:09,802 [main] INFO [org.apache.spark.SecurityManager] - Changing view acls to: ACER,root
2021-12-04 22:43:09,802 [main] INFO [org.apache.spark.SecurityManager] - Changing modify acls to: ACER,root
2021-12-04 22:43:09,802 [main] INFO [org.apache.spark.SecurityManager] - Changing view acls groups to: 
2021-12-04 22:43:09,803 [main] INFO [org.apache.spark.SecurityManager] - Changing modify acls groups to: 
2021-12-04 22:43:09,803 [main] INFO [org.apache.spark.SecurityManager] - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(ACER, root); groups with view permissions: Set(); users  with modify permissions: Set(ACER, root); groups with modify permissions: Set()
2021-12-04 22:43:10,377 [main] INFO [org.apache.spark.util.Utils] - Successfully started service 'sparkDriver' on port 60749.
2021-12-04 22:43:10,393 [main] INFO [org.apache.spark.SparkEnv] - Registering MapOutputTracker
2021-12-04 22:43:10,407 [main] INFO [org.apache.spark.SparkEnv] - Registering BlockManagerMaster
2021-12-04 22:43:10,410 [main] INFO [org.apache.spark.storage.BlockManagerMasterEndpoint] - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2021-12-04 22:43:10,410 [main] INFO [org.apache.spark.storage.BlockManagerMasterEndpoint] - BlockManagerMasterEndpoint up
2021-12-04 22:43:10,418 [main] INFO [org.apache.spark.storage.DiskBlockManager] - Created local directory at C:\Users\ACER\AppData\Local\Temp\blockmgr-59d71033-57c8-4fd8-8fc9-d2bed43dac4e
2021-12-04 22:43:10,433 [main] INFO [org.apache.spark.storage.memory.MemoryStore] - MemoryStore started with capacity 1990.8 MB
2021-12-04 22:43:10,442 [main] INFO [org.apache.spark.SparkEnv] - Registering OutputCommitCoordinator
2021-12-04 22:43:10,497 [main] INFO [org.spark_project.jetty.util.log] - Logging initialized @1982ms
2021-12-04 22:43:10,548 [main] INFO [org.spark_project.jetty.server.Server] - jetty-9.3.z-SNAPSHOT
2021-12-04 22:43:10,558 [main] INFO [org.spark_project.jetty.server.Server] - Started @2044ms
2021-12-04 22:43:10,582 [main] INFO [org.spark_project.jetty.server.AbstractConnector] - Started ServerConnector@5b800468{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2021-12-04 22:43:10,582 [main] INFO [org.apache.spark.util.Utils] - Successfully started service 'SparkUI' on port 4040.
2021-12-04 22:43:10,603 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@1568159{/jobs,null,AVAILABLE,@Spark}
2021-12-04 22:43:10,604 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@63cd604c{/jobs/json,null,AVAILABLE,@Spark}
2021-12-04 22:43:10,605 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@3954d008{/jobs/job,null,AVAILABLE,@Spark}
2021-12-04 22:43:10,606 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@6d8792db{/jobs/job/json,null,AVAILABLE,@Spark}
2021-12-04 22:43:10,607 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@3a1d593e{/stages,null,AVAILABLE,@Spark}
2021-12-04 22:43:10,608 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@285d851a{/stages/json,null,AVAILABLE,@Spark}
2021-12-04 22:43:10,609 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@7876d598{/stages/stage,null,AVAILABLE,@Spark}
2021-12-04 22:43:10,611 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@4985cbcb{/stages/stage/json,null,AVAILABLE,@Spark}
2021-12-04 22:43:10,612 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@54361a9{/stages/pool,null,AVAILABLE,@Spark}
2021-12-04 22:43:10,613 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@293bb8a5{/stages/pool/json,null,AVAILABLE,@Spark}
2021-12-04 22:43:10,614 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@290b1b2e{/storage,null,AVAILABLE,@Spark}
2021-12-04 22:43:10,615 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@5db4c359{/storage/json,null,AVAILABLE,@Spark}
2021-12-04 22:43:10,617 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@6fefce9e{/storage/rdd,null,AVAILABLE,@Spark}
2021-12-04 22:43:10,618 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@8a589a2{/storage/rdd/json,null,AVAILABLE,@Spark}
2021-12-04 22:43:10,620 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@5cc69cfe{/environment,null,AVAILABLE,@Spark}
2021-12-04 22:43:10,621 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@11dee337{/environment/json,null,AVAILABLE,@Spark}
2021-12-04 22:43:10,623 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@74bdc168{/executors,null,AVAILABLE,@Spark}
2021-12-04 22:43:10,624 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@7bb3a9fe{/executors/json,null,AVAILABLE,@Spark}
2021-12-04 22:43:10,625 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@f19c9d2{/executors/threadDump,null,AVAILABLE,@Spark}
2021-12-04 22:43:10,626 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@a77614d{/executors/threadDump/json,null,AVAILABLE,@Spark}
2021-12-04 22:43:10,632 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@523424b5{/static,null,AVAILABLE,@Spark}
2021-12-04 22:43:10,633 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@12cd9150{/,null,AVAILABLE,@Spark}
2021-12-04 22:43:10,635 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@32fe9d0a{/api,null,AVAILABLE,@Spark}
2021-12-04 22:43:10,636 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@59fc684e{/jobs/job/kill,null,AVAILABLE,@Spark}
2021-12-04 22:43:10,636 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@355e34c7{/stages/stage/kill,null,AVAILABLE,@Spark}
2021-12-04 22:43:10,638 [main] INFO [org.apache.spark.ui.SparkUI] - Bound SparkUI to 0.0.0.0, and started at http://qb:4040
2021-12-04 22:43:10,716 [main] INFO [org.apache.spark.executor.Executor] - Starting executor ID driver on host localhost
2021-12-04 22:43:10,761 [main] INFO [org.apache.spark.util.Utils] - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 60793.
2021-12-04 22:43:10,762 [main] INFO [org.apache.spark.network.netty.NettyBlockTransferService] - Server created on qb:60793
2021-12-04 22:43:10,763 [main] INFO [org.apache.spark.storage.BlockManager] - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2021-12-04 22:43:10,764 [main] INFO [org.apache.spark.storage.BlockManagerMaster] - Registering BlockManager BlockManagerId(driver, qb, 60793, None)
2021-12-04 22:43:10,766 [dispatcher-event-loop-10] INFO [org.apache.spark.storage.BlockManagerMasterEndpoint] - Registering block manager qb:60793 with 1990.8 MB RAM, BlockManagerId(driver, qb, 60793, None)
2021-12-04 22:43:10,767 [main] INFO [org.apache.spark.storage.BlockManagerMaster] - Registered BlockManager BlockManagerId(driver, qb, 60793, None)
2021-12-04 22:43:10,768 [main] INFO [org.apache.spark.storage.BlockManager] - Initialized BlockManager: BlockManagerId(driver, qb, 60793, None)
2021-12-04 22:43:10,881 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@6fe46b62{/metrics/json,null,AVAILABLE,@Spark}
2021-12-04 22:43:11,305 [main] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_0 stored as values in memory (estimated size 312.7 KB, free 1990.5 MB)
2021-12-04 22:43:11,490 [main] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_0_piece0 stored as bytes in memory (estimated size 27.3 KB, free 1990.5 MB)
2021-12-04 22:43:11,492 [dispatcher-event-loop-0] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_0_piece0 in memory on qb:60793 (size: 27.3 KB, free: 1990.8 MB)
2021-12-04 22:43:11,495 [main] INFO [org.apache.spark.SparkContext] - Created broadcast 0 from textFile at PaidPromotionAdjustParameter.scala:98
2021-12-04 22:43:11,801 [main] WARN [org.apache.hadoop.hdfs.shortcircuit.DomainSocketFactory] - The short-circuit local reads feature cannot be used because UNIX Domain sockets are not available on Windows.
2021-12-04 22:43:11,871 [main] INFO [org.apache.hadoop.mapred.FileInputFormat] - Total input paths to process : 1
2021-12-04 22:43:11,904 [main] INFO [org.apache.spark.SparkContext] - Starting job: count at PaidPromotionAdjustParameter.scala:100
2021-12-04 22:43:11,913 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 0 (count at PaidPromotionAdjustParameter.scala:100) with 2 output partitions
2021-12-04 22:43:11,914 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 0 (count at PaidPromotionAdjustParameter.scala:100)
2021-12-04 22:43:11,914 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List()
2021-12-04 22:43:11,915 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2021-12-04 22:43:11,920 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 0 (/sk/chongqing/data/order_data.bcp MapPartitionsRDD[1] at textFile at PaidPromotionAdjustParameter.scala:98), which has no missing parents
2021-12-04 22:43:11,950 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_1 stored as values in memory (estimated size 3.1 KB, free 1990.5 MB)
2021-12-04 22:43:11,955 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_1_piece0 stored as bytes in memory (estimated size 1900.0 B, free 1990.5 MB)
2021-12-04 22:43:11,956 [dispatcher-event-loop-1] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_1_piece0 in memory on qb:60793 (size: 1900.0 B, free: 1990.8 MB)
2021-12-04 22:43:11,956 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 1 from broadcast at DAGScheduler.scala:1039
2021-12-04 22:43:11,965 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from ResultStage 0 (/sk/chongqing/data/order_data.bcp MapPartitionsRDD[1] at textFile at PaidPromotionAdjustParameter.scala:98) (first 15 tasks are for partitions Vector(0, 1))
2021-12-04 22:43:11,966 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 0.0 with 2 tasks
2021-12-04 22:43:11,997 [dispatcher-event-loop-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 0.0 (TID 0, localhost, executor driver, partition 0, ANY, 7896 bytes)
2021-12-04 22:43:11,998 [dispatcher-event-loop-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 0.0 (TID 1, localhost, executor driver, partition 1, ANY, 7896 bytes)
2021-12-04 22:43:12,003 [Executor task launch worker for task 1] INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 0.0 (TID 1)
2021-12-04 22:43:12,003 [Executor task launch worker for task 0] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 0.0 (TID 0)
2021-12-04 22:43:12,041 [Executor task launch worker for task 0] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/order_data.bcp:0+3442194
2021-12-04 22:43:12,041 [Executor task launch worker for task 1] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/order_data.bcp:3442194+3442195
2021-12-04 22:43:12,784 [Executor task launch worker for task 0] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 0.0 (TID 0). 711 bytes result sent to driver
2021-12-04 22:43:12,793 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 0.0 (TID 0) in 804 ms on localhost (executor driver) (1/2)
2021-12-04 22:43:12,941 [Executor task launch worker for task 1] INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 0.0 (TID 1). 711 bytes result sent to driver
2021-12-04 22:43:12,945 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 0.0 (TID 1) in 947 ms on localhost (executor driver) (2/2)
2021-12-04 22:43:12,946 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 0.0, whose tasks have all completed, from pool 
2021-12-04 22:43:12,946 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 0 (count at PaidPromotionAdjustParameter.scala:100) finished in 1.012 s
2021-12-04 22:43:12,950 [main] INFO [org.apache.spark.scheduler.DAGScheduler] - Job 0 finished: count at PaidPromotionAdjustParameter.scala:100, took 1.046314 s
2021-12-04 22:43:12,951 [main] INFO [PaidPromotion$] - 订购总数107294
2021-12-04 22:43:12,956 [main] INFO [org.apache.spark.SparkContext] - Starting job: count at PaidPromotionAdjustParameter.scala:108
2021-12-04 22:43:12,957 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 1 (count at PaidPromotionAdjustParameter.scala:108) with 2 output partitions
2021-12-04 22:43:12,957 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 1 (count at PaidPromotionAdjustParameter.scala:108)
2021-12-04 22:43:12,957 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List()
2021-12-04 22:43:12,957 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2021-12-04 22:43:12,957 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 1 (MapPartitionsRDD[2] at map at PaidPromotionAdjustParameter.scala:104), which has no missing parents
2021-12-04 22:43:12,959 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_2 stored as values in memory (estimated size 3.3 KB, free 1990.5 MB)
2021-12-04 22:43:12,963 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_2_piece0 stored as bytes in memory (estimated size 1985.0 B, free 1990.5 MB)
2021-12-04 22:43:12,964 [dispatcher-event-loop-7] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_2_piece0 in memory on qb:60793 (size: 1985.0 B, free: 1990.8 MB)
2021-12-04 22:43:12,964 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 2 from broadcast at DAGScheduler.scala:1039
2021-12-04 22:43:12,965 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from ResultStage 1 (MapPartitionsRDD[2] at map at PaidPromotionAdjustParameter.scala:104) (first 15 tasks are for partitions Vector(0, 1))
2021-12-04 22:43:12,965 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 1.0 with 2 tasks
2021-12-04 22:43:12,966 [dispatcher-event-loop-8] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 1.0 (TID 2, localhost, executor driver, partition 0, ANY, 7896 bytes)
2021-12-04 22:43:12,966 [dispatcher-event-loop-8] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 1.0 (TID 3, localhost, executor driver, partition 1, ANY, 7896 bytes)
2021-12-04 22:43:12,966 [Executor task launch worker for task 2] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 1.0 (TID 2)
2021-12-04 22:43:12,966 [Executor task launch worker for task 3] INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 1.0 (TID 3)
2021-12-04 22:43:12,969 [Executor task launch worker for task 3] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/order_data.bcp:3442194+3442195
2021-12-04 22:43:12,969 [Executor task launch worker for task 2] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/order_data.bcp:0+3442194
2021-12-04 22:43:12,978 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 12
2021-12-04 22:43:12,978 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 21
2021-12-04 22:43:12,979 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 16
2021-12-04 22:43:12,979 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 6
2021-12-04 22:43:12,979 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 7
2021-12-04 22:43:12,979 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 2
2021-12-04 22:43:12,979 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 23
2021-12-04 22:43:12,979 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 3
2021-12-04 22:43:12,992 [dispatcher-event-loop-1] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_1_piece0 on qb:60793 in memory (size: 1900.0 B, free: 1990.8 MB)
2021-12-04 22:43:12,994 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 10
2021-12-04 22:43:12,994 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 22
2021-12-04 22:43:12,994 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 4
2021-12-04 22:43:12,994 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 17
2021-12-04 22:43:12,994 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 24
2021-12-04 22:43:12,995 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 19
2021-12-04 22:43:12,995 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 9
2021-12-04 22:43:12,995 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 13
2021-12-04 22:43:12,995 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 8
2021-12-04 22:43:12,995 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 14
2021-12-04 22:43:12,995 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 11
2021-12-04 22:43:12,995 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 15
2021-12-04 22:43:12,995 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1
2021-12-04 22:43:12,995 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 18
2021-12-04 22:43:12,995 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 0
2021-12-04 22:43:12,995 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 20
2021-12-04 22:43:12,995 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 5
2021-12-04 22:43:13,632 [Executor task launch worker for task 2] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 1.0 (TID 2). 754 bytes result sent to driver
2021-12-04 22:43:13,634 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 1.0 (TID 2) in 668 ms on localhost (executor driver) (1/2)
2021-12-04 22:43:13,666 [Executor task launch worker for task 3] INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 1.0 (TID 3). 754 bytes result sent to driver
2021-12-04 22:43:13,669 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 1.0 (TID 3) in 703 ms on localhost (executor driver) (2/2)
2021-12-04 22:43:13,669 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 1.0, whose tasks have all completed, from pool 
2021-12-04 22:43:13,669 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 1 (count at PaidPromotionAdjustParameter.scala:108) finished in 0.711 s
2021-12-04 22:43:13,669 [main] INFO [org.apache.spark.scheduler.DAGScheduler] - Job 1 finished: count at PaidPromotionAdjustParameter.scala:108, took 0.712868 s
2021-12-04 22:43:13,670 [main] INFO [PaidPromotion$] - 订购总数：107294
2021-12-04 22:43:13,683 [main] INFO [org.apache.spark.SparkContext] - Starting job: count at PaidPromotionAdjustParameter.scala:121
2021-12-04 22:43:13,683 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 2 (count at PaidPromotionAdjustParameter.scala:121) with 2 output partitions
2021-12-04 22:43:13,683 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 2 (count at PaidPromotionAdjustParameter.scala:121)
2021-12-04 22:43:13,683 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List()
2021-12-04 22:43:13,683 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2021-12-04 22:43:13,684 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 2 (MapPartitionsRDD[3] at randomSplit at PaidPromotionAdjustParameter.scala:114), which has no missing parents
2021-12-04 22:43:13,685 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_3 stored as values in memory (estimated size 3.6 KB, free 1990.5 MB)
2021-12-04 22:43:13,691 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 30
2021-12-04 22:43:13,691 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 33
2021-12-04 22:43:13,691 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 44
2021-12-04 22:43:13,691 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 48
2021-12-04 22:43:13,691 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 25
2021-12-04 22:43:13,691 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 34
2021-12-04 22:43:13,691 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 31
2021-12-04 22:43:13,691 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 29
2021-12-04 22:43:13,691 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 49
2021-12-04 22:43:13,691 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_3_piece0 stored as bytes in memory (estimated size 2.1 KB, free 1990.5 MB)
2021-12-04 22:43:13,691 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 45
2021-12-04 22:43:13,691 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 35
2021-12-04 22:43:13,691 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 37
2021-12-04 22:43:13,691 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 26
2021-12-04 22:43:13,692 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 39
2021-12-04 22:43:13,692 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 28
2021-12-04 22:43:13,692 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 32
2021-12-04 22:43:13,692 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 36
2021-12-04 22:43:13,692 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 38
2021-12-04 22:43:13,692 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 40
2021-12-04 22:43:13,692 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 27
2021-12-04 22:43:13,692 [dispatcher-event-loop-3] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_3_piece0 in memory on qb:60793 (size: 2.1 KB, free: 1990.8 MB)
2021-12-04 22:43:13,692 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 3 from broadcast at DAGScheduler.scala:1039
2021-12-04 22:43:13,693 [dispatcher-event-loop-7] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_2_piece0 on qb:60793 in memory (size: 1985.0 B, free: 1990.8 MB)
2021-12-04 22:43:13,693 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 46
2021-12-04 22:43:13,693 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 47
2021-12-04 22:43:13,693 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from ResultStage 2 (MapPartitionsRDD[3] at randomSplit at PaidPromotionAdjustParameter.scala:114) (first 15 tasks are for partitions Vector(0, 1))
2021-12-04 22:43:13,693 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 43
2021-12-04 22:43:13,693 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 2.0 with 2 tasks
2021-12-04 22:43:13,693 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 41
2021-12-04 22:43:13,693 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 42
2021-12-04 22:43:13,694 [dispatcher-event-loop-8] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 2.0 (TID 4, localhost, executor driver, partition 0, ANY, 7896 bytes)
2021-12-04 22:43:13,694 [dispatcher-event-loop-8] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 2.0 (TID 5, localhost, executor driver, partition 1, ANY, 7896 bytes)
2021-12-04 22:43:13,694 [Executor task launch worker for task 5] INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 2.0 (TID 5)
2021-12-04 22:43:13,694 [Executor task launch worker for task 4] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 2.0 (TID 4)
2021-12-04 22:43:13,697 [Executor task launch worker for task 4] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/order_data.bcp:0+3442194
2021-12-04 22:43:13,697 [Executor task launch worker for task 5] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/order_data.bcp:3442194+3442195
2021-12-04 22:43:14,259 [Executor task launch worker for task 4] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 2.0 (TID 4). 711 bytes result sent to driver
2021-12-04 22:43:14,260 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 2.0 (TID 4) in 566 ms on localhost (executor driver) (1/2)
2021-12-04 22:43:14,371 [Executor task launch worker for task 5] INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 2.0 (TID 5). 711 bytes result sent to driver
2021-12-04 22:43:14,372 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 2.0 (TID 5) in 678 ms on localhost (executor driver) (2/2)
2021-12-04 22:43:14,372 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 2.0, whose tasks have all completed, from pool 
2021-12-04 22:43:14,372 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 2 (count at PaidPromotionAdjustParameter.scala:121) finished in 0.688 s
2021-12-04 22:43:14,373 [main] INFO [org.apache.spark.scheduler.DAGScheduler] - Job 2 finished: count at PaidPromotionAdjustParameter.scala:121, took 0.690437 s
2021-12-04 22:43:14,373 [main] INFO [PaidPromotion$] - 初次切分训练集数量：57392
2021-12-04 22:43:14,375 [main] INFO [org.apache.spark.SparkContext] - Starting job: count at PaidPromotionAdjustParameter.scala:122
2021-12-04 22:43:14,375 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 3 (count at PaidPromotionAdjustParameter.scala:122) with 2 output partitions
2021-12-04 22:43:14,375 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 3 (count at PaidPromotionAdjustParameter.scala:122)
2021-12-04 22:43:14,375 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List()
2021-12-04 22:43:14,375 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2021-12-04 22:43:14,375 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 3 (MapPartitionsRDD[4] at randomSplit at PaidPromotionAdjustParameter.scala:114), which has no missing parents
2021-12-04 22:43:14,376 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_4 stored as values in memory (estimated size 3.6 KB, free 1990.5 MB)
2021-12-04 22:43:14,379 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_4_piece0 stored as bytes in memory (estimated size 2.1 KB, free 1990.5 MB)
2021-12-04 22:43:14,380 [dispatcher-event-loop-1] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_4_piece0 in memory on qb:60793 (size: 2.1 KB, free: 1990.8 MB)
2021-12-04 22:43:14,380 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 4 from broadcast at DAGScheduler.scala:1039
2021-12-04 22:43:14,380 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from ResultStage 3 (MapPartitionsRDD[4] at randomSplit at PaidPromotionAdjustParameter.scala:114) (first 15 tasks are for partitions Vector(0, 1))
2021-12-04 22:43:14,380 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 3.0 with 2 tasks
2021-12-04 22:43:14,381 [dispatcher-event-loop-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 3.0 (TID 6, localhost, executor driver, partition 0, ANY, 7896 bytes)
2021-12-04 22:43:14,381 [dispatcher-event-loop-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 3.0 (TID 7, localhost, executor driver, partition 1, ANY, 7896 bytes)
2021-12-04 22:43:14,381 [Executor task launch worker for task 7] INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 3.0 (TID 7)
2021-12-04 22:43:14,381 [Executor task launch worker for task 6] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 3.0 (TID 6)
2021-12-04 22:43:14,383 [Executor task launch worker for task 7] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/order_data.bcp:3442194+3442195
2021-12-04 22:43:14,384 [Executor task launch worker for task 6] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/order_data.bcp:0+3442194
2021-12-04 22:43:14,867 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 70
2021-12-04 22:43:14,867 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 56
2021-12-04 22:43:14,867 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 73
2021-12-04 22:43:14,867 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 72
2021-12-04 22:43:14,867 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 55
2021-12-04 22:43:14,867 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 59
2021-12-04 22:43:14,867 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 53
2021-12-04 22:43:14,868 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 71
2021-12-04 22:43:14,868 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 50
2021-12-04 22:43:14,868 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 64
2021-12-04 22:43:14,868 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 74
2021-12-04 22:43:14,868 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 63
2021-12-04 22:43:14,868 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 62
2021-12-04 22:43:14,868 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 61
2021-12-04 22:43:14,868 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 68
2021-12-04 22:43:14,869 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 60
2021-12-04 22:43:14,869 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 65
2021-12-04 22:43:14,869 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 66
2021-12-04 22:43:14,870 [dispatcher-event-loop-7] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_3_piece0 on qb:60793 in memory (size: 2.1 KB, free: 1990.8 MB)
2021-12-04 22:43:14,870 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 54
2021-12-04 22:43:14,870 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 57
2021-12-04 22:43:14,870 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 58
2021-12-04 22:43:14,870 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 67
2021-12-04 22:43:14,870 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 52
2021-12-04 22:43:14,870 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 69
2021-12-04 22:43:14,871 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 51
2021-12-04 22:43:15,275 [Executor task launch worker for task 7] INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 3.0 (TID 7). 754 bytes result sent to driver
2021-12-04 22:43:15,276 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 3.0 (TID 7) in 895 ms on localhost (executor driver) (1/2)
2021-12-04 22:43:15,818 [Executor task launch worker for task 6] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 3.0 (TID 6). 754 bytes result sent to driver
2021-12-04 22:43:15,819 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 3.0 (TID 6) in 1437 ms on localhost (executor driver) (2/2)
2021-12-04 22:43:15,819 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 3.0, whose tasks have all completed, from pool 
2021-12-04 22:43:15,819 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 3 (count at PaidPromotionAdjustParameter.scala:122) finished in 1.443 s
2021-12-04 22:43:15,819 [main] INFO [org.apache.spark.scheduler.DAGScheduler] - Job 3 finished: count at PaidPromotionAdjustParameter.scala:122, took 1.443973 s
2021-12-04 22:43:15,820 [main] INFO [PaidPromotion$] - 初次切分验证集数量：49902
2021-12-04 22:43:15,870 [main] INFO [PaidPromotion$] - -----------------------------------
2021-12-04 22:43:15,872 [main] INFO [org.apache.spark.SparkContext] - Starting job: count at PaidPromotionAdjustParameter.scala:138
2021-12-04 22:43:15,878 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 6 (distinct at PaidPromotionAdjustParameter.scala:128)
2021-12-04 22:43:15,878 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 4 (count at PaidPromotionAdjustParameter.scala:138) with 2 output partitions
2021-12-04 22:43:15,878 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 5 (count at PaidPromotionAdjustParameter.scala:138)
2021-12-04 22:43:15,878 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 4)
2021-12-04 22:43:15,879 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List(ShuffleMapStage 4)
2021-12-04 22:43:15,879 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ShuffleMapStage 4 (MapPartitionsRDD[6] at distinct at PaidPromotionAdjustParameter.scala:128), which has no missing parents
2021-12-04 22:43:15,888 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_5 stored as values in memory (estimated size 5.2 KB, free 1990.5 MB)
2021-12-04 22:43:15,890 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_5_piece0 stored as bytes in memory (estimated size 2.9 KB, free 1990.5 MB)
2021-12-04 22:43:15,891 [dispatcher-event-loop-9] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_5_piece0 in memory on qb:60793 (size: 2.9 KB, free: 1990.8 MB)
2021-12-04 22:43:15,891 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 5 from broadcast at DAGScheduler.scala:1039
2021-12-04 22:43:15,893 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from ShuffleMapStage 4 (MapPartitionsRDD[6] at distinct at PaidPromotionAdjustParameter.scala:128) (first 15 tasks are for partitions Vector(0, 1))
2021-12-04 22:43:15,893 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 4.0 with 2 tasks
2021-12-04 22:43:15,894 [dispatcher-event-loop-11] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 4.0 (TID 8, localhost, executor driver, partition 0, ANY, 7885 bytes)
2021-12-04 22:43:15,894 [dispatcher-event-loop-11] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 4.0 (TID 9, localhost, executor driver, partition 1, ANY, 7885 bytes)
2021-12-04 22:43:15,894 [Executor task launch worker for task 9] INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 4.0 (TID 9)
2021-12-04 22:43:15,894 [Executor task launch worker for task 8] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 4.0 (TID 8)
2021-12-04 22:43:15,898 [Executor task launch worker for task 9] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/order_data.bcp:3442194+3442195
2021-12-04 22:43:15,898 [Executor task launch worker for task 8] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/order_data.bcp:0+3442194
2021-12-04 22:43:16,194 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 76
2021-12-04 22:43:16,194 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 80
2021-12-04 22:43:16,194 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 82
2021-12-04 22:43:16,194 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 96
2021-12-04 22:43:16,194 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 88
2021-12-04 22:43:16,195 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 85
2021-12-04 22:43:16,195 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 89
2021-12-04 22:43:16,195 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 77
2021-12-04 22:43:16,195 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 84
2021-12-04 22:43:16,195 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 90
2021-12-04 22:43:16,195 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 75
2021-12-04 22:43:16,195 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 81
2021-12-04 22:43:16,195 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 95
2021-12-04 22:43:16,195 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 83
2021-12-04 22:43:16,195 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 86
2021-12-04 22:43:16,196 [dispatcher-event-loop-5] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_4_piece0 on qb:60793 in memory (size: 2.1 KB, free: 1990.8 MB)
2021-12-04 22:43:16,196 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 97
2021-12-04 22:43:16,196 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 91
2021-12-04 22:43:16,196 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 98
2021-12-04 22:43:16,196 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 78
2021-12-04 22:43:16,196 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 79
2021-12-04 22:43:16,197 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 93
2021-12-04 22:43:16,197 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 87
2021-12-04 22:43:16,197 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 99
2021-12-04 22:43:16,197 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 92
2021-12-04 22:43:16,197 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 94
2021-12-04 22:43:16,529 [Executor task launch worker for task 8] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 4.0 (TID 8). 1032 bytes result sent to driver
2021-12-04 22:43:16,542 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 4.0 (TID 8) in 649 ms on localhost (executor driver) (1/2)
2021-12-04 22:43:16,676 [Executor task launch worker for task 9] INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 4.0 (TID 9). 1032 bytes result sent to driver
2021-12-04 22:43:16,677 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 4.0 (TID 9) in 783 ms on localhost (executor driver) (2/2)
2021-12-04 22:43:16,677 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 4.0, whose tasks have all completed, from pool 
2021-12-04 22:43:16,677 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ShuffleMapStage 4 (distinct at PaidPromotionAdjustParameter.scala:128) finished in 0.796 s
2021-12-04 22:43:16,678 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - looking for newly runnable stages
2021-12-04 22:43:16,678 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - running: Set()
2021-12-04 22:43:16,678 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - waiting: Set(ResultStage 5)
2021-12-04 22:43:16,678 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - failed: Set()
2021-12-04 22:43:16,681 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 5 (MapPartitionsRDD[8] at distinct at PaidPromotionAdjustParameter.scala:128), which has no missing parents
2021-12-04 22:43:16,685 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_6 stored as values in memory (estimated size 3.7 KB, free 1990.5 MB)
2021-12-04 22:43:16,687 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_6_piece0 stored as bytes in memory (estimated size 2.2 KB, free 1990.5 MB)
2021-12-04 22:43:16,688 [dispatcher-event-loop-7] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_6_piece0 in memory on qb:60793 (size: 2.2 KB, free: 1990.8 MB)
2021-12-04 22:43:16,688 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 6 from broadcast at DAGScheduler.scala:1039
2021-12-04 22:43:16,688 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from ResultStage 5 (MapPartitionsRDD[8] at distinct at PaidPromotionAdjustParameter.scala:128) (first 15 tasks are for partitions Vector(0, 1))
2021-12-04 22:43:16,688 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 5.0 with 2 tasks
2021-12-04 22:43:16,689 [dispatcher-event-loop-8] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 5.0 (TID 10, localhost, executor driver, partition 0, ANY, 7649 bytes)
2021-12-04 22:43:16,689 [dispatcher-event-loop-8] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 5.0 (TID 11, localhost, executor driver, partition 1, ANY, 7649 bytes)
2021-12-04 22:43:16,690 [Executor task launch worker for task 11] INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 5.0 (TID 11)
2021-12-04 22:43:16,690 [Executor task launch worker for task 10] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 5.0 (TID 10)
2021-12-04 22:43:16,700 [Executor task launch worker for task 10] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 2 non-empty blocks out of 2 blocks
2021-12-04 22:43:16,700 [Executor task launch worker for task 11] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 2 non-empty blocks out of 2 blocks
2021-12-04 22:43:16,701 [Executor task launch worker for task 10] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 4 ms
2021-12-04 22:43:16,701 [Executor task launch worker for task 11] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 4 ms
2021-12-04 22:43:16,813 [Executor task launch worker for task 11] INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 5.0 (TID 11). 1055 bytes result sent to driver
2021-12-04 22:43:16,813 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 5.0 (TID 11) in 124 ms on localhost (executor driver) (1/2)
2021-12-04 22:43:16,814 [Executor task launch worker for task 10] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 5.0 (TID 10). 1055 bytes result sent to driver
2021-12-04 22:43:16,815 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 5.0 (TID 10) in 126 ms on localhost (executor driver) (2/2)
2021-12-04 22:43:16,815 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 5.0, whose tasks have all completed, from pool 
2021-12-04 22:43:16,815 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 5 (count at PaidPromotionAdjustParameter.scala:138) finished in 0.133 s
2021-12-04 22:43:16,816 [main] INFO [org.apache.spark.scheduler.DAGScheduler] - Job 4 finished: count at PaidPromotionAdjustParameter.scala:138, took 0.943196 s
2021-12-04 22:43:16,816 [main] INFO [PaidPromotion$] - 训练集用户数 = 53462
2021-12-04 22:43:16,819 [main] INFO [org.apache.spark.SparkContext] - Starting job: count at PaidPromotionAdjustParameter.scala:139
2021-12-04 22:43:16,819 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 10 (distinct at PaidPromotionAdjustParameter.scala:129)
2021-12-04 22:43:16,819 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 5 (count at PaidPromotionAdjustParameter.scala:139) with 2 output partitions
2021-12-04 22:43:16,819 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 7 (count at PaidPromotionAdjustParameter.scala:139)
2021-12-04 22:43:16,819 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 6)
2021-12-04 22:43:16,819 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List(ShuffleMapStage 6)
2021-12-04 22:43:16,820 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ShuffleMapStage 6 (MapPartitionsRDD[10] at distinct at PaidPromotionAdjustParameter.scala:129), which has no missing parents
2021-12-04 22:43:16,821 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_7 stored as values in memory (estimated size 5.2 KB, free 1990.4 MB)
2021-12-04 22:43:16,823 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_7_piece0 stored as bytes in memory (estimated size 2.9 KB, free 1990.4 MB)
2021-12-04 22:43:16,824 [dispatcher-event-loop-1] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_7_piece0 in memory on qb:60793 (size: 2.9 KB, free: 1990.8 MB)
2021-12-04 22:43:16,824 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 7 from broadcast at DAGScheduler.scala:1039
2021-12-04 22:43:16,825 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from ShuffleMapStage 6 (MapPartitionsRDD[10] at distinct at PaidPromotionAdjustParameter.scala:129) (first 15 tasks are for partitions Vector(0, 1))
2021-12-04 22:43:16,825 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 6.0 with 2 tasks
2021-12-04 22:43:16,826 [dispatcher-event-loop-4] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 6.0 (TID 12, localhost, executor driver, partition 0, ANY, 7885 bytes)
2021-12-04 22:43:16,826 [dispatcher-event-loop-4] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 6.0 (TID 13, localhost, executor driver, partition 1, ANY, 7885 bytes)
2021-12-04 22:43:16,826 [Executor task launch worker for task 13] INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 6.0 (TID 13)
2021-12-04 22:43:16,826 [Executor task launch worker for task 12] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 6.0 (TID 12)
2021-12-04 22:43:16,827 [Executor task launch worker for task 12] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/order_data.bcp:0+3442194
2021-12-04 22:43:16,827 [Executor task launch worker for task 13] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/order_data.bcp:3442194+3442195
2021-12-04 22:43:17,191 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 149
2021-12-04 22:43:17,191 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 119
2021-12-04 22:43:17,191 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 110
2021-12-04 22:43:17,191 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 121
2021-12-04 22:43:17,191 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 129
2021-12-04 22:43:17,191 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 131
2021-12-04 22:43:17,191 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 104
2021-12-04 22:43:17,191 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 140
2021-12-04 22:43:17,191 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 145
2021-12-04 22:43:17,191 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 117
2021-12-04 22:43:17,191 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 122
2021-12-04 22:43:17,192 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 101
2021-12-04 22:43:17,192 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 132
2021-12-04 22:43:17,192 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 118
2021-12-04 22:43:17,192 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 102
2021-12-04 22:43:17,192 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 133
2021-12-04 22:43:17,192 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 103
2021-12-04 22:43:17,192 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 144
2021-12-04 22:43:17,192 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 100
2021-12-04 22:43:17,193 [dispatcher-event-loop-7] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_6_piece0 on qb:60793 in memory (size: 2.2 KB, free: 1990.8 MB)
2021-12-04 22:43:17,193 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 138
2021-12-04 22:43:17,193 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 141
2021-12-04 22:43:17,193 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 114
2021-12-04 22:43:17,193 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 136
2021-12-04 22:43:17,193 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 143
2021-12-04 22:43:17,193 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 113
2021-12-04 22:43:17,193 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 142
2021-12-04 22:43:17,193 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 112
2021-12-04 22:43:17,193 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 123
2021-12-04 22:43:17,193 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 127
2021-12-04 22:43:17,193 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 124
2021-12-04 22:43:17,193 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 139
2021-12-04 22:43:17,193 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 116
2021-12-04 22:43:17,193 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 137
2021-12-04 22:43:17,193 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 147
2021-12-04 22:43:17,194 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 120
2021-12-04 22:43:17,194 [dispatcher-event-loop-10] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_5_piece0 on qb:60793 in memory (size: 2.9 KB, free: 1990.8 MB)
2021-12-04 22:43:17,194 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 134
2021-12-04 22:43:17,194 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 135
2021-12-04 22:43:17,194 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 128
2021-12-04 22:43:17,194 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 115
2021-12-04 22:43:17,194 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 105
2021-12-04 22:43:17,194 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 148
2021-12-04 22:43:17,194 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 106
2021-12-04 22:43:17,194 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 111
2021-12-04 22:43:17,194 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 126
2021-12-04 22:43:17,194 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 146
2021-12-04 22:43:17,195 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 108
2021-12-04 22:43:17,195 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 107
2021-12-04 22:43:17,195 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 109
2021-12-04 22:43:17,195 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 130
2021-12-04 22:43:17,195 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 125
2021-12-04 22:43:17,297 [Executor task launch worker for task 13] INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 6.0 (TID 13). 989 bytes result sent to driver
2021-12-04 22:43:17,298 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 6.0 (TID 13) in 472 ms on localhost (executor driver) (1/2)
2021-12-04 22:43:17,455 [Executor task launch worker for task 12] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 6.0 (TID 12). 989 bytes result sent to driver
2021-12-04 22:43:17,455 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 6.0 (TID 12) in 630 ms on localhost (executor driver) (2/2)
2021-12-04 22:43:17,455 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 6.0, whose tasks have all completed, from pool 
2021-12-04 22:43:17,456 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ShuffleMapStage 6 (distinct at PaidPromotionAdjustParameter.scala:129) finished in 0.636 s
2021-12-04 22:43:17,456 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - looking for newly runnable stages
2021-12-04 22:43:17,456 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - running: Set()
2021-12-04 22:43:17,456 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - waiting: Set(ResultStage 7)
2021-12-04 22:43:17,456 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - failed: Set()
2021-12-04 22:43:17,456 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 7 (MapPartitionsRDD[12] at distinct at PaidPromotionAdjustParameter.scala:129), which has no missing parents
2021-12-04 22:43:17,457 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_8 stored as values in memory (estimated size 3.7 KB, free 1990.5 MB)
2021-12-04 22:43:17,461 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_8_piece0 stored as bytes in memory (estimated size 2.2 KB, free 1990.5 MB)
2021-12-04 22:43:17,461 [dispatcher-event-loop-1] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_8_piece0 in memory on qb:60793 (size: 2.2 KB, free: 1990.8 MB)
2021-12-04 22:43:17,462 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 8 from broadcast at DAGScheduler.scala:1039
2021-12-04 22:43:17,462 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from ResultStage 7 (MapPartitionsRDD[12] at distinct at PaidPromotionAdjustParameter.scala:129) (first 15 tasks are for partitions Vector(0, 1))
2021-12-04 22:43:17,462 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 7.0 with 2 tasks
2021-12-04 22:43:17,463 [dispatcher-event-loop-4] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 7.0 (TID 14, localhost, executor driver, partition 0, ANY, 7649 bytes)
2021-12-04 22:43:17,463 [dispatcher-event-loop-4] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 7.0 (TID 15, localhost, executor driver, partition 1, ANY, 7649 bytes)
2021-12-04 22:43:17,463 [Executor task launch worker for task 14] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 7.0 (TID 14)
2021-12-04 22:43:17,463 [Executor task launch worker for task 15] INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 7.0 (TID 15)
2021-12-04 22:43:17,464 [Executor task launch worker for task 14] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 2 non-empty blocks out of 2 blocks
2021-12-04 22:43:17,464 [Executor task launch worker for task 14] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-04 22:43:17,464 [Executor task launch worker for task 15] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 2 non-empty blocks out of 2 blocks
2021-12-04 22:43:17,464 [Executor task launch worker for task 15] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-04 22:43:17,513 [Executor task launch worker for task 15] INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 7.0 (TID 15). 1055 bytes result sent to driver
2021-12-04 22:43:17,513 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 7.0 (TID 15) in 50 ms on localhost (executor driver) (1/2)
2021-12-04 22:43:17,513 [Executor task launch worker for task 14] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 7.0 (TID 14). 1055 bytes result sent to driver
2021-12-04 22:43:17,514 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 7.0 (TID 14) in 52 ms on localhost (executor driver) (2/2)
2021-12-04 22:43:17,514 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 7.0, whose tasks have all completed, from pool 
2021-12-04 22:43:17,514 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 7 (count at PaidPromotionAdjustParameter.scala:139) finished in 0.057 s
2021-12-04 22:43:17,514 [main] INFO [org.apache.spark.scheduler.DAGScheduler] - Job 5 finished: count at PaidPromotionAdjustParameter.scala:139, took 0.696009 s
2021-12-04 22:43:17,515 [main] INFO [PaidPromotion$] - 验证集用户数 = 46993
2021-12-04 22:43:17,520 [main] INFO [org.apache.spark.SparkContext] - Starting job: count at PaidPromotionAdjustParameter.scala:140
2021-12-04 22:43:17,521 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 13 (intersection at PaidPromotionAdjustParameter.scala:130)
2021-12-04 22:43:17,521 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 14 (intersection at PaidPromotionAdjustParameter.scala:130)
2021-12-04 22:43:17,521 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 6 (count at PaidPromotionAdjustParameter.scala:140) with 2 output partitions
2021-12-04 22:43:17,521 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 12 (count at PaidPromotionAdjustParameter.scala:140)
2021-12-04 22:43:17,521 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 9, ShuffleMapStage 11)
2021-12-04 22:43:17,522 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List(ShuffleMapStage 9, ShuffleMapStage 11)
2021-12-04 22:43:17,522 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ShuffleMapStage 9 (MapPartitionsRDD[13] at intersection at PaidPromotionAdjustParameter.scala:130), which has no missing parents
2021-12-04 22:43:17,524 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_9 stored as values in memory (estimated size 4.0 KB, free 1990.5 MB)
2021-12-04 22:43:17,526 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_9_piece0 stored as bytes in memory (estimated size 2.3 KB, free 1990.4 MB)
2021-12-04 22:43:17,527 [dispatcher-event-loop-7] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_9_piece0 in memory on qb:60793 (size: 2.3 KB, free: 1990.8 MB)
2021-12-04 22:43:17,527 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 9 from broadcast at DAGScheduler.scala:1039
2021-12-04 22:43:17,527 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from ShuffleMapStage 9 (MapPartitionsRDD[13] at intersection at PaidPromotionAdjustParameter.scala:130) (first 15 tasks are for partitions Vector(0, 1))
2021-12-04 22:43:17,528 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 9.0 with 2 tasks
2021-12-04 22:43:17,528 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ShuffleMapStage 11 (MapPartitionsRDD[14] at intersection at PaidPromotionAdjustParameter.scala:130), which has no missing parents
2021-12-04 22:43:17,528 [dispatcher-event-loop-9] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 9.0 (TID 16, localhost, executor driver, partition 0, ANY, 7638 bytes)
2021-12-04 22:43:17,528 [dispatcher-event-loop-9] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 9.0 (TID 17, localhost, executor driver, partition 1, ANY, 7638 bytes)
2021-12-04 22:43:17,528 [Executor task launch worker for task 16] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 9.0 (TID 16)
2021-12-04 22:43:17,528 [Executor task launch worker for task 17] INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 9.0 (TID 17)
2021-12-04 22:43:17,529 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_10 stored as values in memory (estimated size 4.0 KB, free 1990.4 MB)
2021-12-04 22:43:17,531 [Executor task launch worker for task 17] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 2 non-empty blocks out of 2 blocks
2021-12-04 22:43:17,531 [Executor task launch worker for task 17] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-04 22:43:17,531 [Executor task launch worker for task 16] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 2 non-empty blocks out of 2 blocks
2021-12-04 22:43:17,531 [Executor task launch worker for task 16] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-04 22:43:17,532 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_10_piece0 stored as bytes in memory (estimated size 2.3 KB, free 1990.4 MB)
2021-12-04 22:43:17,533 [dispatcher-event-loop-11] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_10_piece0 in memory on qb:60793 (size: 2.3 KB, free: 1990.8 MB)
2021-12-04 22:43:17,533 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 10 from broadcast at DAGScheduler.scala:1039
2021-12-04 22:43:17,533 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from ShuffleMapStage 11 (MapPartitionsRDD[14] at intersection at PaidPromotionAdjustParameter.scala:130) (first 15 tasks are for partitions Vector(0, 1))
2021-12-04 22:43:17,533 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 11.0 with 2 tasks
2021-12-04 22:43:17,534 [dispatcher-event-loop-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 11.0 (TID 18, localhost, executor driver, partition 0, ANY, 7638 bytes)
2021-12-04 22:43:17,534 [dispatcher-event-loop-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 11.0 (TID 19, localhost, executor driver, partition 1, ANY, 7638 bytes)
2021-12-04 22:43:17,535 [Executor task launch worker for task 18] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 11.0 (TID 18)
2021-12-04 22:43:17,535 [Executor task launch worker for task 19] INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 11.0 (TID 19)
2021-12-04 22:43:17,536 [Executor task launch worker for task 18] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 2 non-empty blocks out of 2 blocks
2021-12-04 22:43:17,536 [Executor task launch worker for task 18] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-04 22:43:17,536 [Executor task launch worker for task 19] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 2 non-empty blocks out of 2 blocks
2021-12-04 22:43:17,536 [Executor task launch worker for task 19] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-04 22:43:17,618 [Executor task launch worker for task 16] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 9.0 (TID 16). 1204 bytes result sent to driver
2021-12-04 22:43:17,619 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 9.0 (TID 16) in 90 ms on localhost (executor driver) (1/2)
2021-12-04 22:43:17,628 [Executor task launch worker for task 18] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 11.0 (TID 18). 1161 bytes result sent to driver
2021-12-04 22:43:17,629 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 11.0 (TID 18) in 95 ms on localhost (executor driver) (1/2)
2021-12-04 22:43:17,640 [Executor task launch worker for task 19] INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 11.0 (TID 19). 1204 bytes result sent to driver
2021-12-04 22:43:17,641 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 11.0 (TID 19) in 107 ms on localhost (executor driver) (2/2)
2021-12-04 22:43:17,641 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 11.0, whose tasks have all completed, from pool 
2021-12-04 22:43:17,641 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ShuffleMapStage 11 (intersection at PaidPromotionAdjustParameter.scala:130) finished in 0.113 s
2021-12-04 22:43:17,641 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - looking for newly runnable stages
2021-12-04 22:43:17,641 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - running: Set(ShuffleMapStage 9)
2021-12-04 22:43:17,641 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - waiting: Set(ResultStage 12)
2021-12-04 22:43:17,641 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - failed: Set()
2021-12-04 22:43:17,650 [Executor task launch worker for task 17] INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 9.0 (TID 17). 1204 bytes result sent to driver
2021-12-04 22:43:17,651 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 9.0 (TID 17) in 123 ms on localhost (executor driver) (2/2)
2021-12-04 22:43:17,651 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 9.0, whose tasks have all completed, from pool 
2021-12-04 22:43:17,652 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ShuffleMapStage 9 (intersection at PaidPromotionAdjustParameter.scala:130) finished in 0.129 s
2021-12-04 22:43:17,652 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - looking for newly runnable stages
2021-12-04 22:43:17,652 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - running: Set()
2021-12-04 22:43:17,652 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - waiting: Set(ResultStage 12)
2021-12-04 22:43:17,652 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - failed: Set()
2021-12-04 22:43:17,652 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 12 (MapPartitionsRDD[18] at intersection at PaidPromotionAdjustParameter.scala:130), which has no missing parents
2021-12-04 22:43:17,654 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_11 stored as values in memory (estimated size 3.6 KB, free 1990.4 MB)
2021-12-04 22:43:17,656 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_11_piece0 stored as bytes in memory (estimated size 2.1 KB, free 1990.4 MB)
2021-12-04 22:43:17,657 [dispatcher-event-loop-7] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_11_piece0 in memory on qb:60793 (size: 2.1 KB, free: 1990.8 MB)
2021-12-04 22:43:17,657 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 11 from broadcast at DAGScheduler.scala:1039
2021-12-04 22:43:17,658 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from ResultStage 12 (MapPartitionsRDD[18] at intersection at PaidPromotionAdjustParameter.scala:130) (first 15 tasks are for partitions Vector(0, 1))
2021-12-04 22:43:17,658 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 12.0 with 2 tasks
2021-12-04 22:43:17,659 [dispatcher-event-loop-9] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 12.0 (TID 20, localhost, executor driver, partition 0, PROCESS_LOCAL, 7712 bytes)
2021-12-04 22:43:17,659 [dispatcher-event-loop-9] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 12.0 (TID 21, localhost, executor driver, partition 1, PROCESS_LOCAL, 7712 bytes)
2021-12-04 22:43:17,660 [Executor task launch worker for task 20] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 12.0 (TID 20)
2021-12-04 22:43:17,660 [Executor task launch worker for task 21] INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 12.0 (TID 21)
2021-12-04 22:43:17,663 [Executor task launch worker for task 20] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2021-12-04 22:43:17,663 [Executor task launch worker for task 20] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-04 22:43:17,663 [Executor task launch worker for task 21] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2021-12-04 22:43:17,663 [Executor task launch worker for task 21] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-04 22:43:17,666 [Executor task launch worker for task 20] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2021-12-04 22:43:17,666 [Executor task launch worker for task 21] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2021-12-04 22:43:17,666 [Executor task launch worker for task 20] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-04 22:43:17,666 [Executor task launch worker for task 21] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-04 22:43:17,755 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 165
2021-12-04 22:43:17,756 [dispatcher-event-loop-1] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_7_piece0 on qb:60793 in memory (size: 2.9 KB, free: 1990.8 MB)
2021-12-04 22:43:17,757 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 171
2021-12-04 22:43:17,757 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 168
2021-12-04 22:43:17,757 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 169
2021-12-04 22:43:17,757 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 175
2021-12-04 22:43:17,757 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 192
2021-12-04 22:43:17,758 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 193
2021-12-04 22:43:17,758 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 159
2021-12-04 22:43:17,758 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 194
2021-12-04 22:43:17,759 [dispatcher-event-loop-2] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_8_piece0 on qb:60793 in memory (size: 2.2 KB, free: 1990.8 MB)
2021-12-04 22:43:17,759 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 195
2021-12-04 22:43:17,760 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 150
2021-12-04 22:43:17,760 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 153
2021-12-04 22:43:17,760 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 161
2021-12-04 22:43:17,760 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 174
2021-12-04 22:43:17,760 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 160
2021-12-04 22:43:17,760 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 196
2021-12-04 22:43:17,760 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 157
2021-12-04 22:43:17,760 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 197
2021-12-04 22:43:17,760 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 186
2021-12-04 22:43:17,760 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 188
2021-12-04 22:43:17,760 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 164
2021-12-04 22:43:17,760 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 156
2021-12-04 22:43:17,760 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 166
2021-12-04 22:43:17,760 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 155
2021-12-04 22:43:17,760 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 151
2021-12-04 22:43:17,760 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 180
2021-12-04 22:43:17,760 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 198
2021-12-04 22:43:17,760 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 158
2021-12-04 22:43:17,760 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 178
2021-12-04 22:43:17,761 [dispatcher-event-loop-7] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_10_piece0 on qb:60793 in memory (size: 2.3 KB, free: 1990.8 MB)
2021-12-04 22:43:17,761 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 172
2021-12-04 22:43:17,761 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 154
2021-12-04 22:43:17,761 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 176
2021-12-04 22:43:17,761 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 183
2021-12-04 22:43:17,761 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 152
2021-12-04 22:43:17,763 [dispatcher-event-loop-8] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_9_piece0 on qb:60793 in memory (size: 2.3 KB, free: 1990.8 MB)
2021-12-04 22:43:17,764 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 199
2021-12-04 22:43:17,764 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 179
2021-12-04 22:43:17,764 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 187
2021-12-04 22:43:17,764 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 170
2021-12-04 22:43:17,764 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 185
2021-12-04 22:43:17,764 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 191
2021-12-04 22:43:17,764 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 184
2021-12-04 22:43:17,764 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 190
2021-12-04 22:43:17,764 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 189
2021-12-04 22:43:17,764 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 167
2021-12-04 22:43:17,764 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 163
2021-12-04 22:43:17,764 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 162
2021-12-04 22:43:17,764 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 182
2021-12-04 22:43:17,764 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 177
2021-12-04 22:43:17,764 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 181
2021-12-04 22:43:17,764 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 173
2021-12-04 22:43:17,846 [Executor task launch worker for task 21] INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 12.0 (TID 21). 1097 bytes result sent to driver
2021-12-04 22:43:17,846 [Executor task launch worker for task 20] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 12.0 (TID 20). 1097 bytes result sent to driver
2021-12-04 22:43:17,847 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 12.0 (TID 21) in 188 ms on localhost (executor driver) (1/2)
2021-12-04 22:43:17,847 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 12.0 (TID 20) in 189 ms on localhost (executor driver) (2/2)
2021-12-04 22:43:17,847 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 12.0, whose tasks have all completed, from pool 
2021-12-04 22:43:17,847 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 12 (count at PaidPromotionAdjustParameter.scala:140) finished in 0.195 s
2021-12-04 22:43:17,848 [main] INFO [org.apache.spark.scheduler.DAGScheduler] - Job 6 finished: count at PaidPromotionAdjustParameter.scala:140, took 0.327315 s
2021-12-04 22:43:17,848 [main] INFO [PaidPromotion$] - 共 同 用户数 = 5132
2021-12-04 22:43:17,851 [main] INFO [org.apache.spark.SparkContext] - Starting job: count at PaidPromotionAdjustParameter.scala:141
2021-12-04 22:43:17,851 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 20 (distinct at PaidPromotionAdjustParameter.scala:133)
2021-12-04 22:43:17,851 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 7 (count at PaidPromotionAdjustParameter.scala:141) with 2 output partitions
2021-12-04 22:43:17,851 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 14 (count at PaidPromotionAdjustParameter.scala:141)
2021-12-04 22:43:17,851 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 13)
2021-12-04 22:43:17,851 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List(ShuffleMapStage 13)
2021-12-04 22:43:17,852 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ShuffleMapStage 13 (MapPartitionsRDD[20] at distinct at PaidPromotionAdjustParameter.scala:133), which has no missing parents
2021-12-04 22:43:17,853 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_12 stored as values in memory (estimated size 5.2 KB, free 1990.5 MB)
2021-12-04 22:43:17,855 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_12_piece0 stored as bytes in memory (estimated size 2.9 KB, free 1990.5 MB)
2021-12-04 22:43:17,856 [dispatcher-event-loop-1] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_12_piece0 in memory on qb:60793 (size: 2.9 KB, free: 1990.8 MB)
2021-12-04 22:43:17,856 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 12 from broadcast at DAGScheduler.scala:1039
2021-12-04 22:43:17,856 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from ShuffleMapStage 13 (MapPartitionsRDD[20] at distinct at PaidPromotionAdjustParameter.scala:133) (first 15 tasks are for partitions Vector(0, 1))
2021-12-04 22:43:17,856 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 13.0 with 2 tasks
2021-12-04 22:43:17,857 [dispatcher-event-loop-5] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 13.0 (TID 22, localhost, executor driver, partition 0, ANY, 7885 bytes)
2021-12-04 22:43:17,857 [dispatcher-event-loop-5] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 13.0 (TID 23, localhost, executor driver, partition 1, ANY, 7885 bytes)
2021-12-04 22:43:17,857 [Executor task launch worker for task 23] INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 13.0 (TID 23)
2021-12-04 22:43:17,857 [Executor task launch worker for task 22] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 13.0 (TID 22)
2021-12-04 22:43:17,859 [Executor task launch worker for task 23] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/order_data.bcp:3442194+3442195
2021-12-04 22:43:17,859 [Executor task launch worker for task 22] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/order_data.bcp:0+3442194
2021-12-04 22:43:18,235 [Executor task launch worker for task 22] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 13.0 (TID 22). 1032 bytes result sent to driver
2021-12-04 22:43:18,235 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 13.0 (TID 22) in 378 ms on localhost (executor driver) (1/2)
2021-12-04 22:43:18,731 [Executor task launch worker for task 23] INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 13.0 (TID 23). 989 bytes result sent to driver
2021-12-04 22:43:18,732 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 13.0 (TID 23) in 875 ms on localhost (executor driver) (2/2)
2021-12-04 22:43:18,732 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 13.0, whose tasks have all completed, from pool 
2021-12-04 22:43:18,732 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ShuffleMapStage 13 (distinct at PaidPromotionAdjustParameter.scala:133) finished in 0.880 s
2021-12-04 22:43:18,732 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - looking for newly runnable stages
2021-12-04 22:43:18,733 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - running: Set()
2021-12-04 22:43:18,733 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - waiting: Set(ResultStage 14)
2021-12-04 22:43:18,733 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - failed: Set()
2021-12-04 22:43:18,733 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 14 (MapPartitionsRDD[22] at distinct at PaidPromotionAdjustParameter.scala:133), which has no missing parents
2021-12-04 22:43:18,734 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_13 stored as values in memory (estimated size 3.7 KB, free 1990.5 MB)
2021-12-04 22:43:18,736 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_13_piece0 stored as bytes in memory (estimated size 2.2 KB, free 1990.4 MB)
2021-12-04 22:43:18,737 [dispatcher-event-loop-7] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_13_piece0 in memory on qb:60793 (size: 2.2 KB, free: 1990.8 MB)
2021-12-04 22:43:18,737 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 13 from broadcast at DAGScheduler.scala:1039
2021-12-04 22:43:18,738 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from ResultStage 14 (MapPartitionsRDD[22] at distinct at PaidPromotionAdjustParameter.scala:133) (first 15 tasks are for partitions Vector(0, 1))
2021-12-04 22:43:18,738 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 14.0 with 2 tasks
2021-12-04 22:43:18,738 [dispatcher-event-loop-10] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 14.0 (TID 24, localhost, executor driver, partition 0, ANY, 7649 bytes)
2021-12-04 22:43:18,738 [dispatcher-event-loop-10] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 14.0 (TID 25, localhost, executor driver, partition 1, ANY, 7649 bytes)
2021-12-04 22:43:18,738 [Executor task launch worker for task 24] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 14.0 (TID 24)
2021-12-04 22:43:18,738 [Executor task launch worker for task 25] INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 14.0 (TID 25)
2021-12-04 22:43:18,740 [Executor task launch worker for task 25] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 2 non-empty blocks out of 2 blocks
2021-12-04 22:43:18,740 [Executor task launch worker for task 24] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 2 non-empty blocks out of 2 blocks
2021-12-04 22:43:18,740 [Executor task launch worker for task 25] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-04 22:43:18,740 [Executor task launch worker for task 24] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-04 22:43:18,753 [Executor task launch worker for task 25] INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 14.0 (TID 25). 1053 bytes result sent to driver
2021-12-04 22:43:18,753 [Executor task launch worker for task 24] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 14.0 (TID 24). 1053 bytes result sent to driver
2021-12-04 22:43:18,753 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 14.0 (TID 25) in 15 ms on localhost (executor driver) (1/2)
2021-12-04 22:43:18,753 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 14.0 (TID 24) in 15 ms on localhost (executor driver) (2/2)
2021-12-04 22:43:18,753 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 14.0, whose tasks have all completed, from pool 
2021-12-04 22:43:18,754 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 14 (count at PaidPromotionAdjustParameter.scala:141) finished in 0.021 s
2021-12-04 22:43:18,754 [main] INFO [org.apache.spark.scheduler.DAGScheduler] - Job 7 finished: count at PaidPromotionAdjustParameter.scala:141, took 0.903113 s
2021-12-04 22:43:18,754 [main] INFO [PaidPromotion$] - 训练集节目数 = 120
2021-12-04 22:43:18,757 [main] INFO [org.apache.spark.SparkContext] - Starting job: count at PaidPromotionAdjustParameter.scala:142
2021-12-04 22:43:18,757 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 24 (distinct at PaidPromotionAdjustParameter.scala:134)
2021-12-04 22:43:18,757 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 8 (count at PaidPromotionAdjustParameter.scala:142) with 2 output partitions
2021-12-04 22:43:18,757 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 16 (count at PaidPromotionAdjustParameter.scala:142)
2021-12-04 22:43:18,757 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 15)
2021-12-04 22:43:18,757 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List(ShuffleMapStage 15)
2021-12-04 22:43:18,758 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ShuffleMapStage 15 (MapPartitionsRDD[24] at distinct at PaidPromotionAdjustParameter.scala:134), which has no missing parents
2021-12-04 22:43:18,759 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_14 stored as values in memory (estimated size 5.2 KB, free 1990.4 MB)
2021-12-04 22:43:18,762 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_14_piece0 stored as bytes in memory (estimated size 2.9 KB, free 1990.4 MB)
2021-12-04 22:43:18,762 [dispatcher-event-loop-1] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_14_piece0 in memory on qb:60793 (size: 2.9 KB, free: 1990.8 MB)
2021-12-04 22:43:18,762 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 14 from broadcast at DAGScheduler.scala:1039
2021-12-04 22:43:18,762 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from ShuffleMapStage 15 (MapPartitionsRDD[24] at distinct at PaidPromotionAdjustParameter.scala:134) (first 15 tasks are for partitions Vector(0, 1))
2021-12-04 22:43:18,763 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 15.0 with 2 tasks
2021-12-04 22:43:18,763 [dispatcher-event-loop-5] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 15.0 (TID 26, localhost, executor driver, partition 0, ANY, 7885 bytes)
2021-12-04 22:43:18,763 [dispatcher-event-loop-5] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 15.0 (TID 27, localhost, executor driver, partition 1, ANY, 7885 bytes)
2021-12-04 22:43:18,764 [Executor task launch worker for task 27] INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 15.0 (TID 27)
2021-12-04 22:43:18,764 [Executor task launch worker for task 26] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 15.0 (TID 26)
2021-12-04 22:43:18,765 [Executor task launch worker for task 26] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/order_data.bcp:0+3442194
2021-12-04 22:43:18,765 [Executor task launch worker for task 27] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/order_data.bcp:3442194+3442195
2021-12-04 22:43:18,892 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 285
2021-12-04 22:43:18,892 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 269
2021-12-04 22:43:18,892 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 297
2021-12-04 22:43:18,892 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 247
2021-12-04 22:43:18,892 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 277
2021-12-04 22:43:18,892 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 322
2021-12-04 22:43:18,892 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 211
2021-12-04 22:43:18,893 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 263
2021-12-04 22:43:18,893 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 323
2021-12-04 22:43:18,893 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 258
2021-12-04 22:43:18,893 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 294
2021-12-04 22:43:18,893 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 242
2021-12-04 22:43:18,893 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 215
2021-12-04 22:43:18,893 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 304
2021-12-04 22:43:18,893 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 313
2021-12-04 22:43:18,893 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 227
2021-12-04 22:43:18,893 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 231
2021-12-04 22:43:18,893 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 321
2021-12-04 22:43:18,893 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 220
2021-12-04 22:43:18,893 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 264
2021-12-04 22:43:18,893 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 309
2021-12-04 22:43:18,893 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 238
2021-12-04 22:43:18,893 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 307
2021-12-04 22:43:18,893 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 274
2021-12-04 22:43:18,893 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 286
2021-12-04 22:43:18,893 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 249
2021-12-04 22:43:18,893 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 232
2021-12-04 22:43:18,893 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 203
2021-12-04 22:43:18,893 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 292
2021-12-04 22:43:18,893 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 273
2021-12-04 22:43:18,893 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 210
2021-12-04 22:43:18,893 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 308
2021-12-04 22:43:18,893 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 260
2021-12-04 22:43:18,893 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 310
2021-12-04 22:43:18,893 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 312
2021-12-04 22:43:18,893 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 320
2021-12-04 22:43:18,893 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 202
2021-12-04 22:43:18,893 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 226
2021-12-04 22:43:18,893 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 262
2021-12-04 22:43:18,893 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 216
2021-12-04 22:43:18,893 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 218
2021-12-04 22:43:18,893 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 261
2021-12-04 22:43:18,893 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 246
2021-12-04 22:43:18,893 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 244
2021-12-04 22:43:18,893 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 224
2021-12-04 22:43:18,894 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 314
2021-12-04 22:43:18,894 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 316
2021-12-04 22:43:18,894 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 223
2021-12-04 22:43:18,894 [dispatcher-event-loop-7] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_13_piece0 on qb:60793 in memory (size: 2.2 KB, free: 1990.8 MB)
2021-12-04 22:43:18,895 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 267
2021-12-04 22:43:18,895 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 284
2021-12-04 22:43:18,895 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 278
2021-12-04 22:43:18,895 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 315
2021-12-04 22:43:18,895 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 256
2021-12-04 22:43:18,895 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 303
2021-12-04 22:43:18,895 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 235
2021-12-04 22:43:18,895 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 200
2021-12-04 22:43:18,895 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 265
2021-12-04 22:43:18,895 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 252
2021-12-04 22:43:18,895 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 237
2021-12-04 22:43:18,895 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 311
2021-12-04 22:43:18,895 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 239
2021-12-04 22:43:18,895 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 293
2021-12-04 22:43:18,895 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 276
2021-12-04 22:43:18,895 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 319
2021-12-04 22:43:18,895 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 236
2021-12-04 22:43:18,895 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 209
2021-12-04 22:43:18,895 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 207
2021-12-04 22:43:18,895 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 250
2021-12-04 22:43:18,895 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 287
2021-12-04 22:43:18,895 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 241
2021-12-04 22:43:18,895 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 205
2021-12-04 22:43:18,895 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 240
2021-12-04 22:43:18,895 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 206
2021-12-04 22:43:18,895 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 275
2021-12-04 22:43:18,895 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 317
2021-12-04 22:43:18,895 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 255
2021-12-04 22:43:18,895 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 222
2021-12-04 22:43:18,895 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 299
2021-12-04 22:43:18,895 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 300
2021-12-04 22:43:18,895 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 301
2021-12-04 22:43:18,896 [dispatcher-event-loop-8] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_12_piece0 on qb:60793 in memory (size: 2.9 KB, free: 1990.8 MB)
2021-12-04 22:43:18,897 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 271
2021-12-04 22:43:18,897 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 318
2021-12-04 22:43:18,897 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 251
2021-12-04 22:43:18,897 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 214
2021-12-04 22:43:18,897 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 283
2021-12-04 22:43:18,897 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 219
2021-12-04 22:43:18,897 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 280
2021-12-04 22:43:18,897 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 266
2021-12-04 22:43:18,897 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 282
2021-12-04 22:43:18,897 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 243
2021-12-04 22:43:18,897 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 257
2021-12-04 22:43:18,897 [dispatcher-event-loop-1] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_11_piece0 on qb:60793 in memory (size: 2.1 KB, free: 1990.8 MB)
2021-12-04 22:43:18,898 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 221
2021-12-04 22:43:18,898 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 324
2021-12-04 22:43:18,898 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 245
2021-12-04 22:43:18,898 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 259
2021-12-04 22:43:18,898 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 270
2021-12-04 22:43:18,898 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 302
2021-12-04 22:43:18,898 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 288
2021-12-04 22:43:18,898 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 254
2021-12-04 22:43:18,898 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 291
2021-12-04 22:43:18,898 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 230
2021-12-04 22:43:18,898 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 208
2021-12-04 22:43:18,898 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 295
2021-12-04 22:43:18,898 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 290
2021-12-04 22:43:18,898 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 204
2021-12-04 22:43:18,898 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 248
2021-12-04 22:43:18,898 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 306
2021-12-04 22:43:18,898 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 217
2021-12-04 22:43:18,898 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 225
2021-12-04 22:43:18,898 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 213
2021-12-04 22:43:18,898 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 268
2021-12-04 22:43:18,898 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 298
2021-12-04 22:43:18,898 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 296
2021-12-04 22:43:18,898 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 272
2021-12-04 22:43:18,898 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 233
2021-12-04 22:43:18,898 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 305
2021-12-04 22:43:18,898 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 234
2021-12-04 22:43:18,898 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 201
2021-12-04 22:43:18,898 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 212
2021-12-04 22:43:18,898 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 229
2021-12-04 22:43:18,898 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 281
2021-12-04 22:43:18,898 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 289
2021-12-04 22:43:18,898 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 253
2021-12-04 22:43:18,898 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 279
2021-12-04 22:43:18,898 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 228
2021-12-04 22:43:19,271 [Executor task launch worker for task 26] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 15.0 (TID 26). 1032 bytes result sent to driver
2021-12-04 22:43:19,271 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 15.0 (TID 26) in 508 ms on localhost (executor driver) (1/2)
2021-12-04 22:43:19,533 [Executor task launch worker for task 27] INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 15.0 (TID 27). 1075 bytes result sent to driver
2021-12-04 22:43:19,533 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 15.0 (TID 27) in 770 ms on localhost (executor driver) (2/2)
2021-12-04 22:43:19,533 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 15.0, whose tasks have all completed, from pool 
2021-12-04 22:43:19,533 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ShuffleMapStage 15 (distinct at PaidPromotionAdjustParameter.scala:134) finished in 0.775 s
2021-12-04 22:43:19,533 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - looking for newly runnable stages
2021-12-04 22:43:19,533 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - running: Set()
2021-12-04 22:43:19,533 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - waiting: Set(ResultStage 16)
2021-12-04 22:43:19,533 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - failed: Set()
2021-12-04 22:43:19,534 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 16 (MapPartitionsRDD[26] at distinct at PaidPromotionAdjustParameter.scala:134), which has no missing parents
2021-12-04 22:43:19,535 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_15 stored as values in memory (estimated size 3.7 KB, free 1990.5 MB)
2021-12-04 22:43:19,537 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_15_piece0 stored as bytes in memory (estimated size 2.2 KB, free 1990.5 MB)
2021-12-04 22:43:19,537 [dispatcher-event-loop-2] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_15_piece0 in memory on qb:60793 (size: 2.2 KB, free: 1990.8 MB)
2021-12-04 22:43:19,538 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 15 from broadcast at DAGScheduler.scala:1039
2021-12-04 22:43:19,538 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from ResultStage 16 (MapPartitionsRDD[26] at distinct at PaidPromotionAdjustParameter.scala:134) (first 15 tasks are for partitions Vector(0, 1))
2021-12-04 22:43:19,538 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 16.0 with 2 tasks
2021-12-04 22:43:19,538 [dispatcher-event-loop-6] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 16.0 (TID 28, localhost, executor driver, partition 0, ANY, 7649 bytes)
2021-12-04 22:43:19,539 [dispatcher-event-loop-6] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 16.0 (TID 29, localhost, executor driver, partition 1, ANY, 7649 bytes)
2021-12-04 22:43:19,539 [Executor task launch worker for task 28] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 16.0 (TID 28)
2021-12-04 22:43:19,539 [Executor task launch worker for task 29] INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 16.0 (TID 29)
2021-12-04 22:43:19,540 [Executor task launch worker for task 28] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 2 non-empty blocks out of 2 blocks
2021-12-04 22:43:19,540 [Executor task launch worker for task 29] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 2 non-empty blocks out of 2 blocks
2021-12-04 22:43:19,540 [Executor task launch worker for task 28] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-04 22:43:19,540 [Executor task launch worker for task 29] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-04 22:43:19,551 [Executor task launch worker for task 29] INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 16.0 (TID 29). 1010 bytes result sent to driver
2021-12-04 22:43:19,551 [Executor task launch worker for task 28] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 16.0 (TID 28). 1010 bytes result sent to driver
2021-12-04 22:43:19,552 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 16.0 (TID 29) in 13 ms on localhost (executor driver) (1/2)
2021-12-04 22:43:19,552 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 16.0 (TID 28) in 14 ms on localhost (executor driver) (2/2)
2021-12-04 22:43:19,552 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 16.0, whose tasks have all completed, from pool 
2021-12-04 22:43:19,552 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 16 (count at PaidPromotionAdjustParameter.scala:142) finished in 0.018 s
2021-12-04 22:43:19,552 [main] INFO [org.apache.spark.scheduler.DAGScheduler] - Job 8 finished: count at PaidPromotionAdjustParameter.scala:142, took 0.795076 s
2021-12-04 22:43:19,553 [main] INFO [PaidPromotion$] - 验证集节目数 = 120
2021-12-04 22:43:19,555 [main] INFO [org.apache.spark.SparkContext] - Starting job: count at PaidPromotionAdjustParameter.scala:143
2021-12-04 22:43:19,555 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 27 (intersection at PaidPromotionAdjustParameter.scala:135)
2021-12-04 22:43:19,556 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 28 (intersection at PaidPromotionAdjustParameter.scala:135)
2021-12-04 22:43:19,556 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 9 (count at PaidPromotionAdjustParameter.scala:143) with 2 output partitions
2021-12-04 22:43:19,556 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 21 (count at PaidPromotionAdjustParameter.scala:143)
2021-12-04 22:43:19,556 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 20, ShuffleMapStage 18)
2021-12-04 22:43:19,556 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List(ShuffleMapStage 20, ShuffleMapStage 18)
2021-12-04 22:43:19,556 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ShuffleMapStage 18 (MapPartitionsRDD[27] at intersection at PaidPromotionAdjustParameter.scala:135), which has no missing parents
2021-12-04 22:43:19,557 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_16 stored as values in memory (estimated size 4.0 KB, free 1990.5 MB)
2021-12-04 22:43:19,559 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_16_piece0 stored as bytes in memory (estimated size 2.3 KB, free 1990.4 MB)
2021-12-04 22:43:19,559 [dispatcher-event-loop-8] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_16_piece0 in memory on qb:60793 (size: 2.3 KB, free: 1990.8 MB)
2021-12-04 22:43:19,559 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 16 from broadcast at DAGScheduler.scala:1039
2021-12-04 22:43:19,560 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from ShuffleMapStage 18 (MapPartitionsRDD[27] at intersection at PaidPromotionAdjustParameter.scala:135) (first 15 tasks are for partitions Vector(0, 1))
2021-12-04 22:43:19,560 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 18.0 with 2 tasks
2021-12-04 22:43:19,560 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ShuffleMapStage 20 (MapPartitionsRDD[28] at intersection at PaidPromotionAdjustParameter.scala:135), which has no missing parents
2021-12-04 22:43:19,561 [dispatcher-event-loop-11] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 18.0 (TID 30, localhost, executor driver, partition 0, ANY, 7638 bytes)
2021-12-04 22:43:19,561 [dispatcher-event-loop-11] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 18.0 (TID 31, localhost, executor driver, partition 1, ANY, 7638 bytes)
2021-12-04 22:43:19,561 [Executor task launch worker for task 31] INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 18.0 (TID 31)
2021-12-04 22:43:19,561 [Executor task launch worker for task 30] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 18.0 (TID 30)
2021-12-04 22:43:19,561 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_17 stored as values in memory (estimated size 4.0 KB, free 1990.4 MB)
2021-12-04 22:43:19,562 [Executor task launch worker for task 30] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 2 non-empty blocks out of 2 blocks
2021-12-04 22:43:19,562 [Executor task launch worker for task 30] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-04 22:43:19,562 [Executor task launch worker for task 31] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 2 non-empty blocks out of 2 blocks
2021-12-04 22:43:19,562 [Executor task launch worker for task 31] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-04 22:43:19,563 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_17_piece0 stored as bytes in memory (estimated size 2.3 KB, free 1990.4 MB)
2021-12-04 22:43:19,563 [dispatcher-event-loop-5] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_17_piece0 in memory on qb:60793 (size: 2.3 KB, free: 1990.8 MB)
2021-12-04 22:43:19,563 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 17 from broadcast at DAGScheduler.scala:1039
2021-12-04 22:43:19,564 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from ShuffleMapStage 20 (MapPartitionsRDD[28] at intersection at PaidPromotionAdjustParameter.scala:135) (first 15 tasks are for partitions Vector(0, 1))
2021-12-04 22:43:19,564 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 20.0 with 2 tasks
2021-12-04 22:43:19,564 [dispatcher-event-loop-4] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 20.0 (TID 32, localhost, executor driver, partition 0, ANY, 7638 bytes)
2021-12-04 22:43:19,564 [dispatcher-event-loop-4] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 20.0 (TID 33, localhost, executor driver, partition 1, ANY, 7638 bytes)
2021-12-04 22:43:19,565 [Executor task launch worker for task 33] INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 20.0 (TID 33)
2021-12-04 22:43:19,565 [Executor task launch worker for task 32] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 20.0 (TID 32)
2021-12-04 22:43:19,566 [Executor task launch worker for task 32] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 2 non-empty blocks out of 2 blocks
2021-12-04 22:43:19,566 [Executor task launch worker for task 32] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 1 ms
2021-12-04 22:43:19,566 [Executor task launch worker for task 33] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 2 non-empty blocks out of 2 blocks
2021-12-04 22:43:19,566 [Executor task launch worker for task 33] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-04 22:43:19,578 [Executor task launch worker for task 30] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 18.0 (TID 30). 1204 bytes result sent to driver
2021-12-04 22:43:19,578 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 18.0 (TID 30) in 18 ms on localhost (executor driver) (1/2)
2021-12-04 22:43:19,579 [Executor task launch worker for task 31] INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 18.0 (TID 31). 1204 bytes result sent to driver
2021-12-04 22:43:19,579 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 18.0 (TID 31) in 18 ms on localhost (executor driver) (2/2)
2021-12-04 22:43:19,579 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 18.0, whose tasks have all completed, from pool 
2021-12-04 22:43:19,580 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ShuffleMapStage 18 (intersection at PaidPromotionAdjustParameter.scala:135) finished in 0.024 s
2021-12-04 22:43:19,580 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - looking for newly runnable stages
2021-12-04 22:43:19,580 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - running: Set(ShuffleMapStage 20)
2021-12-04 22:43:19,580 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - waiting: Set(ResultStage 21)
2021-12-04 22:43:19,580 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - failed: Set()
2021-12-04 22:43:19,580 [Executor task launch worker for task 32] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 20.0 (TID 32). 1118 bytes result sent to driver
2021-12-04 22:43:19,580 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 20.0 (TID 32) in 16 ms on localhost (executor driver) (1/2)
2021-12-04 22:43:19,581 [Executor task launch worker for task 33] INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 20.0 (TID 33). 1161 bytes result sent to driver
2021-12-04 22:43:19,581 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 20.0 (TID 33) in 17 ms on localhost (executor driver) (2/2)
2021-12-04 22:43:19,581 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 20.0, whose tasks have all completed, from pool 
2021-12-04 22:43:19,581 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ShuffleMapStage 20 (intersection at PaidPromotionAdjustParameter.scala:135) finished in 0.020 s
2021-12-04 22:43:19,581 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - looking for newly runnable stages
2021-12-04 22:43:19,581 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - running: Set()
2021-12-04 22:43:19,581 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - waiting: Set(ResultStage 21)
2021-12-04 22:43:19,581 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - failed: Set()
2021-12-04 22:43:19,582 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 21 (MapPartitionsRDD[32] at intersection at PaidPromotionAdjustParameter.scala:135), which has no missing parents
2021-12-04 22:43:19,583 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_18 stored as values in memory (estimated size 3.6 KB, free 1990.4 MB)
2021-12-04 22:43:19,585 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_18_piece0 stored as bytes in memory (estimated size 2.1 KB, free 1990.4 MB)
2021-12-04 22:43:19,586 [dispatcher-event-loop-8] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_18_piece0 in memory on qb:60793 (size: 2.1 KB, free: 1990.8 MB)
2021-12-04 22:43:19,586 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 18 from broadcast at DAGScheduler.scala:1039
2021-12-04 22:43:19,586 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from ResultStage 21 (MapPartitionsRDD[32] at intersection at PaidPromotionAdjustParameter.scala:135) (first 15 tasks are for partitions Vector(0, 1))
2021-12-04 22:43:19,586 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 21.0 with 2 tasks
2021-12-04 22:43:19,587 [dispatcher-event-loop-11] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 21.0 (TID 34, localhost, executor driver, partition 0, PROCESS_LOCAL, 7712 bytes)
2021-12-04 22:43:19,587 [dispatcher-event-loop-11] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 21.0 (TID 35, localhost, executor driver, partition 1, PROCESS_LOCAL, 7712 bytes)
2021-12-04 22:43:19,587 [Executor task launch worker for task 34] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 21.0 (TID 34)
2021-12-04 22:43:19,587 [Executor task launch worker for task 35] INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 21.0 (TID 35)
2021-12-04 22:43:19,588 [Executor task launch worker for task 34] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2021-12-04 22:43:19,588 [Executor task launch worker for task 35] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2021-12-04 22:43:19,588 [Executor task launch worker for task 34] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-04 22:43:19,588 [Executor task launch worker for task 35] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-04 22:43:19,590 [Executor task launch worker for task 34] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2021-12-04 22:43:19,590 [Executor task launch worker for task 35] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2021-12-04 22:43:19,590 [Executor task launch worker for task 34] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-04 22:43:19,590 [Executor task launch worker for task 35] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-04 22:43:19,597 [Executor task launch worker for task 35] INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 21.0 (TID 35). 1053 bytes result sent to driver
2021-12-04 22:43:19,597 [Executor task launch worker for task 34] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 21.0 (TID 34). 1053 bytes result sent to driver
2021-12-04 22:43:19,597 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 21.0 (TID 35) in 10 ms on localhost (executor driver) (1/2)
2021-12-04 22:43:19,597 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 21.0 (TID 34) in 10 ms on localhost (executor driver) (2/2)
2021-12-04 22:43:19,597 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 21.0, whose tasks have all completed, from pool 
2021-12-04 22:43:19,597 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 21 (count at PaidPromotionAdjustParameter.scala:143) finished in 0.015 s
2021-12-04 22:43:19,597 [main] INFO [org.apache.spark.scheduler.DAGScheduler] - Job 9 finished: count at PaidPromotionAdjustParameter.scala:143, took 0.042479 s
2021-12-04 22:43:19,597 [main] INFO [PaidPromotion$] - 共 同 节目数 = 108
2021-12-04 22:43:19,605 [main] INFO [org.apache.spark.SparkContext] - Starting job: collect at PaidPromotionAdjustParameter.scala:146
2021-12-04 22:43:19,605 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 10 (collect at PaidPromotionAdjustParameter.scala:146) with 2 output partitions
2021-12-04 22:43:19,605 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 26 (collect at PaidPromotionAdjustParameter.scala:146)
2021-12-04 22:43:19,605 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 25, ShuffleMapStage 23)
2021-12-04 22:43:19,605 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2021-12-04 22:43:19,605 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 26 (MapPartitionsRDD[18] at intersection at PaidPromotionAdjustParameter.scala:130), which has no missing parents
2021-12-04 22:43:19,606 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_19 stored as values in memory (estimated size 3.8 KB, free 1990.4 MB)
2021-12-04 22:43:19,608 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_19_piece0 stored as bytes in memory (estimated size 2.2 KB, free 1990.4 MB)
2021-12-04 22:43:19,609 [dispatcher-event-loop-6] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_19_piece0 in memory on qb:60793 (size: 2.2 KB, free: 1990.8 MB)
2021-12-04 22:43:19,609 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 19 from broadcast at DAGScheduler.scala:1039
2021-12-04 22:43:19,609 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from ResultStage 26 (MapPartitionsRDD[18] at intersection at PaidPromotionAdjustParameter.scala:130) (first 15 tasks are for partitions Vector(0, 1))
2021-12-04 22:43:19,609 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 26.0 with 2 tasks
2021-12-04 22:43:19,610 [dispatcher-event-loop-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 26.0 (TID 36, localhost, executor driver, partition 0, PROCESS_LOCAL, 7712 bytes)
2021-12-04 22:43:19,610 [dispatcher-event-loop-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 26.0 (TID 37, localhost, executor driver, partition 1, PROCESS_LOCAL, 7712 bytes)
2021-12-04 22:43:19,610 [Executor task launch worker for task 36] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 26.0 (TID 36)
2021-12-04 22:43:19,610 [Executor task launch worker for task 37] INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 26.0 (TID 37)
2021-12-04 22:43:19,611 [Executor task launch worker for task 36] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2021-12-04 22:43:19,611 [Executor task launch worker for task 36] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-04 22:43:19,611 [Executor task launch worker for task 37] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2021-12-04 22:43:19,611 [Executor task launch worker for task 37] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-04 22:43:19,613 [Executor task launch worker for task 37] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2021-12-04 22:43:19,613 [Executor task launch worker for task 37] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-04 22:43:19,613 [Executor task launch worker for task 36] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2021-12-04 22:43:19,613 [Executor task launch worker for task 36] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-04 22:43:19,723 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 356
2021-12-04 22:43:19,723 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 388
2021-12-04 22:43:19,723 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 351
2021-12-04 22:43:19,723 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 380
2021-12-04 22:43:19,723 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 377
2021-12-04 22:43:19,723 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 407
2021-12-04 22:43:19,723 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 357
2021-12-04 22:43:19,723 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 432
2021-12-04 22:43:19,723 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 429
2021-12-04 22:43:19,723 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 392
2021-12-04 22:43:19,724 [dispatcher-event-loop-8] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_15_piece0 on qb:60793 in memory (size: 2.2 KB, free: 1990.8 MB)
2021-12-04 22:43:19,724 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 446
2021-12-04 22:43:19,724 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 374
2021-12-04 22:43:19,724 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 337
2021-12-04 22:43:19,724 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 367
2021-12-04 22:43:19,724 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 422
2021-12-04 22:43:19,724 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 348
2021-12-04 22:43:19,724 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 366
2021-12-04 22:43:19,724 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 435
2021-12-04 22:43:19,724 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 401
2021-12-04 22:43:19,724 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 440
2021-12-04 22:43:19,724 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 331
2021-12-04 22:43:19,724 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 436
2021-12-04 22:43:19,724 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 414
2021-12-04 22:43:19,724 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 403
2021-12-04 22:43:19,724 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 420
2021-12-04 22:43:19,724 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 386
2021-12-04 22:43:19,724 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 419
2021-12-04 22:43:19,724 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 447
2021-12-04 22:43:19,724 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 339
2021-12-04 22:43:19,724 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 430
2021-12-04 22:43:19,724 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 353
2021-12-04 22:43:19,724 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 370
2021-12-04 22:43:19,724 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 397
2021-12-04 22:43:19,725 [dispatcher-event-loop-1] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_18_piece0 on qb:60793 in memory (size: 2.1 KB, free: 1990.8 MB)
2021-12-04 22:43:19,725 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 346
2021-12-04 22:43:19,725 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 441
2021-12-04 22:43:19,725 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 383
2021-12-04 22:43:19,725 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 378
2021-12-04 22:43:19,725 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 384
2021-12-04 22:43:19,725 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 442
2021-12-04 22:43:19,725 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 352
2021-12-04 22:43:19,725 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 393
2021-12-04 22:43:19,726 [dispatcher-event-loop-6] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_16_piece0 on qb:60793 in memory (size: 2.3 KB, free: 1990.8 MB)
2021-12-04 22:43:19,726 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 373
2021-12-04 22:43:19,726 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 372
2021-12-04 22:43:19,726 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 344
2021-12-04 22:43:19,726 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 445
2021-12-04 22:43:19,726 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 411
2021-12-04 22:43:19,726 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 379
2021-12-04 22:43:19,726 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 433
2021-12-04 22:43:19,726 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 363
2021-12-04 22:43:19,726 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 385
2021-12-04 22:43:19,726 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 333
2021-12-04 22:43:19,726 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 408
2021-12-04 22:43:19,726 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 418
2021-12-04 22:43:19,726 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 426
2021-12-04 22:43:19,726 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 382
2021-12-04 22:43:19,726 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 421
2021-12-04 22:43:19,726 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 334
2021-12-04 22:43:19,726 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 340
2021-12-04 22:43:19,726 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 417
2021-12-04 22:43:19,727 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 330
2021-12-04 22:43:19,727 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 326
2021-12-04 22:43:19,727 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 443
2021-12-04 22:43:19,727 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 396
2021-12-04 22:43:19,727 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 437
2021-12-04 22:43:19,727 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 347
2021-12-04 22:43:19,727 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 398
2021-12-04 22:43:19,727 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 424
2021-12-04 22:43:19,727 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 399
2021-12-04 22:43:19,727 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 413
2021-12-04 22:43:19,727 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 362
2021-12-04 22:43:19,727 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 368
2021-12-04 22:43:19,727 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 361
2021-12-04 22:43:19,727 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 434
2021-12-04 22:43:19,727 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 325
2021-12-04 22:43:19,727 [dispatcher-event-loop-7] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_17_piece0 on qb:60793 in memory (size: 2.3 KB, free: 1990.8 MB)
2021-12-04 22:43:19,727 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 425
2021-12-04 22:43:19,728 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 391
2021-12-04 22:43:19,728 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 416
2021-12-04 22:43:19,728 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 345
2021-12-04 22:43:19,728 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 381
2021-12-04 22:43:19,728 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 402
2021-12-04 22:43:19,728 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 444
2021-12-04 22:43:19,728 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 329
2021-12-04 22:43:19,728 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 358
2021-12-04 22:43:19,728 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 449
2021-12-04 22:43:19,728 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 438
2021-12-04 22:43:19,728 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 350
2021-12-04 22:43:19,728 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 349
2021-12-04 22:43:19,728 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 365
2021-12-04 22:43:19,728 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 343
2021-12-04 22:43:19,728 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 387
2021-12-04 22:43:19,728 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 376
2021-12-04 22:43:19,728 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 359
2021-12-04 22:43:19,728 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 427
2021-12-04 22:43:19,728 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 369
2021-12-04 22:43:19,728 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 404
2021-12-04 22:43:19,728 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 431
2021-12-04 22:43:19,728 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 355
2021-12-04 22:43:19,728 [dispatcher-event-loop-8] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_14_piece0 on qb:60793 in memory (size: 2.9 KB, free: 1990.8 MB)
2021-12-04 22:43:19,729 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 375
2021-12-04 22:43:19,729 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 415
2021-12-04 22:43:19,729 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 389
2021-12-04 22:43:19,729 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 406
2021-12-04 22:43:19,729 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 336
2021-12-04 22:43:19,729 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 371
2021-12-04 22:43:19,729 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 338
2021-12-04 22:43:19,729 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 332
2021-12-04 22:43:19,729 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 327
2021-12-04 22:43:19,729 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 390
2021-12-04 22:43:19,729 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 428
2021-12-04 22:43:19,729 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 412
2021-12-04 22:43:19,729 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 342
2021-12-04 22:43:19,729 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 394
2021-12-04 22:43:19,729 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 400
2021-12-04 22:43:19,729 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 395
2021-12-04 22:43:19,729 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 328
2021-12-04 22:43:19,729 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 341
2021-12-04 22:43:19,729 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 410
2021-12-04 22:43:19,729 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 354
2021-12-04 22:43:19,729 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 405
2021-12-04 22:43:19,729 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 360
2021-12-04 22:43:19,729 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 423
2021-12-04 22:43:19,729 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 335
2021-12-04 22:43:19,729 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 409
2021-12-04 22:43:19,729 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 448
2021-12-04 22:43:19,729 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 439
2021-12-04 22:43:19,729 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 364
2021-12-04 22:43:19,734 [Executor task launch worker for task 37] INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 26.0 (TID 37). 86686 bytes result sent to driver
2021-12-04 22:43:19,735 [Executor task launch worker for task 36] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 26.0 (TID 36). 85691 bytes result sent to driver
2021-12-04 22:43:19,735 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 26.0 (TID 37) in 125 ms on localhost (executor driver) (1/2)
2021-12-04 22:43:19,736 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 26.0 (TID 36) in 126 ms on localhost (executor driver) (2/2)
2021-12-04 22:43:19,736 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 26.0, whose tasks have all completed, from pool 
2021-12-04 22:43:19,736 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 26 (collect at PaidPromotionAdjustParameter.scala:146) finished in 0.130 s
2021-12-04 22:43:19,736 [main] INFO [org.apache.spark.scheduler.DAGScheduler] - Job 10 finished: collect at PaidPromotionAdjustParameter.scala:146, took 0.131298 s
2021-12-04 22:43:19,742 [main] INFO [org.apache.spark.SparkContext] - Starting job: collect at PaidPromotionAdjustParameter.scala:147
2021-12-04 22:43:19,742 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 11 (collect at PaidPromotionAdjustParameter.scala:147) with 2 output partitions
2021-12-04 22:43:19,743 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 31 (collect at PaidPromotionAdjustParameter.scala:147)
2021-12-04 22:43:19,743 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 30, ShuffleMapStage 28)
2021-12-04 22:43:19,743 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2021-12-04 22:43:19,743 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 31 (MapPartitionsRDD[32] at intersection at PaidPromotionAdjustParameter.scala:135), which has no missing parents
2021-12-04 22:43:19,743 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_20 stored as values in memory (estimated size 3.8 KB, free 1990.5 MB)
2021-12-04 22:43:19,745 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_20_piece0 stored as bytes in memory (estimated size 2.2 KB, free 1990.5 MB)
2021-12-04 22:43:19,745 [dispatcher-event-loop-1] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_20_piece0 in memory on qb:60793 (size: 2.2 KB, free: 1990.8 MB)
2021-12-04 22:43:19,746 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 20 from broadcast at DAGScheduler.scala:1039
2021-12-04 22:43:19,746 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from ResultStage 31 (MapPartitionsRDD[32] at intersection at PaidPromotionAdjustParameter.scala:135) (first 15 tasks are for partitions Vector(0, 1))
2021-12-04 22:43:19,746 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 31.0 with 2 tasks
2021-12-04 22:43:19,746 [dispatcher-event-loop-5] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 31.0 (TID 38, localhost, executor driver, partition 0, PROCESS_LOCAL, 7712 bytes)
2021-12-04 22:43:19,746 [dispatcher-event-loop-5] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 31.0 (TID 39, localhost, executor driver, partition 1, PROCESS_LOCAL, 7712 bytes)
2021-12-04 22:43:19,746 [Executor task launch worker for task 39] INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 31.0 (TID 39)
2021-12-04 22:43:19,746 [Executor task launch worker for task 38] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 31.0 (TID 38)
2021-12-04 22:43:19,747 [Executor task launch worker for task 39] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2021-12-04 22:43:19,747 [Executor task launch worker for task 38] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2021-12-04 22:43:19,747 [Executor task launch worker for task 39] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-04 22:43:19,747 [Executor task launch worker for task 38] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-04 22:43:19,749 [Executor task launch worker for task 39] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2021-12-04 22:43:19,749 [Executor task launch worker for task 38] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2021-12-04 22:43:19,749 [Executor task launch worker for task 39] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-04 22:43:19,749 [Executor task launch worker for task 38] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-04 22:43:19,754 [Executor task launch worker for task 39] INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 31.0 (TID 39). 2648 bytes result sent to driver
2021-12-04 22:43:19,755 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 31.0 (TID 39) in 9 ms on localhost (executor driver) (1/2)
2021-12-04 22:43:19,755 [Executor task launch worker for task 38] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 31.0 (TID 38). 2734 bytes result sent to driver
2021-12-04 22:43:19,755 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 31.0 (TID 38) in 9 ms on localhost (executor driver) (2/2)
2021-12-04 22:43:19,755 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 31.0, whose tasks have all completed, from pool 
2021-12-04 22:43:19,756 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 31 (collect at PaidPromotionAdjustParameter.scala:147) finished in 0.012 s
2021-12-04 22:43:19,756 [main] INFO [org.apache.spark.scheduler.DAGScheduler] - Job 11 finished: collect at PaidPromotionAdjustParameter.scala:147, took 0.013820 s
2021-12-04 22:43:19,777 [main] INFO [org.apache.spark.SparkContext] - Starting job: count at PaidPromotionAdjustParameter.scala:156
2021-12-04 22:43:19,778 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 12 (count at PaidPromotionAdjustParameter.scala:156) with 4 output partitions
2021-12-04 22:43:19,778 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 32 (count at PaidPromotionAdjustParameter.scala:156)
2021-12-04 22:43:19,778 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List()
2021-12-04 22:43:19,778 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2021-12-04 22:43:19,779 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 32 (UnionRDD[35] at union at PaidPromotionAdjustParameter.scala:154), which has no missing parents
2021-12-04 22:43:19,786 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_21 stored as values in memory (estimated size 183.1 KB, free 1990.3 MB)
2021-12-04 22:43:19,789 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_21_piece0 stored as bytes in memory (estimated size 64.6 KB, free 1990.2 MB)
2021-12-04 22:43:19,789 [dispatcher-event-loop-7] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_21_piece0 in memory on qb:60793 (size: 64.6 KB, free: 1990.7 MB)
2021-12-04 22:43:19,790 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 21 from broadcast at DAGScheduler.scala:1039
2021-12-04 22:43:19,790 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 4 missing tasks from ResultStage 32 (UnionRDD[35] at union at PaidPromotionAdjustParameter.scala:154) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
2021-12-04 22:43:19,790 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 32.0 with 4 tasks
2021-12-04 22:43:19,792 [dispatcher-event-loop-10] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 32.0 (TID 40, localhost, executor driver, partition 0, ANY, 8005 bytes)
2021-12-04 22:43:19,793 [dispatcher-event-loop-10] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 32.0 (TID 41, localhost, executor driver, partition 1, ANY, 8005 bytes)
2021-12-04 22:43:19,793 [dispatcher-event-loop-10] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 2.0 in stage 32.0 (TID 42, localhost, executor driver, partition 2, ANY, 8005 bytes)
2021-12-04 22:43:19,793 [dispatcher-event-loop-10] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 3.0 in stage 32.0 (TID 43, localhost, executor driver, partition 3, ANY, 8005 bytes)
2021-12-04 22:43:19,793 [Executor task launch worker for task 40] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 32.0 (TID 40)
2021-12-04 22:43:19,793 [Executor task launch worker for task 43] INFO [org.apache.spark.executor.Executor] - Running task 3.0 in stage 32.0 (TID 43)
2021-12-04 22:43:19,793 [Executor task launch worker for task 42] INFO [org.apache.spark.executor.Executor] - Running task 2.0 in stage 32.0 (TID 42)
2021-12-04 22:43:19,793 [Executor task launch worker for task 41] INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 32.0 (TID 41)
2021-12-04 22:43:19,796 [Executor task launch worker for task 43] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/order_data.bcp:3442194+3442195
2021-12-04 22:43:19,796 [Executor task launch worker for task 40] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/order_data.bcp:0+3442194
2021-12-04 22:43:19,797 [Executor task launch worker for task 41] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/order_data.bcp:3442194+3442195
2021-12-04 22:43:19,797 [Executor task launch worker for task 42] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/order_data.bcp:0+3442194
2021-12-04 22:43:20,291 [Executor task launch worker for task 43] INFO [org.apache.spark.executor.Executor] - Finished task 3.0 in stage 32.0 (TID 43). 754 bytes result sent to driver
2021-12-04 22:43:20,292 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 3.0 in stage 32.0 (TID 43) in 499 ms on localhost (executor driver) (1/4)
2021-12-04 22:43:21,331 [Executor task launch worker for task 41] INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 32.0 (TID 41). 754 bytes result sent to driver
2021-12-04 22:43:21,331 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 32.0 (TID 41) in 1539 ms on localhost (executor driver) (2/4)
2021-12-04 22:43:21,831 [Executor task launch worker for task 40] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 32.0 (TID 40). 754 bytes result sent to driver
2021-12-04 22:43:21,831 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 32.0 (TID 40) in 2041 ms on localhost (executor driver) (3/4)
2021-12-04 22:43:21,901 [Executor task launch worker for task 42] INFO [org.apache.spark.executor.Executor] - Finished task 2.0 in stage 32.0 (TID 42). 711 bytes result sent to driver
2021-12-04 22:43:21,902 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 2.0 in stage 32.0 (TID 42) in 2109 ms on localhost (executor driver) (4/4)
2021-12-04 22:43:21,902 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 32.0, whose tasks have all completed, from pool 
2021-12-04 22:43:21,902 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 32 (count at PaidPromotionAdjustParameter.scala:156) finished in 2.123 s
2021-12-04 22:43:21,902 [main] INFO [org.apache.spark.scheduler.DAGScheduler] - Job 12 finished: count at PaidPromotionAdjustParameter.scala:156, took 2.125434 s
2021-12-04 22:43:21,903 [main] INFO [PaidPromotion$] - 最终训练集数量：101189
2021-12-04 22:43:21,905 [main] INFO [org.apache.spark.SparkContext] - Starting job: count at PaidPromotionAdjustParameter.scala:157
2021-12-04 22:43:21,905 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 13 (count at PaidPromotionAdjustParameter.scala:157) with 2 output partitions
2021-12-04 22:43:21,905 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 33 (count at PaidPromotionAdjustParameter.scala:157)
2021-12-04 22:43:21,905 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List()
2021-12-04 22:43:21,905 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2021-12-04 22:43:21,905 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 33 (MapPartitionsRDD[33] at filter at PaidPromotionAdjustParameter.scala:150), which has no missing parents
2021-12-04 22:43:21,907 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_22 stored as values in memory (estimated size 182.6 KB, free 1990.0 MB)
2021-12-04 22:43:21,910 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_22_piece0 stored as bytes in memory (estimated size 64.3 KB, free 1990.0 MB)
2021-12-04 22:43:21,910 [dispatcher-event-loop-3] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_22_piece0 in memory on qb:60793 (size: 64.3 KB, free: 1990.6 MB)
2021-12-04 22:43:21,910 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 22 from broadcast at DAGScheduler.scala:1039
2021-12-04 22:43:21,911 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from ResultStage 33 (MapPartitionsRDD[33] at filter at PaidPromotionAdjustParameter.scala:150) (first 15 tasks are for partitions Vector(0, 1))
2021-12-04 22:43:21,911 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 33.0 with 2 tasks
2021-12-04 22:43:21,912 [dispatcher-event-loop-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 33.0 (TID 44, localhost, executor driver, partition 0, ANY, 7896 bytes)
2021-12-04 22:43:21,912 [dispatcher-event-loop-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 33.0 (TID 45, localhost, executor driver, partition 1, ANY, 7896 bytes)
2021-12-04 22:43:21,912 [Executor task launch worker for task 45] INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 33.0 (TID 45)
2021-12-04 22:43:21,912 [Executor task launch worker for task 44] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 33.0 (TID 44)
2021-12-04 22:43:21,914 [Executor task launch worker for task 45] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/order_data.bcp:3442194+3442195
2021-12-04 22:43:21,914 [Executor task launch worker for task 44] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/order_data.bcp:0+3442194
2021-12-04 22:43:21,954 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 488
2021-12-04 22:43:21,954 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 511
2021-12-04 22:43:21,954 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 456
2021-12-04 22:43:21,954 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 452
2021-12-04 22:43:21,954 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 484
2021-12-04 22:43:21,954 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 473
2021-12-04 22:43:21,954 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 469
2021-12-04 22:43:21,954 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 476
2021-12-04 22:43:21,954 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 471
2021-12-04 22:43:21,954 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 522
2021-12-04 22:43:21,954 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 515
2021-12-04 22:43:21,954 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 508
2021-12-04 22:43:21,954 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 485
2021-12-04 22:43:21,954 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 458
2021-12-04 22:43:21,954 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 465
2021-12-04 22:43:21,954 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 524
2021-12-04 22:43:21,954 [dispatcher-event-loop-0] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_19_piece0 on qb:60793 in memory (size: 2.2 KB, free: 1990.6 MB)
2021-12-04 22:43:21,955 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 453
2021-12-04 22:43:21,955 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 497
2021-12-04 22:43:21,955 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 483
2021-12-04 22:43:21,955 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 512
2021-12-04 22:43:21,955 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 494
2021-12-04 22:43:21,955 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 474
2021-12-04 22:43:21,955 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 459
2021-12-04 22:43:21,955 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 500
2021-12-04 22:43:21,955 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 520
2021-12-04 22:43:21,955 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 470
2021-12-04 22:43:21,955 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 457
2021-12-04 22:43:21,955 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 451
2021-12-04 22:43:21,955 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 466
2021-12-04 22:43:21,955 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 496
2021-12-04 22:43:21,955 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 503
2021-12-04 22:43:21,955 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 493
2021-12-04 22:43:21,955 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 516
2021-12-04 22:43:21,955 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 509
2021-12-04 22:43:21,955 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 517
2021-12-04 22:43:21,955 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 487
2021-12-04 22:43:21,955 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 463
2021-12-04 22:43:21,955 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 502
2021-12-04 22:43:21,955 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 495
2021-12-04 22:43:21,955 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 454
2021-12-04 22:43:21,955 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 468
2021-12-04 22:43:21,955 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 480
2021-12-04 22:43:21,955 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 479
2021-12-04 22:43:21,955 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 477
2021-12-04 22:43:21,955 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 486
2021-12-04 22:43:21,955 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 450
2021-12-04 22:43:21,955 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 490
2021-12-04 22:43:21,955 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 481
2021-12-04 22:43:21,955 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 498
2021-12-04 22:43:21,955 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 501
2021-12-04 22:43:21,955 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 464
2021-12-04 22:43:21,956 [dispatcher-event-loop-5] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_21_piece0 on qb:60793 in memory (size: 64.6 KB, free: 1990.7 MB)
2021-12-04 22:43:21,956 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 499
2021-12-04 22:43:21,956 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 478
2021-12-04 22:43:21,956 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 482
2021-12-04 22:43:21,956 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 491
2021-12-04 22:43:21,956 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 460
2021-12-04 22:43:21,956 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 489
2021-12-04 22:43:21,957 [dispatcher-event-loop-3] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_20_piece0 on qb:60793 in memory (size: 2.2 KB, free: 1990.7 MB)
2021-12-04 22:43:21,957 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 514
2021-12-04 22:43:21,957 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 518
2021-12-04 22:43:21,957 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 507
2021-12-04 22:43:21,957 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 475
2021-12-04 22:43:21,957 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 513
2021-12-04 22:43:21,957 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 521
2021-12-04 22:43:21,957 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 455
2021-12-04 22:43:21,957 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 519
2021-12-04 22:43:21,957 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 504
2021-12-04 22:43:21,957 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 492
2021-12-04 22:43:21,957 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 510
2021-12-04 22:43:21,957 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 461
2021-12-04 22:43:21,957 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 472
2021-12-04 22:43:21,957 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 505
2021-12-04 22:43:21,957 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 506
2021-12-04 22:43:21,957 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 523
2021-12-04 22:43:21,957 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 462
2021-12-04 22:43:21,957 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 467
2021-12-04 22:43:22,826 [Executor task launch worker for task 44] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 33.0 (TID 44). 753 bytes result sent to driver
2021-12-04 22:43:22,827 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 33.0 (TID 44) in 915 ms on localhost (executor driver) (1/2)
2021-12-04 22:43:23,134 [Executor task launch worker for task 45] INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 33.0 (TID 45). 753 bytes result sent to driver
2021-12-04 22:43:23,135 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 33.0 (TID 45) in 1223 ms on localhost (executor driver) (2/2)
2021-12-04 22:43:23,135 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 33.0, whose tasks have all completed, from pool 
2021-12-04 22:43:23,135 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 33 (count at PaidPromotionAdjustParameter.scala:157) finished in 1.230 s
2021-12-04 22:43:23,135 [main] INFO [org.apache.spark.scheduler.DAGScheduler] - Job 13 finished: count at PaidPromotionAdjustParameter.scala:157, took 1.230160 s
2021-12-04 22:43:23,135 [main] INFO [PaidPromotion$] - 最终验证集数量：6105
2021-12-04 22:43:23,167 [main] INFO [PaidPromotion$] - -----------------------------------
2021-12-04 22:43:23,168 [main] INFO [org.apache.spark.SparkContext] - Starting job: count at PaidPromotionAdjustParameter.scala:169
2021-12-04 22:43:23,168 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 37 (distinct at PaidPromotionAdjustParameter.scala:160)
2021-12-04 22:43:23,168 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 14 (count at PaidPromotionAdjustParameter.scala:169) with 4 output partitions
2021-12-04 22:43:23,168 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 35 (count at PaidPromotionAdjustParameter.scala:169)
2021-12-04 22:43:23,168 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 34)
2021-12-04 22:43:23,169 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List(ShuffleMapStage 34)
2021-12-04 22:43:23,169 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ShuffleMapStage 34 (MapPartitionsRDD[37] at distinct at PaidPromotionAdjustParameter.scala:160), which has no missing parents
2021-12-04 22:43:23,170 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_23 stored as values in memory (estimated size 184.7 KB, free 1990.0 MB)
2021-12-04 22:43:23,172 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_23_piece0 stored as bytes in memory (estimated size 65.5 KB, free 1990.0 MB)
2021-12-04 22:43:23,173 [dispatcher-event-loop-7] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_23_piece0 in memory on qb:60793 (size: 65.5 KB, free: 1990.6 MB)
2021-12-04 22:43:23,173 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 23 from broadcast at DAGScheduler.scala:1039
2021-12-04 22:43:23,173 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 4 missing tasks from ShuffleMapStage 34 (MapPartitionsRDD[37] at distinct at PaidPromotionAdjustParameter.scala:160) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
2021-12-04 22:43:23,173 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 34.0 with 4 tasks
2021-12-04 22:43:23,174 [dispatcher-event-loop-8] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 34.0 (TID 46, localhost, executor driver, partition 0, ANY, 7994 bytes)
2021-12-04 22:43:23,174 [dispatcher-event-loop-8] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 34.0 (TID 47, localhost, executor driver, partition 1, ANY, 7994 bytes)
2021-12-04 22:43:23,174 [dispatcher-event-loop-8] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 2.0 in stage 34.0 (TID 48, localhost, executor driver, partition 2, ANY, 7994 bytes)
2021-12-04 22:43:23,174 [dispatcher-event-loop-8] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 3.0 in stage 34.0 (TID 49, localhost, executor driver, partition 3, ANY, 7994 bytes)
2021-12-04 22:43:23,174 [Executor task launch worker for task 46] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 34.0 (TID 46)
2021-12-04 22:43:23,174 [Executor task launch worker for task 48] INFO [org.apache.spark.executor.Executor] - Running task 2.0 in stage 34.0 (TID 48)
2021-12-04 22:43:23,174 [Executor task launch worker for task 47] INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 34.0 (TID 47)
2021-12-04 22:43:23,174 [Executor task launch worker for task 49] INFO [org.apache.spark.executor.Executor] - Running task 3.0 in stage 34.0 (TID 49)
2021-12-04 22:43:23,176 [Executor task launch worker for task 49] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/order_data.bcp:3442194+3442195
2021-12-04 22:43:23,176 [Executor task launch worker for task 46] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/order_data.bcp:0+3442194
2021-12-04 22:43:23,177 [Executor task launch worker for task 48] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/order_data.bcp:0+3442194
2021-12-04 22:43:23,177 [Executor task launch worker for task 47] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/order_data.bcp:3442194+3442195
2021-12-04 22:43:23,792 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 544
2021-12-04 22:43:23,793 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 531
2021-12-04 22:43:23,793 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 530
2021-12-04 22:43:23,793 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 545
2021-12-04 22:43:23,793 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 538
2021-12-04 22:43:23,793 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 525
2021-12-04 22:43:23,793 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 532
2021-12-04 22:43:23,793 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 542
2021-12-04 22:43:23,793 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 541
2021-12-04 22:43:23,793 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 539
2021-12-04 22:43:23,793 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 548
2021-12-04 22:43:23,793 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 540
2021-12-04 22:43:23,793 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 549
2021-12-04 22:43:23,793 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 534
2021-12-04 22:43:23,793 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 543
2021-12-04 22:43:23,793 [dispatcher-event-loop-2] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_22_piece0 on qb:60793 in memory (size: 64.3 KB, free: 1990.7 MB)
2021-12-04 22:43:23,794 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 546
2021-12-04 22:43:23,794 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 535
2021-12-04 22:43:23,794 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 537
2021-12-04 22:43:23,794 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 547
2021-12-04 22:43:23,794 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 529
2021-12-04 22:43:23,794 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 528
2021-12-04 22:43:23,794 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 533
2021-12-04 22:43:23,794 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 526
2021-12-04 22:43:23,794 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 527
2021-12-04 22:43:23,794 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 536
2021-12-04 22:43:24,140 [Executor task launch worker for task 48] INFO [org.apache.spark.executor.Executor] - Finished task 2.0 in stage 34.0 (TID 48). 1034 bytes result sent to driver
2021-12-04 22:43:24,141 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 2.0 in stage 34.0 (TID 48) in 967 ms on localhost (executor driver) (1/4)
2021-12-04 22:43:24,182 [Executor task launch worker for task 46] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 34.0 (TID 46). 1034 bytes result sent to driver
2021-12-04 22:43:24,182 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 34.0 (TID 46) in 1008 ms on localhost (executor driver) (2/4)
2021-12-04 22:43:24,527 [Executor task launch worker for task 47] INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 34.0 (TID 47). 1034 bytes result sent to driver
2021-12-04 22:43:24,527 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 34.0 (TID 47) in 1353 ms on localhost (executor driver) (3/4)
2021-12-04 22:43:24,660 [Executor task launch worker for task 49] INFO [org.apache.spark.executor.Executor] - Finished task 3.0 in stage 34.0 (TID 49). 1034 bytes result sent to driver
2021-12-04 22:43:24,660 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 3.0 in stage 34.0 (TID 49) in 1486 ms on localhost (executor driver) (4/4)
2021-12-04 22:43:24,661 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 34.0, whose tasks have all completed, from pool 
2021-12-04 22:43:24,661 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ShuffleMapStage 34 (distinct at PaidPromotionAdjustParameter.scala:160) finished in 1.492 s
2021-12-04 22:43:24,661 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - looking for newly runnable stages
2021-12-04 22:43:24,661 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - running: Set()
2021-12-04 22:43:24,661 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - waiting: Set(ResultStage 35)
2021-12-04 22:43:24,661 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - failed: Set()
2021-12-04 22:43:24,661 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 35 (MapPartitionsRDD[39] at distinct at PaidPromotionAdjustParameter.scala:160), which has no missing parents
2021-12-04 22:43:24,662 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_24 stored as values in memory (estimated size 3.7 KB, free 1990.2 MB)
2021-12-04 22:43:24,663 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_24_piece0 stored as bytes in memory (estimated size 2.2 KB, free 1990.2 MB)
2021-12-04 22:43:24,664 [dispatcher-event-loop-0] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_24_piece0 in memory on qb:60793 (size: 2.2 KB, free: 1990.7 MB)
2021-12-04 22:43:24,664 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 24 from broadcast at DAGScheduler.scala:1039
2021-12-04 22:43:24,664 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 4 missing tasks from ResultStage 35 (MapPartitionsRDD[39] at distinct at PaidPromotionAdjustParameter.scala:160) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
2021-12-04 22:43:24,664 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 35.0 with 4 tasks
2021-12-04 22:43:24,664 [dispatcher-event-loop-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 35.0 (TID 50, localhost, executor driver, partition 0, ANY, 7649 bytes)
2021-12-04 22:43:24,665 [dispatcher-event-loop-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 35.0 (TID 51, localhost, executor driver, partition 1, ANY, 7649 bytes)
2021-12-04 22:43:24,665 [dispatcher-event-loop-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 2.0 in stage 35.0 (TID 52, localhost, executor driver, partition 2, ANY, 7649 bytes)
2021-12-04 22:43:24,665 [dispatcher-event-loop-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 3.0 in stage 35.0 (TID 53, localhost, executor driver, partition 3, ANY, 7649 bytes)
2021-12-04 22:43:24,665 [Executor task launch worker for task 51] INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 35.0 (TID 51)
2021-12-04 22:43:24,665 [Executor task launch worker for task 52] INFO [org.apache.spark.executor.Executor] - Running task 2.0 in stage 35.0 (TID 52)
2021-12-04 22:43:24,665 [Executor task launch worker for task 53] INFO [org.apache.spark.executor.Executor] - Running task 3.0 in stage 35.0 (TID 53)
2021-12-04 22:43:24,665 [Executor task launch worker for task 50] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 35.0 (TID 50)
2021-12-04 22:43:24,666 [Executor task launch worker for task 52] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 4 non-empty blocks out of 4 blocks
2021-12-04 22:43:24,666 [Executor task launch worker for task 52] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-04 22:43:24,666 [Executor task launch worker for task 50] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 4 non-empty blocks out of 4 blocks
2021-12-04 22:43:24,666 [Executor task launch worker for task 50] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-04 22:43:24,666 [Executor task launch worker for task 53] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 4 non-empty blocks out of 4 blocks
2021-12-04 22:43:24,666 [Executor task launch worker for task 53] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-04 22:43:24,666 [Executor task launch worker for task 51] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 4 non-empty blocks out of 4 blocks
2021-12-04 22:43:24,666 [Executor task launch worker for task 51] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-04 22:43:24,712 [Executor task launch worker for task 53] INFO [org.apache.spark.executor.Executor] - Finished task 3.0 in stage 35.0 (TID 53). 1055 bytes result sent to driver
2021-12-04 22:43:24,712 [Executor task launch worker for task 51] INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 35.0 (TID 51). 1055 bytes result sent to driver
2021-12-04 22:43:24,712 [Executor task launch worker for task 50] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 35.0 (TID 50). 1055 bytes result sent to driver
2021-12-04 22:43:24,712 [Executor task launch worker for task 52] INFO [org.apache.spark.executor.Executor] - Finished task 2.0 in stage 35.0 (TID 52). 1012 bytes result sent to driver
2021-12-04 22:43:24,712 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 3.0 in stage 35.0 (TID 53) in 47 ms on localhost (executor driver) (1/4)
2021-12-04 22:43:24,712 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 35.0 (TID 50) in 48 ms on localhost (executor driver) (2/4)
2021-12-04 22:43:24,712 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 35.0 (TID 51) in 47 ms on localhost (executor driver) (3/4)
2021-12-04 22:43:24,712 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 2.0 in stage 35.0 (TID 52) in 47 ms on localhost (executor driver) (4/4)
2021-12-04 22:43:24,712 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 35.0, whose tasks have all completed, from pool 
2021-12-04 22:43:24,713 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 35 (count at PaidPromotionAdjustParameter.scala:169) finished in 0.052 s
2021-12-04 22:43:24,713 [main] INFO [org.apache.spark.scheduler.DAGScheduler] - Job 14 finished: count at PaidPromotionAdjustParameter.scala:169, took 1.545129 s
2021-12-04 22:43:24,713 [main] INFO [PaidPromotion$] - 最终训练集用户数 = 95323
2021-12-04 22:43:24,715 [main] INFO [org.apache.spark.SparkContext] - Starting job: count at PaidPromotionAdjustParameter.scala:170
2021-12-04 22:43:24,716 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 41 (distinct at PaidPromotionAdjustParameter.scala:161)
2021-12-04 22:43:24,716 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 15 (count at PaidPromotionAdjustParameter.scala:170) with 2 output partitions
2021-12-04 22:43:24,716 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 37 (count at PaidPromotionAdjustParameter.scala:170)
2021-12-04 22:43:24,716 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 36)
2021-12-04 22:43:24,716 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List(ShuffleMapStage 36)
2021-12-04 22:43:24,716 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ShuffleMapStage 36 (MapPartitionsRDD[41] at distinct at PaidPromotionAdjustParameter.scala:161), which has no missing parents
2021-12-04 22:43:24,718 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_25 stored as values in memory (estimated size 184.1 KB, free 1990.0 MB)
2021-12-04 22:43:24,719 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_25_piece0 stored as bytes in memory (estimated size 65.2 KB, free 1990.0 MB)
2021-12-04 22:43:24,720 [dispatcher-event-loop-8] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_25_piece0 in memory on qb:60793 (size: 65.2 KB, free: 1990.6 MB)
2021-12-04 22:43:24,720 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 25 from broadcast at DAGScheduler.scala:1039
2021-12-04 22:43:24,720 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from ShuffleMapStage 36 (MapPartitionsRDD[41] at distinct at PaidPromotionAdjustParameter.scala:161) (first 15 tasks are for partitions Vector(0, 1))
2021-12-04 22:43:24,720 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 36.0 with 2 tasks
2021-12-04 22:43:24,721 [dispatcher-event-loop-9] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 36.0 (TID 54, localhost, executor driver, partition 0, ANY, 7885 bytes)
2021-12-04 22:43:24,721 [dispatcher-event-loop-9] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 36.0 (TID 55, localhost, executor driver, partition 1, ANY, 7885 bytes)
2021-12-04 22:43:24,721 [Executor task launch worker for task 54] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 36.0 (TID 54)
2021-12-04 22:43:24,721 [Executor task launch worker for task 55] INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 36.0 (TID 55)
2021-12-04 22:43:24,723 [Executor task launch worker for task 54] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/order_data.bcp:0+3442194
2021-12-04 22:43:24,723 [Executor task launch worker for task 55] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/order_data.bcp:3442194+3442195
2021-12-04 22:43:25,752 [Executor task launch worker for task 55] INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 36.0 (TID 55). 989 bytes result sent to driver
2021-12-04 22:43:25,753 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 36.0 (TID 55) in 1032 ms on localhost (executor driver) (1/2)
2021-12-04 22:43:25,825 [Executor task launch worker for task 54] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 36.0 (TID 54). 989 bytes result sent to driver
2021-12-04 22:43:25,826 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 36.0 (TID 54) in 1106 ms on localhost (executor driver) (2/2)
2021-12-04 22:43:25,826 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 36.0, whose tasks have all completed, from pool 
2021-12-04 22:43:25,826 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ShuffleMapStage 36 (distinct at PaidPromotionAdjustParameter.scala:161) finished in 1.110 s
2021-12-04 22:43:25,826 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - looking for newly runnable stages
2021-12-04 22:43:25,826 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - running: Set()
2021-12-04 22:43:25,826 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - waiting: Set(ResultStage 37)
2021-12-04 22:43:25,826 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - failed: Set()
2021-12-04 22:43:25,826 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 37 (MapPartitionsRDD[43] at distinct at PaidPromotionAdjustParameter.scala:161), which has no missing parents
2021-12-04 22:43:25,827 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_26 stored as values in memory (estimated size 3.7 KB, free 1990.0 MB)
2021-12-04 22:43:25,829 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_26_piece0 stored as bytes in memory (estimated size 2.2 KB, free 1990.0 MB)
2021-12-04 22:43:25,829 [dispatcher-event-loop-4] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_26_piece0 in memory on qb:60793 (size: 2.2 KB, free: 1990.6 MB)
2021-12-04 22:43:25,829 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 26 from broadcast at DAGScheduler.scala:1039
2021-12-04 22:43:25,830 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from ResultStage 37 (MapPartitionsRDD[43] at distinct at PaidPromotionAdjustParameter.scala:161) (first 15 tasks are for partitions Vector(0, 1))
2021-12-04 22:43:25,830 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 37.0 with 2 tasks
2021-12-04 22:43:25,830 [dispatcher-event-loop-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 37.0 (TID 56, localhost, executor driver, partition 0, ANY, 7649 bytes)
2021-12-04 22:43:25,830 [dispatcher-event-loop-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 37.0 (TID 57, localhost, executor driver, partition 1, ANY, 7649 bytes)
2021-12-04 22:43:25,830 [Executor task launch worker for task 56] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 37.0 (TID 56)
2021-12-04 22:43:25,830 [Executor task launch worker for task 57] INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 37.0 (TID 57)
2021-12-04 22:43:25,831 [Executor task launch worker for task 56] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 2 non-empty blocks out of 2 blocks
2021-12-04 22:43:25,831 [Executor task launch worker for task 57] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 2 non-empty blocks out of 2 blocks
2021-12-04 22:43:25,831 [Executor task launch worker for task 56] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-04 22:43:25,831 [Executor task launch worker for task 57] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-04 22:43:25,846 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 572
2021-12-04 22:43:25,847 [dispatcher-event-loop-8] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_24_piece0 on qb:60793 in memory (size: 2.2 KB, free: 1990.6 MB)
2021-12-04 22:43:25,847 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 553
2021-12-04 22:43:25,847 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 564
2021-12-04 22:43:25,847 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 565
2021-12-04 22:43:25,847 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 567
2021-12-04 22:43:25,847 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 575
2021-12-04 22:43:25,847 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 566
2021-12-04 22:43:25,847 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 591
2021-12-04 22:43:25,847 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 596
2021-12-04 22:43:25,847 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 554
2021-12-04 22:43:25,847 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 587
2021-12-04 22:43:25,847 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 580
2021-12-04 22:43:25,848 [dispatcher-event-loop-1] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_25_piece0 on qb:60793 in memory (size: 65.2 KB, free: 1990.7 MB)
2021-12-04 22:43:25,848 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 593
2021-12-04 22:43:25,848 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 562
2021-12-04 22:43:25,848 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 563
2021-12-04 22:43:25,848 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 559
2021-12-04 22:43:25,848 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 551
2021-12-04 22:43:25,848 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 590
2021-12-04 22:43:25,848 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 558
2021-12-04 22:43:25,848 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 588
2021-12-04 22:43:25,848 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 583
2021-12-04 22:43:25,848 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 573
2021-12-04 22:43:25,848 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 550
2021-12-04 22:43:25,848 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 570
2021-12-04 22:43:25,848 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 592
2021-12-04 22:43:25,848 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 555
2021-12-04 22:43:25,848 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 597
2021-12-04 22:43:25,848 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 571
2021-12-04 22:43:25,848 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 589
2021-12-04 22:43:25,848 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 576
2021-12-04 22:43:25,848 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 586
2021-12-04 22:43:25,848 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 579
2021-12-04 22:43:25,848 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 598
2021-12-04 22:43:25,848 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 560
2021-12-04 22:43:25,848 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 569
2021-12-04 22:43:25,848 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 595
2021-12-04 22:43:25,848 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 556
2021-12-04 22:43:25,849 [dispatcher-event-loop-4] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_23_piece0 on qb:60793 in memory (size: 65.5 KB, free: 1990.8 MB)
2021-12-04 22:43:25,849 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 561
2021-12-04 22:43:25,849 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 581
2021-12-04 22:43:25,849 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 578
2021-12-04 22:43:25,849 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 568
2021-12-04 22:43:25,849 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 585
2021-12-04 22:43:25,849 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 574
2021-12-04 22:43:25,849 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 594
2021-12-04 22:43:25,849 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 557
2021-12-04 22:43:25,849 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 584
2021-12-04 22:43:25,849 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 552
2021-12-04 22:43:25,849 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 577
2021-12-04 22:43:25,849 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 582
2021-12-04 22:43:25,849 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 599
2021-12-04 22:43:25,853 [Executor task launch worker for task 57] INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 37.0 (TID 57). 1054 bytes result sent to driver
2021-12-04 22:43:25,853 [Executor task launch worker for task 56] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 37.0 (TID 56). 1054 bytes result sent to driver
2021-12-04 22:43:25,853 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 37.0 (TID 57) in 23 ms on localhost (executor driver) (1/2)
2021-12-04 22:43:25,854 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 37.0 (TID 56) in 24 ms on localhost (executor driver) (2/2)
2021-12-04 22:43:25,854 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 37.0, whose tasks have all completed, from pool 
2021-12-04 22:43:25,854 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 37 (count at PaidPromotionAdjustParameter.scala:170) finished in 0.028 s
2021-12-04 22:43:25,854 [main] INFO [org.apache.spark.scheduler.DAGScheduler] - Job 15 finished: count at PaidPromotionAdjustParameter.scala:170, took 1.138414 s
2021-12-04 22:43:25,854 [main] INFO [PaidPromotion$] - 最终验证集用户数 = 5130
2021-12-04 22:43:25,857 [main] INFO [org.apache.spark.SparkContext] - Starting job: count at PaidPromotionAdjustParameter.scala:171
2021-12-04 22:43:25,857 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 45 (intersection at PaidPromotionAdjustParameter.scala:162)
2021-12-04 22:43:25,857 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 44 (intersection at PaidPromotionAdjustParameter.scala:162)
2021-12-04 22:43:25,857 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 16 (count at PaidPromotionAdjustParameter.scala:171) with 4 output partitions
2021-12-04 22:43:25,857 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 42 (count at PaidPromotionAdjustParameter.scala:171)
2021-12-04 22:43:25,857 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 39, ShuffleMapStage 41)
2021-12-04 22:43:25,857 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List(ShuffleMapStage 39, ShuffleMapStage 41)
2021-12-04 22:43:25,857 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ShuffleMapStage 39 (MapPartitionsRDD[45] at intersection at PaidPromotionAdjustParameter.scala:162), which has no missing parents
2021-12-04 22:43:25,858 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_27 stored as values in memory (estimated size 4.0 KB, free 1990.5 MB)
2021-12-04 22:43:25,860 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_27_piece0 stored as bytes in memory (estimated size 2.3 KB, free 1990.5 MB)
2021-12-04 22:43:25,860 [dispatcher-event-loop-2] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_27_piece0 in memory on qb:60793 (size: 2.3 KB, free: 1990.8 MB)
2021-12-04 22:43:25,860 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 27 from broadcast at DAGScheduler.scala:1039
2021-12-04 22:43:25,860 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from ShuffleMapStage 39 (MapPartitionsRDD[45] at intersection at PaidPromotionAdjustParameter.scala:162) (first 15 tasks are for partitions Vector(0, 1))
2021-12-04 22:43:25,860 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 39.0 with 2 tasks
2021-12-04 22:43:25,861 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ShuffleMapStage 41 (MapPartitionsRDD[44] at intersection at PaidPromotionAdjustParameter.scala:162), which has no missing parents
2021-12-04 22:43:25,861 [dispatcher-event-loop-6] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 39.0 (TID 58, localhost, executor driver, partition 0, ANY, 7638 bytes)
2021-12-04 22:43:25,861 [dispatcher-event-loop-6] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 39.0 (TID 59, localhost, executor driver, partition 1, ANY, 7638 bytes)
2021-12-04 22:43:25,861 [Executor task launch worker for task 58] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 39.0 (TID 58)
2021-12-04 22:43:25,861 [Executor task launch worker for task 59] INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 39.0 (TID 59)
2021-12-04 22:43:25,861 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_28 stored as values in memory (estimated size 4.0 KB, free 1990.5 MB)
2021-12-04 22:43:25,862 [Executor task launch worker for task 58] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 2 non-empty blocks out of 2 blocks
2021-12-04 22:43:25,862 [Executor task launch worker for task 58] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-04 22:43:25,862 [Executor task launch worker for task 59] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 2 non-empty blocks out of 2 blocks
2021-12-04 22:43:25,862 [Executor task launch worker for task 59] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-04 22:43:25,863 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_28_piece0 stored as bytes in memory (estimated size 2.3 KB, free 1990.4 MB)
2021-12-04 22:43:25,863 [dispatcher-event-loop-0] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_28_piece0 in memory on qb:60793 (size: 2.3 KB, free: 1990.8 MB)
2021-12-04 22:43:25,863 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 28 from broadcast at DAGScheduler.scala:1039
2021-12-04 22:43:25,863 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 4 missing tasks from ShuffleMapStage 41 (MapPartitionsRDD[44] at intersection at PaidPromotionAdjustParameter.scala:162) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
2021-12-04 22:43:25,863 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 41.0 with 4 tasks
2021-12-04 22:43:25,864 [dispatcher-event-loop-9] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 41.0 (TID 60, localhost, executor driver, partition 0, ANY, 7638 bytes)
2021-12-04 22:43:25,864 [dispatcher-event-loop-9] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 41.0 (TID 61, localhost, executor driver, partition 1, ANY, 7638 bytes)
2021-12-04 22:43:25,864 [dispatcher-event-loop-9] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 2.0 in stage 41.0 (TID 62, localhost, executor driver, partition 2, ANY, 7638 bytes)
2021-12-04 22:43:25,864 [dispatcher-event-loop-9] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 3.0 in stage 41.0 (TID 63, localhost, executor driver, partition 3, ANY, 7638 bytes)
2021-12-04 22:43:25,864 [Executor task launch worker for task 61] INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 41.0 (TID 61)
2021-12-04 22:43:25,864 [Executor task launch worker for task 60] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 41.0 (TID 60)
2021-12-04 22:43:25,865 [Executor task launch worker for task 62] INFO [org.apache.spark.executor.Executor] - Running task 2.0 in stage 41.0 (TID 62)
2021-12-04 22:43:25,865 [Executor task launch worker for task 63] INFO [org.apache.spark.executor.Executor] - Running task 3.0 in stage 41.0 (TID 63)
2021-12-04 22:43:25,866 [Executor task launch worker for task 62] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 4 non-empty blocks out of 4 blocks
2021-12-04 22:43:25,866 [Executor task launch worker for task 63] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 4 non-empty blocks out of 4 blocks
2021-12-04 22:43:25,866 [Executor task launch worker for task 62] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-04 22:43:25,866 [Executor task launch worker for task 63] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-04 22:43:25,866 [Executor task launch worker for task 60] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 4 non-empty blocks out of 4 blocks
2021-12-04 22:43:25,866 [Executor task launch worker for task 61] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 4 non-empty blocks out of 4 blocks
2021-12-04 22:43:25,866 [Executor task launch worker for task 60] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-04 22:43:25,866 [Executor task launch worker for task 61] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-04 22:43:25,894 [Executor task launch worker for task 58] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 39.0 (TID 58). 1163 bytes result sent to driver
2021-12-04 22:43:25,895 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 39.0 (TID 58) in 34 ms on localhost (executor driver) (1/2)
2021-12-04 22:43:25,896 [Executor task launch worker for task 59] INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 39.0 (TID 59). 1163 bytes result sent to driver
2021-12-04 22:43:25,896 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 39.0 (TID 59) in 35 ms on localhost (executor driver) (2/2)
2021-12-04 22:43:25,896 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 39.0, whose tasks have all completed, from pool 
2021-12-04 22:43:25,897 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ShuffleMapStage 39 (intersection at PaidPromotionAdjustParameter.scala:162) finished in 0.038 s
2021-12-04 22:43:25,897 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - looking for newly runnable stages
2021-12-04 22:43:25,897 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - running: Set(ShuffleMapStage 41)
2021-12-04 22:43:25,897 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - waiting: Set(ResultStage 42)
2021-12-04 22:43:25,897 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - failed: Set()
2021-12-04 22:43:25,919 [Executor task launch worker for task 62] INFO [org.apache.spark.executor.Executor] - Finished task 2.0 in stage 41.0 (TID 62). 1163 bytes result sent to driver
2021-12-04 22:43:25,919 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 2.0 in stage 41.0 (TID 62) in 55 ms on localhost (executor driver) (1/4)
2021-12-04 22:43:25,920 [Executor task launch worker for task 60] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 41.0 (TID 60). 1206 bytes result sent to driver
2021-12-04 22:43:25,920 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 41.0 (TID 60) in 56 ms on localhost (executor driver) (2/4)
2021-12-04 22:43:25,921 [Executor task launch worker for task 63] INFO [org.apache.spark.executor.Executor] - Finished task 3.0 in stage 41.0 (TID 63). 1163 bytes result sent to driver
2021-12-04 22:43:25,921 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 3.0 in stage 41.0 (TID 63) in 57 ms on localhost (executor driver) (3/4)
2021-12-04 22:43:25,922 [Executor task launch worker for task 61] INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 41.0 (TID 61). 1163 bytes result sent to driver
2021-12-04 22:43:25,922 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 41.0 (TID 61) in 58 ms on localhost (executor driver) (4/4)
2021-12-04 22:43:25,922 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 41.0, whose tasks have all completed, from pool 
2021-12-04 22:43:25,922 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ShuffleMapStage 41 (intersection at PaidPromotionAdjustParameter.scala:162) finished in 0.061 s
2021-12-04 22:43:25,922 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - looking for newly runnable stages
2021-12-04 22:43:25,922 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - running: Set()
2021-12-04 22:43:25,922 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - waiting: Set(ResultStage 42)
2021-12-04 22:43:25,922 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - failed: Set()
2021-12-04 22:43:25,922 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 42 (MapPartitionsRDD[49] at intersection at PaidPromotionAdjustParameter.scala:162), which has no missing parents
2021-12-04 22:43:25,923 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_29 stored as values in memory (estimated size 3.6 KB, free 1990.4 MB)
2021-12-04 22:43:25,924 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_29_piece0 stored as bytes in memory (estimated size 2.1 KB, free 1990.4 MB)
2021-12-04 22:43:25,925 [dispatcher-event-loop-0] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_29_piece0 in memory on qb:60793 (size: 2.1 KB, free: 1990.8 MB)
2021-12-04 22:43:25,925 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 29 from broadcast at DAGScheduler.scala:1039
2021-12-04 22:43:25,925 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 4 missing tasks from ResultStage 42 (MapPartitionsRDD[49] at intersection at PaidPromotionAdjustParameter.scala:162) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
2021-12-04 22:43:25,925 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 42.0 with 4 tasks
2021-12-04 22:43:25,925 [dispatcher-event-loop-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 42.0 (TID 64, localhost, executor driver, partition 0, PROCESS_LOCAL, 7712 bytes)
2021-12-04 22:43:25,926 [dispatcher-event-loop-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 42.0 (TID 65, localhost, executor driver, partition 1, PROCESS_LOCAL, 7712 bytes)
2021-12-04 22:43:25,926 [dispatcher-event-loop-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 2.0 in stage 42.0 (TID 66, localhost, executor driver, partition 2, PROCESS_LOCAL, 7712 bytes)
2021-12-04 22:43:25,926 [dispatcher-event-loop-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 3.0 in stage 42.0 (TID 67, localhost, executor driver, partition 3, PROCESS_LOCAL, 7712 bytes)
2021-12-04 22:43:25,926 [Executor task launch worker for task 66] INFO [org.apache.spark.executor.Executor] - Running task 2.0 in stage 42.0 (TID 66)
2021-12-04 22:43:25,926 [Executor task launch worker for task 67] INFO [org.apache.spark.executor.Executor] - Running task 3.0 in stage 42.0 (TID 67)
2021-12-04 22:43:25,926 [Executor task launch worker for task 64] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 42.0 (TID 64)
2021-12-04 22:43:25,926 [Executor task launch worker for task 65] INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 42.0 (TID 65)
2021-12-04 22:43:25,927 [Executor task launch worker for task 65] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 4 blocks
2021-12-04 22:43:25,927 [Executor task launch worker for task 66] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 4 blocks
2021-12-04 22:43:25,927 [Executor task launch worker for task 65] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-04 22:43:25,927 [Executor task launch worker for task 66] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-04 22:43:25,927 [Executor task launch worker for task 64] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 4 blocks
2021-12-04 22:43:25,927 [Executor task launch worker for task 64] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-04 22:43:25,927 [Executor task launch worker for task 67] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 4 blocks
2021-12-04 22:43:25,927 [Executor task launch worker for task 67] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-04 22:43:25,929 [Executor task launch worker for task 67] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2021-12-04 22:43:25,929 [Executor task launch worker for task 65] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2021-12-04 22:43:25,929 [Executor task launch worker for task 67] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-04 22:43:25,929 [Executor task launch worker for task 65] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-04 22:43:25,929 [Executor task launch worker for task 66] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2021-12-04 22:43:25,929 [Executor task launch worker for task 64] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2021-12-04 22:43:25,929 [Executor task launch worker for task 66] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-04 22:43:25,929 [Executor task launch worker for task 64] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-04 22:43:25,977 [Executor task launch worker for task 67] INFO [org.apache.spark.executor.Executor] - Finished task 3.0 in stage 42.0 (TID 67). 1054 bytes result sent to driver
2021-12-04 22:43:25,977 [Executor task launch worker for task 65] INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 42.0 (TID 65). 1054 bytes result sent to driver
2021-12-04 22:43:25,977 [Executor task launch worker for task 66] INFO [org.apache.spark.executor.Executor] - Finished task 2.0 in stage 42.0 (TID 66). 1011 bytes result sent to driver
2021-12-04 22:43:25,977 [Executor task launch worker for task 64] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 42.0 (TID 64). 1054 bytes result sent to driver
2021-12-04 22:43:25,978 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 3.0 in stage 42.0 (TID 67) in 52 ms on localhost (executor driver) (1/4)
2021-12-04 22:43:25,978 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 42.0 (TID 65) in 52 ms on localhost (executor driver) (2/4)
2021-12-04 22:43:25,978 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 2.0 in stage 42.0 (TID 66) in 52 ms on localhost (executor driver) (3/4)
2021-12-04 22:43:25,978 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 42.0 (TID 64) in 53 ms on localhost (executor driver) (4/4)
2021-12-04 22:43:25,978 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 42.0, whose tasks have all completed, from pool 
2021-12-04 22:43:25,978 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 42 (count at PaidPromotionAdjustParameter.scala:171) finished in 0.055 s
2021-12-04 22:43:25,978 [main] INFO [org.apache.spark.scheduler.DAGScheduler] - Job 16 finished: count at PaidPromotionAdjustParameter.scala:171, took 0.121366 s
2021-12-04 22:43:25,979 [main] INFO [PaidPromotion$] - 最终共 同 用户数 = 5130
2021-12-04 22:43:25,981 [main] INFO [org.apache.spark.SparkContext] - Starting job: count at PaidPromotionAdjustParameter.scala:172
2021-12-04 22:43:25,981 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 51 (distinct at PaidPromotionAdjustParameter.scala:164)
2021-12-04 22:43:25,981 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 17 (count at PaidPromotionAdjustParameter.scala:172) with 4 output partitions
2021-12-04 22:43:25,981 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 44 (count at PaidPromotionAdjustParameter.scala:172)
2021-12-04 22:43:25,981 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 43)
2021-12-04 22:43:25,981 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List(ShuffleMapStage 43)
2021-12-04 22:43:25,981 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ShuffleMapStage 43 (MapPartitionsRDD[51] at distinct at PaidPromotionAdjustParameter.scala:164), which has no missing parents
2021-12-04 22:43:25,984 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_30 stored as values in memory (estimated size 184.7 KB, free 1990.3 MB)
2021-12-04 22:43:25,986 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_30_piece0 stored as bytes in memory (estimated size 65.5 KB, free 1990.2 MB)
2021-12-04 22:43:25,986 [dispatcher-event-loop-7] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_30_piece0 in memory on qb:60793 (size: 65.5 KB, free: 1990.7 MB)
2021-12-04 22:43:25,986 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 30 from broadcast at DAGScheduler.scala:1039
2021-12-04 22:43:25,986 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 4 missing tasks from ShuffleMapStage 43 (MapPartitionsRDD[51] at distinct at PaidPromotionAdjustParameter.scala:164) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
2021-12-04 22:43:25,986 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 43.0 with 4 tasks
2021-12-04 22:43:25,987 [dispatcher-event-loop-8] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 43.0 (TID 68, localhost, executor driver, partition 0, ANY, 7994 bytes)
2021-12-04 22:43:25,987 [dispatcher-event-loop-8] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 43.0 (TID 69, localhost, executor driver, partition 1, ANY, 7994 bytes)
2021-12-04 22:43:25,987 [dispatcher-event-loop-8] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 2.0 in stage 43.0 (TID 70, localhost, executor driver, partition 2, ANY, 7994 bytes)
2021-12-04 22:43:25,987 [dispatcher-event-loop-8] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 3.0 in stage 43.0 (TID 71, localhost, executor driver, partition 3, ANY, 7994 bytes)
2021-12-04 22:43:25,987 [Executor task launch worker for task 69] INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 43.0 (TID 69)
2021-12-04 22:43:25,987 [Executor task launch worker for task 71] INFO [org.apache.spark.executor.Executor] - Running task 3.0 in stage 43.0 (TID 71)
2021-12-04 22:43:25,987 [Executor task launch worker for task 68] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 43.0 (TID 68)
2021-12-04 22:43:25,987 [Executor task launch worker for task 70] INFO [org.apache.spark.executor.Executor] - Running task 2.0 in stage 43.0 (TID 70)
2021-12-04 22:43:25,990 [Executor task launch worker for task 71] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/order_data.bcp:3442194+3442195
2021-12-04 22:43:25,990 [Executor task launch worker for task 68] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/order_data.bcp:0+3442194
2021-12-04 22:43:25,990 [Executor task launch worker for task 69] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/order_data.bcp:3442194+3442195
2021-12-04 22:43:25,990 [Executor task launch worker for task 70] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/order_data.bcp:0+3442194
2021-12-04 22:43:26,522 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 623
2021-12-04 22:43:26,522 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 716
2021-12-04 22:43:26,522 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 668
2021-12-04 22:43:26,522 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 684
2021-12-04 22:43:26,522 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 614
2021-12-04 22:43:26,522 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 631
2021-12-04 22:43:26,522 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 720
2021-12-04 22:43:26,522 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 685
2021-12-04 22:43:26,522 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 610
2021-12-04 22:43:26,522 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 713
2021-12-04 22:43:26,522 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 605
2021-12-04 22:43:26,522 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 644
2021-12-04 22:43:26,522 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 711
2021-12-04 22:43:26,522 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 703
2021-12-04 22:43:26,522 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 629
2021-12-04 22:43:26,522 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 654
2021-12-04 22:43:26,522 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 708
2021-12-04 22:43:26,523 [dispatcher-event-loop-3] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_26_piece0 on qb:60793 in memory (size: 2.2 KB, free: 1990.7 MB)
2021-12-04 22:43:26,523 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 619
2021-12-04 22:43:26,523 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 615
2021-12-04 22:43:26,523 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 681
2021-12-04 22:43:26,523 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 700
2021-12-04 22:43:26,523 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 658
2021-12-04 22:43:26,523 [dispatcher-event-loop-10] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_28_piece0 on qb:60793 in memory (size: 2.3 KB, free: 1990.7 MB)
2021-12-04 22:43:26,524 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 616
2021-12-04 22:43:26,524 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 628
2021-12-04 22:43:26,524 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 636
2021-12-04 22:43:26,524 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 714
2021-12-04 22:43:26,524 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 661
2021-12-04 22:43:26,524 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 607
2021-12-04 22:43:26,524 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 639
2021-12-04 22:43:26,524 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 670
2021-12-04 22:43:26,524 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 604
2021-12-04 22:43:26,524 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 624
2021-12-04 22:43:26,524 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 613
2021-12-04 22:43:26,524 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 677
2021-12-04 22:43:26,524 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 662
2021-12-04 22:43:26,524 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 660
2021-12-04 22:43:26,524 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 635
2021-12-04 22:43:26,524 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 630
2021-12-04 22:43:26,524 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 606
2021-12-04 22:43:26,524 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 704
2021-12-04 22:43:26,524 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 622
2021-12-04 22:43:26,524 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 688
2021-12-04 22:43:26,524 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 705
2021-12-04 22:43:26,524 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 665
2021-12-04 22:43:26,524 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 617
2021-12-04 22:43:26,524 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 643
2021-12-04 22:43:26,524 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 689
2021-12-04 22:43:26,524 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 667
2021-12-04 22:43:26,524 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 706
2021-12-04 22:43:26,524 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 712
2021-12-04 22:43:26,524 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 691
2021-12-04 22:43:26,524 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 652
2021-12-04 22:43:26,524 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 641
2021-12-04 22:43:26,524 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 719
2021-12-04 22:43:26,524 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 621
2021-12-04 22:43:26,524 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 683
2021-12-04 22:43:26,524 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 697
2021-12-04 22:43:26,524 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 682
2021-12-04 22:43:26,524 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 663
2021-12-04 22:43:26,524 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 633
2021-12-04 22:43:26,524 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 676
2021-12-04 22:43:26,524 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 710
2021-12-04 22:43:26,524 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 718
2021-12-04 22:43:26,525 [dispatcher-event-loop-1] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_27_piece0 on qb:60793 in memory (size: 2.3 KB, free: 1990.7 MB)
2021-12-04 22:43:26,525 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 701
2021-12-04 22:43:26,525 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 678
2021-12-04 22:43:26,525 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 715
2021-12-04 22:43:26,525 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 612
2021-12-04 22:43:26,525 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 666
2021-12-04 22:43:26,525 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 647
2021-12-04 22:43:26,525 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 649
2021-12-04 22:43:26,525 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 637
2021-12-04 22:43:26,525 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 695
2021-12-04 22:43:26,525 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 642
2021-12-04 22:43:26,525 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 692
2021-12-04 22:43:26,525 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 699
2021-12-04 22:43:26,525 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 724
2021-12-04 22:43:26,525 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 653
2021-12-04 22:43:26,525 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 722
2021-12-04 22:43:26,525 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 632
2021-12-04 22:43:26,525 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 696
2021-12-04 22:43:26,525 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 656
2021-12-04 22:43:26,525 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 638
2021-12-04 22:43:26,525 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 609
2021-12-04 22:43:26,525 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 646
2021-12-04 22:43:26,525 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 657
2021-12-04 22:43:26,525 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 675
2021-12-04 22:43:26,525 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 640
2021-12-04 22:43:26,525 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 602
2021-12-04 22:43:26,525 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 611
2021-12-04 22:43:26,525 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 608
2021-12-04 22:43:26,525 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 672
2021-12-04 22:43:26,525 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 693
2021-12-04 22:43:26,525 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 600
2021-12-04 22:43:26,525 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 671
2021-12-04 22:43:26,525 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 618
2021-12-04 22:43:26,525 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 674
2021-12-04 22:43:26,525 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 651
2021-12-04 22:43:26,525 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 694
2021-12-04 22:43:26,525 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 669
2021-12-04 22:43:26,525 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 655
2021-12-04 22:43:26,525 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 680
2021-12-04 22:43:26,525 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 601
2021-12-04 22:43:26,525 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 627
2021-12-04 22:43:26,525 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 603
2021-12-04 22:43:26,525 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 709
2021-12-04 22:43:26,525 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 702
2021-12-04 22:43:26,525 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 659
2021-12-04 22:43:26,525 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 673
2021-12-04 22:43:26,525 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 620
2021-12-04 22:43:26,526 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 679
2021-12-04 22:43:26,526 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 625
2021-12-04 22:43:26,526 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 687
2021-12-04 22:43:26,526 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 648
2021-12-04 22:43:26,526 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 686
2021-12-04 22:43:26,526 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 707
2021-12-04 22:43:26,526 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 721
2021-12-04 22:43:26,526 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 650
2021-12-04 22:43:26,526 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 690
2021-12-04 22:43:26,526 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 698
2021-12-04 22:43:26,526 [dispatcher-event-loop-9] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_29_piece0 on qb:60793 in memory (size: 2.1 KB, free: 1990.7 MB)
2021-12-04 22:43:26,526 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 634
2021-12-04 22:43:26,526 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 717
2021-12-04 22:43:26,526 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 664
2021-12-04 22:43:26,526 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 723
2021-12-04 22:43:26,526 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 626
2021-12-04 22:43:26,527 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 645
2021-12-04 22:43:26,598 [Executor task launch worker for task 71] INFO [org.apache.spark.executor.Executor] - Finished task 3.0 in stage 43.0 (TID 71). 1034 bytes result sent to driver
2021-12-04 22:43:26,599 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 3.0 in stage 43.0 (TID 71) in 612 ms on localhost (executor driver) (1/4)
2021-12-04 22:43:27,065 [Executor task launch worker for task 70] INFO [org.apache.spark.executor.Executor] - Finished task 2.0 in stage 43.0 (TID 70). 1034 bytes result sent to driver
2021-12-04 22:43:27,066 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 2.0 in stage 43.0 (TID 70) in 1078 ms on localhost (executor driver) (2/4)
2021-12-04 22:43:27,075 [Executor task launch worker for task 69] INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 43.0 (TID 69). 1034 bytes result sent to driver
2021-12-04 22:43:27,075 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 43.0 (TID 69) in 1088 ms on localhost (executor driver) (3/4)
2021-12-04 22:43:27,340 [Executor task launch worker for task 68] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 43.0 (TID 68). 1034 bytes result sent to driver
2021-12-04 22:43:27,340 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 43.0 (TID 68) in 1353 ms on localhost (executor driver) (4/4)
2021-12-04 22:43:27,340 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 43.0, whose tasks have all completed, from pool 
2021-12-04 22:43:27,340 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ShuffleMapStage 43 (distinct at PaidPromotionAdjustParameter.scala:164) finished in 1.358 s
2021-12-04 22:43:27,340 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - looking for newly runnable stages
2021-12-04 22:43:27,340 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - running: Set()
2021-12-04 22:43:27,340 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - waiting: Set(ResultStage 44)
2021-12-04 22:43:27,340 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - failed: Set()
2021-12-04 22:43:27,341 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 44 (MapPartitionsRDD[53] at distinct at PaidPromotionAdjustParameter.scala:164), which has no missing parents
2021-12-04 22:43:27,341 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_31 stored as values in memory (estimated size 3.7 KB, free 1990.2 MB)
2021-12-04 22:43:27,343 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_31_piece0 stored as bytes in memory (estimated size 2.2 KB, free 1990.2 MB)
2021-12-04 22:43:27,344 [dispatcher-event-loop-2] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_31_piece0 in memory on qb:60793 (size: 2.2 KB, free: 1990.7 MB)
2021-12-04 22:43:27,344 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 31 from broadcast at DAGScheduler.scala:1039
2021-12-04 22:43:27,344 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 4 missing tasks from ResultStage 44 (MapPartitionsRDD[53] at distinct at PaidPromotionAdjustParameter.scala:164) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
2021-12-04 22:43:27,344 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 44.0 with 4 tasks
2021-12-04 22:43:27,345 [dispatcher-event-loop-10] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 44.0 (TID 72, localhost, executor driver, partition 0, ANY, 7649 bytes)
2021-12-04 22:43:27,345 [dispatcher-event-loop-10] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 44.0 (TID 73, localhost, executor driver, partition 1, ANY, 7649 bytes)
2021-12-04 22:43:27,345 [dispatcher-event-loop-10] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 2.0 in stage 44.0 (TID 74, localhost, executor driver, partition 2, ANY, 7649 bytes)
2021-12-04 22:43:27,345 [dispatcher-event-loop-10] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 3.0 in stage 44.0 (TID 75, localhost, executor driver, partition 3, ANY, 7649 bytes)
2021-12-04 22:43:27,345 [Executor task launch worker for task 74] INFO [org.apache.spark.executor.Executor] - Running task 2.0 in stage 44.0 (TID 74)
2021-12-04 22:43:27,345 [Executor task launch worker for task 72] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 44.0 (TID 72)
2021-12-04 22:43:27,345 [Executor task launch worker for task 73] INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 44.0 (TID 73)
2021-12-04 22:43:27,345 [Executor task launch worker for task 75] INFO [org.apache.spark.executor.Executor] - Running task 3.0 in stage 44.0 (TID 75)
2021-12-04 22:43:27,346 [Executor task launch worker for task 72] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 4 non-empty blocks out of 4 blocks
2021-12-04 22:43:27,346 [Executor task launch worker for task 75] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 4 non-empty blocks out of 4 blocks
2021-12-04 22:43:27,346 [Executor task launch worker for task 72] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-04 22:43:27,346 [Executor task launch worker for task 73] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 4 non-empty blocks out of 4 blocks
2021-12-04 22:43:27,346 [Executor task launch worker for task 73] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-04 22:43:27,346 [Executor task launch worker for task 75] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-04 22:43:27,346 [Executor task launch worker for task 74] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 4 non-empty blocks out of 4 blocks
2021-12-04 22:43:27,346 [Executor task launch worker for task 74] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-04 22:43:27,364 [Executor task launch worker for task 75] INFO [org.apache.spark.executor.Executor] - Finished task 3.0 in stage 44.0 (TID 75). 1010 bytes result sent to driver
2021-12-04 22:43:27,364 [Executor task launch worker for task 74] INFO [org.apache.spark.executor.Executor] - Finished task 2.0 in stage 44.0 (TID 74). 1010 bytes result sent to driver
2021-12-04 22:43:27,364 [Executor task launch worker for task 73] INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 44.0 (TID 73). 1010 bytes result sent to driver
2021-12-04 22:43:27,364 [Executor task launch worker for task 72] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 44.0 (TID 72). 1010 bytes result sent to driver
2021-12-04 22:43:27,365 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 3.0 in stage 44.0 (TID 75) in 20 ms on localhost (executor driver) (1/4)
2021-12-04 22:43:27,365 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 2.0 in stage 44.0 (TID 74) in 20 ms on localhost (executor driver) (2/4)
2021-12-04 22:43:27,365 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 44.0 (TID 73) in 20 ms on localhost (executor driver) (3/4)
2021-12-04 22:43:27,365 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 44.0 (TID 72) in 21 ms on localhost (executor driver) (4/4)
2021-12-04 22:43:27,365 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 44.0, whose tasks have all completed, from pool 
2021-12-04 22:43:27,365 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 44 (count at PaidPromotionAdjustParameter.scala:172) finished in 0.024 s
2021-12-04 22:43:27,365 [main] INFO [org.apache.spark.scheduler.DAGScheduler] - Job 17 finished: count at PaidPromotionAdjustParameter.scala:172, took 1.385428 s
2021-12-04 22:43:27,366 [main] INFO [PaidPromotion$] - 最终训练集节目数 = 132
2021-12-04 22:43:27,368 [main] INFO [org.apache.spark.SparkContext] - Starting job: count at PaidPromotionAdjustParameter.scala:173
2021-12-04 22:43:27,368 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 55 (distinct at PaidPromotionAdjustParameter.scala:165)
2021-12-04 22:43:27,368 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 18 (count at PaidPromotionAdjustParameter.scala:173) with 2 output partitions
2021-12-04 22:43:27,368 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 46 (count at PaidPromotionAdjustParameter.scala:173)
2021-12-04 22:43:27,368 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 45)
2021-12-04 22:43:27,368 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List(ShuffleMapStage 45)
2021-12-04 22:43:27,368 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ShuffleMapStage 45 (MapPartitionsRDD[55] at distinct at PaidPromotionAdjustParameter.scala:165), which has no missing parents
2021-12-04 22:43:27,370 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_32 stored as values in memory (estimated size 184.1 KB, free 1990.0 MB)
2021-12-04 22:43:27,371 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_32_piece0 stored as bytes in memory (estimated size 65.2 KB, free 1990.0 MB)
2021-12-04 22:43:27,372 [dispatcher-event-loop-3] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_32_piece0 in memory on qb:60793 (size: 65.2 KB, free: 1990.6 MB)
2021-12-04 22:43:27,372 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 32 from broadcast at DAGScheduler.scala:1039
2021-12-04 22:43:27,372 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from ShuffleMapStage 45 (MapPartitionsRDD[55] at distinct at PaidPromotionAdjustParameter.scala:165) (first 15 tasks are for partitions Vector(0, 1))
2021-12-04 22:43:27,372 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 45.0 with 2 tasks
2021-12-04 22:43:27,372 [dispatcher-event-loop-6] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 45.0 (TID 76, localhost, executor driver, partition 0, ANY, 7885 bytes)
2021-12-04 22:43:27,373 [dispatcher-event-loop-6] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 45.0 (TID 77, localhost, executor driver, partition 1, ANY, 7885 bytes)
2021-12-04 22:43:27,373 [Executor task launch worker for task 77] INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 45.0 (TID 77)
2021-12-04 22:43:27,373 [Executor task launch worker for task 76] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 45.0 (TID 76)
2021-12-04 22:43:27,375 [Executor task launch worker for task 76] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/order_data.bcp:0+3442194
2021-12-04 22:43:27,375 [Executor task launch worker for task 77] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/order_data.bcp:3442194+3442195
2021-12-04 22:43:28,393 [Executor task launch worker for task 77] INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 45.0 (TID 77). 989 bytes result sent to driver
2021-12-04 22:43:28,394 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 45.0 (TID 77) in 1021 ms on localhost (executor driver) (1/2)
2021-12-04 22:43:28,411 [Executor task launch worker for task 76] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 45.0 (TID 76). 989 bytes result sent to driver
2021-12-04 22:43:28,411 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 45.0 (TID 76) in 1039 ms on localhost (executor driver) (2/2)
2021-12-04 22:43:28,411 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 45.0, whose tasks have all completed, from pool 
2021-12-04 22:43:28,411 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ShuffleMapStage 45 (distinct at PaidPromotionAdjustParameter.scala:165) finished in 1.043 s
2021-12-04 22:43:28,411 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - looking for newly runnable stages
2021-12-04 22:43:28,411 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - running: Set()
2021-12-04 22:43:28,411 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - waiting: Set(ResultStage 46)
2021-12-04 22:43:28,411 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - failed: Set()
2021-12-04 22:43:28,412 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 46 (MapPartitionsRDD[57] at distinct at PaidPromotionAdjustParameter.scala:165), which has no missing parents
2021-12-04 22:43:28,412 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_33 stored as values in memory (estimated size 3.7 KB, free 1990.0 MB)
2021-12-04 22:43:28,413 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_33_piece0 stored as bytes in memory (estimated size 2.2 KB, free 1990.0 MB)
2021-12-04 22:43:28,414 [dispatcher-event-loop-1] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_33_piece0 in memory on qb:60793 (size: 2.2 KB, free: 1990.6 MB)
2021-12-04 22:43:28,414 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 33 from broadcast at DAGScheduler.scala:1039
2021-12-04 22:43:28,414 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from ResultStage 46 (MapPartitionsRDD[57] at distinct at PaidPromotionAdjustParameter.scala:165) (first 15 tasks are for partitions Vector(0, 1))
2021-12-04 22:43:28,414 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 46.0 with 2 tasks
2021-12-04 22:43:28,415 [dispatcher-event-loop-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 46.0 (TID 78, localhost, executor driver, partition 0, ANY, 7649 bytes)
2021-12-04 22:43:28,415 [dispatcher-event-loop-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 46.0 (TID 79, localhost, executor driver, partition 1, ANY, 7649 bytes)
2021-12-04 22:43:28,415 [Executor task launch worker for task 78] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 46.0 (TID 78)
2021-12-04 22:43:28,417 [Executor task launch worker for task 79] INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 46.0 (TID 79)
2021-12-04 22:43:28,417 [Executor task launch worker for task 78] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 2 non-empty blocks out of 2 blocks
2021-12-04 22:43:28,417 [Executor task launch worker for task 78] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-04 22:43:28,418 [Executor task launch worker for task 79] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 2 non-empty blocks out of 2 blocks
2021-12-04 22:43:28,418 [Executor task launch worker for task 79] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-04 22:43:28,428 [Executor task launch worker for task 78] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 46.0 (TID 78). 1010 bytes result sent to driver
2021-12-04 22:43:28,428 [Executor task launch worker for task 79] INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 46.0 (TID 79). 1053 bytes result sent to driver
2021-12-04 22:43:28,429 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 46.0 (TID 79) in 14 ms on localhost (executor driver) (1/2)
2021-12-04 22:43:28,429 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 46.0 (TID 78) in 15 ms on localhost (executor driver) (2/2)
2021-12-04 22:43:28,429 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 46.0, whose tasks have all completed, from pool 
2021-12-04 22:43:28,429 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 46 (count at PaidPromotionAdjustParameter.scala:173) finished in 0.017 s
2021-12-04 22:43:28,429 [main] INFO [org.apache.spark.scheduler.DAGScheduler] - Job 18 finished: count at PaidPromotionAdjustParameter.scala:173, took 1.060677 s
2021-12-04 22:43:28,429 [main] INFO [PaidPromotion$] - 最终验证集节目数 = 79
2021-12-04 22:43:28,432 [main] INFO [org.apache.spark.SparkContext] - Starting job: count at PaidPromotionAdjustParameter.scala:174
2021-12-04 22:43:28,432 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 59 (intersection at PaidPromotionAdjustParameter.scala:166)
2021-12-04 22:43:28,432 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 58 (intersection at PaidPromotionAdjustParameter.scala:166)
2021-12-04 22:43:28,432 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 19 (count at PaidPromotionAdjustParameter.scala:174) with 4 output partitions
2021-12-04 22:43:28,432 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 51 (count at PaidPromotionAdjustParameter.scala:174)
2021-12-04 22:43:28,432 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 48, ShuffleMapStage 50)
2021-12-04 22:43:28,432 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List(ShuffleMapStage 48, ShuffleMapStage 50)
2021-12-04 22:43:28,432 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ShuffleMapStage 48 (MapPartitionsRDD[59] at intersection at PaidPromotionAdjustParameter.scala:166), which has no missing parents
2021-12-04 22:43:28,433 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_34 stored as values in memory (estimated size 4.0 KB, free 1990.0 MB)
2021-12-04 22:43:28,434 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_34_piece0 stored as bytes in memory (estimated size 2.3 KB, free 1990.0 MB)
2021-12-04 22:43:28,435 [dispatcher-event-loop-3] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_34_piece0 in memory on qb:60793 (size: 2.3 KB, free: 1990.6 MB)
2021-12-04 22:43:28,435 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 34 from broadcast at DAGScheduler.scala:1039
2021-12-04 22:43:28,435 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from ShuffleMapStage 48 (MapPartitionsRDD[59] at intersection at PaidPromotionAdjustParameter.scala:166) (first 15 tasks are for partitions Vector(0, 1))
2021-12-04 22:43:28,435 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 48.0 with 2 tasks
2021-12-04 22:43:28,435 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ShuffleMapStage 50 (MapPartitionsRDD[58] at intersection at PaidPromotionAdjustParameter.scala:166), which has no missing parents
2021-12-04 22:43:28,436 [dispatcher-event-loop-6] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 48.0 (TID 80, localhost, executor driver, partition 0, ANY, 7638 bytes)
2021-12-04 22:43:28,436 [dispatcher-event-loop-6] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 48.0 (TID 81, localhost, executor driver, partition 1, ANY, 7638 bytes)
2021-12-04 22:43:28,436 [Executor task launch worker for task 81] INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 48.0 (TID 81)
2021-12-04 22:43:28,436 [Executor task launch worker for task 80] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 48.0 (TID 80)
2021-12-04 22:43:28,436 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_35 stored as values in memory (estimated size 4.0 KB, free 1990.0 MB)
2021-12-04 22:43:28,436 [Executor task launch worker for task 81] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 2 non-empty blocks out of 2 blocks
2021-12-04 22:43:28,436 [Executor task launch worker for task 80] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 2 non-empty blocks out of 2 blocks
2021-12-04 22:43:28,436 [Executor task launch worker for task 81] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-04 22:43:28,437 [Executor task launch worker for task 80] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 1 ms
2021-12-04 22:43:28,438 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_35_piece0 stored as bytes in memory (estimated size 2.3 KB, free 1990.0 MB)
2021-12-04 22:43:28,438 [dispatcher-event-loop-8] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_35_piece0 in memory on qb:60793 (size: 2.3 KB, free: 1990.6 MB)
2021-12-04 22:43:28,438 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 35 from broadcast at DAGScheduler.scala:1039
2021-12-04 22:43:28,438 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 4 missing tasks from ShuffleMapStage 50 (MapPartitionsRDD[58] at intersection at PaidPromotionAdjustParameter.scala:166) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
2021-12-04 22:43:28,438 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 50.0 with 4 tasks
2021-12-04 22:43:28,439 [dispatcher-event-loop-7] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 50.0 (TID 82, localhost, executor driver, partition 0, ANY, 7638 bytes)
2021-12-04 22:43:28,439 [dispatcher-event-loop-7] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 50.0 (TID 83, localhost, executor driver, partition 1, ANY, 7638 bytes)
2021-12-04 22:43:28,439 [dispatcher-event-loop-7] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 2.0 in stage 50.0 (TID 84, localhost, executor driver, partition 2, ANY, 7638 bytes)
2021-12-04 22:43:28,439 [dispatcher-event-loop-7] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 3.0 in stage 50.0 (TID 85, localhost, executor driver, partition 3, ANY, 7638 bytes)
2021-12-04 22:43:28,439 [Executor task launch worker for task 84] INFO [org.apache.spark.executor.Executor] - Running task 2.0 in stage 50.0 (TID 84)
2021-12-04 22:43:28,439 [Executor task launch worker for task 83] INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 50.0 (TID 83)
2021-12-04 22:43:28,439 [Executor task launch worker for task 85] INFO [org.apache.spark.executor.Executor] - Running task 3.0 in stage 50.0 (TID 85)
2021-12-04 22:43:28,439 [Executor task launch worker for task 82] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 50.0 (TID 82)
2021-12-04 22:43:28,439 [Executor task launch worker for task 84] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 4 non-empty blocks out of 4 blocks
2021-12-04 22:43:28,439 [Executor task launch worker for task 84] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-04 22:43:28,439 [Executor task launch worker for task 82] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 4 non-empty blocks out of 4 blocks
2021-12-04 22:43:28,439 [Executor task launch worker for task 82] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-04 22:43:28,439 [Executor task launch worker for task 85] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 4 non-empty blocks out of 4 blocks
2021-12-04 22:43:28,439 [Executor task launch worker for task 83] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 4 non-empty blocks out of 4 blocks
2021-12-04 22:43:28,439 [Executor task launch worker for task 85] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-04 22:43:28,439 [Executor task launch worker for task 83] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-04 22:43:28,455 [Executor task launch worker for task 82] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 50.0 (TID 82). 1120 bytes result sent to driver
2021-12-04 22:43:28,456 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 50.0 (TID 82) in 17 ms on localhost (executor driver) (1/4)
2021-12-04 22:43:28,456 [Executor task launch worker for task 84] INFO [org.apache.spark.executor.Executor] - Finished task 2.0 in stage 50.0 (TID 84). 1120 bytes result sent to driver
2021-12-04 22:43:28,457 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 2.0 in stage 50.0 (TID 84) in 18 ms on localhost (executor driver) (2/4)
2021-12-04 22:43:28,457 [Executor task launch worker for task 85] INFO [org.apache.spark.executor.Executor] - Finished task 3.0 in stage 50.0 (TID 85). 1120 bytes result sent to driver
2021-12-04 22:43:28,458 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 3.0 in stage 50.0 (TID 85) in 19 ms on localhost (executor driver) (3/4)
2021-12-04 22:43:28,458 [Executor task launch worker for task 83] INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 50.0 (TID 83). 1120 bytes result sent to driver
2021-12-04 22:43:28,459 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 50.0 (TID 83) in 20 ms on localhost (executor driver) (4/4)
2021-12-04 22:43:28,459 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 50.0, whose tasks have all completed, from pool 
2021-12-04 22:43:28,459 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ShuffleMapStage 50 (intersection at PaidPromotionAdjustParameter.scala:166) finished in 0.023 s
2021-12-04 22:43:28,459 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - looking for newly runnable stages
2021-12-04 22:43:28,459 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - running: Set(ShuffleMapStage 48)
2021-12-04 22:43:28,459 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - waiting: Set(ResultStage 51)
2021-12-04 22:43:28,459 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - failed: Set()
2021-12-04 22:43:28,459 [Executor task launch worker for task 81] INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 48.0 (TID 81). 1120 bytes result sent to driver
2021-12-04 22:43:28,460 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 48.0 (TID 81) in 24 ms on localhost (executor driver) (1/2)
2021-12-04 22:43:28,461 [Executor task launch worker for task 80] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 48.0 (TID 80). 1120 bytes result sent to driver
2021-12-04 22:43:28,461 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 48.0 (TID 80) in 26 ms on localhost (executor driver) (2/2)
2021-12-04 22:43:28,461 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 48.0, whose tasks have all completed, from pool 
2021-12-04 22:43:28,461 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ShuffleMapStage 48 (intersection at PaidPromotionAdjustParameter.scala:166) finished in 0.028 s
2021-12-04 22:43:28,461 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - looking for newly runnable stages
2021-12-04 22:43:28,461 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - running: Set()
2021-12-04 22:43:28,461 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - waiting: Set(ResultStage 51)
2021-12-04 22:43:28,461 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - failed: Set()
2021-12-04 22:43:28,461 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 51 (MapPartitionsRDD[63] at intersection at PaidPromotionAdjustParameter.scala:166), which has no missing parents
2021-12-04 22:43:28,462 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_36 stored as values in memory (estimated size 3.6 KB, free 1990.0 MB)
2021-12-04 22:43:28,463 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_36_piece0 stored as bytes in memory (estimated size 2.1 KB, free 1990.0 MB)
2021-12-04 22:43:28,464 [dispatcher-event-loop-8] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_36_piece0 in memory on qb:60793 (size: 2.1 KB, free: 1990.6 MB)
2021-12-04 22:43:28,464 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 36 from broadcast at DAGScheduler.scala:1039
2021-12-04 22:43:28,464 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 4 missing tasks from ResultStage 51 (MapPartitionsRDD[63] at intersection at PaidPromotionAdjustParameter.scala:166) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
2021-12-04 22:43:28,464 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 51.0 with 4 tasks
2021-12-04 22:43:28,465 [dispatcher-event-loop-7] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 51.0 (TID 86, localhost, executor driver, partition 0, PROCESS_LOCAL, 7712 bytes)
2021-12-04 22:43:28,465 [dispatcher-event-loop-7] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 51.0 (TID 87, localhost, executor driver, partition 1, PROCESS_LOCAL, 7712 bytes)
2021-12-04 22:43:28,465 [dispatcher-event-loop-7] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 2.0 in stage 51.0 (TID 88, localhost, executor driver, partition 2, PROCESS_LOCAL, 7712 bytes)
2021-12-04 22:43:28,465 [dispatcher-event-loop-7] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 3.0 in stage 51.0 (TID 89, localhost, executor driver, partition 3, PROCESS_LOCAL, 7712 bytes)
2021-12-04 22:43:28,465 [Executor task launch worker for task 87] INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 51.0 (TID 87)
2021-12-04 22:43:28,465 [Executor task launch worker for task 89] INFO [org.apache.spark.executor.Executor] - Running task 3.0 in stage 51.0 (TID 89)
2021-12-04 22:43:28,465 [Executor task launch worker for task 86] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 51.0 (TID 86)
2021-12-04 22:43:28,465 [Executor task launch worker for task 88] INFO [org.apache.spark.executor.Executor] - Running task 2.0 in stage 51.0 (TID 88)
2021-12-04 22:43:28,466 [Executor task launch worker for task 86] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 4 blocks
2021-12-04 22:43:28,466 [Executor task launch worker for task 88] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 4 blocks
2021-12-04 22:43:28,466 [Executor task launch worker for task 86] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-04 22:43:28,466 [Executor task launch worker for task 88] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-04 22:43:28,466 [Executor task launch worker for task 87] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 4 blocks
2021-12-04 22:43:28,466 [Executor task launch worker for task 89] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 4 blocks
2021-12-04 22:43:28,466 [Executor task launch worker for task 89] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-04 22:43:28,466 [Executor task launch worker for task 87] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-04 22:43:28,467 [Executor task launch worker for task 89] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2021-12-04 22:43:28,467 [Executor task launch worker for task 89] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-04 22:43:28,467 [Executor task launch worker for task 88] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2021-12-04 22:43:28,467 [Executor task launch worker for task 86] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2021-12-04 22:43:28,468 [Executor task launch worker for task 86] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 1 ms
2021-12-04 22:43:28,468 [Executor task launch worker for task 87] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2021-12-04 22:43:28,468 [Executor task launch worker for task 88] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 1 ms
2021-12-04 22:43:28,468 [Executor task launch worker for task 87] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 1 ms
2021-12-04 22:43:28,475 [Executor task launch worker for task 87] INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 51.0 (TID 87). 1053 bytes result sent to driver
2021-12-04 22:43:28,475 [Executor task launch worker for task 89] INFO [org.apache.spark.executor.Executor] - Finished task 3.0 in stage 51.0 (TID 89). 1053 bytes result sent to driver
2021-12-04 22:43:28,475 [Executor task launch worker for task 86] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 51.0 (TID 86). 1053 bytes result sent to driver
2021-12-04 22:43:28,475 [Executor task launch worker for task 88] INFO [org.apache.spark.executor.Executor] - Finished task 2.0 in stage 51.0 (TID 88). 1053 bytes result sent to driver
2021-12-04 22:43:28,475 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 51.0 (TID 87) in 10 ms on localhost (executor driver) (1/4)
2021-12-04 22:43:28,475 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 3.0 in stage 51.0 (TID 89) in 10 ms on localhost (executor driver) (2/4)
2021-12-04 22:43:28,476 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 51.0 (TID 86) in 12 ms on localhost (executor driver) (3/4)
2021-12-04 22:43:28,476 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 2.0 in stage 51.0 (TID 88) in 11 ms on localhost (executor driver) (4/4)
2021-12-04 22:43:28,476 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 51.0, whose tasks have all completed, from pool 
2021-12-04 22:43:28,476 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 51 (count at PaidPromotionAdjustParameter.scala:174) finished in 0.015 s
2021-12-04 22:43:28,476 [main] INFO [org.apache.spark.scheduler.DAGScheduler] - Job 19 finished: count at PaidPromotionAdjustParameter.scala:174, took 0.045333 s
2021-12-04 22:43:28,477 [main] INFO [PaidPromotion$] - 最终共 同 节目数 = 79
2021-12-04 22:43:28,492 [main] INFO [org.apache.hadoop.conf.Configuration.deprecation] - mapred.output.dir is deprecated. Instead, use mapreduce.output.fileoutputformat.outputdir
2021-12-04 22:43:28,494 [main] INFO [org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter] - File Output Committer Algorithm version is 1
2021-12-04 22:43:28,543 [main] INFO [org.apache.spark.SparkContext] - Starting job: runJob at SparkHadoopWriter.scala:78
2021-12-04 22:43:28,544 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 20 (runJob at SparkHadoopWriter.scala:78) with 1 output partitions
2021-12-04 22:43:28,544 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 52 (runJob at SparkHadoopWriter.scala:78)
2021-12-04 22:43:28,544 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List()
2021-12-04 22:43:28,544 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2021-12-04 22:43:28,544 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 52 (MapPartitionsRDD[66] at saveAsTextFile at PaidPromotionAdjustParameter.scala:179), which has no missing parents
2021-12-04 22:43:28,553 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_37 stored as values in memory (estimated size 259.8 KB, free 1989.7 MB)
2021-12-04 22:43:28,555 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_37_piece0 stored as bytes in memory (estimated size 93.7 KB, free 1989.6 MB)
2021-12-04 22:43:28,555 [dispatcher-event-loop-2] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_37_piece0 in memory on qb:60793 (size: 93.7 KB, free: 1990.5 MB)
2021-12-04 22:43:28,556 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 37 from broadcast at DAGScheduler.scala:1039
2021-12-04 22:43:28,556 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 52 (MapPartitionsRDD[66] at saveAsTextFile at PaidPromotionAdjustParameter.scala:179) (first 15 tasks are for partitions Vector(0))
2021-12-04 22:43:28,556 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 52.0 with 1 tasks
2021-12-04 22:43:28,558 [dispatcher-event-loop-10] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 52.0 (TID 90, localhost, executor driver, partition 0, ANY, 8509 bytes)
2021-12-04 22:43:28,558 [Executor task launch worker for task 90] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 52.0 (TID 90)
2021-12-04 22:43:28,574 [Executor task launch worker for task 90] INFO [org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter] - File Output Committer Algorithm version is 1
2021-12-04 22:43:28,599 [Executor task launch worker for task 90] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/order_data.bcp:0+3442194
2021-12-04 22:43:28,783 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 776
2021-12-04 22:43:28,784 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 884
2021-12-04 22:43:28,785 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 868
2021-12-04 22:43:28,785 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 772
2021-12-04 22:43:28,785 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 891
2021-12-04 22:43:28,785 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 803
2021-12-04 22:43:28,785 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 786
2021-12-04 22:43:28,785 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 792
2021-12-04 22:43:28,785 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 879
2021-12-04 22:43:28,785 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 846
2021-12-04 22:43:28,785 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 757
2021-12-04 22:43:28,785 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 806
2021-12-04 22:43:28,785 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 819
2021-12-04 22:43:28,785 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 848
2021-12-04 22:43:28,785 [dispatcher-event-loop-0] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_36_piece0 on qb:60793 in memory (size: 2.1 KB, free: 1990.5 MB)
2021-12-04 22:43:28,786 [dispatcher-event-loop-4] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_30_piece0 on qb:60793 in memory (size: 65.5 KB, free: 1990.6 MB)
2021-12-04 22:43:28,786 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 883
2021-12-04 22:43:28,786 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 746
2021-12-04 22:43:28,786 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 737
2021-12-04 22:43:28,786 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 859
2021-12-04 22:43:28,786 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 851
2021-12-04 22:43:28,786 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 867
2021-12-04 22:43:28,787 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 743
2021-12-04 22:43:28,787 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 873
2021-12-04 22:43:28,787 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 807
2021-12-04 22:43:28,787 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 734
2021-12-04 22:43:28,787 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 758
2021-12-04 22:43:28,787 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 896
2021-12-04 22:43:28,787 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 783
2021-12-04 22:43:28,787 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 847
2021-12-04 22:43:28,787 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 882
2021-12-04 22:43:28,787 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 892
2021-12-04 22:43:28,787 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 845
2021-12-04 22:43:28,787 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 823
2021-12-04 22:43:28,787 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 755
2021-12-04 22:43:28,787 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 822
2021-12-04 22:43:28,787 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 843
2021-12-04 22:43:28,787 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 826
2021-12-04 22:43:28,787 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 796
2021-12-04 22:43:28,787 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 773
2021-12-04 22:43:28,787 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 860
2021-12-04 22:43:28,787 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 771
2021-12-04 22:43:28,787 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 727
2021-12-04 22:43:28,787 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 804
2021-12-04 22:43:28,787 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 797
2021-12-04 22:43:28,787 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 801
2021-12-04 22:43:28,787 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 836
2021-12-04 22:43:28,787 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 899
2021-12-04 22:43:28,787 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 787
2021-12-04 22:43:28,787 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 893
2021-12-04 22:43:28,787 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 820
2021-12-04 22:43:28,787 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 886
2021-12-04 22:43:28,787 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 732
2021-12-04 22:43:28,787 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 861
2021-12-04 22:43:28,787 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 887
2021-12-04 22:43:28,787 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 863
2021-12-04 22:43:28,787 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 753
2021-12-04 22:43:28,787 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 766
2021-12-04 22:43:28,787 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 852
2021-12-04 22:43:28,787 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 888
2021-12-04 22:43:28,787 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 802
2021-12-04 22:43:28,787 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 878
2021-12-04 22:43:28,788 [dispatcher-event-loop-11] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_34_piece0 on qb:60793 in memory (size: 2.3 KB, free: 1990.6 MB)
2021-12-04 22:43:28,788 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 795
2021-12-04 22:43:28,788 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 815
2021-12-04 22:43:28,788 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 853
2021-12-04 22:43:28,788 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 813
2021-12-04 22:43:28,788 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 794
2021-12-04 22:43:28,788 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 817
2021-12-04 22:43:28,788 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 744
2021-12-04 22:43:28,788 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 774
2021-12-04 22:43:28,788 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 842
2021-12-04 22:43:28,788 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 855
2021-12-04 22:43:28,788 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 897
2021-12-04 22:43:28,788 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 894
2021-12-04 22:43:28,788 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 761
2021-12-04 22:43:28,788 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 748
2021-12-04 22:43:28,788 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 760
2021-12-04 22:43:28,788 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 816
2021-12-04 22:43:28,788 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 877
2021-12-04 22:43:28,788 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 895
2021-12-04 22:43:28,788 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 821
2021-12-04 22:43:28,788 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 805
2021-12-04 22:43:28,788 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 834
2021-12-04 22:43:28,788 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 782
2021-12-04 22:43:28,788 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 729
2021-12-04 22:43:28,788 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 810
2021-12-04 22:43:28,788 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 811
2021-12-04 22:43:28,788 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 764
2021-12-04 22:43:28,788 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 808
2021-12-04 22:43:28,788 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 784
2021-12-04 22:43:28,788 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 793
2021-12-04 22:43:28,788 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 862
2021-12-04 22:43:28,788 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 849
2021-12-04 22:43:28,788 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 731
2021-12-04 22:43:28,788 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 827
2021-12-04 22:43:28,788 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 750
2021-12-04 22:43:28,788 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 866
2021-12-04 22:43:28,788 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 780
2021-12-04 22:43:28,788 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 839
2021-12-04 22:43:28,788 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 837
2021-12-04 22:43:28,788 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 841
2021-12-04 22:43:28,788 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 790
2021-12-04 22:43:28,788 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 854
2021-12-04 22:43:28,788 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 736
2021-12-04 22:43:28,788 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 778
2021-12-04 22:43:28,788 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 830
2021-12-04 22:43:28,789 [dispatcher-event-loop-8] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_35_piece0 on qb:60793 in memory (size: 2.3 KB, free: 1990.6 MB)
2021-12-04 22:43:28,789 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 756
2021-12-04 22:43:28,789 [dispatcher-event-loop-0] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_32_piece0 on qb:60793 in memory (size: 65.2 KB, free: 1990.7 MB)
2021-12-04 22:43:28,789 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 885
2021-12-04 22:43:28,789 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 831
2021-12-04 22:43:28,789 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 871
2021-12-04 22:43:28,789 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 788
2021-12-04 22:43:28,789 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 856
2021-12-04 22:43:28,789 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 798
2021-12-04 22:43:28,789 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 857
2021-12-04 22:43:28,789 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 751
2021-12-04 22:43:28,789 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 809
2021-12-04 22:43:28,789 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 742
2021-12-04 22:43:28,790 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 728
2021-12-04 22:43:28,790 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 759
2021-12-04 22:43:28,790 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 775
2021-12-04 22:43:28,790 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 818
2021-12-04 22:43:28,790 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 838
2021-12-04 22:43:28,790 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 763
2021-12-04 22:43:28,790 [dispatcher-event-loop-4] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_31_piece0 on qb:60793 in memory (size: 2.2 KB, free: 1990.7 MB)
2021-12-04 22:43:28,790 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 880
2021-12-04 22:43:28,790 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 730
2021-12-04 22:43:28,790 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 812
2021-12-04 22:43:28,790 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 858
2021-12-04 22:43:28,790 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 876
2021-12-04 22:43:28,790 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 733
2021-12-04 22:43:28,790 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 829
2021-12-04 22:43:28,790 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 738
2021-12-04 22:43:28,790 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 814
2021-12-04 22:43:28,790 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 770
2021-12-04 22:43:28,790 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 835
2021-12-04 22:43:28,790 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 735
2021-12-04 22:43:28,790 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 890
2021-12-04 22:43:28,790 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 791
2021-12-04 22:43:28,790 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 777
2021-12-04 22:43:28,790 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 739
2021-12-04 22:43:28,791 [dispatcher-event-loop-11] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_33_piece0 on qb:60793 in memory (size: 2.2 KB, free: 1990.7 MB)
2021-12-04 22:43:28,791 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 767
2021-12-04 22:43:28,791 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 850
2021-12-04 22:43:28,791 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 800
2021-12-04 22:43:28,791 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 881
2021-12-04 22:43:28,791 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 872
2021-12-04 22:43:28,791 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 889
2021-12-04 22:43:28,791 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 875
2021-12-04 22:43:28,791 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 725
2021-12-04 22:43:28,791 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 779
2021-12-04 22:43:28,791 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 828
2021-12-04 22:43:28,791 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 840
2021-12-04 22:43:28,791 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 789
2021-12-04 22:43:28,791 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 824
2021-12-04 22:43:28,791 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 752
2021-12-04 22:43:28,791 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 898
2021-12-04 22:43:28,791 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 833
2021-12-04 22:43:28,791 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 741
2021-12-04 22:43:28,791 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 844
2021-12-04 22:43:28,791 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 762
2021-12-04 22:43:28,791 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 769
2021-12-04 22:43:28,791 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 825
2021-12-04 22:43:28,791 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 754
2021-12-04 22:43:28,791 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 785
2021-12-04 22:43:28,791 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 749
2021-12-04 22:43:28,791 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 832
2021-12-04 22:43:28,791 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 874
2021-12-04 22:43:28,791 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 765
2021-12-04 22:43:28,791 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 869
2021-12-04 22:43:28,791 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 768
2021-12-04 22:43:28,791 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 781
2021-12-04 22:43:28,791 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 740
2021-12-04 22:43:28,792 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 745
2021-12-04 22:43:28,792 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 747
2021-12-04 22:43:28,792 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 799
2021-12-04 22:43:28,792 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 865
2021-12-04 22:43:28,792 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 726
2021-12-04 22:43:28,792 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 864
2021-12-04 22:43:28,792 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 870
2021-12-04 22:43:29,270 [Executor task launch worker for task 90] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/order_data.bcp:3442194+3442195
2021-12-04 22:43:29,923 [Executor task launch worker for task 90] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/order_data.bcp:0+3442194
2021-12-04 22:43:30,236 [Executor task launch worker for task 90] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/order_data.bcp:3442194+3442195
2021-12-04 22:43:30,633 [Executor task launch worker for task 90] INFO [org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter] - Saved output of task 'attempt_20211204224328_0066_m_000000_0' to hdfs://hdp1:8020/sk/chongqing/handle_data/set-train-device-production-data/_temporary/0/task_20211204224328_0066_m_000000
2021-12-04 22:43:30,634 [Executor task launch worker for task 90] INFO [org.apache.spark.mapred.SparkHadoopMapRedUtil] - attempt_20211204224328_0066_m_000000_0: Committed
2021-12-04 22:43:30,635 [Executor task launch worker for task 90] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 52.0 (TID 90). 1041 bytes result sent to driver
2021-12-04 22:43:30,638 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 52.0 (TID 90) in 2082 ms on localhost (executor driver) (1/1)
2021-12-04 22:43:30,638 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 52.0, whose tasks have all completed, from pool 
2021-12-04 22:43:30,638 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 52 (runJob at SparkHadoopWriter.scala:78) finished in 2.094 s
2021-12-04 22:43:30,639 [main] INFO [org.apache.spark.scheduler.DAGScheduler] - Job 20 finished: runJob at SparkHadoopWriter.scala:78, took 2.096246 s
2021-12-04 22:43:30,696 [main] INFO [org.apache.spark.internal.io.SparkHadoopWriter] - Job job_20211204224328_0066 committed.
2021-12-04 22:43:30,701 [main] INFO [org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter] - File Output Committer Algorithm version is 1
2021-12-04 22:43:30,715 [main] INFO [org.apache.spark.SparkContext] - Starting job: runJob at SparkHadoopWriter.scala:78
2021-12-04 22:43:30,716 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 21 (runJob at SparkHadoopWriter.scala:78) with 1 output partitions
2021-12-04 22:43:30,716 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 53 (runJob at SparkHadoopWriter.scala:78)
2021-12-04 22:43:30,716 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List()
2021-12-04 22:43:30,716 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2021-12-04 22:43:30,716 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 53 (MapPartitionsRDD[69] at saveAsTextFile at PaidPromotionAdjustParameter.scala:182), which has no missing parents
2021-12-04 22:43:30,724 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_38 stored as values in memory (estimated size 259.2 KB, free 1989.9 MB)
2021-12-04 22:43:30,726 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_38_piece0 stored as bytes in memory (estimated size 93.4 KB, free 1989.8 MB)
2021-12-04 22:43:30,726 [dispatcher-event-loop-8] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_38_piece0 in memory on qb:60793 (size: 93.4 KB, free: 1990.6 MB)
2021-12-04 22:43:30,727 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 38 from broadcast at DAGScheduler.scala:1039
2021-12-04 22:43:30,727 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 53 (MapPartitionsRDD[69] at saveAsTextFile at PaidPromotionAdjustParameter.scala:182) (first 15 tasks are for partitions Vector(0))
2021-12-04 22:43:30,727 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 53.0 with 1 tasks
2021-12-04 22:43:30,728 [dispatcher-event-loop-7] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 53.0 (TID 91, localhost, executor driver, partition 0, ANY, 8337 bytes)
2021-12-04 22:43:30,728 [Executor task launch worker for task 91] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 53.0 (TID 91)
2021-12-04 22:43:30,733 [Executor task launch worker for task 91] INFO [org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter] - File Output Committer Algorithm version is 1
2021-12-04 22:43:30,741 [Executor task launch worker for task 91] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/order_data.bcp:0+3442194
2021-12-04 22:43:31,424 [dispatcher-event-loop-5] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_37_piece0 on qb:60793 in memory (size: 93.7 KB, free: 1990.7 MB)
2021-12-04 22:43:31,424 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 906
2021-12-04 22:43:31,424 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 915
2021-12-04 22:43:31,424 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 913
2021-12-04 22:43:31,424 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 911
2021-12-04 22:43:31,424 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 917
2021-12-04 22:43:31,424 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 916
2021-12-04 22:43:31,424 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 923
2021-12-04 22:43:31,424 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 910
2021-12-04 22:43:31,424 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 920
2021-12-04 22:43:31,424 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 905
2021-12-04 22:43:31,424 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 900
2021-12-04 22:43:31,424 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 922
2021-12-04 22:43:31,424 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 904
2021-12-04 22:43:31,424 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 907
2021-12-04 22:43:31,424 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 908
2021-12-04 22:43:31,424 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 912
2021-12-04 22:43:31,424 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 901
2021-12-04 22:43:31,424 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 919
2021-12-04 22:43:31,424 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 924
2021-12-04 22:43:31,424 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 909
2021-12-04 22:43:31,424 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 921
2021-12-04 22:43:31,424 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 902
2021-12-04 22:43:31,424 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 914
2021-12-04 22:43:31,424 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 903
2021-12-04 22:43:31,424 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 918
2021-12-04 22:43:31,659 [Executor task launch worker for task 91] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/order_data.bcp:3442194+3442195
2021-12-04 22:43:32,533 [Executor task launch worker for task 91] INFO [org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter] - Saved output of task 'attempt_20211204224330_0069_m_000000_0' to hdfs://hdp1:8020/sk/chongqing/handle_data/set-validation-device-production-data/_temporary/0/task_20211204224330_0069_m_000000
2021-12-04 22:43:32,533 [Executor task launch worker for task 91] INFO [org.apache.spark.mapred.SparkHadoopMapRedUtil] - attempt_20211204224330_0069_m_000000_0: Committed
2021-12-04 22:43:32,534 [Executor task launch worker for task 91] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 53.0 (TID 91). 998 bytes result sent to driver
2021-12-04 22:43:32,535 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 53.0 (TID 91) in 1808 ms on localhost (executor driver) (1/1)
2021-12-04 22:43:32,535 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 53.0, whose tasks have all completed, from pool 
2021-12-04 22:43:32,535 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 53 (runJob at SparkHadoopWriter.scala:78) finished in 1.819 s
2021-12-04 22:43:32,536 [main] INFO [org.apache.spark.scheduler.DAGScheduler] - Job 21 finished: runJob at SparkHadoopWriter.scala:78, took 1.819941 s
2021-12-04 22:43:32,584 [main] INFO [org.apache.spark.internal.io.SparkHadoopWriter] - Job job_20211204224330_0069 committed.
2021-12-04 22:43:32,600 [main] INFO [PaidPromotion$] - 验证集用户实际观看列表-----------------------------------
2021-12-04 22:43:32,602 [main] INFO [org.apache.spark.SparkContext] - Starting job: count at PaidPromotionAdjustParameter.scala:192
2021-12-04 22:43:32,602 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 33 (filter at PaidPromotionAdjustParameter.scala:150)
2021-12-04 22:43:32,602 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 22 (count at PaidPromotionAdjustParameter.scala:192) with 2 output partitions
2021-12-04 22:43:32,602 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 55 (count at PaidPromotionAdjustParameter.scala:192)
2021-12-04 22:43:32,602 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 54)
2021-12-04 22:43:32,602 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List(ShuffleMapStage 54)
2021-12-04 22:43:32,602 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ShuffleMapStage 54 (MapPartitionsRDD[33] at filter at PaidPromotionAdjustParameter.scala:150), which has no missing parents
2021-12-04 22:43:32,604 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_39 stored as values in memory (estimated size 184.6 KB, free 1989.9 MB)
2021-12-04 22:43:32,607 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_39_piece0 stored as bytes in memory (estimated size 65.3 KB, free 1989.9 MB)
2021-12-04 22:43:32,607 [dispatcher-event-loop-6] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_39_piece0 in memory on qb:60793 (size: 65.3 KB, free: 1990.6 MB)
2021-12-04 22:43:32,607 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 39 from broadcast at DAGScheduler.scala:1039
2021-12-04 22:43:32,607 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from ShuffleMapStage 54 (MapPartitionsRDD[33] at filter at PaidPromotionAdjustParameter.scala:150) (first 15 tasks are for partitions Vector(0, 1))
2021-12-04 22:43:32,607 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 54.0 with 2 tasks
2021-12-04 22:43:32,608 [dispatcher-event-loop-11] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 54.0 (TID 92, localhost, executor driver, partition 0, ANY, 7885 bytes)
2021-12-04 22:43:32,608 [dispatcher-event-loop-11] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 54.0 (TID 93, localhost, executor driver, partition 1, ANY, 7885 bytes)
2021-12-04 22:43:32,608 [Executor task launch worker for task 93] INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 54.0 (TID 93)
2021-12-04 22:43:32,608 [Executor task launch worker for task 92] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 54.0 (TID 92)
2021-12-04 22:43:32,611 [Executor task launch worker for task 92] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/order_data.bcp:0+3442194
2021-12-04 22:43:32,611 [Executor task launch worker for task 93] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/order_data.bcp:3442194+3442195
2021-12-04 22:43:33,868 [Executor task launch worker for task 92] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 54.0 (TID 92). 860 bytes result sent to driver
2021-12-04 22:43:33,868 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 54.0 (TID 92) in 1260 ms on localhost (executor driver) (1/2)
2021-12-04 22:43:34,057 [Executor task launch worker for task 93] INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 54.0 (TID 93). 860 bytes result sent to driver
2021-12-04 22:43:34,057 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 54.0 (TID 93) in 1449 ms on localhost (executor driver) (2/2)
2021-12-04 22:43:34,057 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 54.0, whose tasks have all completed, from pool 
2021-12-04 22:43:34,058 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ShuffleMapStage 54 (filter at PaidPromotionAdjustParameter.scala:150) finished in 1.455 s
2021-12-04 22:43:34,058 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - looking for newly runnable stages
2021-12-04 22:43:34,058 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - running: Set()
2021-12-04 22:43:34,058 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - waiting: Set(ResultStage 55)
2021-12-04 22:43:34,058 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - failed: Set()
2021-12-04 22:43:34,058 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 55 (MapPartitionsRDD[71] at map at PaidPromotionAdjustParameter.scala:186), which has no missing parents
2021-12-04 22:43:34,060 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_40 stored as values in memory (estimated size 185.5 KB, free 1989.7 MB)
2021-12-04 22:43:34,062 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_40_piece0 stored as bytes in memory (estimated size 65.7 KB, free 1989.6 MB)
2021-12-04 22:43:34,062 [dispatcher-event-loop-9] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_40_piece0 in memory on qb:60793 (size: 65.7 KB, free: 1990.6 MB)
2021-12-04 22:43:34,063 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 40 from broadcast at DAGScheduler.scala:1039
2021-12-04 22:43:34,063 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from ResultStage 55 (MapPartitionsRDD[71] at map at PaidPromotionAdjustParameter.scala:186) (first 15 tasks are for partitions Vector(0, 1))
2021-12-04 22:43:34,063 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 55.0 with 2 tasks
2021-12-04 22:43:34,063 [dispatcher-event-loop-5] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 55.0 (TID 94, localhost, executor driver, partition 0, ANY, 7649 bytes)
2021-12-04 22:43:34,063 [dispatcher-event-loop-5] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 55.0 (TID 95, localhost, executor driver, partition 1, ANY, 7649 bytes)
2021-12-04 22:43:34,063 [Executor task launch worker for task 94] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 55.0 (TID 94)
2021-12-04 22:43:34,063 [Executor task launch worker for task 95] INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 55.0 (TID 95)
2021-12-04 22:43:34,065 [Executor task launch worker for task 95] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 2 non-empty blocks out of 2 blocks
2021-12-04 22:43:34,065 [Executor task launch worker for task 95] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-04 22:43:34,065 [Executor task launch worker for task 94] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 2 non-empty blocks out of 2 blocks
2021-12-04 22:43:34,065 [Executor task launch worker for task 94] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-04 22:43:34,100 [Executor task launch worker for task 95] INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 55.0 (TID 95). 1054 bytes result sent to driver
2021-12-04 22:43:34,100 [Executor task launch worker for task 94] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 55.0 (TID 94). 1054 bytes result sent to driver
2021-12-04 22:43:34,101 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 55.0 (TID 95) in 38 ms on localhost (executor driver) (1/2)
2021-12-04 22:43:34,101 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 55.0 (TID 94) in 38 ms on localhost (executor driver) (2/2)
2021-12-04 22:43:34,101 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 55.0, whose tasks have all completed, from pool 
2021-12-04 22:43:34,101 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 55 (count at PaidPromotionAdjustParameter.scala:192) finished in 0.043 s
2021-12-04 22:43:34,101 [main] INFO [org.apache.spark.scheduler.DAGScheduler] - Job 22 finished: count at PaidPromotionAdjustParameter.scala:192, took 1.498881 s
2021-12-04 22:43:34,101 [main] INFO [PaidPromotion$] - 验证集用户列表数量：5130
2021-12-04 22:43:34,109 [main] INFO [org.apache.spark.SparkContext] - Starting job: take at PaidPromotionAdjustParameter.scala:193
2021-12-04 22:43:34,109 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 23 (take at PaidPromotionAdjustParameter.scala:193) with 1 output partitions
2021-12-04 22:43:34,109 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 57 (take at PaidPromotionAdjustParameter.scala:193)
2021-12-04 22:43:34,109 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 56)
2021-12-04 22:43:34,109 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2021-12-04 22:43:34,109 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 57 (MapPartitionsRDD[71] at map at PaidPromotionAdjustParameter.scala:186), which has no missing parents
2021-12-04 22:43:34,111 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_41 stored as values in memory (estimated size 185.7 KB, free 1989.5 MB)
2021-12-04 22:43:34,113 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_41_piece0 stored as bytes in memory (estimated size 65.7 KB, free 1989.4 MB)
2021-12-04 22:43:34,113 [dispatcher-event-loop-2] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_41_piece0 in memory on qb:60793 (size: 65.7 KB, free: 1990.5 MB)
2021-12-04 22:43:34,113 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 41 from broadcast at DAGScheduler.scala:1039
2021-12-04 22:43:34,114 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 57 (MapPartitionsRDD[71] at map at PaidPromotionAdjustParameter.scala:186) (first 15 tasks are for partitions Vector(0))
2021-12-04 22:43:34,114 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 57.0 with 1 tasks
2021-12-04 22:43:34,114 [dispatcher-event-loop-10] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 57.0 (TID 96, localhost, executor driver, partition 0, ANY, 7649 bytes)
2021-12-04 22:43:34,114 [Executor task launch worker for task 96] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 57.0 (TID 96)
2021-12-04 22:43:34,116 [Executor task launch worker for task 96] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 2 non-empty blocks out of 2 blocks
2021-12-04 22:43:34,116 [Executor task launch worker for task 96] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-04 22:43:34,131 [Executor task launch worker for task 96] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 57.0 (TID 96). 2614 bytes result sent to driver
2021-12-04 22:43:34,131 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 57.0 (TID 96) in 17 ms on localhost (executor driver) (1/1)
2021-12-04 22:43:34,132 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 57.0, whose tasks have all completed, from pool 
2021-12-04 22:43:34,132 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 57 (take at PaidPromotionAdjustParameter.scala:193) finished in 0.022 s
2021-12-04 22:43:34,132 [main] INFO [org.apache.spark.scheduler.DAGScheduler] - Job 23 finished: take at PaidPromotionAdjustParameter.scala:193, took 0.023009 s
2021-12-04 22:43:34,144 [main] INFO [PaidPromotion$] - 训练集用户实际观看列表-----------------------------------
2021-12-04 22:43:34,145 [main] INFO [org.apache.spark.SparkContext] - Starting job: count at PaidPromotionAdjustParameter.scala:203
2021-12-04 22:43:34,146 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 35 (union at PaidPromotionAdjustParameter.scala:154)
2021-12-04 22:43:34,146 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 24 (count at PaidPromotionAdjustParameter.scala:203) with 4 output partitions
2021-12-04 22:43:34,146 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 59 (count at PaidPromotionAdjustParameter.scala:203)
2021-12-04 22:43:34,146 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 58)
2021-12-04 22:43:34,146 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List(ShuffleMapStage 58)
2021-12-04 22:43:34,146 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ShuffleMapStage 58 (UnionRDD[35] at union at PaidPromotionAdjustParameter.scala:154), which has no missing parents
2021-12-04 22:43:34,147 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_42 stored as values in memory (estimated size 185.2 KB, free 1989.2 MB)
2021-12-04 22:43:34,149 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_42_piece0 stored as bytes in memory (estimated size 65.7 KB, free 1989.1 MB)
2021-12-04 22:43:34,149 [dispatcher-event-loop-1] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_42_piece0 in memory on qb:60793 (size: 65.7 KB, free: 1990.4 MB)
2021-12-04 22:43:34,150 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 42 from broadcast at DAGScheduler.scala:1039
2021-12-04 22:43:34,150 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 4 missing tasks from ShuffleMapStage 58 (UnionRDD[35] at union at PaidPromotionAdjustParameter.scala:154) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
2021-12-04 22:43:34,150 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 58.0 with 4 tasks
2021-12-04 22:43:34,151 [dispatcher-event-loop-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 58.0 (TID 97, localhost, executor driver, partition 0, ANY, 7994 bytes)
2021-12-04 22:43:34,151 [dispatcher-event-loop-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 58.0 (TID 98, localhost, executor driver, partition 1, ANY, 7994 bytes)
2021-12-04 22:43:34,151 [dispatcher-event-loop-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 2.0 in stage 58.0 (TID 99, localhost, executor driver, partition 2, ANY, 7994 bytes)
2021-12-04 22:43:34,151 [dispatcher-event-loop-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 3.0 in stage 58.0 (TID 100, localhost, executor driver, partition 3, ANY, 7994 bytes)
2021-12-04 22:43:34,151 [Executor task launch worker for task 97] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 58.0 (TID 97)
2021-12-04 22:43:34,151 [Executor task launch worker for task 99] INFO [org.apache.spark.executor.Executor] - Running task 2.0 in stage 58.0 (TID 99)
2021-12-04 22:43:34,151 [Executor task launch worker for task 98] INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 58.0 (TID 98)
2021-12-04 22:43:34,151 [Executor task launch worker for task 100] INFO [org.apache.spark.executor.Executor] - Running task 3.0 in stage 58.0 (TID 100)
2021-12-04 22:43:34,153 [Executor task launch worker for task 97] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/order_data.bcp:0+3442194
2021-12-04 22:43:34,153 [Executor task launch worker for task 100] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/order_data.bcp:3442194+3442195
2021-12-04 22:43:34,154 [Executor task launch worker for task 99] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/order_data.bcp:0+3442194
2021-12-04 22:43:34,154 [Executor task launch worker for task 98] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/order_data.bcp:3442194+3442195
2021-12-04 22:43:34,819 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 982
2021-12-04 22:43:34,819 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 952
2021-12-04 22:43:34,819 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 963
2021-12-04 22:43:34,819 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 998
2021-12-04 22:43:34,819 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 964
2021-12-04 22:43:34,819 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 938
2021-12-04 22:43:34,819 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1002
2021-12-04 22:43:34,819 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 944
2021-12-04 22:43:34,819 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 933
2021-12-04 22:43:34,819 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 949
2021-12-04 22:43:34,819 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 986
2021-12-04 22:43:34,819 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 992
2021-12-04 22:43:34,819 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 947
2021-12-04 22:43:34,819 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1006
2021-12-04 22:43:34,819 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1012
2021-12-04 22:43:34,819 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 991
2021-12-04 22:43:34,819 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 951
2021-12-04 22:43:34,819 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1023
2021-12-04 22:43:34,819 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 943
2021-12-04 22:43:34,819 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 931
2021-12-04 22:43:34,819 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 937
2021-12-04 22:43:34,819 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 957
2021-12-04 22:43:34,819 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 994
2021-12-04 22:43:34,819 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1004
2021-12-04 22:43:34,819 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1022
2021-12-04 22:43:34,819 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 929
2021-12-04 22:43:34,819 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 987
2021-12-04 22:43:34,819 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 974
2021-12-04 22:43:34,819 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 928
2021-12-04 22:43:34,819 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 930
2021-12-04 22:43:34,819 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 953
2021-12-04 22:43:34,819 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 926
2021-12-04 22:43:34,819 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1007
2021-12-04 22:43:34,819 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1008
2021-12-04 22:43:34,819 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 961
2021-12-04 22:43:34,819 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 955
2021-12-04 22:43:34,819 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 946
2021-12-04 22:43:34,819 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 962
2021-12-04 22:43:34,819 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1003
2021-12-04 22:43:34,819 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1018
2021-12-04 22:43:34,819 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 939
2021-12-04 22:43:34,819 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 927
2021-12-04 22:43:34,819 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 932
2021-12-04 22:43:34,819 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 968
2021-12-04 22:43:34,820 [dispatcher-event-loop-2] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_39_piece0 on qb:60793 in memory (size: 65.3 KB, free: 1990.5 MB)
2021-12-04 22:43:34,820 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1017
2021-12-04 22:43:34,820 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 973
2021-12-04 22:43:34,820 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 969
2021-12-04 22:43:34,820 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 958
2021-12-04 22:43:34,820 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 925
2021-12-04 22:43:34,820 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 980
2021-12-04 22:43:34,820 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 935
2021-12-04 22:43:34,820 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 997
2021-12-04 22:43:34,820 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 959
2021-12-04 22:43:34,820 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 965
2021-12-04 22:43:34,820 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 954
2021-12-04 22:43:34,820 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 975
2021-12-04 22:43:34,820 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1001
2021-12-04 22:43:34,820 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 971
2021-12-04 22:43:34,820 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 978
2021-12-04 22:43:34,820 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 988
2021-12-04 22:43:34,820 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 979
2021-12-04 22:43:34,821 [dispatcher-event-loop-7] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_38_piece0 on qb:60793 in memory (size: 93.4 KB, free: 1990.6 MB)
2021-12-04 22:43:34,821 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 985
2021-12-04 22:43:34,821 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 945
2021-12-04 22:43:34,821 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 948
2021-12-04 22:43:34,821 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 966
2021-12-04 22:43:34,821 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1019
2021-12-04 22:43:34,821 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1021
2021-12-04 22:43:34,821 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1005
2021-12-04 22:43:34,821 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 984
2021-12-04 22:43:34,821 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1024
2021-12-04 22:43:34,821 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 934
2021-12-04 22:43:34,821 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 993
2021-12-04 22:43:34,821 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 977
2021-12-04 22:43:34,821 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1011
2021-12-04 22:43:34,821 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 989
2021-12-04 22:43:34,821 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1020
2021-12-04 22:43:34,821 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 999
2021-12-04 22:43:34,821 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 972
2021-12-04 22:43:34,821 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 996
2021-12-04 22:43:34,821 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 942
2021-12-04 22:43:34,822 [dispatcher-event-loop-9] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_41_piece0 on qb:60793 in memory (size: 65.7 KB, free: 1990.6 MB)
2021-12-04 22:43:34,822 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 960
2021-12-04 22:43:34,822 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 990
2021-12-04 22:43:34,822 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 983
2021-12-04 22:43:34,822 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 970
2021-12-04 22:43:34,822 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1014
2021-12-04 22:43:34,822 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 995
2021-12-04 22:43:34,822 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1015
2021-12-04 22:43:34,822 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 981
2021-12-04 22:43:34,822 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1013
2021-12-04 22:43:34,822 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 936
2021-12-04 22:43:34,822 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 967
2021-12-04 22:43:34,822 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 976
2021-12-04 22:43:34,822 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1010
2021-12-04 22:43:34,822 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 941
2021-12-04 22:43:34,822 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 940
2021-12-04 22:43:34,822 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 950
2021-12-04 22:43:34,822 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 956
2021-12-04 22:43:34,822 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1000
2021-12-04 22:43:34,822 [dispatcher-event-loop-3] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_40_piece0 on qb:60793 in memory (size: 65.7 KB, free: 1990.7 MB)
2021-12-04 22:43:34,823 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1009
2021-12-04 22:43:34,823 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1016
2021-12-04 22:43:34,894 [Executor task launch worker for task 100] INFO [org.apache.spark.executor.Executor] - Finished task 3.0 in stage 58.0 (TID 100). 948 bytes result sent to driver
2021-12-04 22:43:34,894 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 3.0 in stage 58.0 (TID 100) in 743 ms on localhost (executor driver) (1/4)
2021-12-04 22:43:35,115 [Executor task launch worker for task 98] INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 58.0 (TID 98). 948 bytes result sent to driver
2021-12-04 22:43:35,115 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 58.0 (TID 98) in 964 ms on localhost (executor driver) (2/4)
2021-12-04 22:43:35,302 [Executor task launch worker for task 99] INFO [org.apache.spark.executor.Executor] - Finished task 2.0 in stage 58.0 (TID 99). 948 bytes result sent to driver
2021-12-04 22:43:35,303 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 2.0 in stage 58.0 (TID 99) in 1152 ms on localhost (executor driver) (3/4)
2021-12-04 22:43:35,469 [Executor task launch worker for task 97] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 58.0 (TID 97). 948 bytes result sent to driver
2021-12-04 22:43:35,469 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 58.0 (TID 97) in 1318 ms on localhost (executor driver) (4/4)
2021-12-04 22:43:35,469 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 58.0, whose tasks have all completed, from pool 
2021-12-04 22:43:35,469 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ShuffleMapStage 58 (union at PaidPromotionAdjustParameter.scala:154) finished in 1.323 s
2021-12-04 22:43:35,469 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - looking for newly runnable stages
2021-12-04 22:43:35,469 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - running: Set()
2021-12-04 22:43:35,469 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - waiting: Set(ResultStage 59)
2021-12-04 22:43:35,469 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - failed: Set()
2021-12-04 22:43:35,469 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 59 (MapPartitionsRDD[73] at map at PaidPromotionAdjustParameter.scala:197), which has no missing parents
2021-12-04 22:43:35,471 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_43 stored as values in memory (estimated size 186.1 KB, free 1990.0 MB)
2021-12-04 22:43:35,472 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_43_piece0 stored as bytes in memory (estimated size 66.1 KB, free 1990.0 MB)
2021-12-04 22:43:35,472 [dispatcher-event-loop-8] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_43_piece0 in memory on qb:60793 (size: 66.1 KB, free: 1990.6 MB)
2021-12-04 22:43:35,473 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 43 from broadcast at DAGScheduler.scala:1039
2021-12-04 22:43:35,473 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 4 missing tasks from ResultStage 59 (MapPartitionsRDD[73] at map at PaidPromotionAdjustParameter.scala:197) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
2021-12-04 22:43:35,473 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 59.0 with 4 tasks
2021-12-04 22:43:35,473 [dispatcher-event-loop-7] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 59.0 (TID 101, localhost, executor driver, partition 0, ANY, 7649 bytes)
2021-12-04 22:43:35,473 [dispatcher-event-loop-7] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 59.0 (TID 102, localhost, executor driver, partition 1, ANY, 7649 bytes)
2021-12-04 22:43:35,473 [dispatcher-event-loop-7] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 2.0 in stage 59.0 (TID 103, localhost, executor driver, partition 2, ANY, 7649 bytes)
2021-12-04 22:43:35,473 [dispatcher-event-loop-7] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 3.0 in stage 59.0 (TID 104, localhost, executor driver, partition 3, ANY, 7649 bytes)
2021-12-04 22:43:35,473 [Executor task launch worker for task 101] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 59.0 (TID 101)
2021-12-04 22:43:35,473 [Executor task launch worker for task 103] INFO [org.apache.spark.executor.Executor] - Running task 2.0 in stage 59.0 (TID 103)
2021-12-04 22:43:35,473 [Executor task launch worker for task 104] INFO [org.apache.spark.executor.Executor] - Running task 3.0 in stage 59.0 (TID 104)
2021-12-04 22:43:35,473 [Executor task launch worker for task 102] INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 59.0 (TID 102)
2021-12-04 22:43:35,475 [Executor task launch worker for task 101] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 4 non-empty blocks out of 4 blocks
2021-12-04 22:43:35,475 [Executor task launch worker for task 104] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 4 non-empty blocks out of 4 blocks
2021-12-04 22:43:35,475 [Executor task launch worker for task 101] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-04 22:43:35,475 [Executor task launch worker for task 103] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 4 non-empty blocks out of 4 blocks
2021-12-04 22:43:35,475 [Executor task launch worker for task 103] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-04 22:43:35,475 [Executor task launch worker for task 104] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-04 22:43:35,475 [Executor task launch worker for task 102] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 4 non-empty blocks out of 4 blocks
2021-12-04 22:43:35,475 [Executor task launch worker for task 102] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-04 22:43:35,600 [Executor task launch worker for task 101] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 59.0 (TID 101). 1055 bytes result sent to driver
2021-12-04 22:43:35,600 [Executor task launch worker for task 103] INFO [org.apache.spark.executor.Executor] - Finished task 2.0 in stage 59.0 (TID 103). 1055 bytes result sent to driver
2021-12-04 22:43:35,600 [Executor task launch worker for task 102] INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 59.0 (TID 102). 1055 bytes result sent to driver
2021-12-04 22:43:35,600 [Executor task launch worker for task 104] INFO [org.apache.spark.executor.Executor] - Finished task 3.0 in stage 59.0 (TID 104). 1055 bytes result sent to driver
2021-12-04 22:43:35,601 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 59.0 (TID 101) in 128 ms on localhost (executor driver) (1/4)
2021-12-04 22:43:35,601 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 2.0 in stage 59.0 (TID 103) in 128 ms on localhost (executor driver) (2/4)
2021-12-04 22:43:35,601 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 59.0 (TID 102) in 128 ms on localhost (executor driver) (3/4)
2021-12-04 22:43:35,601 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 3.0 in stage 59.0 (TID 104) in 128 ms on localhost (executor driver) (4/4)
2021-12-04 22:43:35,601 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 59.0, whose tasks have all completed, from pool 
2021-12-04 22:43:35,601 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 59 (count at PaidPromotionAdjustParameter.scala:203) finished in 0.132 s
2021-12-04 22:43:35,601 [main] INFO [org.apache.spark.scheduler.DAGScheduler] - Job 24 finished: count at PaidPromotionAdjustParameter.scala:203, took 1.455017 s
2021-12-04 22:43:35,601 [main] INFO [PaidPromotion$] - 训练集用户列表数量：95323
2021-12-04 22:43:35,607 [main] INFO [org.apache.spark.SparkContext] - Starting job: take at PaidPromotionAdjustParameter.scala:204
2021-12-04 22:43:35,608 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 25 (take at PaidPromotionAdjustParameter.scala:204) with 1 output partitions
2021-12-04 22:43:35,608 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 61 (take at PaidPromotionAdjustParameter.scala:204)
2021-12-04 22:43:35,608 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 60)
2021-12-04 22:43:35,608 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2021-12-04 22:43:35,608 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 61 (MapPartitionsRDD[73] at map at PaidPromotionAdjustParameter.scala:197), which has no missing parents
2021-12-04 22:43:35,609 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_44 stored as values in memory (estimated size 186.2 KB, free 1989.8 MB)
2021-12-04 22:43:35,611 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_44_piece0 stored as bytes in memory (estimated size 66.2 KB, free 1989.7 MB)
2021-12-04 22:43:35,611 [dispatcher-event-loop-2] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_44_piece0 in memory on qb:60793 (size: 66.2 KB, free: 1990.6 MB)
2021-12-04 22:43:35,611 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 44 from broadcast at DAGScheduler.scala:1039
2021-12-04 22:43:35,611 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 61 (MapPartitionsRDD[73] at map at PaidPromotionAdjustParameter.scala:197) (first 15 tasks are for partitions Vector(0))
2021-12-04 22:43:35,611 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 61.0 with 1 tasks
2021-12-04 22:43:35,612 [dispatcher-event-loop-10] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 61.0 (TID 105, localhost, executor driver, partition 0, ANY, 7649 bytes)
2021-12-04 22:43:35,612 [Executor task launch worker for task 105] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 61.0 (TID 105)
2021-12-04 22:43:35,613 [Executor task launch worker for task 105] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 4 non-empty blocks out of 4 blocks
2021-12-04 22:43:35,613 [Executor task launch worker for task 105] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-04 22:43:35,645 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1032
2021-12-04 22:43:35,645 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1057
2021-12-04 22:43:35,645 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1047
2021-12-04 22:43:35,645 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1046
2021-12-04 22:43:35,645 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1028
2021-12-04 22:43:35,645 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1069
2021-12-04 22:43:35,645 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1051
2021-12-04 22:43:35,645 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1045
2021-12-04 22:43:35,646 [dispatcher-event-loop-0] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_42_piece0 on qb:60793 in memory (size: 65.7 KB, free: 1990.6 MB)
2021-12-04 22:43:35,646 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1072
2021-12-04 22:43:35,646 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1053
2021-12-04 22:43:35,646 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1059
2021-12-04 22:43:35,646 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1026
2021-12-04 22:43:35,646 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1027
2021-12-04 22:43:35,646 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1058
2021-12-04 22:43:35,646 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1065
2021-12-04 22:43:35,646 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1062
2021-12-04 22:43:35,646 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1067
2021-12-04 22:43:35,646 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1035
2021-12-04 22:43:35,646 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1056
2021-12-04 22:43:35,646 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1074
2021-12-04 22:43:35,646 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1030
2021-12-04 22:43:35,646 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1068
2021-12-04 22:43:35,646 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1036
2021-12-04 22:43:35,646 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1033
2021-12-04 22:43:35,646 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1048
2021-12-04 22:43:35,646 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1066
2021-12-04 22:43:35,646 [dispatcher-event-loop-3] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_43_piece0 on qb:60793 in memory (size: 66.1 KB, free: 1990.7 MB)
2021-12-04 22:43:35,647 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1073
2021-12-04 22:43:35,647 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1025
2021-12-04 22:43:35,647 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1039
2021-12-04 22:43:35,647 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1029
2021-12-04 22:43:35,647 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1040
2021-12-04 22:43:35,647 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1054
2021-12-04 22:43:35,647 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1052
2021-12-04 22:43:35,647 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1050
2021-12-04 22:43:35,647 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1043
2021-12-04 22:43:35,647 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1037
2021-12-04 22:43:35,647 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1064
2021-12-04 22:43:35,647 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1060
2021-12-04 22:43:35,647 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1061
2021-12-04 22:43:35,647 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1038
2021-12-04 22:43:35,647 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1041
2021-12-04 22:43:35,647 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1063
2021-12-04 22:43:35,647 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1031
2021-12-04 22:43:35,647 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1071
2021-12-04 22:43:35,647 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1044
2021-12-04 22:43:35,647 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1055
2021-12-04 22:43:35,647 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1049
2021-12-04 22:43:35,647 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1034
2021-12-04 22:43:35,647 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1070
2021-12-04 22:43:35,647 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1042
2021-12-04 22:43:35,652 [Executor task launch worker for task 105] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 61.0 (TID 105). 2429 bytes result sent to driver
2021-12-04 22:43:35,652 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 61.0 (TID 105) in 40 ms on localhost (executor driver) (1/1)
2021-12-04 22:43:35,652 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 61.0, whose tasks have all completed, from pool 
2021-12-04 22:43:35,652 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 61 (take at PaidPromotionAdjustParameter.scala:204) finished in 0.044 s
2021-12-04 22:43:35,652 [main] INFO [org.apache.spark.scheduler.DAGScheduler] - Job 25 finished: take at PaidPromotionAdjustParameter.scala:204, took 0.045710 s
2021-12-04 22:43:35,656 [main] INFO [org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter] - File Output Committer Algorithm version is 1
2021-12-04 22:43:35,683 [main] INFO [org.apache.spark.SparkContext] - Starting job: runJob at SparkHadoopWriter.scala:78
2021-12-04 22:43:35,684 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 26 (runJob at SparkHadoopWriter.scala:78) with 1 output partitions
2021-12-04 22:43:35,684 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 63 (runJob at SparkHadoopWriter.scala:78)
2021-12-04 22:43:35,684 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 62)
2021-12-04 22:43:35,684 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2021-12-04 22:43:35,684 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 63 (MapPartitionsRDD[75] at saveAsTextFile at PaidPromotionAdjustParameter.scala:206), which has no missing parents
2021-12-04 22:43:35,692 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_45 stored as values in memory (estimated size 262.0 KB, free 1990.0 MB)
2021-12-04 22:43:35,693 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_45_piece0 stored as bytes in memory (estimated size 94.6 KB, free 1989.9 MB)
2021-12-04 22:43:35,694 [dispatcher-event-loop-11] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_45_piece0 in memory on qb:60793 (size: 94.6 KB, free: 1990.6 MB)
2021-12-04 22:43:35,694 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 45 from broadcast at DAGScheduler.scala:1039
2021-12-04 22:43:35,694 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 63 (MapPartitionsRDD[75] at saveAsTextFile at PaidPromotionAdjustParameter.scala:206) (first 15 tasks are for partitions Vector(0))
2021-12-04 22:43:35,694 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 63.0 with 1 tasks
2021-12-04 22:43:35,695 [dispatcher-event-loop-5] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 63.0 (TID 106, localhost, executor driver, partition 0, ANY, 7943 bytes)
2021-12-04 22:43:35,695 [Executor task launch worker for task 106] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 63.0 (TID 106)
2021-12-04 22:43:35,700 [Executor task launch worker for task 106] INFO [org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter] - File Output Committer Algorithm version is 1
2021-12-04 22:43:35,709 [Executor task launch worker for task 106] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 2 non-empty blocks out of 2 blocks
2021-12-04 22:43:35,709 [Executor task launch worker for task 106] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-04 22:43:35,724 [Executor task launch worker for task 106] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 2 non-empty blocks out of 2 blocks
2021-12-04 22:43:35,724 [Executor task launch worker for task 106] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-04 22:43:35,817 [Executor task launch worker for task 106] INFO [org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter] - Saved output of task 'attempt_20211204224335_0075_m_000000_0' to hdfs://hdp1:8020/sk/chongqing/list/validation/_temporary/0/task_20211204224335_0075_m_000000
2021-12-04 22:43:35,817 [Executor task launch worker for task 106] INFO [org.apache.spark.mapred.SparkHadoopMapRedUtil] - attempt_20211204224335_0075_m_000000_0: Committed
2021-12-04 22:43:35,818 [Executor task launch worker for task 106] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 63.0 (TID 106). 1299 bytes result sent to driver
2021-12-04 22:43:35,818 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 63.0 (TID 106) in 124 ms on localhost (executor driver) (1/1)
2021-12-04 22:43:35,818 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 63.0, whose tasks have all completed, from pool 
2021-12-04 22:43:35,819 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 63 (runJob at SparkHadoopWriter.scala:78) finished in 0.135 s
2021-12-04 22:43:35,819 [main] INFO [org.apache.spark.scheduler.DAGScheduler] - Job 26 finished: runJob at SparkHadoopWriter.scala:78, took 0.135351 s
2021-12-04 22:43:35,868 [main] INFO [org.apache.spark.internal.io.SparkHadoopWriter] - Job job_20211204224335_0075 committed.
2021-12-04 22:43:35,872 [main] INFO [org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter] - File Output Committer Algorithm version is 1
2021-12-04 22:43:35,891 [main] INFO [org.apache.spark.SparkContext] - Starting job: runJob at SparkHadoopWriter.scala:78
2021-12-04 22:43:35,892 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 27 (runJob at SparkHadoopWriter.scala:78) with 1 output partitions
2021-12-04 22:43:35,892 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 65 (runJob at SparkHadoopWriter.scala:78)
2021-12-04 22:43:35,892 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 64)
2021-12-04 22:43:35,892 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2021-12-04 22:43:35,892 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 65 (MapPartitionsRDD[77] at saveAsTextFile at PaidPromotionAdjustParameter.scala:207), which has no missing parents
2021-12-04 22:43:35,899 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_46 stored as values in memory (estimated size 262.5 KB, free 1989.6 MB)
2021-12-04 22:43:35,901 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_46_piece0 stored as bytes in memory (estimated size 95.0 KB, free 1989.5 MB)
2021-12-04 22:43:35,901 [dispatcher-event-loop-1] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_46_piece0 in memory on qb:60793 (size: 95.0 KB, free: 1990.5 MB)
2021-12-04 22:43:35,902 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 46 from broadcast at DAGScheduler.scala:1039
2021-12-04 22:43:35,902 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 65 (MapPartitionsRDD[77] at saveAsTextFile at PaidPromotionAdjustParameter.scala:207) (first 15 tasks are for partitions Vector(0))
2021-12-04 22:43:35,902 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 65.0 with 1 tasks
2021-12-04 22:43:35,902 [dispatcher-event-loop-7] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 65.0 (TID 107, localhost, executor driver, partition 0, ANY, 7979 bytes)
2021-12-04 22:43:35,902 [Executor task launch worker for task 107] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 65.0 (TID 107)
2021-12-04 22:43:35,908 [Executor task launch worker for task 107] INFO [org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter] - File Output Committer Algorithm version is 1
2021-12-04 22:43:35,917 [Executor task launch worker for task 107] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 4 non-empty blocks out of 4 blocks
2021-12-04 22:43:35,917 [Executor task launch worker for task 107] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-04 22:43:35,973 [Executor task launch worker for task 107] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 4 non-empty blocks out of 4 blocks
2021-12-04 22:43:35,974 [Executor task launch worker for task 107] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 1 ms
2021-12-04 22:43:36,027 [Executor task launch worker for task 107] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 4 non-empty blocks out of 4 blocks
2021-12-04 22:43:36,028 [Executor task launch worker for task 107] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 1 ms
2021-12-04 22:43:36,082 [Executor task launch worker for task 107] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 4 non-empty blocks out of 4 blocks
2021-12-04 22:43:36,082 [Executor task launch worker for task 107] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 1 ms
2021-12-04 22:43:36,609 [Executor task launch worker for task 107] INFO [org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter] - Saved output of task 'attempt_20211204224335_0077_m_000000_0' to hdfs://hdp1:8020/sk/chongqing/list/train/_temporary/0/task_20211204224335_0077_m_000000
2021-12-04 22:43:36,609 [Executor task launch worker for task 107] INFO [org.apache.spark.mapred.SparkHadoopMapRedUtil] - attempt_20211204224335_0077_m_000000_0: Committed
2021-12-04 22:43:36,610 [Executor task launch worker for task 107] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 65.0 (TID 107). 1299 bytes result sent to driver
2021-12-04 22:43:36,610 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 65.0 (TID 107) in 708 ms on localhost (executor driver) (1/1)
2021-12-04 22:43:36,611 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 65.0, whose tasks have all completed, from pool 
2021-12-04 22:43:36,611 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 65 (runJob at SparkHadoopWriter.scala:78) finished in 0.719 s
2021-12-04 22:43:36,611 [main] INFO [org.apache.spark.scheduler.DAGScheduler] - Job 27 finished: runJob at SparkHadoopWriter.scala:78, took 0.718852 s
2021-12-04 22:43:36,661 [main] INFO [org.apache.spark.internal.io.SparkHadoopWriter] - Job job_20211204224335_0077 committed.
2021-12-04 22:43:36,668 [main] INFO [org.spark_project.jetty.server.AbstractConnector] - Stopped Spark@5b800468{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2021-12-04 22:43:36,670 [main] INFO [org.apache.spark.ui.SparkUI] - Stopped Spark web UI at http://qb:4040
2021-12-04 22:43:36,678 [dispatcher-event-loop-11] INFO [org.apache.spark.MapOutputTrackerMasterEndpoint] - MapOutputTrackerMasterEndpoint stopped!
2021-12-04 22:43:36,755 [main] INFO [org.apache.spark.storage.memory.MemoryStore] - MemoryStore cleared
2021-12-04 22:43:36,755 [main] INFO [org.apache.spark.storage.BlockManager] - BlockManager stopped
2021-12-04 22:43:36,755 [main] INFO [org.apache.spark.storage.BlockManagerMaster] - BlockManagerMaster stopped
2021-12-04 22:43:36,757 [dispatcher-event-loop-1] INFO [org.apache.spark.scheduler.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint] - OutputCommitCoordinator stopped!
2021-12-04 22:43:36,760 [main] INFO [org.apache.spark.SparkContext] - Successfully stopped SparkContext
2021-12-04 22:43:36,761 [Thread-1] INFO [org.apache.spark.util.ShutdownHookManager] - Shutdown hook called
2021-12-04 22:43:36,762 [Thread-1] INFO [org.apache.spark.util.ShutdownHookManager] - Deleting directory C:\Users\ACER\AppData\Local\Temp\spark-774d4fd8-52a2-4397-a47a-8d1a8a5c20c9
