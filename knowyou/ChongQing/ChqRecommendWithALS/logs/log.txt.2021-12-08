2021-12-08 09:59:02,358 [main] INFO [org.apache.spark.SparkContext] - Running Spark version 2.3.0
2021-12-08 09:59:02,707 [main] INFO [org.apache.spark.SparkContext] - Submitted application: PaidPromotionAdjustParameter
2021-12-08 09:59:02,769 [main] INFO [org.apache.spark.SecurityManager] - Changing view acls to: ACER,root
2021-12-08 09:59:02,770 [main] INFO [org.apache.spark.SecurityManager] - Changing modify acls to: ACER,root
2021-12-08 09:59:02,770 [main] INFO [org.apache.spark.SecurityManager] - Changing view acls groups to: 
2021-12-08 09:59:02,771 [main] INFO [org.apache.spark.SecurityManager] - Changing modify acls groups to: 
2021-12-08 09:59:02,771 [main] INFO [org.apache.spark.SecurityManager] - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(ACER, root); groups with view permissions: Set(); users  with modify permissions: Set(ACER, root); groups with modify permissions: Set()
2021-12-08 09:59:03,369 [main] INFO [org.apache.spark.util.Utils] - Successfully started service 'sparkDriver' on port 63752.
2021-12-08 09:59:03,393 [main] INFO [org.apache.spark.SparkEnv] - Registering MapOutputTracker
2021-12-08 09:59:03,413 [main] INFO [org.apache.spark.SparkEnv] - Registering BlockManagerMaster
2021-12-08 09:59:03,416 [main] INFO [org.apache.spark.storage.BlockManagerMasterEndpoint] - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2021-12-08 09:59:03,416 [main] INFO [org.apache.spark.storage.BlockManagerMasterEndpoint] - BlockManagerMasterEndpoint up
2021-12-08 09:59:03,426 [main] INFO [org.apache.spark.storage.DiskBlockManager] - Created local directory at C:\Users\ACER\AppData\Local\Temp\blockmgr-327e2d26-f898-4efc-b12c-d248b151fe04
2021-12-08 09:59:03,445 [main] INFO [org.apache.spark.storage.memory.MemoryStore] - MemoryStore started with capacity 1990.8 MB
2021-12-08 09:59:03,458 [main] INFO [org.apache.spark.SparkEnv] - Registering OutputCommitCoordinator
2021-12-08 09:59:03,528 [main] INFO [org.spark_project.jetty.util.log] - Logging initialized @2121ms
2021-12-08 09:59:03,591 [main] INFO [org.spark_project.jetty.server.Server] - jetty-9.3.z-SNAPSHOT
2021-12-08 09:59:03,606 [main] INFO [org.spark_project.jetty.server.Server] - Started @2199ms
2021-12-08 09:59:03,634 [main] INFO [org.spark_project.jetty.server.AbstractConnector] - Started ServerConnector@5b800468{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2021-12-08 09:59:03,635 [main] INFO [org.apache.spark.util.Utils] - Successfully started service 'SparkUI' on port 4040.
2021-12-08 09:59:03,656 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@1568159{/jobs,null,AVAILABLE,@Spark}
2021-12-08 09:59:03,657 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@63cd604c{/jobs/json,null,AVAILABLE,@Spark}
2021-12-08 09:59:03,658 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@3954d008{/jobs/job,null,AVAILABLE,@Spark}
2021-12-08 09:59:03,659 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@6d8792db{/jobs/job/json,null,AVAILABLE,@Spark}
2021-12-08 09:59:03,660 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@3a1d593e{/stages,null,AVAILABLE,@Spark}
2021-12-08 09:59:03,661 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@285d851a{/stages/json,null,AVAILABLE,@Spark}
2021-12-08 09:59:03,662 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@7876d598{/stages/stage,null,AVAILABLE,@Spark}
2021-12-08 09:59:03,664 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@4985cbcb{/stages/stage/json,null,AVAILABLE,@Spark}
2021-12-08 09:59:03,666 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@54361a9{/stages/pool,null,AVAILABLE,@Spark}
2021-12-08 09:59:03,667 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@293bb8a5{/stages/pool/json,null,AVAILABLE,@Spark}
2021-12-08 09:59:03,668 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@290b1b2e{/storage,null,AVAILABLE,@Spark}
2021-12-08 09:59:03,669 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@5db4c359{/storage/json,null,AVAILABLE,@Spark}
2021-12-08 09:59:03,670 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@6fefce9e{/storage/rdd,null,AVAILABLE,@Spark}
2021-12-08 09:59:03,672 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@8a589a2{/storage/rdd/json,null,AVAILABLE,@Spark}
2021-12-08 09:59:03,673 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@5cc69cfe{/environment,null,AVAILABLE,@Spark}
2021-12-08 09:59:03,674 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@11dee337{/environment/json,null,AVAILABLE,@Spark}
2021-12-08 09:59:03,675 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@74bdc168{/executors,null,AVAILABLE,@Spark}
2021-12-08 09:59:03,676 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@7bb3a9fe{/executors/json,null,AVAILABLE,@Spark}
2021-12-08 09:59:03,677 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@f19c9d2{/executors/threadDump,null,AVAILABLE,@Spark}
2021-12-08 09:59:03,678 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@a77614d{/executors/threadDump/json,null,AVAILABLE,@Spark}
2021-12-08 09:59:03,684 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@523424b5{/static,null,AVAILABLE,@Spark}
2021-12-08 09:59:03,685 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@12cd9150{/,null,AVAILABLE,@Spark}
2021-12-08 09:59:03,688 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@32fe9d0a{/api,null,AVAILABLE,@Spark}
2021-12-08 09:59:03,689 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@59fc684e{/jobs/job/kill,null,AVAILABLE,@Spark}
2021-12-08 09:59:03,690 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@355e34c7{/stages/stage/kill,null,AVAILABLE,@Spark}
2021-12-08 09:59:03,692 [main] INFO [org.apache.spark.ui.SparkUI] - Bound SparkUI to 0.0.0.0, and started at http://qb:4040
2021-12-08 09:59:03,779 [main] INFO [org.apache.spark.executor.Executor] - Starting executor ID driver on host localhost
2021-12-08 09:59:03,837 [main] INFO [org.apache.spark.util.Utils] - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 63796.
2021-12-08 09:59:03,838 [main] INFO [org.apache.spark.network.netty.NettyBlockTransferService] - Server created on qb:63796
2021-12-08 09:59:03,840 [main] INFO [org.apache.spark.storage.BlockManager] - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2021-12-08 09:59:03,842 [main] INFO [org.apache.spark.storage.BlockManagerMaster] - Registering BlockManager BlockManagerId(driver, qb, 63796, None)
2021-12-08 09:59:03,845 [dispatcher-event-loop-8] INFO [org.apache.spark.storage.BlockManagerMasterEndpoint] - Registering block manager qb:63796 with 1990.8 MB RAM, BlockManagerId(driver, qb, 63796, None)
2021-12-08 09:59:03,848 [main] INFO [org.apache.spark.storage.BlockManagerMaster] - Registered BlockManager BlockManagerId(driver, qb, 63796, None)
2021-12-08 09:59:03,848 [main] INFO [org.apache.spark.storage.BlockManager] - Initialized BlockManager: BlockManagerId(driver, qb, 63796, None)
2021-12-08 09:59:04,001 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@6fe46b62{/metrics/json,null,AVAILABLE,@Spark}
2021-12-08 09:59:04,592 [main] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_0 stored as values in memory (estimated size 284.2 KB, free 1990.5 MB)
2021-12-08 09:59:04,861 [main] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_0_piece0 stored as bytes in memory (estimated size 24.5 KB, free 1990.5 MB)
2021-12-08 09:59:04,863 [dispatcher-event-loop-0] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_0_piece0 in memory on qb:63796 (size: 24.5 KB, free: 1990.8 MB)
2021-12-08 09:59:04,866 [main] INFO [org.apache.spark.SparkContext] - Created broadcast 0 from textFile at PaidPromotionAdjustParameter.scala:239
2021-12-08 09:59:04,913 [main] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_1 stored as values in memory (estimated size 284.2 KB, free 1990.2 MB)
2021-12-08 09:59:04,925 [main] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_1_piece0 stored as bytes in memory (estimated size 24.5 KB, free 1990.2 MB)
2021-12-08 09:59:04,925 [dispatcher-event-loop-1] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_1_piece0 in memory on qb:63796 (size: 24.5 KB, free: 1990.8 MB)
2021-12-08 09:59:04,926 [main] INFO [org.apache.spark.SparkContext] - Created broadcast 1 from textFile at PaidPromotionAdjustParameter.scala:240
2021-12-08 09:59:07,289 [Thread-1] INFO [org.apache.spark.SparkContext] - Invoking stop() from shutdown hook
2021-12-08 09:59:07,294 [Thread-1] INFO [org.spark_project.jetty.server.AbstractConnector] - Stopped Spark@5b800468{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2021-12-08 09:59:07,296 [Thread-1] INFO [org.apache.spark.ui.SparkUI] - Stopped Spark web UI at http://qb:4040
2021-12-08 09:59:07,303 [dispatcher-event-loop-5] INFO [org.apache.spark.MapOutputTrackerMasterEndpoint] - MapOutputTrackerMasterEndpoint stopped!
2021-12-08 09:59:07,311 [Thread-1] INFO [org.apache.spark.storage.memory.MemoryStore] - MemoryStore cleared
2021-12-08 09:59:07,311 [Thread-1] INFO [org.apache.spark.storage.BlockManager] - BlockManager stopped
2021-12-08 09:59:07,316 [Thread-1] INFO [org.apache.spark.storage.BlockManagerMaster] - BlockManagerMaster stopped
2021-12-08 09:59:07,319 [dispatcher-event-loop-9] INFO [org.apache.spark.scheduler.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint] - OutputCommitCoordinator stopped!
2021-12-08 09:59:07,321 [Thread-1] INFO [org.apache.spark.SparkContext] - Successfully stopped SparkContext
2021-12-08 09:59:07,321 [Thread-1] INFO [org.apache.spark.util.ShutdownHookManager] - Shutdown hook called
2021-12-08 09:59:07,322 [Thread-1] INFO [org.apache.spark.util.ShutdownHookManager] - Deleting directory C:\Users\ACER\AppData\Local\Temp\spark-565d9222-6ae5-4870-bab0-74e9bc61cb6c
2021-12-08 10:00:01,796 [main] INFO [org.apache.spark.SparkContext] - Running Spark version 2.3.0
2021-12-08 10:00:02,088 [main] INFO [org.apache.spark.SparkContext] - Submitted application: PaidPromotionAdjustParameter
2021-12-08 10:00:02,133 [main] INFO [org.apache.spark.SecurityManager] - Changing view acls to: ACER,root
2021-12-08 10:00:02,134 [main] INFO [org.apache.spark.SecurityManager] - Changing modify acls to: ACER,root
2021-12-08 10:00:02,134 [main] INFO [org.apache.spark.SecurityManager] - Changing view acls groups to: 
2021-12-08 10:00:02,134 [main] INFO [org.apache.spark.SecurityManager] - Changing modify acls groups to: 
2021-12-08 10:00:02,135 [main] INFO [org.apache.spark.SecurityManager] - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(ACER, root); groups with view permissions: Set(); users  with modify permissions: Set(ACER, root); groups with modify permissions: Set()
2021-12-08 10:00:02,684 [main] INFO [org.apache.spark.util.Utils] - Successfully started service 'sparkDriver' on port 63911.
2021-12-08 10:00:02,700 [main] INFO [org.apache.spark.SparkEnv] - Registering MapOutputTracker
2021-12-08 10:00:02,715 [main] INFO [org.apache.spark.SparkEnv] - Registering BlockManagerMaster
2021-12-08 10:00:02,717 [main] INFO [org.apache.spark.storage.BlockManagerMasterEndpoint] - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2021-12-08 10:00:02,717 [main] INFO [org.apache.spark.storage.BlockManagerMasterEndpoint] - BlockManagerMasterEndpoint up
2021-12-08 10:00:02,724 [main] INFO [org.apache.spark.storage.DiskBlockManager] - Created local directory at C:\Users\ACER\AppData\Local\Temp\blockmgr-0f974636-5b61-4107-9ab3-661a7bfda617
2021-12-08 10:00:02,738 [main] INFO [org.apache.spark.storage.memory.MemoryStore] - MemoryStore started with capacity 1990.8 MB
2021-12-08 10:00:02,747 [main] INFO [org.apache.spark.SparkEnv] - Registering OutputCommitCoordinator
2021-12-08 10:00:02,797 [main] INFO [org.spark_project.jetty.util.log] - Logging initialized @1883ms
2021-12-08 10:00:02,842 [main] INFO [org.spark_project.jetty.server.Server] - jetty-9.3.z-SNAPSHOT
2021-12-08 10:00:02,852 [main] INFO [org.spark_project.jetty.server.Server] - Started @1938ms
2021-12-08 10:00:02,876 [main] INFO [org.spark_project.jetty.server.AbstractConnector] - Started ServerConnector@5f7f2382{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2021-12-08 10:00:02,876 [main] INFO [org.apache.spark.util.Utils] - Successfully started service 'SparkUI' on port 4040.
2021-12-08 10:00:02,893 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@3af17be2{/jobs,null,AVAILABLE,@Spark}
2021-12-08 10:00:02,894 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@6a1d204a{/jobs/json,null,AVAILABLE,@Spark}
2021-12-08 10:00:02,895 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@72ccd81a{/jobs/job,null,AVAILABLE,@Spark}
2021-12-08 10:00:02,896 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@5d25e6bb{/jobs/job/json,null,AVAILABLE,@Spark}
2021-12-08 10:00:02,897 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@7859e786{/stages,null,AVAILABLE,@Spark}
2021-12-08 10:00:02,898 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@5118388b{/stages/json,null,AVAILABLE,@Spark}
2021-12-08 10:00:02,899 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@71104a4{/stages/stage,null,AVAILABLE,@Spark}
2021-12-08 10:00:02,901 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@332a7fce{/stages/stage/json,null,AVAILABLE,@Spark}
2021-12-08 10:00:02,902 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@37ebc9d8{/stages/pool,null,AVAILABLE,@Spark}
2021-12-08 10:00:02,903 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@6e9319f{/stages/pool/json,null,AVAILABLE,@Spark}
2021-12-08 10:00:02,903 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@2c177f9e{/storage,null,AVAILABLE,@Spark}
2021-12-08 10:00:02,904 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@f9b7332{/storage/json,null,AVAILABLE,@Spark}
2021-12-08 10:00:02,906 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@192f2f27{/storage/rdd,null,AVAILABLE,@Spark}
2021-12-08 10:00:02,906 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@b672aa8{/storage/rdd/json,null,AVAILABLE,@Spark}
2021-12-08 10:00:02,908 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@7997b197{/environment,null,AVAILABLE,@Spark}
2021-12-08 10:00:02,909 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@11acdc30{/environment/json,null,AVAILABLE,@Spark}
2021-12-08 10:00:02,910 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@611f8234{/executors,null,AVAILABLE,@Spark}
2021-12-08 10:00:02,911 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@62923ee6{/executors/json,null,AVAILABLE,@Spark}
2021-12-08 10:00:02,913 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@4b6166aa{/executors/threadDump,null,AVAILABLE,@Spark}
2021-12-08 10:00:02,914 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@a1217f9{/executors/threadDump/json,null,AVAILABLE,@Spark}
2021-12-08 10:00:02,919 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@791cbf87{/static,null,AVAILABLE,@Spark}
2021-12-08 10:00:02,920 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@cf65451{/,null,AVAILABLE,@Spark}
2021-12-08 10:00:02,922 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@46074492{/api,null,AVAILABLE,@Spark}
2021-12-08 10:00:02,923 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@5ae76500{/jobs/job/kill,null,AVAILABLE,@Spark}
2021-12-08 10:00:02,925 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@24f360b2{/stages/stage/kill,null,AVAILABLE,@Spark}
2021-12-08 10:00:02,927 [main] INFO [org.apache.spark.ui.SparkUI] - Bound SparkUI to 0.0.0.0, and started at http://qb:4040
2021-12-08 10:00:03,003 [main] INFO [org.apache.spark.executor.Executor] - Starting executor ID driver on host localhost
2021-12-08 10:00:03,048 [main] INFO [org.apache.spark.util.Utils] - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 64003.
2021-12-08 10:00:03,049 [main] INFO [org.apache.spark.network.netty.NettyBlockTransferService] - Server created on qb:64003
2021-12-08 10:00:03,050 [main] INFO [org.apache.spark.storage.BlockManager] - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2021-12-08 10:00:03,051 [main] INFO [org.apache.spark.storage.BlockManagerMaster] - Registering BlockManager BlockManagerId(driver, qb, 64003, None)
2021-12-08 10:00:03,053 [dispatcher-event-loop-10] INFO [org.apache.spark.storage.BlockManagerMasterEndpoint] - Registering block manager qb:64003 with 1990.8 MB RAM, BlockManagerId(driver, qb, 64003, None)
2021-12-08 10:00:03,054 [main] INFO [org.apache.spark.storage.BlockManagerMaster] - Registered BlockManager BlockManagerId(driver, qb, 64003, None)
2021-12-08 10:00:03,054 [main] INFO [org.apache.spark.storage.BlockManager] - Initialized BlockManager: BlockManagerId(driver, qb, 64003, None)
2021-12-08 10:00:03,175 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@7c9b78e3{/metrics/json,null,AVAILABLE,@Spark}
2021-12-08 10:00:03,620 [main] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_0 stored as values in memory (estimated size 312.7 KB, free 1990.5 MB)
2021-12-08 10:00:03,815 [main] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_0_piece0 stored as bytes in memory (estimated size 27.3 KB, free 1990.5 MB)
2021-12-08 10:00:03,816 [dispatcher-event-loop-0] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_0_piece0 in memory on qb:64003 (size: 27.3 KB, free: 1990.8 MB)
2021-12-08 10:00:03,819 [main] INFO [org.apache.spark.SparkContext] - Created broadcast 0 from textFile at PaidPromotionAdjustParameter.scala:239
2021-12-08 10:00:03,865 [main] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_1 stored as values in memory (estimated size 312.7 KB, free 1990.2 MB)
2021-12-08 10:00:03,880 [main] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_1_piece0 stored as bytes in memory (estimated size 27.3 KB, free 1990.1 MB)
2021-12-08 10:00:03,880 [dispatcher-event-loop-1] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_1_piece0 in memory on qb:64003 (size: 27.3 KB, free: 1990.7 MB)
2021-12-08 10:00:03,881 [main] INFO [org.apache.spark.SparkContext] - Created broadcast 1 from textFile at PaidPromotionAdjustParameter.scala:240
2021-12-08 10:00:04,264 [main] WARN [org.apache.hadoop.hdfs.shortcircuit.DomainSocketFactory] - The short-circuit local reads feature cannot be used because UNIX Domain sockets are not available on Windows.
2021-12-08 10:00:04,406 [main] INFO [org.apache.hadoop.mapred.FileInputFormat] - Total input paths to process : 1
2021-12-08 10:00:04,425 [main] INFO [org.apache.spark.SparkContext] - Starting job: count at PaidPromotionAdjustParameter.scala:248
2021-12-08 10:00:04,446 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 0 (count at PaidPromotionAdjustParameter.scala:248) with 2 output partitions
2021-12-08 10:00:04,447 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 0 (count at PaidPromotionAdjustParameter.scala:248)
2021-12-08 10:00:04,448 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List()
2021-12-08 10:00:04,449 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2021-12-08 10:00:04,458 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 0 (MapPartitionsRDD[4] at map at PaidPromotionAdjustParameter.scala:244), which has no missing parents
2021-12-08 10:00:04,515 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_2 stored as values in memory (estimated size 3.3 KB, free 1990.1 MB)
2021-12-08 10:00:04,525 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_2_piece0 stored as bytes in memory (estimated size 1994.0 B, free 1990.1 MB)
2021-12-08 10:00:04,525 [dispatcher-event-loop-2] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_2_piece0 in memory on qb:64003 (size: 1994.0 B, free: 1990.7 MB)
2021-12-08 10:00:04,526 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 2 from broadcast at DAGScheduler.scala:1039
2021-12-08 10:00:04,545 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from ResultStage 0 (MapPartitionsRDD[4] at map at PaidPromotionAdjustParameter.scala:244) (first 15 tasks are for partitions Vector(0, 1))
2021-12-08 10:00:04,546 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 0.0 with 2 tasks
2021-12-08 10:00:04,596 [dispatcher-event-loop-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 0.0 (TID 0, localhost, executor driver, partition 0, ANY, 7932 bytes)
2021-12-08 10:00:04,599 [dispatcher-event-loop-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 0.0 (TID 1, localhost, executor driver, partition 1, ANY, 7932 bytes)
2021-12-08 10:00:04,607 [Executor task launch worker for task 0] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 0.0 (TID 0)
2021-12-08 10:00:04,607 [Executor task launch worker for task 1] INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 0.0 (TID 1)
2021-12-08 10:00:04,660 [Executor task launch worker for task 1] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/handle_data/set-train-device-production-data/part-00000:3237750+3237751
2021-12-08 10:00:04,660 [Executor task launch worker for task 0] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/handle_data/set-train-device-production-data/part-00000:0+3237750
2021-12-08 10:00:05,347 [Executor task launch worker for task 0] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 0.0 (TID 0). 754 bytes result sent to driver
2021-12-08 10:00:05,356 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 0.0 (TID 0) in 770 ms on localhost (executor driver) (1/2)
2021-12-08 10:00:06,044 [Executor task launch worker for task 1] INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 0.0 (TID 1). 754 bytes result sent to driver
2021-12-08 10:00:06,047 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 0.0 (TID 1) in 1449 ms on localhost (executor driver) (2/2)
2021-12-08 10:00:06,048 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 0.0, whose tasks have all completed, from pool 
2021-12-08 10:00:06,049 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 0 (count at PaidPromotionAdjustParameter.scala:248) finished in 1.566 s
2021-12-08 10:00:06,053 [main] INFO [org.apache.spark.scheduler.DAGScheduler] - Job 0 finished: count at PaidPromotionAdjustParameter.scala:248, took 1.627996 s
2021-12-08 10:00:06,055 [main] INFO [PaidPromotionAdjustParameter$] - 订购行为训练集个数：101055
2021-12-08 10:00:06,073 [main] INFO [org.apache.spark.SparkContext] - Starting job: zipWithIndex at PaidPromotionAdjustParameter.scala:253
2021-12-08 10:00:06,081 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 6 (distinct at PaidPromotionAdjustParameter.scala:252)
2021-12-08 10:00:06,082 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 1 (zipWithIndex at PaidPromotionAdjustParameter.scala:253) with 2 output partitions
2021-12-08 10:00:06,082 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 2 (zipWithIndex at PaidPromotionAdjustParameter.scala:253)
2021-12-08 10:00:06,082 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 1)
2021-12-08 10:00:06,082 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List(ShuffleMapStage 1)
2021-12-08 10:00:06,083 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ShuffleMapStage 1 (MapPartitionsRDD[6] at distinct at PaidPromotionAdjustParameter.scala:252), which has no missing parents
2021-12-08 10:00:06,091 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_3 stored as values in memory (estimated size 4.9 KB, free 1990.1 MB)
2021-12-08 10:00:06,096 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_3_piece0 stored as bytes in memory (estimated size 2.8 KB, free 1990.1 MB)
2021-12-08 10:00:06,097 [dispatcher-event-loop-8] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_3_piece0 in memory on qb:64003 (size: 2.8 KB, free: 1990.7 MB)
2021-12-08 10:00:06,097 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 3 from broadcast at DAGScheduler.scala:1039
2021-12-08 10:00:06,099 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from ShuffleMapStage 1 (MapPartitionsRDD[6] at distinct at PaidPromotionAdjustParameter.scala:252) (first 15 tasks are for partitions Vector(0, 1))
2021-12-08 10:00:06,099 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 1.0 with 2 tasks
2021-12-08 10:00:06,100 [dispatcher-event-loop-9] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 1.0 (TID 2, localhost, executor driver, partition 0, ANY, 7921 bytes)
2021-12-08 10:00:06,101 [dispatcher-event-loop-9] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 1.0 (TID 3, localhost, executor driver, partition 1, ANY, 7921 bytes)
2021-12-08 10:00:06,101 [Executor task launch worker for task 2] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 1.0 (TID 2)
2021-12-08 10:00:06,101 [Executor task launch worker for task 3] INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 1.0 (TID 3)
2021-12-08 10:00:06,106 [Executor task launch worker for task 3] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/handle_data/set-train-device-production-data/part-00000:3237750+3237751
2021-12-08 10:00:06,106 [Executor task launch worker for task 2] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/handle_data/set-train-device-production-data/part-00000:0+3237750
2021-12-08 10:00:06,475 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 13
2021-12-08 10:00:06,476 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 11
2021-12-08 10:00:06,476 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1
2021-12-08 10:00:06,476 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 8
2021-12-08 10:00:06,476 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 9
2021-12-08 10:00:06,476 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 12
2021-12-08 10:00:06,476 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 6
2021-12-08 10:00:06,476 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 17
2021-12-08 10:00:06,476 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 4
2021-12-08 10:00:06,476 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 23
2021-12-08 10:00:06,476 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 10
2021-12-08 10:00:06,476 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 18
2021-12-08 10:00:06,476 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 3
2021-12-08 10:00:06,489 [dispatcher-event-loop-2] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_2_piece0 on qb:64003 in memory (size: 1994.0 B, free: 1990.7 MB)
2021-12-08 10:00:06,491 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 5
2021-12-08 10:00:06,491 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 2
2021-12-08 10:00:06,491 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 0
2021-12-08 10:00:06,491 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 20
2021-12-08 10:00:06,491 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 22
2021-12-08 10:00:06,491 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 16
2021-12-08 10:00:06,491 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 7
2021-12-08 10:00:06,491 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 21
2021-12-08 10:00:06,491 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 19
2021-12-08 10:00:06,491 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 14
2021-12-08 10:00:06,491 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 15
2021-12-08 10:00:06,491 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 24
2021-12-08 10:00:06,669 [Executor task launch worker for task 2] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 1.0 (TID 2). 1033 bytes result sent to driver
2021-12-08 10:00:06,687 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 1.0 (TID 2) in 587 ms on localhost (executor driver) (1/2)
2021-12-08 10:00:06,856 [Executor task launch worker for task 3] INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 1.0 (TID 3). 1033 bytes result sent to driver
2021-12-08 10:00:06,858 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 1.0 (TID 3) in 758 ms on localhost (executor driver) (2/2)
2021-12-08 10:00:06,859 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 1.0, whose tasks have all completed, from pool 
2021-12-08 10:00:06,859 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ShuffleMapStage 1 (distinct at PaidPromotionAdjustParameter.scala:252) finished in 0.774 s
2021-12-08 10:00:06,860 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - looking for newly runnable stages
2021-12-08 10:00:06,860 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - running: Set()
2021-12-08 10:00:06,860 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - waiting: Set(ResultStage 2)
2021-12-08 10:00:06,860 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - failed: Set()
2021-12-08 10:00:06,863 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 2 (MapPartitionsRDD[8] at distinct at PaidPromotionAdjustParameter.scala:252), which has no missing parents
2021-12-08 10:00:06,867 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_4 stored as values in memory (estimated size 3.7 KB, free 1990.1 MB)
2021-12-08 10:00:06,870 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_4_piece0 stored as bytes in memory (estimated size 2.2 KB, free 1990.1 MB)
2021-12-08 10:00:06,871 [dispatcher-event-loop-4] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_4_piece0 in memory on qb:64003 (size: 2.2 KB, free: 1990.7 MB)
2021-12-08 10:00:06,871 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 4 from broadcast at DAGScheduler.scala:1039
2021-12-08 10:00:06,872 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from ResultStage 2 (MapPartitionsRDD[8] at distinct at PaidPromotionAdjustParameter.scala:252) (first 15 tasks are for partitions Vector(0, 1))
2021-12-08 10:00:06,872 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 2.0 with 2 tasks
2021-12-08 10:00:06,873 [dispatcher-event-loop-6] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 2.0 (TID 4, localhost, executor driver, partition 0, ANY, 7649 bytes)
2021-12-08 10:00:06,873 [dispatcher-event-loop-6] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 2.0 (TID 5, localhost, executor driver, partition 1, ANY, 7649 bytes)
2021-12-08 10:00:06,873 [Executor task launch worker for task 4] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 2.0 (TID 4)
2021-12-08 10:00:06,873 [Executor task launch worker for task 5] INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 2.0 (TID 5)
2021-12-08 10:00:06,886 [Executor task launch worker for task 4] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 2 non-empty blocks out of 2 blocks
2021-12-08 10:00:06,886 [Executor task launch worker for task 5] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 2 non-empty blocks out of 2 blocks
2021-12-08 10:00:06,888 [Executor task launch worker for task 4] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 6 ms
2021-12-08 10:00:06,888 [Executor task launch worker for task 5] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 6 ms
2021-12-08 10:00:06,924 [Executor task launch worker for task 5] INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 2.0 (TID 5). 1053 bytes result sent to driver
2021-12-08 10:00:06,924 [Executor task launch worker for task 4] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 2.0 (TID 4). 1053 bytes result sent to driver
2021-12-08 10:00:06,925 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 2.0 (TID 5) in 52 ms on localhost (executor driver) (1/2)
2021-12-08 10:00:06,925 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 2.0 (TID 4) in 53 ms on localhost (executor driver) (2/2)
2021-12-08 10:00:06,925 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 2.0, whose tasks have all completed, from pool 
2021-12-08 10:00:06,926 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 2 (zipWithIndex at PaidPromotionAdjustParameter.scala:253) finished in 0.062 s
2021-12-08 10:00:06,926 [main] INFO [org.apache.spark.scheduler.DAGScheduler] - Job 1 finished: zipWithIndex at PaidPromotionAdjustParameter.scala:253, took 0.852900 s
2021-12-08 10:00:06,953 [main] INFO [org.apache.spark.SparkContext] - Starting job: take at PaidPromotionAdjustParameter.scala:259
2021-12-08 10:00:06,953 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 10 (map at PaidPromotionAdjustParameter.scala:256)
2021-12-08 10:00:06,953 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 2 (take at PaidPromotionAdjustParameter.scala:259) with 1 output partitions
2021-12-08 10:00:06,953 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 5 (take at PaidPromotionAdjustParameter.scala:259)
2021-12-08 10:00:06,954 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 4)
2021-12-08 10:00:06,954 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List(ShuffleMapStage 4)
2021-12-08 10:00:06,954 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ShuffleMapStage 4 (MapPartitionsRDD[10] at map at PaidPromotionAdjustParameter.scala:256), which has no missing parents
2021-12-08 10:00:06,956 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_5 stored as values in memory (estimated size 4.0 KB, free 1990.1 MB)
2021-12-08 10:00:06,959 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_5_piece0 stored as bytes in memory (estimated size 2.3 KB, free 1990.1 MB)
2021-12-08 10:00:06,960 [dispatcher-event-loop-11] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_5_piece0 in memory on qb:64003 (size: 2.3 KB, free: 1990.7 MB)
2021-12-08 10:00:06,960 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 5 from broadcast at DAGScheduler.scala:1039
2021-12-08 10:00:06,961 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 3 missing tasks from ShuffleMapStage 4 (MapPartitionsRDD[10] at map at PaidPromotionAdjustParameter.scala:256) (first 15 tasks are for partitions Vector(0, 1, 2))
2021-12-08 10:00:06,961 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 4.0 with 3 tasks
2021-12-08 10:00:06,962 [dispatcher-event-loop-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 4.0 (TID 6, localhost, executor driver, partition 0, ANY, 7748 bytes)
2021-12-08 10:00:06,962 [dispatcher-event-loop-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 4.0 (TID 7, localhost, executor driver, partition 1, ANY, 7748 bytes)
2021-12-08 10:00:06,962 [dispatcher-event-loop-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 2.0 in stage 4.0 (TID 8, localhost, executor driver, partition 2, ANY, 7748 bytes)
2021-12-08 10:00:06,962 [Executor task launch worker for task 7] INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 4.0 (TID 7)
2021-12-08 10:00:06,962 [Executor task launch worker for task 6] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 4.0 (TID 6)
2021-12-08 10:00:06,963 [Executor task launch worker for task 8] INFO [org.apache.spark.executor.Executor] - Running task 2.0 in stage 4.0 (TID 8)
2021-12-08 10:00:06,965 [Executor task launch worker for task 8] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 2 non-empty blocks out of 2 blocks
2021-12-08 10:00:06,965 [Executor task launch worker for task 7] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 2 non-empty blocks out of 2 blocks
2021-12-08 10:00:06,965 [Executor task launch worker for task 8] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-08 10:00:06,965 [Executor task launch worker for task 6] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 2 non-empty blocks out of 2 blocks
2021-12-08 10:00:06,965 [Executor task launch worker for task 7] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-08 10:00:06,965 [Executor task launch worker for task 6] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-08 10:00:06,984 [Executor task launch worker for task 6] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 4.0 (TID 6). 1162 bytes result sent to driver
2021-12-08 10:00:06,984 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 4.0 (TID 6) in 23 ms on localhost (executor driver) (1/3)
2021-12-08 10:00:06,985 [Executor task launch worker for task 7] INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 4.0 (TID 7). 1205 bytes result sent to driver
2021-12-08 10:00:06,986 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 4.0 (TID 7) in 24 ms on localhost (executor driver) (2/3)
2021-12-08 10:00:06,986 [Executor task launch worker for task 8] INFO [org.apache.spark.executor.Executor] - Finished task 2.0 in stage 4.0 (TID 8). 1162 bytes result sent to driver
2021-12-08 10:00:06,987 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 2.0 in stage 4.0 (TID 8) in 25 ms on localhost (executor driver) (3/3)
2021-12-08 10:00:06,987 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 4.0, whose tasks have all completed, from pool 
2021-12-08 10:00:06,987 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ShuffleMapStage 4 (map at PaidPromotionAdjustParameter.scala:256) finished in 0.032 s
2021-12-08 10:00:06,987 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - looking for newly runnable stages
2021-12-08 10:00:06,987 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - running: Set()
2021-12-08 10:00:06,987 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - waiting: Set(ResultStage 5)
2021-12-08 10:00:06,988 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - failed: Set()
2021-12-08 10:00:06,988 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 5 (MapPartitionsRDD[12] at map at PaidPromotionAdjustParameter.scala:258), which has no missing parents
2021-12-08 10:00:06,989 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_6 stored as values in memory (estimated size 3.6 KB, free 1990.1 MB)
2021-12-08 10:00:06,992 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_6_piece0 stored as bytes in memory (estimated size 2.1 KB, free 1990.1 MB)
2021-12-08 10:00:06,993 [dispatcher-event-loop-7] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_6_piece0 in memory on qb:64003 (size: 2.1 KB, free: 1990.7 MB)
2021-12-08 10:00:06,994 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 6 from broadcast at DAGScheduler.scala:1039
2021-12-08 10:00:06,994 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 5 (MapPartitionsRDD[12] at map at PaidPromotionAdjustParameter.scala:258) (first 15 tasks are for partitions Vector(0))
2021-12-08 10:00:06,994 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 5.0 with 1 tasks
2021-12-08 10:00:06,995 [dispatcher-event-loop-8] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 5.0 (TID 9, localhost, executor driver, partition 0, PROCESS_LOCAL, 7649 bytes)
2021-12-08 10:00:06,996 [Executor task launch worker for task 9] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 5.0 (TID 9)
2021-12-08 10:00:06,998 [Executor task launch worker for task 9] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 0 non-empty blocks out of 3 blocks
2021-12-08 10:00:06,998 [Executor task launch worker for task 9] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-08 10:00:07,003 [Executor task launch worker for task 9] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 5.0 (TID 9). 1011 bytes result sent to driver
2021-12-08 10:00:07,003 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 5.0 (TID 9) in 8 ms on localhost (executor driver) (1/1)
2021-12-08 10:00:07,004 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 5.0, whose tasks have all completed, from pool 
2021-12-08 10:00:07,004 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 5 (take at PaidPromotionAdjustParameter.scala:259) finished in 0.016 s
2021-12-08 10:00:07,005 [main] INFO [org.apache.spark.scheduler.DAGScheduler] - Job 2 finished: take at PaidPromotionAdjustParameter.scala:259, took 0.051786 s
2021-12-08 10:00:07,011 [main] INFO [org.apache.spark.SparkContext] - Starting job: take at PaidPromotionAdjustParameter.scala:259
2021-12-08 10:00:07,012 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 3 (take at PaidPromotionAdjustParameter.scala:259) with 2 output partitions
2021-12-08 10:00:07,013 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 8 (take at PaidPromotionAdjustParameter.scala:259)
2021-12-08 10:00:07,013 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 7)
2021-12-08 10:00:07,013 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2021-12-08 10:00:07,013 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 8 (MapPartitionsRDD[12] at map at PaidPromotionAdjustParameter.scala:258), which has no missing parents
2021-12-08 10:00:07,014 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_7 stored as values in memory (estimated size 3.6 KB, free 1990.1 MB)
2021-12-08 10:00:07,016 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_7_piece0 stored as bytes in memory (estimated size 2.1 KB, free 1990.1 MB)
2021-12-08 10:00:07,017 [dispatcher-event-loop-11] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_7_piece0 in memory on qb:64003 (size: 2.1 KB, free: 1990.7 MB)
2021-12-08 10:00:07,017 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 7 from broadcast at DAGScheduler.scala:1039
2021-12-08 10:00:07,018 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from ResultStage 8 (MapPartitionsRDD[12] at map at PaidPromotionAdjustParameter.scala:258) (first 15 tasks are for partitions Vector(1, 2))
2021-12-08 10:00:07,018 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 8.0 with 2 tasks
2021-12-08 10:00:07,018 [dispatcher-event-loop-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 8.0 (TID 10, localhost, executor driver, partition 2, PROCESS_LOCAL, 7649 bytes)
2021-12-08 10:00:07,019 [dispatcher-event-loop-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 8.0 (TID 11, localhost, executor driver, partition 1, ANY, 7649 bytes)
2021-12-08 10:00:07,019 [Executor task launch worker for task 11] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 8.0 (TID 11)
2021-12-08 10:00:07,019 [Executor task launch worker for task 10] INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 8.0 (TID 10)
2021-12-08 10:00:07,020 [Executor task launch worker for task 10] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 0 non-empty blocks out of 3 blocks
2021-12-08 10:00:07,020 [Executor task launch worker for task 10] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-08 10:00:07,021 [Executor task launch worker for task 11] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 3 non-empty blocks out of 3 blocks
2021-12-08 10:00:07,021 [Executor task launch worker for task 11] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 1 ms
2021-12-08 10:00:07,026 [Executor task launch worker for task 10] INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 8.0 (TID 10). 1011 bytes result sent to driver
2021-12-08 10:00:07,026 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 8.0 (TID 10) in 8 ms on localhost (executor driver) (1/2)
2021-12-08 10:00:07,038 [Executor task launch worker for task 11] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 8.0 (TID 11). 970 bytes result sent to driver
2021-12-08 10:00:07,038 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 8.0 (TID 11) in 20 ms on localhost (executor driver) (2/2)
2021-12-08 10:00:07,038 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 8.0, whose tasks have all completed, from pool 
2021-12-08 10:00:07,038 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 8 (take at PaidPromotionAdjustParameter.scala:259) finished in 0.025 s
2021-12-08 10:00:07,039 [main] INFO [org.apache.spark.scheduler.DAGScheduler] - Job 3 finished: take at PaidPromotionAdjustParameter.scala:259, took 0.027194 s
2021-12-08 10:00:07,039 [main] INFO [PaidPromotionAdjustParameter$] - 训练集产品包总数： 131
2021-12-08 10:00:07,049 [main] INFO [org.apache.hadoop.mapred.FileInputFormat] - Total input paths to process : 10
2021-12-08 10:00:07,052 [main] INFO [org.apache.spark.SparkContext] - Starting job: count at PaidPromotionAdjustParameter.scala:269
2021-12-08 10:00:07,052 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 4 (count at PaidPromotionAdjustParameter.scala:269) with 10 output partitions
2021-12-08 10:00:07,052 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 9 (count at PaidPromotionAdjustParameter.scala:269)
2021-12-08 10:00:07,052 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List()
2021-12-08 10:00:07,052 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2021-12-08 10:00:07,052 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 9 (MapPartitionsRDD[13] at map at PaidPromotionAdjustParameter.scala:265), which has no missing parents
2021-12-08 10:00:07,054 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_8 stored as values in memory (estimated size 3.3 KB, free 1990.1 MB)
2021-12-08 10:00:07,056 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_8_piece0 stored as bytes in memory (estimated size 1994.0 B, free 1990.1 MB)
2021-12-08 10:00:07,057 [dispatcher-event-loop-4] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_8_piece0 in memory on qb:64003 (size: 1994.0 B, free: 1990.7 MB)
2021-12-08 10:00:07,057 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 8 from broadcast at DAGScheduler.scala:1039
2021-12-08 10:00:07,057 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 10 missing tasks from ResultStage 9 (MapPartitionsRDD[13] at map at PaidPromotionAdjustParameter.scala:265) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
2021-12-08 10:00:07,057 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 9.0 with 10 tasks
2021-12-08 10:00:07,058 [dispatcher-event-loop-6] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 9.0 (TID 12, localhost, executor driver, partition 0, ANY, 7917 bytes)
2021-12-08 10:00:07,058 [dispatcher-event-loop-6] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 9.0 (TID 13, localhost, executor driver, partition 1, ANY, 7917 bytes)
2021-12-08 10:00:07,058 [dispatcher-event-loop-6] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 2.0 in stage 9.0 (TID 14, localhost, executor driver, partition 2, ANY, 7917 bytes)
2021-12-08 10:00:07,059 [dispatcher-event-loop-6] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 3.0 in stage 9.0 (TID 15, localhost, executor driver, partition 3, ANY, 7917 bytes)
2021-12-08 10:00:07,059 [dispatcher-event-loop-6] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 4.0 in stage 9.0 (TID 16, localhost, executor driver, partition 4, ANY, 7917 bytes)
2021-12-08 10:00:07,059 [dispatcher-event-loop-6] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 5.0 in stage 9.0 (TID 17, localhost, executor driver, partition 5, ANY, 7917 bytes)
2021-12-08 10:00:07,059 [dispatcher-event-loop-6] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 6.0 in stage 9.0 (TID 18, localhost, executor driver, partition 6, ANY, 7917 bytes)
2021-12-08 10:00:07,059 [dispatcher-event-loop-6] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 7.0 in stage 9.0 (TID 19, localhost, executor driver, partition 7, ANY, 7917 bytes)
2021-12-08 10:00:07,059 [dispatcher-event-loop-6] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 8.0 in stage 9.0 (TID 20, localhost, executor driver, partition 8, ANY, 7917 bytes)
2021-12-08 10:00:07,060 [dispatcher-event-loop-6] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 9.0 in stage 9.0 (TID 21, localhost, executor driver, partition 9, ANY, 7917 bytes)
2021-12-08 10:00:07,060 [Executor task launch worker for task 13] INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 9.0 (TID 13)
2021-12-08 10:00:07,060 [Executor task launch worker for task 14] INFO [org.apache.spark.executor.Executor] - Running task 2.0 in stage 9.0 (TID 14)
2021-12-08 10:00:07,060 [Executor task launch worker for task 12] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 9.0 (TID 12)
2021-12-08 10:00:07,060 [Executor task launch worker for task 15] INFO [org.apache.spark.executor.Executor] - Running task 3.0 in stage 9.0 (TID 15)
2021-12-08 10:00:07,061 [Executor task launch worker for task 16] INFO [org.apache.spark.executor.Executor] - Running task 4.0 in stage 9.0 (TID 16)
2021-12-08 10:00:07,061 [Executor task launch worker for task 18] INFO [org.apache.spark.executor.Executor] - Running task 6.0 in stage 9.0 (TID 18)
2021-12-08 10:00:07,061 [Executor task launch worker for task 17] INFO [org.apache.spark.executor.Executor] - Running task 5.0 in stage 9.0 (TID 17)
2021-12-08 10:00:07,062 [Executor task launch worker for task 19] INFO [org.apache.spark.executor.Executor] - Running task 7.0 in stage 9.0 (TID 19)
2021-12-08 10:00:07,062 [Executor task launch worker for task 20] INFO [org.apache.spark.executor.Executor] - Running task 8.0 in stage 9.0 (TID 20)
2021-12-08 10:00:07,062 [Executor task launch worker for task 21] INFO [org.apache.spark.executor.Executor] - Running task 9.0 in stage 9.0 (TID 21)
2021-12-08 10:00:07,063 [Executor task launch worker for task 15] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/handle_data/device_video_data/part-00003:0+29761082
2021-12-08 10:00:07,063 [Executor task launch worker for task 14] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/handle_data/device_video_data/part-00002:0+43831145
2021-12-08 10:00:07,063 [Executor task launch worker for task 12] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/handle_data/device_video_data/part-00000:0+29528642
2021-12-08 10:00:07,065 [Executor task launch worker for task 18] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/handle_data/device_video_data/part-00006:0+29631891
2021-12-08 10:00:07,066 [Executor task launch worker for task 21] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/handle_data/device_video_data/part-00009:0+29225612
2021-12-08 10:00:07,066 [Executor task launch worker for task 13] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/handle_data/device_video_data/part-00001:0+38414410
2021-12-08 10:00:07,066 [Executor task launch worker for task 17] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/handle_data/device_video_data/part-00005:0+14798635
2021-12-08 10:00:07,066 [Executor task launch worker for task 20] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/handle_data/device_video_data/part-00008:0+29423447
2021-12-08 10:00:07,066 [Executor task launch worker for task 19] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/handle_data/device_video_data/part-00007:0+29599448
2021-12-08 10:00:07,066 [Executor task launch worker for task 16] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/handle_data/device_video_data/part-00004:0+14256802
2021-12-08 10:00:07,092 [Executor task launch worker for task 18] ERROR [org.apache.spark.executor.Executor] - Exception in task 6.0 in stage 9.0 (TID 18)
java.lang.ArrayIndexOutOfBoundsException: 1
	at PaidPromotionAdjustParameter$$anonfun$33.apply(PaidPromotionAdjustParameter.scala:266)
	at PaidPromotionAdjustParameter$$anonfun$33.apply(PaidPromotionAdjustParameter.scala:265)
	at scala.collection.Iterator$$anon$11.next(Iterator.scala:409)
	at org.apache.spark.util.Utils$.getIteratorSize(Utils.scala:1835)
	at org.apache.spark.rdd.RDD$$anonfun$count$1.apply(RDD.scala:1162)
	at org.apache.spark.rdd.RDD$$anonfun$count$1.apply(RDD.scala:1162)
	at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2067)
	at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2067)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:109)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:345)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
2021-12-08 10:00:07,108 [task-result-getter-0] WARN [org.apache.spark.scheduler.TaskSetManager] - Lost task 6.0 in stage 9.0 (TID 18, localhost, executor driver): java.lang.ArrayIndexOutOfBoundsException: 1
	at PaidPromotionAdjustParameter$$anonfun$33.apply(PaidPromotionAdjustParameter.scala:266)
	at PaidPromotionAdjustParameter$$anonfun$33.apply(PaidPromotionAdjustParameter.scala:265)
	at scala.collection.Iterator$$anon$11.next(Iterator.scala:409)
	at org.apache.spark.util.Utils$.getIteratorSize(Utils.scala:1835)
	at org.apache.spark.rdd.RDD$$anonfun$count$1.apply(RDD.scala:1162)
	at org.apache.spark.rdd.RDD$$anonfun$count$1.apply(RDD.scala:1162)
	at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2067)
	at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2067)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:109)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:345)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)

2021-12-08 10:00:07,109 [task-result-getter-0] ERROR [org.apache.spark.scheduler.TaskSetManager] - Task 6 in stage 9.0 failed 1 times; aborting job
2021-12-08 10:00:07,114 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Cancelling stage 9
2021-12-08 10:00:07,117 [dispatcher-event-loop-7] INFO [org.apache.spark.executor.Executor] - Executor is trying to kill task 3.0 in stage 9.0 (TID 15), reason: Stage cancelled
2021-12-08 10:00:07,117 [dispatcher-event-loop-7] INFO [org.apache.spark.executor.Executor] - Executor is trying to kill task 0.0 in stage 9.0 (TID 12), reason: Stage cancelled
2021-12-08 10:00:07,117 [dispatcher-event-loop-7] INFO [org.apache.spark.executor.Executor] - Executor is trying to kill task 7.0 in stage 9.0 (TID 19), reason: Stage cancelled
2021-12-08 10:00:07,117 [dispatcher-event-loop-7] INFO [org.apache.spark.executor.Executor] - Executor is trying to kill task 4.0 in stage 9.0 (TID 16), reason: Stage cancelled
2021-12-08 10:00:07,117 [dispatcher-event-loop-7] INFO [org.apache.spark.executor.Executor] - Executor is trying to kill task 1.0 in stage 9.0 (TID 13), reason: Stage cancelled
2021-12-08 10:00:07,117 [dispatcher-event-loop-7] INFO [org.apache.spark.executor.Executor] - Executor is trying to kill task 8.0 in stage 9.0 (TID 20), reason: Stage cancelled
2021-12-08 10:00:07,117 [dispatcher-event-loop-7] INFO [org.apache.spark.executor.Executor] - Executor is trying to kill task 5.0 in stage 9.0 (TID 17), reason: Stage cancelled
2021-12-08 10:00:07,117 [dispatcher-event-loop-7] INFO [org.apache.spark.executor.Executor] - Executor is trying to kill task 9.0 in stage 9.0 (TID 21), reason: Stage cancelled
2021-12-08 10:00:07,117 [dispatcher-event-loop-7] INFO [org.apache.spark.executor.Executor] - Executor is trying to kill task 2.0 in stage 9.0 (TID 14), reason: Stage cancelled
2021-12-08 10:00:07,117 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Stage 9 was cancelled
2021-12-08 10:00:07,118 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 9 (count at PaidPromotionAdjustParameter.scala:269) failed in 0.064 s due to Job aborted due to stage failure: Task 6 in stage 9.0 failed 1 times, most recent failure: Lost task 6.0 in stage 9.0 (TID 18, localhost, executor driver): java.lang.ArrayIndexOutOfBoundsException: 1
	at PaidPromotionAdjustParameter$$anonfun$33.apply(PaidPromotionAdjustParameter.scala:266)
	at PaidPromotionAdjustParameter$$anonfun$33.apply(PaidPromotionAdjustParameter.scala:265)
	at scala.collection.Iterator$$anon$11.next(Iterator.scala:409)
	at org.apache.spark.util.Utils$.getIteratorSize(Utils.scala:1835)
	at org.apache.spark.rdd.RDD$$anonfun$count$1.apply(RDD.scala:1162)
	at org.apache.spark.rdd.RDD$$anonfun$count$1.apply(RDD.scala:1162)
	at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2067)
	at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2067)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:109)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:345)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)

Driver stacktrace:
2021-12-08 10:00:07,119 [main] INFO [org.apache.spark.scheduler.DAGScheduler] - Job 4 failed: count at PaidPromotionAdjustParameter.scala:269, took 0.067274 s
2021-12-08 10:00:07,122 [Thread-1] INFO [org.apache.spark.SparkContext] - Invoking stop() from shutdown hook
2021-12-08 10:00:07,128 [Thread-1] INFO [org.spark_project.jetty.server.AbstractConnector] - Stopped Spark@5f7f2382{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2021-12-08 10:00:07,130 [Thread-1] INFO [org.apache.spark.ui.SparkUI] - Stopped Spark web UI at http://qb:4040
2021-12-08 10:00:07,137 [Executor task launch worker for task 20] INFO [org.apache.spark.executor.Executor] - Executor interrupted and killed task 8.0 in stage 9.0 (TID 20), reason: Stage cancelled
2021-12-08 10:00:07,141 [dispatcher-event-loop-8] INFO [org.apache.spark.MapOutputTrackerMasterEndpoint] - MapOutputTrackerMasterEndpoint stopped!
2021-12-08 10:00:07,152 [Executor task launch worker for task 12] INFO [org.apache.spark.executor.Executor] - Executor interrupted and killed task 0.0 in stage 9.0 (TID 12), reason: Stage cancelled
2021-12-08 10:00:07,176 [Thread-1] INFO [org.apache.spark.storage.memory.MemoryStore] - MemoryStore cleared
2021-12-08 10:00:07,176 [Thread-1] INFO [org.apache.spark.storage.BlockManager] - BlockManager stopped
2021-12-08 10:00:07,178 [Thread-1] INFO [org.apache.spark.storage.BlockManagerMaster] - BlockManagerMaster stopped
2021-12-08 10:00:07,181 [dispatcher-event-loop-2] INFO [org.apache.spark.scheduler.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint] - OutputCommitCoordinator stopped!
2021-12-08 10:00:07,184 [Thread-1] INFO [org.apache.spark.SparkContext] - Successfully stopped SparkContext
2021-12-08 10:00:07,185 [Thread-1] INFO [org.apache.spark.util.ShutdownHookManager] - Shutdown hook called
2021-12-08 10:00:07,187 [Thread-1] INFO [org.apache.spark.util.ShutdownHookManager] - Deleting directory C:\Users\ACER\AppData\Local\Temp\spark-9244c2cf-aaa6-4856-a963-5b4109a92a5d
2021-12-08 10:00:07,189 [Executor task launch worker for task 13] ERROR [org.apache.spark.util.Utils] - Uncaught exception in thread Executor task launch worker for task 13
java.lang.NullPointerException
	at org.apache.spark.scheduler.Task$$anonfun$run$1.apply$mcV$sp(Task.scala:130)
	at org.apache.spark.util.Utils$.tryLogNonFatalError(Utils.scala:1357)
	at org.apache.spark.scheduler.Task.run(Task.scala:128)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:345)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
2021-12-08 10:00:07,209 [Executor task launch worker for task 21] ERROR [org.apache.spark.util.Utils] - Uncaught exception in thread Executor task launch worker for task 21
java.lang.NullPointerException
	at org.apache.spark.scheduler.Task$$anonfun$run$1.apply$mcV$sp(Task.scala:130)
	at org.apache.spark.util.Utils$.tryLogNonFatalError(Utils.scala:1357)
	at org.apache.spark.scheduler.Task.run(Task.scala:128)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:345)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
2021-12-08 10:00:07,212 [Executor task launch worker for task 13] INFO [org.apache.spark.executor.Executor] - Executor interrupted and killed task 1.0 in stage 9.0 (TID 13), reason: Stage cancelled
2021-12-08 10:00:07,212 [Executor task launch worker for task 21] INFO [org.apache.spark.executor.Executor] - Executor interrupted and killed task 9.0 in stage 9.0 (TID 21), reason: Stage cancelled
2021-12-08 10:00:07,224 [Executor task launch worker for task 16] ERROR [org.apache.spark.util.Utils] - Uncaught exception in thread Executor task launch worker for task 16
java.lang.NullPointerException
	at org.apache.spark.scheduler.Task$$anonfun$run$1.apply$mcV$sp(Task.scala:130)
	at org.apache.spark.util.Utils$.tryLogNonFatalError(Utils.scala:1357)
	at org.apache.spark.scheduler.Task.run(Task.scala:128)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:345)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
2021-12-08 10:00:07,225 [Executor task launch worker for task 16] INFO [org.apache.spark.executor.Executor] - Executor interrupted and killed task 4.0 in stage 9.0 (TID 16), reason: Stage cancelled
2021-12-08 10:00:07,229 [Executor task launch worker for task 19] ERROR [org.apache.spark.util.Utils] - Uncaught exception in thread Executor task launch worker for task 19
java.lang.NullPointerException
	at org.apache.spark.scheduler.Task$$anonfun$run$1.apply$mcV$sp(Task.scala:130)
	at org.apache.spark.util.Utils$.tryLogNonFatalError(Utils.scala:1357)
	at org.apache.spark.scheduler.Task.run(Task.scala:128)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:345)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
2021-12-08 10:00:07,229 [Executor task launch worker for task 17] ERROR [org.apache.spark.util.Utils] - Uncaught exception in thread Executor task launch worker for task 17
java.lang.NullPointerException
	at org.apache.spark.scheduler.Task$$anonfun$run$1.apply$mcV$sp(Task.scala:130)
	at org.apache.spark.util.Utils$.tryLogNonFatalError(Utils.scala:1357)
	at org.apache.spark.scheduler.Task.run(Task.scala:128)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:345)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
2021-12-08 10:00:07,229 [Executor task launch worker for task 19] INFO [org.apache.spark.executor.Executor] - Executor interrupted and killed task 7.0 in stage 9.0 (TID 19), reason: Stage cancelled
2021-12-08 10:00:07,230 [Executor task launch worker for task 17] INFO [org.apache.spark.executor.Executor] - Executor interrupted and killed task 5.0 in stage 9.0 (TID 17), reason: Stage cancelled
2021-12-08 10:00:07,247 [Executor task launch worker for task 15] ERROR [org.apache.spark.util.Utils] - Uncaught exception in thread Executor task launch worker for task 15
java.lang.NullPointerException
	at org.apache.spark.scheduler.Task$$anonfun$run$1.apply$mcV$sp(Task.scala:130)
	at org.apache.spark.util.Utils$.tryLogNonFatalError(Utils.scala:1357)
	at org.apache.spark.scheduler.Task.run(Task.scala:128)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:345)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
2021-12-08 10:00:07,248 [Executor task launch worker for task 15] INFO [org.apache.spark.executor.Executor] - Executor interrupted and killed task 3.0 in stage 9.0 (TID 15), reason: Stage cancelled
2021-12-08 10:00:07,258 [Executor task launch worker for task 14] ERROR [org.apache.spark.TaskContextImpl] - Error in TaskCompletionListener
java.lang.IllegalStateException: Block broadcast_8 not found
	at org.apache.spark.storage.BlockInfoManager$$anonfun$2.apply(BlockInfoManager.scala:293)
	at org.apache.spark.storage.BlockInfoManager$$anonfun$2.apply(BlockInfoManager.scala:293)
	at scala.Option.getOrElse(Option.scala:121)
	at org.apache.spark.storage.BlockInfoManager.unlock(BlockInfoManager.scala:292)
	at org.apache.spark.storage.BlockManager.releaseLock(BlockManager.scala:769)
	at org.apache.spark.broadcast.TorrentBroadcast$$anonfun$org$apache$spark$broadcast$TorrentBroadcast$$releaseLock$1.apply(TorrentBroadcast.scala:265)
	at org.apache.spark.broadcast.TorrentBroadcast$$anonfun$org$apache$spark$broadcast$TorrentBroadcast$$releaseLock$1.apply(TorrentBroadcast.scala:265)
	at org.apache.spark.TaskContext$$anon$1.onTaskCompletion(TaskContext.scala:128)
	at org.apache.spark.TaskContextImpl$$anonfun$markTaskCompleted$1.apply(TaskContextImpl.scala:118)
	at org.apache.spark.TaskContextImpl$$anonfun$markTaskCompleted$1.apply(TaskContextImpl.scala:118)
	at org.apache.spark.TaskContextImpl$$anonfun$invokeListeners$1.apply(TaskContextImpl.scala:131)
	at org.apache.spark.TaskContextImpl$$anonfun$invokeListeners$1.apply(TaskContextImpl.scala:129)
	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)
	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48)
	at org.apache.spark.TaskContextImpl.invokeListeners(TaskContextImpl.scala:129)
	at org.apache.spark.TaskContextImpl.markTaskCompleted(TaskContextImpl.scala:117)
	at org.apache.spark.scheduler.Task.run(Task.scala:119)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:345)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
2021-12-08 10:00:07,259 [Executor task launch worker for task 14] ERROR [org.apache.spark.util.Utils] - Uncaught exception in thread Executor task launch worker for task 14
java.lang.NullPointerException
	at org.apache.spark.scheduler.Task$$anonfun$run$1.apply$mcV$sp(Task.scala:130)
	at org.apache.spark.util.Utils$.tryLogNonFatalError(Utils.scala:1357)
	at org.apache.spark.scheduler.Task.run(Task.scala:128)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:345)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
2021-12-08 10:00:07,259 [Executor task launch worker for task 14] INFO [org.apache.spark.executor.Executor] - Executor interrupted and killed task 2.0 in stage 9.0 (TID 14), reason: Stage cancelled
2021-12-08 10:02:35,052 [main] INFO [org.apache.spark.SparkContext] - Running Spark version 2.3.0
2021-12-08 10:02:35,320 [main] INFO [org.apache.spark.SparkContext] - Submitted application: PaidPromotionAdjustParameter
2021-12-08 10:02:35,366 [main] INFO [org.apache.spark.SecurityManager] - Changing view acls to: ACER,root
2021-12-08 10:02:35,366 [main] INFO [org.apache.spark.SecurityManager] - Changing modify acls to: ACER,root
2021-12-08 10:02:35,367 [main] INFO [org.apache.spark.SecurityManager] - Changing view acls groups to: 
2021-12-08 10:02:35,367 [main] INFO [org.apache.spark.SecurityManager] - Changing modify acls groups to: 
2021-12-08 10:02:35,367 [main] INFO [org.apache.spark.SecurityManager] - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(ACER, root); groups with view permissions: Set(); users  with modify permissions: Set(ACER, root); groups with modify permissions: Set()
2021-12-08 10:02:35,921 [main] INFO [org.apache.spark.util.Utils] - Successfully started service 'sparkDriver' on port 55545.
2021-12-08 10:02:35,942 [main] INFO [org.apache.spark.SparkEnv] - Registering MapOutputTracker
2021-12-08 10:02:35,957 [main] INFO [org.apache.spark.SparkEnv] - Registering BlockManagerMaster
2021-12-08 10:02:35,960 [main] INFO [org.apache.spark.storage.BlockManagerMasterEndpoint] - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2021-12-08 10:02:35,960 [main] INFO [org.apache.spark.storage.BlockManagerMasterEndpoint] - BlockManagerMasterEndpoint up
2021-12-08 10:02:35,967 [main] INFO [org.apache.spark.storage.DiskBlockManager] - Created local directory at C:\Users\ACER\AppData\Local\Temp\blockmgr-3eca5f48-2327-4ace-be81-3709d68ac6af
2021-12-08 10:02:35,982 [main] INFO [org.apache.spark.storage.memory.MemoryStore] - MemoryStore started with capacity 1990.8 MB
2021-12-08 10:02:35,991 [main] INFO [org.apache.spark.SparkEnv] - Registering OutputCommitCoordinator
2021-12-08 10:02:36,048 [main] INFO [org.spark_project.jetty.util.log] - Logging initialized @1843ms
2021-12-08 10:02:36,102 [main] INFO [org.spark_project.jetty.server.Server] - jetty-9.3.z-SNAPSHOT
2021-12-08 10:02:36,114 [main] INFO [org.spark_project.jetty.server.Server] - Started @1909ms
2021-12-08 10:02:36,141 [main] INFO [org.spark_project.jetty.server.AbstractConnector] - Started ServerConnector@5b800468{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2021-12-08 10:02:36,141 [main] INFO [org.apache.spark.util.Utils] - Successfully started service 'SparkUI' on port 4040.
2021-12-08 10:02:36,165 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@1568159{/jobs,null,AVAILABLE,@Spark}
2021-12-08 10:02:36,166 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@63cd604c{/jobs/json,null,AVAILABLE,@Spark}
2021-12-08 10:02:36,166 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@3954d008{/jobs/job,null,AVAILABLE,@Spark}
2021-12-08 10:02:36,168 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@6d8792db{/jobs/job/json,null,AVAILABLE,@Spark}
2021-12-08 10:02:36,169 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@3a1d593e{/stages,null,AVAILABLE,@Spark}
2021-12-08 10:02:36,170 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@285d851a{/stages/json,null,AVAILABLE,@Spark}
2021-12-08 10:02:36,171 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@7876d598{/stages/stage,null,AVAILABLE,@Spark}
2021-12-08 10:02:36,173 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@4985cbcb{/stages/stage/json,null,AVAILABLE,@Spark}
2021-12-08 10:02:36,174 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@54361a9{/stages/pool,null,AVAILABLE,@Spark}
2021-12-08 10:02:36,175 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@293bb8a5{/stages/pool/json,null,AVAILABLE,@Spark}
2021-12-08 10:02:36,176 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@290b1b2e{/storage,null,AVAILABLE,@Spark}
2021-12-08 10:02:36,177 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@5db4c359{/storage/json,null,AVAILABLE,@Spark}
2021-12-08 10:02:36,179 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@6fefce9e{/storage/rdd,null,AVAILABLE,@Spark}
2021-12-08 10:02:36,180 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@8a589a2{/storage/rdd/json,null,AVAILABLE,@Spark}
2021-12-08 10:02:36,181 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@5cc69cfe{/environment,null,AVAILABLE,@Spark}
2021-12-08 10:02:36,183 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@11dee337{/environment/json,null,AVAILABLE,@Spark}
2021-12-08 10:02:36,184 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@74bdc168{/executors,null,AVAILABLE,@Spark}
2021-12-08 10:02:36,185 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@7bb3a9fe{/executors/json,null,AVAILABLE,@Spark}
2021-12-08 10:02:36,186 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@f19c9d2{/executors/threadDump,null,AVAILABLE,@Spark}
2021-12-08 10:02:36,187 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@a77614d{/executors/threadDump/json,null,AVAILABLE,@Spark}
2021-12-08 10:02:36,194 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@523424b5{/static,null,AVAILABLE,@Spark}
2021-12-08 10:02:36,195 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@12cd9150{/,null,AVAILABLE,@Spark}
2021-12-08 10:02:36,199 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@32fe9d0a{/api,null,AVAILABLE,@Spark}
2021-12-08 10:02:36,200 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@59fc684e{/jobs/job/kill,null,AVAILABLE,@Spark}
2021-12-08 10:02:36,201 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@355e34c7{/stages/stage/kill,null,AVAILABLE,@Spark}
2021-12-08 10:02:36,204 [main] INFO [org.apache.spark.ui.SparkUI] - Bound SparkUI to 0.0.0.0, and started at http://qb:4040
2021-12-08 10:02:36,280 [main] INFO [org.apache.spark.executor.Executor] - Starting executor ID driver on host localhost
2021-12-08 10:02:36,326 [main] INFO [org.apache.spark.util.Utils] - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 55588.
2021-12-08 10:02:36,327 [main] INFO [org.apache.spark.network.netty.NettyBlockTransferService] - Server created on qb:55588
2021-12-08 10:02:36,328 [main] INFO [org.apache.spark.storage.BlockManager] - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2021-12-08 10:02:36,329 [main] INFO [org.apache.spark.storage.BlockManagerMaster] - Registering BlockManager BlockManagerId(driver, qb, 55588, None)
2021-12-08 10:02:36,331 [dispatcher-event-loop-10] INFO [org.apache.spark.storage.BlockManagerMasterEndpoint] - Registering block manager qb:55588 with 1990.8 MB RAM, BlockManagerId(driver, qb, 55588, None)
2021-12-08 10:02:36,333 [main] INFO [org.apache.spark.storage.BlockManagerMaster] - Registered BlockManager BlockManagerId(driver, qb, 55588, None)
2021-12-08 10:02:36,333 [main] INFO [org.apache.spark.storage.BlockManager] - Initialized BlockManager: BlockManagerId(driver, qb, 55588, None)
2021-12-08 10:02:36,471 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@6fe46b62{/metrics/json,null,AVAILABLE,@Spark}
2021-12-08 10:02:36,968 [main] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_0 stored as values in memory (estimated size 312.7 KB, free 1990.5 MB)
2021-12-08 10:02:37,175 [main] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_0_piece0 stored as bytes in memory (estimated size 27.3 KB, free 1990.5 MB)
2021-12-08 10:02:37,178 [dispatcher-event-loop-0] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_0_piece0 in memory on qb:55588 (size: 27.3 KB, free: 1990.8 MB)
2021-12-08 10:02:37,183 [main] INFO [org.apache.spark.SparkContext] - Created broadcast 0 from textFile at PaidPromotionAdjustParameter.scala:239
2021-12-08 10:02:37,235 [main] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_1 stored as values in memory (estimated size 312.7 KB, free 1990.2 MB)
2021-12-08 10:02:37,253 [main] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_1_piece0 stored as bytes in memory (estimated size 27.3 KB, free 1990.1 MB)
2021-12-08 10:02:37,254 [dispatcher-event-loop-1] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_1_piece0 in memory on qb:55588 (size: 27.3 KB, free: 1990.7 MB)
2021-12-08 10:02:37,255 [main] INFO [org.apache.spark.SparkContext] - Created broadcast 1 from textFile at PaidPromotionAdjustParameter.scala:240
2021-12-08 10:02:37,584 [main] WARN [org.apache.hadoop.hdfs.shortcircuit.DomainSocketFactory] - The short-circuit local reads feature cannot be used because UNIX Domain sockets are not available on Windows.
2021-12-08 10:02:37,712 [main] INFO [org.apache.hadoop.mapred.FileInputFormat] - Total input paths to process : 1
2021-12-08 10:02:37,724 [main] INFO [org.apache.spark.SparkContext] - Starting job: count at PaidPromotionAdjustParameter.scala:248
2021-12-08 10:02:37,734 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 0 (count at PaidPromotionAdjustParameter.scala:248) with 2 output partitions
2021-12-08 10:02:37,735 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 0 (count at PaidPromotionAdjustParameter.scala:248)
2021-12-08 10:02:37,735 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List()
2021-12-08 10:02:37,736 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2021-12-08 10:02:37,741 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 0 (MapPartitionsRDD[4] at map at PaidPromotionAdjustParameter.scala:244), which has no missing parents
2021-12-08 10:02:37,779 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_2 stored as values in memory (estimated size 3.3 KB, free 1990.1 MB)
2021-12-08 10:02:37,784 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_2_piece0 stored as bytes in memory (estimated size 1994.0 B, free 1990.1 MB)
2021-12-08 10:02:37,785 [dispatcher-event-loop-2] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_2_piece0 in memory on qb:55588 (size: 1994.0 B, free: 1990.7 MB)
2021-12-08 10:02:37,786 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 2 from broadcast at DAGScheduler.scala:1039
2021-12-08 10:02:37,796 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from ResultStage 0 (MapPartitionsRDD[4] at map at PaidPromotionAdjustParameter.scala:244) (first 15 tasks are for partitions Vector(0, 1))
2021-12-08 10:02:37,797 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 0.0 with 2 tasks
2021-12-08 10:02:37,829 [dispatcher-event-loop-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 0.0 (TID 0, localhost, executor driver, partition 0, ANY, 7932 bytes)
2021-12-08 10:02:37,831 [dispatcher-event-loop-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 0.0 (TID 1, localhost, executor driver, partition 1, ANY, 7932 bytes)
2021-12-08 10:02:37,836 [Executor task launch worker for task 0] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 0.0 (TID 0)
2021-12-08 10:02:37,836 [Executor task launch worker for task 1] INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 0.0 (TID 1)
2021-12-08 10:02:37,876 [Executor task launch worker for task 1] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/handle_data/set-train-device-production-data/part-00000:3237750+3237751
2021-12-08 10:02:37,876 [Executor task launch worker for task 0] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/handle_data/set-train-device-production-data/part-00000:0+3237750
2021-12-08 10:02:38,542 [Executor task launch worker for task 1] INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 0.0 (TID 1). 754 bytes result sent to driver
2021-12-08 10:02:38,551 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 0.0 (TID 1) in 719 ms on localhost (executor driver) (1/2)
2021-12-08 10:02:38,576 [Executor task launch worker for task 0] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 0.0 (TID 0). 754 bytes result sent to driver
2021-12-08 10:02:38,579 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 0.0 (TID 0) in 759 ms on localhost (executor driver) (2/2)
2021-12-08 10:02:38,580 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 0.0, whose tasks have all completed, from pool 
2021-12-08 10:02:38,580 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 0 (count at PaidPromotionAdjustParameter.scala:248) finished in 0.823 s
2021-12-08 10:02:38,584 [main] INFO [org.apache.spark.scheduler.DAGScheduler] - Job 0 finished: count at PaidPromotionAdjustParameter.scala:248, took 0.860345 s
2021-12-08 10:02:38,585 [main] INFO [PaidPromotionAdjustParameter$] - 订购行为训练集个数：101055
2021-12-08 10:02:38,603 [main] INFO [org.apache.spark.SparkContext] - Starting job: zipWithIndex at PaidPromotionAdjustParameter.scala:253
2021-12-08 10:02:38,610 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 6 (distinct at PaidPromotionAdjustParameter.scala:252)
2021-12-08 10:02:38,611 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 1 (zipWithIndex at PaidPromotionAdjustParameter.scala:253) with 2 output partitions
2021-12-08 10:02:38,611 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 2 (zipWithIndex at PaidPromotionAdjustParameter.scala:253)
2021-12-08 10:02:38,611 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 1)
2021-12-08 10:02:38,612 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List(ShuffleMapStage 1)
2021-12-08 10:02:38,613 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ShuffleMapStage 1 (MapPartitionsRDD[6] at distinct at PaidPromotionAdjustParameter.scala:252), which has no missing parents
2021-12-08 10:02:38,621 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_3 stored as values in memory (estimated size 4.9 KB, free 1990.1 MB)
2021-12-08 10:02:38,624 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_3_piece0 stored as bytes in memory (estimated size 2.8 KB, free 1990.1 MB)
2021-12-08 10:02:38,625 [dispatcher-event-loop-8] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_3_piece0 in memory on qb:55588 (size: 2.8 KB, free: 1990.7 MB)
2021-12-08 10:02:38,625 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 3 from broadcast at DAGScheduler.scala:1039
2021-12-08 10:02:38,627 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from ShuffleMapStage 1 (MapPartitionsRDD[6] at distinct at PaidPromotionAdjustParameter.scala:252) (first 15 tasks are for partitions Vector(0, 1))
2021-12-08 10:02:38,627 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 1.0 with 2 tasks
2021-12-08 10:02:38,628 [dispatcher-event-loop-9] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 1.0 (TID 2, localhost, executor driver, partition 0, ANY, 7921 bytes)
2021-12-08 10:02:38,629 [dispatcher-event-loop-9] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 1.0 (TID 3, localhost, executor driver, partition 1, ANY, 7921 bytes)
2021-12-08 10:02:38,629 [Executor task launch worker for task 3] INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 1.0 (TID 3)
2021-12-08 10:02:38,629 [Executor task launch worker for task 2] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 1.0 (TID 2)
2021-12-08 10:02:38,633 [Executor task launch worker for task 2] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/handle_data/set-train-device-production-data/part-00000:0+3237750
2021-12-08 10:02:38,633 [Executor task launch worker for task 3] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/handle_data/set-train-device-production-data/part-00000:3237750+3237751
2021-12-08 10:02:38,933 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 13
2021-12-08 10:02:38,933 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 6
2021-12-08 10:02:38,944 [dispatcher-event-loop-2] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_2_piece0 on qb:55588 in memory (size: 1994.0 B, free: 1990.7 MB)
2021-12-08 10:02:38,946 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 12
2021-12-08 10:02:38,946 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1
2021-12-08 10:02:38,946 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 20
2021-12-08 10:02:38,946 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 15
2021-12-08 10:02:38,946 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 19
2021-12-08 10:02:38,946 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 21
2021-12-08 10:02:38,947 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 23
2021-12-08 10:02:38,947 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 18
2021-12-08 10:02:38,947 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 14
2021-12-08 10:02:38,947 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 10
2021-12-08 10:02:38,947 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 24
2021-12-08 10:02:38,947 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 2
2021-12-08 10:02:38,947 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 8
2021-12-08 10:02:38,947 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 22
2021-12-08 10:02:38,947 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 7
2021-12-08 10:02:38,947 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 11
2021-12-08 10:02:38,947 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 4
2021-12-08 10:02:38,947 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 3
2021-12-08 10:02:38,947 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 0
2021-12-08 10:02:38,947 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 9
2021-12-08 10:02:38,947 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 17
2021-12-08 10:02:38,947 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 16
2021-12-08 10:02:38,947 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 5
2021-12-08 10:02:39,155 [Executor task launch worker for task 3] INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 1.0 (TID 3). 1033 bytes result sent to driver
2021-12-08 10:02:39,170 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 1.0 (TID 3) in 542 ms on localhost (executor driver) (1/2)
2021-12-08 10:02:39,288 [Executor task launch worker for task 2] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 1.0 (TID 2). 1076 bytes result sent to driver
2021-12-08 10:02:39,290 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 1.0 (TID 2) in 662 ms on localhost (executor driver) (2/2)
2021-12-08 10:02:39,290 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 1.0, whose tasks have all completed, from pool 
2021-12-08 10:02:39,291 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ShuffleMapStage 1 (distinct at PaidPromotionAdjustParameter.scala:252) finished in 0.675 s
2021-12-08 10:02:39,291 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - looking for newly runnable stages
2021-12-08 10:02:39,291 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - running: Set()
2021-12-08 10:02:39,292 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - waiting: Set(ResultStage 2)
2021-12-08 10:02:39,292 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - failed: Set()
2021-12-08 10:02:39,295 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 2 (MapPartitionsRDD[8] at distinct at PaidPromotionAdjustParameter.scala:252), which has no missing parents
2021-12-08 10:02:39,299 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_4 stored as values in memory (estimated size 3.7 KB, free 1990.1 MB)
2021-12-08 10:02:39,303 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_4_piece0 stored as bytes in memory (estimated size 2.2 KB, free 1990.1 MB)
2021-12-08 10:02:39,303 [dispatcher-event-loop-4] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_4_piece0 in memory on qb:55588 (size: 2.2 KB, free: 1990.7 MB)
2021-12-08 10:02:39,304 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 4 from broadcast at DAGScheduler.scala:1039
2021-12-08 10:02:39,304 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from ResultStage 2 (MapPartitionsRDD[8] at distinct at PaidPromotionAdjustParameter.scala:252) (first 15 tasks are for partitions Vector(0, 1))
2021-12-08 10:02:39,304 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 2.0 with 2 tasks
2021-12-08 10:02:39,305 [dispatcher-event-loop-6] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 2.0 (TID 4, localhost, executor driver, partition 0, ANY, 7649 bytes)
2021-12-08 10:02:39,305 [dispatcher-event-loop-6] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 2.0 (TID 5, localhost, executor driver, partition 1, ANY, 7649 bytes)
2021-12-08 10:02:39,305 [Executor task launch worker for task 4] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 2.0 (TID 4)
2021-12-08 10:02:39,305 [Executor task launch worker for task 5] INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 2.0 (TID 5)
2021-12-08 10:02:39,317 [Executor task launch worker for task 5] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 2 non-empty blocks out of 2 blocks
2021-12-08 10:02:39,317 [Executor task launch worker for task 4] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 2 non-empty blocks out of 2 blocks
2021-12-08 10:02:39,319 [Executor task launch worker for task 4] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 5 ms
2021-12-08 10:02:39,319 [Executor task launch worker for task 5] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 5 ms
2021-12-08 10:02:39,346 [Executor task launch worker for task 4] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 2.0 (TID 4). 1053 bytes result sent to driver
2021-12-08 10:02:39,346 [Executor task launch worker for task 5] INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 2.0 (TID 5). 1010 bytes result sent to driver
2021-12-08 10:02:39,346 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 2.0 (TID 4) in 42 ms on localhost (executor driver) (1/2)
2021-12-08 10:02:39,346 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 2.0 (TID 5) in 41 ms on localhost (executor driver) (2/2)
2021-12-08 10:02:39,347 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 2.0, whose tasks have all completed, from pool 
2021-12-08 10:02:39,347 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 2 (zipWithIndex at PaidPromotionAdjustParameter.scala:253) finished in 0.050 s
2021-12-08 10:02:39,347 [main] INFO [org.apache.spark.scheduler.DAGScheduler] - Job 1 finished: zipWithIndex at PaidPromotionAdjustParameter.scala:253, took 0.744711 s
2021-12-08 10:02:39,371 [main] INFO [org.apache.spark.SparkContext] - Starting job: take at PaidPromotionAdjustParameter.scala:259
2021-12-08 10:02:39,372 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 10 (map at PaidPromotionAdjustParameter.scala:256)
2021-12-08 10:02:39,372 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 2 (take at PaidPromotionAdjustParameter.scala:259) with 1 output partitions
2021-12-08 10:02:39,372 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 5 (take at PaidPromotionAdjustParameter.scala:259)
2021-12-08 10:02:39,372 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 4)
2021-12-08 10:02:39,372 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List(ShuffleMapStage 4)
2021-12-08 10:02:39,373 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ShuffleMapStage 4 (MapPartitionsRDD[10] at map at PaidPromotionAdjustParameter.scala:256), which has no missing parents
2021-12-08 10:02:39,375 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_5 stored as values in memory (estimated size 4.0 KB, free 1990.1 MB)
2021-12-08 10:02:39,378 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_5_piece0 stored as bytes in memory (estimated size 2.3 KB, free 1990.1 MB)
2021-12-08 10:02:39,379 [dispatcher-event-loop-11] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_5_piece0 in memory on qb:55588 (size: 2.3 KB, free: 1990.7 MB)
2021-12-08 10:02:39,379 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 5 from broadcast at DAGScheduler.scala:1039
2021-12-08 10:02:39,379 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 3 missing tasks from ShuffleMapStage 4 (MapPartitionsRDD[10] at map at PaidPromotionAdjustParameter.scala:256) (first 15 tasks are for partitions Vector(0, 1, 2))
2021-12-08 10:02:39,379 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 4.0 with 3 tasks
2021-12-08 10:02:39,381 [dispatcher-event-loop-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 4.0 (TID 6, localhost, executor driver, partition 0, ANY, 7748 bytes)
2021-12-08 10:02:39,381 [dispatcher-event-loop-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 4.0 (TID 7, localhost, executor driver, partition 1, ANY, 7748 bytes)
2021-12-08 10:02:39,381 [dispatcher-event-loop-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 2.0 in stage 4.0 (TID 8, localhost, executor driver, partition 2, ANY, 7748 bytes)
2021-12-08 10:02:39,381 [Executor task launch worker for task 6] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 4.0 (TID 6)
2021-12-08 10:02:39,381 [Executor task launch worker for task 7] INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 4.0 (TID 7)
2021-12-08 10:02:39,382 [Executor task launch worker for task 8] INFO [org.apache.spark.executor.Executor] - Running task 2.0 in stage 4.0 (TID 8)
2021-12-08 10:02:39,383 [Executor task launch worker for task 7] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 2 non-empty blocks out of 2 blocks
2021-12-08 10:02:39,384 [Executor task launch worker for task 8] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 2 non-empty blocks out of 2 blocks
2021-12-08 10:02:39,384 [Executor task launch worker for task 7] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 1 ms
2021-12-08 10:02:39,384 [Executor task launch worker for task 8] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 1 ms
2021-12-08 10:02:39,384 [Executor task launch worker for task 6] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 2 non-empty blocks out of 2 blocks
2021-12-08 10:02:39,384 [Executor task launch worker for task 6] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-08 10:02:39,402 [Executor task launch worker for task 8] INFO [org.apache.spark.executor.Executor] - Finished task 2.0 in stage 4.0 (TID 8). 1205 bytes result sent to driver
2021-12-08 10:02:39,403 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 2.0 in stage 4.0 (TID 8) in 21 ms on localhost (executor driver) (1/3)
2021-12-08 10:02:39,403 [Executor task launch worker for task 6] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 4.0 (TID 6). 1162 bytes result sent to driver
2021-12-08 10:02:39,404 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 4.0 (TID 6) in 24 ms on localhost (executor driver) (2/3)
2021-12-08 10:02:39,404 [Executor task launch worker for task 7] INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 4.0 (TID 7). 1205 bytes result sent to driver
2021-12-08 10:02:39,405 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 4.0 (TID 7) in 24 ms on localhost (executor driver) (3/3)
2021-12-08 10:02:39,405 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 4.0, whose tasks have all completed, from pool 
2021-12-08 10:02:39,405 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ShuffleMapStage 4 (map at PaidPromotionAdjustParameter.scala:256) finished in 0.032 s
2021-12-08 10:02:39,405 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - looking for newly runnable stages
2021-12-08 10:02:39,405 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - running: Set()
2021-12-08 10:02:39,405 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - waiting: Set(ResultStage 5)
2021-12-08 10:02:39,405 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - failed: Set()
2021-12-08 10:02:39,406 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 5 (MapPartitionsRDD[12] at map at PaidPromotionAdjustParameter.scala:258), which has no missing parents
2021-12-08 10:02:39,407 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_6 stored as values in memory (estimated size 3.6 KB, free 1990.1 MB)
2021-12-08 10:02:39,410 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_6_piece0 stored as bytes in memory (estimated size 2.1 KB, free 1990.1 MB)
2021-12-08 10:02:39,411 [dispatcher-event-loop-7] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_6_piece0 in memory on qb:55588 (size: 2.1 KB, free: 1990.7 MB)
2021-12-08 10:02:39,411 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 6 from broadcast at DAGScheduler.scala:1039
2021-12-08 10:02:39,412 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 5 (MapPartitionsRDD[12] at map at PaidPromotionAdjustParameter.scala:258) (first 15 tasks are for partitions Vector(0))
2021-12-08 10:02:39,412 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 5.0 with 1 tasks
2021-12-08 10:02:39,413 [dispatcher-event-loop-8] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 5.0 (TID 9, localhost, executor driver, partition 0, PROCESS_LOCAL, 7649 bytes)
2021-12-08 10:02:39,413 [Executor task launch worker for task 9] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 5.0 (TID 9)
2021-12-08 10:02:39,416 [Executor task launch worker for task 9] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 0 non-empty blocks out of 3 blocks
2021-12-08 10:02:39,416 [Executor task launch worker for task 9] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 1 ms
2021-12-08 10:02:39,423 [Executor task launch worker for task 9] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 5.0 (TID 9). 1054 bytes result sent to driver
2021-12-08 10:02:39,423 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 5.0 (TID 9) in 10 ms on localhost (executor driver) (1/1)
2021-12-08 10:02:39,423 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 5.0, whose tasks have all completed, from pool 
2021-12-08 10:02:39,424 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 5 (take at PaidPromotionAdjustParameter.scala:259) finished in 0.018 s
2021-12-08 10:02:39,424 [main] INFO [org.apache.spark.scheduler.DAGScheduler] - Job 2 finished: take at PaidPromotionAdjustParameter.scala:259, took 0.052989 s
2021-12-08 10:02:39,433 [main] INFO [org.apache.spark.SparkContext] - Starting job: take at PaidPromotionAdjustParameter.scala:259
2021-12-08 10:02:39,434 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 3 (take at PaidPromotionAdjustParameter.scala:259) with 2 output partitions
2021-12-08 10:02:39,435 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 8 (take at PaidPromotionAdjustParameter.scala:259)
2021-12-08 10:02:39,435 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 7)
2021-12-08 10:02:39,435 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2021-12-08 10:02:39,435 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 8 (MapPartitionsRDD[12] at map at PaidPromotionAdjustParameter.scala:258), which has no missing parents
2021-12-08 10:02:39,436 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_7 stored as values in memory (estimated size 3.6 KB, free 1990.1 MB)
2021-12-08 10:02:39,440 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_7_piece0 stored as bytes in memory (estimated size 2.1 KB, free 1990.1 MB)
2021-12-08 10:02:39,440 [dispatcher-event-loop-11] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_7_piece0 in memory on qb:55588 (size: 2.1 KB, free: 1990.7 MB)
2021-12-08 10:02:39,440 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 7 from broadcast at DAGScheduler.scala:1039
2021-12-08 10:02:39,441 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from ResultStage 8 (MapPartitionsRDD[12] at map at PaidPromotionAdjustParameter.scala:258) (first 15 tasks are for partitions Vector(1, 2))
2021-12-08 10:02:39,441 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 8.0 with 2 tasks
2021-12-08 10:02:39,441 [dispatcher-event-loop-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 8.0 (TID 10, localhost, executor driver, partition 2, PROCESS_LOCAL, 7649 bytes)
2021-12-08 10:02:39,442 [dispatcher-event-loop-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 8.0 (TID 11, localhost, executor driver, partition 1, ANY, 7649 bytes)
2021-12-08 10:02:39,442 [Executor task launch worker for task 10] INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 8.0 (TID 10)
2021-12-08 10:02:39,442 [Executor task launch worker for task 11] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 8.0 (TID 11)
2021-12-08 10:02:39,443 [Executor task launch worker for task 11] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 3 non-empty blocks out of 3 blocks
2021-12-08 10:02:39,443 [Executor task launch worker for task 10] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 0 non-empty blocks out of 3 blocks
2021-12-08 10:02:39,444 [Executor task launch worker for task 10] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 1 ms
2021-12-08 10:02:39,444 [Executor task launch worker for task 11] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 1 ms
2021-12-08 10:02:39,449 [Executor task launch worker for task 10] INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 8.0 (TID 10). 968 bytes result sent to driver
2021-12-08 10:02:39,450 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 8.0 (TID 10) in 9 ms on localhost (executor driver) (1/2)
2021-12-08 10:02:39,454 [Executor task launch worker for task 11] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 8.0 (TID 11). 1013 bytes result sent to driver
2021-12-08 10:02:39,454 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 8.0 (TID 11) in 12 ms on localhost (executor driver) (2/2)
2021-12-08 10:02:39,454 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 8.0, whose tasks have all completed, from pool 
2021-12-08 10:02:39,454 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 8 (take at PaidPromotionAdjustParameter.scala:259) finished in 0.018 s
2021-12-08 10:02:39,455 [main] INFO [org.apache.spark.scheduler.DAGScheduler] - Job 3 finished: take at PaidPromotionAdjustParameter.scala:259, took 0.021069 s
2021-12-08 10:02:39,455 [main] INFO [PaidPromotionAdjustParameter$] - 训练集产品包总数： 131
2021-12-08 10:02:39,465 [main] INFO [org.apache.hadoop.mapred.FileInputFormat] - Total input paths to process : 10
2021-12-08 10:02:39,467 [main] INFO [org.apache.spark.SparkContext] - Starting job: count at PaidPromotionAdjustParameter.scala:269
2021-12-08 10:02:39,468 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 4 (count at PaidPromotionAdjustParameter.scala:269) with 10 output partitions
2021-12-08 10:02:39,468 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 9 (count at PaidPromotionAdjustParameter.scala:269)
2021-12-08 10:02:39,468 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List()
2021-12-08 10:02:39,468 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2021-12-08 10:02:39,468 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 9 (MapPartitionsRDD[13] at map at PaidPromotionAdjustParameter.scala:265), which has no missing parents
2021-12-08 10:02:39,470 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_8 stored as values in memory (estimated size 3.3 KB, free 1990.1 MB)
2021-12-08 10:02:39,472 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_8_piece0 stored as bytes in memory (estimated size 1994.0 B, free 1990.1 MB)
2021-12-08 10:02:39,472 [dispatcher-event-loop-4] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_8_piece0 in memory on qb:55588 (size: 1994.0 B, free: 1990.7 MB)
2021-12-08 10:02:39,473 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 8 from broadcast at DAGScheduler.scala:1039
2021-12-08 10:02:39,473 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 10 missing tasks from ResultStage 9 (MapPartitionsRDD[13] at map at PaidPromotionAdjustParameter.scala:265) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
2021-12-08 10:02:39,473 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 9.0 with 10 tasks
2021-12-08 10:02:39,474 [dispatcher-event-loop-6] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 9.0 (TID 12, localhost, executor driver, partition 0, ANY, 7917 bytes)
2021-12-08 10:02:39,474 [dispatcher-event-loop-6] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 9.0 (TID 13, localhost, executor driver, partition 1, ANY, 7917 bytes)
2021-12-08 10:02:39,474 [dispatcher-event-loop-6] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 2.0 in stage 9.0 (TID 14, localhost, executor driver, partition 2, ANY, 7917 bytes)
2021-12-08 10:02:39,475 [dispatcher-event-loop-6] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 3.0 in stage 9.0 (TID 15, localhost, executor driver, partition 3, ANY, 7917 bytes)
2021-12-08 10:02:39,475 [dispatcher-event-loop-6] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 4.0 in stage 9.0 (TID 16, localhost, executor driver, partition 4, ANY, 7917 bytes)
2021-12-08 10:02:39,475 [dispatcher-event-loop-6] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 5.0 in stage 9.0 (TID 17, localhost, executor driver, partition 5, ANY, 7917 bytes)
2021-12-08 10:02:39,475 [dispatcher-event-loop-6] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 6.0 in stage 9.0 (TID 18, localhost, executor driver, partition 6, ANY, 7917 bytes)
2021-12-08 10:02:39,475 [dispatcher-event-loop-6] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 7.0 in stage 9.0 (TID 19, localhost, executor driver, partition 7, ANY, 7917 bytes)
2021-12-08 10:02:39,475 [dispatcher-event-loop-6] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 8.0 in stage 9.0 (TID 20, localhost, executor driver, partition 8, ANY, 7917 bytes)
2021-12-08 10:02:39,475 [dispatcher-event-loop-6] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 9.0 in stage 9.0 (TID 21, localhost, executor driver, partition 9, ANY, 7917 bytes)
2021-12-08 10:02:39,476 [Executor task launch worker for task 12] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 9.0 (TID 12)
2021-12-08 10:02:39,476 [Executor task launch worker for task 13] INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 9.0 (TID 13)
2021-12-08 10:02:39,476 [Executor task launch worker for task 14] INFO [org.apache.spark.executor.Executor] - Running task 2.0 in stage 9.0 (TID 14)
2021-12-08 10:02:39,476 [Executor task launch worker for task 15] INFO [org.apache.spark.executor.Executor] - Running task 3.0 in stage 9.0 (TID 15)
2021-12-08 10:02:39,476 [Executor task launch worker for task 17] INFO [org.apache.spark.executor.Executor] - Running task 5.0 in stage 9.0 (TID 17)
2021-12-08 10:02:39,476 [Executor task launch worker for task 16] INFO [org.apache.spark.executor.Executor] - Running task 4.0 in stage 9.0 (TID 16)
2021-12-08 10:02:39,477 [Executor task launch worker for task 18] INFO [org.apache.spark.executor.Executor] - Running task 6.0 in stage 9.0 (TID 18)
2021-12-08 10:02:39,477 [Executor task launch worker for task 19] INFO [org.apache.spark.executor.Executor] - Running task 7.0 in stage 9.0 (TID 19)
2021-12-08 10:02:39,478 [Executor task launch worker for task 20] INFO [org.apache.spark.executor.Executor] - Running task 8.0 in stage 9.0 (TID 20)
2021-12-08 10:02:39,480 [Executor task launch worker for task 13] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/handle_data/device_video_data/part-00001:0+38414410
2021-12-08 10:02:39,480 [Executor task launch worker for task 18] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/handle_data/device_video_data/part-00006:0+29631891
2021-12-08 10:02:39,480 [Executor task launch worker for task 16] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/handle_data/device_video_data/part-00004:0+14256802
2021-12-08 10:02:39,480 [Executor task launch worker for task 21] INFO [org.apache.spark.executor.Executor] - Running task 9.0 in stage 9.0 (TID 21)
2021-12-08 10:02:39,480 [Executor task launch worker for task 12] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/handle_data/device_video_data/part-00000:0+29528642
2021-12-08 10:02:39,481 [Executor task launch worker for task 20] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/handle_data/device_video_data/part-00008:0+29423447
2021-12-08 10:02:39,481 [Executor task launch worker for task 17] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/handle_data/device_video_data/part-00005:0+14798635
2021-12-08 10:02:39,481 [Executor task launch worker for task 19] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/handle_data/device_video_data/part-00007:0+29599448
2021-12-08 10:02:39,481 [Executor task launch worker for task 15] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/handle_data/device_video_data/part-00003:0+29761082
2021-12-08 10:02:39,481 [Executor task launch worker for task 14] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/handle_data/device_video_data/part-00002:0+43831145
2021-12-08 10:02:39,482 [Executor task launch worker for task 21] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/handle_data/device_video_data/part-00009:0+29225612
2021-12-08 10:02:39,705 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 25
2021-12-08 10:02:39,705 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 130
2021-12-08 10:02:39,706 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 107
2021-12-08 10:02:39,706 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 145
2021-12-08 10:02:39,707 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 111
2021-12-08 10:02:39,707 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 44
2021-12-08 10:02:39,707 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 35
2021-12-08 10:02:39,707 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 68
2021-12-08 10:02:39,709 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned shuffle 1
2021-12-08 10:02:39,710 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 40
2021-12-08 10:02:39,710 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 38
2021-12-08 10:02:39,710 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 83
2021-12-08 10:02:39,710 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 96
2021-12-08 10:02:39,710 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 104
2021-12-08 10:02:39,710 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 91
2021-12-08 10:02:39,710 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 101
2021-12-08 10:02:39,710 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 126
2021-12-08 10:02:39,710 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 90
2021-12-08 10:02:39,710 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 45
2021-12-08 10:02:39,710 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 122
2021-12-08 10:02:39,710 [dispatcher-event-loop-9] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_6_piece0 on qb:55588 in memory (size: 2.1 KB, free: 1990.7 MB)
2021-12-08 10:02:39,711 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 46
2021-12-08 10:02:39,711 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 97
2021-12-08 10:02:39,711 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 75
2021-12-08 10:02:39,711 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 121
2021-12-08 10:02:39,711 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 119
2021-12-08 10:02:39,712 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 106
2021-12-08 10:02:39,712 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 123
2021-12-08 10:02:39,712 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 80
2021-12-08 10:02:39,712 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 133
2021-12-08 10:02:39,712 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 79
2021-12-08 10:02:39,712 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 31
2021-12-08 10:02:39,712 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 138
2021-12-08 10:02:39,712 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 114
2021-12-08 10:02:39,712 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 76
2021-12-08 10:02:39,712 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 89
2021-12-08 10:02:39,712 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 87
2021-12-08 10:02:39,712 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 62
2021-12-08 10:02:39,712 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 41
2021-12-08 10:02:39,712 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 117
2021-12-08 10:02:39,712 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 26
2021-12-08 10:02:39,712 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 88
2021-12-08 10:02:39,712 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 136
2021-12-08 10:02:39,712 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 100
2021-12-08 10:02:39,712 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 70
2021-12-08 10:02:39,712 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 139
2021-12-08 10:02:39,712 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 65
2021-12-08 10:02:39,712 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 98
2021-12-08 10:02:39,712 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 93
2021-12-08 10:02:39,712 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 82
2021-12-08 10:02:39,712 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 30
2021-12-08 10:02:39,712 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 147
2021-12-08 10:02:39,712 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 86
2021-12-08 10:02:39,712 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 143
2021-12-08 10:02:39,712 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 36
2021-12-08 10:02:39,712 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 69
2021-12-08 10:02:39,712 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 32
2021-12-08 10:02:39,712 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 115
2021-12-08 10:02:39,712 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 102
2021-12-08 10:02:39,712 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 37
2021-12-08 10:02:39,712 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 148
2021-12-08 10:02:39,712 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 134
2021-12-08 10:02:39,712 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 108
2021-12-08 10:02:39,713 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 105
2021-12-08 10:02:39,713 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 55
2021-12-08 10:02:39,713 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 47
2021-12-08 10:02:39,713 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 132
2021-12-08 10:02:39,713 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 48
2021-12-08 10:02:39,713 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 54
2021-12-08 10:02:39,713 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 84
2021-12-08 10:02:39,713 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 110
2021-12-08 10:02:39,713 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 118
2021-12-08 10:02:39,713 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 128
2021-12-08 10:02:39,713 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 59
2021-12-08 10:02:39,713 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 51
2021-12-08 10:02:39,713 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 64
2021-12-08 10:02:39,713 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 103
2021-12-08 10:02:39,713 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 109
2021-12-08 10:02:39,713 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 52
2021-12-08 10:02:39,713 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 29
2021-12-08 10:02:39,713 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 116
2021-12-08 10:02:39,713 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 78
2021-12-08 10:02:39,713 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 85
2021-12-08 10:02:39,713 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 50
2021-12-08 10:02:39,713 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 81
2021-12-08 10:02:39,713 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 127
2021-12-08 10:02:39,713 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 63
2021-12-08 10:02:39,713 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 95
2021-12-08 10:02:39,713 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 49
2021-12-08 10:02:39,713 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 77
2021-12-08 10:02:39,714 [dispatcher-event-loop-0] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_4_piece0 on qb:55588 in memory (size: 2.2 KB, free: 1990.7 MB)
2021-12-08 10:02:39,715 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 92
2021-12-08 10:02:39,715 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 137
2021-12-08 10:02:39,715 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 144
2021-12-08 10:02:39,715 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 131
2021-12-08 10:02:39,715 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 61
2021-12-08 10:02:39,715 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 43
2021-12-08 10:02:39,715 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 135
2021-12-08 10:02:39,715 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 58
2021-12-08 10:02:39,715 [dispatcher-event-loop-3] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_3_piece0 on qb:55588 in memory (size: 2.8 KB, free: 1990.7 MB)
2021-12-08 10:02:39,716 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 120
2021-12-08 10:02:39,716 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 27
2021-12-08 10:02:39,716 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 74
2021-12-08 10:02:39,716 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 94
2021-12-08 10:02:39,716 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 113
2021-12-08 10:02:39,716 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 67
2021-12-08 10:02:39,716 [dispatcher-event-loop-7] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_7_piece0 on qb:55588 in memory (size: 2.1 KB, free: 1990.7 MB)
2021-12-08 10:02:39,717 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 71
2021-12-08 10:02:39,717 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 99
2021-12-08 10:02:39,717 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 28
2021-12-08 10:02:39,717 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 66
2021-12-08 10:02:39,717 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 72
2021-12-08 10:02:39,717 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 73
2021-12-08 10:02:39,717 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 140
2021-12-08 10:02:39,717 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 141
2021-12-08 10:02:39,717 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 39
2021-12-08 10:02:39,717 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 56
2021-12-08 10:02:39,717 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 125
2021-12-08 10:02:39,717 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 112
2021-12-08 10:02:39,717 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 60
2021-12-08 10:02:39,717 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 146
2021-12-08 10:02:39,717 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 129
2021-12-08 10:02:39,718 [dispatcher-event-loop-9] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_5_piece0 on qb:55588 in memory (size: 2.3 KB, free: 1990.7 MB)
2021-12-08 10:02:39,718 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 53
2021-12-08 10:02:39,718 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 142
2021-12-08 10:02:39,718 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 124
2021-12-08 10:02:39,718 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 42
2021-12-08 10:02:39,718 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 34
2021-12-08 10:02:39,718 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 57
2021-12-08 10:02:39,718 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 33
2021-12-08 10:02:39,718 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 149
2021-12-08 10:02:53,954 [Executor task launch worker for task 16] INFO [org.apache.spark.executor.Executor] - Finished task 4.0 in stage 9.0 (TID 16). 754 bytes result sent to driver
2021-12-08 10:02:53,955 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 4.0 in stage 9.0 (TID 16) in 14480 ms on localhost (executor driver) (1/10)
2021-12-08 10:02:57,617 [Executor task launch worker for task 17] INFO [org.apache.spark.executor.Executor] - Finished task 5.0 in stage 9.0 (TID 17). 754 bytes result sent to driver
2021-12-08 10:02:57,617 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 5.0 in stage 9.0 (TID 17) in 18142 ms on localhost (executor driver) (2/10)
2021-12-08 10:02:59,550 [Executor task launch worker for task 15] INFO [org.apache.spark.executor.Executor] - Finished task 3.0 in stage 9.0 (TID 15). 754 bytes result sent to driver
2021-12-08 10:02:59,551 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 3.0 in stage 9.0 (TID 15) in 20077 ms on localhost (executor driver) (3/10)
2021-12-08 10:03:04,647 [Executor task launch worker for task 13] INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 9.0 (TID 13). 754 bytes result sent to driver
2021-12-08 10:03:04,648 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 9.0 (TID 13) in 25174 ms on localhost (executor driver) (4/10)
2021-12-08 10:03:06,047 [Executor task launch worker for task 12] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 9.0 (TID 12). 754 bytes result sent to driver
2021-12-08 10:03:06,047 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 9.0 (TID 12) in 26573 ms on localhost (executor driver) (5/10)
2021-12-08 10:03:07,629 [Executor task launch worker for task 21] INFO [org.apache.spark.executor.Executor] - Finished task 9.0 in stage 9.0 (TID 21). 754 bytes result sent to driver
2021-12-08 10:03:07,629 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 9.0 in stage 9.0 (TID 21) in 28154 ms on localhost (executor driver) (6/10)
2021-12-08 10:03:08,769 [Executor task launch worker for task 19] INFO [org.apache.spark.executor.Executor] - Finished task 7.0 in stage 9.0 (TID 19). 754 bytes result sent to driver
2021-12-08 10:03:08,769 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 7.0 in stage 9.0 (TID 19) in 29294 ms on localhost (executor driver) (7/10)
2021-12-08 10:03:09,258 [Executor task launch worker for task 18] INFO [org.apache.spark.executor.Executor] - Finished task 6.0 in stage 9.0 (TID 18). 754 bytes result sent to driver
2021-12-08 10:03:09,258 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 6.0 in stage 9.0 (TID 18) in 29783 ms on localhost (executor driver) (8/10)
2021-12-08 10:03:09,369 [Executor task launch worker for task 14] INFO [org.apache.spark.executor.Executor] - Finished task 2.0 in stage 9.0 (TID 14). 754 bytes result sent to driver
2021-12-08 10:03:09,369 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 2.0 in stage 9.0 (TID 14) in 29895 ms on localhost (executor driver) (9/10)
2021-12-08 10:03:09,948 [Executor task launch worker for task 20] INFO [org.apache.spark.executor.Executor] - Finished task 8.0 in stage 9.0 (TID 20). 754 bytes result sent to driver
2021-12-08 10:03:09,948 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 8.0 in stage 9.0 (TID 20) in 30473 ms on localhost (executor driver) (10/10)
2021-12-08 10:03:09,948 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 9.0, whose tasks have all completed, from pool 
2021-12-08 10:03:09,949 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 9 (count at PaidPromotionAdjustParameter.scala:269) finished in 30.480 s
2021-12-08 10:03:09,949 [main] INFO [org.apache.spark.scheduler.DAGScheduler] - Job 4 finished: count at PaidPromotionAdjustParameter.scala:269, took 30.481674 s
2021-12-08 10:03:09,949 [main] INFO [PaidPromotionAdjustParameter$] - 收视行为总数：6662463
2021-12-08 10:03:09,958 [main] INFO [org.apache.spark.SparkContext] - Starting job: zipWithIndex at PaidPromotionAdjustParameter.scala:274
2021-12-08 10:03:09,958 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 15 (distinct at PaidPromotionAdjustParameter.scala:273)
2021-12-08 10:03:09,959 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 5 (zipWithIndex at PaidPromotionAdjustParameter.scala:274) with 11 output partitions
2021-12-08 10:03:09,959 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 11 (zipWithIndex at PaidPromotionAdjustParameter.scala:274)
2021-12-08 10:03:09,959 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 10)
2021-12-08 10:03:09,959 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List(ShuffleMapStage 10)
2021-12-08 10:03:09,959 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ShuffleMapStage 10 (MapPartitionsRDD[15] at distinct at PaidPromotionAdjustParameter.scala:273), which has no missing parents
2021-12-08 10:03:09,960 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_9 stored as values in memory (estimated size 4.9 KB, free 1990.1 MB)
2021-12-08 10:03:09,962 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_9_piece0 stored as bytes in memory (estimated size 2.8 KB, free 1990.1 MB)
2021-12-08 10:03:09,963 [dispatcher-event-loop-0] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_9_piece0 in memory on qb:55588 (size: 2.8 KB, free: 1990.7 MB)
2021-12-08 10:03:09,963 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 9 from broadcast at DAGScheduler.scala:1039
2021-12-08 10:03:09,963 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 10 missing tasks from ShuffleMapStage 10 (MapPartitionsRDD[15] at distinct at PaidPromotionAdjustParameter.scala:273) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
2021-12-08 10:03:09,963 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 10.0 with 10 tasks
2021-12-08 10:03:09,964 [dispatcher-event-loop-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 10.0 (TID 22, localhost, executor driver, partition 0, ANY, 7906 bytes)
2021-12-08 10:03:09,964 [dispatcher-event-loop-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 10.0 (TID 23, localhost, executor driver, partition 1, ANY, 7906 bytes)
2021-12-08 10:03:09,964 [dispatcher-event-loop-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 2.0 in stage 10.0 (TID 24, localhost, executor driver, partition 2, ANY, 7906 bytes)
2021-12-08 10:03:09,964 [dispatcher-event-loop-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 3.0 in stage 10.0 (TID 25, localhost, executor driver, partition 3, ANY, 7906 bytes)
2021-12-08 10:03:09,964 [dispatcher-event-loop-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 4.0 in stage 10.0 (TID 26, localhost, executor driver, partition 4, ANY, 7906 bytes)
2021-12-08 10:03:09,965 [dispatcher-event-loop-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 5.0 in stage 10.0 (TID 27, localhost, executor driver, partition 5, ANY, 7906 bytes)
2021-12-08 10:03:09,965 [dispatcher-event-loop-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 6.0 in stage 10.0 (TID 28, localhost, executor driver, partition 6, ANY, 7906 bytes)
2021-12-08 10:03:09,965 [dispatcher-event-loop-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 7.0 in stage 10.0 (TID 29, localhost, executor driver, partition 7, ANY, 7906 bytes)
2021-12-08 10:03:09,965 [dispatcher-event-loop-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 8.0 in stage 10.0 (TID 30, localhost, executor driver, partition 8, ANY, 7906 bytes)
2021-12-08 10:03:09,965 [dispatcher-event-loop-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 9.0 in stage 10.0 (TID 31, localhost, executor driver, partition 9, ANY, 7906 bytes)
2021-12-08 10:03:09,965 [Executor task launch worker for task 22] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 10.0 (TID 22)
2021-12-08 10:03:09,965 [Executor task launch worker for task 24] INFO [org.apache.spark.executor.Executor] - Running task 2.0 in stage 10.0 (TID 24)
2021-12-08 10:03:09,965 [Executor task launch worker for task 31] INFO [org.apache.spark.executor.Executor] - Running task 9.0 in stage 10.0 (TID 31)
2021-12-08 10:03:09,965 [Executor task launch worker for task 30] INFO [org.apache.spark.executor.Executor] - Running task 8.0 in stage 10.0 (TID 30)
2021-12-08 10:03:09,965 [Executor task launch worker for task 23] INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 10.0 (TID 23)
2021-12-08 10:03:09,965 [Executor task launch worker for task 27] INFO [org.apache.spark.executor.Executor] - Running task 5.0 in stage 10.0 (TID 27)
2021-12-08 10:03:09,965 [Executor task launch worker for task 28] INFO [org.apache.spark.executor.Executor] - Running task 6.0 in stage 10.0 (TID 28)
2021-12-08 10:03:09,965 [Executor task launch worker for task 25] INFO [org.apache.spark.executor.Executor] - Running task 3.0 in stage 10.0 (TID 25)
2021-12-08 10:03:09,965 [Executor task launch worker for task 26] INFO [org.apache.spark.executor.Executor] - Running task 4.0 in stage 10.0 (TID 26)
2021-12-08 10:03:09,965 [Executor task launch worker for task 29] INFO [org.apache.spark.executor.Executor] - Running task 7.0 in stage 10.0 (TID 29)
2021-12-08 10:03:09,967 [Executor task launch worker for task 22] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/handle_data/device_video_data/part-00000:0+29528642
2021-12-08 10:03:09,967 [Executor task launch worker for task 29] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/handle_data/device_video_data/part-00007:0+29599448
2021-12-08 10:03:09,967 [Executor task launch worker for task 31] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/handle_data/device_video_data/part-00009:0+29225612
2021-12-08 10:03:09,967 [Executor task launch worker for task 23] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/handle_data/device_video_data/part-00001:0+38414410
2021-12-08 10:03:09,967 [Executor task launch worker for task 26] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/handle_data/device_video_data/part-00004:0+14256802
2021-12-08 10:03:09,968 [Executor task launch worker for task 25] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/handle_data/device_video_data/part-00003:0+29761082
2021-12-08 10:03:09,968 [Executor task launch worker for task 28] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/handle_data/device_video_data/part-00006:0+29631891
2021-12-08 10:03:09,968 [Executor task launch worker for task 24] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/handle_data/device_video_data/part-00002:0+43831145
2021-12-08 10:03:09,969 [Executor task launch worker for task 30] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/handle_data/device_video_data/part-00008:0+29423447
2021-12-08 10:03:09,969 [Executor task launch worker for task 27] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/handle_data/device_video_data/part-00005:0+14798635
2021-12-08 10:03:20,673 [Executor task launch worker for task 27] INFO [org.apache.spark.executor.Executor] - Finished task 5.0 in stage 10.0 (TID 27). 1042 bytes result sent to driver
2021-12-08 10:03:20,673 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 5.0 in stage 10.0 (TID 27) in 10709 ms on localhost (executor driver) (1/10)
2021-12-08 10:03:23,626 [Executor task launch worker for task 26] INFO [org.apache.spark.executor.Executor] - Finished task 4.0 in stage 10.0 (TID 26). 1042 bytes result sent to driver
2021-12-08 10:03:23,627 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 4.0 in stage 10.0 (TID 26) in 13663 ms on localhost (executor driver) (2/10)
2021-12-08 10:03:33,778 [Executor task launch worker for task 25] INFO [org.apache.spark.executor.Executor] - Finished task 3.0 in stage 10.0 (TID 25). 1042 bytes result sent to driver
2021-12-08 10:03:33,779 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 3.0 in stage 10.0 (TID 25) in 23815 ms on localhost (executor driver) (3/10)
2021-12-08 10:03:35,209 [Executor task launch worker for task 30] INFO [org.apache.spark.executor.Executor] - Finished task 8.0 in stage 10.0 (TID 30). 1042 bytes result sent to driver
2021-12-08 10:03:35,210 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 8.0 in stage 10.0 (TID 30) in 25245 ms on localhost (executor driver) (4/10)
2021-12-08 10:03:37,146 [Executor task launch worker for task 28] INFO [org.apache.spark.executor.Executor] - Finished task 6.0 in stage 10.0 (TID 28). 1042 bytes result sent to driver
2021-12-08 10:03:37,146 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 6.0 in stage 10.0 (TID 28) in 27181 ms on localhost (executor driver) (5/10)
2021-12-08 10:03:37,276 [Executor task launch worker for task 31] INFO [org.apache.spark.executor.Executor] - Finished task 9.0 in stage 10.0 (TID 31). 1042 bytes result sent to driver
2021-12-08 10:03:37,277 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 9.0 in stage 10.0 (TID 31) in 27312 ms on localhost (executor driver) (6/10)
2021-12-08 10:03:37,941 [Executor task launch worker for task 29] INFO [org.apache.spark.executor.Executor] - Finished task 7.0 in stage 10.0 (TID 29). 1042 bytes result sent to driver
2021-12-08 10:03:37,941 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 7.0 in stage 10.0 (TID 29) in 27976 ms on localhost (executor driver) (7/10)
2021-12-08 10:03:38,660 [Executor task launch worker for task 22] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 10.0 (TID 22). 1042 bytes result sent to driver
2021-12-08 10:03:38,661 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 10.0 (TID 22) in 28697 ms on localhost (executor driver) (8/10)
2021-12-08 10:03:40,621 [Executor task launch worker for task 23] INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 10.0 (TID 23). 1042 bytes result sent to driver
2021-12-08 10:03:40,621 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 10.0 (TID 23) in 30657 ms on localhost (executor driver) (9/10)
2021-12-08 10:03:41,194 [Executor task launch worker for task 24] INFO [org.apache.spark.executor.Executor] - Finished task 2.0 in stage 10.0 (TID 24). 1042 bytes result sent to driver
2021-12-08 10:03:41,194 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 2.0 in stage 10.0 (TID 24) in 31230 ms on localhost (executor driver) (10/10)
2021-12-08 10:03:41,194 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 10.0, whose tasks have all completed, from pool 
2021-12-08 10:03:41,194 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ShuffleMapStage 10 (distinct at PaidPromotionAdjustParameter.scala:273) finished in 31.234 s
2021-12-08 10:03:41,195 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - looking for newly runnable stages
2021-12-08 10:03:41,195 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - running: Set()
2021-12-08 10:03:41,195 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - waiting: Set(ResultStage 11)
2021-12-08 10:03:41,195 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - failed: Set()
2021-12-08 10:03:41,195 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 11 (MapPartitionsRDD[17] at distinct at PaidPromotionAdjustParameter.scala:273), which has no missing parents
2021-12-08 10:03:41,196 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_10 stored as values in memory (estimated size 3.7 KB, free 1990.1 MB)
2021-12-08 10:03:41,198 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_10_piece0 stored as bytes in memory (estimated size 2.2 KB, free 1990.1 MB)
2021-12-08 10:03:41,199 [dispatcher-event-loop-4] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_10_piece0 in memory on qb:55588 (size: 2.2 KB, free: 1990.7 MB)
2021-12-08 10:03:41,199 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 10 from broadcast at DAGScheduler.scala:1039
2021-12-08 10:03:41,199 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 11 missing tasks from ResultStage 11 (MapPartitionsRDD[17] at distinct at PaidPromotionAdjustParameter.scala:273) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10))
2021-12-08 10:03:41,199 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 11.0 with 11 tasks
2021-12-08 10:03:41,200 [dispatcher-event-loop-7] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 11.0 (TID 32, localhost, executor driver, partition 0, ANY, 7649 bytes)
2021-12-08 10:03:41,200 [dispatcher-event-loop-7] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 11.0 (TID 33, localhost, executor driver, partition 1, ANY, 7649 bytes)
2021-12-08 10:03:41,200 [dispatcher-event-loop-7] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 2.0 in stage 11.0 (TID 34, localhost, executor driver, partition 2, ANY, 7649 bytes)
2021-12-08 10:03:41,200 [dispatcher-event-loop-7] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 3.0 in stage 11.0 (TID 35, localhost, executor driver, partition 3, ANY, 7649 bytes)
2021-12-08 10:03:41,200 [dispatcher-event-loop-7] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 4.0 in stage 11.0 (TID 36, localhost, executor driver, partition 4, ANY, 7649 bytes)
2021-12-08 10:03:41,200 [dispatcher-event-loop-7] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 5.0 in stage 11.0 (TID 37, localhost, executor driver, partition 5, ANY, 7649 bytes)
2021-12-08 10:03:41,200 [dispatcher-event-loop-7] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 6.0 in stage 11.0 (TID 38, localhost, executor driver, partition 6, ANY, 7649 bytes)
2021-12-08 10:03:41,200 [dispatcher-event-loop-7] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 7.0 in stage 11.0 (TID 39, localhost, executor driver, partition 7, ANY, 7649 bytes)
2021-12-08 10:03:41,200 [dispatcher-event-loop-7] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 8.0 in stage 11.0 (TID 40, localhost, executor driver, partition 8, ANY, 7649 bytes)
2021-12-08 10:03:41,200 [dispatcher-event-loop-7] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 9.0 in stage 11.0 (TID 41, localhost, executor driver, partition 9, ANY, 7649 bytes)
2021-12-08 10:03:41,200 [dispatcher-event-loop-7] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 10.0 in stage 11.0 (TID 42, localhost, executor driver, partition 10, ANY, 7649 bytes)
2021-12-08 10:03:41,200 [Executor task launch worker for task 32] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 11.0 (TID 32)
2021-12-08 10:03:41,200 [Executor task launch worker for task 36] INFO [org.apache.spark.executor.Executor] - Running task 4.0 in stage 11.0 (TID 36)
2021-12-08 10:03:41,201 [Executor task launch worker for task 39] INFO [org.apache.spark.executor.Executor] - Running task 7.0 in stage 11.0 (TID 39)
2021-12-08 10:03:41,200 [Executor task launch worker for task 33] INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 11.0 (TID 33)
2021-12-08 10:03:41,200 [Executor task launch worker for task 38] INFO [org.apache.spark.executor.Executor] - Running task 6.0 in stage 11.0 (TID 38)
2021-12-08 10:03:41,200 [Executor task launch worker for task 34] INFO [org.apache.spark.executor.Executor] - Running task 2.0 in stage 11.0 (TID 34)
2021-12-08 10:03:41,200 [Executor task launch worker for task 37] INFO [org.apache.spark.executor.Executor] - Running task 5.0 in stage 11.0 (TID 37)
2021-12-08 10:03:41,200 [Executor task launch worker for task 35] INFO [org.apache.spark.executor.Executor] - Running task 3.0 in stage 11.0 (TID 35)
2021-12-08 10:03:41,201 [Executor task launch worker for task 42] INFO [org.apache.spark.executor.Executor] - Running task 10.0 in stage 11.0 (TID 42)
2021-12-08 10:03:41,201 [Executor task launch worker for task 41] INFO [org.apache.spark.executor.Executor] - Running task 9.0 in stage 11.0 (TID 41)
2021-12-08 10:03:41,201 [Executor task launch worker for task 40] INFO [org.apache.spark.executor.Executor] - Running task 8.0 in stage 11.0 (TID 40)
2021-12-08 10:03:41,203 [Executor task launch worker for task 32] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 10 non-empty blocks out of 10 blocks
2021-12-08 10:03:41,203 [Executor task launch worker for task 32] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 1 ms
2021-12-08 10:03:41,203 [Executor task launch worker for task 42] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 10 non-empty blocks out of 10 blocks
2021-12-08 10:03:41,203 [Executor task launch worker for task 42] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-08 10:03:41,203 [Executor task launch worker for task 35] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 10 non-empty blocks out of 10 blocks
2021-12-08 10:03:41,203 [Executor task launch worker for task 35] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-08 10:03:41,203 [Executor task launch worker for task 37] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 10 non-empty blocks out of 10 blocks
2021-12-08 10:03:41,203 [Executor task launch worker for task 37] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-08 10:03:41,203 [Executor task launch worker for task 41] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 10 non-empty blocks out of 10 blocks
2021-12-08 10:03:41,203 [Executor task launch worker for task 41] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-08 10:03:41,203 [Executor task launch worker for task 38] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 10 non-empty blocks out of 10 blocks
2021-12-08 10:03:41,203 [Executor task launch worker for task 38] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-08 10:03:41,203 [Executor task launch worker for task 34] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 10 non-empty blocks out of 10 blocks
2021-12-08 10:03:41,203 [Executor task launch worker for task 34] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-08 10:03:41,203 [Executor task launch worker for task 40] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 10 non-empty blocks out of 10 blocks
2021-12-08 10:03:41,203 [Executor task launch worker for task 40] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-08 10:03:41,203 [Executor task launch worker for task 33] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 10 non-empty blocks out of 10 blocks
2021-12-08 10:03:41,203 [Executor task launch worker for task 33] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-08 10:03:41,203 [Executor task launch worker for task 36] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 10 non-empty blocks out of 10 blocks
2021-12-08 10:03:41,204 [Executor task launch worker for task 36] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 1 ms
2021-12-08 10:03:41,204 [Executor task launch worker for task 39] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 10 non-empty blocks out of 10 blocks
2021-12-08 10:03:41,204 [Executor task launch worker for task 39] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 1 ms
2021-12-08 10:03:41,404 [Executor task launch worker for task 32] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 11.0 (TID 32). 1097 bytes result sent to driver
2021-12-08 10:03:41,404 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 11.0 (TID 32) in 205 ms on localhost (executor driver) (1/11)
2021-12-08 10:03:41,423 [Executor task launch worker for task 33] INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 11.0 (TID 33). 1097 bytes result sent to driver
2021-12-08 10:03:41,424 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 11.0 (TID 33) in 224 ms on localhost (executor driver) (2/11)
2021-12-08 10:03:41,424 [Executor task launch worker for task 41] INFO [org.apache.spark.executor.Executor] - Finished task 9.0 in stage 11.0 (TID 41). 1097 bytes result sent to driver
2021-12-08 10:03:41,424 [Executor task launch worker for task 40] INFO [org.apache.spark.executor.Executor] - Finished task 8.0 in stage 11.0 (TID 40). 1097 bytes result sent to driver
2021-12-08 10:03:41,425 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 9.0 in stage 11.0 (TID 41) in 225 ms on localhost (executor driver) (3/11)
2021-12-08 10:03:41,425 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 8.0 in stage 11.0 (TID 40) in 225 ms on localhost (executor driver) (4/11)
2021-12-08 10:03:41,425 [Executor task launch worker for task 34] INFO [org.apache.spark.executor.Executor] - Finished task 2.0 in stage 11.0 (TID 34). 1097 bytes result sent to driver
2021-12-08 10:03:41,426 [Executor task launch worker for task 35] INFO [org.apache.spark.executor.Executor] - Finished task 3.0 in stage 11.0 (TID 35). 1097 bytes result sent to driver
2021-12-08 10:03:41,426 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 2.0 in stage 11.0 (TID 34) in 226 ms on localhost (executor driver) (5/11)
2021-12-08 10:03:41,426 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 3.0 in stage 11.0 (TID 35) in 226 ms on localhost (executor driver) (6/11)
2021-12-08 10:03:41,426 [Executor task launch worker for task 37] INFO [org.apache.spark.executor.Executor] - Finished task 5.0 in stage 11.0 (TID 37). 1097 bytes result sent to driver
2021-12-08 10:03:41,426 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 5.0 in stage 11.0 (TID 37) in 226 ms on localhost (executor driver) (7/11)
2021-12-08 10:03:41,427 [Executor task launch worker for task 36] INFO [org.apache.spark.executor.Executor] - Finished task 4.0 in stage 11.0 (TID 36). 1097 bytes result sent to driver
2021-12-08 10:03:41,427 [Executor task launch worker for task 39] INFO [org.apache.spark.executor.Executor] - Finished task 7.0 in stage 11.0 (TID 39). 1097 bytes result sent to driver
2021-12-08 10:03:41,427 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 4.0 in stage 11.0 (TID 36) in 227 ms on localhost (executor driver) (8/11)
2021-12-08 10:03:41,427 [Executor task launch worker for task 42] INFO [org.apache.spark.executor.Executor] - Finished task 10.0 in stage 11.0 (TID 42). 1054 bytes result sent to driver
2021-12-08 10:03:41,427 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 7.0 in stage 11.0 (TID 39) in 227 ms on localhost (executor driver) (9/11)
2021-12-08 10:03:41,428 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 10.0 in stage 11.0 (TID 42) in 228 ms on localhost (executor driver) (10/11)
2021-12-08 10:03:41,430 [Executor task launch worker for task 38] INFO [org.apache.spark.executor.Executor] - Finished task 6.0 in stage 11.0 (TID 38). 1097 bytes result sent to driver
2021-12-08 10:03:41,430 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 6.0 in stage 11.0 (TID 38) in 230 ms on localhost (executor driver) (11/11)
2021-12-08 10:03:41,430 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 11.0, whose tasks have all completed, from pool 
2021-12-08 10:03:41,430 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 11 (zipWithIndex at PaidPromotionAdjustParameter.scala:274) finished in 0.234 s
2021-12-08 10:03:41,431 [main] INFO [org.apache.spark.scheduler.DAGScheduler] - Job 5 finished: zipWithIndex at PaidPromotionAdjustParameter.scala:274, took 31.472789 s
2021-12-08 10:03:41,452 [main] INFO [org.apache.spark.SparkContext] - Starting job: count at PaidPromotionAdjustParameter.scala:283
2021-12-08 10:03:41,456 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 23 (distinct at PaidPromotionAdjustParameter.scala:280)
2021-12-08 10:03:41,456 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 6 (count at PaidPromotionAdjustParameter.scala:283) with 1 output partitions
2021-12-08 10:03:41,456 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 13 (count at PaidPromotionAdjustParameter.scala:283)
2021-12-08 10:03:41,456 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 12)
2021-12-08 10:03:41,456 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List(ShuffleMapStage 12)
2021-12-08 10:03:41,457 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ShuffleMapStage 12 (MapPartitionsRDD[23] at distinct at PaidPromotionAdjustParameter.scala:280), which has no missing parents
2021-12-08 10:03:41,468 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_11 stored as values in memory (estimated size 5.9 KB, free 1990.1 MB)
2021-12-08 10:03:41,470 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_11_piece0 stored as bytes in memory (estimated size 3.3 KB, free 1990.1 MB)
2021-12-08 10:03:41,471 [dispatcher-event-loop-3] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_11_piece0 in memory on qb:55588 (size: 3.3 KB, free: 1990.7 MB)
2021-12-08 10:03:41,471 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 11 from broadcast at DAGScheduler.scala:1039
2021-12-08 10:03:41,471 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 12 missing tasks from ShuffleMapStage 12 (MapPartitionsRDD[23] at distinct at PaidPromotionAdjustParameter.scala:280) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11))
2021-12-08 10:03:41,471 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 12.0 with 12 tasks
2021-12-08 10:03:41,473 [dispatcher-event-loop-8] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 12.0 (TID 43, localhost, executor driver, partition 0, ANY, 8015 bytes)
2021-12-08 10:03:41,474 [dispatcher-event-loop-8] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 12.0 (TID 44, localhost, executor driver, partition 1, ANY, 8015 bytes)
2021-12-08 10:03:41,474 [dispatcher-event-loop-8] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 2.0 in stage 12.0 (TID 45, localhost, executor driver, partition 2, ANY, 8015 bytes)
2021-12-08 10:03:41,474 [dispatcher-event-loop-8] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 3.0 in stage 12.0 (TID 46, localhost, executor driver, partition 3, ANY, 8015 bytes)
2021-12-08 10:03:41,474 [dispatcher-event-loop-8] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 4.0 in stage 12.0 (TID 47, localhost, executor driver, partition 4, ANY, 8015 bytes)
2021-12-08 10:03:41,474 [dispatcher-event-loop-8] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 5.0 in stage 12.0 (TID 48, localhost, executor driver, partition 5, ANY, 8015 bytes)
2021-12-08 10:03:41,474 [dispatcher-event-loop-8] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 6.0 in stage 12.0 (TID 49, localhost, executor driver, partition 6, ANY, 8015 bytes)
2021-12-08 10:03:41,474 [dispatcher-event-loop-8] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 7.0 in stage 12.0 (TID 50, localhost, executor driver, partition 7, ANY, 8015 bytes)
2021-12-08 10:03:41,475 [dispatcher-event-loop-8] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 8.0 in stage 12.0 (TID 51, localhost, executor driver, partition 8, ANY, 8015 bytes)
2021-12-08 10:03:41,475 [dispatcher-event-loop-8] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 9.0 in stage 12.0 (TID 52, localhost, executor driver, partition 9, ANY, 8015 bytes)
2021-12-08 10:03:41,475 [dispatcher-event-loop-8] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 10.0 in stage 12.0 (TID 53, localhost, executor driver, partition 10, ANY, 8030 bytes)
2021-12-08 10:03:41,475 [dispatcher-event-loop-8] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 11.0 in stage 12.0 (TID 54, localhost, executor driver, partition 11, ANY, 8030 bytes)
2021-12-08 10:03:41,475 [Executor task launch worker for task 43] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 12.0 (TID 43)
2021-12-08 10:03:41,475 [Executor task launch worker for task 45] INFO [org.apache.spark.executor.Executor] - Running task 2.0 in stage 12.0 (TID 45)
2021-12-08 10:03:41,475 [Executor task launch worker for task 49] INFO [org.apache.spark.executor.Executor] - Running task 6.0 in stage 12.0 (TID 49)
2021-12-08 10:03:41,475 [Executor task launch worker for task 50] INFO [org.apache.spark.executor.Executor] - Running task 7.0 in stage 12.0 (TID 50)
2021-12-08 10:03:41,475 [Executor task launch worker for task 52] INFO [org.apache.spark.executor.Executor] - Running task 9.0 in stage 12.0 (TID 52)
2021-12-08 10:03:41,475 [Executor task launch worker for task 44] INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 12.0 (TID 44)
2021-12-08 10:03:41,475 [Executor task launch worker for task 47] INFO [org.apache.spark.executor.Executor] - Running task 4.0 in stage 12.0 (TID 47)
2021-12-08 10:03:41,475 [Executor task launch worker for task 53] INFO [org.apache.spark.executor.Executor] - Running task 10.0 in stage 12.0 (TID 53)
2021-12-08 10:03:41,475 [Executor task launch worker for task 46] INFO [org.apache.spark.executor.Executor] - Running task 3.0 in stage 12.0 (TID 46)
2021-12-08 10:03:41,475 [Executor task launch worker for task 51] INFO [org.apache.spark.executor.Executor] - Running task 8.0 in stage 12.0 (TID 51)
2021-12-08 10:03:41,475 [Executor task launch worker for task 48] INFO [org.apache.spark.executor.Executor] - Running task 5.0 in stage 12.0 (TID 48)
2021-12-08 10:03:41,477 [Executor task launch worker for task 54] INFO [org.apache.spark.executor.Executor] - Running task 11.0 in stage 12.0 (TID 54)
2021-12-08 10:03:41,478 [Executor task launch worker for task 45] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/handle_data/device_video_data/part-00002:0+43831145
2021-12-08 10:03:41,478 [Executor task launch worker for task 46] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/handle_data/device_video_data/part-00003:0+29761082
2021-12-08 10:03:41,478 [Executor task launch worker for task 50] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/handle_data/device_video_data/part-00007:0+29599448
2021-12-08 10:03:41,478 [Executor task launch worker for task 51] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/handle_data/device_video_data/part-00008:0+29423447
2021-12-08 10:03:41,478 [Executor task launch worker for task 53] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/handle_data/set-train-device-production-data/part-00000:0+3237750
2021-12-08 10:03:41,479 [Executor task launch worker for task 49] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/handle_data/device_video_data/part-00006:0+29631891
2021-12-08 10:03:41,479 [Executor task launch worker for task 52] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/handle_data/device_video_data/part-00009:0+29225612
2021-12-08 10:03:41,479 [Executor task launch worker for task 47] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/handle_data/device_video_data/part-00004:0+14256802
2021-12-08 10:03:41,479 [Executor task launch worker for task 44] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/handle_data/device_video_data/part-00001:0+38414410
2021-12-08 10:03:41,480 [Executor task launch worker for task 48] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/handle_data/device_video_data/part-00005:0+14798635
2021-12-08 10:03:41,480 [Executor task launch worker for task 43] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/handle_data/device_video_data/part-00000:0+29528642
2021-12-08 10:03:41,480 [Executor task launch worker for task 54] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/handle_data/set-train-device-production-data/part-00000:3237750+3237751
2021-12-08 10:03:41,636 [dispatcher-event-loop-9] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_10_piece0 on qb:55588 in memory (size: 2.2 KB, free: 1990.7 MB)
2021-12-08 10:03:43,676 [Executor task launch worker for task 53] INFO [org.apache.spark.executor.Executor] - Finished task 10.0 in stage 12.0 (TID 53). 1031 bytes result sent to driver
2021-12-08 10:03:43,677 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 10.0 in stage 12.0 (TID 53) in 2202 ms on localhost (executor driver) (1/12)
2021-12-08 10:03:46,926 [Executor task launch worker for task 54] INFO [org.apache.spark.executor.Executor] - Finished task 11.0 in stage 12.0 (TID 54). 1031 bytes result sent to driver
2021-12-08 10:03:46,926 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 11.0 in stage 12.0 (TID 54) in 5451 ms on localhost (executor driver) (2/12)
2021-12-08 10:03:55,268 [Executor task launch worker for task 47] INFO [org.apache.spark.executor.Executor] - Finished task 4.0 in stage 12.0 (TID 47). 1031 bytes result sent to driver
2021-12-08 10:03:55,269 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 4.0 in stage 12.0 (TID 47) in 13795 ms on localhost (executor driver) (3/12)
2021-12-08 10:03:57,836 [Executor task launch worker for task 48] INFO [org.apache.spark.executor.Executor] - Finished task 5.0 in stage 12.0 (TID 48). 1031 bytes result sent to driver
2021-12-08 10:03:57,836 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 5.0 in stage 12.0 (TID 48) in 16362 ms on localhost (executor driver) (4/12)
2021-12-08 10:04:03,851 [Executor task launch worker for task 43] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 12.0 (TID 43). 1031 bytes result sent to driver
2021-12-08 10:04:03,852 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 12.0 (TID 43) in 22380 ms on localhost (executor driver) (5/12)
2021-12-08 10:04:08,118 [Executor task launch worker for task 49] INFO [org.apache.spark.executor.Executor] - Finished task 6.0 in stage 12.0 (TID 49). 1074 bytes result sent to driver
2021-12-08 10:04:08,118 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 6.0 in stage 12.0 (TID 49) in 26644 ms on localhost (executor driver) (6/12)
2021-12-08 10:04:11,210 [Executor task launch worker for task 46] INFO [org.apache.spark.executor.Executor] - Finished task 3.0 in stage 12.0 (TID 46). 1031 bytes result sent to driver
2021-12-08 10:04:11,210 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 3.0 in stage 12.0 (TID 46) in 29736 ms on localhost (executor driver) (7/12)
2021-12-08 10:04:11,329 [Executor task launch worker for task 51] INFO [org.apache.spark.executor.Executor] - Finished task 8.0 in stage 12.0 (TID 51). 1031 bytes result sent to driver
2021-12-08 10:04:11,330 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 8.0 in stage 12.0 (TID 51) in 29855 ms on localhost (executor driver) (8/12)
2021-12-08 10:04:12,050 [Executor task launch worker for task 45] INFO [org.apache.spark.executor.Executor] - Finished task 2.0 in stage 12.0 (TID 45). 1031 bytes result sent to driver
2021-12-08 10:04:12,050 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 2.0 in stage 12.0 (TID 45) in 30576 ms on localhost (executor driver) (9/12)
2021-12-08 10:04:12,443 [Executor task launch worker for task 50] INFO [org.apache.spark.executor.Executor] - Finished task 7.0 in stage 12.0 (TID 50). 1031 bytes result sent to driver
2021-12-08 10:04:12,444 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 7.0 in stage 12.0 (TID 50) in 30970 ms on localhost (executor driver) (10/12)
2021-12-08 10:04:12,562 [Executor task launch worker for task 52] INFO [org.apache.spark.executor.Executor] - Finished task 9.0 in stage 12.0 (TID 52). 1031 bytes result sent to driver
2021-12-08 10:04:12,563 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 9.0 in stage 12.0 (TID 52) in 31087 ms on localhost (executor driver) (11/12)
2021-12-08 10:04:12,857 [Executor task launch worker for task 44] INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 12.0 (TID 44). 1031 bytes result sent to driver
2021-12-08 10:04:12,857 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 12.0 (TID 44) in 31384 ms on localhost (executor driver) (12/12)
2021-12-08 10:04:12,857 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 12.0, whose tasks have all completed, from pool 
2021-12-08 10:04:12,857 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ShuffleMapStage 12 (distinct at PaidPromotionAdjustParameter.scala:280) finished in 31.399 s
2021-12-08 10:04:12,857 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - looking for newly runnable stages
2021-12-08 10:04:12,857 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - running: Set()
2021-12-08 10:04:12,857 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - waiting: Set(ResultStage 13)
2021-12-08 10:04:12,857 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - failed: Set()
2021-12-08 10:04:12,858 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 13 (ZippedWithIndexRDD[26] at zipWithIndex at PaidPromotionAdjustParameter.scala:281), which has no missing parents
2021-12-08 10:04:12,858 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_12 stored as values in memory (estimated size 3.9 KB, free 1990.1 MB)
2021-12-08 10:04:12,860 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_12_piece0 stored as bytes in memory (estimated size 2.2 KB, free 1990.1 MB)
2021-12-08 10:04:12,861 [dispatcher-event-loop-4] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_12_piece0 in memory on qb:55588 (size: 2.2 KB, free: 1990.7 MB)
2021-12-08 10:04:12,861 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 12 from broadcast at DAGScheduler.scala:1039
2021-12-08 10:04:12,861 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 13 (ZippedWithIndexRDD[26] at zipWithIndex at PaidPromotionAdjustParameter.scala:281) (first 15 tasks are for partitions Vector(0))
2021-12-08 10:04:12,861 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 13.0 with 1 tasks
2021-12-08 10:04:12,862 [dispatcher-event-loop-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 13.0 (TID 55, localhost, executor driver, partition 0, ANY, 7759 bytes)
2021-12-08 10:04:12,862 [Executor task launch worker for task 55] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 13.0 (TID 55)
2021-12-08 10:04:12,863 [Executor task launch worker for task 55] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 12 non-empty blocks out of 12 blocks
2021-12-08 10:04:12,863 [Executor task launch worker for task 55] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-08 10:04:13,058 [Executor task launch worker for task 55] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 13.0 (TID 55). 1098 bytes result sent to driver
2021-12-08 10:04:13,058 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 13.0 (TID 55) in 197 ms on localhost (executor driver) (1/1)
2021-12-08 10:04:13,058 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 13.0, whose tasks have all completed, from pool 
2021-12-08 10:04:13,059 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 13 (count at PaidPromotionAdjustParameter.scala:283) finished in 0.200 s
2021-12-08 10:04:13,059 [main] INFO [org.apache.spark.scheduler.DAGScheduler] - Job 6 finished: count at PaidPromotionAdjustParameter.scala:283, took 31.606285 s
2021-12-08 10:04:13,059 [main] INFO [PaidPromotionAdjustParameter$] - 训练总用户数：170664
2021-12-08 10:04:13,105 [main] INFO [PaidPromotionAdjustParameter$] - Rdd转换时间 : 95s
2021-12-08 10:04:13,123 [main] INFO [org.apache.hadoop.conf.Configuration.deprecation] - mapred.output.dir is deprecated. Instead, use mapreduce.output.fileoutputformat.outputdir
2021-12-08 10:04:13,126 [main] INFO [org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter] - File Output Committer Algorithm version is 1
2021-12-08 10:04:13,174 [main] INFO [org.apache.spark.SparkContext] - Starting job: runJob at SparkHadoopWriter.scala:78
2021-12-08 10:04:13,175 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 4 (map at PaidPromotionAdjustParameter.scala:244)
2021-12-08 10:04:13,175 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 26 (zipWithIndex at PaidPromotionAdjustParameter.scala:281)
2021-12-08 10:04:13,175 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 30 (map at PaidPromotionAdjustParameter.scala:289)
2021-12-08 10:04:13,175 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 26 (zipWithIndex at PaidPromotionAdjustParameter.scala:281)
2021-12-08 10:04:13,175 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 13 (map at PaidPromotionAdjustParameter.scala:265)
2021-12-08 10:04:13,175 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 39 (map at PaidPromotionAdjustParameter.scala:298)
2021-12-08 10:04:13,175 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 19 (map at PaidPromotionAdjustParameter.scala:275)
2021-12-08 10:04:13,176 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 9 (zipWithIndex at PaidPromotionAdjustParameter.scala:253)
2021-12-08 10:04:13,176 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 7 (runJob at SparkHadoopWriter.scala:78) with 10 output partitions
2021-12-08 10:04:13,176 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 25 (runJob at SparkHadoopWriter.scala:78)
2021-12-08 10:04:13,176 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 20, ShuffleMapStage 17, ShuffleMapStage 24, ShuffleMapStage 22)
2021-12-08 10:04:13,176 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List(ShuffleMapStage 20, ShuffleMapStage 17, ShuffleMapStage 24, ShuffleMapStage 22)
2021-12-08 10:04:13,176 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ShuffleMapStage 15 (MapPartitionsRDD[4] at map at PaidPromotionAdjustParameter.scala:244), which has no missing parents
2021-12-08 10:04:13,177 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_13 stored as values in memory (estimated size 4.5 KB, free 1990.1 MB)
2021-12-08 10:04:13,179 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_13_piece0 stored as bytes in memory (estimated size 2.7 KB, free 1990.1 MB)
2021-12-08 10:04:13,180 [dispatcher-event-loop-1] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_13_piece0 in memory on qb:55588 (size: 2.7 KB, free: 1990.7 MB)
2021-12-08 10:04:13,180 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 13 from broadcast at DAGScheduler.scala:1039
2021-12-08 10:04:13,180 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from ShuffleMapStage 15 (MapPartitionsRDD[4] at map at PaidPromotionAdjustParameter.scala:244) (first 15 tasks are for partitions Vector(0, 1))
2021-12-08 10:04:13,180 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 15.0 with 2 tasks
2021-12-08 10:04:13,181 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ShuffleMapStage 16 (ZippedWithIndexRDD[26] at zipWithIndex at PaidPromotionAdjustParameter.scala:281), which has no missing parents
2021-12-08 10:04:13,181 [dispatcher-event-loop-9] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 15.0 (TID 56, localhost, executor driver, partition 0, ANY, 7921 bytes)
2021-12-08 10:04:13,181 [dispatcher-event-loop-9] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 15.0 (TID 57, localhost, executor driver, partition 1, ANY, 7921 bytes)
2021-12-08 10:04:13,181 [Executor task launch worker for task 57] INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 15.0 (TID 57)
2021-12-08 10:04:13,181 [Executor task launch worker for task 56] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 15.0 (TID 56)
2021-12-08 10:04:13,182 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_14 stored as values in memory (estimated size 4.0 KB, free 1990.1 MB)
2021-12-08 10:04:13,182 [Executor task launch worker for task 56] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/handle_data/set-train-device-production-data/part-00000:0+3237750
2021-12-08 10:04:13,182 [Executor task launch worker for task 57] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/handle_data/set-train-device-production-data/part-00000:3237750+3237751
2021-12-08 10:04:13,184 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_14_piece0 stored as bytes in memory (estimated size 2.3 KB, free 1990.1 MB)
2021-12-08 10:04:13,184 [dispatcher-event-loop-2] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_14_piece0 in memory on qb:55588 (size: 2.3 KB, free: 1990.7 MB)
2021-12-08 10:04:13,185 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 14 from broadcast at DAGScheduler.scala:1039
2021-12-08 10:04:13,185 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ShuffleMapStage 16 (ZippedWithIndexRDD[26] at zipWithIndex at PaidPromotionAdjustParameter.scala:281) (first 15 tasks are for partitions Vector(0))
2021-12-08 10:04:13,185 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 16.0 with 1 tasks
2021-12-08 10:04:13,185 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ShuffleMapStage 18 (ZippedWithIndexRDD[26] at zipWithIndex at PaidPromotionAdjustParameter.scala:281), which has no missing parents
2021-12-08 10:04:13,185 [dispatcher-event-loop-11] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 16.0 (TID 58, localhost, executor driver, partition 0, ANY, 7748 bytes)
2021-12-08 10:04:13,186 [Executor task launch worker for task 58] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 16.0 (TID 58)
2021-12-08 10:04:13,186 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_15 stored as values in memory (estimated size 4.0 KB, free 1990.1 MB)
2021-12-08 10:04:13,186 [Executor task launch worker for task 58] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 12 non-empty blocks out of 12 blocks
2021-12-08 10:04:13,186 [Executor task launch worker for task 58] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-08 10:04:13,188 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_15_piece0 stored as bytes in memory (estimated size 2.3 KB, free 1990.1 MB)
2021-12-08 10:04:13,188 [dispatcher-event-loop-6] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_15_piece0 in memory on qb:55588 (size: 2.3 KB, free: 1990.7 MB)
2021-12-08 10:04:13,188 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 15 from broadcast at DAGScheduler.scala:1039
2021-12-08 10:04:13,188 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ShuffleMapStage 18 (ZippedWithIndexRDD[26] at zipWithIndex at PaidPromotionAdjustParameter.scala:281) (first 15 tasks are for partitions Vector(0))
2021-12-08 10:04:13,189 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 18.0 with 1 tasks
2021-12-08 10:04:13,189 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ShuffleMapStage 19 (MapPartitionsRDD[13] at map at PaidPromotionAdjustParameter.scala:265), which has no missing parents
2021-12-08 10:04:13,189 [dispatcher-event-loop-4] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 18.0 (TID 59, localhost, executor driver, partition 0, ANY, 7748 bytes)
2021-12-08 10:04:13,189 [Executor task launch worker for task 59] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 18.0 (TID 59)
2021-12-08 10:04:13,190 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_16 stored as values in memory (estimated size 4.5 KB, free 1990.1 MB)
2021-12-08 10:04:13,190 [Executor task launch worker for task 59] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 12 non-empty blocks out of 12 blocks
2021-12-08 10:04:13,190 [Executor task launch worker for task 59] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-08 10:04:13,198 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_16_piece0 stored as bytes in memory (estimated size 2.7 KB, free 1990.1 MB)
2021-12-08 10:04:13,198 [dispatcher-event-loop-1] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_16_piece0 in memory on qb:55588 (size: 2.7 KB, free: 1990.7 MB)
2021-12-08 10:04:13,199 [dispatcher-event-loop-1] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_12_piece0 on qb:55588 in memory (size: 2.2 KB, free: 1990.7 MB)
2021-12-08 10:04:13,199 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 16 from broadcast at DAGScheduler.scala:1039
2021-12-08 10:04:13,199 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 10 missing tasks from ShuffleMapStage 19 (MapPartitionsRDD[13] at map at PaidPromotionAdjustParameter.scala:265) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
2021-12-08 10:04:13,199 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 19.0 with 10 tasks
2021-12-08 10:04:13,200 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ShuffleMapStage 22 (MapPartitionsRDD[19] at map at PaidPromotionAdjustParameter.scala:275), which has no missing parents
2021-12-08 10:04:13,200 [dispatcher-event-loop-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 19.0 (TID 60, localhost, executor driver, partition 0, ANY, 7906 bytes)
2021-12-08 10:04:13,200 [dispatcher-event-loop-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 19.0 (TID 61, localhost, executor driver, partition 1, ANY, 7906 bytes)
2021-12-08 10:04:13,200 [dispatcher-event-loop-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 2.0 in stage 19.0 (TID 62, localhost, executor driver, partition 2, ANY, 7906 bytes)
2021-12-08 10:04:13,200 [dispatcher-event-loop-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 3.0 in stage 19.0 (TID 63, localhost, executor driver, partition 3, ANY, 7906 bytes)
2021-12-08 10:04:13,200 [dispatcher-event-loop-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 4.0 in stage 19.0 (TID 64, localhost, executor driver, partition 4, ANY, 7906 bytes)
2021-12-08 10:04:13,201 [dispatcher-event-loop-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 5.0 in stage 19.0 (TID 65, localhost, executor driver, partition 5, ANY, 7906 bytes)
2021-12-08 10:04:13,201 [dispatcher-event-loop-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 6.0 in stage 19.0 (TID 66, localhost, executor driver, partition 6, ANY, 7906 bytes)
2021-12-08 10:04:13,201 [dispatcher-event-loop-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 7.0 in stage 19.0 (TID 67, localhost, executor driver, partition 7, ANY, 7906 bytes)
2021-12-08 10:04:13,201 [Executor task launch worker for task 62] INFO [org.apache.spark.executor.Executor] - Running task 2.0 in stage 19.0 (TID 62)
2021-12-08 10:04:13,201 [Executor task launch worker for task 65] INFO [org.apache.spark.executor.Executor] - Running task 5.0 in stage 19.0 (TID 65)
2021-12-08 10:04:13,201 [Executor task launch worker for task 63] INFO [org.apache.spark.executor.Executor] - Running task 3.0 in stage 19.0 (TID 63)
2021-12-08 10:04:13,201 [Executor task launch worker for task 67] INFO [org.apache.spark.executor.Executor] - Running task 7.0 in stage 19.0 (TID 67)
2021-12-08 10:04:13,201 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_17 stored as values in memory (estimated size 4.1 KB, free 1990.1 MB)
2021-12-08 10:04:13,201 [Executor task launch worker for task 64] INFO [org.apache.spark.executor.Executor] - Running task 4.0 in stage 19.0 (TID 64)
2021-12-08 10:04:13,201 [Executor task launch worker for task 61] INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 19.0 (TID 61)
2021-12-08 10:04:13,201 [Executor task launch worker for task 60] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 19.0 (TID 60)
2021-12-08 10:04:13,202 [Executor task launch worker for task 65] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/handle_data/device_video_data/part-00005:0+14798635
2021-12-08 10:04:13,201 [Executor task launch worker for task 66] INFO [org.apache.spark.executor.Executor] - Running task 6.0 in stage 19.0 (TID 66)
2021-12-08 10:04:13,203 [Executor task launch worker for task 63] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/handle_data/device_video_data/part-00003:0+29761082
2021-12-08 10:04:13,203 [Executor task launch worker for task 67] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/handle_data/device_video_data/part-00007:0+29599448
2021-12-08 10:04:13,204 [Executor task launch worker for task 66] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/handle_data/device_video_data/part-00006:0+29631891
2021-12-08 10:04:13,204 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_17_piece0 stored as bytes in memory (estimated size 2.4 KB, free 1990.1 MB)
2021-12-08 10:04:13,202 [Executor task launch worker for task 64] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/handle_data/device_video_data/part-00004:0+14256802
2021-12-08 10:04:13,203 [Executor task launch worker for task 61] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/handle_data/device_video_data/part-00001:0+38414410
2021-12-08 10:04:13,203 [Executor task launch worker for task 60] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/handle_data/device_video_data/part-00000:0+29528642
2021-12-08 10:04:13,203 [Executor task launch worker for task 62] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/handle_data/device_video_data/part-00002:0+43831145
2021-12-08 10:04:13,204 [dispatcher-event-loop-8] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_17_piece0 in memory on qb:55588 (size: 2.4 KB, free: 1990.7 MB)
2021-12-08 10:04:13,205 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 17 from broadcast at DAGScheduler.scala:1039
2021-12-08 10:04:13,206 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 12 missing tasks from ShuffleMapStage 22 (MapPartitionsRDD[19] at map at PaidPromotionAdjustParameter.scala:275) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11))
2021-12-08 10:04:13,206 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 22.0 with 12 tasks
2021-12-08 10:04:13,207 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ShuffleMapStage 24 (ZippedWithIndexRDD[9] at zipWithIndex at PaidPromotionAdjustParameter.scala:253), which has no missing parents
2021-12-08 10:04:13,208 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_18 stored as values in memory (estimated size 4.0 KB, free 1990.1 MB)
2021-12-08 10:04:13,209 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_18_piece0 stored as bytes in memory (estimated size 2.3 KB, free 1990.1 MB)
2021-12-08 10:04:13,210 [dispatcher-event-loop-1] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_18_piece0 in memory on qb:55588 (size: 2.3 KB, free: 1990.7 MB)
2021-12-08 10:04:13,210 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 18 from broadcast at DAGScheduler.scala:1039
2021-12-08 10:04:13,210 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 3 missing tasks from ShuffleMapStage 24 (ZippedWithIndexRDD[9] at zipWithIndex at PaidPromotionAdjustParameter.scala:253) (first 15 tasks are for partitions Vector(0, 1, 2))
2021-12-08 10:04:13,210 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 24.0 with 3 tasks
2021-12-08 10:04:13,473 [Executor task launch worker for task 58] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 16.0 (TID 58). 1204 bytes result sent to driver
2021-12-08 10:04:13,474 [dispatcher-event-loop-7] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 8.0 in stage 19.0 (TID 68, localhost, executor driver, partition 8, ANY, 7906 bytes)
2021-12-08 10:04:13,474 [Executor task launch worker for task 68] INFO [org.apache.spark.executor.Executor] - Running task 8.0 in stage 19.0 (TID 68)
2021-12-08 10:04:13,474 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 16.0 (TID 58) in 289 ms on localhost (executor driver) (1/1)
2021-12-08 10:04:13,474 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 16.0, whose tasks have all completed, from pool 
2021-12-08 10:04:13,474 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ShuffleMapStage 16 (zipWithIndex at PaidPromotionAdjustParameter.scala:281) finished in 0.293 s
2021-12-08 10:04:13,474 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - looking for newly runnable stages
2021-12-08 10:04:13,474 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - running: Set(ShuffleMapStage 15, ShuffleMapStage 19, ShuffleMapStage 24, ShuffleMapStage 18, ShuffleMapStage 22)
2021-12-08 10:04:13,474 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - waiting: Set(ShuffleMapStage 20, ShuffleMapStage 17, ResultStage 25)
2021-12-08 10:04:13,474 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - failed: Set()
2021-12-08 10:04:13,475 [Executor task launch worker for task 68] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/handle_data/device_video_data/part-00008:0+29423447
2021-12-08 10:04:13,537 [dispatcher-event-loop-6] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_14_piece0 on qb:55588 in memory (size: 2.3 KB, free: 1990.7 MB)
2021-12-08 10:04:13,539 [Executor task launch worker for task 59] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 18.0 (TID 59). 1212 bytes result sent to driver
2021-12-08 10:04:13,540 [dispatcher-event-loop-4] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 9.0 in stage 19.0 (TID 69, localhost, executor driver, partition 9, ANY, 7906 bytes)
2021-12-08 10:04:13,540 [Executor task launch worker for task 69] INFO [org.apache.spark.executor.Executor] - Running task 9.0 in stage 19.0 (TID 69)
2021-12-08 10:04:13,540 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 18.0 (TID 59) in 351 ms on localhost (executor driver) (1/1)
2021-12-08 10:04:13,540 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 18.0, whose tasks have all completed, from pool 
2021-12-08 10:04:13,540 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ShuffleMapStage 18 (zipWithIndex at PaidPromotionAdjustParameter.scala:281) finished in 0.354 s
2021-12-08 10:04:13,540 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - looking for newly runnable stages
2021-12-08 10:04:13,540 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - running: Set(ShuffleMapStage 15, ShuffleMapStage 19, ShuffleMapStage 24, ShuffleMapStage 22)
2021-12-08 10:04:13,540 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - waiting: Set(ShuffleMapStage 20, ShuffleMapStage 17, ResultStage 25)
2021-12-08 10:04:13,540 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - failed: Set()
2021-12-08 10:04:13,541 [Executor task launch worker for task 69] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/handle_data/device_video_data/part-00009:0+29225612
2021-12-08 10:04:13,716 [dispatcher-event-loop-9] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_15_piece0 on qb:55588 in memory (size: 2.3 KB, free: 1990.7 MB)
2021-12-08 10:04:15,596 [Executor task launch worker for task 56] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 15.0 (TID 56). 903 bytes result sent to driver
2021-12-08 10:04:15,596 [dispatcher-event-loop-7] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 22.0 (TID 70, localhost, executor driver, partition 0, ANY, 7748 bytes)
2021-12-08 10:04:15,596 [Executor task launch worker for task 70] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 22.0 (TID 70)
2021-12-08 10:04:15,596 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 15.0 (TID 56) in 2415 ms on localhost (executor driver) (1/2)
2021-12-08 10:04:15,597 [Executor task launch worker for task 70] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 10 non-empty blocks out of 10 blocks
2021-12-08 10:04:15,597 [Executor task launch worker for task 70] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-08 10:04:15,632 [Executor task launch worker for task 70] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 22.0 (TID 70). 1214 bytes result sent to driver
2021-12-08 10:04:15,633 [dispatcher-event-loop-5] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 22.0 (TID 71, localhost, executor driver, partition 1, ANY, 7748 bytes)
2021-12-08 10:04:15,633 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 22.0 (TID 70) in 37 ms on localhost (executor driver) (1/12)
2021-12-08 10:04:15,633 [Executor task launch worker for task 71] INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 22.0 (TID 71)
2021-12-08 10:04:15,633 [Executor task launch worker for task 71] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 10 non-empty blocks out of 10 blocks
2021-12-08 10:04:15,633 [Executor task launch worker for task 71] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-08 10:04:15,667 [Executor task launch worker for task 71] INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 22.0 (TID 71). 1171 bytes result sent to driver
2021-12-08 10:04:15,667 [dispatcher-event-loop-6] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 2.0 in stage 22.0 (TID 72, localhost, executor driver, partition 2, ANY, 7748 bytes)
2021-12-08 10:04:15,667 [Executor task launch worker for task 72] INFO [org.apache.spark.executor.Executor] - Running task 2.0 in stage 22.0 (TID 72)
2021-12-08 10:04:15,668 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 22.0 (TID 71) in 36 ms on localhost (executor driver) (2/12)
2021-12-08 10:04:15,668 [Executor task launch worker for task 72] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 10 non-empty blocks out of 10 blocks
2021-12-08 10:04:15,668 [Executor task launch worker for task 72] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-08 10:04:15,700 [Executor task launch worker for task 72] INFO [org.apache.spark.executor.Executor] - Finished task 2.0 in stage 22.0 (TID 72). 1214 bytes result sent to driver
2021-12-08 10:04:15,701 [dispatcher-event-loop-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 3.0 in stage 22.0 (TID 73, localhost, executor driver, partition 3, ANY, 7748 bytes)
2021-12-08 10:04:15,701 [Executor task launch worker for task 73] INFO [org.apache.spark.executor.Executor] - Running task 3.0 in stage 22.0 (TID 73)
2021-12-08 10:04:15,701 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 2.0 in stage 22.0 (TID 72) in 34 ms on localhost (executor driver) (3/12)
2021-12-08 10:04:15,701 [Executor task launch worker for task 73] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 10 non-empty blocks out of 10 blocks
2021-12-08 10:04:15,701 [Executor task launch worker for task 73] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-08 10:04:15,732 [Executor task launch worker for task 73] INFO [org.apache.spark.executor.Executor] - Finished task 3.0 in stage 22.0 (TID 73). 1171 bytes result sent to driver
2021-12-08 10:04:15,733 [dispatcher-event-loop-8] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 4.0 in stage 22.0 (TID 74, localhost, executor driver, partition 4, ANY, 7748 bytes)
2021-12-08 10:04:15,733 [Executor task launch worker for task 74] INFO [org.apache.spark.executor.Executor] - Running task 4.0 in stage 22.0 (TID 74)
2021-12-08 10:04:15,733 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 3.0 in stage 22.0 (TID 73) in 32 ms on localhost (executor driver) (4/12)
2021-12-08 10:04:15,733 [Executor task launch worker for task 74] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 10 non-empty blocks out of 10 blocks
2021-12-08 10:04:15,733 [Executor task launch worker for task 74] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-08 10:04:15,769 [Executor task launch worker for task 74] INFO [org.apache.spark.executor.Executor] - Finished task 4.0 in stage 22.0 (TID 74). 1214 bytes result sent to driver
2021-12-08 10:04:15,770 [dispatcher-event-loop-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 5.0 in stage 22.0 (TID 75, localhost, executor driver, partition 5, ANY, 7748 bytes)
2021-12-08 10:04:15,770 [Executor task launch worker for task 75] INFO [org.apache.spark.executor.Executor] - Running task 5.0 in stage 22.0 (TID 75)
2021-12-08 10:04:15,770 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 4.0 in stage 22.0 (TID 74) in 37 ms on localhost (executor driver) (5/12)
2021-12-08 10:04:15,770 [Executor task launch worker for task 75] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 10 non-empty blocks out of 10 blocks
2021-12-08 10:04:15,770 [Executor task launch worker for task 75] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-08 10:04:15,803 [Executor task launch worker for task 75] INFO [org.apache.spark.executor.Executor] - Finished task 5.0 in stage 22.0 (TID 75). 1171 bytes result sent to driver
2021-12-08 10:04:15,803 [dispatcher-event-loop-7] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 6.0 in stage 22.0 (TID 76, localhost, executor driver, partition 6, ANY, 7748 bytes)
2021-12-08 10:04:15,803 [Executor task launch worker for task 76] INFO [org.apache.spark.executor.Executor] - Running task 6.0 in stage 22.0 (TID 76)
2021-12-08 10:04:15,803 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 5.0 in stage 22.0 (TID 75) in 34 ms on localhost (executor driver) (6/12)
2021-12-08 10:04:15,804 [Executor task launch worker for task 76] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 10 non-empty blocks out of 10 blocks
2021-12-08 10:04:15,804 [Executor task launch worker for task 76] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-08 10:04:15,836 [Executor task launch worker for task 76] INFO [org.apache.spark.executor.Executor] - Finished task 6.0 in stage 22.0 (TID 76). 1171 bytes result sent to driver
2021-12-08 10:04:15,837 [dispatcher-event-loop-5] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 7.0 in stage 22.0 (TID 77, localhost, executor driver, partition 7, ANY, 7748 bytes)
2021-12-08 10:04:15,837 [Executor task launch worker for task 77] INFO [org.apache.spark.executor.Executor] - Running task 7.0 in stage 22.0 (TID 77)
2021-12-08 10:04:15,837 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 6.0 in stage 22.0 (TID 76) in 34 ms on localhost (executor driver) (7/12)
2021-12-08 10:04:15,837 [Executor task launch worker for task 77] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 10 non-empty blocks out of 10 blocks
2021-12-08 10:04:15,838 [Executor task launch worker for task 77] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 1 ms
2021-12-08 10:04:15,871 [Executor task launch worker for task 77] INFO [org.apache.spark.executor.Executor] - Finished task 7.0 in stage 22.0 (TID 77). 1171 bytes result sent to driver
2021-12-08 10:04:15,871 [dispatcher-event-loop-6] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 8.0 in stage 22.0 (TID 78, localhost, executor driver, partition 8, ANY, 7748 bytes)
2021-12-08 10:04:15,871 [Executor task launch worker for task 78] INFO [org.apache.spark.executor.Executor] - Running task 8.0 in stage 22.0 (TID 78)
2021-12-08 10:04:15,871 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 7.0 in stage 22.0 (TID 77) in 34 ms on localhost (executor driver) (8/12)
2021-12-08 10:04:15,872 [Executor task launch worker for task 78] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 10 non-empty blocks out of 10 blocks
2021-12-08 10:04:15,872 [Executor task launch worker for task 78] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-08 10:04:15,904 [Executor task launch worker for task 78] INFO [org.apache.spark.executor.Executor] - Finished task 8.0 in stage 22.0 (TID 78). 1257 bytes result sent to driver
2021-12-08 10:04:15,905 [dispatcher-event-loop-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 9.0 in stage 22.0 (TID 79, localhost, executor driver, partition 9, ANY, 7748 bytes)
2021-12-08 10:04:15,905 [Executor task launch worker for task 79] INFO [org.apache.spark.executor.Executor] - Running task 9.0 in stage 22.0 (TID 79)
2021-12-08 10:04:15,905 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 8.0 in stage 22.0 (TID 78) in 34 ms on localhost (executor driver) (9/12)
2021-12-08 10:04:15,906 [Executor task launch worker for task 79] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 10 non-empty blocks out of 10 blocks
2021-12-08 10:04:15,906 [Executor task launch worker for task 79] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-08 10:04:15,949 [Executor task launch worker for task 79] INFO [org.apache.spark.executor.Executor] - Finished task 9.0 in stage 22.0 (TID 79). 1214 bytes result sent to driver
2021-12-08 10:04:15,949 [dispatcher-event-loop-8] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 10.0 in stage 22.0 (TID 80, localhost, executor driver, partition 10, ANY, 7748 bytes)
2021-12-08 10:04:15,949 [Executor task launch worker for task 80] INFO [org.apache.spark.executor.Executor] - Running task 10.0 in stage 22.0 (TID 80)
2021-12-08 10:04:15,949 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 9.0 in stage 22.0 (TID 79) in 44 ms on localhost (executor driver) (10/12)
2021-12-08 10:04:15,954 [Executor task launch worker for task 80] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 10 non-empty blocks out of 10 blocks
2021-12-08 10:04:15,954 [Executor task launch worker for task 80] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-08 10:04:15,986 [Executor task launch worker for task 80] INFO [org.apache.spark.executor.Executor] - Finished task 10.0 in stage 22.0 (TID 80). 1214 bytes result sent to driver
2021-12-08 10:04:15,986 [dispatcher-event-loop-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 11.0 in stage 22.0 (TID 81, localhost, executor driver, partition 11, ANY, 7748 bytes)
2021-12-08 10:04:15,986 [Executor task launch worker for task 81] INFO [org.apache.spark.executor.Executor] - Running task 11.0 in stage 22.0 (TID 81)
2021-12-08 10:04:15,986 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 10.0 in stage 22.0 (TID 80) in 37 ms on localhost (executor driver) (11/12)
2021-12-08 10:04:15,987 [Executor task launch worker for task 81] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 10 non-empty blocks out of 10 blocks
2021-12-08 10:04:15,987 [Executor task launch worker for task 81] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-08 10:04:16,019 [Executor task launch worker for task 81] INFO [org.apache.spark.executor.Executor] - Finished task 11.0 in stage 22.0 (TID 81). 1214 bytes result sent to driver
2021-12-08 10:04:16,020 [dispatcher-event-loop-7] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 24.0 (TID 82, localhost, executor driver, partition 0, ANY, 7748 bytes)
2021-12-08 10:04:16,020 [Executor task launch worker for task 82] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 24.0 (TID 82)
2021-12-08 10:04:16,020 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 11.0 in stage 22.0 (TID 81) in 34 ms on localhost (executor driver) (12/12)
2021-12-08 10:04:16,020 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 22.0, whose tasks have all completed, from pool 
2021-12-08 10:04:16,020 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ShuffleMapStage 22 (map at PaidPromotionAdjustParameter.scala:275) finished in 2.819 s
2021-12-08 10:04:16,020 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - looking for newly runnable stages
2021-12-08 10:04:16,020 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - running: Set(ShuffleMapStage 15, ShuffleMapStage 19, ShuffleMapStage 24)
2021-12-08 10:04:16,020 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - waiting: Set(ShuffleMapStage 20, ShuffleMapStage 17, ResultStage 25)
2021-12-08 10:04:16,020 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - failed: Set()
2021-12-08 10:04:16,021 [Executor task launch worker for task 82] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 2 non-empty blocks out of 2 blocks
2021-12-08 10:04:16,021 [Executor task launch worker for task 82] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 1 ms
2021-12-08 10:04:16,033 [Executor task launch worker for task 82] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 24.0 (TID 82). 1162 bytes result sent to driver
2021-12-08 10:04:16,033 [dispatcher-event-loop-5] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 24.0 (TID 83, localhost, executor driver, partition 1, ANY, 7748 bytes)
2021-12-08 10:04:16,033 [Executor task launch worker for task 83] INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 24.0 (TID 83)
2021-12-08 10:04:16,033 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 24.0 (TID 82) in 13 ms on localhost (executor driver) (1/3)
2021-12-08 10:04:16,034 [Executor task launch worker for task 83] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 2 non-empty blocks out of 2 blocks
2021-12-08 10:04:16,034 [Executor task launch worker for task 83] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-08 10:04:16,046 [Executor task launch worker for task 83] INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 24.0 (TID 83). 1162 bytes result sent to driver
2021-12-08 10:04:16,047 [dispatcher-event-loop-6] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 2.0 in stage 24.0 (TID 84, localhost, executor driver, partition 2, ANY, 7748 bytes)
2021-12-08 10:04:16,047 [Executor task launch worker for task 84] INFO [org.apache.spark.executor.Executor] - Running task 2.0 in stage 24.0 (TID 84)
2021-12-08 10:04:16,047 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 24.0 (TID 83) in 14 ms on localhost (executor driver) (2/3)
2021-12-08 10:04:16,048 [Executor task launch worker for task 84] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 2 non-empty blocks out of 2 blocks
2021-12-08 10:04:16,048 [Executor task launch worker for task 84] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-08 10:04:16,060 [Executor task launch worker for task 84] INFO [org.apache.spark.executor.Executor] - Finished task 2.0 in stage 24.0 (TID 84). 1119 bytes result sent to driver
2021-12-08 10:04:16,060 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 2.0 in stage 24.0 (TID 84) in 13 ms on localhost (executor driver) (3/3)
2021-12-08 10:04:16,060 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 24.0, whose tasks have all completed, from pool 
2021-12-08 10:04:16,060 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ShuffleMapStage 24 (zipWithIndex at PaidPromotionAdjustParameter.scala:253) finished in 2.853 s
2021-12-08 10:04:16,061 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - looking for newly runnable stages
2021-12-08 10:04:16,061 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - running: Set(ShuffleMapStage 15, ShuffleMapStage 19)
2021-12-08 10:04:16,061 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - waiting: Set(ShuffleMapStage 20, ShuffleMapStage 17, ResultStage 25)
2021-12-08 10:04:16,061 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - failed: Set()
2021-12-08 10:04:16,603 [Executor task launch worker for task 57] INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 15.0 (TID 57). 903 bytes result sent to driver
2021-12-08 10:04:16,603 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 15.0 (TID 57) in 3422 ms on localhost (executor driver) (2/2)
2021-12-08 10:04:16,603 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 15.0, whose tasks have all completed, from pool 
2021-12-08 10:04:16,603 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ShuffleMapStage 15 (map at PaidPromotionAdjustParameter.scala:244) finished in 3.426 s
2021-12-08 10:04:16,603 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - looking for newly runnable stages
2021-12-08 10:04:16,603 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - running: Set(ShuffleMapStage 19)
2021-12-08 10:04:16,603 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - waiting: Set(ShuffleMapStage 20, ShuffleMapStage 17, ResultStage 25)
2021-12-08 10:04:16,603 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - failed: Set()
2021-12-08 10:04:16,603 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ShuffleMapStage 17 (MapPartitionsRDD[30] at map at PaidPromotionAdjustParameter.scala:289), which has no missing parents
2021-12-08 10:04:16,606 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_19 stored as values in memory (estimated size 3.6 KB, free 1990.1 MB)
2021-12-08 10:04:16,608 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_19_piece0 stored as bytes in memory (estimated size 2.1 KB, free 1990.1 MB)
2021-12-08 10:04:16,608 [dispatcher-event-loop-8] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_19_piece0 in memory on qb:55588 (size: 2.1 KB, free: 1990.7 MB)
2021-12-08 10:04:16,608 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 19 from broadcast at DAGScheduler.scala:1039
2021-12-08 10:04:16,609 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from ShuffleMapStage 17 (MapPartitionsRDD[30] at map at PaidPromotionAdjustParameter.scala:289) (first 15 tasks are for partitions Vector(0, 1))
2021-12-08 10:04:16,609 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 17.0 with 2 tasks
2021-12-08 10:04:16,610 [dispatcher-event-loop-9] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 17.0 (TID 85, localhost, executor driver, partition 0, PROCESS_LOCAL, 7701 bytes)
2021-12-08 10:04:16,610 [dispatcher-event-loop-9] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 17.0 (TID 86, localhost, executor driver, partition 1, PROCESS_LOCAL, 7701 bytes)
2021-12-08 10:04:16,610 [Executor task launch worker for task 85] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 17.0 (TID 85)
2021-12-08 10:04:16,610 [Executor task launch worker for task 86] INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 17.0 (TID 86)
2021-12-08 10:04:16,612 [Executor task launch worker for task 86] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 2 non-empty blocks out of 2 blocks
2021-12-08 10:04:16,612 [Executor task launch worker for task 85] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 2 non-empty blocks out of 2 blocks
2021-12-08 10:04:16,612 [Executor task launch worker for task 86] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-08 10:04:16,612 [Executor task launch worker for task 85] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-08 10:04:16,614 [Executor task launch worker for task 86] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 1 blocks
2021-12-08 10:04:16,614 [Executor task launch worker for task 85] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 1 blocks
2021-12-08 10:04:16,614 [Executor task launch worker for task 86] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-08 10:04:16,614 [Executor task launch worker for task 85] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-08 10:04:17,108 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 219
2021-12-08 10:04:17,108 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 265
2021-12-08 10:04:17,108 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 158
2021-12-08 10:04:17,108 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 188
2021-12-08 10:04:17,108 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 171
2021-12-08 10:04:17,108 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 194
2021-12-08 10:04:17,108 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 186
2021-12-08 10:04:17,108 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 274
2021-12-08 10:04:17,108 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 224
2021-12-08 10:04:17,108 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 268
2021-12-08 10:04:17,108 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 245
2021-12-08 10:04:17,108 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 161
2021-12-08 10:04:17,109 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 230
2021-12-08 10:04:17,109 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 238
2021-12-08 10:04:17,109 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 176
2021-12-08 10:04:17,109 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 196
2021-12-08 10:04:17,109 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 179
2021-12-08 10:04:17,109 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 203
2021-12-08 10:04:17,109 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 164
2021-12-08 10:04:17,109 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 244
2021-12-08 10:04:17,109 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 177
2021-12-08 10:04:17,109 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 163
2021-12-08 10:04:17,109 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 198
2021-12-08 10:04:17,109 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 242
2021-12-08 10:04:17,109 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 214
2021-12-08 10:04:17,110 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 249
2021-12-08 10:04:17,110 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 168
2021-12-08 10:04:17,110 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 221
2021-12-08 10:04:17,110 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 218
2021-12-08 10:04:17,110 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 223
2021-12-08 10:04:17,110 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 233
2021-12-08 10:04:17,110 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 154
2021-12-08 10:04:17,110 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 248
2021-12-08 10:04:17,110 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 189
2021-12-08 10:04:17,110 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 236
2021-12-08 10:04:17,114 [dispatcher-event-loop-5] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_8_piece0 on qb:55588 in memory (size: 1994.0 B, free: 1990.7 MB)
2021-12-08 10:04:17,115 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 226
2021-12-08 10:04:17,115 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 270
2021-12-08 10:04:17,115 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 156
2021-12-08 10:04:17,117 [dispatcher-event-loop-4] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_18_piece0 on qb:55588 in memory (size: 2.3 KB, free: 1990.7 MB)
2021-12-08 10:04:17,117 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 180
2021-12-08 10:04:17,117 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 174
2021-12-08 10:04:17,118 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 255
2021-12-08 10:04:17,118 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 215
2021-12-08 10:04:17,118 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 195
2021-12-08 10:04:17,118 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 204
2021-12-08 10:04:17,118 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 169
2021-12-08 10:04:17,118 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 187
2021-12-08 10:04:17,118 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 192
2021-12-08 10:04:17,118 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 172
2021-12-08 10:04:17,118 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 231
2021-12-08 10:04:17,118 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 197
2021-12-08 10:04:17,118 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 252
2021-12-08 10:04:17,118 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 225
2021-12-08 10:04:17,118 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 202
2021-12-08 10:04:17,119 [dispatcher-event-loop-8] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_11_piece0 on qb:55588 in memory (size: 3.3 KB, free: 1990.7 MB)
2021-12-08 10:04:17,119 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 150
2021-12-08 10:04:17,119 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 251
2021-12-08 10:04:17,119 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 256
2021-12-08 10:04:17,120 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 167
2021-12-08 10:04:17,120 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 173
2021-12-08 10:04:17,120 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 259
2021-12-08 10:04:17,120 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 206
2021-12-08 10:04:17,120 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 246
2021-12-08 10:04:17,120 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 152
2021-12-08 10:04:17,120 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 151
2021-12-08 10:04:17,120 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 228
2021-12-08 10:04:17,120 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 159
2021-12-08 10:04:17,120 [dispatcher-event-loop-1] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_13_piece0 on qb:55588 in memory (size: 2.7 KB, free: 1990.7 MB)
2021-12-08 10:04:17,121 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 178
2021-12-08 10:04:17,121 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 182
2021-12-08 10:04:17,121 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 243
2021-12-08 10:04:17,121 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 175
2021-12-08 10:04:17,121 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 253
2021-12-08 10:04:17,121 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 201
2021-12-08 10:04:17,121 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 261
2021-12-08 10:04:17,121 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 220
2021-12-08 10:04:17,121 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 190
2021-12-08 10:04:17,121 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 183
2021-12-08 10:04:17,121 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 162
2021-12-08 10:04:17,121 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 193
2021-12-08 10:04:17,121 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 267
2021-12-08 10:04:17,121 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 153
2021-12-08 10:04:17,121 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 266
2021-12-08 10:04:17,122 [dispatcher-event-loop-5] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_17_piece0 on qb:55588 in memory (size: 2.4 KB, free: 1990.7 MB)
2021-12-08 10:04:17,122 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 185
2021-12-08 10:04:17,122 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 213
2021-12-08 10:04:17,122 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 165
2021-12-08 10:04:17,122 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 166
2021-12-08 10:04:17,122 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 217
2021-12-08 10:04:17,122 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 262
2021-12-08 10:04:17,122 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 181
2021-12-08 10:04:17,122 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 160
2021-12-08 10:04:17,122 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 271
2021-12-08 10:04:17,123 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 257
2021-12-08 10:04:17,123 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 199
2021-12-08 10:04:17,123 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 241
2021-12-08 10:04:17,123 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 250
2021-12-08 10:04:17,123 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 184
2021-12-08 10:04:17,123 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 227
2021-12-08 10:04:17,123 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 191
2021-12-08 10:04:17,123 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 258
2021-12-08 10:04:17,123 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 273
2021-12-08 10:04:17,123 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 260
2021-12-08 10:04:17,123 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 211
2021-12-08 10:04:17,123 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 208
2021-12-08 10:04:17,123 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 254
2021-12-08 10:04:17,123 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 209
2021-12-08 10:04:17,123 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 157
2021-12-08 10:04:17,123 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 200
2021-12-08 10:04:17,123 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 212
2021-12-08 10:04:17,123 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 264
2021-12-08 10:04:17,123 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 232
2021-12-08 10:04:17,124 [dispatcher-event-loop-4] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_9_piece0 on qb:55588 in memory (size: 2.8 KB, free: 1990.7 MB)
2021-12-08 10:04:17,125 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 207
2021-12-08 10:04:17,125 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 272
2021-12-08 10:04:17,125 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 234
2021-12-08 10:04:17,125 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 170
2021-12-08 10:04:17,125 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 155
2021-12-08 10:04:17,125 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 240
2021-12-08 10:04:17,125 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 263
2021-12-08 10:04:17,125 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 205
2021-12-08 10:04:17,125 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 269
2021-12-08 10:04:17,125 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 229
2021-12-08 10:04:17,125 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 222
2021-12-08 10:04:17,125 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 247
2021-12-08 10:04:17,125 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 216
2021-12-08 10:04:17,125 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 239
2021-12-08 10:04:17,125 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 235
2021-12-08 10:04:17,125 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 237
2021-12-08 10:04:17,125 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 210
2021-12-08 10:04:17,135 [Executor task launch worker for task 85] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 17.0 (TID 85). 1248 bytes result sent to driver
2021-12-08 10:04:17,136 [Executor task launch worker for task 86] INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 17.0 (TID 86). 1291 bytes result sent to driver
2021-12-08 10:04:17,136 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 17.0 (TID 85) in 527 ms on localhost (executor driver) (1/2)
2021-12-08 10:04:17,136 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 17.0 (TID 86) in 526 ms on localhost (executor driver) (2/2)
2021-12-08 10:04:17,136 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 17.0, whose tasks have all completed, from pool 
2021-12-08 10:04:17,136 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ShuffleMapStage 17 (map at PaidPromotionAdjustParameter.scala:289) finished in 0.532 s
2021-12-08 10:04:17,136 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - looking for newly runnable stages
2021-12-08 10:04:17,136 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - running: Set(ShuffleMapStage 19)
2021-12-08 10:04:17,136 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - waiting: Set(ShuffleMapStage 20, ResultStage 25)
2021-12-08 10:04:17,136 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - failed: Set()
2021-12-08 10:04:25,439 [Executor task launch worker for task 64] INFO [org.apache.spark.executor.Executor] - Finished task 4.0 in stage 19.0 (TID 64). 911 bytes result sent to driver
2021-12-08 10:04:25,440 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 4.0 in stage 19.0 (TID 64) in 12240 ms on localhost (executor driver) (1/10)
2021-12-08 10:04:25,633 [Executor task launch worker for task 65] INFO [org.apache.spark.executor.Executor] - Finished task 5.0 in stage 19.0 (TID 65). 868 bytes result sent to driver
2021-12-08 10:04:25,633 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 5.0 in stage 19.0 (TID 65) in 12432 ms on localhost (executor driver) (2/10)
2021-12-08 10:04:33,461 [Executor task launch worker for task 69] INFO [org.apache.spark.executor.Executor] - Finished task 9.0 in stage 19.0 (TID 69). 868 bytes result sent to driver
2021-12-08 10:04:33,461 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 9.0 in stage 19.0 (TID 69) in 19921 ms on localhost (executor driver) (3/10)
2021-12-08 10:04:33,532 [Executor task launch worker for task 63] INFO [org.apache.spark.executor.Executor] - Finished task 3.0 in stage 19.0 (TID 63). 911 bytes result sent to driver
2021-12-08 10:04:33,532 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 3.0 in stage 19.0 (TID 63) in 20332 ms on localhost (executor driver) (4/10)
2021-12-08 10:04:36,782 [Executor task launch worker for task 60] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 19.0 (TID 60). 911 bytes result sent to driver
2021-12-08 10:04:36,782 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 19.0 (TID 60) in 23582 ms on localhost (executor driver) (5/10)
2021-12-08 10:04:38,242 [Executor task launch worker for task 67] INFO [org.apache.spark.executor.Executor] - Finished task 7.0 in stage 19.0 (TID 67). 868 bytes result sent to driver
2021-12-08 10:04:38,243 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 7.0 in stage 19.0 (TID 67) in 25042 ms on localhost (executor driver) (6/10)
2021-12-08 10:04:38,269 [Executor task launch worker for task 66] INFO [org.apache.spark.executor.Executor] - Finished task 6.0 in stage 19.0 (TID 66). 911 bytes result sent to driver
2021-12-08 10:04:38,269 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 6.0 in stage 19.0 (TID 66) in 25068 ms on localhost (executor driver) (7/10)
2021-12-08 10:04:39,963 [Executor task launch worker for task 68] INFO [org.apache.spark.executor.Executor] - Finished task 8.0 in stage 19.0 (TID 68). 868 bytes result sent to driver
2021-12-08 10:04:39,963 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 8.0 in stage 19.0 (TID 68) in 26489 ms on localhost (executor driver) (8/10)
2021-12-08 10:04:41,743 [Executor task launch worker for task 61] INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 19.0 (TID 61). 911 bytes result sent to driver
2021-12-08 10:04:41,744 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 19.0 (TID 61) in 28544 ms on localhost (executor driver) (9/10)
2021-12-08 10:04:41,919 [Executor task launch worker for task 62] INFO [org.apache.spark.executor.Executor] - Finished task 2.0 in stage 19.0 (TID 62). 911 bytes result sent to driver
2021-12-08 10:04:41,919 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 2.0 in stage 19.0 (TID 62) in 28719 ms on localhost (executor driver) (10/10)
2021-12-08 10:04:41,919 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 19.0, whose tasks have all completed, from pool 
2021-12-08 10:04:41,919 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ShuffleMapStage 19 (map at PaidPromotionAdjustParameter.scala:265) finished in 28.730 s
2021-12-08 10:04:41,919 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - looking for newly runnable stages
2021-12-08 10:04:41,919 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - running: Set()
2021-12-08 10:04:41,919 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - waiting: Set(ShuffleMapStage 20, ResultStage 25)
2021-12-08 10:04:41,919 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - failed: Set()
2021-12-08 10:04:41,919 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ShuffleMapStage 20 (MapPartitionsRDD[39] at map at PaidPromotionAdjustParameter.scala:298), which has no missing parents
2021-12-08 10:04:41,920 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_20 stored as values in memory (estimated size 3.6 KB, free 1990.1 MB)
2021-12-08 10:04:41,921 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_20_piece0 stored as bytes in memory (estimated size 2.1 KB, free 1990.1 MB)
2021-12-08 10:04:41,922 [dispatcher-event-loop-1] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_20_piece0 in memory on qb:55588 (size: 2.1 KB, free: 1990.7 MB)
2021-12-08 10:04:41,922 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 20 from broadcast at DAGScheduler.scala:1039
2021-12-08 10:04:41,922 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 10 missing tasks from ShuffleMapStage 20 (MapPartitionsRDD[39] at map at PaidPromotionAdjustParameter.scala:298) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
2021-12-08 10:04:41,922 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 20.0 with 10 tasks
2021-12-08 10:04:41,923 [dispatcher-event-loop-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 20.0 (TID 87, localhost, executor driver, partition 0, PROCESS_LOCAL, 7701 bytes)
2021-12-08 10:04:41,923 [dispatcher-event-loop-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 20.0 (TID 88, localhost, executor driver, partition 1, PROCESS_LOCAL, 7701 bytes)
2021-12-08 10:04:41,923 [dispatcher-event-loop-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 2.0 in stage 20.0 (TID 89, localhost, executor driver, partition 2, PROCESS_LOCAL, 7701 bytes)
2021-12-08 10:04:41,923 [dispatcher-event-loop-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 3.0 in stage 20.0 (TID 90, localhost, executor driver, partition 3, PROCESS_LOCAL, 7701 bytes)
2021-12-08 10:04:41,923 [dispatcher-event-loop-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 4.0 in stage 20.0 (TID 91, localhost, executor driver, partition 4, PROCESS_LOCAL, 7701 bytes)
2021-12-08 10:04:41,923 [dispatcher-event-loop-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 5.0 in stage 20.0 (TID 92, localhost, executor driver, partition 5, PROCESS_LOCAL, 7701 bytes)
2021-12-08 10:04:41,923 [dispatcher-event-loop-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 6.0 in stage 20.0 (TID 93, localhost, executor driver, partition 6, PROCESS_LOCAL, 7701 bytes)
2021-12-08 10:04:41,923 [dispatcher-event-loop-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 7.0 in stage 20.0 (TID 94, localhost, executor driver, partition 7, PROCESS_LOCAL, 7701 bytes)
2021-12-08 10:04:41,923 [dispatcher-event-loop-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 8.0 in stage 20.0 (TID 95, localhost, executor driver, partition 8, PROCESS_LOCAL, 7701 bytes)
2021-12-08 10:04:41,923 [dispatcher-event-loop-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 9.0 in stage 20.0 (TID 96, localhost, executor driver, partition 9, PROCESS_LOCAL, 7701 bytes)
2021-12-08 10:04:41,923 [Executor task launch worker for task 87] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 20.0 (TID 87)
2021-12-08 10:04:41,923 [Executor task launch worker for task 90] INFO [org.apache.spark.executor.Executor] - Running task 3.0 in stage 20.0 (TID 90)
2021-12-08 10:04:41,923 [Executor task launch worker for task 96] INFO [org.apache.spark.executor.Executor] - Running task 9.0 in stage 20.0 (TID 96)
2021-12-08 10:04:41,923 [Executor task launch worker for task 93] INFO [org.apache.spark.executor.Executor] - Running task 6.0 in stage 20.0 (TID 93)
2021-12-08 10:04:41,923 [Executor task launch worker for task 95] INFO [org.apache.spark.executor.Executor] - Running task 8.0 in stage 20.0 (TID 95)
2021-12-08 10:04:41,923 [Executor task launch worker for task 94] INFO [org.apache.spark.executor.Executor] - Running task 7.0 in stage 20.0 (TID 94)
2021-12-08 10:04:41,923 [Executor task launch worker for task 91] INFO [org.apache.spark.executor.Executor] - Running task 4.0 in stage 20.0 (TID 91)
2021-12-08 10:04:41,923 [Executor task launch worker for task 92] INFO [org.apache.spark.executor.Executor] - Running task 5.0 in stage 20.0 (TID 92)
2021-12-08 10:04:41,923 [Executor task launch worker for task 89] INFO [org.apache.spark.executor.Executor] - Running task 2.0 in stage 20.0 (TID 89)
2021-12-08 10:04:41,923 [Executor task launch worker for task 88] INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 20.0 (TID 88)
2021-12-08 10:04:41,925 [Executor task launch worker for task 88] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 10 non-empty blocks out of 10 blocks
2021-12-08 10:04:41,925 [Executor task launch worker for task 95] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 10 non-empty blocks out of 10 blocks
2021-12-08 10:04:41,925 [Executor task launch worker for task 88] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-08 10:04:41,925 [Executor task launch worker for task 89] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 10 non-empty blocks out of 10 blocks
2021-12-08 10:04:41,925 [Executor task launch worker for task 89] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-08 10:04:41,925 [Executor task launch worker for task 91] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 10 non-empty blocks out of 10 blocks
2021-12-08 10:04:41,925 [Executor task launch worker for task 92] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 10 non-empty blocks out of 10 blocks
2021-12-08 10:04:41,925 [Executor task launch worker for task 95] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-08 10:04:41,925 [Executor task launch worker for task 94] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 10 non-empty blocks out of 10 blocks
2021-12-08 10:04:41,925 [Executor task launch worker for task 92] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-08 10:04:41,925 [Executor task launch worker for task 91] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-08 10:04:41,925 [Executor task launch worker for task 87] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 10 non-empty blocks out of 10 blocks
2021-12-08 10:04:41,925 [Executor task launch worker for task 90] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 10 non-empty blocks out of 10 blocks
2021-12-08 10:04:41,925 [Executor task launch worker for task 93] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 10 non-empty blocks out of 10 blocks
2021-12-08 10:04:41,925 [Executor task launch worker for task 90] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-08 10:04:41,925 [Executor task launch worker for task 87] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-08 10:04:41,925 [Executor task launch worker for task 94] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-08 10:04:41,925 [Executor task launch worker for task 93] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-08 10:04:41,925 [Executor task launch worker for task 96] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 10 non-empty blocks out of 10 blocks
2021-12-08 10:04:41,925 [Executor task launch worker for task 96] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-08 10:04:41,930 [Executor task launch worker for task 88] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 1 blocks
2021-12-08 10:04:41,930 [Executor task launch worker for task 93] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 1 blocks
2021-12-08 10:04:41,930 [Executor task launch worker for task 88] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-08 10:04:41,930 [Executor task launch worker for task 93] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-08 10:04:41,930 [Executor task launch worker for task 95] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 1 blocks
2021-12-08 10:04:41,930 [Executor task launch worker for task 95] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-08 10:04:41,931 [Executor task launch worker for task 96] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 1 blocks
2021-12-08 10:04:41,931 [Executor task launch worker for task 96] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 1 ms
2021-12-08 10:04:41,931 [Executor task launch worker for task 89] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 1 blocks
2021-12-08 10:04:41,931 [Executor task launch worker for task 89] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-08 10:04:41,931 [Executor task launch worker for task 91] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 1 blocks
2021-12-08 10:04:41,931 [Executor task launch worker for task 91] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-08 10:04:41,931 [Executor task launch worker for task 94] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 1 blocks
2021-12-08 10:04:41,931 [Executor task launch worker for task 94] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-08 10:04:41,931 [Executor task launch worker for task 92] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 1 blocks
2021-12-08 10:04:41,931 [Executor task launch worker for task 92] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-08 10:04:41,931 [Executor task launch worker for task 90] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 1 blocks
2021-12-08 10:04:41,931 [Executor task launch worker for task 90] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-08 10:04:41,932 [Executor task launch worker for task 87] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 1 blocks
2021-12-08 10:04:41,932 [Executor task launch worker for task 87] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 1 ms
2021-12-08 10:04:42,825 [dispatcher-event-loop-7] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_16_piece0 on qb:55588 in memory (size: 2.7 KB, free: 1990.7 MB)
2021-12-08 10:04:42,826 [dispatcher-event-loop-11] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_19_piece0 on qb:55588 in memory (size: 2.1 KB, free: 1990.7 MB)
2021-12-08 10:04:44,824 [Executor task launch worker for task 90] INFO [org.apache.spark.executor.Executor] - Finished task 3.0 in stage 20.0 (TID 90). 1257 bytes result sent to driver
2021-12-08 10:04:44,824 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 3.0 in stage 20.0 (TID 90) in 2901 ms on localhost (executor driver) (1/10)
2021-12-08 10:04:44,826 [Executor task launch worker for task 92] INFO [org.apache.spark.executor.Executor] - Finished task 5.0 in stage 20.0 (TID 92). 1257 bytes result sent to driver
2021-12-08 10:04:44,827 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 5.0 in stage 20.0 (TID 92) in 2904 ms on localhost (executor driver) (2/10)
2021-12-08 10:04:44,838 [Executor task launch worker for task 87] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 20.0 (TID 87). 1257 bytes result sent to driver
2021-12-08 10:04:44,838 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 20.0 (TID 87) in 2916 ms on localhost (executor driver) (3/10)
2021-12-08 10:04:44,844 [Executor task launch worker for task 96] INFO [org.apache.spark.executor.Executor] - Finished task 9.0 in stage 20.0 (TID 96). 1257 bytes result sent to driver
2021-12-08 10:04:44,844 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 9.0 in stage 20.0 (TID 96) in 2921 ms on localhost (executor driver) (4/10)
2021-12-08 10:04:44,863 [Executor task launch worker for task 94] INFO [org.apache.spark.executor.Executor] - Finished task 7.0 in stage 20.0 (TID 94). 1214 bytes result sent to driver
2021-12-08 10:04:44,863 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 7.0 in stage 20.0 (TID 94) in 2940 ms on localhost (executor driver) (5/10)
2021-12-08 10:04:44,864 [Executor task launch worker for task 93] INFO [org.apache.spark.executor.Executor] - Finished task 6.0 in stage 20.0 (TID 93). 1214 bytes result sent to driver
2021-12-08 10:04:44,864 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 6.0 in stage 20.0 (TID 93) in 2941 ms on localhost (executor driver) (6/10)
2021-12-08 10:04:44,869 [Executor task launch worker for task 91] INFO [org.apache.spark.executor.Executor] - Finished task 4.0 in stage 20.0 (TID 91). 1257 bytes result sent to driver
2021-12-08 10:04:44,870 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 4.0 in stage 20.0 (TID 91) in 2946 ms on localhost (executor driver) (7/10)
2021-12-08 10:04:44,875 [Executor task launch worker for task 95] INFO [org.apache.spark.executor.Executor] - Finished task 8.0 in stage 20.0 (TID 95). 1214 bytes result sent to driver
2021-12-08 10:04:44,875 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 8.0 in stage 20.0 (TID 95) in 2952 ms on localhost (executor driver) (8/10)
2021-12-08 10:04:44,897 [Executor task launch worker for task 89] INFO [org.apache.spark.executor.Executor] - Finished task 2.0 in stage 20.0 (TID 89). 1257 bytes result sent to driver
2021-12-08 10:04:44,897 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 2.0 in stage 20.0 (TID 89) in 2974 ms on localhost (executor driver) (9/10)
2021-12-08 10:04:44,916 [Executor task launch worker for task 88] INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 20.0 (TID 88). 1257 bytes result sent to driver
2021-12-08 10:04:44,916 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 20.0 (TID 88) in 2993 ms on localhost (executor driver) (10/10)
2021-12-08 10:04:44,916 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 20.0, whose tasks have all completed, from pool 
2021-12-08 10:04:44,916 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ShuffleMapStage 20 (map at PaidPromotionAdjustParameter.scala:298) finished in 2.996 s
2021-12-08 10:04:44,916 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - looking for newly runnable stages
2021-12-08 10:04:44,916 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - running: Set()
2021-12-08 10:04:44,916 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - waiting: Set(ResultStage 25)
2021-12-08 10:04:44,916 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - failed: Set()
2021-12-08 10:04:44,916 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 25 (MapPartitionsRDD[48] at saveAsTextFile at PaidPromotionAdjustParameter.scala:311), which has no missing parents
2021-12-08 10:04:44,926 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_21 stored as values in memory (estimated size 81.5 KB, free 1990.1 MB)
2021-12-08 10:04:44,928 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_21_piece0 stored as bytes in memory (estimated size 31.2 KB, free 1990.0 MB)
2021-12-08 10:04:44,928 [dispatcher-event-loop-4] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_21_piece0 in memory on qb:55588 (size: 31.2 KB, free: 1990.7 MB)
2021-12-08 10:04:44,928 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 21 from broadcast at DAGScheduler.scala:1039
2021-12-08 10:04:44,928 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 10 missing tasks from ResultStage 25 (MapPartitionsRDD[48] at saveAsTextFile at PaidPromotionAdjustParameter.scala:311) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
2021-12-08 10:04:44,928 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 25.0 with 10 tasks
2021-12-08 10:04:44,930 [dispatcher-event-loop-10] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 25.0 (TID 97, localhost, executor driver, partition 0, PROCESS_LOCAL, 8097 bytes)
2021-12-08 10:04:44,931 [dispatcher-event-loop-10] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 25.0 (TID 98, localhost, executor driver, partition 1, PROCESS_LOCAL, 8146 bytes)
2021-12-08 10:04:44,931 [dispatcher-event-loop-10] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 2.0 in stage 25.0 (TID 99, localhost, executor driver, partition 2, PROCESS_LOCAL, 8097 bytes)
2021-12-08 10:04:44,931 [dispatcher-event-loop-10] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 3.0 in stage 25.0 (TID 100, localhost, executor driver, partition 3, PROCESS_LOCAL, 8146 bytes)
2021-12-08 10:04:44,931 [dispatcher-event-loop-10] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 4.0 in stage 25.0 (TID 101, localhost, executor driver, partition 4, PROCESS_LOCAL, 8097 bytes)
2021-12-08 10:04:44,931 [dispatcher-event-loop-10] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 5.0 in stage 25.0 (TID 102, localhost, executor driver, partition 5, PROCESS_LOCAL, 8146 bytes)
2021-12-08 10:04:44,931 [dispatcher-event-loop-10] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 6.0 in stage 25.0 (TID 103, localhost, executor driver, partition 6, PROCESS_LOCAL, 8097 bytes)
2021-12-08 10:04:44,931 [dispatcher-event-loop-10] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 7.0 in stage 25.0 (TID 104, localhost, executor driver, partition 7, PROCESS_LOCAL, 8146 bytes)
2021-12-08 10:04:44,931 [dispatcher-event-loop-10] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 8.0 in stage 25.0 (TID 105, localhost, executor driver, partition 8, PROCESS_LOCAL, 8097 bytes)
2021-12-08 10:04:44,931 [dispatcher-event-loop-10] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 9.0 in stage 25.0 (TID 106, localhost, executor driver, partition 9, PROCESS_LOCAL, 8146 bytes)
2021-12-08 10:04:44,932 [Executor task launch worker for task 100] INFO [org.apache.spark.executor.Executor] - Running task 3.0 in stage 25.0 (TID 100)
2021-12-08 10:04:44,932 [Executor task launch worker for task 99] INFO [org.apache.spark.executor.Executor] - Running task 2.0 in stage 25.0 (TID 99)
2021-12-08 10:04:44,932 [Executor task launch worker for task 102] INFO [org.apache.spark.executor.Executor] - Running task 5.0 in stage 25.0 (TID 102)
2021-12-08 10:04:44,932 [Executor task launch worker for task 97] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 25.0 (TID 97)
2021-12-08 10:04:44,932 [Executor task launch worker for task 98] INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 25.0 (TID 98)
2021-12-08 10:04:44,932 [Executor task launch worker for task 103] INFO [org.apache.spark.executor.Executor] - Running task 6.0 in stage 25.0 (TID 103)
2021-12-08 10:04:44,932 [Executor task launch worker for task 104] INFO [org.apache.spark.executor.Executor] - Running task 7.0 in stage 25.0 (TID 104)
2021-12-08 10:04:44,932 [Executor task launch worker for task 101] INFO [org.apache.spark.executor.Executor] - Running task 4.0 in stage 25.0 (TID 101)
2021-12-08 10:04:44,932 [Executor task launch worker for task 105] INFO [org.apache.spark.executor.Executor] - Running task 8.0 in stage 25.0 (TID 105)
2021-12-08 10:04:44,932 [Executor task launch worker for task 106] INFO [org.apache.spark.executor.Executor] - Running task 9.0 in stage 25.0 (TID 106)
2021-12-08 10:04:44,952 [Executor task launch worker for task 106] INFO [org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter] - File Output Committer Algorithm version is 1
2021-12-08 10:04:44,952 [Executor task launch worker for task 104] INFO [org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter] - File Output Committer Algorithm version is 1
2021-12-08 10:04:44,952 [Executor task launch worker for task 103] INFO [org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter] - File Output Committer Algorithm version is 1
2021-12-08 10:04:44,952 [Executor task launch worker for task 98] INFO [org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter] - File Output Committer Algorithm version is 1
2021-12-08 10:04:44,952 [Executor task launch worker for task 102] INFO [org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter] - File Output Committer Algorithm version is 1
2021-12-08 10:04:44,952 [Executor task launch worker for task 100] INFO [org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter] - File Output Committer Algorithm version is 1
2021-12-08 10:04:44,953 [Executor task launch worker for task 97] INFO [org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter] - File Output Committer Algorithm version is 1
2021-12-08 10:04:44,953 [Executor task launch worker for task 99] INFO [org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter] - File Output Committer Algorithm version is 1
2021-12-08 10:04:44,953 [Executor task launch worker for task 101] INFO [org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter] - File Output Committer Algorithm version is 1
2021-12-08 10:04:44,954 [Executor task launch worker for task 105] INFO [org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter] - File Output Committer Algorithm version is 1
2021-12-08 10:04:44,994 [Executor task launch worker for task 101] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 10 non-empty blocks out of 10 blocks
2021-12-08 10:04:44,994 [Executor task launch worker for task 101] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-08 10:04:44,996 [Executor task launch worker for task 100] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 10 non-empty blocks out of 10 blocks
2021-12-08 10:04:44,996 [Executor task launch worker for task 100] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-08 10:04:44,996 [Executor task launch worker for task 99] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 10 non-empty blocks out of 10 blocks
2021-12-08 10:04:44,996 [Executor task launch worker for task 99] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-08 10:04:44,996 [Executor task launch worker for task 104] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 10 non-empty blocks out of 10 blocks
2021-12-08 10:04:44,996 [Executor task launch worker for task 104] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-08 10:04:44,996 [Executor task launch worker for task 105] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 10 non-empty blocks out of 10 blocks
2021-12-08 10:04:44,996 [Executor task launch worker for task 105] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-08 10:04:44,996 [Executor task launch worker for task 106] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 10 non-empty blocks out of 10 blocks
2021-12-08 10:04:44,996 [Executor task launch worker for task 97] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 2 non-empty blocks out of 2 blocks
2021-12-08 10:04:44,996 [Executor task launch worker for task 106] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-08 10:04:44,996 [Executor task launch worker for task 97] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-08 10:04:44,996 [Executor task launch worker for task 103] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 10 non-empty blocks out of 10 blocks
2021-12-08 10:04:44,996 [Executor task launch worker for task 103] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-08 10:04:44,997 [Executor task launch worker for task 98] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 2 non-empty blocks out of 2 blocks
2021-12-08 10:04:44,997 [Executor task launch worker for task 98] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-08 10:04:44,997 [Executor task launch worker for task 102] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 10 non-empty blocks out of 10 blocks
2021-12-08 10:04:44,997 [Executor task launch worker for task 102] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-08 10:04:44,999 [Executor task launch worker for task 98] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 3 blocks
2021-12-08 10:04:44,999 [Executor task launch worker for task 97] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 3 blocks
2021-12-08 10:04:44,999 [Executor task launch worker for task 98] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-08 10:04:44,999 [Executor task launch worker for task 97] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-08 10:04:45,000 [Executor task launch worker for task 101] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 12 blocks
2021-12-08 10:04:45,000 [Executor task launch worker for task 101] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-08 10:04:45,001 [Executor task launch worker for task 99] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 12 blocks
2021-12-08 10:04:45,001 [Executor task launch worker for task 99] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-08 10:04:45,002 [Executor task launch worker for task 100] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 12 blocks
2021-12-08 10:04:45,002 [Executor task launch worker for task 100] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-08 10:04:45,002 [Executor task launch worker for task 105] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 12 blocks
2021-12-08 10:04:45,002 [Executor task launch worker for task 105] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-08 10:04:45,002 [Executor task launch worker for task 106] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 12 blocks
2021-12-08 10:04:45,002 [Executor task launch worker for task 106] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-08 10:04:45,003 [Executor task launch worker for task 103] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 12 blocks
2021-12-08 10:04:45,003 [Executor task launch worker for task 103] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-08 10:04:45,003 [Executor task launch worker for task 102] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 12 blocks
2021-12-08 10:04:45,003 [Executor task launch worker for task 102] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-08 10:04:45,004 [Executor task launch worker for task 104] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 12 blocks
2021-12-08 10:04:45,004 [Executor task launch worker for task 104] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-08 10:04:45,099 [Executor task launch worker for task 98] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 2 non-empty blocks out of 2 blocks
2021-12-08 10:04:45,099 [Executor task launch worker for task 98] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-08 10:04:45,108 [Executor task launch worker for task 98] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 3 blocks
2021-12-08 10:04:45,108 [Executor task launch worker for task 98] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-08 10:04:45,396 [Executor task launch worker for task 97] INFO [org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter] - Saved output of task 'attempt_20211208100413_0048_m_000000_0' to hdfs://hdp1:8020/sk/chongqing/model/input/rating/_temporary/0/task_20211208100413_0048_m_000000
2021-12-08 10:04:45,396 [Executor task launch worker for task 97] INFO [org.apache.spark.mapred.SparkHadoopMapRedUtil] - attempt_20211208100413_0048_m_000000_0: Committed
2021-12-08 10:04:45,399 [Executor task launch worker for task 97] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 25.0 (TID 97). 1385 bytes result sent to driver
2021-12-08 10:04:45,404 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 25.0 (TID 97) in 476 ms on localhost (executor driver) (1/10)
2021-12-08 10:04:45,597 [Executor task launch worker for task 98] INFO [org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter] - Saved output of task 'attempt_20211208100413_0048_m_000001_0' to hdfs://hdp1:8020/sk/chongqing/model/input/rating/_temporary/0/task_20211208100413_0048_m_000001
2021-12-08 10:04:45,597 [Executor task launch worker for task 98] INFO [org.apache.spark.mapred.SparkHadoopMapRedUtil] - attempt_20211208100413_0048_m_000001_0: Committed
2021-12-08 10:04:45,599 [Executor task launch worker for task 98] INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 25.0 (TID 98). 1385 bytes result sent to driver
2021-12-08 10:04:45,601 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 25.0 (TID 98) in 670 ms on localhost (executor driver) (2/10)
2021-12-08 10:04:46,131 [dispatcher-event-loop-0] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_20_piece0 on qb:55588 in memory (size: 2.1 KB, free: 1990.7 MB)
2021-12-08 10:04:47,588 [Executor task launch worker for task 100] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 10 non-empty blocks out of 10 blocks
2021-12-08 10:04:47,588 [Executor task launch worker for task 100] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-08 10:04:47,594 [Executor task launch worker for task 100] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 12 blocks
2021-12-08 10:04:47,594 [Executor task launch worker for task 100] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 1 ms
2021-12-08 10:04:47,682 [Executor task launch worker for task 106] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 10 non-empty blocks out of 10 blocks
2021-12-08 10:04:47,683 [Executor task launch worker for task 106] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 1 ms
2021-12-08 10:04:47,691 [Executor task launch worker for task 106] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 12 blocks
2021-12-08 10:04:47,691 [Executor task launch worker for task 106] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-08 10:04:47,816 [Executor task launch worker for task 104] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 10 non-empty blocks out of 10 blocks
2021-12-08 10:04:47,816 [Executor task launch worker for task 104] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-08 10:04:47,821 [Executor task launch worker for task 104] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 12 blocks
2021-12-08 10:04:47,821 [Executor task launch worker for task 104] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-08 10:04:48,464 [Executor task launch worker for task 102] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 10 non-empty blocks out of 10 blocks
2021-12-08 10:04:48,464 [Executor task launch worker for task 102] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-08 10:04:48,468 [Executor task launch worker for task 102] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 12 blocks
2021-12-08 10:04:48,468 [Executor task launch worker for task 102] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-08 10:04:51,783 [Executor task launch worker for task 99] INFO [org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter] - Saved output of task 'attempt_20211208100413_0048_m_000002_0' to hdfs://hdp1:8020/sk/chongqing/model/input/rating/_temporary/0/task_20211208100413_0048_m_000002
2021-12-08 10:04:51,783 [Executor task launch worker for task 99] INFO [org.apache.spark.mapred.SparkHadoopMapRedUtil] - attempt_20211208100413_0048_m_000002_0: Committed
2021-12-08 10:04:51,784 [Executor task launch worker for task 99] INFO [org.apache.spark.executor.Executor] - Finished task 2.0 in stage 25.0 (TID 99). 1299 bytes result sent to driver
2021-12-08 10:04:51,785 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 2.0 in stage 25.0 (TID 99) in 6854 ms on localhost (executor driver) (3/10)
2021-12-08 10:04:52,324 [Executor task launch worker for task 103] INFO [org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter] - Saved output of task 'attempt_20211208100413_0048_m_000006_0' to hdfs://hdp1:8020/sk/chongqing/model/input/rating/_temporary/0/task_20211208100413_0048_m_000006
2021-12-08 10:04:52,324 [Executor task launch worker for task 103] INFO [org.apache.spark.mapred.SparkHadoopMapRedUtil] - attempt_20211208100413_0048_m_000006_0: Committed
2021-12-08 10:04:52,326 [Executor task launch worker for task 103] INFO [org.apache.spark.executor.Executor] - Finished task 6.0 in stage 25.0 (TID 103). 1342 bytes result sent to driver
2021-12-08 10:04:52,327 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 6.0 in stage 25.0 (TID 103) in 7396 ms on localhost (executor driver) (4/10)
2021-12-08 10:04:52,505 [Executor task launch worker for task 101] INFO [org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter] - Saved output of task 'attempt_20211208100413_0048_m_000004_0' to hdfs://hdp1:8020/sk/chongqing/model/input/rating/_temporary/0/task_20211208100413_0048_m_000004
2021-12-08 10:04:52,505 [Executor task launch worker for task 101] INFO [org.apache.spark.mapred.SparkHadoopMapRedUtil] - attempt_20211208100413_0048_m_000004_0: Committed
2021-12-08 10:04:52,506 [Executor task launch worker for task 101] INFO [org.apache.spark.executor.Executor] - Finished task 4.0 in stage 25.0 (TID 101). 1342 bytes result sent to driver
2021-12-08 10:04:52,507 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 4.0 in stage 25.0 (TID 101) in 7576 ms on localhost (executor driver) (5/10)
2021-12-08 10:04:55,095 [Executor task launch worker for task 105] INFO [org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter] - Saved output of task 'attempt_20211208100413_0048_m_000008_0' to hdfs://hdp1:8020/sk/chongqing/model/input/rating/_temporary/0/task_20211208100413_0048_m_000008
2021-12-08 10:04:55,096 [Executor task launch worker for task 105] INFO [org.apache.spark.mapred.SparkHadoopMapRedUtil] - attempt_20211208100413_0048_m_000008_0: Committed
2021-12-08 10:04:55,097 [Executor task launch worker for task 105] INFO [org.apache.spark.executor.Executor] - Finished task 8.0 in stage 25.0 (TID 105). 1342 bytes result sent to driver
2021-12-08 10:04:55,097 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 8.0 in stage 25.0 (TID 105) in 10166 ms on localhost (executor driver) (6/10)
2021-12-08 10:04:55,104 [Executor task launch worker for task 100] INFO [org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter] - Saved output of task 'attempt_20211208100413_0048_m_000003_0' to hdfs://hdp1:8020/sk/chongqing/model/input/rating/_temporary/0/task_20211208100413_0048_m_000003
2021-12-08 10:04:55,104 [Executor task launch worker for task 100] INFO [org.apache.spark.mapred.SparkHadoopMapRedUtil] - attempt_20211208100413_0048_m_000003_0: Committed
2021-12-08 10:04:55,105 [Executor task launch worker for task 100] INFO [org.apache.spark.executor.Executor] - Finished task 3.0 in stage 25.0 (TID 100). 1299 bytes result sent to driver
2021-12-08 10:04:55,105 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 3.0 in stage 25.0 (TID 100) in 10174 ms on localhost (executor driver) (7/10)
2021-12-08 10:04:55,912 [Executor task launch worker for task 102] INFO [org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter] - Saved output of task 'attempt_20211208100413_0048_m_000005_0' to hdfs://hdp1:8020/sk/chongqing/model/input/rating/_temporary/0/task_20211208100413_0048_m_000005
2021-12-08 10:04:55,912 [Executor task launch worker for task 102] INFO [org.apache.spark.mapred.SparkHadoopMapRedUtil] - attempt_20211208100413_0048_m_000005_0: Committed
2021-12-08 10:04:55,913 [Executor task launch worker for task 102] INFO [org.apache.spark.executor.Executor] - Finished task 5.0 in stage 25.0 (TID 102). 1342 bytes result sent to driver
2021-12-08 10:04:55,914 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 5.0 in stage 25.0 (TID 102) in 10983 ms on localhost (executor driver) (8/10)
2021-12-08 10:04:56,037 [Executor task launch worker for task 104] INFO [org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter] - Saved output of task 'attempt_20211208100413_0048_m_000007_0' to hdfs://hdp1:8020/sk/chongqing/model/input/rating/_temporary/0/task_20211208100413_0048_m_000007
2021-12-08 10:04:56,037 [Executor task launch worker for task 104] INFO [org.apache.spark.mapred.SparkHadoopMapRedUtil] - attempt_20211208100413_0048_m_000007_0: Committed
2021-12-08 10:04:56,039 [Executor task launch worker for task 104] INFO [org.apache.spark.executor.Executor] - Finished task 7.0 in stage 25.0 (TID 104). 1342 bytes result sent to driver
2021-12-08 10:04:56,039 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 7.0 in stage 25.0 (TID 104) in 11108 ms on localhost (executor driver) (9/10)
2021-12-08 10:04:56,121 [Executor task launch worker for task 106] INFO [org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter] - Saved output of task 'attempt_20211208100413_0048_m_000009_0' to hdfs://hdp1:8020/sk/chongqing/model/input/rating/_temporary/0/task_20211208100413_0048_m_000009
2021-12-08 10:04:56,121 [Executor task launch worker for task 106] INFO [org.apache.spark.mapred.SparkHadoopMapRedUtil] - attempt_20211208100413_0048_m_000009_0: Committed
2021-12-08 10:04:56,122 [Executor task launch worker for task 106] INFO [org.apache.spark.executor.Executor] - Finished task 9.0 in stage 25.0 (TID 106). 1342 bytes result sent to driver
2021-12-08 10:04:56,122 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 9.0 in stage 25.0 (TID 106) in 11191 ms on localhost (executor driver) (10/10)
2021-12-08 10:04:56,122 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 25.0, whose tasks have all completed, from pool 
2021-12-08 10:04:56,122 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 25 (runJob at SparkHadoopWriter.scala:78) finished in 11.205 s
2021-12-08 10:04:56,123 [main] INFO [org.apache.spark.scheduler.DAGScheduler] - Job 7 finished: runJob at SparkHadoopWriter.scala:78, took 42.948275 s
2021-12-08 10:04:56,250 [main] INFO [org.apache.spark.internal.io.SparkHadoopWriter] - Job job_20211208100413_0048 committed.
2021-12-08 10:04:56,257 [main] INFO [org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter] - File Output Committer Algorithm version is 1
2021-12-08 10:04:56,274 [main] INFO [org.apache.spark.SparkContext] - Starting job: runJob at SparkHadoopWriter.scala:78
2021-12-08 10:04:56,275 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 8 (runJob at SparkHadoopWriter.scala:78) with 1 output partitions
2021-12-08 10:04:56,275 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 27 (runJob at SparkHadoopWriter.scala:78)
2021-12-08 10:04:56,275 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 26)
2021-12-08 10:04:56,275 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2021-12-08 10:04:56,275 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 27 (MapPartitionsRDD[51] at saveAsTextFile at PaidPromotionAdjustParameter.scala:312), which has no missing parents
2021-12-08 10:04:56,282 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_22 stored as values in memory (estimated size 80.5 KB, free 1989.9 MB)
2021-12-08 10:04:56,283 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_22_piece0 stored as bytes in memory (estimated size 30.8 KB, free 1989.9 MB)
2021-12-08 10:04:56,284 [dispatcher-event-loop-10] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_22_piece0 in memory on qb:55588 (size: 30.8 KB, free: 1990.7 MB)
2021-12-08 10:04:56,284 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 22 from broadcast at DAGScheduler.scala:1039
2021-12-08 10:04:56,284 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 27 (MapPartitionsRDD[51] at saveAsTextFile at PaidPromotionAdjustParameter.scala:312) (first 15 tasks are for partitions Vector(0))
2021-12-08 10:04:56,284 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 27.0 with 1 tasks
2021-12-08 10:04:56,285 [dispatcher-event-loop-8] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 27.0 (TID 107, localhost, executor driver, partition 0, ANY, 8107 bytes)
2021-12-08 10:04:56,285 [Executor task launch worker for task 107] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 27.0 (TID 107)
2021-12-08 10:04:56,288 [Executor task launch worker for task 107] INFO [org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter] - File Output Committer Algorithm version is 1
2021-12-08 10:04:56,302 [Executor task launch worker for task 107] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 2 non-empty blocks out of 2 blocks
2021-12-08 10:04:56,302 [Executor task launch worker for task 107] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-08 10:04:56,305 [Executor task launch worker for task 107] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 2 non-empty blocks out of 2 blocks
2021-12-08 10:04:56,306 [Executor task launch worker for task 107] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 1 ms
2021-12-08 10:04:56,308 [Executor task launch worker for task 107] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 2 non-empty blocks out of 2 blocks
2021-12-08 10:04:56,308 [Executor task launch worker for task 107] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-08 10:04:56,387 [Executor task launch worker for task 107] INFO [org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter] - Saved output of task 'attempt_20211208100456_0051_m_000000_0' to hdfs://hdp1:8020/sk/chongqing/model/input/productionWithIndex/_temporary/0/task_20211208100456_0051_m_000000
2021-12-08 10:04:56,387 [Executor task launch worker for task 107] INFO [org.apache.spark.mapred.SparkHadoopMapRedUtil] - attempt_20211208100456_0051_m_000000_0: Committed
2021-12-08 10:04:56,388 [Executor task launch worker for task 107] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 27.0 (TID 107). 1299 bytes result sent to driver
2021-12-08 10:04:56,388 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 27.0 (TID 107) in 104 ms on localhost (executor driver) (1/1)
2021-12-08 10:04:56,388 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 27.0, whose tasks have all completed, from pool 
2021-12-08 10:04:56,389 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 27 (runJob at SparkHadoopWriter.scala:78) finished in 0.114 s
2021-12-08 10:04:56,389 [main] INFO [org.apache.spark.scheduler.DAGScheduler] - Job 8 finished: runJob at SparkHadoopWriter.scala:78, took 0.115319 s
2021-12-08 10:04:56,430 [main] INFO [org.apache.spark.internal.io.SparkHadoopWriter] - Job job_20211208100456_0051 committed.
2021-12-08 10:04:56,435 [main] INFO [org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter] - File Output Committer Algorithm version is 1
2021-12-08 10:04:56,454 [main] INFO [org.apache.spark.SparkContext] - Starting job: runJob at SparkHadoopWriter.scala:78
2021-12-08 10:04:56,455 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 9 (runJob at SparkHadoopWriter.scala:78) with 1 output partitions
2021-12-08 10:04:56,455 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 29 (runJob at SparkHadoopWriter.scala:78)
2021-12-08 10:04:56,455 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 28)
2021-12-08 10:04:56,455 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2021-12-08 10:04:56,455 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 29 (MapPartitionsRDD[54] at saveAsTextFile at PaidPromotionAdjustParameter.scala:313), which has no missing parents
2021-12-08 10:04:56,463 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_23 stored as values in memory (estimated size 80.5 KB, free 1989.8 MB)
2021-12-08 10:04:56,464 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_23_piece0 stored as bytes in memory (estimated size 30.8 KB, free 1989.8 MB)
2021-12-08 10:04:56,464 [dispatcher-event-loop-0] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_23_piece0 in memory on qb:55588 (size: 30.8 KB, free: 1990.7 MB)
2021-12-08 10:04:56,465 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 23 from broadcast at DAGScheduler.scala:1039
2021-12-08 10:04:56,465 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 29 (MapPartitionsRDD[54] at saveAsTextFile at PaidPromotionAdjustParameter.scala:313) (first 15 tasks are for partitions Vector(0))
2021-12-08 10:04:56,465 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 29.0 with 1 tasks
2021-12-08 10:04:56,466 [dispatcher-event-loop-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 29.0 (TID 108, localhost, executor driver, partition 0, ANY, 8035 bytes)
2021-12-08 10:04:56,466 [Executor task launch worker for task 108] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 29.0 (TID 108)
2021-12-08 10:04:56,469 [Executor task launch worker for task 108] INFO [org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter] - File Output Committer Algorithm version is 1
2021-12-08 10:04:56,479 [Executor task launch worker for task 108] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 12 non-empty blocks out of 12 blocks
2021-12-08 10:04:56,479 [Executor task launch worker for task 108] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-08 10:04:57,296 [Executor task launch worker for task 108] INFO [org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter] - Saved output of task 'attempt_20211208100456_0054_m_000000_0' to hdfs://hdp1:8020/sk/chongqing/model/input/deviceWithIndex/_temporary/0/task_20211208100456_0054_m_000000
2021-12-08 10:04:57,296 [Executor task launch worker for task 108] INFO [org.apache.spark.mapred.SparkHadoopMapRedUtil] - attempt_20211208100456_0054_m_000000_0: Committed
2021-12-08 10:04:57,297 [Executor task launch worker for task 108] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 29.0 (TID 108). 1256 bytes result sent to driver
2021-12-08 10:04:57,297 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 29.0 (TID 108) in 831 ms on localhost (executor driver) (1/1)
2021-12-08 10:04:57,298 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 29.0, whose tasks have all completed, from pool 
2021-12-08 10:04:57,298 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 29 (runJob at SparkHadoopWriter.scala:78) finished in 0.843 s
2021-12-08 10:04:57,298 [main] INFO [org.apache.spark.scheduler.DAGScheduler] - Job 9 finished: runJob at SparkHadoopWriter.scala:78, took 0.844245 s
2021-12-08 10:04:57,373 [main] INFO [org.apache.spark.internal.io.SparkHadoopWriter] - Job job_20211208100456_0054 committed.
2021-12-08 10:04:57,378 [main] INFO [org.spark_project.jetty.server.AbstractConnector] - Stopped Spark@5b800468{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2021-12-08 10:04:57,379 [main] INFO [org.apache.spark.ui.SparkUI] - Stopped Spark web UI at http://qb:4040
2021-12-08 10:04:57,387 [dispatcher-event-loop-10] INFO [org.apache.spark.MapOutputTrackerMasterEndpoint] - MapOutputTrackerMasterEndpoint stopped!
2021-12-08 10:04:57,493 [main] INFO [org.apache.spark.storage.memory.MemoryStore] - MemoryStore cleared
2021-12-08 10:04:57,494 [main] INFO [org.apache.spark.storage.BlockManager] - BlockManager stopped
2021-12-08 10:04:57,494 [main] INFO [org.apache.spark.storage.BlockManagerMaster] - BlockManagerMaster stopped
2021-12-08 10:04:57,496 [dispatcher-event-loop-0] INFO [org.apache.spark.scheduler.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint] - OutputCommitCoordinator stopped!
2021-12-08 10:04:57,499 [main] INFO [org.apache.spark.SparkContext] - Successfully stopped SparkContext
2021-12-08 10:04:57,501 [Thread-1] INFO [org.apache.spark.util.ShutdownHookManager] - Shutdown hook called
2021-12-08 10:04:57,501 [Thread-1] INFO [org.apache.spark.util.ShutdownHookManager] - Deleting directory C:\Users\ACER\AppData\Local\Temp\spark-0463b1f0-9e1f-4254-8940-7b9fadb7d1ca
2021-12-08 10:08:57,779 [main] INFO [org.apache.spark.SparkContext] - Running Spark version 2.3.0
2021-12-08 10:08:58,062 [main] INFO [org.apache.spark.SparkContext] - Submitted application: PaidPromotionAdjustParameter
2021-12-08 10:08:58,117 [main] INFO [org.apache.spark.SecurityManager] - Changing view acls to: ACER,root
2021-12-08 10:08:58,117 [main] INFO [org.apache.spark.SecurityManager] - Changing modify acls to: ACER,root
2021-12-08 10:08:58,117 [main] INFO [org.apache.spark.SecurityManager] - Changing view acls groups to: 
2021-12-08 10:08:58,118 [main] INFO [org.apache.spark.SecurityManager] - Changing modify acls groups to: 
2021-12-08 10:08:58,118 [main] INFO [org.apache.spark.SecurityManager] - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(ACER, root); groups with view permissions: Set(); users  with modify permissions: Set(ACER, root); groups with modify permissions: Set()
2021-12-08 10:08:58,692 [main] INFO [org.apache.spark.util.Utils] - Successfully started service 'sparkDriver' on port 61251.
2021-12-08 10:08:58,708 [main] INFO [org.apache.spark.SparkEnv] - Registering MapOutputTracker
2021-12-08 10:08:58,722 [main] INFO [org.apache.spark.SparkEnv] - Registering BlockManagerMaster
2021-12-08 10:08:58,725 [main] INFO [org.apache.spark.storage.BlockManagerMasterEndpoint] - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2021-12-08 10:08:58,726 [main] INFO [org.apache.spark.storage.BlockManagerMasterEndpoint] - BlockManagerMasterEndpoint up
2021-12-08 10:08:58,733 [main] INFO [org.apache.spark.storage.DiskBlockManager] - Created local directory at C:\Users\ACER\AppData\Local\Temp\blockmgr-f119084c-2af7-457f-a842-b496da2aed40
2021-12-08 10:08:58,748 [main] INFO [org.apache.spark.storage.memory.MemoryStore] - MemoryStore started with capacity 1990.8 MB
2021-12-08 10:08:58,757 [main] INFO [org.apache.spark.SparkEnv] - Registering OutputCommitCoordinator
2021-12-08 10:08:58,810 [main] INFO [org.spark_project.jetty.util.log] - Logging initialized @1892ms
2021-12-08 10:08:58,857 [main] INFO [org.spark_project.jetty.server.Server] - jetty-9.3.z-SNAPSHOT
2021-12-08 10:08:58,868 [main] INFO [org.spark_project.jetty.server.Server] - Started @1951ms
2021-12-08 10:08:58,894 [main] INFO [org.spark_project.jetty.server.AbstractConnector] - Started ServerConnector@5f7f2382{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2021-12-08 10:08:58,894 [main] INFO [org.apache.spark.util.Utils] - Successfully started service 'SparkUI' on port 4040.
2021-12-08 10:08:58,913 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@3af17be2{/jobs,null,AVAILABLE,@Spark}
2021-12-08 10:08:58,914 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@6a1d204a{/jobs/json,null,AVAILABLE,@Spark}
2021-12-08 10:08:58,914 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@72ccd81a{/jobs/job,null,AVAILABLE,@Spark}
2021-12-08 10:08:58,916 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@5d25e6bb{/jobs/job/json,null,AVAILABLE,@Spark}
2021-12-08 10:08:58,917 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@7859e786{/stages,null,AVAILABLE,@Spark}
2021-12-08 10:08:58,918 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@5118388b{/stages/json,null,AVAILABLE,@Spark}
2021-12-08 10:08:58,919 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@71104a4{/stages/stage,null,AVAILABLE,@Spark}
2021-12-08 10:08:58,920 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@332a7fce{/stages/stage/json,null,AVAILABLE,@Spark}
2021-12-08 10:08:58,921 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@37ebc9d8{/stages/pool,null,AVAILABLE,@Spark}
2021-12-08 10:08:58,922 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@6e9319f{/stages/pool/json,null,AVAILABLE,@Spark}
2021-12-08 10:08:58,923 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@2c177f9e{/storage,null,AVAILABLE,@Spark}
2021-12-08 10:08:58,924 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@f9b7332{/storage/json,null,AVAILABLE,@Spark}
2021-12-08 10:08:58,925 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@192f2f27{/storage/rdd,null,AVAILABLE,@Spark}
2021-12-08 10:08:58,926 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@b672aa8{/storage/rdd/json,null,AVAILABLE,@Spark}
2021-12-08 10:08:58,927 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@7997b197{/environment,null,AVAILABLE,@Spark}
2021-12-08 10:08:58,929 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@11acdc30{/environment/json,null,AVAILABLE,@Spark}
2021-12-08 10:08:58,930 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@611f8234{/executors,null,AVAILABLE,@Spark}
2021-12-08 10:08:58,932 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@62923ee6{/executors/json,null,AVAILABLE,@Spark}
2021-12-08 10:08:58,933 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@4b6166aa{/executors/threadDump,null,AVAILABLE,@Spark}
2021-12-08 10:08:58,935 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@a1217f9{/executors/threadDump/json,null,AVAILABLE,@Spark}
2021-12-08 10:08:58,941 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@791cbf87{/static,null,AVAILABLE,@Spark}
2021-12-08 10:08:58,942 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@cf65451{/,null,AVAILABLE,@Spark}
2021-12-08 10:08:58,944 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@46074492{/api,null,AVAILABLE,@Spark}
2021-12-08 10:08:58,944 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@5ae76500{/jobs/job/kill,null,AVAILABLE,@Spark}
2021-12-08 10:08:58,946 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@24f360b2{/stages/stage/kill,null,AVAILABLE,@Spark}
2021-12-08 10:08:58,948 [main] INFO [org.apache.spark.ui.SparkUI] - Bound SparkUI to 0.0.0.0, and started at http://qb:4040
2021-12-08 10:08:59,021 [main] INFO [org.apache.spark.executor.Executor] - Starting executor ID driver on host localhost
2021-12-08 10:08:59,070 [main] INFO [org.apache.spark.util.Utils] - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 61292.
2021-12-08 10:08:59,070 [main] INFO [org.apache.spark.network.netty.NettyBlockTransferService] - Server created on qb:61292
2021-12-08 10:08:59,071 [main] INFO [org.apache.spark.storage.BlockManager] - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2021-12-08 10:08:59,072 [main] INFO [org.apache.spark.storage.BlockManagerMaster] - Registering BlockManager BlockManagerId(driver, qb, 61292, None)
2021-12-08 10:08:59,075 [dispatcher-event-loop-10] INFO [org.apache.spark.storage.BlockManagerMasterEndpoint] - Registering block manager qb:61292 with 1990.8 MB RAM, BlockManagerId(driver, qb, 61292, None)
2021-12-08 10:08:59,077 [main] INFO [org.apache.spark.storage.BlockManagerMaster] - Registered BlockManager BlockManagerId(driver, qb, 61292, None)
2021-12-08 10:08:59,077 [main] INFO [org.apache.spark.storage.BlockManager] - Initialized BlockManager: BlockManagerId(driver, qb, 61292, None)
2021-12-08 10:08:59,209 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@7c9b78e3{/metrics/json,null,AVAILABLE,@Spark}
2021-12-08 10:08:59,654 [main] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_0 stored as values in memory (estimated size 312.7 KB, free 1990.5 MB)
2021-12-08 10:08:59,850 [main] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_0_piece0 stored as bytes in memory (estimated size 27.3 KB, free 1990.5 MB)
2021-12-08 10:08:59,852 [dispatcher-event-loop-0] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_0_piece0 in memory on qb:61292 (size: 27.3 KB, free: 1990.8 MB)
2021-12-08 10:08:59,855 [main] INFO [org.apache.spark.SparkContext] - Created broadcast 0 from textFile at PaidPromotionAdjustParameter.scala:320
2021-12-08 10:08:59,905 [main] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_1 stored as values in memory (estimated size 312.7 KB, free 1990.2 MB)
2021-12-08 10:08:59,918 [main] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_1_piece0 stored as bytes in memory (estimated size 27.3 KB, free 1990.1 MB)
2021-12-08 10:08:59,919 [dispatcher-event-loop-1] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_1_piece0 in memory on qb:61292 (size: 27.3 KB, free: 1990.7 MB)
2021-12-08 10:08:59,919 [main] INFO [org.apache.spark.SparkContext] - Created broadcast 1 from textFile at PaidPromotionAdjustParameter.scala:323
2021-12-08 10:08:59,931 [main] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_2 stored as values in memory (estimated size 312.7 KB, free 1989.8 MB)
2021-12-08 10:08:59,944 [main] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_2_piece0 stored as bytes in memory (estimated size 27.3 KB, free 1989.8 MB)
2021-12-08 10:08:59,945 [dispatcher-event-loop-2] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_2_piece0 in memory on qb:61292 (size: 27.3 KB, free: 1990.7 MB)
2021-12-08 10:08:59,945 [main] INFO [org.apache.spark.SparkContext] - Created broadcast 2 from textFile at PaidPromotionAdjustParameter.scala:326
2021-12-08 10:08:59,955 [main] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_3 stored as values in memory (estimated size 312.7 KB, free 1989.5 MB)
2021-12-08 10:08:59,972 [main] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_3_piece0 stored as bytes in memory (estimated size 27.3 KB, free 1989.5 MB)
2021-12-08 10:08:59,972 [dispatcher-event-loop-3] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_3_piece0 in memory on qb:61292 (size: 27.3 KB, free: 1990.7 MB)
2021-12-08 10:08:59,973 [main] INFO [org.apache.spark.SparkContext] - Created broadcast 3 from textFile at PaidPromotionAdjustParameter.scala:329
2021-12-08 10:08:59,982 [main] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_4 stored as values in memory (estimated size 312.7 KB, free 1989.2 MB)
2021-12-08 10:08:59,993 [main] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_4_piece0 stored as bytes in memory (estimated size 27.3 KB, free 1989.1 MB)
2021-12-08 10:08:59,994 [dispatcher-event-loop-4] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_4_piece0 in memory on qb:61292 (size: 27.3 KB, free: 1990.7 MB)
2021-12-08 10:08:59,995 [main] INFO [org.apache.spark.SparkContext] - Created broadcast 4 from textFile at PaidPromotionAdjustParameter.scala:332
2021-12-08 10:09:00,318 [main] WARN [org.apache.hadoop.hdfs.shortcircuit.DomainSocketFactory] - The short-circuit local reads feature cannot be used because UNIX Domain sockets are not available on Windows.
2021-12-08 10:09:00,437 [main] INFO [org.apache.hadoop.mapred.FileInputFormat] - Total input paths to process : 10
2021-12-08 10:09:00,484 [main] INFO [org.apache.spark.SparkContext] - Starting job: isEmpty at ALS.scala:240
2021-12-08 10:09:00,498 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 0 (isEmpty at ALS.scala:240) with 1 output partitions
2021-12-08 10:09:00,499 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 0 (isEmpty at ALS.scala:240)
2021-12-08 10:09:00,499 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List()
2021-12-08 10:09:00,500 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2021-12-08 10:09:00,507 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 0 (MapPartitionsRDD[2] at map at PaidPromotionAdjustParameter.scala:321), which has no missing parents
2021-12-08 10:09:00,525 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_5 stored as values in memory (estimated size 3.5 KB, free 1989.1 MB)
2021-12-08 10:09:00,529 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_5_piece0 stored as bytes in memory (estimated size 2.1 KB, free 1989.1 MB)
2021-12-08 10:09:00,530 [dispatcher-event-loop-5] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_5_piece0 in memory on qb:61292 (size: 2.1 KB, free: 1990.7 MB)
2021-12-08 10:09:00,530 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 5 from broadcast at DAGScheduler.scala:1039
2021-12-08 10:09:00,540 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[2] at map at PaidPromotionAdjustParameter.scala:321) (first 15 tasks are for partitions Vector(0))
2021-12-08 10:09:00,540 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 0.0 with 1 tasks
2021-12-08 10:09:00,577 [dispatcher-event-loop-6] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 0.0 (TID 0, localhost, executor driver, partition 0, ANY, 7906 bytes)
2021-12-08 10:09:00,586 [Executor task launch worker for task 0] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 0.0 (TID 0)
2021-12-08 10:09:00,627 [Executor task launch worker for task 0] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/model/input/rating/part-00000:0+132087
2021-12-08 10:09:00,833 [Executor task launch worker for task 0] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 0.0 (TID 0). 860 bytes result sent to driver
2021-12-08 10:09:00,849 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 0.0 (TID 0) in 282 ms on localhost (executor driver) (1/1)
2021-12-08 10:09:00,852 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 0.0, whose tasks have all completed, from pool 
2021-12-08 10:09:00,855 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 0 (isEmpty at ALS.scala:240) finished in 0.332 s
2021-12-08 10:09:00,859 [main] INFO [org.apache.spark.scheduler.DAGScheduler] - Job 0 finished: isEmpty at ALS.scala:240, took 0.375211 s
2021-12-08 10:09:00,883 [main] INFO [org.apache.spark.SparkContext] - Starting job: isEmpty at ALS.scala:918
2021-12-08 10:09:00,884 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 1 (isEmpty at ALS.scala:918) with 1 output partitions
2021-12-08 10:09:00,884 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 1 (isEmpty at ALS.scala:918)
2021-12-08 10:09:00,884 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List()
2021-12-08 10:09:00,884 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2021-12-08 10:09:00,885 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 1 (MapPartitionsRDD[15] at map at ALS.scala:256), which has no missing parents
2021-12-08 10:09:00,887 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_6 stored as values in memory (estimated size 3.7 KB, free 1989.1 MB)
2021-12-08 10:09:00,891 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_6_piece0 stored as bytes in memory (estimated size 2.2 KB, free 1989.1 MB)
2021-12-08 10:09:00,892 [dispatcher-event-loop-9] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_6_piece0 in memory on qb:61292 (size: 2.2 KB, free: 1990.7 MB)
2021-12-08 10:09:00,892 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 6 from broadcast at DAGScheduler.scala:1039
2021-12-08 10:09:00,893 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[15] at map at ALS.scala:256) (first 15 tasks are for partitions Vector(0))
2021-12-08 10:09:00,893 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 1.0 with 1 tasks
2021-12-08 10:09:00,894 [dispatcher-event-loop-10] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 1.0 (TID 1, localhost, executor driver, partition 0, ANY, 7906 bytes)
2021-12-08 10:09:00,894 [Executor task launch worker for task 1] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 1.0 (TID 1)
2021-12-08 10:09:00,897 [Executor task launch worker for task 1] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/model/input/rating/part-00000:0+132087
2021-12-08 10:09:00,943 [Executor task launch worker for task 1] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 1.0 (TID 1). 867 bytes result sent to driver
2021-12-08 10:09:00,946 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 1.0 (TID 1) in 53 ms on localhost (executor driver) (1/1)
2021-12-08 10:09:00,947 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 1.0, whose tasks have all completed, from pool 
2021-12-08 10:09:00,947 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 1 (isEmpty at ALS.scala:918) finished in 0.062 s
2021-12-08 10:09:00,948 [main] INFO [org.apache.spark.scheduler.DAGScheduler] - Job 1 finished: isEmpty at ALS.scala:918, took 0.063982 s
2021-12-08 10:09:00,982 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 4
2021-12-08 10:09:00,996 [dispatcher-event-loop-3] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_5_piece0 on qb:61292 in memory (size: 2.1 KB, free: 1990.7 MB)
2021-12-08 10:09:00,999 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 14
2021-12-08 10:09:00,999 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 41
2021-12-08 10:09:00,999 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 40
2021-12-08 10:09:00,999 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 6
2021-12-08 10:09:01,001 [dispatcher-event-loop-6] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_6_piece0 on qb:61292 in memory (size: 2.2 KB, free: 1990.7 MB)
2021-12-08 10:09:01,002 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 23
2021-12-08 10:09:01,002 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 44
2021-12-08 10:09:01,002 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 8
2021-12-08 10:09:01,002 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 13
2021-12-08 10:09:01,002 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 21
2021-12-08 10:09:01,002 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 7
2021-12-08 10:09:01,002 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 26
2021-12-08 10:09:01,002 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 29
2021-12-08 10:09:01,002 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 30
2021-12-08 10:09:01,002 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 5
2021-12-08 10:09:01,002 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 42
2021-12-08 10:09:01,002 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 46
2021-12-08 10:09:01,002 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 48
2021-12-08 10:09:01,002 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 12
2021-12-08 10:09:01,002 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 36
2021-12-08 10:09:01,002 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 10
2021-12-08 10:09:01,002 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 18
2021-12-08 10:09:01,002 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 3
2021-12-08 10:09:01,002 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 45
2021-12-08 10:09:01,002 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 31
2021-12-08 10:09:01,002 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 34
2021-12-08 10:09:01,002 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 19
2021-12-08 10:09:01,002 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 2
2021-12-08 10:09:01,002 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 27
2021-12-08 10:09:01,002 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 11
2021-12-08 10:09:01,002 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 33
2021-12-08 10:09:01,002 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 49
2021-12-08 10:09:01,003 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 43
2021-12-08 10:09:01,003 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 47
2021-12-08 10:09:01,003 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 20
2021-12-08 10:09:01,003 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 37
2021-12-08 10:09:01,003 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 9
2021-12-08 10:09:01,003 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 24
2021-12-08 10:09:01,003 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 0
2021-12-08 10:09:01,003 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 15
2021-12-08 10:09:01,003 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 16
2021-12-08 10:09:01,003 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1
2021-12-08 10:09:01,003 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 35
2021-12-08 10:09:01,003 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 28
2021-12-08 10:09:01,003 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 39
2021-12-08 10:09:01,003 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 22
2021-12-08 10:09:01,003 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 25
2021-12-08 10:09:01,003 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 17
2021-12-08 10:09:01,003 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 38
2021-12-08 10:09:01,003 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 32
2021-12-08 10:09:01,026 [main] INFO [org.apache.spark.SparkContext] - Starting job: count at ALS.scala:931
2021-12-08 10:09:01,029 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 16 (mapPartitions at ALS.scala:1321)
2021-12-08 10:09:01,031 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 19 (map at ALS.scala:1564)
2021-12-08 10:09:01,031 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 2 (count at ALS.scala:931) with 12 output partitions
2021-12-08 10:09:01,031 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 4 (count at ALS.scala:931)
2021-12-08 10:09:01,031 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 3)
2021-12-08 10:09:01,034 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List(ShuffleMapStage 3)
2021-12-08 10:09:01,035 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ShuffleMapStage 2 (MapPartitionsRDD[16] at mapPartitions at ALS.scala:1321), which has no missing parents
2021-12-08 10:09:01,040 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_7 stored as values in memory (estimated size 6.3 KB, free 1989.1 MB)
2021-12-08 10:09:01,043 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_7_piece0 stored as bytes in memory (estimated size 3.5 KB, free 1989.1 MB)
2021-12-08 10:09:01,044 [dispatcher-event-loop-10] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_7_piece0 in memory on qb:61292 (size: 3.5 KB, free: 1990.7 MB)
2021-12-08 10:09:01,044 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 7 from broadcast at DAGScheduler.scala:1039
2021-12-08 10:09:01,047 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 10 missing tasks from ShuffleMapStage 2 (MapPartitionsRDD[16] at mapPartitions at ALS.scala:1321) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
2021-12-08 10:09:01,047 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 2.0 with 10 tasks
2021-12-08 10:09:01,049 [dispatcher-event-loop-11] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 2.0 (TID 2, localhost, executor driver, partition 0, ANY, 7895 bytes)
2021-12-08 10:09:01,049 [dispatcher-event-loop-11] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 2.0 (TID 3, localhost, executor driver, partition 1, ANY, 7895 bytes)
2021-12-08 10:09:01,050 [dispatcher-event-loop-11] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 2.0 in stage 2.0 (TID 4, localhost, executor driver, partition 2, ANY, 7895 bytes)
2021-12-08 10:09:01,050 [dispatcher-event-loop-11] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 3.0 in stage 2.0 (TID 5, localhost, executor driver, partition 3, ANY, 7895 bytes)
2021-12-08 10:09:01,051 [dispatcher-event-loop-11] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 4.0 in stage 2.0 (TID 6, localhost, executor driver, partition 4, ANY, 7895 bytes)
2021-12-08 10:09:01,051 [dispatcher-event-loop-11] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 5.0 in stage 2.0 (TID 7, localhost, executor driver, partition 5, ANY, 7895 bytes)
2021-12-08 10:09:01,052 [dispatcher-event-loop-11] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 6.0 in stage 2.0 (TID 8, localhost, executor driver, partition 6, ANY, 7895 bytes)
2021-12-08 10:09:01,052 [dispatcher-event-loop-11] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 7.0 in stage 2.0 (TID 9, localhost, executor driver, partition 7, ANY, 7895 bytes)
2021-12-08 10:09:01,052 [dispatcher-event-loop-11] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 8.0 in stage 2.0 (TID 10, localhost, executor driver, partition 8, ANY, 7895 bytes)
2021-12-08 10:09:01,052 [dispatcher-event-loop-11] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 9.0 in stage 2.0 (TID 11, localhost, executor driver, partition 9, ANY, 7895 bytes)
2021-12-08 10:09:01,053 [Executor task launch worker for task 2] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 2.0 (TID 2)
2021-12-08 10:09:01,053 [Executor task launch worker for task 3] INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 2.0 (TID 3)
2021-12-08 10:09:01,053 [Executor task launch worker for task 4] INFO [org.apache.spark.executor.Executor] - Running task 2.0 in stage 2.0 (TID 4)
2021-12-08 10:09:01,054 [Executor task launch worker for task 5] INFO [org.apache.spark.executor.Executor] - Running task 3.0 in stage 2.0 (TID 5)
2021-12-08 10:09:01,054 [Executor task launch worker for task 7] INFO [org.apache.spark.executor.Executor] - Running task 5.0 in stage 2.0 (TID 7)
2021-12-08 10:09:01,055 [Executor task launch worker for task 6] INFO [org.apache.spark.executor.Executor] - Running task 4.0 in stage 2.0 (TID 6)
2021-12-08 10:09:01,056 [Executor task launch worker for task 8] INFO [org.apache.spark.executor.Executor] - Running task 6.0 in stage 2.0 (TID 8)
2021-12-08 10:09:01,056 [Executor task launch worker for task 9] INFO [org.apache.spark.executor.Executor] - Running task 7.0 in stage 2.0 (TID 9)
2021-12-08 10:09:01,059 [Executor task launch worker for task 10] INFO [org.apache.spark.executor.Executor] - Running task 8.0 in stage 2.0 (TID 10)
2021-12-08 10:09:01,059 [Executor task launch worker for task 3] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/model/input/rating/part-00001:0+864992
2021-12-08 10:09:01,059 [Executor task launch worker for task 2] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/model/input/rating/part-00000:0+132087
2021-12-08 10:09:01,060 [Executor task launch worker for task 8] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/model/input/rating/part-00006:0+6530115
2021-12-08 10:09:01,060 [Executor task launch worker for task 9] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/model/input/rating/part-00007:0+13862185
2021-12-08 10:09:01,061 [Executor task launch worker for task 4] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/model/input/rating/part-00002:0+6206649
2021-12-08 10:09:01,063 [Executor task launch worker for task 11] INFO [org.apache.spark.executor.Executor] - Running task 9.0 in stage 2.0 (TID 11)
2021-12-08 10:09:01,064 [Executor task launch worker for task 5] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/model/input/rating/part-00003:0+13046026
2021-12-08 10:09:01,064 [Executor task launch worker for task 10] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/model/input/rating/part-00008:0+7396167
2021-12-08 10:09:01,065 [Executor task launch worker for task 6] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/model/input/rating/part-00004:0+6736990
2021-12-08 10:09:01,068 [Executor task launch worker for task 11] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/model/input/rating/part-00009:0+12581480
2021-12-08 10:09:01,069 [Executor task launch worker for task 7] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/model/input/rating/part-00005:0+14679212
2021-12-08 10:09:01,531 [Executor task launch worker for task 2] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 2.0 (TID 2). 911 bytes result sent to driver
2021-12-08 10:09:01,546 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 2.0 (TID 2) in 498 ms on localhost (executor driver) (1/10)
2021-12-08 10:09:01,602 [Executor task launch worker for task 3] INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 2.0 (TID 3). 911 bytes result sent to driver
2021-12-08 10:09:01,606 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 2.0 (TID 3) in 556 ms on localhost (executor driver) (2/10)
2021-12-08 10:09:03,978 [Executor task launch worker for task 10] INFO [org.apache.spark.executor.Executor] - Finished task 8.0 in stage 2.0 (TID 10). 911 bytes result sent to driver
2021-12-08 10:09:03,979 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 8.0 in stage 2.0 (TID 10) in 2927 ms on localhost (executor driver) (3/10)
2021-12-08 10:09:04,107 [Executor task launch worker for task 4] INFO [org.apache.spark.executor.Executor] - Finished task 2.0 in stage 2.0 (TID 4). 911 bytes result sent to driver
2021-12-08 10:09:04,107 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 2.0 in stage 2.0 (TID 4) in 3058 ms on localhost (executor driver) (4/10)
2021-12-08 10:09:06,354 [Executor task launch worker for task 5] INFO [org.apache.spark.executor.Executor] - Finished task 3.0 in stage 2.0 (TID 5). 911 bytes result sent to driver
2021-12-08 10:09:06,354 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 3.0 in stage 2.0 (TID 5) in 5304 ms on localhost (executor driver) (5/10)
2021-12-08 10:09:07,454 [Executor task launch worker for task 7] INFO [org.apache.spark.executor.Executor] - Finished task 5.0 in stage 2.0 (TID 7). 911 bytes result sent to driver
2021-12-08 10:09:07,455 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 5.0 in stage 2.0 (TID 7) in 6403 ms on localhost (executor driver) (6/10)
2021-12-08 10:09:07,583 [Executor task launch worker for task 8] INFO [org.apache.spark.executor.Executor] - Finished task 6.0 in stage 2.0 (TID 8). 911 bytes result sent to driver
2021-12-08 10:09:07,584 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 6.0 in stage 2.0 (TID 8) in 6533 ms on localhost (executor driver) (7/10)
2021-12-08 10:09:07,988 [Executor task launch worker for task 6] INFO [org.apache.spark.executor.Executor] - Finished task 4.0 in stage 2.0 (TID 6). 911 bytes result sent to driver
2021-12-08 10:09:07,988 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 4.0 in stage 2.0 (TID 6) in 6938 ms on localhost (executor driver) (8/10)
2021-12-08 10:09:08,009 [Executor task launch worker for task 9] INFO [org.apache.spark.executor.Executor] - Finished task 7.0 in stage 2.0 (TID 9). 911 bytes result sent to driver
2021-12-08 10:09:08,010 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 7.0 in stage 2.0 (TID 9) in 6958 ms on localhost (executor driver) (9/10)
2021-12-08 10:09:08,443 [Executor task launch worker for task 11] INFO [org.apache.spark.executor.Executor] - Finished task 9.0 in stage 2.0 (TID 11). 911 bytes result sent to driver
2021-12-08 10:09:08,444 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 9.0 in stage 2.0 (TID 11) in 7391 ms on localhost (executor driver) (10/10)
2021-12-08 10:09:08,444 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 2.0, whose tasks have all completed, from pool 
2021-12-08 10:09:08,444 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ShuffleMapStage 2 (mapPartitions at ALS.scala:1321) finished in 7.406 s
2021-12-08 10:09:08,444 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - looking for newly runnable stages
2021-12-08 10:09:08,445 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - running: Set()
2021-12-08 10:09:08,445 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - waiting: Set(ShuffleMapStage 3, ResultStage 4)
2021-12-08 10:09:08,445 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - failed: Set()
2021-12-08 10:09:08,448 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ShuffleMapStage 3 (MapPartitionsRDD[19] at map at ALS.scala:1564), which has no missing parents
2021-12-08 10:09:08,452 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_8 stored as values in memory (estimated size 7.6 KB, free 1989.1 MB)
2021-12-08 10:09:08,453 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_8_piece0 stored as bytes in memory (estimated size 4.0 KB, free 1989.1 MB)
2021-12-08 10:09:08,453 [dispatcher-event-loop-9] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_8_piece0 in memory on qb:61292 (size: 4.0 KB, free: 1990.7 MB)
2021-12-08 10:09:08,454 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 8 from broadcast at DAGScheduler.scala:1039
2021-12-08 10:09:08,454 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 10 missing tasks from ShuffleMapStage 3 (MapPartitionsRDD[19] at map at ALS.scala:1564) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
2021-12-08 10:09:08,454 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 3.0 with 10 tasks
2021-12-08 10:09:08,455 [dispatcher-event-loop-10] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 3.0 (TID 12, localhost, executor driver, partition 0, ANY, 7638 bytes)
2021-12-08 10:09:08,455 [dispatcher-event-loop-10] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 3.0 (TID 13, localhost, executor driver, partition 1, ANY, 7638 bytes)
2021-12-08 10:09:08,456 [dispatcher-event-loop-10] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 2.0 in stage 3.0 (TID 14, localhost, executor driver, partition 2, ANY, 7638 bytes)
2021-12-08 10:09:08,456 [dispatcher-event-loop-10] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 3.0 in stage 3.0 (TID 15, localhost, executor driver, partition 3, ANY, 7638 bytes)
2021-12-08 10:09:08,456 [dispatcher-event-loop-10] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 4.0 in stage 3.0 (TID 16, localhost, executor driver, partition 4, ANY, 7638 bytes)
2021-12-08 10:09:08,456 [dispatcher-event-loop-10] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 5.0 in stage 3.0 (TID 17, localhost, executor driver, partition 5, ANY, 7638 bytes)
2021-12-08 10:09:08,456 [dispatcher-event-loop-10] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 6.0 in stage 3.0 (TID 18, localhost, executor driver, partition 6, ANY, 7638 bytes)
2021-12-08 10:09:08,456 [dispatcher-event-loop-10] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 7.0 in stage 3.0 (TID 19, localhost, executor driver, partition 7, ANY, 7638 bytes)
2021-12-08 10:09:08,456 [dispatcher-event-loop-10] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 8.0 in stage 3.0 (TID 20, localhost, executor driver, partition 8, ANY, 7638 bytes)
2021-12-08 10:09:08,456 [dispatcher-event-loop-10] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 9.0 in stage 3.0 (TID 21, localhost, executor driver, partition 9, ANY, 7638 bytes)
2021-12-08 10:09:08,457 [Executor task launch worker for task 12] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 3.0 (TID 12)
2021-12-08 10:09:08,457 [Executor task launch worker for task 14] INFO [org.apache.spark.executor.Executor] - Running task 2.0 in stage 3.0 (TID 14)
2021-12-08 10:09:08,457 [Executor task launch worker for task 19] INFO [org.apache.spark.executor.Executor] - Running task 7.0 in stage 3.0 (TID 19)
2021-12-08 10:09:08,457 [Executor task launch worker for task 18] INFO [org.apache.spark.executor.Executor] - Running task 6.0 in stage 3.0 (TID 18)
2021-12-08 10:09:08,457 [Executor task launch worker for task 21] INFO [org.apache.spark.executor.Executor] - Running task 9.0 in stage 3.0 (TID 21)
2021-12-08 10:09:08,457 [Executor task launch worker for task 20] INFO [org.apache.spark.executor.Executor] - Running task 8.0 in stage 3.0 (TID 20)
2021-12-08 10:09:08,457 [Executor task launch worker for task 17] INFO [org.apache.spark.executor.Executor] - Running task 5.0 in stage 3.0 (TID 17)
2021-12-08 10:09:08,457 [Executor task launch worker for task 16] INFO [org.apache.spark.executor.Executor] - Running task 4.0 in stage 3.0 (TID 16)
2021-12-08 10:09:08,457 [Executor task launch worker for task 13] INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 3.0 (TID 13)
2021-12-08 10:09:08,457 [Executor task launch worker for task 15] INFO [org.apache.spark.executor.Executor] - Running task 3.0 in stage 3.0 (TID 15)
2021-12-08 10:09:08,478 [Executor task launch worker for task 12] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 10 non-empty blocks out of 10 blocks
2021-12-08 10:09:08,478 [Executor task launch worker for task 18] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 10 non-empty blocks out of 10 blocks
2021-12-08 10:09:08,478 [Executor task launch worker for task 17] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 10 non-empty blocks out of 10 blocks
2021-12-08 10:09:08,478 [Executor task launch worker for task 14] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 10 non-empty blocks out of 10 blocks
2021-12-08 10:09:08,478 [Executor task launch worker for task 21] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 10 non-empty blocks out of 10 blocks
2021-12-08 10:09:08,478 [Executor task launch worker for task 15] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 10 non-empty blocks out of 10 blocks
2021-12-08 10:09:08,478 [Executor task launch worker for task 16] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 10 non-empty blocks out of 10 blocks
2021-12-08 10:09:08,478 [Executor task launch worker for task 19] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 10 non-empty blocks out of 10 blocks
2021-12-08 10:09:08,478 [Executor task launch worker for task 20] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 10 non-empty blocks out of 10 blocks
2021-12-08 10:09:08,478 [Executor task launch worker for task 13] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 10 non-empty blocks out of 10 blocks
2021-12-08 10:09:08,479 [Executor task launch worker for task 20] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 5 ms
2021-12-08 10:09:08,479 [Executor task launch worker for task 13] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 5 ms
2021-12-08 10:09:08,479 [Executor task launch worker for task 12] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 5 ms
2021-12-08 10:09:08,479 [Executor task launch worker for task 16] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 5 ms
2021-12-08 10:09:08,479 [Executor task launch worker for task 15] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 5 ms
2021-12-08 10:09:08,479 [Executor task launch worker for task 14] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 5 ms
2021-12-08 10:09:08,479 [Executor task launch worker for task 21] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 5 ms
2021-12-08 10:09:08,479 [Executor task launch worker for task 17] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 5 ms
2021-12-08 10:09:08,479 [Executor task launch worker for task 18] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 5 ms
2021-12-08 10:09:08,479 [Executor task launch worker for task 19] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 5 ms
2021-12-08 10:09:08,833 [dispatcher-event-loop-11] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_7_piece0 on qb:61292 in memory (size: 3.5 KB, free: 1990.7 MB)
2021-12-08 10:09:08,845 [Executor task launch worker for task 16] INFO [org.apache.spark.storage.memory.MemoryStore] - Block rdd_18_4 stored as values in memory (estimated size 5.5 MB, free 1937.9 MB)
2021-12-08 10:09:08,854 [Executor task launch worker for task 12] INFO [org.apache.spark.storage.memory.MemoryStore] - Block rdd_18_0 stored as values in memory (estimated size 4.6 MB, free 1933.3 MB)
2021-12-08 10:09:08,855 [dispatcher-event-loop-0] INFO [org.apache.spark.storage.BlockManagerInfo] - Added rdd_18_4 in memory on qb:61292 (size: 5.5 MB, free: 1985.2 MB)
2021-12-08 10:09:08,856 [dispatcher-event-loop-0] INFO [org.apache.spark.storage.BlockManagerInfo] - Added rdd_18_0 in memory on qb:61292 (size: 4.6 MB, free: 1980.5 MB)
2021-12-08 10:09:08,856 [Executor task launch worker for task 19] INFO [org.apache.spark.storage.memory.MemoryStore] - Block rdd_18_7 stored as values in memory (estimated size 5.5 MB, free 1933.9 MB)
2021-12-08 10:09:08,857 [dispatcher-event-loop-10] INFO [org.apache.spark.storage.BlockManagerInfo] - Added rdd_18_7 in memory on qb:61292 (size: 5.5 MB, free: 1975.0 MB)
2021-12-08 10:09:08,862 [Executor task launch worker for task 21] INFO [org.apache.spark.storage.memory.MemoryStore] - Block rdd_18_9 stored as values in memory (estimated size 6.1 MB, free 1933.6 MB)
2021-12-08 10:09:08,869 [dispatcher-event-loop-2] INFO [org.apache.spark.storage.BlockManagerInfo] - Added rdd_18_9 in memory on qb:61292 (size: 6.1 MB, free: 1968.9 MB)
2021-12-08 10:09:08,877 [Executor task launch worker for task 18] INFO [org.apache.spark.storage.memory.MemoryStore] - Block rdd_18_6 stored as values in memory (estimated size 9.1 MB, free 1930.2 MB)
2021-12-08 10:09:08,878 [dispatcher-event-loop-3] INFO [org.apache.spark.storage.BlockManagerInfo] - Added rdd_18_6 in memory on qb:61292 (size: 9.1 MB, free: 1959.8 MB)
2021-12-08 10:09:08,878 [Executor task launch worker for task 20] INFO [org.apache.spark.storage.memory.MemoryStore] - Block rdd_18_8 stored as values in memory (estimated size 10.4 MB, free 1925.5 MB)
2021-12-08 10:09:08,879 [dispatcher-event-loop-5] INFO [org.apache.spark.storage.BlockManagerInfo] - Added rdd_18_8 in memory on qb:61292 (size: 10.4 MB, free: 1949.4 MB)
2021-12-08 10:09:08,882 [Executor task launch worker for task 13] INFO [org.apache.spark.storage.memory.MemoryStore] - Block rdd_18_1 stored as values in memory (estimated size 7.1 MB, free 1924.5 MB)
2021-12-08 10:09:08,882 [dispatcher-event-loop-4] INFO [org.apache.spark.storage.BlockManagerInfo] - Added rdd_18_1 in memory on qb:61292 (size: 7.1 MB, free: 1942.3 MB)
2021-12-08 10:09:08,891 [Executor task launch worker for task 15] INFO [org.apache.spark.storage.memory.MemoryStore] - Block rdd_18_3 stored as values in memory (estimated size 9.5 MB, free 1920.2 MB)
2021-12-08 10:09:08,892 [Executor task launch worker for task 14] INFO [org.apache.spark.storage.memory.MemoryStore] - Block rdd_18_2 stored as values in memory (estimated size 10.6 MB, free 1915.1 MB)
2021-12-08 10:09:08,894 [dispatcher-event-loop-6] INFO [org.apache.spark.storage.BlockManagerInfo] - Added rdd_18_3 in memory on qb:61292 (size: 9.5 MB, free: 1932.8 MB)
2021-12-08 10:09:08,894 [dispatcher-event-loop-6] INFO [org.apache.spark.storage.BlockManagerInfo] - Added rdd_18_2 in memory on qb:61292 (size: 10.6 MB, free: 1922.2 MB)
2021-12-08 10:09:08,919 [Executor task launch worker for task 17] INFO [org.apache.spark.storage.memory.MemoryStore] - Block rdd_18_5 stored as values in memory (estimated size 8.9 MB, free 1911.7 MB)
2021-12-08 10:09:08,919 [dispatcher-event-loop-7] INFO [org.apache.spark.storage.BlockManagerInfo] - Added rdd_18_5 in memory on qb:61292 (size: 8.9 MB, free: 1913.2 MB)
2021-12-08 10:09:09,237 [Executor task launch worker for task 21] INFO [org.apache.spark.executor.Executor] - Finished task 9.0 in stage 3.0 (TID 21). 1343 bytes result sent to driver
2021-12-08 10:09:09,238 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 9.0 in stage 3.0 (TID 21) in 782 ms on localhost (executor driver) (1/10)
2021-12-08 10:09:09,251 [Executor task launch worker for task 16] INFO [org.apache.spark.executor.Executor] - Finished task 4.0 in stage 3.0 (TID 16). 1300 bytes result sent to driver
2021-12-08 10:09:09,253 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 4.0 in stage 3.0 (TID 16) in 797 ms on localhost (executor driver) (2/10)
2021-12-08 10:09:09,273 [Executor task launch worker for task 12] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 3.0 (TID 12). 1300 bytes result sent to driver
2021-12-08 10:09:09,273 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 3.0 (TID 12) in 818 ms on localhost (executor driver) (3/10)
2021-12-08 10:09:09,282 [Executor task launch worker for task 19] INFO [org.apache.spark.executor.Executor] - Finished task 7.0 in stage 3.0 (TID 19). 1300 bytes result sent to driver
2021-12-08 10:09:09,283 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 7.0 in stage 3.0 (TID 19) in 827 ms on localhost (executor driver) (4/10)
2021-12-08 10:09:09,288 [Executor task launch worker for task 13] INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 3.0 (TID 13). 1300 bytes result sent to driver
2021-12-08 10:09:09,289 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 3.0 (TID 13) in 834 ms on localhost (executor driver) (5/10)
2021-12-08 10:09:09,318 [Executor task launch worker for task 18] INFO [org.apache.spark.executor.Executor] - Finished task 6.0 in stage 3.0 (TID 18). 1257 bytes result sent to driver
2021-12-08 10:09:09,319 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 6.0 in stage 3.0 (TID 18) in 863 ms on localhost (executor driver) (6/10)
2021-12-08 10:09:09,320 [Executor task launch worker for task 15] INFO [org.apache.spark.executor.Executor] - Finished task 3.0 in stage 3.0 (TID 15). 1257 bytes result sent to driver
2021-12-08 10:09:09,320 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 3.0 in stage 3.0 (TID 15) in 864 ms on localhost (executor driver) (7/10)
2021-12-08 10:09:09,329 [Executor task launch worker for task 14] INFO [org.apache.spark.executor.Executor] - Finished task 2.0 in stage 3.0 (TID 14). 1300 bytes result sent to driver
2021-12-08 10:09:09,330 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 2.0 in stage 3.0 (TID 14) in 874 ms on localhost (executor driver) (8/10)
2021-12-08 10:09:09,337 [Executor task launch worker for task 17] INFO [org.apache.spark.executor.Executor] - Finished task 5.0 in stage 3.0 (TID 17). 1300 bytes result sent to driver
2021-12-08 10:09:09,338 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 5.0 in stage 3.0 (TID 17) in 882 ms on localhost (executor driver) (9/10)
2021-12-08 10:09:09,346 [Executor task launch worker for task 20] INFO [org.apache.spark.executor.Executor] - Finished task 8.0 in stage 3.0 (TID 20). 1257 bytes result sent to driver
2021-12-08 10:09:09,346 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 8.0 in stage 3.0 (TID 20) in 890 ms on localhost (executor driver) (10/10)
2021-12-08 10:09:09,346 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 3.0, whose tasks have all completed, from pool 
2021-12-08 10:09:09,346 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ShuffleMapStage 3 (map at ALS.scala:1564) finished in 0.895 s
2021-12-08 10:09:09,347 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - looking for newly runnable stages
2021-12-08 10:09:09,347 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - running: Set()
2021-12-08 10:09:09,347 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - waiting: Set(ResultStage 4)
2021-12-08 10:09:09,347 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - failed: Set()
2021-12-08 10:09:09,347 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 4 (userOutBlocks MapPartitionsRDD[22] at mapValues at ALS.scala:1601), which has no missing parents
2021-12-08 10:09:09,350 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_9 stored as values in memory (estimated size 8.2 KB, free 1911.7 MB)
2021-12-08 10:09:09,352 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_9_piece0 stored as bytes in memory (estimated size 4.2 KB, free 1911.7 MB)
2021-12-08 10:09:09,352 [dispatcher-event-loop-8] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_9_piece0 in memory on qb:61292 (size: 4.2 KB, free: 1913.2 MB)
2021-12-08 10:09:09,353 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 9 from broadcast at DAGScheduler.scala:1039
2021-12-08 10:09:09,353 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 12 missing tasks from ResultStage 4 (userOutBlocks MapPartitionsRDD[22] at mapValues at ALS.scala:1601) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11))
2021-12-08 10:09:09,353 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 4.0 with 12 tasks
2021-12-08 10:09:09,354 [dispatcher-event-loop-11] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 4.0 (TID 22, localhost, executor driver, partition 0, ANY, 7649 bytes)
2021-12-08 10:09:09,354 [dispatcher-event-loop-11] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 4.0 (TID 23, localhost, executor driver, partition 1, ANY, 7649 bytes)
2021-12-08 10:09:09,354 [dispatcher-event-loop-11] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 2.0 in stage 4.0 (TID 24, localhost, executor driver, partition 2, ANY, 7649 bytes)
2021-12-08 10:09:09,354 [dispatcher-event-loop-11] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 3.0 in stage 4.0 (TID 25, localhost, executor driver, partition 3, ANY, 7649 bytes)
2021-12-08 10:09:09,354 [dispatcher-event-loop-11] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 4.0 in stage 4.0 (TID 26, localhost, executor driver, partition 4, ANY, 7649 bytes)
2021-12-08 10:09:09,354 [dispatcher-event-loop-11] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 5.0 in stage 4.0 (TID 27, localhost, executor driver, partition 5, ANY, 7649 bytes)
2021-12-08 10:09:09,355 [dispatcher-event-loop-11] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 6.0 in stage 4.0 (TID 28, localhost, executor driver, partition 6, ANY, 7649 bytes)
2021-12-08 10:09:09,355 [dispatcher-event-loop-11] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 7.0 in stage 4.0 (TID 29, localhost, executor driver, partition 7, ANY, 7649 bytes)
2021-12-08 10:09:09,355 [dispatcher-event-loop-11] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 8.0 in stage 4.0 (TID 30, localhost, executor driver, partition 8, ANY, 7649 bytes)
2021-12-08 10:09:09,355 [dispatcher-event-loop-11] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 9.0 in stage 4.0 (TID 31, localhost, executor driver, partition 9, ANY, 7649 bytes)
2021-12-08 10:09:09,355 [dispatcher-event-loop-11] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 10.0 in stage 4.0 (TID 32, localhost, executor driver, partition 10, ANY, 7649 bytes)
2021-12-08 10:09:09,355 [dispatcher-event-loop-11] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 11.0 in stage 4.0 (TID 33, localhost, executor driver, partition 11, ANY, 7649 bytes)
2021-12-08 10:09:09,355 [Executor task launch worker for task 24] INFO [org.apache.spark.executor.Executor] - Running task 2.0 in stage 4.0 (TID 24)
2021-12-08 10:09:09,355 [Executor task launch worker for task 26] INFO [org.apache.spark.executor.Executor] - Running task 4.0 in stage 4.0 (TID 26)
2021-12-08 10:09:09,355 [Executor task launch worker for task 27] INFO [org.apache.spark.executor.Executor] - Running task 5.0 in stage 4.0 (TID 27)
2021-12-08 10:09:09,355 [Executor task launch worker for task 29] INFO [org.apache.spark.executor.Executor] - Running task 7.0 in stage 4.0 (TID 29)
2021-12-08 10:09:09,356 [Executor task launch worker for task 31] INFO [org.apache.spark.executor.Executor] - Running task 9.0 in stage 4.0 (TID 31)
2021-12-08 10:09:09,355 [Executor task launch worker for task 25] INFO [org.apache.spark.executor.Executor] - Running task 3.0 in stage 4.0 (TID 25)
2021-12-08 10:09:09,355 [Executor task launch worker for task 30] INFO [org.apache.spark.executor.Executor] - Running task 8.0 in stage 4.0 (TID 30)
2021-12-08 10:09:09,355 [Executor task launch worker for task 22] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 4.0 (TID 22)
2021-12-08 10:09:09,355 [Executor task launch worker for task 23] INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 4.0 (TID 23)
2021-12-08 10:09:09,355 [Executor task launch worker for task 28] INFO [org.apache.spark.executor.Executor] - Running task 6.0 in stage 4.0 (TID 28)
2021-12-08 10:09:09,359 [Executor task launch worker for task 27] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 6 non-empty blocks out of 10 blocks
2021-12-08 10:09:09,359 [Executor task launch worker for task 27] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 1 ms
2021-12-08 10:09:09,359 [Executor task launch worker for task 25] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 8 non-empty blocks out of 10 blocks
2021-12-08 10:09:09,359 [Executor task launch worker for task 25] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-08 10:09:09,359 [Executor task launch worker for task 22] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 9 non-empty blocks out of 10 blocks
2021-12-08 10:09:09,359 [Executor task launch worker for task 22] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-08 10:09:09,359 [Executor task launch worker for task 24] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 7 non-empty blocks out of 10 blocks
2021-12-08 10:09:09,359 [Executor task launch worker for task 24] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-08 10:09:09,360 [Executor task launch worker for task 30] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 9 non-empty blocks out of 10 blocks
2021-12-08 10:09:09,360 [Executor task launch worker for task 30] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-08 10:09:09,359 [Executor task launch worker for task 31] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 8 non-empty blocks out of 10 blocks
2021-12-08 10:09:09,360 [Executor task launch worker for task 31] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 1 ms
2021-12-08 10:09:09,360 [Executor task launch worker for task 26] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 5 non-empty blocks out of 10 blocks
2021-12-08 10:09:09,360 [Executor task launch worker for task 26] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 1 ms
2021-12-08 10:09:09,360 [Executor task launch worker for task 23] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 5 non-empty blocks out of 10 blocks
2021-12-08 10:09:09,360 [Executor task launch worker for task 23] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-08 10:09:09,361 [Executor task launch worker for task 29] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 7 non-empty blocks out of 10 blocks
2021-12-08 10:09:09,361 [Executor task launch worker for task 29] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-08 10:09:09,361 [Executor task launch worker for task 28] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 7 non-empty blocks out of 10 blocks
2021-12-08 10:09:09,361 [Executor task launch worker for task 28] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-08 10:09:09,363 [Executor task launch worker for task 32] INFO [org.apache.spark.executor.Executor] - Running task 10.0 in stage 4.0 (TID 32)
2021-12-08 10:09:09,364 [Executor task launch worker for task 33] INFO [org.apache.spark.executor.Executor] - Running task 11.0 in stage 4.0 (TID 33)
2021-12-08 10:09:09,366 [Executor task launch worker for task 32] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 5 non-empty blocks out of 10 blocks
2021-12-08 10:09:09,366 [Executor task launch worker for task 32] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-08 10:09:09,370 [Executor task launch worker for task 33] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 7 non-empty blocks out of 10 blocks
2021-12-08 10:09:09,370 [Executor task launch worker for task 33] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-08 10:09:09,930 [dispatcher-event-loop-7] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_8_piece0 on qb:61292 in memory (size: 4.0 KB, free: 1913.2 MB)
2021-12-08 10:09:10,766 [Executor task launch worker for task 31] INFO [org.apache.spark.storage.memory.MemoryStore] - Block rdd_21_9 stored as values in memory (estimated size 4.4 MB, free 1907.3 MB)
2021-12-08 10:09:10,766 [dispatcher-event-loop-1] INFO [org.apache.spark.storage.BlockManagerInfo] - Added rdd_21_9 in memory on qb:61292 (size: 4.4 MB, free: 1908.9 MB)
2021-12-08 10:09:10,779 [Executor task launch worker for task 32] INFO [org.apache.spark.storage.memory.MemoryStore] - Block rdd_21_10 stored as values in memory (estimated size 4.5 MB, free 1902.9 MB)
2021-12-08 10:09:10,779 [dispatcher-event-loop-11] INFO [org.apache.spark.storage.BlockManagerInfo] - Added rdd_21_10 in memory on qb:61292 (size: 4.5 MB, free: 1904.4 MB)
2021-12-08 10:09:10,781 [Executor task launch worker for task 22] INFO [org.apache.spark.storage.memory.MemoryStore] - Block rdd_21_0 stored as values in memory (estimated size 4.4 MB, free 1898.5 MB)
2021-12-08 10:09:10,781 [dispatcher-event-loop-2] INFO [org.apache.spark.storage.BlockManagerInfo] - Added rdd_21_0 in memory on qb:61292 (size: 4.4 MB, free: 1900.0 MB)
2021-12-08 10:09:10,782 [Executor task launch worker for task 28] INFO [org.apache.spark.storage.memory.MemoryStore] - Block rdd_21_6 stored as values in memory (estimated size 4.4 MB, free 1894.0 MB)
2021-12-08 10:09:10,782 [Executor task launch worker for task 29] INFO [org.apache.spark.storage.memory.MemoryStore] - Block rdd_21_7 stored as values in memory (estimated size 4.4 MB, free 1889.6 MB)
2021-12-08 10:09:10,782 [dispatcher-event-loop-3] INFO [org.apache.spark.storage.BlockManagerInfo] - Added rdd_21_7 in memory on qb:61292 (size: 4.4 MB, free: 1895.5 MB)
2021-12-08 10:09:10,784 [dispatcher-event-loop-10] INFO [org.apache.spark.storage.BlockManagerInfo] - Added rdd_21_6 in memory on qb:61292 (size: 4.4 MB, free: 1891.1 MB)
2021-12-08 10:09:10,784 [Executor task launch worker for task 27] INFO [org.apache.spark.storage.memory.MemoryStore] - Block rdd_21_5 stored as values in memory (estimated size 4.4 MB, free 1885.2 MB)
2021-12-08 10:09:10,784 [dispatcher-event-loop-5] INFO [org.apache.spark.storage.BlockManagerInfo] - Added rdd_21_5 in memory on qb:61292 (size: 4.4 MB, free: 1886.8 MB)
2021-12-08 10:09:10,787 [Executor task launch worker for task 30] INFO [org.apache.spark.storage.memory.MemoryStore] - Block rdd_21_8 stored as values in memory (estimated size 4.4 MB, free 1880.8 MB)
2021-12-08 10:09:10,788 [dispatcher-event-loop-4] INFO [org.apache.spark.storage.BlockManagerInfo] - Added rdd_21_8 in memory on qb:61292 (size: 4.4 MB, free: 1882.4 MB)
2021-12-08 10:09:10,789 [Executor task launch worker for task 24] INFO [org.apache.spark.storage.memory.MemoryStore] - Block rdd_21_2 stored as values in memory (estimated size 4.3 MB, free 1876.5 MB)
2021-12-08 10:09:10,789 [dispatcher-event-loop-9] INFO [org.apache.spark.storage.BlockManagerInfo] - Added rdd_21_2 in memory on qb:61292 (size: 4.3 MB, free: 1878.0 MB)
2021-12-08 10:09:10,790 [Executor task launch worker for task 31] INFO [org.apache.spark.storage.memory.MemoryStore] - Block rdd_22_9 stored as values in memory (estimated size 344.5 KB, free 1876.2 MB)
2021-12-08 10:09:10,790 [dispatcher-event-loop-0] INFO [org.apache.spark.storage.BlockManagerInfo] - Added rdd_22_9 in memory on qb:61292 (size: 344.5 KB, free: 1877.7 MB)
2021-12-08 10:09:10,792 [Executor task launch worker for task 31] INFO [org.apache.spark.executor.Executor] - Finished task 9.0 in stage 4.0 (TID 31). 1096 bytes result sent to driver
2021-12-08 10:09:10,792 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 9.0 in stage 4.0 (TID 31) in 1437 ms on localhost (executor driver) (1/12)
2021-12-08 10:09:10,792 [Executor task launch worker for task 27] INFO [org.apache.spark.storage.memory.MemoryStore] - Block rdd_22_5 stored as values in memory (estimated size 340.8 KB, free 1875.5 MB)
2021-12-08 10:09:10,792 [Executor task launch worker for task 29] INFO [org.apache.spark.storage.memory.MemoryStore] - Block rdd_22_7 stored as values in memory (estimated size 343.9 KB, free 1875.5 MB)
2021-12-08 10:09:10,793 [dispatcher-event-loop-8] INFO [org.apache.spark.storage.BlockManagerInfo] - Added rdd_22_5 in memory on qb:61292 (size: 340.8 KB, free: 1877.4 MB)
2021-12-08 10:09:10,793 [dispatcher-event-loop-8] INFO [org.apache.spark.storage.BlockManagerInfo] - Added rdd_22_7 in memory on qb:61292 (size: 343.9 KB, free: 1877.0 MB)
2021-12-08 10:09:10,794 [Executor task launch worker for task 23] INFO [org.apache.spark.storage.memory.MemoryStore] - Block rdd_21_1 stored as values in memory (estimated size 4.4 MB, free 1871.1 MB)
2021-12-08 10:09:10,794 [dispatcher-event-loop-1] INFO [org.apache.spark.storage.BlockManagerInfo] - Added rdd_21_1 in memory on qb:61292 (size: 4.4 MB, free: 1872.6 MB)
2021-12-08 10:09:10,794 [Executor task launch worker for task 32] INFO [org.apache.spark.storage.memory.MemoryStore] - Block rdd_22_10 stored as values in memory (estimated size 342.7 KB, free 1866.3 MB)
2021-12-08 10:09:10,795 [dispatcher-event-loop-11] INFO [org.apache.spark.storage.BlockManagerInfo] - Added rdd_22_10 in memory on qb:61292 (size: 342.7 KB, free: 1872.3 MB)
2021-12-08 10:09:10,795 [Executor task launch worker for task 27] INFO [org.apache.spark.executor.Executor] - Finished task 5.0 in stage 4.0 (TID 27). 1096 bytes result sent to driver
2021-12-08 10:09:10,795 [Executor task launch worker for task 29] INFO [org.apache.spark.executor.Executor] - Finished task 7.0 in stage 4.0 (TID 29). 1096 bytes result sent to driver
2021-12-08 10:09:10,795 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 5.0 in stage 4.0 (TID 27) in 1441 ms on localhost (executor driver) (2/12)
2021-12-08 10:09:10,795 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 7.0 in stage 4.0 (TID 29) in 1440 ms on localhost (executor driver) (3/12)
2021-12-08 10:09:10,796 [Executor task launch worker for task 26] INFO [org.apache.spark.storage.memory.MemoryStore] - Block rdd_21_4 stored as values in memory (estimated size 4.4 MB, free 1866.3 MB)
2021-12-08 10:09:10,796 [dispatcher-event-loop-10] INFO [org.apache.spark.storage.BlockManagerInfo] - Added rdd_21_4 in memory on qb:61292 (size: 4.4 MB, free: 1867.8 MB)
2021-12-08 10:09:10,796 [Executor task launch worker for task 32] INFO [org.apache.spark.executor.Executor] - Finished task 10.0 in stage 4.0 (TID 32). 1096 bytes result sent to driver
2021-12-08 10:09:10,803 [Executor task launch worker for task 30] INFO [org.apache.spark.storage.memory.MemoryStore] - Block rdd_22_8 stored as values in memory (estimated size 343.2 KB, free 1866.0 MB)
2021-12-08 10:09:10,803 [dispatcher-event-loop-4] INFO [org.apache.spark.storage.BlockManagerInfo] - Added rdd_22_8 in memory on qb:61292 (size: 343.2 KB, free: 1867.5 MB)
2021-12-08 10:09:10,805 [Executor task launch worker for task 30] INFO [org.apache.spark.executor.Executor] - Finished task 8.0 in stage 4.0 (TID 30). 1096 bytes result sent to driver
2021-12-08 10:09:10,807 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 10.0 in stage 4.0 (TID 32) in 1443 ms on localhost (executor driver) (4/12)
2021-12-08 10:09:10,810 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 8.0 in stage 4.0 (TID 30) in 1455 ms on localhost (executor driver) (5/12)
2021-12-08 10:09:10,817 [Executor task launch worker for task 33] INFO [org.apache.spark.storage.memory.MemoryStore] - Block rdd_21_11 stored as values in memory (estimated size 4.4 MB, free 1861.6 MB)
2021-12-08 10:09:10,817 [dispatcher-event-loop-0] INFO [org.apache.spark.storage.BlockManagerInfo] - Added rdd_21_11 in memory on qb:61292 (size: 4.4 MB, free: 1863.1 MB)
2021-12-08 10:09:10,818 [Executor task launch worker for task 25] INFO [org.apache.spark.storage.memory.MemoryStore] - Block rdd_21_3 stored as values in memory (estimated size 4.5 MB, free 1857.1 MB)
2021-12-08 10:09:10,818 [dispatcher-event-loop-6] INFO [org.apache.spark.storage.BlockManagerInfo] - Added rdd_21_3 in memory on qb:61292 (size: 4.5 MB, free: 1858.7 MB)
2021-12-08 10:09:10,823 [Executor task launch worker for task 33] INFO [org.apache.spark.storage.memory.MemoryStore] - Block rdd_22_11 stored as values in memory (estimated size 338.4 KB, free 1856.5 MB)
2021-12-08 10:09:10,823 [Executor task launch worker for task 25] INFO [org.apache.spark.storage.memory.MemoryStore] - Block rdd_22_3 stored as values in memory (estimated size 342.3 KB, free 1856.5 MB)
2021-12-08 10:09:10,823 [dispatcher-event-loop-7] INFO [org.apache.spark.storage.BlockManagerInfo] - Added rdd_22_3 in memory on qb:61292 (size: 342.3 KB, free: 1858.3 MB)
2021-12-08 10:09:10,823 [dispatcher-event-loop-7] INFO [org.apache.spark.storage.BlockManagerInfo] - Added rdd_22_11 in memory on qb:61292 (size: 338.4 KB, free: 1858.0 MB)
2021-12-08 10:09:10,825 [Executor task launch worker for task 25] INFO [org.apache.spark.executor.Executor] - Finished task 3.0 in stage 4.0 (TID 25). 1139 bytes result sent to driver
2021-12-08 10:09:10,825 [Executor task launch worker for task 33] INFO [org.apache.spark.executor.Executor] - Finished task 11.0 in stage 4.0 (TID 33). 1096 bytes result sent to driver
2021-12-08 10:09:10,825 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 3.0 in stage 4.0 (TID 25) in 1471 ms on localhost (executor driver) (6/12)
2021-12-08 10:09:10,825 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 11.0 in stage 4.0 (TID 33) in 1470 ms on localhost (executor driver) (7/12)
2021-12-08 10:09:10,827 [Executor task launch worker for task 28] INFO [org.apache.spark.storage.memory.MemoryStore] - Block rdd_22_6 stored as values in memory (estimated size 341.6 KB, free 1856.1 MB)
2021-12-08 10:09:10,827 [Executor task launch worker for task 24] INFO [org.apache.spark.storage.memory.MemoryStore] - Block rdd_22_2 stored as values in memory (estimated size 338.6 KB, free 1855.8 MB)
2021-12-08 10:09:10,827 [dispatcher-event-loop-2] INFO [org.apache.spark.storage.BlockManagerInfo] - Added rdd_22_6 in memory on qb:61292 (size: 341.6 KB, free: 1857.7 MB)
2021-12-08 10:09:10,827 [Executor task launch worker for task 22] INFO [org.apache.spark.storage.memory.MemoryStore] - Block rdd_22_0 stored as values in memory (estimated size 342.9 KB, free 1855.1 MB)
2021-12-08 10:09:10,828 [Executor task launch worker for task 23] INFO [org.apache.spark.storage.memory.MemoryStore] - Block rdd_22_1 stored as values in memory (estimated size 343.3 KB, free 1855.1 MB)
2021-12-08 10:09:10,828 [dispatcher-event-loop-2] INFO [org.apache.spark.storage.BlockManagerInfo] - Added rdd_22_2 in memory on qb:61292 (size: 338.6 KB, free: 1857.3 MB)
2021-12-08 10:09:10,828 [dispatcher-event-loop-2] INFO [org.apache.spark.storage.BlockManagerInfo] - Added rdd_22_0 in memory on qb:61292 (size: 342.9 KB, free: 1857.0 MB)
2021-12-08 10:09:10,828 [Executor task launch worker for task 26] INFO [org.apache.spark.storage.memory.MemoryStore] - Block rdd_22_4 stored as values in memory (estimated size 343.9 KB, free 1854.8 MB)
2021-12-08 10:09:10,828 [dispatcher-event-loop-2] INFO [org.apache.spark.storage.BlockManagerInfo] - Added rdd_22_1 in memory on qb:61292 (size: 343.3 KB, free: 1856.7 MB)
2021-12-08 10:09:10,828 [dispatcher-event-loop-2] INFO [org.apache.spark.storage.BlockManagerInfo] - Added rdd_22_4 in memory on qb:61292 (size: 343.9 KB, free: 1856.3 MB)
2021-12-08 10:09:10,829 [Executor task launch worker for task 28] INFO [org.apache.spark.executor.Executor] - Finished task 6.0 in stage 4.0 (TID 28). 1096 bytes result sent to driver
2021-12-08 10:09:10,829 [Executor task launch worker for task 24] INFO [org.apache.spark.executor.Executor] - Finished task 2.0 in stage 4.0 (TID 24). 1096 bytes result sent to driver
2021-12-08 10:09:10,829 [Executor task launch worker for task 22] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 4.0 (TID 22). 1096 bytes result sent to driver
2021-12-08 10:09:10,829 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 6.0 in stage 4.0 (TID 28) in 1475 ms on localhost (executor driver) (8/12)
2021-12-08 10:09:10,830 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 2.0 in stage 4.0 (TID 24) in 1476 ms on localhost (executor driver) (9/12)
2021-12-08 10:09:10,830 [Executor task launch worker for task 23] INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 4.0 (TID 23). 1096 bytes result sent to driver
2021-12-08 10:09:10,830 [Executor task launch worker for task 26] INFO [org.apache.spark.executor.Executor] - Finished task 4.0 in stage 4.0 (TID 26). 1096 bytes result sent to driver
2021-12-08 10:09:10,830 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 4.0 (TID 22) in 1476 ms on localhost (executor driver) (10/12)
2021-12-08 10:09:10,830 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 4.0 (TID 23) in 1476 ms on localhost (executor driver) (11/12)
2021-12-08 10:09:10,830 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 4.0 in stage 4.0 (TID 26) in 1476 ms on localhost (executor driver) (12/12)
2021-12-08 10:09:10,830 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 4.0, whose tasks have all completed, from pool 
2021-12-08 10:09:10,830 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 4 (count at ALS.scala:931) finished in 1.481 s
2021-12-08 10:09:10,831 [main] INFO [org.apache.spark.scheduler.DAGScheduler] - Job 2 finished: count at ALS.scala:931, took 9.804179 s
2021-12-08 10:09:10,849 [main] INFO [org.apache.spark.SparkContext] - Starting job: count at ALS.scala:938
2021-12-08 10:09:10,850 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 24 (map at ALS.scala:1564)
2021-12-08 10:09:10,850 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 3 (count at ALS.scala:938) with 12 output partitions
2021-12-08 10:09:10,850 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 7 (count at ALS.scala:938)
2021-12-08 10:09:10,850 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 6)
2021-12-08 10:09:10,850 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List(ShuffleMapStage 6)
2021-12-08 10:09:10,851 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ShuffleMapStage 6 (MapPartitionsRDD[24] at map at ALS.scala:1564), which has no missing parents
2021-12-08 10:09:10,852 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_10 stored as values in memory (estimated size 7.8 KB, free 1854.8 MB)
2021-12-08 10:09:10,853 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_10_piece0 stored as bytes in memory (estimated size 4.0 KB, free 1854.8 MB)
2021-12-08 10:09:10,853 [dispatcher-event-loop-10] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_10_piece0 in memory on qb:61292 (size: 4.0 KB, free: 1856.3 MB)
2021-12-08 10:09:10,854 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 10 from broadcast at DAGScheduler.scala:1039
2021-12-08 10:09:10,854 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 10 missing tasks from ShuffleMapStage 6 (MapPartitionsRDD[24] at map at ALS.scala:1564) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
2021-12-08 10:09:10,854 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 6.0 with 10 tasks
2021-12-08 10:09:10,856 [dispatcher-event-loop-5] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 6.0 (TID 34, localhost, executor driver, partition 0, PROCESS_LOCAL, 7638 bytes)
2021-12-08 10:09:10,856 [dispatcher-event-loop-5] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 6.0 (TID 35, localhost, executor driver, partition 1, PROCESS_LOCAL, 7638 bytes)
2021-12-08 10:09:10,856 [dispatcher-event-loop-5] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 2.0 in stage 6.0 (TID 36, localhost, executor driver, partition 2, PROCESS_LOCAL, 7638 bytes)
2021-12-08 10:09:10,856 [dispatcher-event-loop-5] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 3.0 in stage 6.0 (TID 37, localhost, executor driver, partition 3, PROCESS_LOCAL, 7638 bytes)
2021-12-08 10:09:10,856 [dispatcher-event-loop-5] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 4.0 in stage 6.0 (TID 38, localhost, executor driver, partition 4, PROCESS_LOCAL, 7638 bytes)
2021-12-08 10:09:10,856 [dispatcher-event-loop-5] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 5.0 in stage 6.0 (TID 39, localhost, executor driver, partition 5, PROCESS_LOCAL, 7638 bytes)
2021-12-08 10:09:10,856 [dispatcher-event-loop-5] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 6.0 in stage 6.0 (TID 40, localhost, executor driver, partition 6, PROCESS_LOCAL, 7638 bytes)
2021-12-08 10:09:10,856 [dispatcher-event-loop-5] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 7.0 in stage 6.0 (TID 41, localhost, executor driver, partition 7, PROCESS_LOCAL, 7638 bytes)
2021-12-08 10:09:10,856 [dispatcher-event-loop-5] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 8.0 in stage 6.0 (TID 42, localhost, executor driver, partition 8, PROCESS_LOCAL, 7638 bytes)
2021-12-08 10:09:10,856 [dispatcher-event-loop-5] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 9.0 in stage 6.0 (TID 43, localhost, executor driver, partition 9, PROCESS_LOCAL, 7638 bytes)
2021-12-08 10:09:10,857 [Executor task launch worker for task 35] INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 6.0 (TID 35)
2021-12-08 10:09:10,857 [Executor task launch worker for task 40] INFO [org.apache.spark.executor.Executor] - Running task 6.0 in stage 6.0 (TID 40)
2021-12-08 10:09:10,857 [Executor task launch worker for task 43] INFO [org.apache.spark.executor.Executor] - Running task 9.0 in stage 6.0 (TID 43)
2021-12-08 10:09:10,857 [Executor task launch worker for task 42] INFO [org.apache.spark.executor.Executor] - Running task 8.0 in stage 6.0 (TID 42)
2021-12-08 10:09:10,857 [Executor task launch worker for task 41] INFO [org.apache.spark.executor.Executor] - Running task 7.0 in stage 6.0 (TID 41)
2021-12-08 10:09:10,857 [Executor task launch worker for task 39] INFO [org.apache.spark.executor.Executor] - Running task 5.0 in stage 6.0 (TID 39)
2021-12-08 10:09:10,857 [Executor task launch worker for task 38] INFO [org.apache.spark.executor.Executor] - Running task 4.0 in stage 6.0 (TID 38)
2021-12-08 10:09:10,857 [Executor task launch worker for task 36] INFO [org.apache.spark.executor.Executor] - Running task 2.0 in stage 6.0 (TID 36)
2021-12-08 10:09:10,857 [Executor task launch worker for task 37] INFO [org.apache.spark.executor.Executor] - Running task 3.0 in stage 6.0 (TID 37)
2021-12-08 10:09:10,857 [Executor task launch worker for task 34] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 6.0 (TID 34)
2021-12-08 10:09:10,859 [Executor task launch worker for task 37] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_18_3 locally
2021-12-08 10:09:10,859 [Executor task launch worker for task 39] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_18_5 locally
2021-12-08 10:09:10,859 [Executor task launch worker for task 38] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_18_4 locally
2021-12-08 10:09:10,859 [Executor task launch worker for task 41] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_18_7 locally
2021-12-08 10:09:10,859 [Executor task launch worker for task 43] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_18_9 locally
2021-12-08 10:09:10,859 [Executor task launch worker for task 40] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_18_6 locally
2021-12-08 10:09:10,859 [Executor task launch worker for task 34] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_18_0 locally
2021-12-08 10:09:10,859 [Executor task launch worker for task 35] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_18_1 locally
2021-12-08 10:09:10,860 [Executor task launch worker for task 36] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_18_2 locally
2021-12-08 10:09:10,860 [Executor task launch worker for task 42] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_18_8 locally
2021-12-08 10:09:11,098 [Executor task launch worker for task 38] INFO [org.apache.spark.executor.Executor] - Finished task 4.0 in stage 6.0 (TID 38). 913 bytes result sent to driver
2021-12-08 10:09:11,099 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 4.0 in stage 6.0 (TID 38) in 243 ms on localhost (executor driver) (1/10)
2021-12-08 10:09:11,108 [Executor task launch worker for task 43] INFO [org.apache.spark.executor.Executor] - Finished task 9.0 in stage 6.0 (TID 43). 913 bytes result sent to driver
2021-12-08 10:09:11,108 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 9.0 in stage 6.0 (TID 43) in 252 ms on localhost (executor driver) (2/10)
2021-12-08 10:09:11,110 [Executor task launch worker for task 34] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 6.0 (TID 34). 913 bytes result sent to driver
2021-12-08 10:09:11,110 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 6.0 (TID 34) in 255 ms on localhost (executor driver) (3/10)
2021-12-08 10:09:11,138 [Executor task launch worker for task 41] INFO [org.apache.spark.executor.Executor] - Finished task 7.0 in stage 6.0 (TID 41). 913 bytes result sent to driver
2021-12-08 10:09:11,139 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 7.0 in stage 6.0 (TID 41) in 283 ms on localhost (executor driver) (4/10)
2021-12-08 10:09:11,143 [Executor task launch worker for task 35] INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 6.0 (TID 35). 913 bytes result sent to driver
2021-12-08 10:09:11,144 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 6.0 (TID 35) in 288 ms on localhost (executor driver) (5/10)
2021-12-08 10:09:11,174 [Executor task launch worker for task 40] INFO [org.apache.spark.executor.Executor] - Finished task 6.0 in stage 6.0 (TID 40). 913 bytes result sent to driver
2021-12-08 10:09:11,175 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 6.0 in stage 6.0 (TID 40) in 319 ms on localhost (executor driver) (6/10)
2021-12-08 10:09:11,180 [Executor task launch worker for task 39] INFO [org.apache.spark.executor.Executor] - Finished task 5.0 in stage 6.0 (TID 39). 913 bytes result sent to driver
2021-12-08 10:09:11,181 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 5.0 in stage 6.0 (TID 39) in 325 ms on localhost (executor driver) (7/10)
2021-12-08 10:09:11,184 [Executor task launch worker for task 37] INFO [org.apache.spark.executor.Executor] - Finished task 3.0 in stage 6.0 (TID 37). 913 bytes result sent to driver
2021-12-08 10:09:11,184 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 3.0 in stage 6.0 (TID 37) in 328 ms on localhost (executor driver) (8/10)
2021-12-08 10:09:11,197 [Executor task launch worker for task 42] INFO [org.apache.spark.executor.Executor] - Finished task 8.0 in stage 6.0 (TID 42). 913 bytes result sent to driver
2021-12-08 10:09:11,198 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 8.0 in stage 6.0 (TID 42) in 342 ms on localhost (executor driver) (9/10)
2021-12-08 10:09:11,215 [Executor task launch worker for task 36] INFO [org.apache.spark.executor.Executor] - Finished task 2.0 in stage 6.0 (TID 36). 913 bytes result sent to driver
2021-12-08 10:09:11,215 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 2.0 in stage 6.0 (TID 36) in 359 ms on localhost (executor driver) (10/10)
2021-12-08 10:09:11,215 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 6.0, whose tasks have all completed, from pool 
2021-12-08 10:09:11,216 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ShuffleMapStage 6 (map at ALS.scala:1564) finished in 0.365 s
2021-12-08 10:09:11,216 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - looking for newly runnable stages
2021-12-08 10:09:11,216 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - running: Set()
2021-12-08 10:09:11,216 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - waiting: Set(ResultStage 7)
2021-12-08 10:09:11,216 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - failed: Set()
2021-12-08 10:09:11,216 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 7 (itemOutBlocks MapPartitionsRDD[27] at mapValues at ALS.scala:1601), which has no missing parents
2021-12-08 10:09:11,217 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_11 stored as values in memory (estimated size 8.4 KB, free 1854.8 MB)
2021-12-08 10:09:11,219 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_11_piece0 stored as bytes in memory (estimated size 4.2 KB, free 1854.8 MB)
2021-12-08 10:09:11,219 [dispatcher-event-loop-10] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_11_piece0 in memory on qb:61292 (size: 4.2 KB, free: 1856.3 MB)
2021-12-08 10:09:11,219 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 11 from broadcast at DAGScheduler.scala:1039
2021-12-08 10:09:11,220 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 12 missing tasks from ResultStage 7 (itemOutBlocks MapPartitionsRDD[27] at mapValues at ALS.scala:1601) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11))
2021-12-08 10:09:11,220 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 7.0 with 12 tasks
2021-12-08 10:09:11,220 [dispatcher-event-loop-5] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 7.0 (TID 44, localhost, executor driver, partition 0, ANY, 7649 bytes)
2021-12-08 10:09:11,220 [dispatcher-event-loop-5] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 7.0 (TID 45, localhost, executor driver, partition 1, ANY, 7649 bytes)
2021-12-08 10:09:11,220 [dispatcher-event-loop-5] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 2.0 in stage 7.0 (TID 46, localhost, executor driver, partition 2, ANY, 7649 bytes)
2021-12-08 10:09:11,220 [dispatcher-event-loop-5] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 3.0 in stage 7.0 (TID 47, localhost, executor driver, partition 3, ANY, 7649 bytes)
2021-12-08 10:09:11,220 [dispatcher-event-loop-5] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 4.0 in stage 7.0 (TID 48, localhost, executor driver, partition 4, ANY, 7649 bytes)
2021-12-08 10:09:11,220 [dispatcher-event-loop-5] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 5.0 in stage 7.0 (TID 49, localhost, executor driver, partition 5, ANY, 7649 bytes)
2021-12-08 10:09:11,221 [dispatcher-event-loop-5] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 6.0 in stage 7.0 (TID 50, localhost, executor driver, partition 6, ANY, 7649 bytes)
2021-12-08 10:09:11,221 [dispatcher-event-loop-5] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 7.0 in stage 7.0 (TID 51, localhost, executor driver, partition 7, ANY, 7649 bytes)
2021-12-08 10:09:11,221 [dispatcher-event-loop-5] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 8.0 in stage 7.0 (TID 52, localhost, executor driver, partition 8, ANY, 7649 bytes)
2021-12-08 10:09:11,221 [dispatcher-event-loop-5] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 9.0 in stage 7.0 (TID 53, localhost, executor driver, partition 9, ANY, 7649 bytes)
2021-12-08 10:09:11,221 [dispatcher-event-loop-5] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 10.0 in stage 7.0 (TID 54, localhost, executor driver, partition 10, ANY, 7649 bytes)
2021-12-08 10:09:11,221 [dispatcher-event-loop-5] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 11.0 in stage 7.0 (TID 55, localhost, executor driver, partition 11, ANY, 7649 bytes)
2021-12-08 10:09:11,221 [Executor task launch worker for task 44] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 7.0 (TID 44)
2021-12-08 10:09:11,221 [Executor task launch worker for task 45] INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 7.0 (TID 45)
2021-12-08 10:09:11,221 [Executor task launch worker for task 51] INFO [org.apache.spark.executor.Executor] - Running task 7.0 in stage 7.0 (TID 51)
2021-12-08 10:09:11,221 [Executor task launch worker for task 46] INFO [org.apache.spark.executor.Executor] - Running task 2.0 in stage 7.0 (TID 46)
2021-12-08 10:09:11,221 [Executor task launch worker for task 49] INFO [org.apache.spark.executor.Executor] - Running task 5.0 in stage 7.0 (TID 49)
2021-12-08 10:09:11,221 [Executor task launch worker for task 50] INFO [org.apache.spark.executor.Executor] - Running task 6.0 in stage 7.0 (TID 50)
2021-12-08 10:09:11,221 [Executor task launch worker for task 47] INFO [org.apache.spark.executor.Executor] - Running task 3.0 in stage 7.0 (TID 47)
2021-12-08 10:09:11,221 [Executor task launch worker for task 48] INFO [org.apache.spark.executor.Executor] - Running task 4.0 in stage 7.0 (TID 48)
2021-12-08 10:09:11,221 [Executor task launch worker for task 53] INFO [org.apache.spark.executor.Executor] - Running task 9.0 in stage 7.0 (TID 53)
2021-12-08 10:09:11,221 [Executor task launch worker for task 52] INFO [org.apache.spark.executor.Executor] - Running task 8.0 in stage 7.0 (TID 52)
2021-12-08 10:09:11,221 [Executor task launch worker for task 55] INFO [org.apache.spark.executor.Executor] - Running task 11.0 in stage 7.0 (TID 55)
2021-12-08 10:09:11,221 [Executor task launch worker for task 54] INFO [org.apache.spark.executor.Executor] - Running task 10.0 in stage 7.0 (TID 54)
2021-12-08 10:09:11,223 [Executor task launch worker for task 54] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 8 non-empty blocks out of 10 blocks
2021-12-08 10:09:11,224 [Executor task launch worker for task 54] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 1 ms
2021-12-08 10:09:11,223 [Executor task launch worker for task 48] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 9 non-empty blocks out of 10 blocks
2021-12-08 10:09:11,224 [Executor task launch worker for task 48] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 1 ms
2021-12-08 10:09:11,224 [Executor task launch worker for task 50] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 6 non-empty blocks out of 10 blocks
2021-12-08 10:09:11,224 [Executor task launch worker for task 50] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-08 10:09:11,224 [Executor task launch worker for task 46] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 8 non-empty blocks out of 10 blocks
2021-12-08 10:09:11,224 [Executor task launch worker for task 46] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-08 10:09:11,224 [Executor task launch worker for task 49] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 7 non-empty blocks out of 10 blocks
2021-12-08 10:09:11,224 [Executor task launch worker for task 49] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-08 10:09:11,224 [Executor task launch worker for task 52] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 8 non-empty blocks out of 10 blocks
2021-12-08 10:09:11,224 [Executor task launch worker for task 52] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-08 10:09:11,224 [Executor task launch worker for task 55] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 5 non-empty blocks out of 10 blocks
2021-12-08 10:09:11,224 [Executor task launch worker for task 55] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-08 10:09:11,224 [Executor task launch worker for task 51] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 9 non-empty blocks out of 10 blocks
2021-12-08 10:09:11,224 [Executor task launch worker for task 51] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-08 10:09:11,224 [Executor task launch worker for task 53] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 6 non-empty blocks out of 10 blocks
2021-12-08 10:09:11,224 [Executor task launch worker for task 53] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-08 10:09:11,224 [Executor task launch worker for task 44] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 7 non-empty blocks out of 10 blocks
2021-12-08 10:09:11,224 [Executor task launch worker for task 45] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 8 non-empty blocks out of 10 blocks
2021-12-08 10:09:11,224 [Executor task launch worker for task 45] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-08 10:09:11,224 [Executor task launch worker for task 44] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-08 10:09:11,225 [Executor task launch worker for task 47] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 7 non-empty blocks out of 10 blocks
2021-12-08 10:09:11,225 [Executor task launch worker for task 47] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-08 10:09:11,470 [Executor task launch worker for task 54] INFO [org.apache.spark.storage.memory.MemoryStore] - Block rdd_26_10 stored as values in memory (estimated size 4.3 MB, free 1850.5 MB)
2021-12-08 10:09:11,473 [dispatcher-event-loop-0] INFO [org.apache.spark.storage.BlockManagerInfo] - Added rdd_26_10 in memory on qb:61292 (size: 4.3 MB, free: 1852.1 MB)
2021-12-08 10:09:11,477 [Executor task launch worker for task 54] INFO [org.apache.spark.storage.memory.MemoryStore] - Block rdd_27_10 stored as values in memory (estimated size 138.7 KB, free 1850.4 MB)
2021-12-08 10:09:11,479 [dispatcher-event-loop-2] INFO [org.apache.spark.storage.BlockManagerInfo] - Added rdd_27_10 in memory on qb:61292 (size: 138.7 KB, free: 1851.9 MB)
2021-12-08 10:09:11,482 [Executor task launch worker for task 54] INFO [org.apache.spark.executor.Executor] - Finished task 10.0 in stage 7.0 (TID 54). 1096 bytes result sent to driver
2021-12-08 10:09:11,482 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 10.0 in stage 7.0 (TID 54) in 261 ms on localhost (executor driver) (1/12)
2021-12-08 10:09:11,506 [Executor task launch worker for task 55] INFO [org.apache.spark.storage.memory.MemoryStore] - Block rdd_26_11 stored as values in memory (estimated size 4.2 MB, free 1846.2 MB)
2021-12-08 10:09:11,507 [dispatcher-event-loop-8] INFO [org.apache.spark.storage.BlockManagerInfo] - Added rdd_26_11 in memory on qb:61292 (size: 4.2 MB, free: 1847.8 MB)
2021-12-08 10:09:11,511 [Executor task launch worker for task 45] INFO [org.apache.spark.storage.memory.MemoryStore] - Block rdd_26_1 stored as values in memory (estimated size 3.9 MB, free 1842.4 MB)
2021-12-08 10:09:11,512 [dispatcher-event-loop-6] INFO [org.apache.spark.storage.BlockManagerInfo] - Added rdd_26_1 in memory on qb:61292 (size: 3.9 MB, free: 1843.9 MB)
2021-12-08 10:09:11,514 [Executor task launch worker for task 55] INFO [org.apache.spark.storage.memory.MemoryStore] - Block rdd_27_11 stored as values in memory (estimated size 138.1 KB, free 1842.2 MB)
2021-12-08 10:09:11,514 [dispatcher-event-loop-9] INFO [org.apache.spark.storage.BlockManagerInfo] - Added rdd_27_11 in memory on qb:61292 (size: 138.1 KB, free: 1843.8 MB)
2021-12-08 10:09:11,516 [Executor task launch worker for task 45] INFO [org.apache.spark.storage.memory.MemoryStore] - Block rdd_27_1 stored as values in memory (estimated size 139.2 KB, free 1842.1 MB)
2021-12-08 10:09:11,517 [Executor task launch worker for task 55] INFO [org.apache.spark.executor.Executor] - Finished task 11.0 in stage 7.0 (TID 55). 1139 bytes result sent to driver
2021-12-08 10:09:11,517 [dispatcher-event-loop-7] INFO [org.apache.spark.storage.BlockManagerInfo] - Added rdd_27_1 in memory on qb:61292 (size: 139.2 KB, free: 1843.6 MB)
2021-12-08 10:09:11,517 [Executor task launch worker for task 44] INFO [org.apache.spark.storage.memory.MemoryStore] - Block rdd_26_0 stored as values in memory (estimated size 4.1 MB, free 1838.0 MB)
2021-12-08 10:09:11,518 [dispatcher-event-loop-10] INFO [org.apache.spark.storage.BlockManagerInfo] - Added rdd_26_0 in memory on qb:61292 (size: 4.1 MB, free: 1839.6 MB)
2021-12-08 10:09:11,518 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 11.0 in stage 7.0 (TID 55) in 297 ms on localhost (executor driver) (2/12)
2021-12-08 10:09:11,520 [Executor task launch worker for task 45] INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 7.0 (TID 45). 1096 bytes result sent to driver
2021-12-08 10:09:11,520 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 7.0 (TID 45) in 300 ms on localhost (executor driver) (3/12)
2021-12-08 10:09:11,522 [Executor task launch worker for task 44] INFO [org.apache.spark.storage.memory.MemoryStore] - Block rdd_27_0 stored as values in memory (estimated size 136.3 KB, free 1837.9 MB)
2021-12-08 10:09:11,523 [dispatcher-event-loop-11] INFO [org.apache.spark.storage.BlockManagerInfo] - Added rdd_27_0 in memory on qb:61292 (size: 136.3 KB, free: 1839.4 MB)
2021-12-08 10:09:11,525 [Executor task launch worker for task 46] INFO [org.apache.spark.storage.memory.MemoryStore] - Block rdd_26_2 stored as values in memory (estimated size 4.9 MB, free 1833.0 MB)
2021-12-08 10:09:11,525 [dispatcher-event-loop-1] INFO [org.apache.spark.storage.BlockManagerInfo] - Added rdd_26_2 in memory on qb:61292 (size: 4.9 MB, free: 1834.5 MB)
2021-12-08 10:09:11,526 [Executor task launch worker for task 44] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 7.0 (TID 44). 1096 bytes result sent to driver
2021-12-08 10:09:11,527 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 7.0 (TID 44) in 307 ms on localhost (executor driver) (4/12)
2021-12-08 10:09:11,528 [Executor task launch worker for task 48] INFO [org.apache.spark.storage.memory.MemoryStore] - Block rdd_26_4 stored as values in memory (estimated size 4.1 MB, free 1828.9 MB)
2021-12-08 10:09:11,530 [Executor task launch worker for task 50] INFO [org.apache.spark.storage.memory.MemoryStore] - Block rdd_26_6 stored as values in memory (estimated size 4.9 MB, free 1824.0 MB)
2021-12-08 10:09:11,531 [Executor task launch worker for task 46] INFO [org.apache.spark.storage.memory.MemoryStore] - Block rdd_27_2 stored as values in memory (estimated size 137.0 KB, free 1823.9 MB)
2021-12-08 10:09:11,532 [dispatcher-event-loop-2] INFO [org.apache.spark.storage.BlockManagerInfo] - Added rdd_26_4 in memory on qb:61292 (size: 4.1 MB, free: 1830.4 MB)
2021-12-08 10:09:11,532 [dispatcher-event-loop-2] INFO [org.apache.spark.storage.BlockManagerInfo] - Added rdd_26_6 in memory on qb:61292 (size: 4.9 MB, free: 1825.6 MB)
2021-12-08 10:09:11,532 [dispatcher-event-loop-2] INFO [org.apache.spark.storage.BlockManagerInfo] - Added rdd_27_2 in memory on qb:61292 (size: 137.0 KB, free: 1825.4 MB)
2021-12-08 10:09:11,536 [Executor task launch worker for task 46] INFO [org.apache.spark.executor.Executor] - Finished task 2.0 in stage 7.0 (TID 46). 1096 bytes result sent to driver
2021-12-08 10:09:11,537 [Executor task launch worker for task 48] INFO [org.apache.spark.storage.memory.MemoryStore] - Block rdd_27_4 stored as values in memory (estimated size 138.3 KB, free 1823.8 MB)
2021-12-08 10:09:11,537 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 2.0 in stage 7.0 (TID 46) in 317 ms on localhost (executor driver) (5/12)
2021-12-08 10:09:11,537 [dispatcher-event-loop-6] INFO [org.apache.spark.storage.BlockManagerInfo] - Added rdd_27_4 in memory on qb:61292 (size: 138.3 KB, free: 1825.3 MB)
2021-12-08 10:09:11,541 [Executor task launch worker for task 50] INFO [org.apache.spark.storage.memory.MemoryStore] - Block rdd_27_6 stored as values in memory (estimated size 138.5 KB, free 1823.6 MB)
2021-12-08 10:09:11,542 [dispatcher-event-loop-7] INFO [org.apache.spark.storage.BlockManagerInfo] - Added rdd_27_6 in memory on qb:61292 (size: 138.5 KB, free: 1825.2 MB)
2021-12-08 10:09:11,542 [Executor task launch worker for task 48] INFO [org.apache.spark.executor.Executor] - Finished task 4.0 in stage 7.0 (TID 48). 1096 bytes result sent to driver
2021-12-08 10:09:11,543 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 4.0 in stage 7.0 (TID 48) in 323 ms on localhost (executor driver) (6/12)
2021-12-08 10:09:11,544 [Executor task launch worker for task 50] INFO [org.apache.spark.executor.Executor] - Finished task 6.0 in stage 7.0 (TID 50). 1096 bytes result sent to driver
2021-12-08 10:09:11,545 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 6.0 in stage 7.0 (TID 50) in 324 ms on localhost (executor driver) (7/12)
2021-12-08 10:09:11,551 [Executor task launch worker for task 52] INFO [org.apache.spark.storage.memory.MemoryStore] - Block rdd_26_8 stored as values in memory (estimated size 4.3 MB, free 1819.3 MB)
2021-12-08 10:09:11,552 [dispatcher-event-loop-5] INFO [org.apache.spark.storage.BlockManagerInfo] - Added rdd_26_8 in memory on qb:61292 (size: 4.3 MB, free: 1820.9 MB)
2021-12-08 10:09:11,557 [Executor task launch worker for task 52] INFO [org.apache.spark.storage.memory.MemoryStore] - Block rdd_27_8 stored as values in memory (estimated size 137.0 KB, free 1819.2 MB)
2021-12-08 10:09:11,558 [dispatcher-event-loop-11] INFO [org.apache.spark.storage.BlockManagerInfo] - Added rdd_27_8 in memory on qb:61292 (size: 137.0 KB, free: 1820.8 MB)
2021-12-08 10:09:11,559 [Executor task launch worker for task 49] INFO [org.apache.spark.storage.memory.MemoryStore] - Block rdd_26_5 stored as values in memory (estimated size 3.9 MB, free 1815.4 MB)
2021-12-08 10:09:11,559 [dispatcher-event-loop-1] INFO [org.apache.spark.storage.BlockManagerInfo] - Added rdd_26_5 in memory on qb:61292 (size: 3.9 MB, free: 1816.9 MB)
2021-12-08 10:09:11,560 [Executor task launch worker for task 52] INFO [org.apache.spark.executor.Executor] - Finished task 8.0 in stage 7.0 (TID 52). 1096 bytes result sent to driver
2021-12-08 10:09:11,562 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 8.0 in stage 7.0 (TID 52) in 341 ms on localhost (executor driver) (8/12)
2021-12-08 10:09:11,564 [Executor task launch worker for task 49] INFO [org.apache.spark.storage.memory.MemoryStore] - Block rdd_27_5 stored as values in memory (estimated size 137.8 KB, free 1815.2 MB)
2021-12-08 10:09:11,565 [dispatcher-event-loop-4] INFO [org.apache.spark.storage.BlockManagerInfo] - Added rdd_27_5 in memory on qb:61292 (size: 137.8 KB, free: 1816.8 MB)
2021-12-08 10:09:11,567 [Executor task launch worker for task 49] INFO [org.apache.spark.executor.Executor] - Finished task 5.0 in stage 7.0 (TID 49). 1096 bytes result sent to driver
2021-12-08 10:09:11,568 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 5.0 in stage 7.0 (TID 49) in 348 ms on localhost (executor driver) (9/12)
2021-12-08 10:09:11,569 [Executor task launch worker for task 53] INFO [org.apache.spark.storage.memory.MemoryStore] - Block rdd_26_9 stored as values in memory (estimated size 4.6 MB, free 1810.6 MB)
2021-12-08 10:09:11,569 [Executor task launch worker for task 51] INFO [org.apache.spark.storage.memory.MemoryStore] - Block rdd_26_7 stored as values in memory (estimated size 4.4 MB, free 1806.2 MB)
2021-12-08 10:09:11,569 [dispatcher-event-loop-2] INFO [org.apache.spark.storage.BlockManagerInfo] - Added rdd_26_7 in memory on qb:61292 (size: 4.4 MB, free: 1812.4 MB)
2021-12-08 10:09:11,569 [dispatcher-event-loop-2] INFO [org.apache.spark.storage.BlockManagerInfo] - Added rdd_26_9 in memory on qb:61292 (size: 4.6 MB, free: 1807.7 MB)
2021-12-08 10:09:11,573 [Executor task launch worker for task 51] INFO [org.apache.spark.storage.memory.MemoryStore] - Block rdd_27_7 stored as values in memory (estimated size 138.3 KB, free 1806.1 MB)
2021-12-08 10:09:11,573 [Executor task launch worker for task 53] INFO [org.apache.spark.storage.memory.MemoryStore] - Block rdd_27_9 stored as values in memory (estimated size 136.9 KB, free 1805.9 MB)
2021-12-08 10:09:11,573 [dispatcher-event-loop-6] INFO [org.apache.spark.storage.BlockManagerInfo] - Added rdd_27_7 in memory on qb:61292 (size: 138.3 KB, free: 1807.6 MB)
2021-12-08 10:09:11,573 [dispatcher-event-loop-6] INFO [org.apache.spark.storage.BlockManagerInfo] - Added rdd_27_9 in memory on qb:61292 (size: 136.9 KB, free: 1807.5 MB)
2021-12-08 10:09:11,573 [Executor task launch worker for task 47] INFO [org.apache.spark.storage.memory.MemoryStore] - Block rdd_26_3 stored as values in memory (estimated size 4.7 MB, free 1801.2 MB)
2021-12-08 10:09:11,574 [dispatcher-event-loop-3] INFO [org.apache.spark.storage.BlockManagerInfo] - Added rdd_26_3 in memory on qb:61292 (size: 4.7 MB, free: 1802.8 MB)
2021-12-08 10:09:11,575 [Executor task launch worker for task 51] INFO [org.apache.spark.executor.Executor] - Finished task 7.0 in stage 7.0 (TID 51). 1096 bytes result sent to driver
2021-12-08 10:09:11,575 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 7.0 in stage 7.0 (TID 51) in 354 ms on localhost (executor driver) (10/12)
2021-12-08 10:09:11,576 [Executor task launch worker for task 53] INFO [org.apache.spark.executor.Executor] - Finished task 9.0 in stage 7.0 (TID 53). 1096 bytes result sent to driver
2021-12-08 10:09:11,576 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 9.0 in stage 7.0 (TID 53) in 355 ms on localhost (executor driver) (11/12)
2021-12-08 10:09:11,577 [Executor task launch worker for task 47] INFO [org.apache.spark.storage.memory.MemoryStore] - Block rdd_27_3 stored as values in memory (estimated size 139.4 KB, free 1801.1 MB)
2021-12-08 10:09:11,578 [dispatcher-event-loop-11] INFO [org.apache.spark.storage.BlockManagerInfo] - Added rdd_27_3 in memory on qb:61292 (size: 139.4 KB, free: 1802.6 MB)
2021-12-08 10:09:11,579 [Executor task launch worker for task 47] INFO [org.apache.spark.executor.Executor] - Finished task 3.0 in stage 7.0 (TID 47). 1096 bytes result sent to driver
2021-12-08 10:09:11,580 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 3.0 in stage 7.0 (TID 47) in 359 ms on localhost (executor driver) (12/12)
2021-12-08 10:09:11,580 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 7.0, whose tasks have all completed, from pool 
2021-12-08 10:09:11,580 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 7 (count at ALS.scala:938) finished in 0.363 s
2021-12-08 10:09:11,580 [main] INFO [org.apache.spark.scheduler.DAGScheduler] - Job 3 finished: count at ALS.scala:938, took 0.731005 s
2021-12-08 10:09:11,611 [main] INFO [org.apache.spark.SparkContext] - Starting job: aggregate at ALS.scala:1711
2021-12-08 10:09:11,611 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 4 (aggregate at ALS.scala:1711) with 12 output partitions
2021-12-08 10:09:11,612 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 10 (aggregate at ALS.scala:1711)
2021-12-08 10:09:11,612 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 9)
2021-12-08 10:09:11,612 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2021-12-08 10:09:11,612 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 10 (MapPartitionsRDD[30] at values at ALS.scala:1711), which has no missing parents
2021-12-08 10:09:11,614 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_12 stored as values in memory (estimated size 169.2 KB, free 1800.9 MB)
2021-12-08 10:09:11,616 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_12_piece0 stored as bytes in memory (estimated size 5.3 KB, free 1800.9 MB)
2021-12-08 10:09:11,617 [dispatcher-event-loop-8] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_12_piece0 in memory on qb:61292 (size: 5.3 KB, free: 1802.6 MB)
2021-12-08 10:09:11,617 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 12 from broadcast at DAGScheduler.scala:1039
2021-12-08 10:09:11,617 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 12 missing tasks from ResultStage 10 (MapPartitionsRDD[30] at values at ALS.scala:1711) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11))
2021-12-08 10:09:11,617 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 10.0 with 12 tasks
2021-12-08 10:09:11,618 [dispatcher-event-loop-9] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 10.0 (TID 56, localhost, executor driver, partition 0, PROCESS_LOCAL, 7649 bytes)
2021-12-08 10:09:11,618 [dispatcher-event-loop-9] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 10.0 (TID 57, localhost, executor driver, partition 1, PROCESS_LOCAL, 7649 bytes)
2021-12-08 10:09:11,618 [dispatcher-event-loop-9] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 2.0 in stage 10.0 (TID 58, localhost, executor driver, partition 2, PROCESS_LOCAL, 7649 bytes)
2021-12-08 10:09:11,618 [dispatcher-event-loop-9] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 3.0 in stage 10.0 (TID 59, localhost, executor driver, partition 3, PROCESS_LOCAL, 7649 bytes)
2021-12-08 10:09:11,618 [dispatcher-event-loop-9] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 4.0 in stage 10.0 (TID 60, localhost, executor driver, partition 4, PROCESS_LOCAL, 7649 bytes)
2021-12-08 10:09:11,618 [dispatcher-event-loop-9] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 5.0 in stage 10.0 (TID 61, localhost, executor driver, partition 5, PROCESS_LOCAL, 7649 bytes)
2021-12-08 10:09:11,618 [dispatcher-event-loop-9] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 6.0 in stage 10.0 (TID 62, localhost, executor driver, partition 6, PROCESS_LOCAL, 7649 bytes)
2021-12-08 10:09:11,619 [dispatcher-event-loop-9] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 7.0 in stage 10.0 (TID 63, localhost, executor driver, partition 7, PROCESS_LOCAL, 7649 bytes)
2021-12-08 10:09:11,619 [dispatcher-event-loop-9] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 8.0 in stage 10.0 (TID 64, localhost, executor driver, partition 8, PROCESS_LOCAL, 7649 bytes)
2021-12-08 10:09:11,619 [dispatcher-event-loop-9] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 9.0 in stage 10.0 (TID 65, localhost, executor driver, partition 9, PROCESS_LOCAL, 7649 bytes)
2021-12-08 10:09:11,619 [dispatcher-event-loop-9] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 10.0 in stage 10.0 (TID 66, localhost, executor driver, partition 10, PROCESS_LOCAL, 7649 bytes)
2021-12-08 10:09:11,619 [dispatcher-event-loop-9] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 11.0 in stage 10.0 (TID 67, localhost, executor driver, partition 11, PROCESS_LOCAL, 7649 bytes)
2021-12-08 10:09:11,619 [Executor task launch worker for task 58] INFO [org.apache.spark.executor.Executor] - Running task 2.0 in stage 10.0 (TID 58)
2021-12-08 10:09:11,619 [Executor task launch worker for task 62] INFO [org.apache.spark.executor.Executor] - Running task 6.0 in stage 10.0 (TID 62)
2021-12-08 10:09:11,619 [Executor task launch worker for task 67] INFO [org.apache.spark.executor.Executor] - Running task 11.0 in stage 10.0 (TID 67)
2021-12-08 10:09:11,619 [Executor task launch worker for task 61] INFO [org.apache.spark.executor.Executor] - Running task 5.0 in stage 10.0 (TID 61)
2021-12-08 10:09:11,619 [Executor task launch worker for task 60] INFO [org.apache.spark.executor.Executor] - Running task 4.0 in stage 10.0 (TID 60)
2021-12-08 10:09:11,619 [Executor task launch worker for task 57] INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 10.0 (TID 57)
2021-12-08 10:09:11,619 [Executor task launch worker for task 56] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 10.0 (TID 56)
2021-12-08 10:09:11,619 [Executor task launch worker for task 59] INFO [org.apache.spark.executor.Executor] - Running task 3.0 in stage 10.0 (TID 59)
2021-12-08 10:09:11,619 [Executor task launch worker for task 66] INFO [org.apache.spark.executor.Executor] - Running task 10.0 in stage 10.0 (TID 66)
2021-12-08 10:09:11,619 [Executor task launch worker for task 65] INFO [org.apache.spark.executor.Executor] - Running task 9.0 in stage 10.0 (TID 65)
2021-12-08 10:09:11,619 [Executor task launch worker for task 63] INFO [org.apache.spark.executor.Executor] - Running task 7.0 in stage 10.0 (TID 63)
2021-12-08 10:09:11,619 [Executor task launch worker for task 64] INFO [org.apache.spark.executor.Executor] - Running task 8.0 in stage 10.0 (TID 64)
2021-12-08 10:09:11,621 [Executor task launch worker for task 62] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_21_6 locally
2021-12-08 10:09:11,621 [Executor task launch worker for task 60] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_21_4 locally
2021-12-08 10:09:11,621 [Executor task launch worker for task 59] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_21_3 locally
2021-12-08 10:09:11,621 [Executor task launch worker for task 56] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_21_0 locally
2021-12-08 10:09:11,622 [Executor task launch worker for task 66] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_21_10 locally
2021-12-08 10:09:11,622 [Executor task launch worker for task 58] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_21_2 locally
2021-12-08 10:09:11,623 [Executor task launch worker for task 57] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_21_1 locally
2021-12-08 10:09:11,623 [Executor task launch worker for task 67] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_21_11 locally
2021-12-08 10:09:11,623 [Executor task launch worker for task 65] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_21_9 locally
2021-12-08 10:09:11,623 [Executor task launch worker for task 64] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_21_8 locally
2021-12-08 10:09:11,623 [Executor task launch worker for task 63] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_21_7 locally
2021-12-08 10:09:11,623 [Executor task launch worker for task 61] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_21_5 locally
2021-12-08 10:09:11,627 [Executor task launch worker for task 59] WARN [com.github.fommil.netlib.BLAS] - Failed to load implementation from: com.github.fommil.netlib.NativeSystemBLAS
2021-12-08 10:09:11,628 [Executor task launch worker for task 59] WARN [com.github.fommil.netlib.BLAS] - Failed to load implementation from: com.github.fommil.netlib.NativeRefBLAS
2021-12-08 10:09:11,847 [Executor task launch worker for task 67] INFO [org.apache.spark.storage.memory.MemoryStore] - Block rdd_28_11 stored as values in memory (estimated size 11.1 MB, free 1789.8 MB)
2021-12-08 10:09:11,847 [dispatcher-event-loop-2] INFO [org.apache.spark.storage.BlockManagerInfo] - Added rdd_28_11 in memory on qb:61292 (size: 11.1 MB, free: 1791.5 MB)
2021-12-08 10:09:11,848 [Executor task launch worker for task 62] INFO [org.apache.spark.storage.memory.MemoryStore] - Block rdd_28_6 stored as values in memory (estimated size 11.1 MB, free 1778.7 MB)
2021-12-08 10:09:11,849 [dispatcher-event-loop-6] INFO [org.apache.spark.storage.BlockManagerInfo] - Added rdd_28_6 in memory on qb:61292 (size: 11.1 MB, free: 1780.4 MB)
2021-12-08 10:09:11,851 [Executor task launch worker for task 65] INFO [org.apache.spark.storage.memory.MemoryStore] - Block rdd_28_9 stored as values in memory (estimated size 11.1 MB, free 1756.5 MB)
2021-12-08 10:09:11,851 [Executor task launch worker for task 64] INFO [org.apache.spark.storage.memory.MemoryStore] - Block rdd_28_8 stored as values in memory (estimated size 11.1 MB, free 1756.5 MB)
2021-12-08 10:09:11,851 [dispatcher-event-loop-7] INFO [org.apache.spark.storage.BlockManagerInfo] - Added rdd_28_8 in memory on qb:61292 (size: 11.1 MB, free: 1769.3 MB)
2021-12-08 10:09:11,851 [dispatcher-event-loop-7] INFO [org.apache.spark.storage.BlockManagerInfo] - Added rdd_28_9 in memory on qb:61292 (size: 11.1 MB, free: 1758.2 MB)
2021-12-08 10:09:11,860 [Executor task launch worker for task 66] INFO [org.apache.spark.storage.memory.MemoryStore] - Block rdd_28_10 stored as values in memory (estimated size 11.1 MB, free 1734.3 MB)
2021-12-08 10:09:11,860 [Executor task launch worker for task 61] INFO [org.apache.spark.storage.memory.MemoryStore] - Block rdd_28_5 stored as values in memory (estimated size 11.1 MB, free 1734.3 MB)
2021-12-08 10:09:11,860 [dispatcher-event-loop-1] INFO [org.apache.spark.storage.BlockManagerInfo] - Added rdd_28_5 in memory on qb:61292 (size: 11.1 MB, free: 1747.1 MB)
2021-12-08 10:09:11,861 [dispatcher-event-loop-1] INFO [org.apache.spark.storage.BlockManagerInfo] - Added rdd_28_10 in memory on qb:61292 (size: 11.1 MB, free: 1736.0 MB)
2021-12-08 10:09:11,867 [Executor task launch worker for task 60] INFO [org.apache.spark.storage.memory.MemoryStore] - Block rdd_28_4 stored as values in memory (estimated size 11.1 MB, free 1723.2 MB)
2021-12-08 10:09:11,867 [dispatcher-event-loop-0] INFO [org.apache.spark.storage.BlockManagerInfo] - Added rdd_28_4 in memory on qb:61292 (size: 11.1 MB, free: 1724.9 MB)
2021-12-08 10:09:11,870 [Executor task launch worker for task 58] INFO [org.apache.spark.storage.memory.MemoryStore] - Block rdd_28_2 stored as values in memory (estimated size 11.1 MB, free 1712.1 MB)
2021-12-08 10:09:11,871 [dispatcher-event-loop-8] INFO [org.apache.spark.storage.BlockManagerInfo] - Added rdd_28_2 in memory on qb:61292 (size: 11.1 MB, free: 1713.8 MB)
2021-12-08 10:09:11,890 [Executor task launch worker for task 57] INFO [org.apache.spark.storage.memory.MemoryStore] - Block rdd_28_1 stored as values in memory (estimated size 11.1 MB, free 1701.0 MB)
2021-12-08 10:09:11,891 [dispatcher-event-loop-4] INFO [org.apache.spark.storage.BlockManagerInfo] - Added rdd_28_1 in memory on qb:61292 (size: 11.1 MB, free: 1702.7 MB)
2021-12-08 10:09:11,893 [Executor task launch worker for task 63] INFO [org.apache.spark.storage.memory.MemoryStore] - Block rdd_28_7 stored as values in memory (estimated size 11.1 MB, free 1689.9 MB)
2021-12-08 10:09:11,893 [dispatcher-event-loop-5] INFO [org.apache.spark.storage.BlockManagerInfo] - Added rdd_28_7 in memory on qb:61292 (size: 11.1 MB, free: 1691.6 MB)
2021-12-08 10:09:11,897 [Executor task launch worker for task 59] INFO [org.apache.spark.storage.memory.MemoryStore] - Block rdd_28_3 stored as values in memory (estimated size 11.1 MB, free 1678.8 MB)
2021-12-08 10:09:11,897 [dispatcher-event-loop-9] INFO [org.apache.spark.storage.BlockManagerInfo] - Added rdd_28_3 in memory on qb:61292 (size: 11.1 MB, free: 1680.5 MB)
2021-12-08 10:09:11,921 [Executor task launch worker for task 56] INFO [org.apache.spark.storage.memory.MemoryStore] - Block rdd_28_0 stored as values in memory (estimated size 11.1 MB, free 1667.6 MB)
2021-12-08 10:09:11,921 [dispatcher-event-loop-10] INFO [org.apache.spark.storage.BlockManagerInfo] - Added rdd_28_0 in memory on qb:61292 (size: 11.1 MB, free: 1669.4 MB)
2021-12-08 10:09:12,220 [Executor task launch worker for task 62] INFO [org.apache.spark.executor.Executor] - Finished task 6.0 in stage 10.0 (TID 62). 165667 bytes result sent to driver
2021-12-08 10:09:12,227 [Executor task launch worker for task 66] INFO [org.apache.spark.executor.Executor] - Finished task 10.0 in stage 10.0 (TID 66). 165667 bytes result sent to driver
2021-12-08 10:09:12,229 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 6.0 in stage 10.0 (TID 62) in 611 ms on localhost (executor driver) (1/12)
2021-12-08 10:09:12,230 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 10.0 in stage 10.0 (TID 66) in 611 ms on localhost (executor driver) (2/12)
2021-12-08 10:09:12,235 [Executor task launch worker for task 61] INFO [org.apache.spark.executor.Executor] - Finished task 5.0 in stage 10.0 (TID 61). 165667 bytes result sent to driver
2021-12-08 10:09:12,235 [Executor task launch worker for task 67] INFO [org.apache.spark.executor.Executor] - Finished task 11.0 in stage 10.0 (TID 67). 165667 bytes result sent to driver
2021-12-08 10:09:12,235 [Executor task launch worker for task 57] INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 10.0 (TID 57). 165667 bytes result sent to driver
2021-12-08 10:09:12,236 [Executor task launch worker for task 64] INFO [org.apache.spark.executor.Executor] - Finished task 8.0 in stage 10.0 (TID 64). 165667 bytes result sent to driver
2021-12-08 10:09:12,236 [Executor task launch worker for task 59] INFO [org.apache.spark.executor.Executor] - Finished task 3.0 in stage 10.0 (TID 59). 165667 bytes result sent to driver
2021-12-08 10:09:12,237 [Executor task launch worker for task 65] INFO [org.apache.spark.executor.Executor] - Finished task 9.0 in stage 10.0 (TID 65). 165624 bytes result sent to driver
2021-12-08 10:09:12,237 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 10.0 (TID 57) in 619 ms on localhost (executor driver) (3/12)
2021-12-08 10:09:12,238 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 3.0 in stage 10.0 (TID 59) in 620 ms on localhost (executor driver) (4/12)
2021-12-08 10:09:12,240 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 9.0 in stage 10.0 (TID 65) in 621 ms on localhost (executor driver) (5/12)
2021-12-08 10:09:12,240 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 8.0 in stage 10.0 (TID 64) in 621 ms on localhost (executor driver) (6/12)
2021-12-08 10:09:12,241 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 11.0 in stage 10.0 (TID 67) in 622 ms on localhost (executor driver) (7/12)
2021-12-08 10:09:12,241 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 5.0 in stage 10.0 (TID 61) in 623 ms on localhost (executor driver) (8/12)
2021-12-08 10:09:12,243 [Executor task launch worker for task 60] INFO [org.apache.spark.executor.Executor] - Finished task 4.0 in stage 10.0 (TID 60). 165667 bytes result sent to driver
2021-12-08 10:09:12,243 [Executor task launch worker for task 58] INFO [org.apache.spark.executor.Executor] - Finished task 2.0 in stage 10.0 (TID 58). 165624 bytes result sent to driver
2021-12-08 10:09:12,244 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 4.0 in stage 10.0 (TID 60) in 626 ms on localhost (executor driver) (9/12)
2021-12-08 10:09:12,244 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 2.0 in stage 10.0 (TID 58) in 626 ms on localhost (executor driver) (10/12)
2021-12-08 10:09:12,248 [Executor task launch worker for task 56] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 10.0 (TID 56). 165624 bytes result sent to driver
2021-12-08 10:09:12,249 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 10.0 (TID 56) in 631 ms on localhost (executor driver) (11/12)
2021-12-08 10:09:12,252 [Executor task launch worker for task 63] INFO [org.apache.spark.executor.Executor] - Finished task 7.0 in stage 10.0 (TID 63). 165667 bytes result sent to driver
2021-12-08 10:09:12,252 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 7.0 in stage 10.0 (TID 63) in 633 ms on localhost (executor driver) (12/12)
2021-12-08 10:09:12,252 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 10.0, whose tasks have all completed, from pool 
2021-12-08 10:09:12,252 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 10 (aggregate at ALS.scala:1711) finished in 0.639 s
2021-12-08 10:09:12,253 [main] INFO [org.apache.spark.scheduler.DAGScheduler] - Job 4 finished: aggregate at ALS.scala:1711, took 0.642340 s
2021-12-08 10:09:12,281 [main] INFO [org.apache.spark.rdd.MapPartitionsRDD] - Removing RDD 29 from persistence list
2021-12-08 10:09:12,284 [block-manager-slave-async-thread-pool-0] INFO [org.apache.spark.storage.BlockManager] - Removing RDD 29
2021-12-08 10:09:12,296 [main] INFO [org.apache.spark.SparkContext] - Starting job: aggregate at ALS.scala:1711
2021-12-08 10:09:12,299 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 28 (map at ALS.scala:1231)
2021-12-08 10:09:12,299 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 34 (flatMap at ALS.scala:1653)
2021-12-08 10:09:12,299 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 5 (aggregate at ALS.scala:1711) with 12 output partitions
2021-12-08 10:09:12,299 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 16 (aggregate at ALS.scala:1711)
2021-12-08 10:09:12,299 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 15, ShuffleMapStage 12)
2021-12-08 10:09:12,300 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List(ShuffleMapStage 15)
2021-12-08 10:09:12,301 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ShuffleMapStage 14 (userFactors-1 MapPartitionsRDD[28] at map at ALS.scala:1231), which has no missing parents
2021-12-08 10:09:12,302 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_13 stored as values in memory (estimated size 8.2 KB, free 1667.6 MB)
2021-12-08 10:09:12,303 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_13_piece0 stored as bytes in memory (estimated size 4.2 KB, free 1667.6 MB)
2021-12-08 10:09:12,303 [dispatcher-event-loop-3] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_13_piece0 in memory on qb:61292 (size: 4.2 KB, free: 1669.4 MB)
2021-12-08 10:09:12,304 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 13 from broadcast at DAGScheduler.scala:1039
2021-12-08 10:09:12,304 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 12 missing tasks from ShuffleMapStage 14 (userFactors-1 MapPartitionsRDD[28] at map at ALS.scala:1231) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11))
2021-12-08 10:09:12,304 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 14.0 with 12 tasks
2021-12-08 10:09:12,305 [dispatcher-event-loop-8] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 14.0 (TID 68, localhost, executor driver, partition 0, PROCESS_LOCAL, 7638 bytes)
2021-12-08 10:09:12,305 [dispatcher-event-loop-8] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 14.0 (TID 69, localhost, executor driver, partition 1, PROCESS_LOCAL, 7638 bytes)
2021-12-08 10:09:12,305 [dispatcher-event-loop-8] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 2.0 in stage 14.0 (TID 70, localhost, executor driver, partition 2, PROCESS_LOCAL, 7638 bytes)
2021-12-08 10:09:12,305 [dispatcher-event-loop-8] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 3.0 in stage 14.0 (TID 71, localhost, executor driver, partition 3, PROCESS_LOCAL, 7638 bytes)
2021-12-08 10:09:12,305 [dispatcher-event-loop-8] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 4.0 in stage 14.0 (TID 72, localhost, executor driver, partition 4, PROCESS_LOCAL, 7638 bytes)
2021-12-08 10:09:12,305 [dispatcher-event-loop-8] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 5.0 in stage 14.0 (TID 73, localhost, executor driver, partition 5, PROCESS_LOCAL, 7638 bytes)
2021-12-08 10:09:12,305 [dispatcher-event-loop-8] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 6.0 in stage 14.0 (TID 74, localhost, executor driver, partition 6, PROCESS_LOCAL, 7638 bytes)
2021-12-08 10:09:12,305 [dispatcher-event-loop-8] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 7.0 in stage 14.0 (TID 75, localhost, executor driver, partition 7, PROCESS_LOCAL, 7638 bytes)
2021-12-08 10:09:12,306 [dispatcher-event-loop-8] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 8.0 in stage 14.0 (TID 76, localhost, executor driver, partition 8, PROCESS_LOCAL, 7638 bytes)
2021-12-08 10:09:12,306 [dispatcher-event-loop-8] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 9.0 in stage 14.0 (TID 77, localhost, executor driver, partition 9, PROCESS_LOCAL, 7638 bytes)
2021-12-08 10:09:12,306 [dispatcher-event-loop-8] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 10.0 in stage 14.0 (TID 78, localhost, executor driver, partition 10, PROCESS_LOCAL, 7638 bytes)
2021-12-08 10:09:12,306 [dispatcher-event-loop-8] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 11.0 in stage 14.0 (TID 79, localhost, executor driver, partition 11, PROCESS_LOCAL, 7638 bytes)
2021-12-08 10:09:12,306 [Executor task launch worker for task 68] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 14.0 (TID 68)
2021-12-08 10:09:12,306 [Executor task launch worker for task 71] INFO [org.apache.spark.executor.Executor] - Running task 3.0 in stage 14.0 (TID 71)
2021-12-08 10:09:12,306 [Executor task launch worker for task 75] INFO [org.apache.spark.executor.Executor] - Running task 7.0 in stage 14.0 (TID 75)
2021-12-08 10:09:12,306 [Executor task launch worker for task 79] INFO [org.apache.spark.executor.Executor] - Running task 11.0 in stage 14.0 (TID 79)
2021-12-08 10:09:12,306 [Executor task launch worker for task 70] INFO [org.apache.spark.executor.Executor] - Running task 2.0 in stage 14.0 (TID 70)
2021-12-08 10:09:12,306 [Executor task launch worker for task 73] INFO [org.apache.spark.executor.Executor] - Running task 5.0 in stage 14.0 (TID 73)
2021-12-08 10:09:12,306 [Executor task launch worker for task 69] INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 14.0 (TID 69)
2021-12-08 10:09:12,306 [Executor task launch worker for task 72] INFO [org.apache.spark.executor.Executor] - Running task 4.0 in stage 14.0 (TID 72)
2021-12-08 10:09:12,306 [Executor task launch worker for task 74] INFO [org.apache.spark.executor.Executor] - Running task 6.0 in stage 14.0 (TID 74)
2021-12-08 10:09:12,306 [Executor task launch worker for task 77] INFO [org.apache.spark.executor.Executor] - Running task 9.0 in stage 14.0 (TID 77)
2021-12-08 10:09:12,306 [Executor task launch worker for task 78] INFO [org.apache.spark.executor.Executor] - Running task 10.0 in stage 14.0 (TID 78)
2021-12-08 10:09:12,306 [Executor task launch worker for task 76] INFO [org.apache.spark.executor.Executor] - Running task 8.0 in stage 14.0 (TID 76)
2021-12-08 10:09:12,308 [Executor task launch worker for task 72] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_28_4 locally
2021-12-08 10:09:12,308 [Executor task launch worker for task 73] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_28_5 locally
2021-12-08 10:09:12,308 [Executor task launch worker for task 68] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_28_0 locally
2021-12-08 10:09:12,308 [Executor task launch worker for task 70] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_28_2 locally
2021-12-08 10:09:12,308 [Executor task launch worker for task 75] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_28_7 locally
2021-12-08 10:09:12,308 [Executor task launch worker for task 77] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_28_9 locally
2021-12-08 10:09:12,308 [Executor task launch worker for task 74] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_28_6 locally
2021-12-08 10:09:12,308 [Executor task launch worker for task 78] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_28_10 locally
2021-12-08 10:09:12,310 [Executor task launch worker for task 76] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_28_8 locally
2021-12-08 10:09:12,311 [Executor task launch worker for task 71] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_28_3 locally
2021-12-08 10:09:12,311 [Executor task launch worker for task 69] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_28_1 locally
2021-12-08 10:09:12,311 [Executor task launch worker for task 79] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_28_11 locally
2021-12-08 10:09:12,422 [Executor task launch worker for task 77] INFO [org.apache.spark.executor.Executor] - Finished task 9.0 in stage 14.0 (TID 77). 870 bytes result sent to driver
2021-12-08 10:09:12,425 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 9.0 in stage 14.0 (TID 77) in 118 ms on localhost (executor driver) (1/12)
2021-12-08 10:09:12,426 [Executor task launch worker for task 76] INFO [org.apache.spark.executor.Executor] - Finished task 8.0 in stage 14.0 (TID 76). 870 bytes result sent to driver
2021-12-08 10:09:12,427 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 8.0 in stage 14.0 (TID 76) in 122 ms on localhost (executor driver) (2/12)
2021-12-08 10:09:12,430 [Executor task launch worker for task 68] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 14.0 (TID 68). 870 bytes result sent to driver
2021-12-08 10:09:12,433 [Executor task launch worker for task 79] INFO [org.apache.spark.executor.Executor] - Finished task 11.0 in stage 14.0 (TID 79). 827 bytes result sent to driver
2021-12-08 10:09:12,433 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 14.0 (TID 68) in 128 ms on localhost (executor driver) (3/12)
2021-12-08 10:09:12,433 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 11.0 in stage 14.0 (TID 79) in 127 ms on localhost (executor driver) (4/12)
2021-12-08 10:09:12,436 [Executor task launch worker for task 72] INFO [org.apache.spark.executor.Executor] - Finished task 4.0 in stage 14.0 (TID 72). 870 bytes result sent to driver
2021-12-08 10:09:12,437 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 4.0 in stage 14.0 (TID 72) in 131 ms on localhost (executor driver) (5/12)
2021-12-08 10:09:12,438 [Executor task launch worker for task 73] INFO [org.apache.spark.executor.Executor] - Finished task 5.0 in stage 14.0 (TID 73). 870 bytes result sent to driver
2021-12-08 10:09:12,438 [Executor task launch worker for task 78] INFO [org.apache.spark.executor.Executor] - Finished task 10.0 in stage 14.0 (TID 78). 870 bytes result sent to driver
2021-12-08 10:09:12,439 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 5.0 in stage 14.0 (TID 73) in 134 ms on localhost (executor driver) (6/12)
2021-12-08 10:09:12,439 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 10.0 in stage 14.0 (TID 78) in 133 ms on localhost (executor driver) (7/12)
2021-12-08 10:09:12,440 [Executor task launch worker for task 74] INFO [org.apache.spark.executor.Executor] - Finished task 6.0 in stage 14.0 (TID 74). 870 bytes result sent to driver
2021-12-08 10:09:12,440 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 6.0 in stage 14.0 (TID 74) in 135 ms on localhost (executor driver) (8/12)
2021-12-08 10:09:12,447 [Executor task launch worker for task 70] INFO [org.apache.spark.executor.Executor] - Finished task 2.0 in stage 14.0 (TID 70). 870 bytes result sent to driver
2021-12-08 10:09:12,448 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 2.0 in stage 14.0 (TID 70) in 143 ms on localhost (executor driver) (9/12)
2021-12-08 10:09:12,453 [Executor task launch worker for task 71] INFO [org.apache.spark.executor.Executor] - Finished task 3.0 in stage 14.0 (TID 71). 827 bytes result sent to driver
2021-12-08 10:09:12,453 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 3.0 in stage 14.0 (TID 71) in 148 ms on localhost (executor driver) (10/12)
2021-12-08 10:09:12,455 [Executor task launch worker for task 69] INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 14.0 (TID 69). 827 bytes result sent to driver
2021-12-08 10:09:12,455 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 14.0 (TID 69) in 150 ms on localhost (executor driver) (11/12)
2021-12-08 10:09:12,462 [Executor task launch worker for task 75] INFO [org.apache.spark.executor.Executor] - Finished task 7.0 in stage 14.0 (TID 75). 870 bytes result sent to driver
2021-12-08 10:09:12,462 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 7.0 in stage 14.0 (TID 75) in 157 ms on localhost (executor driver) (12/12)
2021-12-08 10:09:12,462 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 14.0, whose tasks have all completed, from pool 
2021-12-08 10:09:12,462 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ShuffleMapStage 14 (map at ALS.scala:1231) finished in 0.161 s
2021-12-08 10:09:12,462 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - looking for newly runnable stages
2021-12-08 10:09:12,462 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - running: Set()
2021-12-08 10:09:12,462 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - waiting: Set(ShuffleMapStage 15, ResultStage 16)
2021-12-08 10:09:12,462 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - failed: Set()
2021-12-08 10:09:12,463 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ShuffleMapStage 15 (MapPartitionsRDD[34] at flatMap at ALS.scala:1653), which has no missing parents
2021-12-08 10:09:12,464 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_14 stored as values in memory (estimated size 9.3 KB, free 1667.6 MB)
2021-12-08 10:09:12,466 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_14_piece0 stored as bytes in memory (estimated size 4.5 KB, free 1667.6 MB)
2021-12-08 10:09:12,466 [dispatcher-event-loop-4] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_14_piece0 in memory on qb:61292 (size: 4.5 KB, free: 1669.4 MB)
2021-12-08 10:09:12,466 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 14 from broadcast at DAGScheduler.scala:1039
2021-12-08 10:09:12,467 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 12 missing tasks from ShuffleMapStage 15 (MapPartitionsRDD[34] at flatMap at ALS.scala:1653) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11))
2021-12-08 10:09:12,467 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 15.0 with 12 tasks
2021-12-08 10:09:12,469 [dispatcher-event-loop-10] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 15.0 (TID 80, localhost, executor driver, partition 0, PROCESS_LOCAL, 7855 bytes)
2021-12-08 10:09:12,469 [dispatcher-event-loop-10] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 15.0 (TID 81, localhost, executor driver, partition 1, PROCESS_LOCAL, 7855 bytes)
2021-12-08 10:09:12,469 [dispatcher-event-loop-10] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 2.0 in stage 15.0 (TID 82, localhost, executor driver, partition 2, PROCESS_LOCAL, 7855 bytes)
2021-12-08 10:09:12,469 [dispatcher-event-loop-10] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 3.0 in stage 15.0 (TID 83, localhost, executor driver, partition 3, PROCESS_LOCAL, 7855 bytes)
2021-12-08 10:09:12,469 [dispatcher-event-loop-10] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 4.0 in stage 15.0 (TID 84, localhost, executor driver, partition 4, PROCESS_LOCAL, 7855 bytes)
2021-12-08 10:09:12,469 [dispatcher-event-loop-10] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 5.0 in stage 15.0 (TID 85, localhost, executor driver, partition 5, PROCESS_LOCAL, 7855 bytes)
2021-12-08 10:09:12,470 [dispatcher-event-loop-10] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 6.0 in stage 15.0 (TID 86, localhost, executor driver, partition 6, PROCESS_LOCAL, 7855 bytes)
2021-12-08 10:09:12,470 [dispatcher-event-loop-10] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 7.0 in stage 15.0 (TID 87, localhost, executor driver, partition 7, PROCESS_LOCAL, 7855 bytes)
2021-12-08 10:09:12,470 [dispatcher-event-loop-10] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 8.0 in stage 15.0 (TID 88, localhost, executor driver, partition 8, PROCESS_LOCAL, 7855 bytes)
2021-12-08 10:09:12,470 [dispatcher-event-loop-10] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 9.0 in stage 15.0 (TID 89, localhost, executor driver, partition 9, PROCESS_LOCAL, 7855 bytes)
2021-12-08 10:09:12,470 [dispatcher-event-loop-10] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 10.0 in stage 15.0 (TID 90, localhost, executor driver, partition 10, PROCESS_LOCAL, 7855 bytes)
2021-12-08 10:09:12,470 [dispatcher-event-loop-10] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 11.0 in stage 15.0 (TID 91, localhost, executor driver, partition 11, PROCESS_LOCAL, 7855 bytes)
2021-12-08 10:09:12,470 [Executor task launch worker for task 80] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 15.0 (TID 80)
2021-12-08 10:09:12,470 [Executor task launch worker for task 91] INFO [org.apache.spark.executor.Executor] - Running task 11.0 in stage 15.0 (TID 91)
2021-12-08 10:09:12,470 [Executor task launch worker for task 90] INFO [org.apache.spark.executor.Executor] - Running task 10.0 in stage 15.0 (TID 90)
2021-12-08 10:09:12,470 [Executor task launch worker for task 89] INFO [org.apache.spark.executor.Executor] - Running task 9.0 in stage 15.0 (TID 89)
2021-12-08 10:09:12,470 [Executor task launch worker for task 88] INFO [org.apache.spark.executor.Executor] - Running task 8.0 in stage 15.0 (TID 88)
2021-12-08 10:09:12,470 [Executor task launch worker for task 86] INFO [org.apache.spark.executor.Executor] - Running task 6.0 in stage 15.0 (TID 86)
2021-12-08 10:09:12,470 [Executor task launch worker for task 87] INFO [org.apache.spark.executor.Executor] - Running task 7.0 in stage 15.0 (TID 87)
2021-12-08 10:09:12,470 [Executor task launch worker for task 85] INFO [org.apache.spark.executor.Executor] - Running task 5.0 in stage 15.0 (TID 85)
2021-12-08 10:09:12,470 [Executor task launch worker for task 84] INFO [org.apache.spark.executor.Executor] - Running task 4.0 in stage 15.0 (TID 84)
2021-12-08 10:09:12,470 [Executor task launch worker for task 83] INFO [org.apache.spark.executor.Executor] - Running task 3.0 in stage 15.0 (TID 83)
2021-12-08 10:09:12,470 [Executor task launch worker for task 82] INFO [org.apache.spark.executor.Executor] - Running task 2.0 in stage 15.0 (TID 82)
2021-12-08 10:09:12,470 [Executor task launch worker for task 81] INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 15.0 (TID 81)
2021-12-08 10:09:12,473 [Executor task launch worker for task 85] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_22_5 locally
2021-12-08 10:09:12,473 [Executor task launch worker for task 82] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_22_2 locally
2021-12-08 10:09:12,474 [Executor task launch worker for task 90] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_22_10 locally
2021-12-08 10:09:12,474 [Executor task launch worker for task 83] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_22_3 locally
2021-12-08 10:09:12,473 [Executor task launch worker for task 88] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_22_8 locally
2021-12-08 10:09:12,473 [Executor task launch worker for task 86] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_22_6 locally
2021-12-08 10:09:12,473 [Executor task launch worker for task 87] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_22_7 locally
2021-12-08 10:09:12,474 [Executor task launch worker for task 82] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 12 blocks
2021-12-08 10:09:12,474 [Executor task launch worker for task 90] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 12 blocks
2021-12-08 10:09:12,474 [Executor task launch worker for task 90] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-08 10:09:12,474 [Executor task launch worker for task 89] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_22_9 locally
2021-12-08 10:09:12,474 [Executor task launch worker for task 83] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 12 blocks
2021-12-08 10:09:12,474 [Executor task launch worker for task 83] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-08 10:09:12,474 [Executor task launch worker for task 84] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_22_4 locally
2021-12-08 10:09:12,474 [Executor task launch worker for task 81] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_22_1 locally
2021-12-08 10:09:12,474 [Executor task launch worker for task 85] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 12 blocks
2021-12-08 10:09:12,475 [Executor task launch worker for task 85] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 1 ms
2021-12-08 10:09:12,474 [Executor task launch worker for task 87] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 12 blocks
2021-12-08 10:09:12,475 [Executor task launch worker for task 89] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 12 blocks
2021-12-08 10:09:12,475 [Executor task launch worker for task 89] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 1 ms
2021-12-08 10:09:12,474 [Executor task launch worker for task 82] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-08 10:09:12,474 [Executor task launch worker for task 86] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 12 blocks
2021-12-08 10:09:12,475 [Executor task launch worker for task 87] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 1 ms
2021-12-08 10:09:12,475 [Executor task launch worker for task 88] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 12 blocks
2021-12-08 10:09:12,475 [Executor task launch worker for task 88] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 1 ms
2021-12-08 10:09:12,475 [Executor task launch worker for task 80] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_22_0 locally
2021-12-08 10:09:12,475 [Executor task launch worker for task 80] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 12 blocks
2021-12-08 10:09:12,475 [Executor task launch worker for task 80] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-08 10:09:12,476 [Executor task launch worker for task 91] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_22_11 locally
2021-12-08 10:09:12,476 [Executor task launch worker for task 84] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 12 blocks
2021-12-08 10:09:12,476 [Executor task launch worker for task 84] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 2 ms
2021-12-08 10:09:12,475 [Executor task launch worker for task 86] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 1 ms
2021-12-08 10:09:12,476 [Executor task launch worker for task 91] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 12 blocks
2021-12-08 10:09:12,477 [Executor task launch worker for task 91] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 1 ms
2021-12-08 10:09:12,476 [Executor task launch worker for task 81] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 12 blocks
2021-12-08 10:09:12,477 [Executor task launch worker for task 81] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 1 ms
2021-12-08 10:09:13,458 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 154
2021-12-08 10:09:13,461 [dispatcher-event-loop-7] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_13_piece0 on qb:61292 in memory (size: 4.2 KB, free: 1669.4 MB)
2021-12-08 10:09:13,462 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 195
2021-12-08 10:09:13,462 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 182
2021-12-08 10:09:13,462 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 193
2021-12-08 10:09:13,462 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 68
2021-12-08 10:09:13,462 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 63
2021-12-08 10:09:13,462 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 165
2021-12-08 10:09:13,462 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 168
2021-12-08 10:09:13,462 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 71
2021-12-08 10:09:13,462 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 106
2021-12-08 10:09:13,462 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 123
2021-12-08 10:09:13,462 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 101
2021-12-08 10:09:13,462 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 127
2021-12-08 10:09:13,462 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 86
2021-12-08 10:09:13,462 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 166
2021-12-08 10:09:13,462 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 113
2021-12-08 10:09:13,462 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 125
2021-12-08 10:09:13,462 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 124
2021-12-08 10:09:13,462 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 89
2021-12-08 10:09:13,462 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 95
2021-12-08 10:09:13,462 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 153
2021-12-08 10:09:13,462 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 119
2021-12-08 10:09:13,462 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 138
2021-12-08 10:09:13,462 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 58
2021-12-08 10:09:13,462 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 50
2021-12-08 10:09:13,464 [dispatcher-event-loop-11] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_12_piece0 on qb:61292 in memory (size: 5.3 KB, free: 1669.4 MB)
2021-12-08 10:09:13,465 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 51
2021-12-08 10:09:13,465 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 75
2021-12-08 10:09:13,465 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 185
2021-12-08 10:09:13,465 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 198
2021-12-08 10:09:13,465 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 109
2021-12-08 10:09:13,465 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 184
2021-12-08 10:09:13,465 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 156
2021-12-08 10:09:13,465 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 96
2021-12-08 10:09:13,465 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 167
2021-12-08 10:09:13,465 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 72
2021-12-08 10:09:13,465 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 59
2021-12-08 10:09:13,465 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 191
2021-12-08 10:09:13,465 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 118
2021-12-08 10:09:13,465 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 196
2021-12-08 10:09:13,465 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 122
2021-12-08 10:09:13,465 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 52
2021-12-08 10:09:13,465 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 177
2021-12-08 10:09:13,465 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 179
2021-12-08 10:09:13,465 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 103
2021-12-08 10:09:13,465 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 190
2021-12-08 10:09:13,465 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 100
2021-12-08 10:09:13,465 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 169
2021-12-08 10:09:13,465 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 187
2021-12-08 10:09:13,465 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 128
2021-12-08 10:09:13,465 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 117
2021-12-08 10:09:13,465 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 105
2021-12-08 10:09:13,466 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 57
2021-12-08 10:09:13,466 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 88
2021-12-08 10:09:13,466 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 175
2021-12-08 10:09:13,466 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 162
2021-12-08 10:09:13,466 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 158
2021-12-08 10:09:13,466 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 114
2021-12-08 10:09:13,466 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 134
2021-12-08 10:09:13,466 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 84
2021-12-08 10:09:13,466 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 135
2021-12-08 10:09:13,466 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 61
2021-12-08 10:09:13,466 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 155
2021-12-08 10:09:13,466 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 151
2021-12-08 10:09:13,466 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 98
2021-12-08 10:09:13,466 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 116
2021-12-08 10:09:13,466 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 174
2021-12-08 10:09:13,466 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 180
2021-12-08 10:09:13,466 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 99
2021-12-08 10:09:13,466 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 104
2021-12-08 10:09:13,466 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 97
2021-12-08 10:09:13,466 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 186
2021-12-08 10:09:13,466 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 53
2021-12-08 10:09:13,466 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 65
2021-12-08 10:09:13,466 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 76
2021-12-08 10:09:13,466 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 142
2021-12-08 10:09:13,466 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 93
2021-12-08 10:09:13,466 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 90
2021-12-08 10:09:13,467 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 136
2021-12-08 10:09:13,467 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 69
2021-12-08 10:09:13,467 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 171
2021-12-08 10:09:13,469 [dispatcher-event-loop-0] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_9_piece0 on qb:61292 in memory (size: 4.2 KB, free: 1669.4 MB)
2021-12-08 10:09:13,471 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 110
2021-12-08 10:09:13,471 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 140
2021-12-08 10:09:13,471 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 73
2021-12-08 10:09:13,471 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 87
2021-12-08 10:09:13,471 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 111
2021-12-08 10:09:13,471 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 139
2021-12-08 10:09:13,471 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 55
2021-12-08 10:09:13,471 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 145
2021-12-08 10:09:13,472 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 85
2021-12-08 10:09:13,472 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 78
2021-12-08 10:09:13,472 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 197
2021-12-08 10:09:13,472 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 121
2021-12-08 10:09:13,472 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 149
2021-12-08 10:09:13,472 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 178
2021-12-08 10:09:13,472 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 164
2021-12-08 10:09:13,472 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 126
2021-12-08 10:09:13,472 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 189
2021-12-08 10:09:13,472 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 199
2021-12-08 10:09:13,472 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 159
2021-12-08 10:09:13,473 [dispatcher-event-loop-10] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_11_piece0 on qb:61292 in memory (size: 4.2 KB, free: 1669.4 MB)
2021-12-08 10:09:13,474 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 129
2021-12-08 10:09:13,474 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 192
2021-12-08 10:09:13,475 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 141
2021-12-08 10:09:13,475 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 176
2021-12-08 10:09:13,475 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 137
2021-12-08 10:09:13,475 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 112
2021-12-08 10:09:13,475 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 80
2021-12-08 10:09:13,475 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 172
2021-12-08 10:09:13,475 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 181
2021-12-08 10:09:13,475 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 157
2021-12-08 10:09:13,478 [dispatcher-event-loop-7] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_10_piece0 on qb:61292 in memory (size: 4.0 KB, free: 1669.4 MB)
2021-12-08 10:09:13,481 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 133
2021-12-08 10:09:13,481 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 188
2021-12-08 10:09:13,481 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 107
2021-12-08 10:09:13,481 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 102
2021-12-08 10:09:13,481 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 147
2021-12-08 10:09:13,481 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 82
2021-12-08 10:09:13,481 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 146
2021-12-08 10:09:13,481 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 173
2021-12-08 10:09:13,481 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 54
2021-12-08 10:09:13,481 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 91
2021-12-08 10:09:13,481 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 67
2021-12-08 10:09:13,481 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 108
2021-12-08 10:09:13,481 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 170
2021-12-08 10:09:13,481 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 92
2021-12-08 10:09:13,481 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 62
2021-12-08 10:09:13,481 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 79
2021-12-08 10:09:13,481 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 152
2021-12-08 10:09:13,481 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 131
2021-12-08 10:09:13,482 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 66
2021-12-08 10:09:13,482 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 183
2021-12-08 10:09:13,482 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 115
2021-12-08 10:09:13,482 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 163
2021-12-08 10:09:13,482 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 64
2021-12-08 10:09:13,482 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 160
2021-12-08 10:09:13,482 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 74
2021-12-08 10:09:13,482 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 161
2021-12-08 10:09:13,482 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 77
2021-12-08 10:09:13,482 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 81
2021-12-08 10:09:13,482 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 94
2021-12-08 10:09:13,482 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 150
2021-12-08 10:09:13,482 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 194
2021-12-08 10:09:13,482 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 120
2021-12-08 10:09:13,482 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 83
2021-12-08 10:09:13,482 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 60
2021-12-08 10:09:13,482 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 132
2021-12-08 10:09:13,482 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 144
2021-12-08 10:09:13,482 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 130
2021-12-08 10:09:13,482 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 56
2021-12-08 10:09:13,482 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 148
2021-12-08 10:09:13,482 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 70
2021-12-08 10:09:13,482 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 143
2021-12-08 10:09:14,469 [Executor task launch worker for task 91] INFO [org.apache.spark.executor.Executor] - Finished task 11.0 in stage 15.0 (TID 91). 1343 bytes result sent to driver
2021-12-08 10:09:14,470 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 11.0 in stage 15.0 (TID 91) in 2000 ms on localhost (executor driver) (1/12)
2021-12-08 10:09:14,517 [Executor task launch worker for task 89] INFO [org.apache.spark.executor.Executor] - Finished task 9.0 in stage 15.0 (TID 89). 1343 bytes result sent to driver
2021-12-08 10:09:14,518 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 9.0 in stage 15.0 (TID 89) in 2048 ms on localhost (executor driver) (2/12)
2021-12-08 10:09:14,598 [Executor task launch worker for task 80] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 15.0 (TID 80). 1343 bytes result sent to driver
2021-12-08 10:09:14,598 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 15.0 (TID 80) in 2131 ms on localhost (executor driver) (3/12)
2021-12-08 10:09:14,599 [Executor task launch worker for task 87] INFO [org.apache.spark.executor.Executor] - Finished task 7.0 in stage 15.0 (TID 87). 1343 bytes result sent to driver
2021-12-08 10:09:14,599 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 7.0 in stage 15.0 (TID 87) in 2129 ms on localhost (executor driver) (4/12)
2021-12-08 10:09:14,600 [Executor task launch worker for task 90] INFO [org.apache.spark.executor.Executor] - Finished task 10.0 in stage 15.0 (TID 90). 1343 bytes result sent to driver
2021-12-08 10:09:14,600 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 10.0 in stage 15.0 (TID 90) in 2130 ms on localhost (executor driver) (5/12)
2021-12-08 10:09:14,600 [Executor task launch worker for task 85] INFO [org.apache.spark.executor.Executor] - Finished task 5.0 in stage 15.0 (TID 85). 1343 bytes result sent to driver
2021-12-08 10:09:14,601 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 5.0 in stage 15.0 (TID 85) in 2132 ms on localhost (executor driver) (6/12)
2021-12-08 10:09:14,651 [Executor task launch worker for task 82] INFO [org.apache.spark.executor.Executor] - Finished task 2.0 in stage 15.0 (TID 82). 1343 bytes result sent to driver
2021-12-08 10:09:14,651 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 2.0 in stage 15.0 (TID 82) in 2182 ms on localhost (executor driver) (7/12)
2021-12-08 10:09:14,891 [Executor task launch worker for task 86] INFO [org.apache.spark.executor.Executor] - Finished task 6.0 in stage 15.0 (TID 86). 1343 bytes result sent to driver
2021-12-08 10:09:14,891 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 6.0 in stage 15.0 (TID 86) in 2421 ms on localhost (executor driver) (8/12)
2021-12-08 10:09:15,145 [Executor task launch worker for task 84] INFO [org.apache.spark.executor.Executor] - Finished task 4.0 in stage 15.0 (TID 84). 1343 bytes result sent to driver
2021-12-08 10:09:15,146 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 4.0 in stage 15.0 (TID 84) in 2677 ms on localhost (executor driver) (9/12)
2021-12-08 10:09:15,146 [Executor task launch worker for task 83] INFO [org.apache.spark.executor.Executor] - Finished task 3.0 in stage 15.0 (TID 83). 1343 bytes result sent to driver
2021-12-08 10:09:15,146 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 3.0 in stage 15.0 (TID 83) in 2677 ms on localhost (executor driver) (10/12)
2021-12-08 10:09:15,147 [Executor task launch worker for task 88] INFO [org.apache.spark.executor.Executor] - Finished task 8.0 in stage 15.0 (TID 88). 1343 bytes result sent to driver
2021-12-08 10:09:15,147 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 8.0 in stage 15.0 (TID 88) in 2677 ms on localhost (executor driver) (11/12)
2021-12-08 10:09:15,148 [Executor task launch worker for task 81] INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 15.0 (TID 81). 1343 bytes result sent to driver
2021-12-08 10:09:15,148 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 15.0 (TID 81) in 2679 ms on localhost (executor driver) (12/12)
2021-12-08 10:09:15,148 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 15.0, whose tasks have all completed, from pool 
2021-12-08 10:09:15,148 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ShuffleMapStage 15 (flatMap at ALS.scala:1653) finished in 2.685 s
2021-12-08 10:09:15,148 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - looking for newly runnable stages
2021-12-08 10:09:15,148 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - running: Set()
2021-12-08 10:09:15,148 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - waiting: Set(ResultStage 16)
2021-12-08 10:09:15,148 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - failed: Set()
2021-12-08 10:09:15,149 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 16 (MapPartitionsRDD[40] at values at ALS.scala:1711), which has no missing parents
2021-12-08 10:09:15,151 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_15 stored as values in memory (estimated size 332.3 KB, free 1667.5 MB)
2021-12-08 10:09:15,153 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_15_piece0 stored as bytes in memory (estimated size 163.9 KB, free 1667.4 MB)
2021-12-08 10:09:15,153 [dispatcher-event-loop-1] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_15_piece0 in memory on qb:61292 (size: 163.9 KB, free: 1669.2 MB)
2021-12-08 10:09:15,154 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 15 from broadcast at DAGScheduler.scala:1039
2021-12-08 10:09:15,154 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 12 missing tasks from ResultStage 16 (MapPartitionsRDD[40] at values at ALS.scala:1711) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11))
2021-12-08 10:09:15,154 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 16.0 with 12 tasks
2021-12-08 10:09:15,155 [dispatcher-event-loop-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 16.0 (TID 92, localhost, executor driver, partition 0, PROCESS_LOCAL, 7888 bytes)
2021-12-08 10:09:15,155 [dispatcher-event-loop-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 16.0 (TID 93, localhost, executor driver, partition 1, PROCESS_LOCAL, 7888 bytes)
2021-12-08 10:09:15,156 [dispatcher-event-loop-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 2.0 in stage 16.0 (TID 94, localhost, executor driver, partition 2, PROCESS_LOCAL, 7888 bytes)
2021-12-08 10:09:15,156 [dispatcher-event-loop-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 3.0 in stage 16.0 (TID 95, localhost, executor driver, partition 3, PROCESS_LOCAL, 7888 bytes)
2021-12-08 10:09:15,156 [dispatcher-event-loop-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 4.0 in stage 16.0 (TID 96, localhost, executor driver, partition 4, PROCESS_LOCAL, 7888 bytes)
2021-12-08 10:09:15,156 [dispatcher-event-loop-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 5.0 in stage 16.0 (TID 97, localhost, executor driver, partition 5, PROCESS_LOCAL, 7888 bytes)
2021-12-08 10:09:15,156 [dispatcher-event-loop-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 6.0 in stage 16.0 (TID 98, localhost, executor driver, partition 6, PROCESS_LOCAL, 7888 bytes)
2021-12-08 10:09:15,156 [dispatcher-event-loop-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 7.0 in stage 16.0 (TID 99, localhost, executor driver, partition 7, PROCESS_LOCAL, 7888 bytes)
2021-12-08 10:09:15,156 [dispatcher-event-loop-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 8.0 in stage 16.0 (TID 100, localhost, executor driver, partition 8, PROCESS_LOCAL, 7888 bytes)
2021-12-08 10:09:15,156 [dispatcher-event-loop-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 9.0 in stage 16.0 (TID 101, localhost, executor driver, partition 9, PROCESS_LOCAL, 7888 bytes)
2021-12-08 10:09:15,157 [dispatcher-event-loop-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 10.0 in stage 16.0 (TID 102, localhost, executor driver, partition 10, PROCESS_LOCAL, 7888 bytes)
2021-12-08 10:09:15,157 [dispatcher-event-loop-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 11.0 in stage 16.0 (TID 103, localhost, executor driver, partition 11, PROCESS_LOCAL, 7888 bytes)
2021-12-08 10:09:15,157 [Executor task launch worker for task 93] INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 16.0 (TID 93)
2021-12-08 10:09:15,157 [Executor task launch worker for task 97] INFO [org.apache.spark.executor.Executor] - Running task 5.0 in stage 16.0 (TID 97)
2021-12-08 10:09:15,157 [Executor task launch worker for task 92] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 16.0 (TID 92)
2021-12-08 10:09:15,157 [Executor task launch worker for task 101] INFO [org.apache.spark.executor.Executor] - Running task 9.0 in stage 16.0 (TID 101)
2021-12-08 10:09:15,157 [Executor task launch worker for task 102] INFO [org.apache.spark.executor.Executor] - Running task 10.0 in stage 16.0 (TID 102)
2021-12-08 10:09:15,157 [Executor task launch worker for task 95] INFO [org.apache.spark.executor.Executor] - Running task 3.0 in stage 16.0 (TID 95)
2021-12-08 10:09:15,157 [Executor task launch worker for task 98] INFO [org.apache.spark.executor.Executor] - Running task 6.0 in stage 16.0 (TID 98)
2021-12-08 10:09:15,157 [Executor task launch worker for task 96] INFO [org.apache.spark.executor.Executor] - Running task 4.0 in stage 16.0 (TID 96)
2021-12-08 10:09:15,157 [Executor task launch worker for task 94] INFO [org.apache.spark.executor.Executor] - Running task 2.0 in stage 16.0 (TID 94)
2021-12-08 10:09:15,157 [Executor task launch worker for task 103] INFO [org.apache.spark.executor.Executor] - Running task 11.0 in stage 16.0 (TID 103)
2021-12-08 10:09:15,157 [Executor task launch worker for task 99] INFO [org.apache.spark.executor.Executor] - Running task 7.0 in stage 16.0 (TID 99)
2021-12-08 10:09:15,157 [Executor task launch worker for task 100] INFO [org.apache.spark.executor.Executor] - Running task 8.0 in stage 16.0 (TID 100)
2021-12-08 10:09:15,160 [Executor task launch worker for task 99] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_26_7 locally
2021-12-08 10:09:15,160 [Executor task launch worker for task 96] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_26_4 locally
2021-12-08 10:09:15,160 [Executor task launch worker for task 101] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_26_9 locally
2021-12-08 10:09:15,160 [Executor task launch worker for task 99] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 12 non-empty blocks out of 12 blocks
2021-12-08 10:09:15,160 [Executor task launch worker for task 102] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_26_10 locally
2021-12-08 10:09:15,160 [Executor task launch worker for task 93] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_26_1 locally
2021-12-08 10:09:15,161 [Executor task launch worker for task 99] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 1 ms
2021-12-08 10:09:15,161 [Executor task launch worker for task 96] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 12 non-empty blocks out of 12 blocks
2021-12-08 10:09:15,161 [Executor task launch worker for task 96] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 1 ms
2021-12-08 10:09:15,161 [Executor task launch worker for task 102] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 12 non-empty blocks out of 12 blocks
2021-12-08 10:09:15,160 [Executor task launch worker for task 94] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_26_2 locally
2021-12-08 10:09:15,160 [Executor task launch worker for task 95] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_26_3 locally
2021-12-08 10:09:15,161 [Executor task launch worker for task 100] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_26_8 locally
2021-12-08 10:09:15,161 [Executor task launch worker for task 102] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-08 10:09:15,161 [Executor task launch worker for task 101] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 12 non-empty blocks out of 12 blocks
2021-12-08 10:09:15,161 [Executor task launch worker for task 101] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-08 10:09:15,161 [Executor task launch worker for task 92] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_26_0 locally
2021-12-08 10:09:15,161 [Executor task launch worker for task 95] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 12 non-empty blocks out of 12 blocks
2021-12-08 10:09:15,161 [Executor task launch worker for task 95] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-08 10:09:15,161 [Executor task launch worker for task 94] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 12 non-empty blocks out of 12 blocks
2021-12-08 10:09:15,161 [Executor task launch worker for task 94] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-08 10:09:15,161 [Executor task launch worker for task 103] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_26_11 locally
2021-12-08 10:09:15,161 [Executor task launch worker for task 98] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_26_6 locally
2021-12-08 10:09:15,161 [Executor task launch worker for task 97] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_26_5 locally
2021-12-08 10:09:15,161 [Executor task launch worker for task 93] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 12 non-empty blocks out of 12 blocks
2021-12-08 10:09:15,161 [Executor task launch worker for task 93] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-08 10:09:15,161 [Executor task launch worker for task 100] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 12 non-empty blocks out of 12 blocks
2021-12-08 10:09:15,161 [Executor task launch worker for task 92] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 12 non-empty blocks out of 12 blocks
2021-12-08 10:09:15,161 [Executor task launch worker for task 92] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-08 10:09:15,161 [Executor task launch worker for task 100] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-08 10:09:15,161 [Executor task launch worker for task 97] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 12 non-empty blocks out of 12 blocks
2021-12-08 10:09:15,161 [Executor task launch worker for task 98] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 12 non-empty blocks out of 12 blocks
2021-12-08 10:09:15,161 [Executor task launch worker for task 103] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 12 non-empty blocks out of 12 blocks
2021-12-08 10:09:15,161 [Executor task launch worker for task 98] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-08 10:09:15,161 [Executor task launch worker for task 97] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-08 10:09:15,161 [Executor task launch worker for task 103] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-08 10:09:15,870 [dispatcher-event-loop-9] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_14_piece0 on qb:61292 in memory (size: 4.5 KB, free: 1669.2 MB)
2021-12-08 10:09:15,904 [Executor task launch worker for task 102] WARN [com.github.fommil.netlib.LAPACK] - Failed to load implementation from: com.github.fommil.netlib.NativeSystemLAPACK
2021-12-08 10:09:15,904 [Executor task launch worker for task 102] WARN [com.github.fommil.netlib.LAPACK] - Failed to load implementation from: com.github.fommil.netlib.NativeRefLAPACK
2021-12-08 10:09:36,303 [Executor task launch worker for task 97] INFO [org.apache.spark.storage.memory.MemoryStore] - Block rdd_39_5 stored as values in memory (estimated size 4.0 MB, free 1663.4 MB)
2021-12-08 10:09:36,303 [dispatcher-event-loop-1] INFO [org.apache.spark.storage.BlockManagerInfo] - Added rdd_39_5 in memory on qb:61292 (size: 4.0 MB, free: 1665.2 MB)
2021-12-08 10:09:36,425 [Executor task launch worker for task 97] INFO [org.apache.spark.executor.Executor] - Finished task 5.0 in stage 16.0 (TID 97). 166097 bytes result sent to driver
2021-12-08 10:09:36,452 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 5.0 in stage 16.0 (TID 97) in 21296 ms on localhost (executor driver) (1/12)
2021-12-08 10:09:36,734 [Executor task launch worker for task 93] INFO [org.apache.spark.storage.memory.MemoryStore] - Block rdd_39_1 stored as values in memory (estimated size 4.0 MB, free 1659.4 MB)
2021-12-08 10:09:36,735 [dispatcher-event-loop-3] INFO [org.apache.spark.storage.BlockManagerInfo] - Added rdd_39_1 in memory on qb:61292 (size: 4.0 MB, free: 1661.2 MB)
2021-12-08 10:09:36,853 [Executor task launch worker for task 93] INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 16.0 (TID 93). 166097 bytes result sent to driver
2021-12-08 10:09:36,854 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 16.0 (TID 93) in 21699 ms on localhost (executor driver) (2/12)
2021-12-08 10:09:37,207 [Executor task launch worker for task 92] INFO [org.apache.spark.storage.memory.MemoryStore] - Block rdd_39_0 stored as values in memory (estimated size 4.0 MB, free 1655.4 MB)
2021-12-08 10:09:37,208 [dispatcher-event-loop-8] INFO [org.apache.spark.storage.BlockManagerInfo] - Added rdd_39_0 in memory on qb:61292 (size: 4.0 MB, free: 1657.3 MB)
2021-12-08 10:09:37,312 [Executor task launch worker for task 92] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 16.0 (TID 92). 166054 bytes result sent to driver
2021-12-08 10:09:37,313 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 16.0 (TID 92) in 22158 ms on localhost (executor driver) (3/12)
2021-12-08 10:09:37,436 [Executor task launch worker for task 96] INFO [org.apache.spark.storage.memory.MemoryStore] - Block rdd_39_4 stored as values in memory (estimated size 4.0 MB, free 1651.4 MB)
2021-12-08 10:09:37,436 [dispatcher-event-loop-10] INFO [org.apache.spark.storage.BlockManagerInfo] - Added rdd_39_4 in memory on qb:61292 (size: 4.0 MB, free: 1653.3 MB)
2021-12-08 10:09:37,543 [Executor task launch worker for task 96] INFO [org.apache.spark.executor.Executor] - Finished task 4.0 in stage 16.0 (TID 96). 166097 bytes result sent to driver
2021-12-08 10:09:37,543 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 4.0 in stage 16.0 (TID 96) in 22387 ms on localhost (executor driver) (4/12)
2021-12-08 10:09:37,642 [Executor task launch worker for task 103] INFO [org.apache.spark.storage.memory.MemoryStore] - Block rdd_39_11 stored as values in memory (estimated size 4.0 MB, free 1647.4 MB)
2021-12-08 10:09:37,643 [dispatcher-event-loop-6] INFO [org.apache.spark.storage.BlockManagerInfo] - Added rdd_39_11 in memory on qb:61292 (size: 4.0 MB, free: 1649.3 MB)
2021-12-08 10:09:37,750 [Executor task launch worker for task 103] INFO [org.apache.spark.executor.Executor] - Finished task 11.0 in stage 16.0 (TID 103). 166054 bytes result sent to driver
2021-12-08 10:09:37,750 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 11.0 in stage 16.0 (TID 103) in 22593 ms on localhost (executor driver) (5/12)
2021-12-08 10:09:37,794 [Executor task launch worker for task 102] INFO [org.apache.spark.storage.memory.MemoryStore] - Block rdd_39_10 stored as values in memory (estimated size 4.0 MB, free 1643.4 MB)
2021-12-08 10:09:37,795 [dispatcher-event-loop-2] INFO [org.apache.spark.storage.BlockManagerInfo] - Added rdd_39_10 in memory on qb:61292 (size: 4.0 MB, free: 1645.3 MB)
2021-12-08 10:09:37,878 [Executor task launch worker for task 102] INFO [org.apache.spark.executor.Executor] - Finished task 10.0 in stage 16.0 (TID 102). 166054 bytes result sent to driver
2021-12-08 10:09:37,879 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 10.0 in stage 16.0 (TID 102) in 22723 ms on localhost (executor driver) (6/12)
2021-12-08 10:09:38,065 [Executor task launch worker for task 100] INFO [org.apache.spark.storage.memory.MemoryStore] - Block rdd_39_8 stored as values in memory (estimated size 4.0 MB, free 1639.4 MB)
2021-12-08 10:09:38,065 [dispatcher-event-loop-1] INFO [org.apache.spark.storage.BlockManagerInfo] - Added rdd_39_8 in memory on qb:61292 (size: 4.0 MB, free: 1641.3 MB)
2021-12-08 10:09:38,137 [Executor task launch worker for task 100] INFO [org.apache.spark.executor.Executor] - Finished task 8.0 in stage 16.0 (TID 100). 166054 bytes result sent to driver
2021-12-08 10:09:38,137 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 8.0 in stage 16.0 (TID 100) in 22981 ms on localhost (executor driver) (7/12)
2021-12-08 10:09:38,186 [Executor task launch worker for task 99] INFO [org.apache.spark.storage.memory.MemoryStore] - Block rdd_39_7 stored as values in memory (estimated size 4.0 MB, free 1635.5 MB)
2021-12-08 10:09:38,186 [dispatcher-event-loop-3] INFO [org.apache.spark.storage.BlockManagerInfo] - Added rdd_39_7 in memory on qb:61292 (size: 4.0 MB, free: 1637.3 MB)
2021-12-08 10:09:38,256 [Executor task launch worker for task 99] INFO [org.apache.spark.executor.Executor] - Finished task 7.0 in stage 16.0 (TID 99). 166054 bytes result sent to driver
2021-12-08 10:09:38,256 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 7.0 in stage 16.0 (TID 99) in 23100 ms on localhost (executor driver) (8/12)
2021-12-08 10:09:38,441 [Executor task launch worker for task 101] INFO [org.apache.spark.storage.memory.MemoryStore] - Block rdd_39_9 stored as values in memory (estimated size 4.0 MB, free 1631.5 MB)
2021-12-08 10:09:38,441 [dispatcher-event-loop-8] INFO [org.apache.spark.storage.BlockManagerInfo] - Added rdd_39_9 in memory on qb:61292 (size: 4.0 MB, free: 1633.3 MB)
2021-12-08 10:09:38,513 [Executor task launch worker for task 101] INFO [org.apache.spark.executor.Executor] - Finished task 9.0 in stage 16.0 (TID 101). 166054 bytes result sent to driver
2021-12-08 10:09:38,513 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 9.0 in stage 16.0 (TID 101) in 23357 ms on localhost (executor driver) (9/12)
2021-12-08 10:09:38,840 [Executor task launch worker for task 94] INFO [org.apache.spark.storage.memory.MemoryStore] - Block rdd_39_2 stored as values in memory (estimated size 4.0 MB, free 1627.5 MB)
2021-12-08 10:09:38,841 [dispatcher-event-loop-10] INFO [org.apache.spark.storage.BlockManagerInfo] - Added rdd_39_2 in memory on qb:61292 (size: 4.0 MB, free: 1629.3 MB)
2021-12-08 10:09:38,905 [Executor task launch worker for task 94] INFO [org.apache.spark.executor.Executor] - Finished task 2.0 in stage 16.0 (TID 94). 166054 bytes result sent to driver
2021-12-08 10:09:38,905 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 2.0 in stage 16.0 (TID 94) in 23749 ms on localhost (executor driver) (10/12)
2021-12-08 10:09:38,991 [Executor task launch worker for task 95] INFO [org.apache.spark.storage.memory.MemoryStore] - Block rdd_39_3 stored as values in memory (estimated size 4.0 MB, free 1623.5 MB)
2021-12-08 10:09:38,992 [dispatcher-event-loop-6] INFO [org.apache.spark.storage.BlockManagerInfo] - Added rdd_39_3 in memory on qb:61292 (size: 4.0 MB, free: 1625.3 MB)
2021-12-08 10:09:39,057 [Executor task launch worker for task 95] INFO [org.apache.spark.executor.Executor] - Finished task 3.0 in stage 16.0 (TID 95). 166097 bytes result sent to driver
2021-12-08 10:09:39,057 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 3.0 in stage 16.0 (TID 95) in 23901 ms on localhost (executor driver) (11/12)
2021-12-08 10:09:39,320 [Executor task launch worker for task 98] INFO [org.apache.spark.storage.memory.MemoryStore] - Block rdd_39_6 stored as values in memory (estimated size 4.0 MB, free 1619.5 MB)
2021-12-08 10:09:39,320 [dispatcher-event-loop-2] INFO [org.apache.spark.storage.BlockManagerInfo] - Added rdd_39_6 in memory on qb:61292 (size: 4.0 MB, free: 1621.4 MB)
2021-12-08 10:09:39,383 [Executor task launch worker for task 98] INFO [org.apache.spark.executor.Executor] - Finished task 6.0 in stage 16.0 (TID 98). 166097 bytes result sent to driver
2021-12-08 10:09:39,384 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 6.0 in stage 16.0 (TID 98) in 24228 ms on localhost (executor driver) (12/12)
2021-12-08 10:09:39,384 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 16.0, whose tasks have all completed, from pool 
2021-12-08 10:09:39,384 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 16 (aggregate at ALS.scala:1711) finished in 24.234 s
2021-12-08 10:09:39,384 [main] INFO [org.apache.spark.scheduler.DAGScheduler] - Job 5 finished: aggregate at ALS.scala:1711, took 27.087479 s
2021-12-08 10:09:39,400 [main] INFO [org.apache.spark.rdd.MapPartitionsRDD] - Removing RDD 28 from persistence list
2021-12-08 10:09:39,401 [block-manager-slave-async-thread-pool-2] INFO [org.apache.spark.storage.BlockManager] - Removing RDD 28
2021-12-08 10:09:39,408 [main] INFO [org.apache.spark.SparkContext] - Starting job: aggregate at ALS.scala:1711
2021-12-08 10:09:39,409 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 44 (flatMap at ALS.scala:1653)
2021-12-08 10:09:39,409 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 6 (aggregate at ALS.scala:1711) with 12 output partitions
2021-12-08 10:09:39,409 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 23 (aggregate at ALS.scala:1711)
2021-12-08 10:09:39,409 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 18, ShuffleMapStage 22)
2021-12-08 10:09:39,409 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List(ShuffleMapStage 22)
2021-12-08 10:09:39,409 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ShuffleMapStage 22 (MapPartitionsRDD[44] at flatMap at ALS.scala:1653), which has no missing parents
2021-12-08 10:09:39,411 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_16 stored as values in memory (estimated size 171.9 KB, free 1752.6 MB)
2021-12-08 10:09:39,412 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_16_piece0 stored as bytes in memory (estimated size 162.9 KB, free 1752.4 MB)
2021-12-08 10:09:39,412 [dispatcher-event-loop-10] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_16_piece0 in memory on qb:61292 (size: 162.9 KB, free: 1754.5 MB)
2021-12-08 10:09:39,412 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 16 from broadcast at DAGScheduler.scala:1039
2021-12-08 10:09:39,412 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 12 missing tasks from ShuffleMapStage 22 (MapPartitionsRDD[44] at flatMap at ALS.scala:1653) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11))
2021-12-08 10:09:39,412 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 22.0 with 12 tasks
2021-12-08 10:09:39,413 [dispatcher-event-loop-9] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 22.0 (TID 104, localhost, executor driver, partition 0, PROCESS_LOCAL, 7928 bytes)
2021-12-08 10:09:39,413 [dispatcher-event-loop-9] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 22.0 (TID 105, localhost, executor driver, partition 1, PROCESS_LOCAL, 7928 bytes)
2021-12-08 10:09:39,413 [dispatcher-event-loop-9] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 2.0 in stage 22.0 (TID 106, localhost, executor driver, partition 2, PROCESS_LOCAL, 7928 bytes)
2021-12-08 10:09:39,413 [dispatcher-event-loop-9] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 3.0 in stage 22.0 (TID 107, localhost, executor driver, partition 3, PROCESS_LOCAL, 7928 bytes)
2021-12-08 10:09:39,413 [dispatcher-event-loop-9] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 4.0 in stage 22.0 (TID 108, localhost, executor driver, partition 4, PROCESS_LOCAL, 7928 bytes)
2021-12-08 10:09:39,413 [dispatcher-event-loop-9] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 5.0 in stage 22.0 (TID 109, localhost, executor driver, partition 5, PROCESS_LOCAL, 7928 bytes)
2021-12-08 10:09:39,413 [dispatcher-event-loop-9] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 6.0 in stage 22.0 (TID 110, localhost, executor driver, partition 6, PROCESS_LOCAL, 7928 bytes)
2021-12-08 10:09:39,413 [dispatcher-event-loop-9] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 7.0 in stage 22.0 (TID 111, localhost, executor driver, partition 7, PROCESS_LOCAL, 7928 bytes)
2021-12-08 10:09:39,414 [dispatcher-event-loop-9] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 8.0 in stage 22.0 (TID 112, localhost, executor driver, partition 8, PROCESS_LOCAL, 7928 bytes)
2021-12-08 10:09:39,414 [dispatcher-event-loop-9] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 9.0 in stage 22.0 (TID 113, localhost, executor driver, partition 9, PROCESS_LOCAL, 7928 bytes)
2021-12-08 10:09:39,414 [dispatcher-event-loop-9] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 10.0 in stage 22.0 (TID 114, localhost, executor driver, partition 10, PROCESS_LOCAL, 7928 bytes)
2021-12-08 10:09:39,414 [dispatcher-event-loop-9] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 11.0 in stage 22.0 (TID 115, localhost, executor driver, partition 11, PROCESS_LOCAL, 7928 bytes)
2021-12-08 10:09:39,414 [Executor task launch worker for task 105] INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 22.0 (TID 105)
2021-12-08 10:09:39,414 [Executor task launch worker for task 106] INFO [org.apache.spark.executor.Executor] - Running task 2.0 in stage 22.0 (TID 106)
2021-12-08 10:09:39,414 [Executor task launch worker for task 114] INFO [org.apache.spark.executor.Executor] - Running task 10.0 in stage 22.0 (TID 114)
2021-12-08 10:09:39,414 [Executor task launch worker for task 115] INFO [org.apache.spark.executor.Executor] - Running task 11.0 in stage 22.0 (TID 115)
2021-12-08 10:09:39,414 [Executor task launch worker for task 109] INFO [org.apache.spark.executor.Executor] - Running task 5.0 in stage 22.0 (TID 109)
2021-12-08 10:09:39,414 [Executor task launch worker for task 108] INFO [org.apache.spark.executor.Executor] - Running task 4.0 in stage 22.0 (TID 108)
2021-12-08 10:09:39,414 [Executor task launch worker for task 110] INFO [org.apache.spark.executor.Executor] - Running task 6.0 in stage 22.0 (TID 110)
2021-12-08 10:09:39,414 [Executor task launch worker for task 104] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 22.0 (TID 104)
2021-12-08 10:09:39,414 [Executor task launch worker for task 111] INFO [org.apache.spark.executor.Executor] - Running task 7.0 in stage 22.0 (TID 111)
2021-12-08 10:09:39,414 [Executor task launch worker for task 113] INFO [org.apache.spark.executor.Executor] - Running task 9.0 in stage 22.0 (TID 113)
2021-12-08 10:09:39,414 [Executor task launch worker for task 112] INFO [org.apache.spark.executor.Executor] - Running task 8.0 in stage 22.0 (TID 112)
2021-12-08 10:09:39,414 [Executor task launch worker for task 107] INFO [org.apache.spark.executor.Executor] - Running task 3.0 in stage 22.0 (TID 107)
2021-12-08 10:09:39,416 [Executor task launch worker for task 111] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_27_7 locally
2021-12-08 10:09:39,416 [Executor task launch worker for task 109] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_27_5 locally
2021-12-08 10:09:39,416 [Executor task launch worker for task 107] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_27_3 locally
2021-12-08 10:09:39,416 [Executor task launch worker for task 114] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_27_10 locally
2021-12-08 10:09:39,416 [Executor task launch worker for task 108] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_27_4 locally
2021-12-08 10:09:39,416 [Executor task launch worker for task 110] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_27_6 locally
2021-12-08 10:09:39,416 [Executor task launch worker for task 113] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_27_9 locally
2021-12-08 10:09:39,416 [Executor task launch worker for task 104] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_27_0 locally
2021-12-08 10:09:39,416 [Executor task launch worker for task 109] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_39_5 locally
2021-12-08 10:09:39,416 [Executor task launch worker for task 111] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_39_7 locally
2021-12-08 10:09:39,416 [Executor task launch worker for task 112] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_27_8 locally
2021-12-08 10:09:39,416 [Executor task launch worker for task 107] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_39_3 locally
2021-12-08 10:09:39,416 [Executor task launch worker for task 110] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_39_6 locally
2021-12-08 10:09:39,416 [Executor task launch worker for task 104] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_39_0 locally
2021-12-08 10:09:39,416 [Executor task launch worker for task 114] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_39_10 locally
2021-12-08 10:09:39,416 [Executor task launch worker for task 112] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_39_8 locally
2021-12-08 10:09:39,416 [Executor task launch worker for task 108] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_39_4 locally
2021-12-08 10:09:39,416 [Executor task launch worker for task 106] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_27_2 locally
2021-12-08 10:09:39,416 [Executor task launch worker for task 106] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_39_2 locally
2021-12-08 10:09:39,416 [Executor task launch worker for task 113] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_39_9 locally
2021-12-08 10:09:39,417 [Executor task launch worker for task 115] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_27_11 locally
2021-12-08 10:09:39,417 [Executor task launch worker for task 115] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_39_11 locally
2021-12-08 10:09:39,418 [Executor task launch worker for task 105] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_27_1 locally
2021-12-08 10:09:39,418 [Executor task launch worker for task 105] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_39_1 locally
2021-12-08 10:09:40,430 [Executor task launch worker for task 104] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 22.0 (TID 104). 999 bytes result sent to driver
2021-12-08 10:09:40,431 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 22.0 (TID 104) in 1018 ms on localhost (executor driver) (1/12)
2021-12-08 10:09:40,431 [Executor task launch worker for task 114] INFO [org.apache.spark.executor.Executor] - Finished task 10.0 in stage 22.0 (TID 114). 999 bytes result sent to driver
2021-12-08 10:09:40,432 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 10.0 in stage 22.0 (TID 114) in 1018 ms on localhost (executor driver) (2/12)
2021-12-08 10:09:40,435 [Executor task launch worker for task 111] INFO [org.apache.spark.executor.Executor] - Finished task 7.0 in stage 22.0 (TID 111). 999 bytes result sent to driver
2021-12-08 10:09:40,436 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 7.0 in stage 22.0 (TID 111) in 1023 ms on localhost (executor driver) (3/12)
2021-12-08 10:09:40,452 [Executor task launch worker for task 112] INFO [org.apache.spark.executor.Executor] - Finished task 8.0 in stage 22.0 (TID 112). 999 bytes result sent to driver
2021-12-08 10:09:40,452 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 8.0 in stage 22.0 (TID 112) in 1038 ms on localhost (executor driver) (4/12)
2021-12-08 10:09:40,457 [Executor task launch worker for task 109] INFO [org.apache.spark.executor.Executor] - Finished task 5.0 in stage 22.0 (TID 109). 999 bytes result sent to driver
2021-12-08 10:09:40,457 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 5.0 in stage 22.0 (TID 109) in 1044 ms on localhost (executor driver) (5/12)
2021-12-08 10:09:40,465 [Executor task launch worker for task 110] INFO [org.apache.spark.executor.Executor] - Finished task 6.0 in stage 22.0 (TID 110). 999 bytes result sent to driver
2021-12-08 10:09:40,465 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 6.0 in stage 22.0 (TID 110) in 1052 ms on localhost (executor driver) (6/12)
2021-12-08 10:09:40,486 [Executor task launch worker for task 113] INFO [org.apache.spark.executor.Executor] - Finished task 9.0 in stage 22.0 (TID 113). 999 bytes result sent to driver
2021-12-08 10:09:40,486 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 9.0 in stage 22.0 (TID 113) in 1072 ms on localhost (executor driver) (7/12)
2021-12-08 10:09:40,489 [Executor task launch worker for task 115] INFO [org.apache.spark.executor.Executor] - Finished task 11.0 in stage 22.0 (TID 115). 999 bytes result sent to driver
2021-12-08 10:09:40,490 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 11.0 in stage 22.0 (TID 115) in 1075 ms on localhost (executor driver) (8/12)
2021-12-08 10:09:40,520 [Executor task launch worker for task 108] INFO [org.apache.spark.executor.Executor] - Finished task 4.0 in stage 22.0 (TID 108). 999 bytes result sent to driver
2021-12-08 10:09:40,520 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 4.0 in stage 22.0 (TID 108) in 1107 ms on localhost (executor driver) (9/12)
2021-12-08 10:09:40,550 [Executor task launch worker for task 105] INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 22.0 (TID 105). 999 bytes result sent to driver
2021-12-08 10:09:40,551 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 22.0 (TID 105) in 1138 ms on localhost (executor driver) (10/12)
2021-12-08 10:09:40,556 [Executor task launch worker for task 107] INFO [org.apache.spark.executor.Executor] - Finished task 3.0 in stage 22.0 (TID 107). 999 bytes result sent to driver
2021-12-08 10:09:40,557 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 3.0 in stage 22.0 (TID 107) in 1144 ms on localhost (executor driver) (11/12)
2021-12-08 10:09:40,557 [Executor task launch worker for task 106] INFO [org.apache.spark.executor.Executor] - Finished task 2.0 in stage 22.0 (TID 106). 999 bytes result sent to driver
2021-12-08 10:09:40,557 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 2.0 in stage 22.0 (TID 106) in 1144 ms on localhost (executor driver) (12/12)
2021-12-08 10:09:40,557 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 22.0, whose tasks have all completed, from pool 
2021-12-08 10:09:40,558 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ShuffleMapStage 22 (flatMap at ALS.scala:1653) finished in 1.148 s
2021-12-08 10:09:40,558 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - looking for newly runnable stages
2021-12-08 10:09:40,558 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - running: Set()
2021-12-08 10:09:40,558 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - waiting: Set(ResultStage 23)
2021-12-08 10:09:40,558 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - failed: Set()
2021-12-08 10:09:40,558 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 23 (MapPartitionsRDD[50] at values at ALS.scala:1711), which has no missing parents
2021-12-08 10:09:40,559 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_17 stored as values in memory (estimated size 493.5 KB, free 1752.0 MB)
2021-12-08 10:09:40,561 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_17_piece0 stored as bytes in memory (estimated size 321.7 KB, free 1751.6 MB)
2021-12-08 10:09:40,561 [dispatcher-event-loop-11] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_17_piece0 in memory on qb:61292 (size: 321.7 KB, free: 1754.1 MB)
2021-12-08 10:09:40,561 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 17 from broadcast at DAGScheduler.scala:1039
2021-12-08 10:09:40,562 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 12 missing tasks from ResultStage 23 (MapPartitionsRDD[50] at values at ALS.scala:1711) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11))
2021-12-08 10:09:40,562 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 23.0 with 12 tasks
2021-12-08 10:09:40,562 [dispatcher-event-loop-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 23.0 (TID 116, localhost, executor driver, partition 0, PROCESS_LOCAL, 7888 bytes)
2021-12-08 10:09:40,562 [dispatcher-event-loop-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 23.0 (TID 117, localhost, executor driver, partition 1, PROCESS_LOCAL, 7888 bytes)
2021-12-08 10:09:40,562 [dispatcher-event-loop-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 2.0 in stage 23.0 (TID 118, localhost, executor driver, partition 2, PROCESS_LOCAL, 7888 bytes)
2021-12-08 10:09:40,562 [dispatcher-event-loop-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 3.0 in stage 23.0 (TID 119, localhost, executor driver, partition 3, PROCESS_LOCAL, 7888 bytes)
2021-12-08 10:09:40,562 [dispatcher-event-loop-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 4.0 in stage 23.0 (TID 120, localhost, executor driver, partition 4, PROCESS_LOCAL, 7888 bytes)
2021-12-08 10:09:40,562 [dispatcher-event-loop-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 5.0 in stage 23.0 (TID 121, localhost, executor driver, partition 5, PROCESS_LOCAL, 7888 bytes)
2021-12-08 10:09:40,562 [dispatcher-event-loop-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 6.0 in stage 23.0 (TID 122, localhost, executor driver, partition 6, PROCESS_LOCAL, 7888 bytes)
2021-12-08 10:09:40,563 [dispatcher-event-loop-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 7.0 in stage 23.0 (TID 123, localhost, executor driver, partition 7, PROCESS_LOCAL, 7888 bytes)
2021-12-08 10:09:40,563 [dispatcher-event-loop-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 8.0 in stage 23.0 (TID 124, localhost, executor driver, partition 8, PROCESS_LOCAL, 7888 bytes)
2021-12-08 10:09:40,563 [dispatcher-event-loop-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 9.0 in stage 23.0 (TID 125, localhost, executor driver, partition 9, PROCESS_LOCAL, 7888 bytes)
2021-12-08 10:09:40,563 [dispatcher-event-loop-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 10.0 in stage 23.0 (TID 126, localhost, executor driver, partition 10, PROCESS_LOCAL, 7888 bytes)
2021-12-08 10:09:40,563 [dispatcher-event-loop-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 11.0 in stage 23.0 (TID 127, localhost, executor driver, partition 11, PROCESS_LOCAL, 7888 bytes)
2021-12-08 10:09:40,563 [Executor task launch worker for task 116] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 23.0 (TID 116)
2021-12-08 10:09:40,563 [Executor task launch worker for task 117] INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 23.0 (TID 117)
2021-12-08 10:09:40,563 [Executor task launch worker for task 126] INFO [org.apache.spark.executor.Executor] - Running task 10.0 in stage 23.0 (TID 126)
2021-12-08 10:09:40,563 [Executor task launch worker for task 127] INFO [org.apache.spark.executor.Executor] - Running task 11.0 in stage 23.0 (TID 127)
2021-12-08 10:09:40,563 [Executor task launch worker for task 123] INFO [org.apache.spark.executor.Executor] - Running task 7.0 in stage 23.0 (TID 123)
2021-12-08 10:09:40,563 [Executor task launch worker for task 118] INFO [org.apache.spark.executor.Executor] - Running task 2.0 in stage 23.0 (TID 118)
2021-12-08 10:09:40,563 [Executor task launch worker for task 124] INFO [org.apache.spark.executor.Executor] - Running task 8.0 in stage 23.0 (TID 124)
2021-12-08 10:09:40,563 [Executor task launch worker for task 122] INFO [org.apache.spark.executor.Executor] - Running task 6.0 in stage 23.0 (TID 122)
2021-12-08 10:09:40,563 [Executor task launch worker for task 119] INFO [org.apache.spark.executor.Executor] - Running task 3.0 in stage 23.0 (TID 119)
2021-12-08 10:09:40,563 [Executor task launch worker for task 121] INFO [org.apache.spark.executor.Executor] - Running task 5.0 in stage 23.0 (TID 121)
2021-12-08 10:09:40,563 [Executor task launch worker for task 120] INFO [org.apache.spark.executor.Executor] - Running task 4.0 in stage 23.0 (TID 120)
2021-12-08 10:09:40,563 [Executor task launch worker for task 125] INFO [org.apache.spark.executor.Executor] - Running task 9.0 in stage 23.0 (TID 125)
2021-12-08 10:09:40,565 [Executor task launch worker for task 122] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_21_6 locally
2021-12-08 10:09:40,565 [Executor task launch worker for task 121] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_21_5 locally
2021-12-08 10:09:40,566 [Executor task launch worker for task 124] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_21_8 locally
2021-12-08 10:09:40,565 [Executor task launch worker for task 127] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_21_11 locally
2021-12-08 10:09:40,566 [Executor task launch worker for task 119] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_21_3 locally
2021-12-08 10:09:40,566 [Executor task launch worker for task 117] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_21_1 locally
2021-12-08 10:09:40,566 [Executor task launch worker for task 116] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_21_0 locally
2021-12-08 10:09:40,566 [Executor task launch worker for task 120] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_21_4 locally
2021-12-08 10:09:40,566 [Executor task launch worker for task 118] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_21_2 locally
2021-12-08 10:09:40,566 [Executor task launch worker for task 117] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 12 non-empty blocks out of 12 blocks
2021-12-08 10:09:40,566 [Executor task launch worker for task 121] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 12 non-empty blocks out of 12 blocks
2021-12-08 10:09:40,566 [Executor task launch worker for task 119] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 12 non-empty blocks out of 12 blocks
2021-12-08 10:09:40,566 [Executor task launch worker for task 121] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-08 10:09:40,566 [Executor task launch worker for task 124] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 12 non-empty blocks out of 12 blocks
2021-12-08 10:09:40,566 [Executor task launch worker for task 122] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 12 non-empty blocks out of 12 blocks
2021-12-08 10:09:40,566 [Executor task launch worker for task 124] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-08 10:09:40,566 [Executor task launch worker for task 119] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-08 10:09:40,566 [Executor task launch worker for task 127] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 12 non-empty blocks out of 12 blocks
2021-12-08 10:09:40,566 [Executor task launch worker for task 117] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-08 10:09:40,566 [Executor task launch worker for task 126] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_21_10 locally
2021-12-08 10:09:40,566 [Executor task launch worker for task 127] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-08 10:09:40,566 [Executor task launch worker for task 123] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_21_7 locally
2021-12-08 10:09:40,566 [Executor task launch worker for task 118] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 12 non-empty blocks out of 12 blocks
2021-12-08 10:09:40,566 [Executor task launch worker for task 118] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-08 10:09:40,566 [Executor task launch worker for task 120] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 12 non-empty blocks out of 12 blocks
2021-12-08 10:09:40,566 [Executor task launch worker for task 116] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 12 non-empty blocks out of 12 blocks
2021-12-08 10:09:40,566 [Executor task launch worker for task 122] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-08 10:09:40,566 [Executor task launch worker for task 116] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-08 10:09:40,566 [Executor task launch worker for task 120] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-08 10:09:40,566 [Executor task launch worker for task 125] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_21_9 locally
2021-12-08 10:09:40,566 [Executor task launch worker for task 123] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 12 non-empty blocks out of 12 blocks
2021-12-08 10:09:40,566 [Executor task launch worker for task 123] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-08 10:09:40,566 [Executor task launch worker for task 126] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 12 non-empty blocks out of 12 blocks
2021-12-08 10:09:40,566 [Executor task launch worker for task 126] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-08 10:09:40,566 [Executor task launch worker for task 125] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 12 non-empty blocks out of 12 blocks
2021-12-08 10:09:40,567 [Executor task launch worker for task 125] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 1 ms
2021-12-08 10:09:40,638 [dispatcher-event-loop-5] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_16_piece0 on qb:61292 in memory (size: 162.9 KB, free: 1754.3 MB)
2021-12-08 10:10:17,268 [Executor task launch worker for task 121] INFO [org.apache.spark.storage.memory.MemoryStore] - Block rdd_49_5 stored as values in memory (estimated size 11.1 MB, free 1740.9 MB)
2021-12-08 10:10:17,268 [dispatcher-event-loop-3] INFO [org.apache.spark.storage.BlockManagerInfo] - Added rdd_49_5 in memory on qb:61292 (size: 11.1 MB, free: 1743.2 MB)
2021-12-08 10:10:17,606 [Executor task launch worker for task 121] INFO [org.apache.spark.executor.Executor] - Finished task 5.0 in stage 23.0 (TID 121). 166054 bytes result sent to driver
2021-12-08 10:10:17,611 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 5.0 in stage 23.0 (TID 121) in 37049 ms on localhost (executor driver) (1/12)
2021-12-08 10:10:17,645 [Executor task launch worker for task 116] INFO [org.apache.spark.storage.memory.MemoryStore] - Block rdd_49_0 stored as values in memory (estimated size 11.1 MB, free 1729.8 MB)
2021-12-08 10:10:17,645 [dispatcher-event-loop-5] INFO [org.apache.spark.storage.BlockManagerInfo] - Added rdd_49_0 in memory on qb:61292 (size: 11.1 MB, free: 1732.1 MB)
2021-12-08 10:10:17,834 [Executor task launch worker for task 120] INFO [org.apache.spark.storage.memory.MemoryStore] - Block rdd_49_4 stored as values in memory (estimated size 11.1 MB, free 1718.7 MB)
2021-12-08 10:10:17,835 [dispatcher-event-loop-1] INFO [org.apache.spark.storage.BlockManagerInfo] - Added rdd_49_4 in memory on qb:61292 (size: 11.1 MB, free: 1721.0 MB)
2021-12-08 10:10:17,846 [Executor task launch worker for task 117] INFO [org.apache.spark.storage.memory.MemoryStore] - Block rdd_49_1 stored as values in memory (estimated size 11.1 MB, free 1707.5 MB)
2021-12-08 10:10:17,846 [dispatcher-event-loop-8] INFO [org.apache.spark.storage.BlockManagerInfo] - Added rdd_49_1 in memory on qb:61292 (size: 11.1 MB, free: 1709.9 MB)
2021-12-08 10:10:18,023 [Executor task launch worker for task 116] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 23.0 (TID 116). 166097 bytes result sent to driver
2021-12-08 10:10:18,024 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 23.0 (TID 116) in 37462 ms on localhost (executor driver) (2/12)
2021-12-08 10:10:18,067 [Executor task launch worker for task 122] INFO [org.apache.spark.storage.memory.MemoryStore] - Block rdd_49_6 stored as values in memory (estimated size 11.1 MB, free 1696.4 MB)
2021-12-08 10:10:18,068 [dispatcher-event-loop-10] INFO [org.apache.spark.storage.BlockManagerInfo] - Added rdd_49_6 in memory on qb:61292 (size: 11.1 MB, free: 1698.8 MB)
2021-12-08 10:10:18,083 [Executor task launch worker for task 125] INFO [org.apache.spark.storage.memory.MemoryStore] - Block rdd_49_9 stored as values in memory (estimated size 11.1 MB, free 1685.3 MB)
2021-12-08 10:10:18,084 [dispatcher-event-loop-7] INFO [org.apache.spark.storage.BlockManagerInfo] - Added rdd_49_9 in memory on qb:61292 (size: 11.1 MB, free: 1687.7 MB)
2021-12-08 10:10:18,156 [Executor task launch worker for task 120] INFO [org.apache.spark.executor.Executor] - Finished task 4.0 in stage 23.0 (TID 120). 166054 bytes result sent to driver
2021-12-08 10:10:18,157 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 4.0 in stage 23.0 (TID 120) in 37595 ms on localhost (executor driver) (3/12)
2021-12-08 10:10:18,173 [Executor task launch worker for task 117] INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 23.0 (TID 117). 166054 bytes result sent to driver
2021-12-08 10:10:18,174 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 23.0 (TID 117) in 37612 ms on localhost (executor driver) (4/12)
2021-12-08 10:10:18,374 [Executor task launch worker for task 122] INFO [org.apache.spark.executor.Executor] - Finished task 6.0 in stage 23.0 (TID 122). 166054 bytes result sent to driver
2021-12-08 10:10:18,374 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 6.0 in stage 23.0 (TID 122) in 37812 ms on localhost (executor driver) (5/12)
2021-12-08 10:10:18,391 [Executor task launch worker for task 125] INFO [org.apache.spark.executor.Executor] - Finished task 9.0 in stage 23.0 (TID 125). 166054 bytes result sent to driver
2021-12-08 10:10:18,391 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 9.0 in stage 23.0 (TID 125) in 37828 ms on localhost (executor driver) (6/12)
2021-12-08 10:10:18,407 [Executor task launch worker for task 118] INFO [org.apache.spark.storage.memory.MemoryStore] - Block rdd_49_2 stored as values in memory (estimated size 11.1 MB, free 1674.2 MB)
2021-12-08 10:10:18,407 [dispatcher-event-loop-3] INFO [org.apache.spark.storage.BlockManagerInfo] - Added rdd_49_2 in memory on qb:61292 (size: 11.1 MB, free: 1676.6 MB)
2021-12-08 10:10:18,588 [Executor task launch worker for task 124] INFO [org.apache.spark.storage.memory.MemoryStore] - Block rdd_49_8 stored as values in memory (estimated size 11.1 MB, free 1663.1 MB)
2021-12-08 10:10:18,588 [dispatcher-event-loop-2] INFO [org.apache.spark.storage.BlockManagerInfo] - Added rdd_49_8 in memory on qb:61292 (size: 11.1 MB, free: 1665.5 MB)
2021-12-08 10:10:18,646 [Executor task launch worker for task 118] INFO [org.apache.spark.executor.Executor] - Finished task 2.0 in stage 23.0 (TID 118). 166054 bytes result sent to driver
2021-12-08 10:10:18,646 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 2.0 in stage 23.0 (TID 118) in 38084 ms on localhost (executor driver) (7/12)
2021-12-08 10:10:18,745 [Executor task launch worker for task 126] INFO [org.apache.spark.storage.memory.MemoryStore] - Block rdd_49_10 stored as values in memory (estimated size 11.1 MB, free 1652.0 MB)
2021-12-08 10:10:18,745 [dispatcher-event-loop-1] INFO [org.apache.spark.storage.BlockManagerInfo] - Added rdd_49_10 in memory on qb:61292 (size: 11.1 MB, free: 1654.4 MB)
2021-12-08 10:10:18,788 [Executor task launch worker for task 124] INFO [org.apache.spark.executor.Executor] - Finished task 8.0 in stage 23.0 (TID 124). 166054 bytes result sent to driver
2021-12-08 10:10:18,788 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 8.0 in stage 23.0 (TID 124) in 38225 ms on localhost (executor driver) (8/12)
2021-12-08 10:10:18,907 [Executor task launch worker for task 127] INFO [org.apache.spark.storage.memory.MemoryStore] - Block rdd_49_11 stored as values in memory (estimated size 11.1 MB, free 1640.9 MB)
2021-12-08 10:10:18,907 [dispatcher-event-loop-4] INFO [org.apache.spark.storage.BlockManagerInfo] - Added rdd_49_11 in memory on qb:61292 (size: 11.1 MB, free: 1643.3 MB)
2021-12-08 10:10:18,920 [Executor task launch worker for task 119] INFO [org.apache.spark.storage.memory.MemoryStore] - Block rdd_49_3 stored as values in memory (estimated size 11.1 MB, free 1629.8 MB)
2021-12-08 10:10:18,920 [dispatcher-event-loop-10] INFO [org.apache.spark.storage.BlockManagerInfo] - Added rdd_49_3 in memory on qb:61292 (size: 11.1 MB, free: 1632.1 MB)
2021-12-08 10:10:18,921 [Executor task launch worker for task 123] INFO [org.apache.spark.storage.memory.MemoryStore] - Block rdd_49_7 stored as values in memory (estimated size 11.1 MB, free 1618.7 MB)
2021-12-08 10:10:18,922 [dispatcher-event-loop-7] INFO [org.apache.spark.storage.BlockManagerInfo] - Added rdd_49_7 in memory on qb:61292 (size: 11.1 MB, free: 1621.0 MB)
2021-12-08 10:10:18,927 [Executor task launch worker for task 126] INFO [org.apache.spark.executor.Executor] - Finished task 10.0 in stage 23.0 (TID 126). 166054 bytes result sent to driver
2021-12-08 10:10:18,927 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 10.0 in stage 23.0 (TID 126) in 38364 ms on localhost (executor driver) (9/12)
2021-12-08 10:10:19,094 [Executor task launch worker for task 119] INFO [org.apache.spark.executor.Executor] - Finished task 3.0 in stage 23.0 (TID 119). 166054 bytes result sent to driver
2021-12-08 10:10:19,094 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 3.0 in stage 23.0 (TID 119) in 38532 ms on localhost (executor driver) (10/12)
2021-12-08 10:10:19,101 [Executor task launch worker for task 127] INFO [org.apache.spark.executor.Executor] - Finished task 11.0 in stage 23.0 (TID 127). 166054 bytes result sent to driver
2021-12-08 10:10:19,102 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 11.0 in stage 23.0 (TID 127) in 38539 ms on localhost (executor driver) (11/12)
2021-12-08 10:10:19,115 [Executor task launch worker for task 123] INFO [org.apache.spark.executor.Executor] - Finished task 7.0 in stage 23.0 (TID 123). 166097 bytes result sent to driver
2021-12-08 10:10:19,115 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 7.0 in stage 23.0 (TID 123) in 38553 ms on localhost (executor driver) (12/12)
2021-12-08 10:10:19,116 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 23.0, whose tasks have all completed, from pool 
2021-12-08 10:10:19,116 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 23 (aggregate at ALS.scala:1711) finished in 38.558 s
2021-12-08 10:10:19,116 [main] INFO [org.apache.spark.scheduler.DAGScheduler] - Job 6 finished: aggregate at ALS.scala:1711, took 39.708305 s
2021-12-08 10:10:19,132 [main] INFO [org.apache.spark.rdd.MapPartitionsRDD] - Removing RDD 39 from persistence list
2021-12-08 10:10:19,133 [block-manager-slave-async-thread-pool-2] INFO [org.apache.spark.storage.BlockManager] - Removing RDD 39
2021-12-08 10:10:19,139 [main] INFO [org.apache.spark.SparkContext] - Starting job: aggregate at ALS.scala:1711
2021-12-08 10:10:19,140 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 54 (flatMap at ALS.scala:1653)
2021-12-08 10:10:19,140 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 7 (aggregate at ALS.scala:1711) with 12 output partitions
2021-12-08 10:10:19,140 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 31 (aggregate at ALS.scala:1711)
2021-12-08 10:10:19,140 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 30, ShuffleMapStage 28)
2021-12-08 10:10:19,141 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List(ShuffleMapStage 30)
2021-12-08 10:10:19,141 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ShuffleMapStage 30 (MapPartitionsRDD[54] at flatMap at ALS.scala:1653), which has no missing parents
2021-12-08 10:10:19,142 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_18 stored as values in memory (estimated size 333.0 KB, free 1666.2 MB)
2021-12-08 10:10:19,144 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_18_piece0 stored as bytes in memory (estimated size 320.6 KB, free 1665.9 MB)
2021-12-08 10:10:19,144 [dispatcher-event-loop-10] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_18_piece0 in memory on qb:61292 (size: 320.6 KB, free: 1668.6 MB)
2021-12-08 10:10:19,144 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 18 from broadcast at DAGScheduler.scala:1039
2021-12-08 10:10:19,144 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 12 missing tasks from ShuffleMapStage 30 (MapPartitionsRDD[54] at flatMap at ALS.scala:1653) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11))
2021-12-08 10:10:19,144 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 30.0 with 12 tasks
2021-12-08 10:10:19,145 [dispatcher-event-loop-7] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 30.0 (TID 128, localhost, executor driver, partition 0, PROCESS_LOCAL, 7928 bytes)
2021-12-08 10:10:19,145 [dispatcher-event-loop-7] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 30.0 (TID 129, localhost, executor driver, partition 1, PROCESS_LOCAL, 7928 bytes)
2021-12-08 10:10:19,145 [dispatcher-event-loop-7] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 2.0 in stage 30.0 (TID 130, localhost, executor driver, partition 2, PROCESS_LOCAL, 7928 bytes)
2021-12-08 10:10:19,145 [dispatcher-event-loop-7] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 3.0 in stage 30.0 (TID 131, localhost, executor driver, partition 3, PROCESS_LOCAL, 7928 bytes)
2021-12-08 10:10:19,145 [dispatcher-event-loop-7] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 4.0 in stage 30.0 (TID 132, localhost, executor driver, partition 4, PROCESS_LOCAL, 7928 bytes)
2021-12-08 10:10:19,145 [dispatcher-event-loop-7] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 5.0 in stage 30.0 (TID 133, localhost, executor driver, partition 5, PROCESS_LOCAL, 7928 bytes)
2021-12-08 10:10:19,145 [dispatcher-event-loop-7] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 6.0 in stage 30.0 (TID 134, localhost, executor driver, partition 6, PROCESS_LOCAL, 7928 bytes)
2021-12-08 10:10:19,145 [dispatcher-event-loop-7] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 7.0 in stage 30.0 (TID 135, localhost, executor driver, partition 7, PROCESS_LOCAL, 7928 bytes)
2021-12-08 10:10:19,145 [dispatcher-event-loop-7] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 8.0 in stage 30.0 (TID 136, localhost, executor driver, partition 8, PROCESS_LOCAL, 7928 bytes)
2021-12-08 10:10:19,145 [dispatcher-event-loop-7] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 9.0 in stage 30.0 (TID 137, localhost, executor driver, partition 9, PROCESS_LOCAL, 7928 bytes)
2021-12-08 10:10:19,145 [dispatcher-event-loop-7] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 10.0 in stage 30.0 (TID 138, localhost, executor driver, partition 10, PROCESS_LOCAL, 7928 bytes)
2021-12-08 10:10:19,146 [dispatcher-event-loop-7] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 11.0 in stage 30.0 (TID 139, localhost, executor driver, partition 11, PROCESS_LOCAL, 7928 bytes)
2021-12-08 10:10:19,146 [Executor task launch worker for task 130] INFO [org.apache.spark.executor.Executor] - Running task 2.0 in stage 30.0 (TID 130)
2021-12-08 10:10:19,146 [Executor task launch worker for task 131] INFO [org.apache.spark.executor.Executor] - Running task 3.0 in stage 30.0 (TID 131)
2021-12-08 10:10:19,146 [Executor task launch worker for task 137] INFO [org.apache.spark.executor.Executor] - Running task 9.0 in stage 30.0 (TID 137)
2021-12-08 10:10:19,146 [Executor task launch worker for task 132] INFO [org.apache.spark.executor.Executor] - Running task 4.0 in stage 30.0 (TID 132)
2021-12-08 10:10:19,146 [Executor task launch worker for task 129] INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 30.0 (TID 129)
2021-12-08 10:10:19,146 [Executor task launch worker for task 134] INFO [org.apache.spark.executor.Executor] - Running task 6.0 in stage 30.0 (TID 134)
2021-12-08 10:10:19,146 [Executor task launch worker for task 136] INFO [org.apache.spark.executor.Executor] - Running task 8.0 in stage 30.0 (TID 136)
2021-12-08 10:10:19,146 [Executor task launch worker for task 135] INFO [org.apache.spark.executor.Executor] - Running task 7.0 in stage 30.0 (TID 135)
2021-12-08 10:10:19,146 [Executor task launch worker for task 133] INFO [org.apache.spark.executor.Executor] - Running task 5.0 in stage 30.0 (TID 133)
2021-12-08 10:10:19,146 [Executor task launch worker for task 128] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 30.0 (TID 128)
2021-12-08 10:10:19,146 [Executor task launch worker for task 139] INFO [org.apache.spark.executor.Executor] - Running task 11.0 in stage 30.0 (TID 139)
2021-12-08 10:10:19,146 [Executor task launch worker for task 138] INFO [org.apache.spark.executor.Executor] - Running task 10.0 in stage 30.0 (TID 138)
2021-12-08 10:10:19,147 [Executor task launch worker for task 136] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_22_8 locally
2021-12-08 10:10:19,147 [Executor task launch worker for task 137] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_22_9 locally
2021-12-08 10:10:19,147 [Executor task launch worker for task 135] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_22_7 locally
2021-12-08 10:10:19,147 [Executor task launch worker for task 133] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_22_5 locally
2021-12-08 10:10:19,147 [Executor task launch worker for task 139] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_22_11 locally
2021-12-08 10:10:19,147 [Executor task launch worker for task 138] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_22_10 locally
2021-12-08 10:10:19,147 [Executor task launch worker for task 132] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_22_4 locally
2021-12-08 10:10:19,147 [Executor task launch worker for task 135] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_49_7 locally
2021-12-08 10:10:19,147 [Executor task launch worker for task 137] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_49_9 locally
2021-12-08 10:10:19,148 [Executor task launch worker for task 133] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_49_5 locally
2021-12-08 10:10:19,147 [Executor task launch worker for task 139] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_49_11 locally
2021-12-08 10:10:19,148 [Executor task launch worker for task 136] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_49_8 locally
2021-12-08 10:10:19,148 [Executor task launch worker for task 134] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_22_6 locally
2021-12-08 10:10:19,148 [Executor task launch worker for task 134] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_49_6 locally
2021-12-08 10:10:19,148 [Executor task launch worker for task 131] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_22_3 locally
2021-12-08 10:10:19,148 [Executor task launch worker for task 138] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_49_10 locally
2021-12-08 10:10:19,148 [Executor task launch worker for task 130] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_22_2 locally
2021-12-08 10:10:19,148 [Executor task launch worker for task 132] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_49_4 locally
2021-12-08 10:10:19,148 [Executor task launch worker for task 129] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_22_1 locally
2021-12-08 10:10:19,148 [Executor task launch worker for task 129] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_49_1 locally
2021-12-08 10:10:19,148 [Executor task launch worker for task 130] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_49_2 locally
2021-12-08 10:10:19,148 [Executor task launch worker for task 128] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_22_0 locally
2021-12-08 10:10:19,149 [Executor task launch worker for task 128] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_49_0 locally
2021-12-08 10:10:19,148 [Executor task launch worker for task 131] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_49_3 locally
2021-12-08 10:10:19,410 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 228
2021-12-08 10:10:19,410 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 297
2021-12-08 10:10:19,410 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 224
2021-12-08 10:10:19,410 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 232
2021-12-08 10:10:19,410 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 209
2021-12-08 10:10:19,410 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 321
2021-12-08 10:10:19,410 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 310
2021-12-08 10:10:19,410 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 248
2021-12-08 10:10:19,410 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 316
2021-12-08 10:10:19,410 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 252
2021-12-08 10:10:19,410 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 267
2021-12-08 10:10:19,410 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 299
2021-12-08 10:10:19,410 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 223
2021-12-08 10:10:19,410 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 229
2021-12-08 10:10:19,410 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 274
2021-12-08 10:10:19,410 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 281
2021-12-08 10:10:19,410 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 255
2021-12-08 10:10:19,410 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 298
2021-12-08 10:10:19,410 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 294
2021-12-08 10:10:19,410 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 283
2021-12-08 10:10:19,410 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 243
2021-12-08 10:10:19,410 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 204
2021-12-08 10:10:19,410 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 220
2021-12-08 10:10:19,410 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 251
2021-12-08 10:10:19,410 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 260
2021-12-08 10:10:19,410 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 264
2021-12-08 10:10:19,410 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 214
2021-12-08 10:10:19,410 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 295
2021-12-08 10:10:19,410 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 231
2021-12-08 10:10:19,410 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 247
2021-12-08 10:10:19,410 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 237
2021-12-08 10:10:19,410 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 302
2021-12-08 10:10:19,410 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 286
2021-12-08 10:10:19,410 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 206
2021-12-08 10:10:19,410 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 233
2021-12-08 10:10:19,410 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 277
2021-12-08 10:10:19,412 [dispatcher-event-loop-9] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_17_piece0 on qb:61292 in memory (size: 321.7 KB, free: 1668.9 MB)
2021-12-08 10:10:19,413 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 250
2021-12-08 10:10:19,414 [dispatcher-event-loop-3] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_15_piece0 on qb:61292 in memory (size: 163.9 KB, free: 1669.1 MB)
2021-12-08 10:10:19,415 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 211
2021-12-08 10:10:19,415 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 304
2021-12-08 10:10:19,415 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 207
2021-12-08 10:10:19,415 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 306
2021-12-08 10:10:19,415 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 235
2021-12-08 10:10:19,415 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 259
2021-12-08 10:10:19,415 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 284
2021-12-08 10:10:19,415 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 210
2021-12-08 10:10:19,415 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 290
2021-12-08 10:10:19,415 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 222
2021-12-08 10:10:19,415 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 244
2021-12-08 10:10:19,415 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 265
2021-12-08 10:10:19,415 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 202
2021-12-08 10:10:19,415 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 324
2021-12-08 10:10:19,415 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 221
2021-12-08 10:10:19,415 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 296
2021-12-08 10:10:19,415 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 309
2021-12-08 10:10:19,415 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 269
2021-12-08 10:10:19,415 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 226
2021-12-08 10:10:19,415 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 249
2021-12-08 10:10:19,415 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 317
2021-12-08 10:10:19,415 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 311
2021-12-08 10:10:19,415 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 278
2021-12-08 10:10:19,415 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 305
2021-12-08 10:10:19,415 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 218
2021-12-08 10:10:19,415 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 263
2021-12-08 10:10:19,415 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 271
2021-12-08 10:10:19,415 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 289
2021-12-08 10:10:19,415 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 258
2021-12-08 10:10:19,415 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 266
2021-12-08 10:10:19,415 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 261
2021-12-08 10:10:19,415 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 227
2021-12-08 10:10:19,415 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 288
2021-12-08 10:10:19,415 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 312
2021-12-08 10:10:19,415 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 301
2021-12-08 10:10:19,416 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 215
2021-12-08 10:10:19,416 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 276
2021-12-08 10:10:19,416 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 254
2021-12-08 10:10:19,416 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 245
2021-12-08 10:10:19,416 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 293
2021-12-08 10:10:19,416 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 291
2021-12-08 10:10:19,416 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 201
2021-12-08 10:10:19,416 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 314
2021-12-08 10:10:19,416 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 280
2021-12-08 10:10:19,416 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 213
2021-12-08 10:10:19,416 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 282
2021-12-08 10:10:19,416 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 308
2021-12-08 10:10:19,416 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 318
2021-12-08 10:10:19,416 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 230
2021-12-08 10:10:19,416 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 208
2021-12-08 10:10:19,416 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 200
2021-12-08 10:10:19,416 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 300
2021-12-08 10:10:19,416 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 225
2021-12-08 10:10:19,416 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 303
2021-12-08 10:10:19,416 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 253
2021-12-08 10:10:19,416 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 256
2021-12-08 10:10:19,416 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 315
2021-12-08 10:10:19,416 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 219
2021-12-08 10:10:19,416 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 323
2021-12-08 10:10:19,416 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 275
2021-12-08 10:10:19,416 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 246
2021-12-08 10:10:19,416 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 238
2021-12-08 10:10:19,416 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 307
2021-12-08 10:10:19,416 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 241
2021-12-08 10:10:19,416 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 217
2021-12-08 10:10:19,416 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 292
2021-12-08 10:10:19,416 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 203
2021-12-08 10:10:19,416 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 242
2021-12-08 10:10:19,416 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 239
2021-12-08 10:10:19,416 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 205
2021-12-08 10:10:19,416 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 287
2021-12-08 10:10:19,416 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 216
2021-12-08 10:10:19,416 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 322
2021-12-08 10:10:19,416 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 257
2021-12-08 10:10:19,416 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 240
2021-12-08 10:10:19,416 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 272
2021-12-08 10:10:19,416 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 270
2021-12-08 10:10:19,416 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 313
2021-12-08 10:10:19,416 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 268
2021-12-08 10:10:19,416 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 262
2021-12-08 10:10:19,416 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 273
2021-12-08 10:10:19,416 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 236
2021-12-08 10:10:19,416 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 279
2021-12-08 10:10:19,416 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 319
2021-12-08 10:10:19,416 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 320
2021-12-08 10:10:19,416 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 234
2021-12-08 10:10:19,416 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 212
2021-12-08 10:10:19,416 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 285
2021-12-08 10:10:21,042 [Executor task launch worker for task 128] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 30.0 (TID 128). 1042 bytes result sent to driver
2021-12-08 10:10:21,042 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 30.0 (TID 128) in 1897 ms on localhost (executor driver) (1/12)
2021-12-08 10:10:21,093 [Executor task launch worker for task 130] INFO [org.apache.spark.executor.Executor] - Finished task 2.0 in stage 30.0 (TID 130). 1042 bytes result sent to driver
2021-12-08 10:10:21,093 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 2.0 in stage 30.0 (TID 130) in 1948 ms on localhost (executor driver) (2/12)
2021-12-08 10:10:21,102 [Executor task launch worker for task 129] INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 30.0 (TID 129). 1085 bytes result sent to driver
2021-12-08 10:10:21,103 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 30.0 (TID 129) in 1958 ms on localhost (executor driver) (3/12)
2021-12-08 10:10:21,159 [Executor task launch worker for task 139] INFO [org.apache.spark.executor.Executor] - Finished task 11.0 in stage 30.0 (TID 139). 1085 bytes result sent to driver
2021-12-08 10:10:21,159 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 11.0 in stage 30.0 (TID 139) in 2014 ms on localhost (executor driver) (4/12)
2021-12-08 10:10:21,174 [Executor task launch worker for task 136] INFO [org.apache.spark.executor.Executor] - Finished task 8.0 in stage 30.0 (TID 136). 1085 bytes result sent to driver
2021-12-08 10:10:21,174 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 8.0 in stage 30.0 (TID 136) in 2029 ms on localhost (executor driver) (5/12)
2021-12-08 10:10:21,179 [Executor task launch worker for task 134] INFO [org.apache.spark.executor.Executor] - Finished task 6.0 in stage 30.0 (TID 134). 1042 bytes result sent to driver
2021-12-08 10:10:21,180 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 6.0 in stage 30.0 (TID 134) in 2035 ms on localhost (executor driver) (6/12)
2021-12-08 10:10:21,204 [Executor task launch worker for task 135] INFO [org.apache.spark.executor.Executor] - Finished task 7.0 in stage 30.0 (TID 135). 1085 bytes result sent to driver
2021-12-08 10:10:21,204 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 7.0 in stage 30.0 (TID 135) in 2059 ms on localhost (executor driver) (7/12)
2021-12-08 10:10:21,210 [Executor task launch worker for task 138] INFO [org.apache.spark.executor.Executor] - Finished task 10.0 in stage 30.0 (TID 138). 1085 bytes result sent to driver
2021-12-08 10:10:21,211 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 10.0 in stage 30.0 (TID 138) in 2065 ms on localhost (executor driver) (8/12)
2021-12-08 10:10:21,218 [Executor task launch worker for task 131] INFO [org.apache.spark.executor.Executor] - Finished task 3.0 in stage 30.0 (TID 131). 1042 bytes result sent to driver
2021-12-08 10:10:21,218 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 3.0 in stage 30.0 (TID 131) in 2073 ms on localhost (executor driver) (9/12)
2021-12-08 10:10:21,232 [Executor task launch worker for task 132] INFO [org.apache.spark.executor.Executor] - Finished task 4.0 in stage 30.0 (TID 132). 1085 bytes result sent to driver
2021-12-08 10:10:21,232 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 4.0 in stage 30.0 (TID 132) in 2087 ms on localhost (executor driver) (10/12)
2021-12-08 10:10:21,241 [Executor task launch worker for task 133] INFO [org.apache.spark.executor.Executor] - Finished task 5.0 in stage 30.0 (TID 133). 1085 bytes result sent to driver
2021-12-08 10:10:21,242 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 5.0 in stage 30.0 (TID 133) in 2097 ms on localhost (executor driver) (11/12)
2021-12-08 10:10:21,427 [Executor task launch worker for task 137] INFO [org.apache.spark.executor.Executor] - Finished task 9.0 in stage 30.0 (TID 137). 1085 bytes result sent to driver
2021-12-08 10:10:21,428 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 9.0 in stage 30.0 (TID 137) in 2283 ms on localhost (executor driver) (12/12)
2021-12-08 10:10:21,428 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 30.0, whose tasks have all completed, from pool 
2021-12-08 10:10:21,428 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ShuffleMapStage 30 (flatMap at ALS.scala:1653) finished in 2.286 s
2021-12-08 10:10:21,428 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - looking for newly runnable stages
2021-12-08 10:10:21,428 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - running: Set()
2021-12-08 10:10:21,428 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - waiting: Set(ResultStage 31)
2021-12-08 10:10:21,428 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - failed: Set()
2021-12-08 10:10:21,429 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 31 (MapPartitionsRDD[60] at values at ALS.scala:1711), which has no missing parents
2021-12-08 10:10:21,431 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_19 stored as values in memory (estimated size 654.6 KB, free 1666.6 MB)
2021-12-08 10:10:21,432 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_19_piece0 stored as bytes in memory (estimated size 479.4 KB, free 1666.1 MB)
2021-12-08 10:10:21,433 [dispatcher-event-loop-8] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_19_piece0 in memory on qb:61292 (size: 479.4 KB, free: 1668.6 MB)
2021-12-08 10:10:21,433 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 19 from broadcast at DAGScheduler.scala:1039
2021-12-08 10:10:21,434 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 12 missing tasks from ResultStage 31 (MapPartitionsRDD[60] at values at ALS.scala:1711) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11))
2021-12-08 10:10:21,434 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 31.0 with 12 tasks
2021-12-08 10:10:21,434 [dispatcher-event-loop-4] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 31.0 (TID 140, localhost, executor driver, partition 0, PROCESS_LOCAL, 7888 bytes)
2021-12-08 10:10:21,434 [dispatcher-event-loop-4] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 31.0 (TID 141, localhost, executor driver, partition 1, PROCESS_LOCAL, 7888 bytes)
2021-12-08 10:10:21,434 [dispatcher-event-loop-4] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 2.0 in stage 31.0 (TID 142, localhost, executor driver, partition 2, PROCESS_LOCAL, 7888 bytes)
2021-12-08 10:10:21,434 [dispatcher-event-loop-4] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 3.0 in stage 31.0 (TID 143, localhost, executor driver, partition 3, PROCESS_LOCAL, 7888 bytes)
2021-12-08 10:10:21,435 [dispatcher-event-loop-4] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 4.0 in stage 31.0 (TID 144, localhost, executor driver, partition 4, PROCESS_LOCAL, 7888 bytes)
2021-12-08 10:10:21,435 [dispatcher-event-loop-4] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 5.0 in stage 31.0 (TID 145, localhost, executor driver, partition 5, PROCESS_LOCAL, 7888 bytes)
2021-12-08 10:10:21,435 [dispatcher-event-loop-4] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 6.0 in stage 31.0 (TID 146, localhost, executor driver, partition 6, PROCESS_LOCAL, 7888 bytes)
2021-12-08 10:10:21,435 [dispatcher-event-loop-4] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 7.0 in stage 31.0 (TID 147, localhost, executor driver, partition 7, PROCESS_LOCAL, 7888 bytes)
2021-12-08 10:10:21,435 [dispatcher-event-loop-4] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 8.0 in stage 31.0 (TID 148, localhost, executor driver, partition 8, PROCESS_LOCAL, 7888 bytes)
2021-12-08 10:10:21,435 [dispatcher-event-loop-4] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 9.0 in stage 31.0 (TID 149, localhost, executor driver, partition 9, PROCESS_LOCAL, 7888 bytes)
2021-12-08 10:10:21,435 [dispatcher-event-loop-4] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 10.0 in stage 31.0 (TID 150, localhost, executor driver, partition 10, PROCESS_LOCAL, 7888 bytes)
2021-12-08 10:10:21,435 [dispatcher-event-loop-4] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 11.0 in stage 31.0 (TID 151, localhost, executor driver, partition 11, PROCESS_LOCAL, 7888 bytes)
2021-12-08 10:10:21,435 [Executor task launch worker for task 140] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 31.0 (TID 140)
2021-12-08 10:10:21,435 [Executor task launch worker for task 143] INFO [org.apache.spark.executor.Executor] - Running task 3.0 in stage 31.0 (TID 143)
2021-12-08 10:10:21,435 [Executor task launch worker for task 147] INFO [org.apache.spark.executor.Executor] - Running task 7.0 in stage 31.0 (TID 147)
2021-12-08 10:10:21,435 [Executor task launch worker for task 150] INFO [org.apache.spark.executor.Executor] - Running task 10.0 in stage 31.0 (TID 150)
2021-12-08 10:10:21,435 [Executor task launch worker for task 144] INFO [org.apache.spark.executor.Executor] - Running task 4.0 in stage 31.0 (TID 144)
2021-12-08 10:10:21,435 [Executor task launch worker for task 149] INFO [org.apache.spark.executor.Executor] - Running task 9.0 in stage 31.0 (TID 149)
2021-12-08 10:10:21,435 [Executor task launch worker for task 142] INFO [org.apache.spark.executor.Executor] - Running task 2.0 in stage 31.0 (TID 142)
2021-12-08 10:10:21,435 [Executor task launch worker for task 145] INFO [org.apache.spark.executor.Executor] - Running task 5.0 in stage 31.0 (TID 145)
2021-12-08 10:10:21,435 [Executor task launch worker for task 141] INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 31.0 (TID 141)
2021-12-08 10:10:21,435 [Executor task launch worker for task 148] INFO [org.apache.spark.executor.Executor] - Running task 8.0 in stage 31.0 (TID 148)
2021-12-08 10:10:21,435 [Executor task launch worker for task 151] INFO [org.apache.spark.executor.Executor] - Running task 11.0 in stage 31.0 (TID 151)
2021-12-08 10:10:21,435 [Executor task launch worker for task 146] INFO [org.apache.spark.executor.Executor] - Running task 6.0 in stage 31.0 (TID 146)
2021-12-08 10:10:21,438 [Executor task launch worker for task 146] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_26_6 locally
2021-12-08 10:10:21,438 [Executor task launch worker for task 142] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_26_2 locally
2021-12-08 10:10:21,438 [Executor task launch worker for task 146] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 12 non-empty blocks out of 12 blocks
2021-12-08 10:10:21,438 [Executor task launch worker for task 146] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-08 10:10:21,438 [Executor task launch worker for task 145] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_26_5 locally
2021-12-08 10:10:21,438 [Executor task launch worker for task 148] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_26_8 locally
2021-12-08 10:10:21,439 [Executor task launch worker for task 148] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 12 non-empty blocks out of 12 blocks
2021-12-08 10:10:21,439 [Executor task launch worker for task 148] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-08 10:10:21,439 [Executor task launch worker for task 145] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 12 non-empty blocks out of 12 blocks
2021-12-08 10:10:21,439 [Executor task launch worker for task 145] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-08 10:10:21,438 [Executor task launch worker for task 142] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 12 non-empty blocks out of 12 blocks
2021-12-08 10:10:21,439 [Executor task launch worker for task 150] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_26_10 locally
2021-12-08 10:10:21,439 [Executor task launch worker for task 150] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 12 non-empty blocks out of 12 blocks
2021-12-08 10:10:21,439 [Executor task launch worker for task 150] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-08 10:10:21,438 [Executor task launch worker for task 143] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_26_3 locally
2021-12-08 10:10:21,439 [Executor task launch worker for task 143] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 12 non-empty blocks out of 12 blocks
2021-12-08 10:10:21,439 [Executor task launch worker for task 143] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-08 10:10:21,438 [Executor task launch worker for task 151] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_26_11 locally
2021-12-08 10:10:21,439 [Executor task launch worker for task 142] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 1 ms
2021-12-08 10:10:21,439 [Executor task launch worker for task 147] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_26_7 locally
2021-12-08 10:10:21,439 [Executor task launch worker for task 144] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_26_4 locally
2021-12-08 10:10:21,439 [Executor task launch worker for task 147] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 12 non-empty blocks out of 12 blocks
2021-12-08 10:10:21,439 [Executor task launch worker for task 147] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-08 10:10:21,439 [Executor task launch worker for task 151] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 12 non-empty blocks out of 12 blocks
2021-12-08 10:10:21,439 [Executor task launch worker for task 140] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_26_0 locally
2021-12-08 10:10:21,440 [Executor task launch worker for task 151] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 1 ms
2021-12-08 10:10:21,440 [Executor task launch worker for task 144] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 12 non-empty blocks out of 12 blocks
2021-12-08 10:10:21,440 [Executor task launch worker for task 140] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 12 non-empty blocks out of 12 blocks
2021-12-08 10:10:21,440 [Executor task launch worker for task 140] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-08 10:10:21,439 [Executor task launch worker for task 149] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_26_9 locally
2021-12-08 10:10:21,440 [Executor task launch worker for task 144] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 1 ms
2021-12-08 10:10:21,440 [Executor task launch worker for task 141] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_26_1 locally
2021-12-08 10:10:21,440 [Executor task launch worker for task 149] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 12 non-empty blocks out of 12 blocks
2021-12-08 10:10:21,440 [Executor task launch worker for task 149] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-08 10:10:21,440 [Executor task launch worker for task 141] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 12 non-empty blocks out of 12 blocks
2021-12-08 10:10:21,440 [Executor task launch worker for task 141] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-08 10:10:22,020 [dispatcher-event-loop-10] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_18_piece0 on qb:61292 in memory (size: 320.6 KB, free: 1668.9 MB)
2021-12-08 10:10:43,098 [Executor task launch worker for task 141] INFO [org.apache.spark.storage.memory.MemoryStore] - Block rdd_59_1 stored as values in memory (estimated size 4.0 MB, free 1662.8 MB)
2021-12-08 10:10:43,098 [dispatcher-event-loop-3] INFO [org.apache.spark.storage.BlockManagerInfo] - Added rdd_59_1 in memory on qb:61292 (size: 4.0 MB, free: 1664.9 MB)
2021-12-08 10:10:43,218 [Executor task launch worker for task 141] INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 31.0 (TID 141). 166097 bytes result sent to driver
2021-12-08 10:10:43,223 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 31.0 (TID 141) in 21789 ms on localhost (executor driver) (1/12)
2021-12-08 10:10:43,227 [Executor task launch worker for task 144] INFO [org.apache.spark.storage.memory.MemoryStore] - Block rdd_59_4 stored as values in memory (estimated size 4.0 MB, free 1658.8 MB)
2021-12-08 10:10:43,227 [dispatcher-event-loop-5] INFO [org.apache.spark.storage.BlockManagerInfo] - Added rdd_59_4 in memory on qb:61292 (size: 4.0 MB, free: 1660.9 MB)
2021-12-08 10:10:43,298 [Executor task launch worker for task 140] INFO [org.apache.spark.storage.memory.MemoryStore] - Block rdd_59_0 stored as values in memory (estimated size 4.0 MB, free 1654.8 MB)
2021-12-08 10:10:43,298 [dispatcher-event-loop-8] INFO [org.apache.spark.storage.BlockManagerInfo] - Added rdd_59_0 in memory on qb:61292 (size: 4.0 MB, free: 1656.9 MB)
2021-12-08 10:10:43,298 [Executor task launch worker for task 145] INFO [org.apache.spark.storage.memory.MemoryStore] - Block rdd_59_5 stored as values in memory (estimated size 4.0 MB, free 1650.8 MB)
2021-12-08 10:10:43,298 [dispatcher-event-loop-4] INFO [org.apache.spark.storage.BlockManagerInfo] - Added rdd_59_5 in memory on qb:61292 (size: 4.0 MB, free: 1653.0 MB)
2021-12-08 10:10:43,353 [Executor task launch worker for task 144] INFO [org.apache.spark.executor.Executor] - Finished task 4.0 in stage 31.0 (TID 144). 166054 bytes result sent to driver
2021-12-08 10:10:43,355 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 4.0 in stage 31.0 (TID 144) in 21921 ms on localhost (executor driver) (2/12)
2021-12-08 10:10:43,423 [Executor task launch worker for task 140] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 31.0 (TID 140). 166054 bytes result sent to driver
2021-12-08 10:10:43,425 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 31.0 (TID 140) in 21991 ms on localhost (executor driver) (3/12)
2021-12-08 10:10:43,434 [Executor task launch worker for task 145] INFO [org.apache.spark.executor.Executor] - Finished task 5.0 in stage 31.0 (TID 145). 166054 bytes result sent to driver
2021-12-08 10:10:43,434 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 5.0 in stage 31.0 (TID 145) in 21999 ms on localhost (executor driver) (4/12)
2021-12-08 10:10:43,828 [Executor task launch worker for task 148] INFO [org.apache.spark.storage.memory.MemoryStore] - Block rdd_59_8 stored as values in memory (estimated size 4.0 MB, free 1646.8 MB)
2021-12-08 10:10:43,828 [dispatcher-event-loop-11] INFO [org.apache.spark.storage.BlockManagerInfo] - Added rdd_59_8 in memory on qb:61292 (size: 4.0 MB, free: 1649.0 MB)
2021-12-08 10:10:43,921 [Executor task launch worker for task 148] INFO [org.apache.spark.executor.Executor] - Finished task 8.0 in stage 31.0 (TID 148). 166097 bytes result sent to driver
2021-12-08 10:10:43,921 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 8.0 in stage 31.0 (TID 148) in 22486 ms on localhost (executor driver) (5/12)
2021-12-08 10:10:44,030 [Executor task launch worker for task 151] INFO [org.apache.spark.storage.memory.MemoryStore] - Block rdd_59_11 stored as values in memory (estimated size 4.0 MB, free 1642.8 MB)
2021-12-08 10:10:44,031 [dispatcher-event-loop-2] INFO [org.apache.spark.storage.BlockManagerInfo] - Added rdd_59_11 in memory on qb:61292 (size: 4.0 MB, free: 1645.0 MB)
2021-12-08 10:10:44,110 [Executor task launch worker for task 151] INFO [org.apache.spark.executor.Executor] - Finished task 11.0 in stage 31.0 (TID 151). 166097 bytes result sent to driver
2021-12-08 10:10:44,111 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 11.0 in stage 31.0 (TID 151) in 22676 ms on localhost (executor driver) (6/12)
2021-12-08 10:10:44,161 [Executor task launch worker for task 150] INFO [org.apache.spark.storage.memory.MemoryStore] - Block rdd_59_10 stored as values in memory (estimated size 4.0 MB, free 1638.8 MB)
2021-12-08 10:10:44,161 [dispatcher-event-loop-3] INFO [org.apache.spark.storage.BlockManagerInfo] - Added rdd_59_10 in memory on qb:61292 (size: 4.0 MB, free: 1641.0 MB)
2021-12-08 10:10:44,197 [Executor task launch worker for task 147] INFO [org.apache.spark.storage.memory.MemoryStore] - Block rdd_59_7 stored as values in memory (estimated size 4.0 MB, free 1634.8 MB)
2021-12-08 10:10:44,197 [dispatcher-event-loop-1] INFO [org.apache.spark.storage.BlockManagerInfo] - Added rdd_59_7 in memory on qb:61292 (size: 4.0 MB, free: 1637.0 MB)
2021-12-08 10:10:44,232 [Executor task launch worker for task 150] INFO [org.apache.spark.executor.Executor] - Finished task 10.0 in stage 31.0 (TID 150). 166054 bytes result sent to driver
2021-12-08 10:10:44,233 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 10.0 in stage 31.0 (TID 150) in 22797 ms on localhost (executor driver) (7/12)
2021-12-08 10:10:44,280 [Executor task launch worker for task 147] INFO [org.apache.spark.executor.Executor] - Finished task 7.0 in stage 31.0 (TID 147). 166054 bytes result sent to driver
2021-12-08 10:10:44,281 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 7.0 in stage 31.0 (TID 147) in 22846 ms on localhost (executor driver) (8/12)
2021-12-08 10:10:44,941 [Executor task launch worker for task 149] INFO [org.apache.spark.storage.memory.MemoryStore] - Block rdd_59_9 stored as values in memory (estimated size 4.0 MB, free 1630.8 MB)
2021-12-08 10:10:44,941 [dispatcher-event-loop-4] INFO [org.apache.spark.storage.BlockManagerInfo] - Added rdd_59_9 in memory on qb:61292 (size: 4.0 MB, free: 1633.0 MB)
2021-12-08 10:10:45,023 [Executor task launch worker for task 149] INFO [org.apache.spark.executor.Executor] - Finished task 9.0 in stage 31.0 (TID 149). 166054 bytes result sent to driver
2021-12-08 10:10:45,024 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 9.0 in stage 31.0 (TID 149) in 23589 ms on localhost (executor driver) (9/12)
2021-12-08 10:10:45,170 [Executor task launch worker for task 143] INFO [org.apache.spark.storage.memory.MemoryStore] - Block rdd_59_3 stored as values in memory (estimated size 4.0 MB, free 1626.9 MB)
2021-12-08 10:10:45,171 [dispatcher-event-loop-6] INFO [org.apache.spark.storage.BlockManagerInfo] - Added rdd_59_3 in memory on qb:61292 (size: 4.0 MB, free: 1629.0 MB)
2021-12-08 10:10:45,240 [Executor task launch worker for task 143] INFO [org.apache.spark.executor.Executor] - Finished task 3.0 in stage 31.0 (TID 143). 166054 bytes result sent to driver
2021-12-08 10:10:45,241 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 3.0 in stage 31.0 (TID 143) in 23807 ms on localhost (executor driver) (10/12)
2021-12-08 10:10:45,292 [Executor task launch worker for task 142] INFO [org.apache.spark.storage.memory.MemoryStore] - Block rdd_59_2 stored as values in memory (estimated size 4.0 MB, free 1622.9 MB)
2021-12-08 10:10:45,292 [dispatcher-event-loop-2] INFO [org.apache.spark.storage.BlockManagerInfo] - Added rdd_59_2 in memory on qb:61292 (size: 4.0 MB, free: 1625.0 MB)
2021-12-08 10:10:45,356 [Executor task launch worker for task 142] INFO [org.apache.spark.executor.Executor] - Finished task 2.0 in stage 31.0 (TID 142). 166097 bytes result sent to driver
2021-12-08 10:10:45,357 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 2.0 in stage 31.0 (TID 142) in 23922 ms on localhost (executor driver) (11/12)
2021-12-08 10:10:45,674 [Executor task launch worker for task 146] INFO [org.apache.spark.storage.memory.MemoryStore] - Block rdd_59_6 stored as values in memory (estimated size 4.0 MB, free 1618.9 MB)
2021-12-08 10:10:45,674 [dispatcher-event-loop-3] INFO [org.apache.spark.storage.BlockManagerInfo] - Added rdd_59_6 in memory on qb:61292 (size: 4.0 MB, free: 1621.0 MB)
2021-12-08 10:10:45,737 [Executor task launch worker for task 146] INFO [org.apache.spark.executor.Executor] - Finished task 6.0 in stage 31.0 (TID 146). 166054 bytes result sent to driver
2021-12-08 10:10:45,737 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 6.0 in stage 31.0 (TID 146) in 24302 ms on localhost (executor driver) (12/12)
2021-12-08 10:10:45,737 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 31.0, whose tasks have all completed, from pool 
2021-12-08 10:10:45,737 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 31 (aggregate at ALS.scala:1711) finished in 24.308 s
2021-12-08 10:10:45,737 [main] INFO [org.apache.spark.scheduler.DAGScheduler] - Job 7 finished: aggregate at ALS.scala:1711, took 26.598013 s
2021-12-08 10:10:45,753 [main] INFO [org.apache.spark.rdd.MapPartitionsRDD] - Removing RDD 49 from persistence list
2021-12-08 10:10:45,754 [block-manager-slave-async-thread-pool-2] INFO [org.apache.spark.storage.BlockManager] - Removing RDD 49
2021-12-08 10:10:45,760 [main] INFO [org.apache.spark.SparkContext] - Starting job: aggregate at ALS.scala:1711
2021-12-08 10:10:45,761 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 64 (flatMap at ALS.scala:1653)
2021-12-08 10:10:45,761 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 8 (aggregate at ALS.scala:1711) with 12 output partitions
2021-12-08 10:10:45,761 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 40 (aggregate at ALS.scala:1711)
2021-12-08 10:10:45,761 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 33, ShuffleMapStage 39)
2021-12-08 10:10:45,762 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List(ShuffleMapStage 39)
2021-12-08 10:10:45,762 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ShuffleMapStage 39 (MapPartitionsRDD[64] at flatMap at ALS.scala:1653), which has no missing parents
2021-12-08 10:10:45,764 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_20 stored as values in memory (estimated size 494.1 KB, free 1751.7 MB)
2021-12-08 10:10:45,766 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_20_piece0 stored as bytes in memory (estimated size 478.4 KB, free 1751.2 MB)
2021-12-08 10:10:45,766 [dispatcher-event-loop-11] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_20_piece0 in memory on qb:61292 (size: 478.4 KB, free: 1753.8 MB)
2021-12-08 10:10:45,766 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 20 from broadcast at DAGScheduler.scala:1039
2021-12-08 10:10:45,767 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 12 missing tasks from ShuffleMapStage 39 (MapPartitionsRDD[64] at flatMap at ALS.scala:1653) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11))
2021-12-08 10:10:45,767 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 39.0 with 12 tasks
2021-12-08 10:10:45,767 [dispatcher-event-loop-9] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 39.0 (TID 152, localhost, executor driver, partition 0, PROCESS_LOCAL, 7928 bytes)
2021-12-08 10:10:45,767 [dispatcher-event-loop-9] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 39.0 (TID 153, localhost, executor driver, partition 1, PROCESS_LOCAL, 7928 bytes)
2021-12-08 10:10:45,767 [dispatcher-event-loop-9] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 2.0 in stage 39.0 (TID 154, localhost, executor driver, partition 2, PROCESS_LOCAL, 7928 bytes)
2021-12-08 10:10:45,767 [dispatcher-event-loop-9] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 3.0 in stage 39.0 (TID 155, localhost, executor driver, partition 3, PROCESS_LOCAL, 7928 bytes)
2021-12-08 10:10:45,767 [dispatcher-event-loop-9] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 4.0 in stage 39.0 (TID 156, localhost, executor driver, partition 4, PROCESS_LOCAL, 7928 bytes)
2021-12-08 10:10:45,767 [dispatcher-event-loop-9] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 5.0 in stage 39.0 (TID 157, localhost, executor driver, partition 5, PROCESS_LOCAL, 7928 bytes)
2021-12-08 10:10:45,768 [dispatcher-event-loop-9] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 6.0 in stage 39.0 (TID 158, localhost, executor driver, partition 6, PROCESS_LOCAL, 7928 bytes)
2021-12-08 10:10:45,768 [dispatcher-event-loop-9] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 7.0 in stage 39.0 (TID 159, localhost, executor driver, partition 7, PROCESS_LOCAL, 7928 bytes)
2021-12-08 10:10:45,768 [dispatcher-event-loop-9] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 8.0 in stage 39.0 (TID 160, localhost, executor driver, partition 8, PROCESS_LOCAL, 7928 bytes)
2021-12-08 10:10:45,768 [dispatcher-event-loop-9] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 9.0 in stage 39.0 (TID 161, localhost, executor driver, partition 9, PROCESS_LOCAL, 7928 bytes)
2021-12-08 10:10:45,768 [dispatcher-event-loop-9] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 10.0 in stage 39.0 (TID 162, localhost, executor driver, partition 10, PROCESS_LOCAL, 7928 bytes)
2021-12-08 10:10:45,768 [dispatcher-event-loop-9] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 11.0 in stage 39.0 (TID 163, localhost, executor driver, partition 11, PROCESS_LOCAL, 7928 bytes)
2021-12-08 10:10:45,768 [Executor task launch worker for task 152] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 39.0 (TID 152)
2021-12-08 10:10:45,768 [Executor task launch worker for task 153] INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 39.0 (TID 153)
2021-12-08 10:10:45,768 [Executor task launch worker for task 157] INFO [org.apache.spark.executor.Executor] - Running task 5.0 in stage 39.0 (TID 157)
2021-12-08 10:10:45,768 [Executor task launch worker for task 163] INFO [org.apache.spark.executor.Executor] - Running task 11.0 in stage 39.0 (TID 163)
2021-12-08 10:10:45,768 [Executor task launch worker for task 161] INFO [org.apache.spark.executor.Executor] - Running task 9.0 in stage 39.0 (TID 161)
2021-12-08 10:10:45,768 [Executor task launch worker for task 162] INFO [org.apache.spark.executor.Executor] - Running task 10.0 in stage 39.0 (TID 162)
2021-12-08 10:10:45,768 [Executor task launch worker for task 159] INFO [org.apache.spark.executor.Executor] - Running task 7.0 in stage 39.0 (TID 159)
2021-12-08 10:10:45,768 [Executor task launch worker for task 158] INFO [org.apache.spark.executor.Executor] - Running task 6.0 in stage 39.0 (TID 158)
2021-12-08 10:10:45,768 [Executor task launch worker for task 155] INFO [org.apache.spark.executor.Executor] - Running task 3.0 in stage 39.0 (TID 155)
2021-12-08 10:10:45,768 [Executor task launch worker for task 156] INFO [org.apache.spark.executor.Executor] - Running task 4.0 in stage 39.0 (TID 156)
2021-12-08 10:10:45,768 [Executor task launch worker for task 154] INFO [org.apache.spark.executor.Executor] - Running task 2.0 in stage 39.0 (TID 154)
2021-12-08 10:10:45,768 [Executor task launch worker for task 160] INFO [org.apache.spark.executor.Executor] - Running task 8.0 in stage 39.0 (TID 160)
2021-12-08 10:10:45,770 [Executor task launch worker for task 155] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_27_3 locally
2021-12-08 10:10:45,770 [Executor task launch worker for task 158] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_27_6 locally
2021-12-08 10:10:45,770 [Executor task launch worker for task 156] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_27_4 locally
2021-12-08 10:10:45,770 [Executor task launch worker for task 156] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_59_4 locally
2021-12-08 10:10:45,770 [Executor task launch worker for task 158] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_59_6 locally
2021-12-08 10:10:45,770 [Executor task launch worker for task 160] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_27_8 locally
2021-12-08 10:10:45,770 [Executor task launch worker for task 160] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_59_8 locally
2021-12-08 10:10:45,770 [Executor task launch worker for task 154] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_27_2 locally
2021-12-08 10:10:45,771 [Executor task launch worker for task 154] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_59_2 locally
2021-12-08 10:10:45,771 [Executor task launch worker for task 161] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_27_9 locally
2021-12-08 10:10:45,771 [Executor task launch worker for task 161] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_59_9 locally
2021-12-08 10:10:45,771 [Executor task launch worker for task 153] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_27_1 locally
2021-12-08 10:10:45,771 [Executor task launch worker for task 153] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_59_1 locally
2021-12-08 10:10:45,770 [Executor task launch worker for task 163] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_27_11 locally
2021-12-08 10:10:45,771 [Executor task launch worker for task 152] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_27_0 locally
2021-12-08 10:10:45,771 [Executor task launch worker for task 163] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_59_11 locally
2021-12-08 10:10:45,771 [Executor task launch worker for task 162] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_27_10 locally
2021-12-08 10:10:45,771 [Executor task launch worker for task 162] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_59_10 locally
2021-12-08 10:10:45,773 [Executor task launch worker for task 159] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_27_7 locally
2021-12-08 10:10:45,773 [Executor task launch worker for task 159] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_59_7 locally
2021-12-08 10:10:45,774 [Executor task launch worker for task 157] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_27_5 locally
2021-12-08 10:10:45,770 [Executor task launch worker for task 155] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_59_3 locally
2021-12-08 10:10:45,774 [Executor task launch worker for task 157] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_59_5 locally
2021-12-08 10:10:45,775 [Executor task launch worker for task 152] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_59_0 locally
2021-12-08 10:10:46,541 [Executor task launch worker for task 156] INFO [org.apache.spark.executor.Executor] - Finished task 4.0 in stage 39.0 (TID 156). 999 bytes result sent to driver
2021-12-08 10:10:46,542 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 4.0 in stage 39.0 (TID 156) in 775 ms on localhost (executor driver) (1/12)
2021-12-08 10:10:46,548 [Executor task launch worker for task 160] INFO [org.apache.spark.executor.Executor] - Finished task 8.0 in stage 39.0 (TID 160). 999 bytes result sent to driver
2021-12-08 10:10:46,549 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 8.0 in stage 39.0 (TID 160) in 781 ms on localhost (executor driver) (2/12)
2021-12-08 10:10:46,562 [Executor task launch worker for task 162] INFO [org.apache.spark.executor.Executor] - Finished task 10.0 in stage 39.0 (TID 162). 999 bytes result sent to driver
2021-12-08 10:10:46,563 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 10.0 in stage 39.0 (TID 162) in 795 ms on localhost (executor driver) (3/12)
2021-12-08 10:10:46,566 [Executor task launch worker for task 157] INFO [org.apache.spark.executor.Executor] - Finished task 5.0 in stage 39.0 (TID 157). 999 bytes result sent to driver
2021-12-08 10:10:46,566 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 5.0 in stage 39.0 (TID 157) in 799 ms on localhost (executor driver) (4/12)
2021-12-08 10:10:46,566 [Executor task launch worker for task 153] INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 39.0 (TID 153). 999 bytes result sent to driver
2021-12-08 10:10:46,567 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 39.0 (TID 153) in 800 ms on localhost (executor driver) (5/12)
2021-12-08 10:10:46,571 [Executor task launch worker for task 163] INFO [org.apache.spark.executor.Executor] - Finished task 11.0 in stage 39.0 (TID 163). 999 bytes result sent to driver
2021-12-08 10:10:46,571 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 11.0 in stage 39.0 (TID 163) in 803 ms on localhost (executor driver) (6/12)
2021-12-08 10:10:46,581 [Executor task launch worker for task 155] INFO [org.apache.spark.executor.Executor] - Finished task 3.0 in stage 39.0 (TID 155). 999 bytes result sent to driver
2021-12-08 10:10:46,581 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 3.0 in stage 39.0 (TID 155) in 814 ms on localhost (executor driver) (7/12)
2021-12-08 10:10:46,585 [Executor task launch worker for task 161] INFO [org.apache.spark.executor.Executor] - Finished task 9.0 in stage 39.0 (TID 161). 999 bytes result sent to driver
2021-12-08 10:10:46,585 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 9.0 in stage 39.0 (TID 161) in 817 ms on localhost (executor driver) (8/12)
2021-12-08 10:10:46,597 [Executor task launch worker for task 154] INFO [org.apache.spark.executor.Executor] - Finished task 2.0 in stage 39.0 (TID 154). 999 bytes result sent to driver
2021-12-08 10:10:46,597 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 2.0 in stage 39.0 (TID 154) in 830 ms on localhost (executor driver) (9/12)
2021-12-08 10:10:46,687 [Executor task launch worker for task 158] INFO [org.apache.spark.executor.Executor] - Finished task 6.0 in stage 39.0 (TID 158). 999 bytes result sent to driver
2021-12-08 10:10:46,687 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 6.0 in stage 39.0 (TID 158) in 919 ms on localhost (executor driver) (10/12)
2021-12-08 10:10:46,702 [Executor task launch worker for task 159] INFO [org.apache.spark.executor.Executor] - Finished task 7.0 in stage 39.0 (TID 159). 999 bytes result sent to driver
2021-12-08 10:10:46,702 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 7.0 in stage 39.0 (TID 159) in 934 ms on localhost (executor driver) (11/12)
2021-12-08 10:10:46,716 [Executor task launch worker for task 152] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 39.0 (TID 152). 999 bytes result sent to driver
2021-12-08 10:10:46,716 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 39.0 (TID 152) in 949 ms on localhost (executor driver) (12/12)
2021-12-08 10:10:46,716 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 39.0, whose tasks have all completed, from pool 
2021-12-08 10:10:46,716 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ShuffleMapStage 39 (flatMap at ALS.scala:1653) finished in 0.953 s
2021-12-08 10:10:46,716 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - looking for newly runnable stages
2021-12-08 10:10:46,716 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - running: Set()
2021-12-08 10:10:46,716 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - waiting: Set(ResultStage 40)
2021-12-08 10:10:46,716 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - failed: Set()
2021-12-08 10:10:46,717 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 40 (MapPartitionsRDD[70] at values at ALS.scala:1711), which has no missing parents
2021-12-08 10:10:46,719 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_21 stored as values in memory (estimated size 815.7 KB, free 1750.4 MB)
2021-12-08 10:10:46,720 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_21_piece0 stored as bytes in memory (estimated size 637.1 KB, free 1749.8 MB)
2021-12-08 10:10:46,721 [dispatcher-event-loop-3] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_21_piece0 in memory on qb:61292 (size: 637.1 KB, free: 1753.2 MB)
2021-12-08 10:10:46,721 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 21 from broadcast at DAGScheduler.scala:1039
2021-12-08 10:10:46,721 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 12 missing tasks from ResultStage 40 (MapPartitionsRDD[70] at values at ALS.scala:1711) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11))
2021-12-08 10:10:46,721 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 40.0 with 12 tasks
2021-12-08 10:10:46,721 [dispatcher-event-loop-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 40.0 (TID 164, localhost, executor driver, partition 0, PROCESS_LOCAL, 7888 bytes)
2021-12-08 10:10:46,722 [dispatcher-event-loop-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 40.0 (TID 165, localhost, executor driver, partition 1, PROCESS_LOCAL, 7888 bytes)
2021-12-08 10:10:46,722 [dispatcher-event-loop-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 2.0 in stage 40.0 (TID 166, localhost, executor driver, partition 2, PROCESS_LOCAL, 7888 bytes)
2021-12-08 10:10:46,722 [dispatcher-event-loop-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 3.0 in stage 40.0 (TID 167, localhost, executor driver, partition 3, PROCESS_LOCAL, 7888 bytes)
2021-12-08 10:10:46,722 [dispatcher-event-loop-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 4.0 in stage 40.0 (TID 168, localhost, executor driver, partition 4, PROCESS_LOCAL, 7888 bytes)
2021-12-08 10:10:46,722 [dispatcher-event-loop-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 5.0 in stage 40.0 (TID 169, localhost, executor driver, partition 5, PROCESS_LOCAL, 7888 bytes)
2021-12-08 10:10:46,722 [dispatcher-event-loop-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 6.0 in stage 40.0 (TID 170, localhost, executor driver, partition 6, PROCESS_LOCAL, 7888 bytes)
2021-12-08 10:10:46,722 [dispatcher-event-loop-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 7.0 in stage 40.0 (TID 171, localhost, executor driver, partition 7, PROCESS_LOCAL, 7888 bytes)
2021-12-08 10:10:46,722 [dispatcher-event-loop-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 8.0 in stage 40.0 (TID 172, localhost, executor driver, partition 8, PROCESS_LOCAL, 7888 bytes)
2021-12-08 10:10:46,722 [dispatcher-event-loop-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 9.0 in stage 40.0 (TID 173, localhost, executor driver, partition 9, PROCESS_LOCAL, 7888 bytes)
2021-12-08 10:10:46,722 [dispatcher-event-loop-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 10.0 in stage 40.0 (TID 174, localhost, executor driver, partition 10, PROCESS_LOCAL, 7888 bytes)
2021-12-08 10:10:46,722 [dispatcher-event-loop-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 11.0 in stage 40.0 (TID 175, localhost, executor driver, partition 11, PROCESS_LOCAL, 7888 bytes)
2021-12-08 10:10:46,722 [Executor task launch worker for task 164] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 40.0 (TID 164)
2021-12-08 10:10:46,722 [Executor task launch worker for task 171] INFO [org.apache.spark.executor.Executor] - Running task 7.0 in stage 40.0 (TID 171)
2021-12-08 10:10:46,722 [Executor task launch worker for task 165] INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 40.0 (TID 165)
2021-12-08 10:10:46,722 [Executor task launch worker for task 173] INFO [org.apache.spark.executor.Executor] - Running task 9.0 in stage 40.0 (TID 173)
2021-12-08 10:10:46,722 [Executor task launch worker for task 175] INFO [org.apache.spark.executor.Executor] - Running task 11.0 in stage 40.0 (TID 175)
2021-12-08 10:10:46,722 [Executor task launch worker for task 174] INFO [org.apache.spark.executor.Executor] - Running task 10.0 in stage 40.0 (TID 174)
2021-12-08 10:10:46,722 [Executor task launch worker for task 172] INFO [org.apache.spark.executor.Executor] - Running task 8.0 in stage 40.0 (TID 172)
2021-12-08 10:10:46,722 [Executor task launch worker for task 170] INFO [org.apache.spark.executor.Executor] - Running task 6.0 in stage 40.0 (TID 170)
2021-12-08 10:10:46,722 [Executor task launch worker for task 168] INFO [org.apache.spark.executor.Executor] - Running task 4.0 in stage 40.0 (TID 168)
2021-12-08 10:10:46,722 [Executor task launch worker for task 169] INFO [org.apache.spark.executor.Executor] - Running task 5.0 in stage 40.0 (TID 169)
2021-12-08 10:10:46,722 [Executor task launch worker for task 167] INFO [org.apache.spark.executor.Executor] - Running task 3.0 in stage 40.0 (TID 167)
2021-12-08 10:10:46,722 [Executor task launch worker for task 166] INFO [org.apache.spark.executor.Executor] - Running task 2.0 in stage 40.0 (TID 166)
2021-12-08 10:10:46,725 [Executor task launch worker for task 164] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_21_0 locally
2021-12-08 10:10:46,725 [Executor task launch worker for task 175] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_21_11 locally
2021-12-08 10:10:46,725 [Executor task launch worker for task 165] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_21_1 locally
2021-12-08 10:10:46,725 [Executor task launch worker for task 169] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_21_5 locally
2021-12-08 10:10:46,726 [Executor task launch worker for task 172] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_21_8 locally
2021-12-08 10:10:46,726 [Executor task launch worker for task 169] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 12 non-empty blocks out of 12 blocks
2021-12-08 10:10:46,726 [Executor task launch worker for task 173] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_21_9 locally
2021-12-08 10:10:46,726 [Executor task launch worker for task 170] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_21_6 locally
2021-12-08 10:10:46,726 [Executor task launch worker for task 169] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-08 10:10:46,726 [Executor task launch worker for task 164] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 12 non-empty blocks out of 12 blocks
2021-12-08 10:10:46,726 [Executor task launch worker for task 165] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 12 non-empty blocks out of 12 blocks
2021-12-08 10:10:46,726 [Executor task launch worker for task 175] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 12 non-empty blocks out of 12 blocks
2021-12-08 10:10:46,726 [Executor task launch worker for task 165] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-08 10:10:46,726 [Executor task launch worker for task 164] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-08 10:10:46,726 [Executor task launch worker for task 172] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 12 non-empty blocks out of 12 blocks
2021-12-08 10:10:46,726 [Executor task launch worker for task 167] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_21_3 locally
2021-12-08 10:10:46,726 [Executor task launch worker for task 170] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 12 non-empty blocks out of 12 blocks
2021-12-08 10:10:46,726 [Executor task launch worker for task 172] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-08 10:10:46,726 [Executor task launch worker for task 175] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-08 10:10:46,726 [Executor task launch worker for task 174] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_21_10 locally
2021-12-08 10:10:46,726 [Executor task launch worker for task 173] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 12 non-empty blocks out of 12 blocks
2021-12-08 10:10:46,726 [Executor task launch worker for task 170] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-08 10:10:46,726 [Executor task launch worker for task 173] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-08 10:10:46,726 [Executor task launch worker for task 167] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 12 non-empty blocks out of 12 blocks
2021-12-08 10:10:46,726 [Executor task launch worker for task 167] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-08 10:10:46,726 [Executor task launch worker for task 174] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 12 non-empty blocks out of 12 blocks
2021-12-08 10:10:46,726 [Executor task launch worker for task 174] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-08 10:10:46,726 [Executor task launch worker for task 166] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_21_2 locally
2021-12-08 10:10:46,726 [Executor task launch worker for task 168] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_21_4 locally
2021-12-08 10:10:46,727 [Executor task launch worker for task 171] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_21_7 locally
2021-12-08 10:10:46,727 [Executor task launch worker for task 168] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 12 non-empty blocks out of 12 blocks
2021-12-08 10:10:46,727 [Executor task launch worker for task 168] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-08 10:10:46,727 [Executor task launch worker for task 171] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 12 non-empty blocks out of 12 blocks
2021-12-08 10:10:46,727 [Executor task launch worker for task 166] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 12 non-empty blocks out of 12 blocks
2021-12-08 10:10:46,727 [Executor task launch worker for task 166] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-08 10:10:46,727 [Executor task launch worker for task 171] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-08 10:10:46,985 [dispatcher-event-loop-4] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_20_piece0 on qb:61292 in memory (size: 478.4 KB, free: 1753.7 MB)
2021-12-08 10:10:47,242 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 355
2021-12-08 10:10:47,243 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 327
2021-12-08 10:10:47,243 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 352
2021-12-08 10:10:47,243 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 337
2021-12-08 10:10:47,243 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 347
2021-12-08 10:10:47,243 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 340
2021-12-08 10:10:47,243 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 343
2021-12-08 10:10:47,243 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 369
2021-12-08 10:10:47,243 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 360
2021-12-08 10:10:47,243 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 363
2021-12-08 10:10:47,243 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 335
2021-12-08 10:10:47,243 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 371
2021-12-08 10:10:47,243 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 328
2021-12-08 10:10:47,243 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 344
2021-12-08 10:10:47,243 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 342
2021-12-08 10:10:47,243 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 331
2021-12-08 10:10:47,243 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 365
2021-12-08 10:10:47,243 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 353
2021-12-08 10:10:47,243 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 372
2021-12-08 10:10:47,243 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 341
2021-12-08 10:10:47,243 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 349
2021-12-08 10:10:47,243 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 356
2021-12-08 10:10:47,243 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 366
2021-12-08 10:10:47,243 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 358
2021-12-08 10:10:47,243 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 329
2021-12-08 10:10:47,247 [dispatcher-event-loop-11] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_19_piece0 on qb:61292 in memory (size: 479.4 KB, free: 1754.2 MB)
2021-12-08 10:10:47,275 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 339
2021-12-08 10:10:47,275 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 334
2021-12-08 10:10:47,275 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 325
2021-12-08 10:10:47,275 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 357
2021-12-08 10:10:47,275 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 345
2021-12-08 10:10:47,275 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 338
2021-12-08 10:10:47,275 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 350
2021-12-08 10:10:47,275 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 336
2021-12-08 10:10:47,275 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 367
2021-12-08 10:10:47,275 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 326
2021-12-08 10:10:47,275 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 373
2021-12-08 10:10:47,275 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 346
2021-12-08 10:10:47,275 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 351
2021-12-08 10:10:47,275 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 359
2021-12-08 10:10:47,275 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 374
2021-12-08 10:10:47,275 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 364
2021-12-08 10:10:47,275 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 361
2021-12-08 10:10:47,275 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 348
2021-12-08 10:10:47,275 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 362
2021-12-08 10:10:47,275 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 330
2021-12-08 10:10:47,275 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 333
2021-12-08 10:10:47,275 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 332
2021-12-08 10:10:47,275 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 370
2021-12-08 10:10:47,275 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 368
2021-12-08 10:10:47,275 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 354
2021-12-08 10:11:23,840 [Executor task launch worker for task 175] INFO [org.apache.spark.storage.memory.MemoryStore] - Block rdd_69_11 stored as values in memory (estimated size 11.1 MB, free 1740.7 MB)
2021-12-08 10:11:23,841 [dispatcher-event-loop-7] INFO [org.apache.spark.storage.BlockManagerInfo] - Added rdd_69_11 in memory on qb:61292 (size: 11.1 MB, free: 1743.0 MB)
2021-12-08 10:11:23,883 [Executor task launch worker for task 173] INFO [org.apache.spark.storage.memory.MemoryStore] - Block rdd_69_9 stored as values in memory (estimated size 11.1 MB, free 1729.6 MB)
2021-12-08 10:11:23,883 [dispatcher-event-loop-4] INFO [org.apache.spark.storage.BlockManagerInfo] - Added rdd_69_9 in memory on qb:61292 (size: 11.1 MB, free: 1731.9 MB)
2021-12-08 10:11:24,039 [Executor task launch worker for task 168] INFO [org.apache.spark.storage.memory.MemoryStore] - Block rdd_69_4 stored as values in memory (estimated size 11.1 MB, free 1718.5 MB)
2021-12-08 10:11:24,040 [dispatcher-event-loop-8] INFO [org.apache.spark.storage.BlockManagerInfo] - Added rdd_69_4 in memory on qb:61292 (size: 11.1 MB, free: 1720.8 MB)
2021-12-08 10:11:24,180 [Executor task launch worker for task 175] INFO [org.apache.spark.executor.Executor] - Finished task 11.0 in stage 40.0 (TID 175). 166054 bytes result sent to driver
2021-12-08 10:11:24,181 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 11.0 in stage 40.0 (TID 175) in 37459 ms on localhost (executor driver) (1/12)
2021-12-08 10:11:24,220 [Executor task launch worker for task 173] INFO [org.apache.spark.executor.Executor] - Finished task 9.0 in stage 40.0 (TID 173). 166097 bytes result sent to driver
2021-12-08 10:11:24,226 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 9.0 in stage 40.0 (TID 173) in 37504 ms on localhost (executor driver) (2/12)
2021-12-08 10:11:24,366 [Executor task launch worker for task 168] INFO [org.apache.spark.executor.Executor] - Finished task 4.0 in stage 40.0 (TID 168). 166054 bytes result sent to driver
2021-12-08 10:11:24,367 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 4.0 in stage 40.0 (TID 168) in 37645 ms on localhost (executor driver) (3/12)
2021-12-08 10:11:24,413 [Executor task launch worker for task 171] INFO [org.apache.spark.storage.memory.MemoryStore] - Block rdd_69_7 stored as values in memory (estimated size 11.1 MB, free 1707.4 MB)
2021-12-08 10:11:24,414 [dispatcher-event-loop-9] INFO [org.apache.spark.storage.BlockManagerInfo] - Added rdd_69_7 in memory on qb:61292 (size: 11.1 MB, free: 1709.7 MB)
2021-12-08 10:11:24,540 [Executor task launch worker for task 165] INFO [org.apache.spark.storage.memory.MemoryStore] - Block rdd_69_1 stored as values in memory (estimated size 11.1 MB, free 1696.3 MB)
2021-12-08 10:11:24,540 [dispatcher-event-loop-0] INFO [org.apache.spark.storage.BlockManagerInfo] - Added rdd_69_1 in memory on qb:61292 (size: 11.1 MB, free: 1698.6 MB)
2021-12-08 10:11:24,698 [Executor task launch worker for task 171] INFO [org.apache.spark.executor.Executor] - Finished task 7.0 in stage 40.0 (TID 171). 166097 bytes result sent to driver
2021-12-08 10:11:24,699 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 7.0 in stage 40.0 (TID 171) in 37977 ms on localhost (executor driver) (4/12)
2021-12-08 10:11:24,739 [Executor task launch worker for task 166] INFO [org.apache.spark.storage.memory.MemoryStore] - Block rdd_69_2 stored as values in memory (estimated size 11.1 MB, free 1685.2 MB)
2021-12-08 10:11:24,739 [dispatcher-event-loop-2] INFO [org.apache.spark.storage.BlockManagerInfo] - Added rdd_69_2 in memory on qb:61292 (size: 11.1 MB, free: 1687.5 MB)
2021-12-08 10:11:24,799 [Executor task launch worker for task 165] INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 40.0 (TID 165). 166054 bytes result sent to driver
2021-12-08 10:11:24,800 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 40.0 (TID 165) in 38078 ms on localhost (executor driver) (5/12)
2021-12-08 10:11:24,834 [Executor task launch worker for task 169] INFO [org.apache.spark.storage.memory.MemoryStore] - Block rdd_69_5 stored as values in memory (estimated size 11.1 MB, free 1674.1 MB)
2021-12-08 10:11:24,835 [dispatcher-event-loop-6] INFO [org.apache.spark.storage.BlockManagerInfo] - Added rdd_69_5 in memory on qb:61292 (size: 11.1 MB, free: 1676.4 MB)
2021-12-08 10:11:24,990 [Executor task launch worker for task 166] INFO [org.apache.spark.executor.Executor] - Finished task 2.0 in stage 40.0 (TID 166). 166054 bytes result sent to driver
2021-12-08 10:11:24,990 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 2.0 in stage 40.0 (TID 166) in 38268 ms on localhost (executor driver) (6/12)
2021-12-08 10:11:25,066 [Executor task launch worker for task 170] INFO [org.apache.spark.storage.memory.MemoryStore] - Block rdd_69_6 stored as values in memory (estimated size 11.1 MB, free 1663.0 MB)
2021-12-08 10:11:25,066 [dispatcher-event-loop-4] INFO [org.apache.spark.storage.BlockManagerInfo] - Added rdd_69_6 in memory on qb:61292 (size: 11.1 MB, free: 1665.3 MB)
2021-12-08 10:11:25,090 [Executor task launch worker for task 169] INFO [org.apache.spark.executor.Executor] - Finished task 5.0 in stage 40.0 (TID 169). 166054 bytes result sent to driver
2021-12-08 10:11:25,091 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 5.0 in stage 40.0 (TID 169) in 38369 ms on localhost (executor driver) (7/12)
2021-12-08 10:11:25,106 [Executor task launch worker for task 172] INFO [org.apache.spark.storage.memory.MemoryStore] - Block rdd_69_8 stored as values in memory (estimated size 11.1 MB, free 1651.9 MB)
2021-12-08 10:11:25,106 [dispatcher-event-loop-10] INFO [org.apache.spark.storage.BlockManagerInfo] - Added rdd_69_8 in memory on qb:61292 (size: 11.1 MB, free: 1654.2 MB)
2021-12-08 10:11:25,290 [Executor task launch worker for task 172] INFO [org.apache.spark.executor.Executor] - Finished task 8.0 in stage 40.0 (TID 172). 166054 bytes result sent to driver
2021-12-08 10:11:25,291 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 8.0 in stage 40.0 (TID 172) in 38569 ms on localhost (executor driver) (8/12)
2021-12-08 10:11:25,304 [Executor task launch worker for task 170] INFO [org.apache.spark.executor.Executor] - Finished task 6.0 in stage 40.0 (TID 170). 166054 bytes result sent to driver
2021-12-08 10:11:25,305 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 6.0 in stage 40.0 (TID 170) in 38583 ms on localhost (executor driver) (9/12)
2021-12-08 10:11:25,377 [Executor task launch worker for task 164] INFO [org.apache.spark.storage.memory.MemoryStore] - Block rdd_69_0 stored as values in memory (estimated size 11.1 MB, free 1640.8 MB)
2021-12-08 10:11:25,377 [dispatcher-event-loop-3] INFO [org.apache.spark.storage.BlockManagerInfo] - Added rdd_69_0 in memory on qb:61292 (size: 11.1 MB, free: 1643.1 MB)
2021-12-08 10:11:25,407 [Executor task launch worker for task 174] INFO [org.apache.spark.storage.memory.MemoryStore] - Block rdd_69_10 stored as values in memory (estimated size 11.1 MB, free 1629.7 MB)
2021-12-08 10:11:25,408 [dispatcher-event-loop-2] INFO [org.apache.spark.storage.BlockManagerInfo] - Added rdd_69_10 in memory on qb:61292 (size: 11.1 MB, free: 1632.0 MB)
2021-12-08 10:11:25,425 [Executor task launch worker for task 167] INFO [org.apache.spark.storage.memory.MemoryStore] - Block rdd_69_3 stored as values in memory (estimated size 11.1 MB, free 1618.6 MB)
2021-12-08 10:11:25,425 [dispatcher-event-loop-1] INFO [org.apache.spark.storage.BlockManagerInfo] - Added rdd_69_3 in memory on qb:61292 (size: 11.1 MB, free: 1620.9 MB)
2021-12-08 10:11:25,564 [Executor task launch worker for task 164] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 40.0 (TID 164). 166054 bytes result sent to driver
2021-12-08 10:11:25,564 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 40.0 (TID 164) in 38843 ms on localhost (executor driver) (10/12)
2021-12-08 10:11:25,588 [Executor task launch worker for task 174] INFO [org.apache.spark.executor.Executor] - Finished task 10.0 in stage 40.0 (TID 174). 166054 bytes result sent to driver
2021-12-08 10:11:25,588 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 10.0 in stage 40.0 (TID 174) in 38866 ms on localhost (executor driver) (11/12)
2021-12-08 10:11:25,610 [Executor task launch worker for task 167] INFO [org.apache.spark.executor.Executor] - Finished task 3.0 in stage 40.0 (TID 167). 166054 bytes result sent to driver
2021-12-08 10:11:25,610 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 3.0 in stage 40.0 (TID 167) in 38888 ms on localhost (executor driver) (12/12)
2021-12-08 10:11:25,610 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 40.0, whose tasks have all completed, from pool 
2021-12-08 10:11:25,610 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 40 (aggregate at ALS.scala:1711) finished in 38.893 s
2021-12-08 10:11:25,611 [main] INFO [org.apache.spark.scheduler.DAGScheduler] - Job 8 finished: aggregate at ALS.scala:1711, took 39.849976 s
2021-12-08 10:11:25,626 [main] INFO [org.apache.spark.rdd.MapPartitionsRDD] - Removing RDD 59 from persistence list
2021-12-08 10:11:25,626 [block-manager-slave-async-thread-pool-0] INFO [org.apache.spark.storage.BlockManager] - Removing RDD 59
2021-12-08 10:11:25,632 [main] INFO [org.apache.spark.SparkContext] - Starting job: aggregate at ALS.scala:1711
2021-12-08 10:11:25,633 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 74 (flatMap at ALS.scala:1653)
2021-12-08 10:11:25,634 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 9 (aggregate at ALS.scala:1711) with 12 output partitions
2021-12-08 10:11:25,634 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 50 (aggregate at ALS.scala:1711)
2021-12-08 10:11:25,634 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 45, ShuffleMapStage 49)
2021-12-08 10:11:25,634 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List(ShuffleMapStage 49)
2021-12-08 10:11:25,634 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ShuffleMapStage 49 (MapPartitionsRDD[74] at flatMap at ALS.scala:1653), which has no missing parents
2021-12-08 10:11:25,636 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_22 stored as values in memory (estimated size 655.3 KB, free 1665.8 MB)
2021-12-08 10:11:25,638 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_22_piece0 stored as bytes in memory (estimated size 636.1 KB, free 1665.2 MB)
2021-12-08 10:11:25,638 [dispatcher-event-loop-3] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_22_piece0 in memory on qb:61292 (size: 636.1 KB, free: 1668.1 MB)
2021-12-08 10:11:25,639 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 22 from broadcast at DAGScheduler.scala:1039
2021-12-08 10:11:25,639 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 12 missing tasks from ShuffleMapStage 49 (MapPartitionsRDD[74] at flatMap at ALS.scala:1653) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11))
2021-12-08 10:11:25,639 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 49.0 with 12 tasks
2021-12-08 10:11:25,639 [dispatcher-event-loop-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 49.0 (TID 176, localhost, executor driver, partition 0, PROCESS_LOCAL, 7928 bytes)
2021-12-08 10:11:25,639 [dispatcher-event-loop-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 49.0 (TID 177, localhost, executor driver, partition 1, PROCESS_LOCAL, 7928 bytes)
2021-12-08 10:11:25,639 [dispatcher-event-loop-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 2.0 in stage 49.0 (TID 178, localhost, executor driver, partition 2, PROCESS_LOCAL, 7928 bytes)
2021-12-08 10:11:25,639 [dispatcher-event-loop-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 3.0 in stage 49.0 (TID 179, localhost, executor driver, partition 3, PROCESS_LOCAL, 7928 bytes)
2021-12-08 10:11:25,640 [dispatcher-event-loop-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 4.0 in stage 49.0 (TID 180, localhost, executor driver, partition 4, PROCESS_LOCAL, 7928 bytes)
2021-12-08 10:11:25,640 [dispatcher-event-loop-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 5.0 in stage 49.0 (TID 181, localhost, executor driver, partition 5, PROCESS_LOCAL, 7928 bytes)
2021-12-08 10:11:25,640 [dispatcher-event-loop-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 6.0 in stage 49.0 (TID 182, localhost, executor driver, partition 6, PROCESS_LOCAL, 7928 bytes)
2021-12-08 10:11:25,640 [dispatcher-event-loop-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 7.0 in stage 49.0 (TID 183, localhost, executor driver, partition 7, PROCESS_LOCAL, 7928 bytes)
2021-12-08 10:11:25,640 [dispatcher-event-loop-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 8.0 in stage 49.0 (TID 184, localhost, executor driver, partition 8, PROCESS_LOCAL, 7928 bytes)
2021-12-08 10:11:25,640 [dispatcher-event-loop-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 9.0 in stage 49.0 (TID 185, localhost, executor driver, partition 9, PROCESS_LOCAL, 7928 bytes)
2021-12-08 10:11:25,640 [dispatcher-event-loop-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 10.0 in stage 49.0 (TID 186, localhost, executor driver, partition 10, PROCESS_LOCAL, 7928 bytes)
2021-12-08 10:11:25,640 [dispatcher-event-loop-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 11.0 in stage 49.0 (TID 187, localhost, executor driver, partition 11, PROCESS_LOCAL, 7928 bytes)
2021-12-08 10:11:25,640 [Executor task launch worker for task 177] INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 49.0 (TID 177)
2021-12-08 10:11:25,640 [Executor task launch worker for task 182] INFO [org.apache.spark.executor.Executor] - Running task 6.0 in stage 49.0 (TID 182)
2021-12-08 10:11:25,640 [Executor task launch worker for task 185] INFO [org.apache.spark.executor.Executor] - Running task 9.0 in stage 49.0 (TID 185)
2021-12-08 10:11:25,640 [Executor task launch worker for task 186] INFO [org.apache.spark.executor.Executor] - Running task 10.0 in stage 49.0 (TID 186)
2021-12-08 10:11:25,640 [Executor task launch worker for task 187] INFO [org.apache.spark.executor.Executor] - Running task 11.0 in stage 49.0 (TID 187)
2021-12-08 10:11:25,640 [Executor task launch worker for task 178] INFO [org.apache.spark.executor.Executor] - Running task 2.0 in stage 49.0 (TID 178)
2021-12-08 10:11:25,640 [Executor task launch worker for task 180] INFO [org.apache.spark.executor.Executor] - Running task 4.0 in stage 49.0 (TID 180)
2021-12-08 10:11:25,640 [Executor task launch worker for task 183] INFO [org.apache.spark.executor.Executor] - Running task 7.0 in stage 49.0 (TID 183)
2021-12-08 10:11:25,640 [Executor task launch worker for task 176] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 49.0 (TID 176)
2021-12-08 10:11:25,640 [Executor task launch worker for task 179] INFO [org.apache.spark.executor.Executor] - Running task 3.0 in stage 49.0 (TID 179)
2021-12-08 10:11:25,640 [Executor task launch worker for task 181] INFO [org.apache.spark.executor.Executor] - Running task 5.0 in stage 49.0 (TID 181)
2021-12-08 10:11:25,640 [Executor task launch worker for task 184] INFO [org.apache.spark.executor.Executor] - Running task 8.0 in stage 49.0 (TID 184)
2021-12-08 10:11:25,642 [Executor task launch worker for task 178] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_22_2 locally
2021-12-08 10:11:25,642 [Executor task launch worker for task 182] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_22_6 locally
2021-12-08 10:11:25,642 [Executor task launch worker for task 184] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_22_8 locally
2021-12-08 10:11:25,642 [Executor task launch worker for task 185] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_22_9 locally
2021-12-08 10:11:25,642 [Executor task launch worker for task 181] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_22_5 locally
2021-12-08 10:11:25,642 [Executor task launch worker for task 186] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_22_10 locally
2021-12-08 10:11:25,642 [Executor task launch worker for task 176] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_22_0 locally
2021-12-08 10:11:25,642 [Executor task launch worker for task 179] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_22_3 locally
2021-12-08 10:11:25,642 [Executor task launch worker for task 177] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_22_1 locally
2021-12-08 10:11:25,642 [Executor task launch worker for task 187] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_22_11 locally
2021-12-08 10:11:25,642 [Executor task launch worker for task 177] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_69_1 locally
2021-12-08 10:11:25,642 [Executor task launch worker for task 179] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_69_3 locally
2021-12-08 10:11:25,642 [Executor task launch worker for task 185] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_69_9 locally
2021-12-08 10:11:25,642 [Executor task launch worker for task 184] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_69_8 locally
2021-12-08 10:11:25,642 [Executor task launch worker for task 181] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_69_5 locally
2021-12-08 10:11:25,642 [Executor task launch worker for task 186] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_69_10 locally
2021-12-08 10:11:25,642 [Executor task launch worker for task 187] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_69_11 locally
2021-12-08 10:11:25,642 [Executor task launch worker for task 176] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_69_0 locally
2021-12-08 10:11:25,642 [Executor task launch worker for task 180] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_22_4 locally
2021-12-08 10:11:25,642 [Executor task launch worker for task 182] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_69_6 locally
2021-12-08 10:11:25,643 [Executor task launch worker for task 183] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_22_7 locally
2021-12-08 10:11:25,643 [Executor task launch worker for task 183] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_69_7 locally
2021-12-08 10:11:25,643 [Executor task launch worker for task 178] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_69_2 locally
2021-12-08 10:11:25,643 [Executor task launch worker for task 180] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_69_4 locally
2021-12-08 10:11:27,770 [Executor task launch worker for task 182] INFO [org.apache.spark.executor.Executor] - Finished task 6.0 in stage 49.0 (TID 182). 999 bytes result sent to driver
2021-12-08 10:11:27,770 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 6.0 in stage 49.0 (TID 182) in 2130 ms on localhost (executor driver) (1/12)
2021-12-08 10:11:27,798 [Executor task launch worker for task 181] INFO [org.apache.spark.executor.Executor] - Finished task 5.0 in stage 49.0 (TID 181). 999 bytes result sent to driver
2021-12-08 10:11:27,799 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 5.0 in stage 49.0 (TID 181) in 2158 ms on localhost (executor driver) (2/12)
2021-12-08 10:11:27,847 [Executor task launch worker for task 183] INFO [org.apache.spark.executor.Executor] - Finished task 7.0 in stage 49.0 (TID 183). 999 bytes result sent to driver
2021-12-08 10:11:27,847 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 7.0 in stage 49.0 (TID 183) in 2207 ms on localhost (executor driver) (3/12)
2021-12-08 10:11:27,848 [Executor task launch worker for task 186] INFO [org.apache.spark.executor.Executor] - Finished task 10.0 in stage 49.0 (TID 186). 999 bytes result sent to driver
2021-12-08 10:11:27,848 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 10.0 in stage 49.0 (TID 186) in 2208 ms on localhost (executor driver) (4/12)
2021-12-08 10:11:27,950 [Executor task launch worker for task 179] INFO [org.apache.spark.executor.Executor] - Finished task 3.0 in stage 49.0 (TID 179). 999 bytes result sent to driver
2021-12-08 10:11:27,951 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 3.0 in stage 49.0 (TID 179) in 2312 ms on localhost (executor driver) (5/12)
2021-12-08 10:11:27,956 [Executor task launch worker for task 187] INFO [org.apache.spark.executor.Executor] - Finished task 11.0 in stage 49.0 (TID 187). 999 bytes result sent to driver
2021-12-08 10:11:27,956 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 11.0 in stage 49.0 (TID 187) in 2316 ms on localhost (executor driver) (6/12)
2021-12-08 10:11:27,956 [Executor task launch worker for task 176] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 49.0 (TID 176). 999 bytes result sent to driver
2021-12-08 10:11:27,956 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 49.0 (TID 176) in 2317 ms on localhost (executor driver) (7/12)
2021-12-08 10:11:27,957 [Executor task launch worker for task 177] INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 49.0 (TID 177). 999 bytes result sent to driver
2021-12-08 10:11:27,957 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 49.0 (TID 177) in 2318 ms on localhost (executor driver) (8/12)
2021-12-08 10:11:27,958 [Executor task launch worker for task 184] INFO [org.apache.spark.executor.Executor] - Finished task 8.0 in stage 49.0 (TID 184). 999 bytes result sent to driver
2021-12-08 10:11:27,958 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 8.0 in stage 49.0 (TID 184) in 2318 ms on localhost (executor driver) (9/12)
2021-12-08 10:11:27,959 [Executor task launch worker for task 185] INFO [org.apache.spark.executor.Executor] - Finished task 9.0 in stage 49.0 (TID 185). 999 bytes result sent to driver
2021-12-08 10:11:27,959 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 9.0 in stage 49.0 (TID 185) in 2319 ms on localhost (executor driver) (10/12)
2021-12-08 10:11:27,960 [Executor task launch worker for task 178] INFO [org.apache.spark.executor.Executor] - Finished task 2.0 in stage 49.0 (TID 178). 999 bytes result sent to driver
2021-12-08 10:11:27,960 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 2.0 in stage 49.0 (TID 178) in 2321 ms on localhost (executor driver) (11/12)
2021-12-08 10:11:27,969 [Executor task launch worker for task 180] INFO [org.apache.spark.executor.Executor] - Finished task 4.0 in stage 49.0 (TID 180). 999 bytes result sent to driver
2021-12-08 10:11:27,969 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 4.0 in stage 49.0 (TID 180) in 2330 ms on localhost (executor driver) (12/12)
2021-12-08 10:11:27,969 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 49.0, whose tasks have all completed, from pool 
2021-12-08 10:11:27,969 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ShuffleMapStage 49 (flatMap at ALS.scala:1653) finished in 2.334 s
2021-12-08 10:11:27,970 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - looking for newly runnable stages
2021-12-08 10:11:27,970 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - running: Set()
2021-12-08 10:11:27,970 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - waiting: Set(ResultStage 50)
2021-12-08 10:11:27,970 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - failed: Set()
2021-12-08 10:11:27,970 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 50 (MapPartitionsRDD[80] at values at ALS.scala:1711), which has no missing parents
2021-12-08 10:11:27,972 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_23 stored as values in memory (estimated size 976.9 KB, free 1664.2 MB)
2021-12-08 10:11:27,974 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_23_piece0 stored as bytes in memory (estimated size 794.8 KB, free 1663.4 MB)
2021-12-08 10:11:27,974 [dispatcher-event-loop-7] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_23_piece0 in memory on qb:61292 (size: 794.8 KB, free: 1667.4 MB)
2021-12-08 10:11:27,974 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 23 from broadcast at DAGScheduler.scala:1039
2021-12-08 10:11:27,975 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 12 missing tasks from ResultStage 50 (MapPartitionsRDD[80] at values at ALS.scala:1711) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11))
2021-12-08 10:11:27,975 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 50.0 with 12 tasks
2021-12-08 10:11:27,975 [dispatcher-event-loop-4] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 50.0 (TID 188, localhost, executor driver, partition 0, PROCESS_LOCAL, 7888 bytes)
2021-12-08 10:11:27,975 [dispatcher-event-loop-4] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 50.0 (TID 189, localhost, executor driver, partition 1, PROCESS_LOCAL, 7888 bytes)
2021-12-08 10:11:27,975 [dispatcher-event-loop-4] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 2.0 in stage 50.0 (TID 190, localhost, executor driver, partition 2, PROCESS_LOCAL, 7888 bytes)
2021-12-08 10:11:27,976 [dispatcher-event-loop-4] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 3.0 in stage 50.0 (TID 191, localhost, executor driver, partition 3, PROCESS_LOCAL, 7888 bytes)
2021-12-08 10:11:27,976 [dispatcher-event-loop-4] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 4.0 in stage 50.0 (TID 192, localhost, executor driver, partition 4, PROCESS_LOCAL, 7888 bytes)
2021-12-08 10:11:27,976 [dispatcher-event-loop-4] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 5.0 in stage 50.0 (TID 193, localhost, executor driver, partition 5, PROCESS_LOCAL, 7888 bytes)
2021-12-08 10:11:27,976 [dispatcher-event-loop-4] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 6.0 in stage 50.0 (TID 194, localhost, executor driver, partition 6, PROCESS_LOCAL, 7888 bytes)
2021-12-08 10:11:27,976 [dispatcher-event-loop-4] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 7.0 in stage 50.0 (TID 195, localhost, executor driver, partition 7, PROCESS_LOCAL, 7888 bytes)
2021-12-08 10:11:27,976 [dispatcher-event-loop-4] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 8.0 in stage 50.0 (TID 196, localhost, executor driver, partition 8, PROCESS_LOCAL, 7888 bytes)
2021-12-08 10:11:27,976 [dispatcher-event-loop-4] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 9.0 in stage 50.0 (TID 197, localhost, executor driver, partition 9, PROCESS_LOCAL, 7888 bytes)
2021-12-08 10:11:27,976 [dispatcher-event-loop-4] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 10.0 in stage 50.0 (TID 198, localhost, executor driver, partition 10, PROCESS_LOCAL, 7888 bytes)
2021-12-08 10:11:27,976 [dispatcher-event-loop-4] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 11.0 in stage 50.0 (TID 199, localhost, executor driver, partition 11, PROCESS_LOCAL, 7888 bytes)
2021-12-08 10:11:27,976 [Executor task launch worker for task 189] INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 50.0 (TID 189)
2021-12-08 10:11:27,976 [Executor task launch worker for task 194] INFO [org.apache.spark.executor.Executor] - Running task 6.0 in stage 50.0 (TID 194)
2021-12-08 10:11:27,976 [Executor task launch worker for task 199] INFO [org.apache.spark.executor.Executor] - Running task 11.0 in stage 50.0 (TID 199)
2021-12-08 10:11:27,976 [Executor task launch worker for task 193] INFO [org.apache.spark.executor.Executor] - Running task 5.0 in stage 50.0 (TID 193)
2021-12-08 10:11:27,976 [Executor task launch worker for task 190] INFO [org.apache.spark.executor.Executor] - Running task 2.0 in stage 50.0 (TID 190)
2021-12-08 10:11:27,976 [Executor task launch worker for task 188] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 50.0 (TID 188)
2021-12-08 10:11:27,976 [Executor task launch worker for task 192] INFO [org.apache.spark.executor.Executor] - Running task 4.0 in stage 50.0 (TID 192)
2021-12-08 10:11:27,976 [Executor task launch worker for task 191] INFO [org.apache.spark.executor.Executor] - Running task 3.0 in stage 50.0 (TID 191)
2021-12-08 10:11:27,976 [Executor task launch worker for task 197] INFO [org.apache.spark.executor.Executor] - Running task 9.0 in stage 50.0 (TID 197)
2021-12-08 10:11:27,976 [Executor task launch worker for task 198] INFO [org.apache.spark.executor.Executor] - Running task 10.0 in stage 50.0 (TID 198)
2021-12-08 10:11:27,976 [Executor task launch worker for task 196] INFO [org.apache.spark.executor.Executor] - Running task 8.0 in stage 50.0 (TID 196)
2021-12-08 10:11:27,976 [Executor task launch worker for task 195] INFO [org.apache.spark.executor.Executor] - Running task 7.0 in stage 50.0 (TID 195)
2021-12-08 10:11:27,979 [Executor task launch worker for task 190] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_26_2 locally
2021-12-08 10:11:27,979 [Executor task launch worker for task 196] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_26_8 locally
2021-12-08 10:11:27,979 [Executor task launch worker for task 189] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_26_1 locally
2021-12-08 10:11:27,980 [Executor task launch worker for task 199] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_26_11 locally
2021-12-08 10:11:27,980 [Executor task launch worker for task 195] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_26_7 locally
2021-12-08 10:11:27,980 [Executor task launch worker for task 195] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 12 non-empty blocks out of 12 blocks
2021-12-08 10:11:27,980 [Executor task launch worker for task 195] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-08 10:11:27,980 [Executor task launch worker for task 189] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 12 non-empty blocks out of 12 blocks
2021-12-08 10:11:27,980 [Executor task launch worker for task 189] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-08 10:11:27,980 [Executor task launch worker for task 190] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 12 non-empty blocks out of 12 blocks
2021-12-08 10:11:27,980 [Executor task launch worker for task 190] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-08 10:11:27,980 [Executor task launch worker for task 196] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 12 non-empty blocks out of 12 blocks
2021-12-08 10:11:27,980 [Executor task launch worker for task 196] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-08 10:11:27,980 [Executor task launch worker for task 199] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 12 non-empty blocks out of 12 blocks
2021-12-08 10:11:27,981 [Executor task launch worker for task 199] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 1 ms
2021-12-08 10:11:27,980 [Executor task launch worker for task 198] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_26_10 locally
2021-12-08 10:11:27,981 [Executor task launch worker for task 194] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_26_6 locally
2021-12-08 10:11:27,981 [Executor task launch worker for task 198] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 12 non-empty blocks out of 12 blocks
2021-12-08 10:11:27,981 [Executor task launch worker for task 194] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 12 non-empty blocks out of 12 blocks
2021-12-08 10:11:27,981 [Executor task launch worker for task 194] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-08 10:11:27,981 [Executor task launch worker for task 198] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-08 10:11:27,981 [Executor task launch worker for task 188] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_26_0 locally
2021-12-08 10:11:27,981 [Executor task launch worker for task 188] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 12 non-empty blocks out of 12 blocks
2021-12-08 10:11:27,981 [Executor task launch worker for task 188] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-08 10:11:27,981 [Executor task launch worker for task 197] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_26_9 locally
2021-12-08 10:11:27,981 [Executor task launch worker for task 191] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_26_3 locally
2021-12-08 10:11:27,981 [Executor task launch worker for task 197] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 12 non-empty blocks out of 12 blocks
2021-12-08 10:11:27,981 [Executor task launch worker for task 197] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-08 10:11:27,981 [Executor task launch worker for task 191] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 12 non-empty blocks out of 12 blocks
2021-12-08 10:11:27,981 [Executor task launch worker for task 191] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-08 10:11:27,981 [Executor task launch worker for task 193] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_26_5 locally
2021-12-08 10:11:27,982 [Executor task launch worker for task 193] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 12 non-empty blocks out of 12 blocks
2021-12-08 10:11:27,982 [Executor task launch worker for task 193] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 1 ms
2021-12-08 10:11:27,982 [Executor task launch worker for task 192] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_26_4 locally
2021-12-08 10:11:27,982 [Executor task launch worker for task 192] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 12 non-empty blocks out of 12 blocks
2021-12-08 10:11:27,982 [Executor task launch worker for task 192] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-08 10:11:28,061 [dispatcher-event-loop-11] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_22_piece0 on qb:61292 in memory (size: 636.1 KB, free: 1668.0 MB)
2021-12-08 10:11:28,488 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 395
2021-12-08 10:11:28,488 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 397
2021-12-08 10:11:28,488 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 418
2021-12-08 10:11:28,488 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 412
2021-12-08 10:11:28,488 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 419
2021-12-08 10:11:28,488 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 386
2021-12-08 10:11:28,488 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 389
2021-12-08 10:11:28,488 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 403
2021-12-08 10:11:28,488 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 382
2021-12-08 10:11:28,488 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 415
2021-12-08 10:11:28,488 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 375
2021-12-08 10:11:28,488 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 402
2021-12-08 10:11:28,488 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 394
2021-12-08 10:11:28,488 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 385
2021-12-08 10:11:28,488 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 411
2021-12-08 10:11:28,488 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 376
2021-12-08 10:11:28,488 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 380
2021-12-08 10:11:28,488 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 414
2021-12-08 10:11:28,488 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 377
2021-12-08 10:11:28,489 [dispatcher-event-loop-3] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_21_piece0 on qb:61292 in memory (size: 637.1 KB, free: 1668.6 MB)
2021-12-08 10:11:28,490 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 407
2021-12-08 10:11:28,490 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 417
2021-12-08 10:11:28,490 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 400
2021-12-08 10:11:28,490 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 392
2021-12-08 10:11:28,490 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 423
2021-12-08 10:11:28,490 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 384
2021-12-08 10:11:28,490 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 422
2021-12-08 10:11:28,490 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 388
2021-12-08 10:11:28,490 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 421
2021-12-08 10:11:28,490 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 416
2021-12-08 10:11:28,490 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 398
2021-12-08 10:11:28,490 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 379
2021-12-08 10:11:28,490 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 408
2021-12-08 10:11:28,490 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 409
2021-12-08 10:11:28,490 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 393
2021-12-08 10:11:28,490 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 410
2021-12-08 10:11:28,490 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 390
2021-12-08 10:11:28,490 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 383
2021-12-08 10:11:28,490 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 378
2021-12-08 10:11:28,490 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 420
2021-12-08 10:11:28,490 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 404
2021-12-08 10:11:28,490 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 424
2021-12-08 10:11:28,490 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 401
2021-12-08 10:11:28,490 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 399
2021-12-08 10:11:28,491 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 406
2021-12-08 10:11:28,491 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 391
2021-12-08 10:11:28,491 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 413
2021-12-08 10:11:28,491 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 396
2021-12-08 10:11:28,491 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 381
2021-12-08 10:11:28,491 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 405
2021-12-08 10:11:28,491 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 387
2021-12-08 10:11:49,230 [Executor task launch worker for task 193] INFO [org.apache.spark.storage.memory.MemoryStore] - Block rdd_79_5 stored as values in memory (estimated size 4.0 MB, free 1662.1 MB)
2021-12-08 10:11:49,230 [dispatcher-event-loop-7] INFO [org.apache.spark.storage.BlockManagerInfo] - Added rdd_79_5 in memory on qb:61292 (size: 4.0 MB, free: 1664.6 MB)
2021-12-08 10:11:49,351 [Executor task launch worker for task 193] INFO [org.apache.spark.executor.Executor] - Finished task 5.0 in stage 50.0 (TID 193). 166054 bytes result sent to driver
2021-12-08 10:11:49,355 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 5.0 in stage 50.0 (TID 193) in 21379 ms on localhost (executor driver) (1/12)
2021-12-08 10:11:49,502 [Executor task launch worker for task 189] INFO [org.apache.spark.storage.memory.MemoryStore] - Block rdd_79_1 stored as values in memory (estimated size 4.0 MB, free 1658.1 MB)
2021-12-08 10:11:49,502 [dispatcher-event-loop-8] INFO [org.apache.spark.storage.BlockManagerInfo] - Added rdd_79_1 in memory on qb:61292 (size: 4.0 MB, free: 1660.6 MB)
2021-12-08 10:11:49,617 [Executor task launch worker for task 189] INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 50.0 (TID 189). 166054 bytes result sent to driver
2021-12-08 10:11:49,618 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 50.0 (TID 189) in 21643 ms on localhost (executor driver) (2/12)
2021-12-08 10:11:49,977 [Executor task launch worker for task 188] INFO [org.apache.spark.storage.memory.MemoryStore] - Block rdd_79_0 stored as values in memory (estimated size 4.0 MB, free 1654.2 MB)
2021-12-08 10:11:49,978 [dispatcher-event-loop-11] INFO [org.apache.spark.storage.BlockManagerInfo] - Added rdd_79_0 in memory on qb:61292 (size: 4.0 MB, free: 1656.6 MB)
2021-12-08 10:11:50,053 [Executor task launch worker for task 192] INFO [org.apache.spark.storage.memory.MemoryStore] - Block rdd_79_4 stored as values in memory (estimated size 4.0 MB, free 1650.2 MB)
2021-12-08 10:11:50,053 [dispatcher-event-loop-0] INFO [org.apache.spark.storage.BlockManagerInfo] - Added rdd_79_4 in memory on qb:61292 (size: 4.0 MB, free: 1652.6 MB)
2021-12-08 10:11:50,090 [Executor task launch worker for task 188] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 50.0 (TID 188). 166097 bytes result sent to driver
2021-12-08 10:11:50,090 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 50.0 (TID 188) in 22115 ms on localhost (executor driver) (3/12)
2021-12-08 10:11:50,098 [Executor task launch worker for task 199] INFO [org.apache.spark.storage.memory.MemoryStore] - Block rdd_79_11 stored as values in memory (estimated size 4.0 MB, free 1646.2 MB)
2021-12-08 10:11:50,099 [dispatcher-event-loop-3] INFO [org.apache.spark.storage.BlockManagerInfo] - Added rdd_79_11 in memory on qb:61292 (size: 4.0 MB, free: 1648.7 MB)
2021-12-08 10:11:50,146 [Executor task launch worker for task 192] INFO [org.apache.spark.executor.Executor] - Finished task 4.0 in stage 50.0 (TID 192). 166097 bytes result sent to driver
2021-12-08 10:11:50,147 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 4.0 in stage 50.0 (TID 192) in 22171 ms on localhost (executor driver) (4/12)
2021-12-08 10:11:50,202 [Executor task launch worker for task 199] INFO [org.apache.spark.executor.Executor] - Finished task 11.0 in stage 50.0 (TID 199). 166054 bytes result sent to driver
2021-12-08 10:11:50,203 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 11.0 in stage 50.0 (TID 199) in 22227 ms on localhost (executor driver) (5/12)
2021-12-08 10:11:50,518 [Executor task launch worker for task 198] INFO [org.apache.spark.storage.memory.MemoryStore] - Block rdd_79_10 stored as values in memory (estimated size 4.0 MB, free 1642.2 MB)
2021-12-08 10:11:50,518 [dispatcher-event-loop-6] INFO [org.apache.spark.storage.BlockManagerInfo] - Added rdd_79_10 in memory on qb:61292 (size: 4.0 MB, free: 1644.7 MB)
2021-12-08 10:11:50,577 [Executor task launch worker for task 196] INFO [org.apache.spark.storage.memory.MemoryStore] - Block rdd_79_8 stored as values in memory (estimated size 4.0 MB, free 1638.2 MB)
2021-12-08 10:11:50,578 [dispatcher-event-loop-1] INFO [org.apache.spark.storage.BlockManagerInfo] - Added rdd_79_8 in memory on qb:61292 (size: 4.0 MB, free: 1640.7 MB)
2021-12-08 10:11:50,596 [Executor task launch worker for task 198] INFO [org.apache.spark.executor.Executor] - Finished task 10.0 in stage 50.0 (TID 198). 166054 bytes result sent to driver
2021-12-08 10:11:50,597 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 10.0 in stage 50.0 (TID 198) in 22621 ms on localhost (executor driver) (6/12)
2021-12-08 10:11:50,652 [Executor task launch worker for task 196] INFO [org.apache.spark.executor.Executor] - Finished task 8.0 in stage 50.0 (TID 196). 166054 bytes result sent to driver
2021-12-08 10:11:50,653 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 8.0 in stage 50.0 (TID 196) in 22677 ms on localhost (executor driver) (7/12)
2021-12-08 10:11:50,906 [Executor task launch worker for task 195] INFO [org.apache.spark.storage.memory.MemoryStore] - Block rdd_79_7 stored as values in memory (estimated size 4.0 MB, free 1634.2 MB)
2021-12-08 10:11:50,906 [dispatcher-event-loop-8] INFO [org.apache.spark.storage.BlockManagerInfo] - Added rdd_79_7 in memory on qb:61292 (size: 4.0 MB, free: 1636.7 MB)
2021-12-08 10:11:50,978 [Executor task launch worker for task 195] INFO [org.apache.spark.executor.Executor] - Finished task 7.0 in stage 50.0 (TID 195). 166054 bytes result sent to driver
2021-12-08 10:11:50,978 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 7.0 in stage 50.0 (TID 195) in 23002 ms on localhost (executor driver) (8/12)
2021-12-08 10:11:51,184 [Executor task launch worker for task 197] INFO [org.apache.spark.storage.memory.MemoryStore] - Block rdd_79_9 stored as values in memory (estimated size 4.0 MB, free 1630.2 MB)
2021-12-08 10:11:51,184 [dispatcher-event-loop-11] INFO [org.apache.spark.storage.BlockManagerInfo] - Added rdd_79_9 in memory on qb:61292 (size: 4.0 MB, free: 1632.7 MB)
2021-12-08 10:11:51,266 [Executor task launch worker for task 197] INFO [org.apache.spark.executor.Executor] - Finished task 9.0 in stage 50.0 (TID 197). 166054 bytes result sent to driver
2021-12-08 10:11:51,267 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 9.0 in stage 50.0 (TID 197) in 23291 ms on localhost (executor driver) (9/12)
2021-12-08 10:11:51,403 [Executor task launch worker for task 191] INFO [org.apache.spark.storage.memory.MemoryStore] - Block rdd_79_3 stored as values in memory (estimated size 4.0 MB, free 1626.2 MB)
2021-12-08 10:11:51,404 [dispatcher-event-loop-5] INFO [org.apache.spark.storage.BlockManagerInfo] - Added rdd_79_3 in memory on qb:61292 (size: 4.0 MB, free: 1628.7 MB)
2021-12-08 10:11:51,472 [Executor task launch worker for task 191] INFO [org.apache.spark.executor.Executor] - Finished task 3.0 in stage 50.0 (TID 191). 166054 bytes result sent to driver
2021-12-08 10:11:51,472 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 3.0 in stage 50.0 (TID 191) in 23497 ms on localhost (executor driver) (10/12)
2021-12-08 10:11:51,634 [Executor task launch worker for task 194] INFO [org.apache.spark.storage.memory.MemoryStore] - Block rdd_79_6 stored as values in memory (estimated size 4.0 MB, free 1622.2 MB)
2021-12-08 10:11:51,634 [dispatcher-event-loop-9] INFO [org.apache.spark.storage.BlockManagerInfo] - Added rdd_79_6 in memory on qb:61292 (size: 4.0 MB, free: 1624.7 MB)
2021-12-08 10:11:51,698 [Executor task launch worker for task 194] INFO [org.apache.spark.executor.Executor] - Finished task 6.0 in stage 50.0 (TID 194). 166054 bytes result sent to driver
2021-12-08 10:11:51,698 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 6.0 in stage 50.0 (TID 194) in 23722 ms on localhost (executor driver) (11/12)
2021-12-08 10:11:51,834 [Executor task launch worker for task 190] INFO [org.apache.spark.storage.memory.MemoryStore] - Block rdd_79_2 stored as values in memory (estimated size 4.0 MB, free 1618.3 MB)
2021-12-08 10:11:51,835 [dispatcher-event-loop-6] INFO [org.apache.spark.storage.BlockManagerInfo] - Added rdd_79_2 in memory on qb:61292 (size: 4.0 MB, free: 1620.7 MB)
2021-12-08 10:11:51,898 [Executor task launch worker for task 190] INFO [org.apache.spark.executor.Executor] - Finished task 2.0 in stage 50.0 (TID 190). 166054 bytes result sent to driver
2021-12-08 10:11:51,899 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 2.0 in stage 50.0 (TID 190) in 23924 ms on localhost (executor driver) (12/12)
2021-12-08 10:11:51,899 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 50.0, whose tasks have all completed, from pool 
2021-12-08 10:11:51,899 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 50 (aggregate at ALS.scala:1711) finished in 23.929 s
2021-12-08 10:11:51,899 [main] INFO [org.apache.spark.scheduler.DAGScheduler] - Job 9 finished: aggregate at ALS.scala:1711, took 26.266748 s
2021-12-08 10:11:51,914 [main] INFO [org.apache.spark.rdd.MapPartitionsRDD] - Removing RDD 69 from persistence list
2021-12-08 10:11:51,914 [block-manager-slave-async-thread-pool-2] INFO [org.apache.spark.storage.BlockManager] - Removing RDD 69
2021-12-08 10:11:51,921 [main] INFO [org.apache.spark.SparkContext] - Starting job: aggregate at ALS.scala:1711
2021-12-08 10:11:51,922 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 84 (flatMap at ALS.scala:1653)
2021-12-08 10:11:51,922 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 10 (aggregate at ALS.scala:1711) with 12 output partitions
2021-12-08 10:11:51,922 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 61 (aggregate at ALS.scala:1711)
2021-12-08 10:11:51,922 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 60, ShuffleMapStage 52)
2021-12-08 10:11:51,923 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List(ShuffleMapStage 60)
2021-12-08 10:11:51,923 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ShuffleMapStage 60 (MapPartitionsRDD[84] at flatMap at ALS.scala:1653), which has no missing parents
2021-12-08 10:11:51,925 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_24 stored as values in memory (estimated size 816.4 KB, free 1750.7 MB)
2021-12-08 10:11:51,926 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_24_piece0 stored as bytes in memory (estimated size 793.8 KB, free 1749.9 MB)
2021-12-08 10:11:51,927 [dispatcher-event-loop-5] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_24_piece0 in memory on qb:61292 (size: 793.8 KB, free: 1753.2 MB)
2021-12-08 10:11:51,927 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 24 from broadcast at DAGScheduler.scala:1039
2021-12-08 10:11:51,927 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 12 missing tasks from ShuffleMapStage 60 (MapPartitionsRDD[84] at flatMap at ALS.scala:1653) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11))
2021-12-08 10:11:51,927 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 60.0 with 12 tasks
2021-12-08 10:11:51,928 [dispatcher-event-loop-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 60.0 (TID 200, localhost, executor driver, partition 0, PROCESS_LOCAL, 7928 bytes)
2021-12-08 10:11:51,928 [dispatcher-event-loop-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 60.0 (TID 201, localhost, executor driver, partition 1, PROCESS_LOCAL, 7928 bytes)
2021-12-08 10:11:51,928 [dispatcher-event-loop-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 2.0 in stage 60.0 (TID 202, localhost, executor driver, partition 2, PROCESS_LOCAL, 7928 bytes)
2021-12-08 10:11:51,928 [dispatcher-event-loop-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 3.0 in stage 60.0 (TID 203, localhost, executor driver, partition 3, PROCESS_LOCAL, 7928 bytes)
2021-12-08 10:11:51,928 [dispatcher-event-loop-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 4.0 in stage 60.0 (TID 204, localhost, executor driver, partition 4, PROCESS_LOCAL, 7928 bytes)
2021-12-08 10:11:51,928 [dispatcher-event-loop-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 5.0 in stage 60.0 (TID 205, localhost, executor driver, partition 5, PROCESS_LOCAL, 7928 bytes)
2021-12-08 10:11:51,928 [dispatcher-event-loop-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 6.0 in stage 60.0 (TID 206, localhost, executor driver, partition 6, PROCESS_LOCAL, 7928 bytes)
2021-12-08 10:11:51,928 [dispatcher-event-loop-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 7.0 in stage 60.0 (TID 207, localhost, executor driver, partition 7, PROCESS_LOCAL, 7928 bytes)
2021-12-08 10:11:51,928 [dispatcher-event-loop-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 8.0 in stage 60.0 (TID 208, localhost, executor driver, partition 8, PROCESS_LOCAL, 7928 bytes)
2021-12-08 10:11:51,928 [dispatcher-event-loop-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 9.0 in stage 60.0 (TID 209, localhost, executor driver, partition 9, PROCESS_LOCAL, 7928 bytes)
2021-12-08 10:11:51,928 [dispatcher-event-loop-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 10.0 in stage 60.0 (TID 210, localhost, executor driver, partition 10, PROCESS_LOCAL, 7928 bytes)
2021-12-08 10:11:51,928 [dispatcher-event-loop-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 11.0 in stage 60.0 (TID 211, localhost, executor driver, partition 11, PROCESS_LOCAL, 7928 bytes)
2021-12-08 10:11:51,928 [Executor task launch worker for task 205] INFO [org.apache.spark.executor.Executor] - Running task 5.0 in stage 60.0 (TID 205)
2021-12-08 10:11:51,928 [Executor task launch worker for task 211] INFO [org.apache.spark.executor.Executor] - Running task 11.0 in stage 60.0 (TID 211)
2021-12-08 10:11:51,928 [Executor task launch worker for task 200] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 60.0 (TID 200)
2021-12-08 10:11:51,928 [Executor task launch worker for task 202] INFO [org.apache.spark.executor.Executor] - Running task 2.0 in stage 60.0 (TID 202)
2021-12-08 10:11:51,928 [Executor task launch worker for task 206] INFO [org.apache.spark.executor.Executor] - Running task 6.0 in stage 60.0 (TID 206)
2021-12-08 10:11:51,928 [Executor task launch worker for task 207] INFO [org.apache.spark.executor.Executor] - Running task 7.0 in stage 60.0 (TID 207)
2021-12-08 10:11:51,928 [Executor task launch worker for task 203] INFO [org.apache.spark.executor.Executor] - Running task 3.0 in stage 60.0 (TID 203)
2021-12-08 10:11:51,928 [Executor task launch worker for task 210] INFO [org.apache.spark.executor.Executor] - Running task 10.0 in stage 60.0 (TID 210)
2021-12-08 10:11:51,928 [Executor task launch worker for task 208] INFO [org.apache.spark.executor.Executor] - Running task 8.0 in stage 60.0 (TID 208)
2021-12-08 10:11:51,928 [Executor task launch worker for task 201] INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 60.0 (TID 201)
2021-12-08 10:11:51,928 [Executor task launch worker for task 209] INFO [org.apache.spark.executor.Executor] - Running task 9.0 in stage 60.0 (TID 209)
2021-12-08 10:11:51,928 [Executor task launch worker for task 204] INFO [org.apache.spark.executor.Executor] - Running task 4.0 in stage 60.0 (TID 204)
2021-12-08 10:11:51,931 [Executor task launch worker for task 209] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_27_9 locally
2021-12-08 10:11:51,931 [Executor task launch worker for task 210] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_27_10 locally
2021-12-08 10:11:51,931 [Executor task launch worker for task 200] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_27_0 locally
2021-12-08 10:11:51,931 [Executor task launch worker for task 207] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_27_7 locally
2021-12-08 10:11:51,931 [Executor task launch worker for task 203] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_27_3 locally
2021-12-08 10:11:51,931 [Executor task launch worker for task 200] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_79_0 locally
2021-12-08 10:11:51,931 [Executor task launch worker for task 206] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_27_6 locally
2021-12-08 10:11:51,931 [Executor task launch worker for task 209] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_79_9 locally
2021-12-08 10:11:51,931 [Executor task launch worker for task 205] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_27_5 locally
2021-12-08 10:11:51,931 [Executor task launch worker for task 205] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_79_5 locally
2021-12-08 10:11:51,931 [Executor task launch worker for task 206] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_79_6 locally
2021-12-08 10:11:51,931 [Executor task launch worker for task 210] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_79_10 locally
2021-12-08 10:11:51,931 [Executor task launch worker for task 211] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_27_11 locally
2021-12-08 10:11:51,931 [Executor task launch worker for task 211] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_79_11 locally
2021-12-08 10:11:51,931 [Executor task launch worker for task 201] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_27_1 locally
2021-12-08 10:11:51,931 [Executor task launch worker for task 201] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_79_1 locally
2021-12-08 10:11:51,932 [Executor task launch worker for task 202] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_27_2 locally
2021-12-08 10:11:51,932 [Executor task launch worker for task 202] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_79_2 locally
2021-12-08 10:11:51,931 [Executor task launch worker for task 207] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_79_7 locally
2021-12-08 10:11:51,932 [Executor task launch worker for task 203] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_79_3 locally
2021-12-08 10:11:51,933 [Executor task launch worker for task 204] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_27_4 locally
2021-12-08 10:11:51,933 [Executor task launch worker for task 204] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_79_4 locally
2021-12-08 10:11:51,932 [Executor task launch worker for task 208] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_27_8 locally
2021-12-08 10:11:51,933 [Executor task launch worker for task 208] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_79_8 locally
2021-12-08 10:11:52,800 [Executor task launch worker for task 205] INFO [org.apache.spark.executor.Executor] - Finished task 5.0 in stage 60.0 (TID 205). 1042 bytes result sent to driver
2021-12-08 10:11:52,800 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 5.0 in stage 60.0 (TID 205) in 872 ms on localhost (executor driver) (1/12)
2021-12-08 10:11:52,817 [Executor task launch worker for task 208] INFO [org.apache.spark.executor.Executor] - Finished task 8.0 in stage 60.0 (TID 208). 999 bytes result sent to driver
2021-12-08 10:11:52,817 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 8.0 in stage 60.0 (TID 208) in 889 ms on localhost (executor driver) (2/12)
2021-12-08 10:11:52,831 [Executor task launch worker for task 210] INFO [org.apache.spark.executor.Executor] - Finished task 10.0 in stage 60.0 (TID 210). 999 bytes result sent to driver
2021-12-08 10:11:52,831 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 10.0 in stage 60.0 (TID 210) in 903 ms on localhost (executor driver) (3/12)
2021-12-08 10:11:52,841 [Executor task launch worker for task 209] INFO [org.apache.spark.executor.Executor] - Finished task 9.0 in stage 60.0 (TID 209). 999 bytes result sent to driver
2021-12-08 10:11:52,841 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 9.0 in stage 60.0 (TID 209) in 913 ms on localhost (executor driver) (4/12)
2021-12-08 10:11:52,854 [Executor task launch worker for task 202] INFO [org.apache.spark.executor.Executor] - Finished task 2.0 in stage 60.0 (TID 202). 1042 bytes result sent to driver
2021-12-08 10:11:52,855 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 2.0 in stage 60.0 (TID 202) in 927 ms on localhost (executor driver) (5/12)
2021-12-08 10:11:52,869 [Executor task launch worker for task 201] INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 60.0 (TID 201). 999 bytes result sent to driver
2021-12-08 10:11:52,869 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 60.0 (TID 201) in 941 ms on localhost (executor driver) (6/12)
2021-12-08 10:11:52,869 [Executor task launch worker for task 200] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 60.0 (TID 200). 1042 bytes result sent to driver
2021-12-08 10:11:52,870 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 60.0 (TID 200) in 943 ms on localhost (executor driver) (7/12)
2021-12-08 10:11:52,870 [Executor task launch worker for task 211] INFO [org.apache.spark.executor.Executor] - Finished task 11.0 in stage 60.0 (TID 211). 1042 bytes result sent to driver
2021-12-08 10:11:52,870 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 11.0 in stage 60.0 (TID 211) in 942 ms on localhost (executor driver) (8/12)
2021-12-08 10:11:52,913 [Executor task launch worker for task 206] INFO [org.apache.spark.executor.Executor] - Finished task 6.0 in stage 60.0 (TID 206). 1042 bytes result sent to driver
2021-12-08 10:11:52,913 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 6.0 in stage 60.0 (TID 206) in 985 ms on localhost (executor driver) (9/12)
2021-12-08 10:11:52,970 [Executor task launch worker for task 204] INFO [org.apache.spark.executor.Executor] - Finished task 4.0 in stage 60.0 (TID 204). 999 bytes result sent to driver
2021-12-08 10:11:52,971 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 4.0 in stage 60.0 (TID 204) in 1043 ms on localhost (executor driver) (10/12)
2021-12-08 10:11:52,971 [Executor task launch worker for task 203] INFO [org.apache.spark.executor.Executor] - Finished task 3.0 in stage 60.0 (TID 203). 1042 bytes result sent to driver
2021-12-08 10:11:52,971 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 3.0 in stage 60.0 (TID 203) in 1043 ms on localhost (executor driver) (11/12)
2021-12-08 10:11:52,972 [Executor task launch worker for task 207] INFO [org.apache.spark.executor.Executor] - Finished task 7.0 in stage 60.0 (TID 207). 1042 bytes result sent to driver
2021-12-08 10:11:52,972 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 7.0 in stage 60.0 (TID 207) in 1044 ms on localhost (executor driver) (12/12)
2021-12-08 10:11:52,972 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 60.0, whose tasks have all completed, from pool 
2021-12-08 10:11:52,972 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ShuffleMapStage 60 (flatMap at ALS.scala:1653) finished in 1.049 s
2021-12-08 10:11:52,972 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - looking for newly runnable stages
2021-12-08 10:11:52,972 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - running: Set()
2021-12-08 10:11:52,972 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - waiting: Set(ResultStage 61)
2021-12-08 10:11:52,972 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - failed: Set()
2021-12-08 10:11:52,973 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 61 (MapPartitionsRDD[90] at values at ALS.scala:1711), which has no missing parents
2021-12-08 10:11:52,975 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_25 stored as values in memory (estimated size 1138.0 KB, free 1748.8 MB)
2021-12-08 10:11:52,978 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_25_piece0 stored as bytes in memory (estimated size 952.5 KB, free 1747.9 MB)
2021-12-08 10:11:52,978 [dispatcher-event-loop-6] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_25_piece0 in memory on qb:61292 (size: 952.5 KB, free: 1752.3 MB)
2021-12-08 10:11:52,978 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 25 from broadcast at DAGScheduler.scala:1039
2021-12-08 10:11:52,978 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 12 missing tasks from ResultStage 61 (MapPartitionsRDD[90] at values at ALS.scala:1711) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11))
2021-12-08 10:11:52,978 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 61.0 with 12 tasks
2021-12-08 10:11:52,979 [dispatcher-event-loop-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 61.0 (TID 212, localhost, executor driver, partition 0, PROCESS_LOCAL, 7888 bytes)
2021-12-08 10:11:52,979 [dispatcher-event-loop-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 61.0 (TID 213, localhost, executor driver, partition 1, PROCESS_LOCAL, 7888 bytes)
2021-12-08 10:11:52,979 [dispatcher-event-loop-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 2.0 in stage 61.0 (TID 214, localhost, executor driver, partition 2, PROCESS_LOCAL, 7888 bytes)
2021-12-08 10:11:52,979 [dispatcher-event-loop-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 3.0 in stage 61.0 (TID 215, localhost, executor driver, partition 3, PROCESS_LOCAL, 7888 bytes)
2021-12-08 10:11:52,979 [dispatcher-event-loop-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 4.0 in stage 61.0 (TID 216, localhost, executor driver, partition 4, PROCESS_LOCAL, 7888 bytes)
2021-12-08 10:11:52,979 [dispatcher-event-loop-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 5.0 in stage 61.0 (TID 217, localhost, executor driver, partition 5, PROCESS_LOCAL, 7888 bytes)
2021-12-08 10:11:52,979 [dispatcher-event-loop-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 6.0 in stage 61.0 (TID 218, localhost, executor driver, partition 6, PROCESS_LOCAL, 7888 bytes)
2021-12-08 10:11:52,979 [dispatcher-event-loop-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 7.0 in stage 61.0 (TID 219, localhost, executor driver, partition 7, PROCESS_LOCAL, 7888 bytes)
2021-12-08 10:11:52,979 [dispatcher-event-loop-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 8.0 in stage 61.0 (TID 220, localhost, executor driver, partition 8, PROCESS_LOCAL, 7888 bytes)
2021-12-08 10:11:52,979 [dispatcher-event-loop-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 9.0 in stage 61.0 (TID 221, localhost, executor driver, partition 9, PROCESS_LOCAL, 7888 bytes)
2021-12-08 10:11:52,979 [dispatcher-event-loop-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 10.0 in stage 61.0 (TID 222, localhost, executor driver, partition 10, PROCESS_LOCAL, 7888 bytes)
2021-12-08 10:11:52,979 [dispatcher-event-loop-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 11.0 in stage 61.0 (TID 223, localhost, executor driver, partition 11, PROCESS_LOCAL, 7888 bytes)
2021-12-08 10:11:52,980 [Executor task launch worker for task 212] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 61.0 (TID 212)
2021-12-08 10:11:52,980 [Executor task launch worker for task 215] INFO [org.apache.spark.executor.Executor] - Running task 3.0 in stage 61.0 (TID 215)
2021-12-08 10:11:52,980 [Executor task launch worker for task 213] INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 61.0 (TID 213)
2021-12-08 10:11:52,980 [Executor task launch worker for task 219] INFO [org.apache.spark.executor.Executor] - Running task 7.0 in stage 61.0 (TID 219)
2021-12-08 10:11:52,980 [Executor task launch worker for task 218] INFO [org.apache.spark.executor.Executor] - Running task 6.0 in stage 61.0 (TID 218)
2021-12-08 10:11:52,980 [Executor task launch worker for task 220] INFO [org.apache.spark.executor.Executor] - Running task 8.0 in stage 61.0 (TID 220)
2021-12-08 10:11:52,980 [Executor task launch worker for task 216] INFO [org.apache.spark.executor.Executor] - Running task 4.0 in stage 61.0 (TID 216)
2021-12-08 10:11:52,980 [Executor task launch worker for task 217] INFO [org.apache.spark.executor.Executor] - Running task 5.0 in stage 61.0 (TID 217)
2021-12-08 10:11:52,980 [Executor task launch worker for task 214] INFO [org.apache.spark.executor.Executor] - Running task 2.0 in stage 61.0 (TID 214)
2021-12-08 10:11:52,980 [Executor task launch worker for task 221] INFO [org.apache.spark.executor.Executor] - Running task 9.0 in stage 61.0 (TID 221)
2021-12-08 10:11:52,980 [Executor task launch worker for task 222] INFO [org.apache.spark.executor.Executor] - Running task 10.0 in stage 61.0 (TID 222)
2021-12-08 10:11:52,980 [Executor task launch worker for task 223] INFO [org.apache.spark.executor.Executor] - Running task 11.0 in stage 61.0 (TID 223)
2021-12-08 10:11:52,983 [Executor task launch worker for task 220] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_21_8 locally
2021-12-08 10:11:52,983 [Executor task launch worker for task 223] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_21_11 locally
2021-12-08 10:11:52,983 [Executor task launch worker for task 217] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_21_5 locally
2021-12-08 10:11:52,983 [Executor task launch worker for task 216] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_21_4 locally
2021-12-08 10:11:52,983 [Executor task launch worker for task 218] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_21_6 locally
2021-12-08 10:11:52,983 [Executor task launch worker for task 221] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_21_9 locally
2021-12-08 10:11:52,984 [Executor task launch worker for task 215] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_21_3 locally
2021-12-08 10:11:52,983 [Executor task launch worker for task 214] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_21_2 locally
2021-12-08 10:11:52,984 [Executor task launch worker for task 220] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 12 non-empty blocks out of 12 blocks
2021-12-08 10:11:52,984 [Executor task launch worker for task 217] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 12 non-empty blocks out of 12 blocks
2021-12-08 10:11:52,984 [Executor task launch worker for task 213] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_21_1 locally
2021-12-08 10:11:52,984 [Executor task launch worker for task 217] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 1 ms
2021-12-08 10:11:52,984 [Executor task launch worker for task 212] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_21_0 locally
2021-12-08 10:11:52,984 [Executor task launch worker for task 216] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 12 non-empty blocks out of 12 blocks
2021-12-08 10:11:52,984 [Executor task launch worker for task 216] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 1 ms
2021-12-08 10:11:52,984 [Executor task launch worker for task 220] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-08 10:11:52,984 [Executor task launch worker for task 223] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 12 non-empty blocks out of 12 blocks
2021-12-08 10:11:52,984 [Executor task launch worker for task 218] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 12 non-empty blocks out of 12 blocks
2021-12-08 10:11:52,984 [Executor task launch worker for task 223] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-08 10:11:52,984 [Executor task launch worker for task 221] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 12 non-empty blocks out of 12 blocks
2021-12-08 10:11:52,984 [Executor task launch worker for task 213] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 12 non-empty blocks out of 12 blocks
2021-12-08 10:11:52,984 [Executor task launch worker for task 215] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 12 non-empty blocks out of 12 blocks
2021-12-08 10:11:52,984 [Executor task launch worker for task 214] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 12 non-empty blocks out of 12 blocks
2021-12-08 10:11:52,984 [Executor task launch worker for task 215] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-08 10:11:52,984 [Executor task launch worker for task 212] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 12 non-empty blocks out of 12 blocks
2021-12-08 10:11:52,984 [Executor task launch worker for task 213] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-08 10:11:52,984 [Executor task launch worker for task 221] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-08 10:11:52,984 [Executor task launch worker for task 218] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-08 10:11:52,984 [Executor task launch worker for task 212] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-08 10:11:52,984 [Executor task launch worker for task 214] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-08 10:11:52,984 [Executor task launch worker for task 219] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_21_7 locally
2021-12-08 10:11:52,984 [Executor task launch worker for task 222] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_21_10 locally
2021-12-08 10:11:52,984 [Executor task launch worker for task 219] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 12 non-empty blocks out of 12 blocks
2021-12-08 10:11:52,984 [Executor task launch worker for task 222] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 12 non-empty blocks out of 12 blocks
2021-12-08 10:11:52,984 [Executor task launch worker for task 219] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-08 10:11:52,984 [Executor task launch worker for task 222] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-08 10:11:53,082 [dispatcher-event-loop-4] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_24_piece0 on qb:61292 in memory (size: 793.8 KB, free: 1753.1 MB)
2021-12-08 10:11:53,411 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 435
2021-12-08 10:11:53,411 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 459
2021-12-08 10:11:53,413 [dispatcher-event-loop-5] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_23_piece0 on qb:61292 in memory (size: 794.8 KB, free: 1753.8 MB)
2021-12-08 10:11:53,414 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 451
2021-12-08 10:11:53,414 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 453
2021-12-08 10:11:53,414 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 450
2021-12-08 10:11:53,414 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 439
2021-12-08 10:11:53,414 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 444
2021-12-08 10:11:53,414 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 440
2021-12-08 10:11:53,414 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 465
2021-12-08 10:11:53,414 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 431
2021-12-08 10:11:53,414 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 432
2021-12-08 10:11:53,414 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 458
2021-12-08 10:11:53,414 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 468
2021-12-08 10:11:53,414 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 455
2021-12-08 10:11:53,414 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 446
2021-12-08 10:11:53,414 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 429
2021-12-08 10:11:53,414 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 438
2021-12-08 10:11:53,414 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 430
2021-12-08 10:11:53,414 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 456
2021-12-08 10:11:53,414 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 428
2021-12-08 10:11:53,414 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 437
2021-12-08 10:11:53,414 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 449
2021-12-08 10:11:53,414 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 470
2021-12-08 10:11:53,414 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 464
2021-12-08 10:11:53,414 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 466
2021-12-08 10:11:53,414 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 471
2021-12-08 10:11:53,414 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 463
2021-12-08 10:11:53,414 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 452
2021-12-08 10:11:53,414 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 454
2021-12-08 10:11:53,414 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 474
2021-12-08 10:11:53,414 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 469
2021-12-08 10:11:53,414 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 434
2021-12-08 10:11:53,414 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 445
2021-12-08 10:11:53,414 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 433
2021-12-08 10:11:53,414 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 467
2021-12-08 10:11:53,414 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 447
2021-12-08 10:11:53,414 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 442
2021-12-08 10:11:53,414 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 448
2021-12-08 10:11:53,414 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 427
2021-12-08 10:11:53,414 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 443
2021-12-08 10:11:53,414 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 473
2021-12-08 10:11:53,414 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 441
2021-12-08 10:11:53,414 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 461
2021-12-08 10:11:53,414 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 460
2021-12-08 10:11:53,414 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 425
2021-12-08 10:11:53,414 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 436
2021-12-08 10:11:53,414 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 462
2021-12-08 10:11:53,414 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 457
2021-12-08 10:11:53,414 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 472
2021-12-08 10:11:53,414 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 426
2021-12-08 10:12:30,052 [Executor task launch worker for task 217] INFO [org.apache.spark.storage.memory.MemoryStore] - Block rdd_89_5 stored as values in memory (estimated size 11.1 MB, free 1740.1 MB)
2021-12-08 10:12:30,053 [dispatcher-event-loop-11] INFO [org.apache.spark.storage.BlockManagerInfo] - Added rdd_89_5 in memory on qb:61292 (size: 11.1 MB, free: 1742.7 MB)
2021-12-08 10:12:30,163 [Executor task launch worker for task 218] INFO [org.apache.spark.storage.memory.MemoryStore] - Block rdd_89_6 stored as values in memory (estimated size 11.1 MB, free 1729.0 MB)
2021-12-08 10:12:30,164 [dispatcher-event-loop-0] INFO [org.apache.spark.storage.BlockManagerInfo] - Added rdd_89_6 in memory on qb:61292 (size: 11.1 MB, free: 1731.6 MB)
2021-12-08 10:12:30,240 [Executor task launch worker for task 223] INFO [org.apache.spark.storage.memory.MemoryStore] - Block rdd_89_11 stored as values in memory (estimated size 11.1 MB, free 1717.9 MB)
2021-12-08 10:12:30,240 [dispatcher-event-loop-5] INFO [org.apache.spark.storage.BlockManagerInfo] - Added rdd_89_11 in memory on qb:61292 (size: 11.1 MB, free: 1720.5 MB)
2021-12-08 10:12:30,255 [Executor task launch worker for task 219] INFO [org.apache.spark.storage.memory.MemoryStore] - Block rdd_89_7 stored as values in memory (estimated size 11.1 MB, free 1706.8 MB)
2021-12-08 10:12:30,255 [dispatcher-event-loop-3] INFO [org.apache.spark.storage.BlockManagerInfo] - Added rdd_89_7 in memory on qb:61292 (size: 11.1 MB, free: 1709.4 MB)
2021-12-08 10:12:30,372 [Executor task launch worker for task 221] INFO [org.apache.spark.storage.memory.MemoryStore] - Block rdd_89_9 stored as values in memory (estimated size 11.1 MB, free 1695.7 MB)
2021-12-08 10:12:30,372 [dispatcher-event-loop-2] INFO [org.apache.spark.storage.BlockManagerInfo] - Added rdd_89_9 in memory on qb:61292 (size: 11.1 MB, free: 1698.3 MB)
2021-12-08 10:12:30,377 [Executor task launch worker for task 214] INFO [org.apache.spark.storage.memory.MemoryStore] - Block rdd_89_2 stored as values in memory (estimated size 11.1 MB, free 1684.6 MB)
2021-12-08 10:12:30,377 [dispatcher-event-loop-9] INFO [org.apache.spark.storage.BlockManagerInfo] - Added rdd_89_2 in memory on qb:61292 (size: 11.1 MB, free: 1687.2 MB)
2021-12-08 10:12:30,385 [Executor task launch worker for task 217] INFO [org.apache.spark.executor.Executor] - Finished task 5.0 in stage 61.0 (TID 217). 166054 bytes result sent to driver
2021-12-08 10:12:30,387 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 5.0 in stage 61.0 (TID 217) in 37408 ms on localhost (executor driver) (1/12)
2021-12-08 10:12:30,502 [Executor task launch worker for task 218] INFO [org.apache.spark.executor.Executor] - Finished task 6.0 in stage 61.0 (TID 218). 166054 bytes result sent to driver
2021-12-08 10:12:30,510 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 6.0 in stage 61.0 (TID 218) in 37531 ms on localhost (executor driver) (2/12)
2021-12-08 10:12:30,520 [Executor task launch worker for task 213] INFO [org.apache.spark.storage.memory.MemoryStore] - Block rdd_89_1 stored as values in memory (estimated size 11.1 MB, free 1673.5 MB)
2021-12-08 10:12:30,520 [dispatcher-event-loop-6] INFO [org.apache.spark.storage.BlockManagerInfo] - Added rdd_89_1 in memory on qb:61292 (size: 11.1 MB, free: 1676.1 MB)
2021-12-08 10:12:30,570 [Executor task launch worker for task 223] INFO [org.apache.spark.executor.Executor] - Finished task 11.0 in stage 61.0 (TID 223). 166054 bytes result sent to driver
2021-12-08 10:12:30,571 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 11.0 in stage 61.0 (TID 223) in 37592 ms on localhost (executor driver) (3/12)
2021-12-08 10:12:30,598 [Executor task launch worker for task 219] INFO [org.apache.spark.executor.Executor] - Finished task 7.0 in stage 61.0 (TID 219). 166054 bytes result sent to driver
2021-12-08 10:12:30,598 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 7.0 in stage 61.0 (TID 219) in 37619 ms on localhost (executor driver) (4/12)
2021-12-08 10:12:30,666 [Executor task launch worker for task 221] INFO [org.apache.spark.executor.Executor] - Finished task 9.0 in stage 61.0 (TID 221). 166054 bytes result sent to driver
2021-12-08 10:12:30,667 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 9.0 in stage 61.0 (TID 221) in 37688 ms on localhost (executor driver) (5/12)
2021-12-08 10:12:30,686 [Executor task launch worker for task 212] INFO [org.apache.spark.storage.memory.MemoryStore] - Block rdd_89_0 stored as values in memory (estimated size 11.1 MB, free 1662.4 MB)
2021-12-08 10:12:30,686 [dispatcher-event-loop-11] INFO [org.apache.spark.storage.BlockManagerInfo] - Added rdd_89_0 in memory on qb:61292 (size: 11.1 MB, free: 1665.0 MB)
2021-12-08 10:12:30,702 [Executor task launch worker for task 214] INFO [org.apache.spark.executor.Executor] - Finished task 2.0 in stage 61.0 (TID 214). 166054 bytes result sent to driver
2021-12-08 10:12:30,702 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 2.0 in stage 61.0 (TID 214) in 37723 ms on localhost (executor driver) (6/12)
2021-12-08 10:12:30,738 [Executor task launch worker for task 220] INFO [org.apache.spark.storage.memory.MemoryStore] - Block rdd_89_8 stored as values in memory (estimated size 11.1 MB, free 1651.3 MB)
2021-12-08 10:12:30,738 [dispatcher-event-loop-5] INFO [org.apache.spark.storage.BlockManagerInfo] - Added rdd_89_8 in memory on qb:61292 (size: 11.1 MB, free: 1653.9 MB)
2021-12-08 10:12:30,793 [Executor task launch worker for task 213] INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 61.0 (TID 213). 166097 bytes result sent to driver
2021-12-08 10:12:30,793 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 61.0 (TID 213) in 37814 ms on localhost (executor driver) (7/12)
2021-12-08 10:12:30,811 [Executor task launch worker for task 222] INFO [org.apache.spark.storage.memory.MemoryStore] - Block rdd_89_10 stored as values in memory (estimated size 11.1 MB, free 1640.2 MB)
2021-12-08 10:12:30,812 [dispatcher-event-loop-2] INFO [org.apache.spark.storage.BlockManagerInfo] - Added rdd_89_10 in memory on qb:61292 (size: 11.1 MB, free: 1642.8 MB)
2021-12-08 10:12:30,829 [Executor task launch worker for task 215] INFO [org.apache.spark.storage.memory.MemoryStore] - Block rdd_89_3 stored as values in memory (estimated size 11.1 MB, free 1629.1 MB)
2021-12-08 10:12:30,829 [dispatcher-event-loop-9] INFO [org.apache.spark.storage.BlockManagerInfo] - Added rdd_89_3 in memory on qb:61292 (size: 11.1 MB, free: 1631.7 MB)
2021-12-08 10:12:30,965 [Executor task launch worker for task 212] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 61.0 (TID 212). 166097 bytes result sent to driver
2021-12-08 10:12:30,965 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 61.0 (TID 212) in 37986 ms on localhost (executor driver) (8/12)
2021-12-08 10:12:30,980 [Executor task launch worker for task 220] INFO [org.apache.spark.executor.Executor] - Finished task 8.0 in stage 61.0 (TID 220). 166097 bytes result sent to driver
2021-12-08 10:12:30,980 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 8.0 in stage 61.0 (TID 220) in 38001 ms on localhost (executor driver) (9/12)
2021-12-08 10:12:31,027 [Executor task launch worker for task 222] INFO [org.apache.spark.executor.Executor] - Finished task 10.0 in stage 61.0 (TID 222). 166054 bytes result sent to driver
2021-12-08 10:12:31,027 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 10.0 in stage 61.0 (TID 222) in 38048 ms on localhost (executor driver) (10/12)
2021-12-08 10:12:31,030 [Executor task launch worker for task 216] INFO [org.apache.spark.storage.memory.MemoryStore] - Block rdd_89_4 stored as values in memory (estimated size 11.1 MB, free 1617.9 MB)
2021-12-08 10:12:31,030 [dispatcher-event-loop-8] INFO [org.apache.spark.storage.BlockManagerInfo] - Added rdd_89_4 in memory on qb:61292 (size: 11.1 MB, free: 1620.6 MB)
2021-12-08 10:12:31,057 [Executor task launch worker for task 215] INFO [org.apache.spark.executor.Executor] - Finished task 3.0 in stage 61.0 (TID 215). 166054 bytes result sent to driver
2021-12-08 10:12:31,058 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 3.0 in stage 61.0 (TID 215) in 38079 ms on localhost (executor driver) (11/12)
2021-12-08 10:12:31,207 [Executor task launch worker for task 216] INFO [org.apache.spark.executor.Executor] - Finished task 4.0 in stage 61.0 (TID 216). 166054 bytes result sent to driver
2021-12-08 10:12:31,208 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 4.0 in stage 61.0 (TID 216) in 38229 ms on localhost (executor driver) (12/12)
2021-12-08 10:12:31,208 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 61.0, whose tasks have all completed, from pool 
2021-12-08 10:12:31,208 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 61 (aggregate at ALS.scala:1711) finished in 38.235 s
2021-12-08 10:12:31,208 [main] INFO [org.apache.spark.scheduler.DAGScheduler] - Job 10 finished: aggregate at ALS.scala:1711, took 39.287043 s
2021-12-08 10:12:31,224 [main] INFO [org.apache.spark.rdd.MapPartitionsRDD] - Removing RDD 79 from persistence list
2021-12-08 10:12:31,224 [block-manager-slave-async-thread-pool-0] INFO [org.apache.spark.storage.BlockManager] - Removing RDD 79
2021-12-08 10:12:31,231 [main] INFO [org.apache.spark.SparkContext] - Starting job: aggregate at ALS.scala:1711
2021-12-08 10:12:31,232 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 94 (flatMap at ALS.scala:1653)
2021-12-08 10:12:31,232 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 11 (aggregate at ALS.scala:1711) with 12 output partitions
2021-12-08 10:12:31,232 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 73 (aggregate at ALS.scala:1711)
2021-12-08 10:12:31,232 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 63, ShuffleMapStage 72)
2021-12-08 10:12:31,232 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List(ShuffleMapStage 72)
2021-12-08 10:12:31,233 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ShuffleMapStage 72 (MapPartitionsRDD[94] at flatMap at ALS.scala:1653), which has no missing parents
2021-12-08 10:12:31,234 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_26 stored as values in memory (estimated size 977.5 KB, free 1664.9 MB)
2021-12-08 10:12:31,237 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_26_piece0 stored as bytes in memory (estimated size 951.5 KB, free 1663.9 MB)
2021-12-08 10:12:31,237 [dispatcher-event-loop-10] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_26_piece0 in memory on qb:61292 (size: 951.5 KB, free: 1667.5 MB)
2021-12-08 10:12:31,238 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 26 from broadcast at DAGScheduler.scala:1039
2021-12-08 10:12:31,238 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 12 missing tasks from ShuffleMapStage 72 (MapPartitionsRDD[94] at flatMap at ALS.scala:1653) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11))
2021-12-08 10:12:31,238 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 72.0 with 12 tasks
2021-12-08 10:12:31,238 [dispatcher-event-loop-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 72.0 (TID 224, localhost, executor driver, partition 0, PROCESS_LOCAL, 7928 bytes)
2021-12-08 10:12:31,239 [dispatcher-event-loop-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 72.0 (TID 225, localhost, executor driver, partition 1, PROCESS_LOCAL, 7928 bytes)
2021-12-08 10:12:31,239 [dispatcher-event-loop-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 2.0 in stage 72.0 (TID 226, localhost, executor driver, partition 2, PROCESS_LOCAL, 7928 bytes)
2021-12-08 10:12:31,239 [dispatcher-event-loop-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 3.0 in stage 72.0 (TID 227, localhost, executor driver, partition 3, PROCESS_LOCAL, 7928 bytes)
2021-12-08 10:12:31,239 [dispatcher-event-loop-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 4.0 in stage 72.0 (TID 228, localhost, executor driver, partition 4, PROCESS_LOCAL, 7928 bytes)
2021-12-08 10:12:31,239 [dispatcher-event-loop-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 5.0 in stage 72.0 (TID 229, localhost, executor driver, partition 5, PROCESS_LOCAL, 7928 bytes)
2021-12-08 10:12:31,239 [dispatcher-event-loop-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 6.0 in stage 72.0 (TID 230, localhost, executor driver, partition 6, PROCESS_LOCAL, 7928 bytes)
2021-12-08 10:12:31,239 [dispatcher-event-loop-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 7.0 in stage 72.0 (TID 231, localhost, executor driver, partition 7, PROCESS_LOCAL, 7928 bytes)
2021-12-08 10:12:31,239 [dispatcher-event-loop-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 8.0 in stage 72.0 (TID 232, localhost, executor driver, partition 8, PROCESS_LOCAL, 7928 bytes)
2021-12-08 10:12:31,239 [dispatcher-event-loop-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 9.0 in stage 72.0 (TID 233, localhost, executor driver, partition 9, PROCESS_LOCAL, 7928 bytes)
2021-12-08 10:12:31,239 [dispatcher-event-loop-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 10.0 in stage 72.0 (TID 234, localhost, executor driver, partition 10, PROCESS_LOCAL, 7928 bytes)
2021-12-08 10:12:31,239 [dispatcher-event-loop-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 11.0 in stage 72.0 (TID 235, localhost, executor driver, partition 11, PROCESS_LOCAL, 7928 bytes)
2021-12-08 10:12:31,239 [Executor task launch worker for task 226] INFO [org.apache.spark.executor.Executor] - Running task 2.0 in stage 72.0 (TID 226)
2021-12-08 10:12:31,239 [Executor task launch worker for task 224] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 72.0 (TID 224)
2021-12-08 10:12:31,239 [Executor task launch worker for task 225] INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 72.0 (TID 225)
2021-12-08 10:12:31,239 [Executor task launch worker for task 228] INFO [org.apache.spark.executor.Executor] - Running task 4.0 in stage 72.0 (TID 228)
2021-12-08 10:12:31,239 [Executor task launch worker for task 230] INFO [org.apache.spark.executor.Executor] - Running task 6.0 in stage 72.0 (TID 230)
2021-12-08 10:12:31,239 [Executor task launch worker for task 229] INFO [org.apache.spark.executor.Executor] - Running task 5.0 in stage 72.0 (TID 229)
2021-12-08 10:12:31,239 [Executor task launch worker for task 227] INFO [org.apache.spark.executor.Executor] - Running task 3.0 in stage 72.0 (TID 227)
2021-12-08 10:12:31,239 [Executor task launch worker for task 235] INFO [org.apache.spark.executor.Executor] - Running task 11.0 in stage 72.0 (TID 235)
2021-12-08 10:12:31,239 [Executor task launch worker for task 233] INFO [org.apache.spark.executor.Executor] - Running task 9.0 in stage 72.0 (TID 233)
2021-12-08 10:12:31,239 [Executor task launch worker for task 234] INFO [org.apache.spark.executor.Executor] - Running task 10.0 in stage 72.0 (TID 234)
2021-12-08 10:12:31,239 [Executor task launch worker for task 231] INFO [org.apache.spark.executor.Executor] - Running task 7.0 in stage 72.0 (TID 231)
2021-12-08 10:12:31,239 [Executor task launch worker for task 232] INFO [org.apache.spark.executor.Executor] - Running task 8.0 in stage 72.0 (TID 232)
2021-12-08 10:12:31,242 [Executor task launch worker for task 232] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_22_8 locally
2021-12-08 10:12:31,242 [Executor task launch worker for task 228] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_22_4 locally
2021-12-08 10:12:31,242 [Executor task launch worker for task 235] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_22_11 locally
2021-12-08 10:12:31,242 [Executor task launch worker for task 235] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_89_11 locally
2021-12-08 10:12:31,242 [Executor task launch worker for task 234] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_22_10 locally
2021-12-08 10:12:31,242 [Executor task launch worker for task 234] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_89_10 locally
2021-12-08 10:12:31,242 [Executor task launch worker for task 229] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_22_5 locally
2021-12-08 10:12:31,242 [Executor task launch worker for task 229] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_89_5 locally
2021-12-08 10:12:31,242 [Executor task launch worker for task 230] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_22_6 locally
2021-12-08 10:12:31,242 [Executor task launch worker for task 227] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_22_3 locally
2021-12-08 10:12:31,243 [Executor task launch worker for task 227] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_89_3 locally
2021-12-08 10:12:31,243 [Executor task launch worker for task 225] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_22_1 locally
2021-12-08 10:12:31,243 [Executor task launch worker for task 226] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_22_2 locally
2021-12-08 10:12:31,243 [Executor task launch worker for task 226] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_89_2 locally
2021-12-08 10:12:31,242 [Executor task launch worker for task 228] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_89_4 locally
2021-12-08 10:12:31,243 [Executor task launch worker for task 224] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_22_0 locally
2021-12-08 10:12:31,243 [Executor task launch worker for task 225] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_89_1 locally
2021-12-08 10:12:31,242 [Executor task launch worker for task 230] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_89_6 locally
2021-12-08 10:12:31,244 [Executor task launch worker for task 224] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_89_0 locally
2021-12-08 10:12:31,244 [Executor task launch worker for task 233] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_22_9 locally
2021-12-08 10:12:31,244 [Executor task launch worker for task 233] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_89_9 locally
2021-12-08 10:12:31,243 [Executor task launch worker for task 232] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_89_8 locally
2021-12-08 10:12:31,243 [Executor task launch worker for task 231] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_22_7 locally
2021-12-08 10:12:31,248 [Executor task launch worker for task 231] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_89_7 locally
2021-12-08 10:12:33,357 [Executor task launch worker for task 226] INFO [org.apache.spark.executor.Executor] - Finished task 2.0 in stage 72.0 (TID 226). 1085 bytes result sent to driver
2021-12-08 10:12:33,358 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 2.0 in stage 72.0 (TID 226) in 2119 ms on localhost (executor driver) (1/12)
2021-12-08 10:12:33,439 [Executor task launch worker for task 228] INFO [org.apache.spark.executor.Executor] - Finished task 4.0 in stage 72.0 (TID 228). 1085 bytes result sent to driver
2021-12-08 10:12:33,439 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 4.0 in stage 72.0 (TID 228) in 2200 ms on localhost (executor driver) (2/12)
2021-12-08 10:12:33,449 [Executor task launch worker for task 233] INFO [org.apache.spark.executor.Executor] - Finished task 9.0 in stage 72.0 (TID 233). 1042 bytes result sent to driver
2021-12-08 10:12:33,449 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 9.0 in stage 72.0 (TID 233) in 2210 ms on localhost (executor driver) (3/12)
2021-12-08 10:12:33,472 [Executor task launch worker for task 232] INFO [org.apache.spark.executor.Executor] - Finished task 8.0 in stage 72.0 (TID 232). 1085 bytes result sent to driver
2021-12-08 10:12:33,472 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 8.0 in stage 72.0 (TID 232) in 2233 ms on localhost (executor driver) (4/12)
2021-12-08 10:12:33,485 [Executor task launch worker for task 235] INFO [org.apache.spark.executor.Executor] - Finished task 11.0 in stage 72.0 (TID 235). 1085 bytes result sent to driver
2021-12-08 10:12:33,485 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 11.0 in stage 72.0 (TID 235) in 2246 ms on localhost (executor driver) (5/12)
2021-12-08 10:12:33,506 [Executor task launch worker for task 229] INFO [org.apache.spark.executor.Executor] - Finished task 5.0 in stage 72.0 (TID 229). 1085 bytes result sent to driver
2021-12-08 10:12:33,506 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 5.0 in stage 72.0 (TID 229) in 2267 ms on localhost (executor driver) (6/12)
2021-12-08 10:12:33,633 [Executor task launch worker for task 231] INFO [org.apache.spark.executor.Executor] - Finished task 7.0 in stage 72.0 (TID 231). 1042 bytes result sent to driver
2021-12-08 10:12:33,633 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 7.0 in stage 72.0 (TID 231) in 2394 ms on localhost (executor driver) (7/12)
2021-12-08 10:12:33,634 [Executor task launch worker for task 230] INFO [org.apache.spark.executor.Executor] - Finished task 6.0 in stage 72.0 (TID 230). 1085 bytes result sent to driver
2021-12-08 10:12:33,635 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 6.0 in stage 72.0 (TID 230) in 2396 ms on localhost (executor driver) (8/12)
2021-12-08 10:12:33,640 [Executor task launch worker for task 225] INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 72.0 (TID 225). 1085 bytes result sent to driver
2021-12-08 10:12:33,640 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 72.0 (TID 225) in 2402 ms on localhost (executor driver) (9/12)
2021-12-08 10:12:33,656 [Executor task launch worker for task 227] INFO [org.apache.spark.executor.Executor] - Finished task 3.0 in stage 72.0 (TID 227). 1085 bytes result sent to driver
2021-12-08 10:12:33,656 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 3.0 in stage 72.0 (TID 227) in 2417 ms on localhost (executor driver) (10/12)
2021-12-08 10:12:33,657 [Executor task launch worker for task 234] INFO [org.apache.spark.executor.Executor] - Finished task 10.0 in stage 72.0 (TID 234). 1085 bytes result sent to driver
2021-12-08 10:12:33,657 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 10.0 in stage 72.0 (TID 234) in 2418 ms on localhost (executor driver) (11/12)
2021-12-08 10:12:33,742 [Executor task launch worker for task 224] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 72.0 (TID 224). 1042 bytes result sent to driver
2021-12-08 10:12:33,742 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 72.0 (TID 224) in 2504 ms on localhost (executor driver) (12/12)
2021-12-08 10:12:33,742 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 72.0, whose tasks have all completed, from pool 
2021-12-08 10:12:33,742 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ShuffleMapStage 72 (flatMap at ALS.scala:1653) finished in 2.509 s
2021-12-08 10:12:33,742 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - looking for newly runnable stages
2021-12-08 10:12:33,742 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - running: Set()
2021-12-08 10:12:33,742 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - waiting: Set(ResultStage 73)
2021-12-08 10:12:33,742 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - failed: Set()
2021-12-08 10:12:33,743 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 73 (MapPartitionsRDD[100] at values at ALS.scala:1711), which has no missing parents
2021-12-08 10:12:33,745 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_27 stored as values in memory (estimated size 1299.1 KB, free 1662.7 MB)
2021-12-08 10:12:33,747 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_27_piece0 stored as bytes in memory (estimated size 1110.2 KB, free 1661.6 MB)
2021-12-08 10:12:33,747 [dispatcher-event-loop-4] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_27_piece0 in memory on qb:61292 (size: 1110.2 KB, free: 1666.4 MB)
2021-12-08 10:12:33,747 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 27 from broadcast at DAGScheduler.scala:1039
2021-12-08 10:12:33,748 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 12 missing tasks from ResultStage 73 (MapPartitionsRDD[100] at values at ALS.scala:1711) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11))
2021-12-08 10:12:33,748 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 73.0 with 12 tasks
2021-12-08 10:12:33,748 [dispatcher-event-loop-6] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 73.0 (TID 236, localhost, executor driver, partition 0, PROCESS_LOCAL, 7888 bytes)
2021-12-08 10:12:33,748 [dispatcher-event-loop-6] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 73.0 (TID 237, localhost, executor driver, partition 1, PROCESS_LOCAL, 7888 bytes)
2021-12-08 10:12:33,748 [dispatcher-event-loop-6] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 2.0 in stage 73.0 (TID 238, localhost, executor driver, partition 2, PROCESS_LOCAL, 7888 bytes)
2021-12-08 10:12:33,748 [dispatcher-event-loop-6] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 3.0 in stage 73.0 (TID 239, localhost, executor driver, partition 3, PROCESS_LOCAL, 7888 bytes)
2021-12-08 10:12:33,748 [dispatcher-event-loop-6] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 4.0 in stage 73.0 (TID 240, localhost, executor driver, partition 4, PROCESS_LOCAL, 7888 bytes)
2021-12-08 10:12:33,748 [dispatcher-event-loop-6] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 5.0 in stage 73.0 (TID 241, localhost, executor driver, partition 5, PROCESS_LOCAL, 7888 bytes)
2021-12-08 10:12:33,748 [dispatcher-event-loop-6] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 6.0 in stage 73.0 (TID 242, localhost, executor driver, partition 6, PROCESS_LOCAL, 7888 bytes)
2021-12-08 10:12:33,748 [dispatcher-event-loop-6] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 7.0 in stage 73.0 (TID 243, localhost, executor driver, partition 7, PROCESS_LOCAL, 7888 bytes)
2021-12-08 10:12:33,749 [dispatcher-event-loop-6] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 8.0 in stage 73.0 (TID 244, localhost, executor driver, partition 8, PROCESS_LOCAL, 7888 bytes)
2021-12-08 10:12:33,749 [dispatcher-event-loop-6] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 9.0 in stage 73.0 (TID 245, localhost, executor driver, partition 9, PROCESS_LOCAL, 7888 bytes)
2021-12-08 10:12:33,749 [dispatcher-event-loop-6] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 10.0 in stage 73.0 (TID 246, localhost, executor driver, partition 10, PROCESS_LOCAL, 7888 bytes)
2021-12-08 10:12:33,749 [dispatcher-event-loop-6] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 11.0 in stage 73.0 (TID 247, localhost, executor driver, partition 11, PROCESS_LOCAL, 7888 bytes)
2021-12-08 10:12:33,749 [Executor task launch worker for task 237] INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 73.0 (TID 237)
2021-12-08 10:12:33,749 [Executor task launch worker for task 241] INFO [org.apache.spark.executor.Executor] - Running task 5.0 in stage 73.0 (TID 241)
2021-12-08 10:12:33,749 [Executor task launch worker for task 247] INFO [org.apache.spark.executor.Executor] - Running task 11.0 in stage 73.0 (TID 247)
2021-12-08 10:12:33,749 [Executor task launch worker for task 246] INFO [org.apache.spark.executor.Executor] - Running task 10.0 in stage 73.0 (TID 246)
2021-12-08 10:12:33,749 [Executor task launch worker for task 243] INFO [org.apache.spark.executor.Executor] - Running task 7.0 in stage 73.0 (TID 243)
2021-12-08 10:12:33,749 [Executor task launch worker for task 245] INFO [org.apache.spark.executor.Executor] - Running task 9.0 in stage 73.0 (TID 245)
2021-12-08 10:12:33,749 [Executor task launch worker for task 242] INFO [org.apache.spark.executor.Executor] - Running task 6.0 in stage 73.0 (TID 242)
2021-12-08 10:12:33,749 [Executor task launch worker for task 244] INFO [org.apache.spark.executor.Executor] - Running task 8.0 in stage 73.0 (TID 244)
2021-12-08 10:12:33,749 [Executor task launch worker for task 240] INFO [org.apache.spark.executor.Executor] - Running task 4.0 in stage 73.0 (TID 240)
2021-12-08 10:12:33,749 [Executor task launch worker for task 238] INFO [org.apache.spark.executor.Executor] - Running task 2.0 in stage 73.0 (TID 238)
2021-12-08 10:12:33,749 [Executor task launch worker for task 239] INFO [org.apache.spark.executor.Executor] - Running task 3.0 in stage 73.0 (TID 239)
2021-12-08 10:12:33,749 [Executor task launch worker for task 236] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 73.0 (TID 236)
2021-12-08 10:12:33,752 [Executor task launch worker for task 240] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_26_4 locally
2021-12-08 10:12:33,752 [Executor task launch worker for task 243] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_26_7 locally
2021-12-08 10:12:33,752 [Executor task launch worker for task 238] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_26_2 locally
2021-12-08 10:12:33,752 [Executor task launch worker for task 237] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_26_1 locally
2021-12-08 10:12:33,752 [Executor task launch worker for task 242] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_26_6 locally
2021-12-08 10:12:33,753 [Executor task launch worker for task 243] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 12 non-empty blocks out of 12 blocks
2021-12-08 10:12:33,753 [Executor task launch worker for task 243] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-08 10:12:33,753 [Executor task launch worker for task 237] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 12 non-empty blocks out of 12 blocks
2021-12-08 10:12:33,753 [Executor task launch worker for task 236] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_26_0 locally
2021-12-08 10:12:33,753 [Executor task launch worker for task 242] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 12 non-empty blocks out of 12 blocks
2021-12-08 10:12:33,753 [Executor task launch worker for task 238] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 12 non-empty blocks out of 12 blocks
2021-12-08 10:12:33,753 [Executor task launch worker for task 242] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-08 10:12:33,753 [Executor task launch worker for task 237] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-08 10:12:33,753 [Executor task launch worker for task 239] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_26_3 locally
2021-12-08 10:12:33,753 [Executor task launch worker for task 240] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 12 non-empty blocks out of 12 blocks
2021-12-08 10:12:33,753 [Executor task launch worker for task 241] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_26_5 locally
2021-12-08 10:12:33,753 [Executor task launch worker for task 238] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-08 10:12:33,753 [Executor task launch worker for task 236] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 12 non-empty blocks out of 12 blocks
2021-12-08 10:12:33,753 [Executor task launch worker for task 240] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-08 10:12:33,753 [Executor task launch worker for task 236] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-08 10:12:33,753 [Executor task launch worker for task 239] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 12 non-empty blocks out of 12 blocks
2021-12-08 10:12:33,753 [Executor task launch worker for task 239] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-08 10:12:33,753 [Executor task launch worker for task 241] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 12 non-empty blocks out of 12 blocks
2021-12-08 10:12:33,754 [Executor task launch worker for task 241] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 1 ms
2021-12-08 10:12:33,754 [Executor task launch worker for task 246] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_26_10 locally
2021-12-08 10:12:33,754 [Executor task launch worker for task 244] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_26_8 locally
2021-12-08 10:12:33,754 [Executor task launch worker for task 246] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 12 non-empty blocks out of 12 blocks
2021-12-08 10:12:33,754 [Executor task launch worker for task 246] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-08 10:12:33,754 [Executor task launch worker for task 245] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_26_9 locally
2021-12-08 10:12:33,754 [Executor task launch worker for task 244] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 12 non-empty blocks out of 12 blocks
2021-12-08 10:12:33,754 [Executor task launch worker for task 244] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-08 10:12:33,754 [Executor task launch worker for task 245] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 12 non-empty blocks out of 12 blocks
2021-12-08 10:12:33,754 [Executor task launch worker for task 245] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-08 10:12:33,754 [Executor task launch worker for task 247] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_26_11 locally
2021-12-08 10:12:33,754 [Executor task launch worker for task 247] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 12 non-empty blocks out of 12 blocks
2021-12-08 10:12:33,754 [Executor task launch worker for task 247] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-08 10:12:34,227 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 517
2021-12-08 10:12:34,227 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 481
2021-12-08 10:12:34,227 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 508
2021-12-08 10:12:34,227 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 478
2021-12-08 10:12:34,227 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 519
2021-12-08 10:12:34,228 [dispatcher-event-loop-3] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_25_piece0 on qb:61292 in memory (size: 952.5 KB, free: 1667.4 MB)
2021-12-08 10:12:34,229 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 509
2021-12-08 10:12:34,229 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 480
2021-12-08 10:12:34,229 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 498
2021-12-08 10:12:34,229 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 504
2021-12-08 10:12:34,229 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 516
2021-12-08 10:12:34,229 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 475
2021-12-08 10:12:34,229 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 497
2021-12-08 10:12:34,229 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 510
2021-12-08 10:12:34,229 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 503
2021-12-08 10:12:34,229 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 501
2021-12-08 10:12:34,229 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 514
2021-12-08 10:12:34,229 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 490
2021-12-08 10:12:34,229 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 499
2021-12-08 10:12:34,229 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 491
2021-12-08 10:12:34,229 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 500
2021-12-08 10:12:34,229 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 492
2021-12-08 10:12:34,229 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 521
2021-12-08 10:12:34,229 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 489
2021-12-08 10:12:34,229 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 520
2021-12-08 10:12:34,229 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 523
2021-12-08 10:12:34,230 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 479
2021-12-08 10:12:34,230 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 511
2021-12-08 10:12:34,230 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 502
2021-12-08 10:12:34,230 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 486
2021-12-08 10:12:34,230 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 485
2021-12-08 10:12:34,230 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 493
2021-12-08 10:12:34,230 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 522
2021-12-08 10:12:34,230 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 476
2021-12-08 10:12:34,230 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 495
2021-12-08 10:12:34,230 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 483
2021-12-08 10:12:34,230 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 482
2021-12-08 10:12:34,230 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 505
2021-12-08 10:12:34,230 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 513
2021-12-08 10:12:34,230 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 507
2021-12-08 10:12:34,230 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 477
2021-12-08 10:12:34,230 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 496
2021-12-08 10:12:34,230 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 512
2021-12-08 10:12:34,231 [dispatcher-event-loop-0] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_26_piece0 on qb:61292 in memory (size: 951.5 KB, free: 1668.3 MB)
2021-12-08 10:12:34,231 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 518
2021-12-08 10:12:34,231 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 484
2021-12-08 10:12:34,231 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 494
2021-12-08 10:12:34,231 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 487
2021-12-08 10:12:34,231 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 515
2021-12-08 10:12:34,231 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 488
2021-12-08 10:12:34,231 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 524
2021-12-08 10:12:34,231 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 506
2021-12-08 10:12:54,903 [Executor task launch worker for task 237] INFO [org.apache.spark.storage.memory.MemoryStore] - Block rdd_99_1 stored as values in memory (estimated size 4.0 MB, free 1661.5 MB)
2021-12-08 10:12:54,903 [dispatcher-event-loop-4] INFO [org.apache.spark.storage.BlockManagerInfo] - Added rdd_99_1 in memory on qb:61292 (size: 4.0 MB, free: 1664.3 MB)
2021-12-08 10:12:55,025 [Executor task launch worker for task 237] INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 73.0 (TID 237). 166054 bytes result sent to driver
2021-12-08 10:12:55,034 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 73.0 (TID 237) in 21286 ms on localhost (executor driver) (1/12)
2021-12-08 10:12:55,036 [Executor task launch worker for task 241] INFO [org.apache.spark.storage.memory.MemoryStore] - Block rdd_99_5 stored as values in memory (estimated size 4.0 MB, free 1657.5 MB)
2021-12-08 10:12:55,036 [dispatcher-event-loop-11] INFO [org.apache.spark.storage.BlockManagerInfo] - Added rdd_99_5 in memory on qb:61292 (size: 4.0 MB, free: 1660.3 MB)
2021-12-08 10:12:55,162 [Executor task launch worker for task 241] INFO [org.apache.spark.executor.Executor] - Finished task 5.0 in stage 73.0 (TID 241). 166054 bytes result sent to driver
2021-12-08 10:12:55,170 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 5.0 in stage 73.0 (TID 241) in 21422 ms on localhost (executor driver) (2/12)
2021-12-08 10:12:55,643 [Executor task launch worker for task 236] INFO [org.apache.spark.storage.memory.MemoryStore] - Block rdd_99_0 stored as values in memory (estimated size 4.0 MB, free 1653.5 MB)
2021-12-08 10:12:55,643 [dispatcher-event-loop-2] INFO [org.apache.spark.storage.BlockManagerInfo] - Added rdd_99_0 in memory on qb:61292 (size: 4.0 MB, free: 1656.3 MB)
2021-12-08 10:12:55,720 [Executor task launch worker for task 240] INFO [org.apache.spark.storage.memory.MemoryStore] - Block rdd_99_4 stored as values in memory (estimated size 4.0 MB, free 1649.5 MB)
2021-12-08 10:12:55,721 [dispatcher-event-loop-0] INFO [org.apache.spark.storage.BlockManagerInfo] - Added rdd_99_4 in memory on qb:61292 (size: 4.0 MB, free: 1652.3 MB)
2021-12-08 10:12:55,760 [Executor task launch worker for task 236] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 73.0 (TID 236). 166054 bytes result sent to driver
2021-12-08 10:12:55,761 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 73.0 (TID 236) in 22013 ms on localhost (executor driver) (3/12)
2021-12-08 10:12:55,831 [Executor task launch worker for task 240] INFO [org.apache.spark.executor.Executor] - Finished task 4.0 in stage 73.0 (TID 240). 166054 bytes result sent to driver
2021-12-08 10:12:55,831 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 4.0 in stage 73.0 (TID 240) in 22083 ms on localhost (executor driver) (4/12)
2021-12-08 10:12:55,912 [Executor task launch worker for task 247] INFO [org.apache.spark.storage.memory.MemoryStore] - Block rdd_99_11 stored as values in memory (estimated size 4.0 MB, free 1645.6 MB)
2021-12-08 10:12:55,912 [dispatcher-event-loop-8] INFO [org.apache.spark.storage.BlockManagerInfo] - Added rdd_99_11 in memory on qb:61292 (size: 4.0 MB, free: 1648.4 MB)
2021-12-08 10:12:55,999 [Executor task launch worker for task 247] INFO [org.apache.spark.executor.Executor] - Finished task 11.0 in stage 73.0 (TID 247). 166054 bytes result sent to driver
2021-12-08 10:12:55,999 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 11.0 in stage 73.0 (TID 247) in 22250 ms on localhost (executor driver) (5/12)
2021-12-08 10:12:56,021 [Executor task launch worker for task 244] INFO [org.apache.spark.storage.memory.MemoryStore] - Block rdd_99_8 stored as values in memory (estimated size 4.0 MB, free 1641.6 MB)
2021-12-08 10:12:56,021 [dispatcher-event-loop-4] INFO [org.apache.spark.storage.BlockManagerInfo] - Added rdd_99_8 in memory on qb:61292 (size: 4.0 MB, free: 1644.4 MB)
2021-12-08 10:12:56,102 [Executor task launch worker for task 244] INFO [org.apache.spark.executor.Executor] - Finished task 8.0 in stage 73.0 (TID 244). 166097 bytes result sent to driver
2021-12-08 10:12:56,103 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 8.0 in stage 73.0 (TID 244) in 22355 ms on localhost (executor driver) (6/12)
2021-12-08 10:12:56,291 [Executor task launch worker for task 246] INFO [org.apache.spark.storage.memory.MemoryStore] - Block rdd_99_10 stored as values in memory (estimated size 4.0 MB, free 1637.6 MB)
2021-12-08 10:12:56,291 [dispatcher-event-loop-11] INFO [org.apache.spark.storage.BlockManagerInfo] - Added rdd_99_10 in memory on qb:61292 (size: 4.0 MB, free: 1640.4 MB)
2021-12-08 10:12:56,389 [Executor task launch worker for task 246] INFO [org.apache.spark.executor.Executor] - Finished task 10.0 in stage 73.0 (TID 246). 166097 bytes result sent to driver
2021-12-08 10:12:56,389 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 10.0 in stage 73.0 (TID 246) in 22640 ms on localhost (executor driver) (7/12)
2021-12-08 10:12:56,472 [Executor task launch worker for task 243] INFO [org.apache.spark.storage.memory.MemoryStore] - Block rdd_99_7 stored as values in memory (estimated size 4.0 MB, free 1633.6 MB)
2021-12-08 10:12:56,472 [dispatcher-event-loop-3] INFO [org.apache.spark.storage.BlockManagerInfo] - Added rdd_99_7 in memory on qb:61292 (size: 4.0 MB, free: 1636.4 MB)
2021-12-08 10:12:56,553 [Executor task launch worker for task 243] INFO [org.apache.spark.executor.Executor] - Finished task 7.0 in stage 73.0 (TID 243). 166054 bytes result sent to driver
2021-12-08 10:12:56,553 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 7.0 in stage 73.0 (TID 243) in 22805 ms on localhost (executor driver) (8/12)
2021-12-08 10:12:56,918 [Executor task launch worker for task 245] INFO [org.apache.spark.storage.memory.MemoryStore] - Block rdd_99_9 stored as values in memory (estimated size 4.0 MB, free 1629.6 MB)
2021-12-08 10:12:56,918 [dispatcher-event-loop-2] INFO [org.apache.spark.storage.BlockManagerInfo] - Added rdd_99_9 in memory on qb:61292 (size: 4.0 MB, free: 1632.4 MB)
2021-12-08 10:12:56,981 [Executor task launch worker for task 245] INFO [org.apache.spark.executor.Executor] - Finished task 9.0 in stage 73.0 (TID 245). 166097 bytes result sent to driver
2021-12-08 10:12:56,981 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 9.0 in stage 73.0 (TID 245) in 23232 ms on localhost (executor driver) (9/12)
2021-12-08 10:12:57,122 [Executor task launch worker for task 239] INFO [org.apache.spark.storage.memory.MemoryStore] - Block rdd_99_3 stored as values in memory (estimated size 4.0 MB, free 1625.6 MB)
2021-12-08 10:12:57,122 [dispatcher-event-loop-10] INFO [org.apache.spark.storage.BlockManagerInfo] - Added rdd_99_3 in memory on qb:61292 (size: 4.0 MB, free: 1628.4 MB)
2021-12-08 10:12:57,185 [Executor task launch worker for task 239] INFO [org.apache.spark.executor.Executor] - Finished task 3.0 in stage 73.0 (TID 239). 166054 bytes result sent to driver
2021-12-08 10:12:57,186 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 3.0 in stage 73.0 (TID 239) in 23438 ms on localhost (executor driver) (10/12)
2021-12-08 10:12:57,332 [Executor task launch worker for task 242] INFO [org.apache.spark.storage.memory.MemoryStore] - Block rdd_99_6 stored as values in memory (estimated size 4.0 MB, free 1621.6 MB)
2021-12-08 10:12:57,332 [dispatcher-event-loop-8] INFO [org.apache.spark.storage.BlockManagerInfo] - Added rdd_99_6 in memory on qb:61292 (size: 4.0 MB, free: 1624.4 MB)
2021-12-08 10:12:57,394 [Executor task launch worker for task 242] INFO [org.apache.spark.executor.Executor] - Finished task 6.0 in stage 73.0 (TID 242). 166054 bytes result sent to driver
2021-12-08 10:12:57,394 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 6.0 in stage 73.0 (TID 242) in 23646 ms on localhost (executor driver) (11/12)
2021-12-08 10:12:57,547 [Executor task launch worker for task 238] INFO [org.apache.spark.storage.memory.MemoryStore] - Block rdd_99_2 stored as values in memory (estimated size 4.0 MB, free 1617.6 MB)
2021-12-08 10:12:57,547 [dispatcher-event-loop-4] INFO [org.apache.spark.storage.BlockManagerInfo] - Added rdd_99_2 in memory on qb:61292 (size: 4.0 MB, free: 1620.4 MB)
2021-12-08 10:12:57,610 [Executor task launch worker for task 238] INFO [org.apache.spark.executor.Executor] - Finished task 2.0 in stage 73.0 (TID 238). 166054 bytes result sent to driver
2021-12-08 10:12:57,611 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 2.0 in stage 73.0 (TID 238) in 23863 ms on localhost (executor driver) (12/12)
2021-12-08 10:12:57,611 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 73.0, whose tasks have all completed, from pool 
2021-12-08 10:12:57,611 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 73 (aggregate at ALS.scala:1711) finished in 23.868 s
2021-12-08 10:12:57,611 [main] INFO [org.apache.spark.scheduler.DAGScheduler] - Job 11 finished: aggregate at ALS.scala:1711, took 26.380316 s
2021-12-08 10:12:57,626 [main] INFO [org.apache.spark.rdd.MapPartitionsRDD] - Removing RDD 89 from persistence list
2021-12-08 10:12:57,626 [block-manager-slave-async-thread-pool-2] INFO [org.apache.spark.storage.BlockManager] - Removing RDD 89
2021-12-08 10:12:57,634 [main] INFO [org.apache.spark.SparkContext] - Starting job: aggregate at ALS.scala:1711
2021-12-08 10:12:57,636 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 104 (flatMap at ALS.scala:1653)
2021-12-08 10:12:57,636 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 12 (aggregate at ALS.scala:1711) with 12 output partitions
2021-12-08 10:12:57,636 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 86 (aggregate at ALS.scala:1711)
2021-12-08 10:12:57,636 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 85, ShuffleMapStage 75)
2021-12-08 10:12:57,636 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List(ShuffleMapStage 85)
2021-12-08 10:12:57,637 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ShuffleMapStage 85 (MapPartitionsRDD[104] at flatMap at ALS.scala:1653), which has no missing parents
2021-12-08 10:12:57,639 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_28 stored as values in memory (estimated size 1138.6 KB, free 1749.8 MB)
2021-12-08 10:12:57,641 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_28_piece0 stored as bytes in memory (estimated size 1109.2 KB, free 1748.7 MB)
2021-12-08 10:12:57,642 [dispatcher-event-loop-10] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_28_piece0 in memory on qb:61292 (size: 1109.2 KB, free: 1752.6 MB)
2021-12-08 10:12:57,642 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 28 from broadcast at DAGScheduler.scala:1039
2021-12-08 10:12:57,642 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 12 missing tasks from ShuffleMapStage 85 (MapPartitionsRDD[104] at flatMap at ALS.scala:1653) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11))
2021-12-08 10:12:57,642 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 85.0 with 12 tasks
2021-12-08 10:12:57,642 [dispatcher-event-loop-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 85.0 (TID 248, localhost, executor driver, partition 0, PROCESS_LOCAL, 7928 bytes)
2021-12-08 10:12:57,642 [dispatcher-event-loop-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 85.0 (TID 249, localhost, executor driver, partition 1, PROCESS_LOCAL, 7928 bytes)
2021-12-08 10:12:57,643 [dispatcher-event-loop-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 2.0 in stage 85.0 (TID 250, localhost, executor driver, partition 2, PROCESS_LOCAL, 7928 bytes)
2021-12-08 10:12:57,643 [dispatcher-event-loop-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 3.0 in stage 85.0 (TID 251, localhost, executor driver, partition 3, PROCESS_LOCAL, 7928 bytes)
2021-12-08 10:12:57,643 [dispatcher-event-loop-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 4.0 in stage 85.0 (TID 252, localhost, executor driver, partition 4, PROCESS_LOCAL, 7928 bytes)
2021-12-08 10:12:57,643 [dispatcher-event-loop-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 5.0 in stage 85.0 (TID 253, localhost, executor driver, partition 5, PROCESS_LOCAL, 7928 bytes)
2021-12-08 10:12:57,643 [dispatcher-event-loop-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 6.0 in stage 85.0 (TID 254, localhost, executor driver, partition 6, PROCESS_LOCAL, 7928 bytes)
2021-12-08 10:12:57,643 [dispatcher-event-loop-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 7.0 in stage 85.0 (TID 255, localhost, executor driver, partition 7, PROCESS_LOCAL, 7928 bytes)
2021-12-08 10:12:57,643 [dispatcher-event-loop-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 8.0 in stage 85.0 (TID 256, localhost, executor driver, partition 8, PROCESS_LOCAL, 7928 bytes)
2021-12-08 10:12:57,643 [dispatcher-event-loop-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 9.0 in stage 85.0 (TID 257, localhost, executor driver, partition 9, PROCESS_LOCAL, 7928 bytes)
2021-12-08 10:12:57,643 [dispatcher-event-loop-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 10.0 in stage 85.0 (TID 258, localhost, executor driver, partition 10, PROCESS_LOCAL, 7928 bytes)
2021-12-08 10:12:57,643 [dispatcher-event-loop-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 11.0 in stage 85.0 (TID 259, localhost, executor driver, partition 11, PROCESS_LOCAL, 7928 bytes)
2021-12-08 10:12:57,643 [Executor task launch worker for task 248] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 85.0 (TID 248)
2021-12-08 10:12:57,643 [Executor task launch worker for task 250] INFO [org.apache.spark.executor.Executor] - Running task 2.0 in stage 85.0 (TID 250)
2021-12-08 10:12:57,643 [Executor task launch worker for task 256] INFO [org.apache.spark.executor.Executor] - Running task 8.0 in stage 85.0 (TID 256)
2021-12-08 10:12:57,643 [Executor task launch worker for task 259] INFO [org.apache.spark.executor.Executor] - Running task 11.0 in stage 85.0 (TID 259)
2021-12-08 10:12:57,643 [Executor task launch worker for task 254] INFO [org.apache.spark.executor.Executor] - Running task 6.0 in stage 85.0 (TID 254)
2021-12-08 10:12:57,643 [Executor task launch worker for task 255] INFO [org.apache.spark.executor.Executor] - Running task 7.0 in stage 85.0 (TID 255)
2021-12-08 10:12:57,643 [Executor task launch worker for task 251] INFO [org.apache.spark.executor.Executor] - Running task 3.0 in stage 85.0 (TID 251)
2021-12-08 10:12:57,643 [Executor task launch worker for task 252] INFO [org.apache.spark.executor.Executor] - Running task 4.0 in stage 85.0 (TID 252)
2021-12-08 10:12:57,643 [Executor task launch worker for task 249] INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 85.0 (TID 249)
2021-12-08 10:12:57,643 [Executor task launch worker for task 253] INFO [org.apache.spark.executor.Executor] - Running task 5.0 in stage 85.0 (TID 253)
2021-12-08 10:12:57,643 [Executor task launch worker for task 257] INFO [org.apache.spark.executor.Executor] - Running task 9.0 in stage 85.0 (TID 257)
2021-12-08 10:12:57,643 [Executor task launch worker for task 258] INFO [org.apache.spark.executor.Executor] - Running task 10.0 in stage 85.0 (TID 258)
2021-12-08 10:12:57,646 [Executor task launch worker for task 251] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_27_3 locally
2021-12-08 10:12:57,646 [Executor task launch worker for task 258] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_27_10 locally
2021-12-08 10:12:57,646 [Executor task launch worker for task 250] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_27_2 locally
2021-12-08 10:12:57,646 [Executor task launch worker for task 250] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_99_2 locally
2021-12-08 10:12:57,646 [Executor task launch worker for task 257] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_27_9 locally
2021-12-08 10:12:57,646 [Executor task launch worker for task 255] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_27_7 locally
2021-12-08 10:12:57,646 [Executor task launch worker for task 248] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_27_0 locally
2021-12-08 10:12:57,646 [Executor task launch worker for task 254] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_27_6 locally
2021-12-08 10:12:57,646 [Executor task launch worker for task 251] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_99_3 locally
2021-12-08 10:12:57,646 [Executor task launch worker for task 257] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_99_9 locally
2021-12-08 10:12:57,646 [Executor task launch worker for task 259] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_27_11 locally
2021-12-08 10:12:57,646 [Executor task launch worker for task 255] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_99_7 locally
2021-12-08 10:12:57,646 [Executor task launch worker for task 256] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_27_8 locally
2021-12-08 10:12:57,646 [Executor task launch worker for task 258] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_99_10 locally
2021-12-08 10:12:57,646 [Executor task launch worker for task 248] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_99_0 locally
2021-12-08 10:12:57,646 [Executor task launch worker for task 254] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_99_6 locally
2021-12-08 10:12:57,646 [Executor task launch worker for task 259] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_99_11 locally
2021-12-08 10:12:57,646 [Executor task launch worker for task 256] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_99_8 locally
2021-12-08 10:12:57,647 [Executor task launch worker for task 253] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_27_5 locally
2021-12-08 10:12:57,647 [Executor task launch worker for task 253] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_99_5 locally
2021-12-08 10:12:57,647 [Executor task launch worker for task 249] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_27_1 locally
2021-12-08 10:12:57,647 [Executor task launch worker for task 249] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_99_1 locally
2021-12-08 10:12:57,647 [Executor task launch worker for task 252] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_27_4 locally
2021-12-08 10:12:57,647 [Executor task launch worker for task 252] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_99_4 locally
2021-12-08 10:12:58,578 [Executor task launch worker for task 250] INFO [org.apache.spark.executor.Executor] - Finished task 2.0 in stage 85.0 (TID 250). 999 bytes result sent to driver
2021-12-08 10:12:58,579 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 2.0 in stage 85.0 (TID 250) in 937 ms on localhost (executor driver) (1/12)
2021-12-08 10:12:58,581 [Executor task launch worker for task 257] INFO [org.apache.spark.executor.Executor] - Finished task 9.0 in stage 85.0 (TID 257). 999 bytes result sent to driver
2021-12-08 10:12:58,582 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 9.0 in stage 85.0 (TID 257) in 939 ms on localhost (executor driver) (2/12)
2021-12-08 10:12:58,586 [Executor task launch worker for task 255] INFO [org.apache.spark.executor.Executor] - Finished task 7.0 in stage 85.0 (TID 255). 999 bytes result sent to driver
2021-12-08 10:12:58,586 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 7.0 in stage 85.0 (TID 255) in 943 ms on localhost (executor driver) (3/12)
2021-12-08 10:12:58,588 [Executor task launch worker for task 248] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 85.0 (TID 248). 999 bytes result sent to driver
2021-12-08 10:12:58,588 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 85.0 (TID 248) in 946 ms on localhost (executor driver) (4/12)
2021-12-08 10:12:58,589 [Executor task launch worker for task 253] INFO [org.apache.spark.executor.Executor] - Finished task 5.0 in stage 85.0 (TID 253). 1042 bytes result sent to driver
2021-12-08 10:12:58,589 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 5.0 in stage 85.0 (TID 253) in 946 ms on localhost (executor driver) (5/12)
2021-12-08 10:12:58,608 [Executor task launch worker for task 252] INFO [org.apache.spark.executor.Executor] - Finished task 4.0 in stage 85.0 (TID 252). 999 bytes result sent to driver
2021-12-08 10:12:58,608 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 4.0 in stage 85.0 (TID 252) in 965 ms on localhost (executor driver) (6/12)
2021-12-08 10:12:58,615 [Executor task launch worker for task 254] INFO [org.apache.spark.executor.Executor] - Finished task 6.0 in stage 85.0 (TID 254). 999 bytes result sent to driver
2021-12-08 10:12:58,615 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 6.0 in stage 85.0 (TID 254) in 972 ms on localhost (executor driver) (7/12)
2021-12-08 10:12:58,616 [Executor task launch worker for task 249] INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 85.0 (TID 249). 1042 bytes result sent to driver
2021-12-08 10:12:58,616 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 85.0 (TID 249) in 974 ms on localhost (executor driver) (8/12)
2021-12-08 10:12:58,616 [Executor task launch worker for task 259] INFO [org.apache.spark.executor.Executor] - Finished task 11.0 in stage 85.0 (TID 259). 999 bytes result sent to driver
2021-12-08 10:12:58,617 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 11.0 in stage 85.0 (TID 259) in 974 ms on localhost (executor driver) (9/12)
2021-12-08 10:12:58,692 [Executor task launch worker for task 251] INFO [org.apache.spark.executor.Executor] - Finished task 3.0 in stage 85.0 (TID 251). 999 bytes result sent to driver
2021-12-08 10:12:58,693 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 3.0 in stage 85.0 (TID 251) in 1050 ms on localhost (executor driver) (10/12)
2021-12-08 10:12:58,693 [Executor task launch worker for task 258] INFO [org.apache.spark.executor.Executor] - Finished task 10.0 in stage 85.0 (TID 258). 999 bytes result sent to driver
2021-12-08 10:12:58,693 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 10.0 in stage 85.0 (TID 258) in 1050 ms on localhost (executor driver) (11/12)
2021-12-08 10:12:58,712 [Executor task launch worker for task 256] INFO [org.apache.spark.executor.Executor] - Finished task 8.0 in stage 85.0 (TID 256). 999 bytes result sent to driver
2021-12-08 10:12:58,712 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 8.0 in stage 85.0 (TID 256) in 1069 ms on localhost (executor driver) (12/12)
2021-12-08 10:12:58,712 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 85.0, whose tasks have all completed, from pool 
2021-12-08 10:12:58,712 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ShuffleMapStage 85 (flatMap at ALS.scala:1653) finished in 1.075 s
2021-12-08 10:12:58,712 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - looking for newly runnable stages
2021-12-08 10:12:58,712 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - running: Set()
2021-12-08 10:12:58,712 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - waiting: Set(ResultStage 86)
2021-12-08 10:12:58,712 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - failed: Set()
2021-12-08 10:12:58,713 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 86 (MapPartitionsRDD[110] at values at ALS.scala:1711), which has no missing parents
2021-12-08 10:12:58,715 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_29 stored as values in memory (estimated size 1460.2 KB, free 1747.3 MB)
2021-12-08 10:12:58,718 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_29_piece0 stored as bytes in memory (estimated size 1268.0 KB, free 1746.0 MB)
2021-12-08 10:12:58,719 [dispatcher-event-loop-4] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_29_piece0 in memory on qb:61292 (size: 1268.0 KB, free: 1751.4 MB)
2021-12-08 10:12:58,719 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 29 from broadcast at DAGScheduler.scala:1039
2021-12-08 10:12:58,719 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 12 missing tasks from ResultStage 86 (MapPartitionsRDD[110] at values at ALS.scala:1711) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11))
2021-12-08 10:12:58,719 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 86.0 with 12 tasks
2021-12-08 10:12:58,719 [dispatcher-event-loop-6] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 86.0 (TID 260, localhost, executor driver, partition 0, PROCESS_LOCAL, 7888 bytes)
2021-12-08 10:12:58,720 [dispatcher-event-loop-6] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 86.0 (TID 261, localhost, executor driver, partition 1, PROCESS_LOCAL, 7888 bytes)
2021-12-08 10:12:58,720 [dispatcher-event-loop-6] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 2.0 in stage 86.0 (TID 262, localhost, executor driver, partition 2, PROCESS_LOCAL, 7888 bytes)
2021-12-08 10:12:58,720 [dispatcher-event-loop-6] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 3.0 in stage 86.0 (TID 263, localhost, executor driver, partition 3, PROCESS_LOCAL, 7888 bytes)
2021-12-08 10:12:58,720 [dispatcher-event-loop-6] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 4.0 in stage 86.0 (TID 264, localhost, executor driver, partition 4, PROCESS_LOCAL, 7888 bytes)
2021-12-08 10:12:58,720 [dispatcher-event-loop-6] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 5.0 in stage 86.0 (TID 265, localhost, executor driver, partition 5, PROCESS_LOCAL, 7888 bytes)
2021-12-08 10:12:58,720 [dispatcher-event-loop-6] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 6.0 in stage 86.0 (TID 266, localhost, executor driver, partition 6, PROCESS_LOCAL, 7888 bytes)
2021-12-08 10:12:58,720 [dispatcher-event-loop-6] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 7.0 in stage 86.0 (TID 267, localhost, executor driver, partition 7, PROCESS_LOCAL, 7888 bytes)
2021-12-08 10:12:58,720 [dispatcher-event-loop-6] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 8.0 in stage 86.0 (TID 268, localhost, executor driver, partition 8, PROCESS_LOCAL, 7888 bytes)
2021-12-08 10:12:58,720 [dispatcher-event-loop-6] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 9.0 in stage 86.0 (TID 269, localhost, executor driver, partition 9, PROCESS_LOCAL, 7888 bytes)
2021-12-08 10:12:58,720 [dispatcher-event-loop-6] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 10.0 in stage 86.0 (TID 270, localhost, executor driver, partition 10, PROCESS_LOCAL, 7888 bytes)
2021-12-08 10:12:58,720 [dispatcher-event-loop-6] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 11.0 in stage 86.0 (TID 271, localhost, executor driver, partition 11, PROCESS_LOCAL, 7888 bytes)
2021-12-08 10:12:58,720 [Executor task launch worker for task 261] INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 86.0 (TID 261)
2021-12-08 10:12:58,720 [Executor task launch worker for task 264] INFO [org.apache.spark.executor.Executor] - Running task 4.0 in stage 86.0 (TID 264)
2021-12-08 10:12:58,720 [Executor task launch worker for task 268] INFO [org.apache.spark.executor.Executor] - Running task 8.0 in stage 86.0 (TID 268)
2021-12-08 10:12:58,720 [Executor task launch worker for task 260] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 86.0 (TID 260)
2021-12-08 10:12:58,720 [Executor task launch worker for task 262] INFO [org.apache.spark.executor.Executor] - Running task 2.0 in stage 86.0 (TID 262)
2021-12-08 10:12:58,720 [Executor task launch worker for task 265] INFO [org.apache.spark.executor.Executor] - Running task 5.0 in stage 86.0 (TID 265)
2021-12-08 10:12:58,720 [Executor task launch worker for task 263] INFO [org.apache.spark.executor.Executor] - Running task 3.0 in stage 86.0 (TID 263)
2021-12-08 10:12:58,720 [Executor task launch worker for task 266] INFO [org.apache.spark.executor.Executor] - Running task 6.0 in stage 86.0 (TID 266)
2021-12-08 10:12:58,720 [Executor task launch worker for task 267] INFO [org.apache.spark.executor.Executor] - Running task 7.0 in stage 86.0 (TID 267)
2021-12-08 10:12:58,720 [Executor task launch worker for task 269] INFO [org.apache.spark.executor.Executor] - Running task 9.0 in stage 86.0 (TID 269)
2021-12-08 10:12:58,720 [Executor task launch worker for task 271] INFO [org.apache.spark.executor.Executor] - Running task 11.0 in stage 86.0 (TID 271)
2021-12-08 10:12:58,720 [Executor task launch worker for task 270] INFO [org.apache.spark.executor.Executor] - Running task 10.0 in stage 86.0 (TID 270)
2021-12-08 10:12:58,723 [Executor task launch worker for task 261] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_21_1 locally
2021-12-08 10:12:58,723 [Executor task launch worker for task 269] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_21_9 locally
2021-12-08 10:12:58,723 [Executor task launch worker for task 260] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_21_0 locally
2021-12-08 10:12:58,724 [Executor task launch worker for task 263] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_21_3 locally
2021-12-08 10:12:58,724 [Executor task launch worker for task 268] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_21_8 locally
2021-12-08 10:12:58,724 [Executor task launch worker for task 261] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 12 non-empty blocks out of 12 blocks
2021-12-08 10:12:58,724 [Executor task launch worker for task 261] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-08 10:12:58,724 [Executor task launch worker for task 262] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_21_2 locally
2021-12-08 10:12:58,724 [Executor task launch worker for task 269] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 12 non-empty blocks out of 12 blocks
2021-12-08 10:12:58,724 [Executor task launch worker for task 267] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_21_7 locally
2021-12-08 10:12:58,724 [Executor task launch worker for task 269] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-08 10:12:58,724 [Executor task launch worker for task 268] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 12 non-empty blocks out of 12 blocks
2021-12-08 10:12:58,724 [Executor task launch worker for task 263] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 12 non-empty blocks out of 12 blocks
2021-12-08 10:12:58,724 [Executor task launch worker for task 263] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-08 10:12:58,724 [Executor task launch worker for task 268] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-08 10:12:58,724 [Executor task launch worker for task 270] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_21_10 locally
2021-12-08 10:12:58,724 [Executor task launch worker for task 262] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 12 non-empty blocks out of 12 blocks
2021-12-08 10:12:58,724 [Executor task launch worker for task 271] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_21_11 locally
2021-12-08 10:12:58,724 [Executor task launch worker for task 260] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 12 non-empty blocks out of 12 blocks
2021-12-08 10:12:58,724 [Executor task launch worker for task 265] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_21_5 locally
2021-12-08 10:12:58,724 [Executor task launch worker for task 260] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-08 10:12:58,724 [Executor task launch worker for task 270] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 12 non-empty blocks out of 12 blocks
2021-12-08 10:12:58,724 [Executor task launch worker for task 262] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-08 10:12:58,724 [Executor task launch worker for task 270] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-08 10:12:58,724 [Executor task launch worker for task 267] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 12 non-empty blocks out of 12 blocks
2021-12-08 10:12:58,724 [Executor task launch worker for task 271] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 12 non-empty blocks out of 12 blocks
2021-12-08 10:12:58,724 [Executor task launch worker for task 271] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-08 10:12:58,724 [Executor task launch worker for task 267] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-08 10:12:58,724 [Executor task launch worker for task 265] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 12 non-empty blocks out of 12 blocks
2021-12-08 10:12:58,724 [Executor task launch worker for task 265] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-08 10:12:58,725 [Executor task launch worker for task 266] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_21_6 locally
2021-12-08 10:12:58,725 [Executor task launch worker for task 264] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_21_4 locally
2021-12-08 10:12:58,725 [Executor task launch worker for task 266] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 12 non-empty blocks out of 12 blocks
2021-12-08 10:12:58,725 [Executor task launch worker for task 266] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-08 10:12:58,725 [Executor task launch worker for task 264] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 12 non-empty blocks out of 12 blocks
2021-12-08 10:12:58,725 [Executor task launch worker for task 264] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-08 10:12:58,851 [dispatcher-event-loop-2] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_28_piece0 on qb:61292 in memory (size: 1109.2 KB, free: 1752.5 MB)
2021-12-08 10:12:59,135 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 571
2021-12-08 10:12:59,135 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 528
2021-12-08 10:12:59,135 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 550
2021-12-08 10:12:59,135 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 529
2021-12-08 10:12:59,135 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 526
2021-12-08 10:12:59,135 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 537
2021-12-08 10:12:59,135 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 558
2021-12-08 10:12:59,135 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 547
2021-12-08 10:12:59,135 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 530
2021-12-08 10:12:59,135 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 557
2021-12-08 10:12:59,135 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 555
2021-12-08 10:12:59,135 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 566
2021-12-08 10:12:59,135 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 553
2021-12-08 10:12:59,135 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 567
2021-12-08 10:12:59,135 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 561
2021-12-08 10:12:59,135 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 535
2021-12-08 10:12:59,135 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 532
2021-12-08 10:12:59,135 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 562
2021-12-08 10:12:59,135 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 556
2021-12-08 10:12:59,135 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 525
2021-12-08 10:12:59,135 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 527
2021-12-08 10:12:59,135 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 565
2021-12-08 10:12:59,135 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 546
2021-12-08 10:12:59,135 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 549
2021-12-08 10:12:59,135 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 573
2021-12-08 10:12:59,135 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 536
2021-12-08 10:12:59,135 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 563
2021-12-08 10:12:59,135 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 540
2021-12-08 10:12:59,135 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 560
2021-12-08 10:12:59,135 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 542
2021-12-08 10:12:59,135 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 564
2021-12-08 10:12:59,135 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 552
2021-12-08 10:12:59,135 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 531
2021-12-08 10:12:59,135 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 569
2021-12-08 10:12:59,135 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 534
2021-12-08 10:12:59,135 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 533
2021-12-08 10:12:59,135 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 574
2021-12-08 10:12:59,135 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 570
2021-12-08 10:12:59,135 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 548
2021-12-08 10:12:59,135 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 572
2021-12-08 10:12:59,135 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 543
2021-12-08 10:12:59,136 [dispatcher-event-loop-1] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_27_piece0 on qb:61292 in memory (size: 1110.2 KB, free: 1753.5 MB)
2021-12-08 10:12:59,137 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 541
2021-12-08 10:12:59,137 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 559
2021-12-08 10:12:59,137 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 551
2021-12-08 10:12:59,137 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 544
2021-12-08 10:12:59,137 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 539
2021-12-08 10:12:59,137 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 538
2021-12-08 10:12:59,137 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 554
2021-12-08 10:12:59,137 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 545
2021-12-08 10:12:59,137 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 568
2021-12-08 10:13:35,775 [Executor task launch worker for task 262] INFO [org.apache.spark.storage.memory.MemoryStore] - Block rdd_109_2 stored as values in memory (estimated size 11.1 MB, free 1739.5 MB)
2021-12-08 10:13:35,775 [dispatcher-event-loop-0] INFO [org.apache.spark.storage.BlockManagerInfo] - Added rdd_109_2 in memory on qb:61292 (size: 11.1 MB, free: 1742.4 MB)
2021-12-08 10:13:35,887 [Executor task launch worker for task 264] INFO [org.apache.spark.storage.memory.MemoryStore] - Block rdd_109_4 stored as values in memory (estimated size 11.1 MB, free 1728.4 MB)
2021-12-08 10:13:35,887 [dispatcher-event-loop-5] INFO [org.apache.spark.storage.BlockManagerInfo] - Added rdd_109_4 in memory on qb:61292 (size: 11.1 MB, free: 1731.3 MB)
2021-12-08 10:13:35,911 [Executor task launch worker for task 265] INFO [org.apache.spark.storage.memory.MemoryStore] - Block rdd_109_5 stored as values in memory (estimated size 11.1 MB, free 1717.3 MB)
2021-12-08 10:13:35,911 [dispatcher-event-loop-10] INFO [org.apache.spark.storage.BlockManagerInfo] - Added rdd_109_5 in memory on qb:61292 (size: 11.1 MB, free: 1720.2 MB)
2021-12-08 10:13:35,919 [Executor task launch worker for task 266] INFO [org.apache.spark.storage.memory.MemoryStore] - Block rdd_109_6 stored as values in memory (estimated size 11.1 MB, free 1706.2 MB)
2021-12-08 10:13:35,919 [dispatcher-event-loop-1] INFO [org.apache.spark.storage.BlockManagerInfo] - Added rdd_109_6 in memory on qb:61292 (size: 11.1 MB, free: 1709.1 MB)
2021-12-08 10:13:36,004 [Executor task launch worker for task 263] INFO [org.apache.spark.storage.memory.MemoryStore] - Block rdd_109_3 stored as values in memory (estimated size 11.1 MB, free 1695.1 MB)
2021-12-08 10:13:36,005 [dispatcher-event-loop-7] INFO [org.apache.spark.storage.BlockManagerInfo] - Added rdd_109_3 in memory on qb:61292 (size: 11.1 MB, free: 1698.0 MB)
2021-12-08 10:13:36,019 [Executor task launch worker for task 271] INFO [org.apache.spark.storage.memory.MemoryStore] - Block rdd_109_11 stored as values in memory (estimated size 11.1 MB, free 1684.0 MB)
2021-12-08 10:13:36,019 [dispatcher-event-loop-4] INFO [org.apache.spark.storage.BlockManagerInfo] - Added rdd_109_11 in memory on qb:61292 (size: 11.1 MB, free: 1686.9 MB)
2021-12-08 10:13:36,068 [Executor task launch worker for task 269] INFO [org.apache.spark.storage.memory.MemoryStore] - Block rdd_109_9 stored as values in memory (estimated size 11.1 MB, free 1672.8 MB)
2021-12-08 10:13:36,069 [dispatcher-event-loop-11] INFO [org.apache.spark.storage.BlockManagerInfo] - Added rdd_109_9 in memory on qb:61292 (size: 11.1 MB, free: 1675.8 MB)
2021-12-08 10:13:36,121 [Executor task launch worker for task 268] INFO [org.apache.spark.storage.memory.MemoryStore] - Block rdd_109_8 stored as values in memory (estimated size 11.1 MB, free 1661.7 MB)
2021-12-08 10:13:36,121 [dispatcher-event-loop-6] INFO [org.apache.spark.storage.BlockManagerInfo] - Added rdd_109_8 in memory on qb:61292 (size: 11.1 MB, free: 1664.7 MB)
2021-12-08 10:13:36,140 [Executor task launch worker for task 261] INFO [org.apache.spark.storage.memory.MemoryStore] - Block rdd_109_1 stored as values in memory (estimated size 11.1 MB, free 1650.6 MB)
2021-12-08 10:13:36,140 [dispatcher-event-loop-8] INFO [org.apache.spark.storage.BlockManagerInfo] - Added rdd_109_1 in memory on qb:61292 (size: 11.1 MB, free: 1653.6 MB)
2021-12-08 10:13:36,150 [Executor task launch worker for task 262] INFO [org.apache.spark.executor.Executor] - Finished task 2.0 in stage 86.0 (TID 262). 166054 bytes result sent to driver
2021-12-08 10:13:36,151 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 2.0 in stage 86.0 (TID 262) in 37431 ms on localhost (executor driver) (1/12)
2021-12-08 10:13:36,240 [Executor task launch worker for task 264] INFO [org.apache.spark.executor.Executor] - Finished task 4.0 in stage 86.0 (TID 264). 166097 bytes result sent to driver
2021-12-08 10:13:36,240 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 4.0 in stage 86.0 (TID 264) in 37520 ms on localhost (executor driver) (2/12)
2021-12-08 10:13:36,276 [Executor task launch worker for task 266] INFO [org.apache.spark.executor.Executor] - Finished task 6.0 in stage 86.0 (TID 266). 166097 bytes result sent to driver
2021-12-08 10:13:36,277 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 6.0 in stage 86.0 (TID 266) in 37557 ms on localhost (executor driver) (3/12)
2021-12-08 10:13:36,288 [Executor task launch worker for task 265] INFO [org.apache.spark.executor.Executor] - Finished task 5.0 in stage 86.0 (TID 265). 166054 bytes result sent to driver
2021-12-08 10:13:36,289 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 5.0 in stage 86.0 (TID 265) in 37569 ms on localhost (executor driver) (4/12)
2021-12-08 10:13:36,321 [Executor task launch worker for task 260] INFO [org.apache.spark.storage.memory.MemoryStore] - Block rdd_109_0 stored as values in memory (estimated size 11.1 MB, free 1639.5 MB)
2021-12-08 10:13:36,321 [dispatcher-event-loop-5] INFO [org.apache.spark.storage.BlockManagerInfo] - Added rdd_109_0 in memory on qb:61292 (size: 11.1 MB, free: 1642.5 MB)
2021-12-08 10:13:36,334 [Executor task launch worker for task 263] INFO [org.apache.spark.executor.Executor] - Finished task 3.0 in stage 86.0 (TID 263). 166097 bytes result sent to driver
2021-12-08 10:13:36,334 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 3.0 in stage 86.0 (TID 263) in 37614 ms on localhost (executor driver) (5/12)
2021-12-08 10:13:36,340 [Executor task launch worker for task 271] INFO [org.apache.spark.executor.Executor] - Finished task 11.0 in stage 86.0 (TID 271). 166054 bytes result sent to driver
2021-12-08 10:13:36,340 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 11.0 in stage 86.0 (TID 271) in 37620 ms on localhost (executor driver) (6/12)
2021-12-08 10:13:36,359 [Executor task launch worker for task 269] INFO [org.apache.spark.executor.Executor] - Finished task 9.0 in stage 86.0 (TID 269). 166097 bytes result sent to driver
2021-12-08 10:13:36,360 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 9.0 in stage 86.0 (TID 269) in 37640 ms on localhost (executor driver) (7/12)
2021-12-08 10:13:36,403 [Executor task launch worker for task 268] INFO [org.apache.spark.executor.Executor] - Finished task 8.0 in stage 86.0 (TID 268). 166097 bytes result sent to driver
2021-12-08 10:13:36,404 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 8.0 in stage 86.0 (TID 268) in 37684 ms on localhost (executor driver) (8/12)
2021-12-08 10:13:36,413 [Executor task launch worker for task 261] INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 86.0 (TID 261). 166054 bytes result sent to driver
2021-12-08 10:13:36,413 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 86.0 (TID 261) in 37694 ms on localhost (executor driver) (9/12)
2021-12-08 10:13:36,447 [Executor task launch worker for task 267] INFO [org.apache.spark.storage.memory.MemoryStore] - Block rdd_109_7 stored as values in memory (estimated size 11.1 MB, free 1628.4 MB)
2021-12-08 10:13:36,447 [dispatcher-event-loop-6] INFO [org.apache.spark.storage.BlockManagerInfo] - Added rdd_109_7 in memory on qb:61292 (size: 11.1 MB, free: 1631.4 MB)
2021-12-08 10:13:36,493 [Executor task launch worker for task 270] INFO [org.apache.spark.storage.memory.MemoryStore] - Block rdd_109_10 stored as values in memory (estimated size 11.1 MB, free 1617.3 MB)
2021-12-08 10:13:36,493 [dispatcher-event-loop-8] INFO [org.apache.spark.storage.BlockManagerInfo] - Added rdd_109_10 in memory on qb:61292 (size: 11.1 MB, free: 1620.3 MB)
2021-12-08 10:13:36,517 [Executor task launch worker for task 260] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 86.0 (TID 260). 166054 bytes result sent to driver
2021-12-08 10:13:36,518 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 86.0 (TID 260) in 37799 ms on localhost (executor driver) (10/12)
2021-12-08 10:13:36,638 [Executor task launch worker for task 267] INFO [org.apache.spark.executor.Executor] - Finished task 7.0 in stage 86.0 (TID 267). 166054 bytes result sent to driver
2021-12-08 10:13:36,638 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 7.0 in stage 86.0 (TID 267) in 37918 ms on localhost (executor driver) (11/12)
2021-12-08 10:13:36,678 [Executor task launch worker for task 270] INFO [org.apache.spark.executor.Executor] - Finished task 10.0 in stage 86.0 (TID 270). 166054 bytes result sent to driver
2021-12-08 10:13:36,678 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 10.0 in stage 86.0 (TID 270) in 37958 ms on localhost (executor driver) (12/12)
2021-12-08 10:13:36,678 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 86.0, whose tasks have all completed, from pool 
2021-12-08 10:13:36,678 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 86 (aggregate at ALS.scala:1711) finished in 37.965 s
2021-12-08 10:13:36,678 [main] INFO [org.apache.spark.scheduler.DAGScheduler] - Job 12 finished: aggregate at ALS.scala:1711, took 39.044268 s
2021-12-08 10:13:36,693 [main] INFO [org.apache.spark.rdd.MapPartitionsRDD] - Removing RDD 99 from persistence list
2021-12-08 10:13:36,693 [block-manager-slave-async-thread-pool-0] INFO [org.apache.spark.storage.BlockManager] - Removing RDD 99
2021-12-08 10:13:36,699 [main] INFO [org.apache.spark.SparkContext] - Starting job: aggregate at ALS.scala:1711
2021-12-08 10:13:36,700 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 114 (flatMap at ALS.scala:1653)
2021-12-08 10:13:36,700 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 13 (aggregate at ALS.scala:1711) with 12 output partitions
2021-12-08 10:13:36,701 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 100 (aggregate at ALS.scala:1711)
2021-12-08 10:13:36,701 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 99, ShuffleMapStage 91)
2021-12-08 10:13:36,701 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List(ShuffleMapStage 99)
2021-12-08 10:13:36,701 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ShuffleMapStage 99 (MapPartitionsRDD[114] at flatMap at ALS.scala:1653), which has no missing parents
2021-12-08 10:13:36,703 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_30 stored as values in memory (estimated size 1299.8 KB, free 1663.9 MB)
2021-12-08 10:13:36,706 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_30_piece0 stored as bytes in memory (estimated size 1266.9 KB, free 1662.7 MB)
2021-12-08 10:13:36,706 [dispatcher-event-loop-11] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_30_piece0 in memory on qb:61292 (size: 1266.9 KB, free: 1666.9 MB)
2021-12-08 10:13:36,706 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 30 from broadcast at DAGScheduler.scala:1039
2021-12-08 10:13:36,706 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 12 missing tasks from ShuffleMapStage 99 (MapPartitionsRDD[114] at flatMap at ALS.scala:1653) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11))
2021-12-08 10:13:36,706 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 99.0 with 12 tasks
2021-12-08 10:13:36,707 [dispatcher-event-loop-6] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 99.0 (TID 272, localhost, executor driver, partition 0, PROCESS_LOCAL, 7928 bytes)
2021-12-08 10:13:36,707 [dispatcher-event-loop-6] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 99.0 (TID 273, localhost, executor driver, partition 1, PROCESS_LOCAL, 7928 bytes)
2021-12-08 10:13:36,707 [dispatcher-event-loop-6] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 2.0 in stage 99.0 (TID 274, localhost, executor driver, partition 2, PROCESS_LOCAL, 7928 bytes)
2021-12-08 10:13:36,707 [dispatcher-event-loop-6] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 3.0 in stage 99.0 (TID 275, localhost, executor driver, partition 3, PROCESS_LOCAL, 7928 bytes)
2021-12-08 10:13:36,707 [dispatcher-event-loop-6] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 4.0 in stage 99.0 (TID 276, localhost, executor driver, partition 4, PROCESS_LOCAL, 7928 bytes)
2021-12-08 10:13:36,707 [dispatcher-event-loop-6] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 5.0 in stage 99.0 (TID 277, localhost, executor driver, partition 5, PROCESS_LOCAL, 7928 bytes)
2021-12-08 10:13:36,707 [dispatcher-event-loop-6] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 6.0 in stage 99.0 (TID 278, localhost, executor driver, partition 6, PROCESS_LOCAL, 7928 bytes)
2021-12-08 10:13:36,707 [dispatcher-event-loop-6] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 7.0 in stage 99.0 (TID 279, localhost, executor driver, partition 7, PROCESS_LOCAL, 7928 bytes)
2021-12-08 10:13:36,707 [dispatcher-event-loop-6] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 8.0 in stage 99.0 (TID 280, localhost, executor driver, partition 8, PROCESS_LOCAL, 7928 bytes)
2021-12-08 10:13:36,707 [dispatcher-event-loop-6] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 9.0 in stage 99.0 (TID 281, localhost, executor driver, partition 9, PROCESS_LOCAL, 7928 bytes)
2021-12-08 10:13:36,707 [dispatcher-event-loop-6] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 10.0 in stage 99.0 (TID 282, localhost, executor driver, partition 10, PROCESS_LOCAL, 7928 bytes)
2021-12-08 10:13:36,707 [dispatcher-event-loop-6] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 11.0 in stage 99.0 (TID 283, localhost, executor driver, partition 11, PROCESS_LOCAL, 7928 bytes)
2021-12-08 10:13:36,707 [Executor task launch worker for task 274] INFO [org.apache.spark.executor.Executor] - Running task 2.0 in stage 99.0 (TID 274)
2021-12-08 10:13:36,707 [Executor task launch worker for task 272] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 99.0 (TID 272)
2021-12-08 10:13:36,707 [Executor task launch worker for task 277] INFO [org.apache.spark.executor.Executor] - Running task 5.0 in stage 99.0 (TID 277)
2021-12-08 10:13:36,707 [Executor task launch worker for task 275] INFO [org.apache.spark.executor.Executor] - Running task 3.0 in stage 99.0 (TID 275)
2021-12-08 10:13:36,707 [Executor task launch worker for task 278] INFO [org.apache.spark.executor.Executor] - Running task 6.0 in stage 99.0 (TID 278)
2021-12-08 10:13:36,707 [Executor task launch worker for task 279] INFO [org.apache.spark.executor.Executor] - Running task 7.0 in stage 99.0 (TID 279)
2021-12-08 10:13:36,707 [Executor task launch worker for task 280] INFO [org.apache.spark.executor.Executor] - Running task 8.0 in stage 99.0 (TID 280)
2021-12-08 10:13:36,707 [Executor task launch worker for task 276] INFO [org.apache.spark.executor.Executor] - Running task 4.0 in stage 99.0 (TID 276)
2021-12-08 10:13:36,707 [Executor task launch worker for task 281] INFO [org.apache.spark.executor.Executor] - Running task 9.0 in stage 99.0 (TID 281)
2021-12-08 10:13:36,707 [Executor task launch worker for task 273] INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 99.0 (TID 273)
2021-12-08 10:13:36,707 [Executor task launch worker for task 282] INFO [org.apache.spark.executor.Executor] - Running task 10.0 in stage 99.0 (TID 282)
2021-12-08 10:13:36,707 [Executor task launch worker for task 283] INFO [org.apache.spark.executor.Executor] - Running task 11.0 in stage 99.0 (TID 283)
2021-12-08 10:13:36,710 [Executor task launch worker for task 283] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_22_11 locally
2021-12-08 10:13:36,710 [Executor task launch worker for task 279] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_22_7 locally
2021-12-08 10:13:36,710 [Executor task launch worker for task 280] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_22_8 locally
2021-12-08 10:13:36,710 [Executor task launch worker for task 282] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_22_10 locally
2021-12-08 10:13:36,710 [Executor task launch worker for task 282] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_109_10 locally
2021-12-08 10:13:36,711 [Executor task launch worker for task 277] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_22_5 locally
2021-12-08 10:13:36,711 [Executor task launch worker for task 277] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_109_5 locally
2021-12-08 10:13:36,711 [Executor task launch worker for task 281] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_22_9 locally
2021-12-08 10:13:36,710 [Executor task launch worker for task 278] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_22_6 locally
2021-12-08 10:13:36,711 [Executor task launch worker for task 281] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_109_9 locally
2021-12-08 10:13:36,711 [Executor task launch worker for task 276] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_22_4 locally
2021-12-08 10:13:36,711 [Executor task launch worker for task 275] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_22_3 locally
2021-12-08 10:13:36,711 [Executor task launch worker for task 280] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_109_8 locally
2021-12-08 10:13:36,711 [Executor task launch worker for task 275] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_109_3 locally
2021-12-08 10:13:36,710 [Executor task launch worker for task 279] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_109_7 locally
2021-12-08 10:13:36,710 [Executor task launch worker for task 283] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_109_11 locally
2021-12-08 10:13:36,712 [Executor task launch worker for task 272] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_22_0 locally
2021-12-08 10:13:36,712 [Executor task launch worker for task 276] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_109_4 locally
2021-12-08 10:13:36,712 [Executor task launch worker for task 278] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_109_6 locally
2021-12-08 10:13:36,714 [Executor task launch worker for task 273] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_22_1 locally
2021-12-08 10:13:36,714 [Executor task launch worker for task 273] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_109_1 locally
2021-12-08 10:13:36,715 [Executor task launch worker for task 272] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_109_0 locally
2021-12-08 10:13:36,712 [Executor task launch worker for task 274] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_22_2 locally
2021-12-08 10:13:36,715 [Executor task launch worker for task 274] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_109_2 locally
2021-12-08 10:13:38,464 [Executor task launch worker for task 274] INFO [org.apache.spark.executor.Executor] - Finished task 2.0 in stage 99.0 (TID 274). 999 bytes result sent to driver
2021-12-08 10:13:38,465 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 2.0 in stage 99.0 (TID 274) in 1758 ms on localhost (executor driver) (1/12)
2021-12-08 10:13:38,489 [Executor task launch worker for task 275] INFO [org.apache.spark.executor.Executor] - Finished task 3.0 in stage 99.0 (TID 275). 1042 bytes result sent to driver
2021-12-08 10:13:38,490 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 3.0 in stage 99.0 (TID 275) in 1783 ms on localhost (executor driver) (2/12)
2021-12-08 10:13:38,511 [Executor task launch worker for task 283] INFO [org.apache.spark.executor.Executor] - Finished task 11.0 in stage 99.0 (TID 283). 1042 bytes result sent to driver
2021-12-08 10:13:38,511 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 11.0 in stage 99.0 (TID 283) in 1804 ms on localhost (executor driver) (3/12)
2021-12-08 10:13:38,569 [Executor task launch worker for task 272] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 99.0 (TID 272). 999 bytes result sent to driver
2021-12-08 10:13:38,569 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 99.0 (TID 272) in 1863 ms on localhost (executor driver) (4/12)
2021-12-08 10:13:38,625 [Executor task launch worker for task 279] INFO [org.apache.spark.executor.Executor] - Finished task 7.0 in stage 99.0 (TID 279). 1042 bytes result sent to driver
2021-12-08 10:13:38,625 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 7.0 in stage 99.0 (TID 279) in 1918 ms on localhost (executor driver) (5/12)
2021-12-08 10:13:38,626 [Executor task launch worker for task 282] INFO [org.apache.spark.executor.Executor] - Finished task 10.0 in stage 99.0 (TID 282). 1042 bytes result sent to driver
2021-12-08 10:13:38,626 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 10.0 in stage 99.0 (TID 282) in 1919 ms on localhost (executor driver) (6/12)
2021-12-08 10:13:38,690 [Executor task launch worker for task 277] INFO [org.apache.spark.executor.Executor] - Finished task 5.0 in stage 99.0 (TID 277). 1042 bytes result sent to driver
2021-12-08 10:13:38,690 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 5.0 in stage 99.0 (TID 277) in 1983 ms on localhost (executor driver) (7/12)
2021-12-08 10:13:38,691 [Executor task launch worker for task 276] INFO [org.apache.spark.executor.Executor] - Finished task 4.0 in stage 99.0 (TID 276). 1042 bytes result sent to driver
2021-12-08 10:13:38,691 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 4.0 in stage 99.0 (TID 276) in 1984 ms on localhost (executor driver) (8/12)
2021-12-08 10:13:38,885 [Executor task launch worker for task 273] INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 99.0 (TID 273). 1042 bytes result sent to driver
2021-12-08 10:13:38,886 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 99.0 (TID 273) in 2179 ms on localhost (executor driver) (9/12)
2021-12-08 10:13:38,887 [Executor task launch worker for task 280] INFO [org.apache.spark.executor.Executor] - Finished task 8.0 in stage 99.0 (TID 280). 1042 bytes result sent to driver
2021-12-08 10:13:38,887 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 8.0 in stage 99.0 (TID 280) in 2180 ms on localhost (executor driver) (10/12)
2021-12-08 10:13:38,887 [Executor task launch worker for task 281] INFO [org.apache.spark.executor.Executor] - Finished task 9.0 in stage 99.0 (TID 281). 1042 bytes result sent to driver
2021-12-08 10:13:38,888 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 9.0 in stage 99.0 (TID 281) in 2181 ms on localhost (executor driver) (11/12)
2021-12-08 10:13:38,888 [Executor task launch worker for task 278] INFO [org.apache.spark.executor.Executor] - Finished task 6.0 in stage 99.0 (TID 278). 1042 bytes result sent to driver
2021-12-08 10:13:38,888 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 6.0 in stage 99.0 (TID 278) in 2181 ms on localhost (executor driver) (12/12)
2021-12-08 10:13:38,888 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 99.0, whose tasks have all completed, from pool 
2021-12-08 10:13:38,889 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ShuffleMapStage 99 (flatMap at ALS.scala:1653) finished in 2.188 s
2021-12-08 10:13:38,889 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - looking for newly runnable stages
2021-12-08 10:13:38,889 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - running: Set()
2021-12-08 10:13:38,889 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - waiting: Set(ResultStage 100)
2021-12-08 10:13:38,889 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - failed: Set()
2021-12-08 10:13:38,889 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 100 (MapPartitionsRDD[120] at values at ALS.scala:1711), which has no missing parents
2021-12-08 10:13:38,891 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_31 stored as values in memory (estimated size 1621.3 KB, free 1661.1 MB)
2021-12-08 10:13:38,894 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_31_piece0 stored as bytes in memory (estimated size 1425.7 KB, free 1659.7 MB)
2021-12-08 10:13:38,894 [dispatcher-event-loop-9] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_31_piece0 in memory on qb:61292 (size: 1425.7 KB, free: 1665.5 MB)
2021-12-08 10:13:38,894 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 31 from broadcast at DAGScheduler.scala:1039
2021-12-08 10:13:38,894 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 12 missing tasks from ResultStage 100 (MapPartitionsRDD[120] at values at ALS.scala:1711) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11))
2021-12-08 10:13:38,894 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 100.0 with 12 tasks
2021-12-08 10:13:38,894 [dispatcher-event-loop-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 100.0 (TID 284, localhost, executor driver, partition 0, PROCESS_LOCAL, 7888 bytes)
2021-12-08 10:13:38,895 [dispatcher-event-loop-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 100.0 (TID 285, localhost, executor driver, partition 1, PROCESS_LOCAL, 7888 bytes)
2021-12-08 10:13:38,895 [dispatcher-event-loop-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 2.0 in stage 100.0 (TID 286, localhost, executor driver, partition 2, PROCESS_LOCAL, 7888 bytes)
2021-12-08 10:13:38,895 [dispatcher-event-loop-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 3.0 in stage 100.0 (TID 287, localhost, executor driver, partition 3, PROCESS_LOCAL, 7888 bytes)
2021-12-08 10:13:38,895 [dispatcher-event-loop-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 4.0 in stage 100.0 (TID 288, localhost, executor driver, partition 4, PROCESS_LOCAL, 7888 bytes)
2021-12-08 10:13:38,895 [dispatcher-event-loop-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 5.0 in stage 100.0 (TID 289, localhost, executor driver, partition 5, PROCESS_LOCAL, 7888 bytes)
2021-12-08 10:13:38,895 [dispatcher-event-loop-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 6.0 in stage 100.0 (TID 290, localhost, executor driver, partition 6, PROCESS_LOCAL, 7888 bytes)
2021-12-08 10:13:38,895 [dispatcher-event-loop-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 7.0 in stage 100.0 (TID 291, localhost, executor driver, partition 7, PROCESS_LOCAL, 7888 bytes)
2021-12-08 10:13:38,895 [dispatcher-event-loop-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 8.0 in stage 100.0 (TID 292, localhost, executor driver, partition 8, PROCESS_LOCAL, 7888 bytes)
2021-12-08 10:13:38,895 [dispatcher-event-loop-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 9.0 in stage 100.0 (TID 293, localhost, executor driver, partition 9, PROCESS_LOCAL, 7888 bytes)
2021-12-08 10:13:38,895 [dispatcher-event-loop-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 10.0 in stage 100.0 (TID 294, localhost, executor driver, partition 10, PROCESS_LOCAL, 7888 bytes)
2021-12-08 10:13:38,895 [dispatcher-event-loop-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 11.0 in stage 100.0 (TID 295, localhost, executor driver, partition 11, PROCESS_LOCAL, 7888 bytes)
2021-12-08 10:13:38,895 [Executor task launch worker for task 284] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 100.0 (TID 284)
2021-12-08 10:13:38,895 [Executor task launch worker for task 287] INFO [org.apache.spark.executor.Executor] - Running task 3.0 in stage 100.0 (TID 287)
2021-12-08 10:13:38,895 [Executor task launch worker for task 293] INFO [org.apache.spark.executor.Executor] - Running task 9.0 in stage 100.0 (TID 293)
2021-12-08 10:13:38,895 [Executor task launch worker for task 291] INFO [org.apache.spark.executor.Executor] - Running task 7.0 in stage 100.0 (TID 291)
2021-12-08 10:13:38,895 [Executor task launch worker for task 292] INFO [org.apache.spark.executor.Executor] - Running task 8.0 in stage 100.0 (TID 292)
2021-12-08 10:13:38,895 [Executor task launch worker for task 289] INFO [org.apache.spark.executor.Executor] - Running task 5.0 in stage 100.0 (TID 289)
2021-12-08 10:13:38,895 [Executor task launch worker for task 288] INFO [org.apache.spark.executor.Executor] - Running task 4.0 in stage 100.0 (TID 288)
2021-12-08 10:13:38,895 [Executor task launch worker for task 285] INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 100.0 (TID 285)
2021-12-08 10:13:38,895 [Executor task launch worker for task 286] INFO [org.apache.spark.executor.Executor] - Running task 2.0 in stage 100.0 (TID 286)
2021-12-08 10:13:38,895 [Executor task launch worker for task 290] INFO [org.apache.spark.executor.Executor] - Running task 6.0 in stage 100.0 (TID 290)
2021-12-08 10:13:38,895 [Executor task launch worker for task 295] INFO [org.apache.spark.executor.Executor] - Running task 11.0 in stage 100.0 (TID 295)
2021-12-08 10:13:38,895 [Executor task launch worker for task 294] INFO [org.apache.spark.executor.Executor] - Running task 10.0 in stage 100.0 (TID 294)
2021-12-08 10:13:38,899 [Executor task launch worker for task 290] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_26_6 locally
2021-12-08 10:13:38,899 [Executor task launch worker for task 286] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_26_2 locally
2021-12-08 10:13:38,899 [Executor task launch worker for task 292] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_26_8 locally
2021-12-08 10:13:38,899 [Executor task launch worker for task 295] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_26_11 locally
2021-12-08 10:13:38,900 [Executor task launch worker for task 290] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 12 non-empty blocks out of 12 blocks
2021-12-08 10:13:38,900 [Executor task launch worker for task 290] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 1 ms
2021-12-08 10:13:38,900 [Executor task launch worker for task 292] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 12 non-empty blocks out of 12 blocks
2021-12-08 10:13:38,900 [Executor task launch worker for task 292] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 1 ms
2021-12-08 10:13:38,900 [Executor task launch worker for task 286] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 12 non-empty blocks out of 12 blocks
2021-12-08 10:13:38,900 [Executor task launch worker for task 286] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 1 ms
2021-12-08 10:13:38,900 [Executor task launch worker for task 295] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 12 non-empty blocks out of 12 blocks
2021-12-08 10:13:38,900 [Executor task launch worker for task 295] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-08 10:13:38,900 [Executor task launch worker for task 291] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_26_7 locally
2021-12-08 10:13:38,900 [Executor task launch worker for task 291] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 12 non-empty blocks out of 12 blocks
2021-12-08 10:13:38,900 [Executor task launch worker for task 291] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-08 10:13:38,900 [Executor task launch worker for task 288] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_26_4 locally
2021-12-08 10:13:38,900 [Executor task launch worker for task 284] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_26_0 locally
2021-12-08 10:13:38,900 [Executor task launch worker for task 293] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_26_9 locally
2021-12-08 10:13:38,900 [Executor task launch worker for task 294] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_26_10 locally
2021-12-08 10:13:38,900 [Executor task launch worker for task 288] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 12 non-empty blocks out of 12 blocks
2021-12-08 10:13:38,900 [Executor task launch worker for task 288] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-08 10:13:38,900 [Executor task launch worker for task 293] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 12 non-empty blocks out of 12 blocks
2021-12-08 10:13:38,900 [Executor task launch worker for task 284] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 12 non-empty blocks out of 12 blocks
2021-12-08 10:13:38,900 [Executor task launch worker for task 284] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-08 10:13:38,900 [Executor task launch worker for task 293] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-08 10:13:38,900 [Executor task launch worker for task 287] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_26_3 locally
2021-12-08 10:13:38,900 [Executor task launch worker for task 294] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 12 non-empty blocks out of 12 blocks
2021-12-08 10:13:38,900 [Executor task launch worker for task 294] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-08 10:13:38,900 [Executor task launch worker for task 287] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 12 non-empty blocks out of 12 blocks
2021-12-08 10:13:38,900 [Executor task launch worker for task 287] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-08 10:13:38,901 [Executor task launch worker for task 285] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_26_1 locally
2021-12-08 10:13:38,901 [Executor task launch worker for task 285] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 12 non-empty blocks out of 12 blocks
2021-12-08 10:13:38,901 [Executor task launch worker for task 285] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-08 10:13:38,902 [Executor task launch worker for task 289] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_26_5 locally
2021-12-08 10:13:38,902 [Executor task launch worker for task 289] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 12 non-empty blocks out of 12 blocks
2021-12-08 10:13:38,902 [Executor task launch worker for task 289] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-08 10:13:38,972 [dispatcher-event-loop-0] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_30_piece0 on qb:61292 in memory (size: 1266.9 KB, free: 1666.7 MB)
2021-12-08 10:13:39,486 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 600
2021-12-08 10:13:39,486 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 585
2021-12-08 10:13:39,486 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 582
2021-12-08 10:13:39,486 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 578
2021-12-08 10:13:39,486 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 616
2021-12-08 10:13:39,486 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 601
2021-12-08 10:13:39,486 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 592
2021-12-08 10:13:39,486 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 609
2021-12-08 10:13:39,486 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 588
2021-12-08 10:13:39,486 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 607
2021-12-08 10:13:39,486 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 624
2021-12-08 10:13:39,486 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 587
2021-12-08 10:13:39,486 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 584
2021-12-08 10:13:39,486 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 610
2021-12-08 10:13:39,486 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 591
2021-12-08 10:13:39,486 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 618
2021-12-08 10:13:39,486 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 608
2021-12-08 10:13:39,486 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 617
2021-12-08 10:13:39,486 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 623
2021-12-08 10:13:39,486 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 612
2021-12-08 10:13:39,486 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 589
2021-12-08 10:13:39,486 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 613
2021-12-08 10:13:39,486 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 619
2021-12-08 10:13:39,486 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 593
2021-12-08 10:13:39,486 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 577
2021-12-08 10:13:39,486 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 583
2021-12-08 10:13:39,486 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 575
2021-12-08 10:13:39,486 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 597
2021-12-08 10:13:39,486 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 620
2021-12-08 10:13:39,486 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 579
2021-12-08 10:13:39,486 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 598
2021-12-08 10:13:39,492 [dispatcher-event-loop-11] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_29_piece0 on qb:61292 in memory (size: 1268.0 KB, free: 1668.0 MB)
2021-12-08 10:13:39,493 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 621
2021-12-08 10:13:39,493 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 611
2021-12-08 10:13:39,493 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 599
2021-12-08 10:13:39,493 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 615
2021-12-08 10:13:39,493 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 614
2021-12-08 10:13:39,493 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 581
2021-12-08 10:13:39,493 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 576
2021-12-08 10:13:39,493 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 580
2021-12-08 10:13:39,493 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 595
2021-12-08 10:13:39,493 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 594
2021-12-08 10:13:39,493 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 590
2021-12-08 10:13:39,493 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 604
2021-12-08 10:13:39,494 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 586
2021-12-08 10:13:39,494 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 602
2021-12-08 10:13:39,494 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 605
2021-12-08 10:13:39,494 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 596
2021-12-08 10:13:39,494 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 603
2021-12-08 10:13:39,494 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 606
2021-12-08 10:13:39,494 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 622
2021-12-08 10:14:00,109 [Executor task launch worker for task 289] INFO [org.apache.spark.storage.memory.MemoryStore] - Block rdd_119_5 stored as values in memory (estimated size 4.0 MB, free 1660.9 MB)
2021-12-08 10:14:00,110 [dispatcher-event-loop-2] INFO [org.apache.spark.storage.BlockManagerInfo] - Added rdd_119_5 in memory on qb:61292 (size: 4.0 MB, free: 1664.0 MB)
2021-12-08 10:14:00,230 [Executor task launch worker for task 285] INFO [org.apache.spark.storage.memory.MemoryStore] - Block rdd_119_1 stored as values in memory (estimated size 4.0 MB, free 1656.9 MB)
2021-12-08 10:14:00,230 [dispatcher-event-loop-10] INFO [org.apache.spark.storage.BlockManagerInfo] - Added rdd_119_1 in memory on qb:61292 (size: 4.0 MB, free: 1660.0 MB)
2021-12-08 10:14:00,253 [Executor task launch worker for task 289] INFO [org.apache.spark.executor.Executor] - Finished task 5.0 in stage 100.0 (TID 289). 166097 bytes result sent to driver
2021-12-08 10:14:00,257 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 5.0 in stage 100.0 (TID 289) in 21362 ms on localhost (executor driver) (1/12)
2021-12-08 10:14:00,366 [Executor task launch worker for task 285] INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 100.0 (TID 285). 166054 bytes result sent to driver
2021-12-08 10:14:00,366 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 100.0 (TID 285) in 21471 ms on localhost (executor driver) (2/12)
2021-12-08 10:14:00,771 [Executor task launch worker for task 288] INFO [org.apache.spark.storage.memory.MemoryStore] - Block rdd_119_4 stored as values in memory (estimated size 4.0 MB, free 1652.9 MB)
2021-12-08 10:14:00,771 [dispatcher-event-loop-1] INFO [org.apache.spark.storage.BlockManagerInfo] - Added rdd_119_4 in memory on qb:61292 (size: 4.0 MB, free: 1656.0 MB)
2021-12-08 10:14:00,810 [Executor task launch worker for task 284] INFO [org.apache.spark.storage.memory.MemoryStore] - Block rdd_119_0 stored as values in memory (estimated size 4.0 MB, free 1648.9 MB)
2021-12-08 10:14:00,810 [dispatcher-event-loop-7] INFO [org.apache.spark.storage.BlockManagerInfo] - Added rdd_119_0 in memory on qb:61292 (size: 4.0 MB, free: 1652.0 MB)
2021-12-08 10:14:00,876 [Executor task launch worker for task 288] INFO [org.apache.spark.executor.Executor] - Finished task 4.0 in stage 100.0 (TID 288). 166140 bytes result sent to driver
2021-12-08 10:14:00,876 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 4.0 in stage 100.0 (TID 288) in 21981 ms on localhost (executor driver) (3/12)
2021-12-08 10:14:00,921 [Executor task launch worker for task 284] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 100.0 (TID 284). 166097 bytes result sent to driver
2021-12-08 10:14:00,921 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 100.0 (TID 284) in 22027 ms on localhost (executor driver) (4/12)
2021-12-08 10:14:01,055 [Executor task launch worker for task 295] INFO [org.apache.spark.storage.memory.MemoryStore] - Block rdd_119_11 stored as values in memory (estimated size 4.0 MB, free 1644.9 MB)
2021-12-08 10:14:01,056 [dispatcher-event-loop-3] INFO [org.apache.spark.storage.BlockManagerInfo] - Added rdd_119_11 in memory on qb:61292 (size: 4.0 MB, free: 1648.0 MB)
2021-12-08 10:14:01,136 [Executor task launch worker for task 295] INFO [org.apache.spark.executor.Executor] - Finished task 11.0 in stage 100.0 (TID 295). 166097 bytes result sent to driver
2021-12-08 10:14:01,137 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 11.0 in stage 100.0 (TID 295) in 22242 ms on localhost (executor driver) (5/12)
2021-12-08 10:14:01,318 [Executor task launch worker for task 294] INFO [org.apache.spark.storage.memory.MemoryStore] - Block rdd_119_10 stored as values in memory (estimated size 4.0 MB, free 1640.9 MB)
2021-12-08 10:14:01,319 [dispatcher-event-loop-8] INFO [org.apache.spark.storage.BlockManagerInfo] - Added rdd_119_10 in memory on qb:61292 (size: 4.0 MB, free: 1644.1 MB)
2021-12-08 10:14:01,393 [Executor task launch worker for task 292] INFO [org.apache.spark.storage.memory.MemoryStore] - Block rdd_119_8 stored as values in memory (estimated size 4.0 MB, free 1637.0 MB)
2021-12-08 10:14:01,393 [dispatcher-event-loop-9] INFO [org.apache.spark.storage.BlockManagerInfo] - Added rdd_119_8 in memory on qb:61292 (size: 4.0 MB, free: 1640.1 MB)
2021-12-08 10:14:01,409 [Executor task launch worker for task 294] INFO [org.apache.spark.executor.Executor] - Finished task 10.0 in stage 100.0 (TID 294). 166097 bytes result sent to driver
2021-12-08 10:14:01,409 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 10.0 in stage 100.0 (TID 294) in 22514 ms on localhost (executor driver) (6/12)
2021-12-08 10:14:01,476 [Executor task launch worker for task 292] INFO [org.apache.spark.executor.Executor] - Finished task 8.0 in stage 100.0 (TID 292). 166097 bytes result sent to driver
2021-12-08 10:14:01,476 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 8.0 in stage 100.0 (TID 292) in 22581 ms on localhost (executor driver) (7/12)
2021-12-08 10:14:01,850 [Executor task launch worker for task 291] INFO [org.apache.spark.storage.memory.MemoryStore] - Block rdd_119_7 stored as values in memory (estimated size 4.0 MB, free 1633.0 MB)
2021-12-08 10:14:01,851 [dispatcher-event-loop-5] INFO [org.apache.spark.storage.BlockManagerInfo] - Added rdd_119_7 in memory on qb:61292 (size: 4.0 MB, free: 1636.1 MB)
2021-12-08 10:14:01,932 [Executor task launch worker for task 291] INFO [org.apache.spark.executor.Executor] - Finished task 7.0 in stage 100.0 (TID 291). 166097 bytes result sent to driver
2021-12-08 10:14:01,933 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 7.0 in stage 100.0 (TID 291) in 23038 ms on localhost (executor driver) (8/12)
2021-12-08 10:14:02,353 [Executor task launch worker for task 287] INFO [org.apache.spark.storage.memory.MemoryStore] - Block rdd_119_3 stored as values in memory (estimated size 4.0 MB, free 1629.0 MB)
2021-12-08 10:14:02,354 [dispatcher-event-loop-1] INFO [org.apache.spark.storage.BlockManagerInfo] - Added rdd_119_3 in memory on qb:61292 (size: 4.0 MB, free: 1632.1 MB)
2021-12-08 10:14:02,394 [Executor task launch worker for task 293] INFO [org.apache.spark.storage.memory.MemoryStore] - Block rdd_119_9 stored as values in memory (estimated size 4.0 MB, free 1625.0 MB)
2021-12-08 10:14:02,394 [dispatcher-event-loop-7] INFO [org.apache.spark.storage.BlockManagerInfo] - Added rdd_119_9 in memory on qb:61292 (size: 4.0 MB, free: 1628.1 MB)
2021-12-08 10:14:02,422 [Executor task launch worker for task 287] INFO [org.apache.spark.executor.Executor] - Finished task 3.0 in stage 100.0 (TID 287). 166054 bytes result sent to driver
2021-12-08 10:14:02,423 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 3.0 in stage 100.0 (TID 287) in 23528 ms on localhost (executor driver) (9/12)
2021-12-08 10:14:02,457 [Executor task launch worker for task 293] INFO [org.apache.spark.executor.Executor] - Finished task 9.0 in stage 100.0 (TID 293). 166097 bytes result sent to driver
2021-12-08 10:14:02,457 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 9.0 in stage 100.0 (TID 293) in 23562 ms on localhost (executor driver) (10/12)
2021-12-08 10:14:02,660 [Executor task launch worker for task 290] INFO [org.apache.spark.storage.memory.MemoryStore] - Block rdd_119_6 stored as values in memory (estimated size 4.0 MB, free 1621.0 MB)
2021-12-08 10:14:02,660 [dispatcher-event-loop-3] INFO [org.apache.spark.storage.BlockManagerInfo] - Added rdd_119_6 in memory on qb:61292 (size: 4.0 MB, free: 1624.1 MB)
2021-12-08 10:14:02,711 [Executor task launch worker for task 286] INFO [org.apache.spark.storage.memory.MemoryStore] - Block rdd_119_2 stored as values in memory (estimated size 4.0 MB, free 1617.0 MB)
2021-12-08 10:14:02,711 [dispatcher-event-loop-4] INFO [org.apache.spark.storage.BlockManagerInfo] - Added rdd_119_2 in memory on qb:61292 (size: 4.0 MB, free: 1620.1 MB)
2021-12-08 10:14:02,723 [Executor task launch worker for task 290] INFO [org.apache.spark.executor.Executor] - Finished task 6.0 in stage 100.0 (TID 290). 166097 bytes result sent to driver
2021-12-08 10:14:02,723 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 6.0 in stage 100.0 (TID 290) in 23828 ms on localhost (executor driver) (11/12)
2021-12-08 10:14:02,774 [Executor task launch worker for task 286] INFO [org.apache.spark.executor.Executor] - Finished task 2.0 in stage 100.0 (TID 286). 166097 bytes result sent to driver
2021-12-08 10:14:02,774 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 2.0 in stage 100.0 (TID 286) in 23879 ms on localhost (executor driver) (12/12)
2021-12-08 10:14:02,774 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 100.0, whose tasks have all completed, from pool 
2021-12-08 10:14:02,774 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 100 (aggregate at ALS.scala:1711) finished in 23.885 s
2021-12-08 10:14:02,775 [main] INFO [org.apache.spark.scheduler.DAGScheduler] - Job 13 finished: aggregate at ALS.scala:1711, took 26.075262 s
2021-12-08 10:14:02,790 [main] INFO [org.apache.spark.rdd.MapPartitionsRDD] - Removing RDD 109 from persistence list
2021-12-08 10:14:02,790 [block-manager-slave-async-thread-pool-2] INFO [org.apache.spark.storage.BlockManager] - Removing RDD 109
2021-12-08 10:14:02,796 [main] INFO [org.apache.spark.SparkContext] - Starting job: aggregate at ALS.scala:1711
2021-12-08 10:14:02,797 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 124 (flatMap at ALS.scala:1653)
2021-12-08 10:14:02,797 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 14 (aggregate at ALS.scala:1711) with 12 output partitions
2021-12-08 10:14:02,797 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 115 (aggregate at ALS.scala:1711)
2021-12-08 10:14:02,797 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 102, ShuffleMapStage 114)
2021-12-08 10:14:02,797 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List(ShuffleMapStage 114)
2021-12-08 10:14:02,798 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ShuffleMapStage 114 (MapPartitionsRDD[124] at flatMap at ALS.scala:1653), which has no missing parents
2021-12-08 10:14:02,800 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_32 stored as values in memory (estimated size 1460.9 KB, free 1748.8 MB)
2021-12-08 10:14:02,803 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_32_piece0 stored as bytes in memory (estimated size 1424.7 KB, free 1747.5 MB)
2021-12-08 10:14:02,803 [dispatcher-event-loop-11] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_32_piece0 in memory on qb:61292 (size: 1424.7 KB, free: 1752.0 MB)
2021-12-08 10:14:02,803 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 32 from broadcast at DAGScheduler.scala:1039
2021-12-08 10:14:02,803 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 12 missing tasks from ShuffleMapStage 114 (MapPartitionsRDD[124] at flatMap at ALS.scala:1653) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11))
2021-12-08 10:14:02,803 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 114.0 with 12 tasks
2021-12-08 10:14:02,804 [dispatcher-event-loop-6] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 114.0 (TID 296, localhost, executor driver, partition 0, PROCESS_LOCAL, 7928 bytes)
2021-12-08 10:14:02,804 [dispatcher-event-loop-6] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 114.0 (TID 297, localhost, executor driver, partition 1, PROCESS_LOCAL, 7928 bytes)
2021-12-08 10:14:02,804 [dispatcher-event-loop-6] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 2.0 in stage 114.0 (TID 298, localhost, executor driver, partition 2, PROCESS_LOCAL, 7928 bytes)
2021-12-08 10:14:02,804 [dispatcher-event-loop-6] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 3.0 in stage 114.0 (TID 299, localhost, executor driver, partition 3, PROCESS_LOCAL, 7928 bytes)
2021-12-08 10:14:02,804 [dispatcher-event-loop-6] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 4.0 in stage 114.0 (TID 300, localhost, executor driver, partition 4, PROCESS_LOCAL, 7928 bytes)
2021-12-08 10:14:02,804 [dispatcher-event-loop-6] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 5.0 in stage 114.0 (TID 301, localhost, executor driver, partition 5, PROCESS_LOCAL, 7928 bytes)
2021-12-08 10:14:02,804 [dispatcher-event-loop-6] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 6.0 in stage 114.0 (TID 302, localhost, executor driver, partition 6, PROCESS_LOCAL, 7928 bytes)
2021-12-08 10:14:02,804 [dispatcher-event-loop-6] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 7.0 in stage 114.0 (TID 303, localhost, executor driver, partition 7, PROCESS_LOCAL, 7928 bytes)
2021-12-08 10:14:02,804 [dispatcher-event-loop-6] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 8.0 in stage 114.0 (TID 304, localhost, executor driver, partition 8, PROCESS_LOCAL, 7928 bytes)
2021-12-08 10:14:02,804 [dispatcher-event-loop-6] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 9.0 in stage 114.0 (TID 305, localhost, executor driver, partition 9, PROCESS_LOCAL, 7928 bytes)
2021-12-08 10:14:02,804 [dispatcher-event-loop-6] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 10.0 in stage 114.0 (TID 306, localhost, executor driver, partition 10, PROCESS_LOCAL, 7928 bytes)
2021-12-08 10:14:02,804 [dispatcher-event-loop-6] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 11.0 in stage 114.0 (TID 307, localhost, executor driver, partition 11, PROCESS_LOCAL, 7928 bytes)
2021-12-08 10:14:02,804 [Executor task launch worker for task 298] INFO [org.apache.spark.executor.Executor] - Running task 2.0 in stage 114.0 (TID 298)
2021-12-08 10:14:02,804 [Executor task launch worker for task 300] INFO [org.apache.spark.executor.Executor] - Running task 4.0 in stage 114.0 (TID 300)
2021-12-08 10:14:02,804 [Executor task launch worker for task 305] INFO [org.apache.spark.executor.Executor] - Running task 9.0 in stage 114.0 (TID 305)
2021-12-08 10:14:02,804 [Executor task launch worker for task 297] INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 114.0 (TID 297)
2021-12-08 10:14:02,804 [Executor task launch worker for task 302] INFO [org.apache.spark.executor.Executor] - Running task 6.0 in stage 114.0 (TID 302)
2021-12-08 10:14:02,804 [Executor task launch worker for task 306] INFO [org.apache.spark.executor.Executor] - Running task 10.0 in stage 114.0 (TID 306)
2021-12-08 10:14:02,804 [Executor task launch worker for task 301] INFO [org.apache.spark.executor.Executor] - Running task 5.0 in stage 114.0 (TID 301)
2021-12-08 10:14:02,804 [Executor task launch worker for task 304] INFO [org.apache.spark.executor.Executor] - Running task 8.0 in stage 114.0 (TID 304)
2021-12-08 10:14:02,804 [Executor task launch worker for task 303] INFO [org.apache.spark.executor.Executor] - Running task 7.0 in stage 114.0 (TID 303)
2021-12-08 10:14:02,804 [Executor task launch worker for task 299] INFO [org.apache.spark.executor.Executor] - Running task 3.0 in stage 114.0 (TID 299)
2021-12-08 10:14:02,804 [Executor task launch worker for task 296] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 114.0 (TID 296)
2021-12-08 10:14:02,804 [Executor task launch worker for task 307] INFO [org.apache.spark.executor.Executor] - Running task 11.0 in stage 114.0 (TID 307)
2021-12-08 10:14:02,807 [Executor task launch worker for task 303] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_27_7 locally
2021-12-08 10:14:02,807 [Executor task launch worker for task 304] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_27_8 locally
2021-12-08 10:14:02,807 [Executor task launch worker for task 296] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_27_0 locally
2021-12-08 10:14:02,807 [Executor task launch worker for task 307] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_27_11 locally
2021-12-08 10:14:02,807 [Executor task launch worker for task 299] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_27_3 locally
2021-12-08 10:14:02,807 [Executor task launch worker for task 300] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_27_4 locally
2021-12-08 10:14:02,807 [Executor task launch worker for task 297] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_27_1 locally
2021-12-08 10:14:02,807 [Executor task launch worker for task 303] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_119_7 locally
2021-12-08 10:14:02,807 [Executor task launch worker for task 298] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_27_2 locally
2021-12-08 10:14:02,807 [Executor task launch worker for task 304] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_119_8 locally
2021-12-08 10:14:02,807 [Executor task launch worker for task 307] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_119_11 locally
2021-12-08 10:14:02,807 [Executor task launch worker for task 299] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_119_3 locally
2021-12-08 10:14:02,807 [Executor task launch worker for task 305] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_27_9 locally
2021-12-08 10:14:02,808 [Executor task launch worker for task 305] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_119_9 locally
2021-12-08 10:14:02,807 [Executor task launch worker for task 296] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_119_0 locally
2021-12-08 10:14:02,807 [Executor task launch worker for task 300] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_119_4 locally
2021-12-08 10:14:02,809 [Executor task launch worker for task 301] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_27_5 locally
2021-12-08 10:14:02,809 [Executor task launch worker for task 301] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_119_5 locally
2021-12-08 10:14:02,809 [Executor task launch worker for task 306] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_27_10 locally
2021-12-08 10:14:02,809 [Executor task launch worker for task 306] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_119_10 locally
2021-12-08 10:14:02,811 [Executor task launch worker for task 297] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_119_1 locally
2021-12-08 10:14:02,812 [Executor task launch worker for task 302] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_27_6 locally
2021-12-08 10:14:02,812 [Executor task launch worker for task 302] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_119_6 locally
2021-12-08 10:14:02,812 [Executor task launch worker for task 298] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_119_2 locally
2021-12-08 10:14:04,078 [Executor task launch worker for task 296] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 114.0 (TID 296). 999 bytes result sent to driver
2021-12-08 10:14:04,078 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 114.0 (TID 296) in 1274 ms on localhost (executor driver) (1/12)
2021-12-08 10:14:04,080 [Executor task launch worker for task 307] INFO [org.apache.spark.executor.Executor] - Finished task 11.0 in stage 114.0 (TID 307). 999 bytes result sent to driver
2021-12-08 10:14:04,080 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 11.0 in stage 114.0 (TID 307) in 1276 ms on localhost (executor driver) (2/12)
2021-12-08 10:14:04,112 [Executor task launch worker for task 304] INFO [org.apache.spark.executor.Executor] - Finished task 8.0 in stage 114.0 (TID 304). 999 bytes result sent to driver
2021-12-08 10:14:04,113 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 8.0 in stage 114.0 (TID 304) in 1309 ms on localhost (executor driver) (3/12)
2021-12-08 10:14:04,113 [Executor task launch worker for task 298] INFO [org.apache.spark.executor.Executor] - Finished task 2.0 in stage 114.0 (TID 298). 999 bytes result sent to driver
2021-12-08 10:14:04,113 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 2.0 in stage 114.0 (TID 298) in 1309 ms on localhost (executor driver) (4/12)
2021-12-08 10:14:04,116 [Executor task launch worker for task 305] INFO [org.apache.spark.executor.Executor] - Finished task 9.0 in stage 114.0 (TID 305). 999 bytes result sent to driver
2021-12-08 10:14:04,116 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 9.0 in stage 114.0 (TID 305) in 1312 ms on localhost (executor driver) (5/12)
2021-12-08 10:14:04,126 [Executor task launch worker for task 300] INFO [org.apache.spark.executor.Executor] - Finished task 4.0 in stage 114.0 (TID 300). 999 bytes result sent to driver
2021-12-08 10:14:04,126 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 4.0 in stage 114.0 (TID 300) in 1322 ms on localhost (executor driver) (6/12)
2021-12-08 10:14:04,128 [Executor task launch worker for task 302] INFO [org.apache.spark.executor.Executor] - Finished task 6.0 in stage 114.0 (TID 302). 999 bytes result sent to driver
2021-12-08 10:14:04,129 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 6.0 in stage 114.0 (TID 302) in 1325 ms on localhost (executor driver) (7/12)
2021-12-08 10:14:04,137 [Executor task launch worker for task 303] INFO [org.apache.spark.executor.Executor] - Finished task 7.0 in stage 114.0 (TID 303). 999 bytes result sent to driver
2021-12-08 10:14:04,137 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 7.0 in stage 114.0 (TID 303) in 1333 ms on localhost (executor driver) (8/12)
2021-12-08 10:14:04,138 [Executor task launch worker for task 297] INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 114.0 (TID 297). 999 bytes result sent to driver
2021-12-08 10:14:04,139 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 114.0 (TID 297) in 1335 ms on localhost (executor driver) (9/12)
2021-12-08 10:14:04,141 [Executor task launch worker for task 301] INFO [org.apache.spark.executor.Executor] - Finished task 5.0 in stage 114.0 (TID 301). 999 bytes result sent to driver
2021-12-08 10:14:04,141 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 5.0 in stage 114.0 (TID 301) in 1337 ms on localhost (executor driver) (10/12)
2021-12-08 10:14:04,146 [Executor task launch worker for task 299] INFO [org.apache.spark.executor.Executor] - Finished task 3.0 in stage 114.0 (TID 299). 999 bytes result sent to driver
2021-12-08 10:14:04,146 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 3.0 in stage 114.0 (TID 299) in 1342 ms on localhost (executor driver) (11/12)
2021-12-08 10:14:04,167 [Executor task launch worker for task 306] INFO [org.apache.spark.executor.Executor] - Finished task 10.0 in stage 114.0 (TID 306). 999 bytes result sent to driver
2021-12-08 10:14:04,167 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 10.0 in stage 114.0 (TID 306) in 1363 ms on localhost (executor driver) (12/12)
2021-12-08 10:14:04,167 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 114.0, whose tasks have all completed, from pool 
2021-12-08 10:14:04,167 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ShuffleMapStage 114 (flatMap at ALS.scala:1653) finished in 1.369 s
2021-12-08 10:14:04,167 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - looking for newly runnable stages
2021-12-08 10:14:04,167 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - running: Set()
2021-12-08 10:14:04,167 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - waiting: Set(ResultStage 115)
2021-12-08 10:14:04,167 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - failed: Set()
2021-12-08 10:14:04,168 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 115 (MapPartitionsRDD[130] at values at ALS.scala:1711), which has no missing parents
2021-12-08 10:14:04,170 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_33 stored as values in memory (estimated size 1782.5 KB, free 1745.7 MB)
2021-12-08 10:14:04,173 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_33_piece0 stored as bytes in memory (estimated size 1583.4 KB, free 1744.2 MB)
2021-12-08 10:14:04,173 [dispatcher-event-loop-9] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_33_piece0 in memory on qb:61292 (size: 1583.4 KB, free: 1750.4 MB)
2021-12-08 10:14:04,173 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 33 from broadcast at DAGScheduler.scala:1039
2021-12-08 10:14:04,173 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 12 missing tasks from ResultStage 115 (MapPartitionsRDD[130] at values at ALS.scala:1711) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11))
2021-12-08 10:14:04,173 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 115.0 with 12 tasks
2021-12-08 10:14:04,174 [dispatcher-event-loop-8] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 115.0 (TID 308, localhost, executor driver, partition 0, PROCESS_LOCAL, 7888 bytes)
2021-12-08 10:14:04,174 [dispatcher-event-loop-8] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 115.0 (TID 309, localhost, executor driver, partition 1, PROCESS_LOCAL, 7888 bytes)
2021-12-08 10:14:04,174 [dispatcher-event-loop-8] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 2.0 in stage 115.0 (TID 310, localhost, executor driver, partition 2, PROCESS_LOCAL, 7888 bytes)
2021-12-08 10:14:04,174 [dispatcher-event-loop-8] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 3.0 in stage 115.0 (TID 311, localhost, executor driver, partition 3, PROCESS_LOCAL, 7888 bytes)
2021-12-08 10:14:04,174 [dispatcher-event-loop-8] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 4.0 in stage 115.0 (TID 312, localhost, executor driver, partition 4, PROCESS_LOCAL, 7888 bytes)
2021-12-08 10:14:04,174 [dispatcher-event-loop-8] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 5.0 in stage 115.0 (TID 313, localhost, executor driver, partition 5, PROCESS_LOCAL, 7888 bytes)
2021-12-08 10:14:04,174 [dispatcher-event-loop-8] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 6.0 in stage 115.0 (TID 314, localhost, executor driver, partition 6, PROCESS_LOCAL, 7888 bytes)
2021-12-08 10:14:04,174 [dispatcher-event-loop-8] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 7.0 in stage 115.0 (TID 315, localhost, executor driver, partition 7, PROCESS_LOCAL, 7888 bytes)
2021-12-08 10:14:04,174 [dispatcher-event-loop-8] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 8.0 in stage 115.0 (TID 316, localhost, executor driver, partition 8, PROCESS_LOCAL, 7888 bytes)
2021-12-08 10:14:04,174 [dispatcher-event-loop-8] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 9.0 in stage 115.0 (TID 317, localhost, executor driver, partition 9, PROCESS_LOCAL, 7888 bytes)
2021-12-08 10:14:04,174 [dispatcher-event-loop-8] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 10.0 in stage 115.0 (TID 318, localhost, executor driver, partition 10, PROCESS_LOCAL, 7888 bytes)
2021-12-08 10:14:04,174 [dispatcher-event-loop-8] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 11.0 in stage 115.0 (TID 319, localhost, executor driver, partition 11, PROCESS_LOCAL, 7888 bytes)
2021-12-08 10:14:04,175 [Executor task launch worker for task 308] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 115.0 (TID 308)
2021-12-08 10:14:04,175 [Executor task launch worker for task 310] INFO [org.apache.spark.executor.Executor] - Running task 2.0 in stage 115.0 (TID 310)
2021-12-08 10:14:04,175 [Executor task launch worker for task 317] INFO [org.apache.spark.executor.Executor] - Running task 9.0 in stage 115.0 (TID 317)
2021-12-08 10:14:04,175 [Executor task launch worker for task 318] INFO [org.apache.spark.executor.Executor] - Running task 10.0 in stage 115.0 (TID 318)
2021-12-08 10:14:04,175 [Executor task launch worker for task 314] INFO [org.apache.spark.executor.Executor] - Running task 6.0 in stage 115.0 (TID 314)
2021-12-08 10:14:04,175 [Executor task launch worker for task 312] INFO [org.apache.spark.executor.Executor] - Running task 4.0 in stage 115.0 (TID 312)
2021-12-08 10:14:04,175 [Executor task launch worker for task 311] INFO [org.apache.spark.executor.Executor] - Running task 3.0 in stage 115.0 (TID 311)
2021-12-08 10:14:04,175 [Executor task launch worker for task 309] INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 115.0 (TID 309)
2021-12-08 10:14:04,175 [Executor task launch worker for task 313] INFO [org.apache.spark.executor.Executor] - Running task 5.0 in stage 115.0 (TID 313)
2021-12-08 10:14:04,175 [Executor task launch worker for task 315] INFO [org.apache.spark.executor.Executor] - Running task 7.0 in stage 115.0 (TID 315)
2021-12-08 10:14:04,175 [Executor task launch worker for task 316] INFO [org.apache.spark.executor.Executor] - Running task 8.0 in stage 115.0 (TID 316)
2021-12-08 10:14:04,175 [Executor task launch worker for task 319] INFO [org.apache.spark.executor.Executor] - Running task 11.0 in stage 115.0 (TID 319)
2021-12-08 10:14:04,178 [Executor task launch worker for task 319] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_21_11 locally
2021-12-08 10:14:04,178 [Executor task launch worker for task 308] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_21_0 locally
2021-12-08 10:14:04,178 [Executor task launch worker for task 311] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_21_3 locally
2021-12-08 10:14:04,178 [Executor task launch worker for task 314] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_21_6 locally
2021-12-08 10:14:04,178 [Executor task launch worker for task 316] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_21_8 locally
2021-12-08 10:14:04,178 [Executor task launch worker for task 312] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_21_4 locally
2021-12-08 10:14:04,178 [Executor task launch worker for task 315] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_21_7 locally
2021-12-08 10:14:04,180 [Executor task launch worker for task 313] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_21_5 locally
2021-12-08 10:14:04,180 [Executor task launch worker for task 309] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_21_1 locally
2021-12-08 10:14:04,180 [Executor task launch worker for task 316] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 12 non-empty blocks out of 12 blocks
2021-12-08 10:14:04,180 [Executor task launch worker for task 314] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 12 non-empty blocks out of 12 blocks
2021-12-08 10:14:04,180 [Executor task launch worker for task 311] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 12 non-empty blocks out of 12 blocks
2021-12-08 10:14:04,180 [Executor task launch worker for task 311] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-08 10:14:04,180 [Executor task launch worker for task 312] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 12 non-empty blocks out of 12 blocks
2021-12-08 10:14:04,180 [Executor task launch worker for task 312] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-08 10:14:04,180 [Executor task launch worker for task 314] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-08 10:14:04,180 [Executor task launch worker for task 315] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 12 non-empty blocks out of 12 blocks
2021-12-08 10:14:04,180 [Executor task launch worker for task 315] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-08 10:14:04,180 [Executor task launch worker for task 316] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-08 10:14:04,180 [Executor task launch worker for task 308] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 12 non-empty blocks out of 12 blocks
2021-12-08 10:14:04,180 [Executor task launch worker for task 313] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 12 non-empty blocks out of 12 blocks
2021-12-08 10:14:04,180 [Executor task launch worker for task 310] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_21_2 locally
2021-12-08 10:14:04,180 [Executor task launch worker for task 313] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-08 10:14:04,180 [Executor task launch worker for task 319] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 12 non-empty blocks out of 12 blocks
2021-12-08 10:14:04,180 [Executor task launch worker for task 308] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-08 10:14:04,180 [Executor task launch worker for task 319] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-08 10:14:04,180 [Executor task launch worker for task 309] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 12 non-empty blocks out of 12 blocks
2021-12-08 10:14:04,180 [Executor task launch worker for task 309] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-08 10:14:04,180 [Executor task launch worker for task 310] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 12 non-empty blocks out of 12 blocks
2021-12-08 10:14:04,181 [Executor task launch worker for task 310] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 1 ms
2021-12-08 10:14:04,181 [Executor task launch worker for task 317] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_21_9 locally
2021-12-08 10:14:04,181 [Executor task launch worker for task 318] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_21_10 locally
2021-12-08 10:14:04,181 [Executor task launch worker for task 317] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 12 non-empty blocks out of 12 blocks
2021-12-08 10:14:04,181 [Executor task launch worker for task 317] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-08 10:14:04,181 [Executor task launch worker for task 318] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 12 non-empty blocks out of 12 blocks
2021-12-08 10:14:04,181 [Executor task launch worker for task 318] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-08 10:14:04,479 [dispatcher-event-loop-5] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_32_piece0 on qb:61292 in memory (size: 1424.7 KB, free: 1751.8 MB)
2021-12-08 10:14:27,264 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 633
2021-12-08 10:14:27,264 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 640
2021-12-08 10:14:27,264 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 666
2021-12-08 10:14:27,264 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 665
2021-12-08 10:14:27,265 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 636
2021-12-08 10:14:27,265 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 641
2021-12-08 10:14:27,265 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 644
2021-12-08 10:14:27,265 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 649
2021-12-08 10:14:27,265 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 668
2021-12-08 10:14:27,265 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 647
2021-12-08 10:14:27,265 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 656
2021-12-08 10:14:27,265 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 661
2021-12-08 10:14:27,265 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 626
2021-12-08 10:14:27,266 [dispatcher-event-loop-8] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_31_piece0 on qb:61292 in memory (size: 1425.7 KB, free: 1753.2 MB)
2021-12-08 10:14:27,297 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 662
2021-12-08 10:14:27,297 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 629
2021-12-08 10:14:27,297 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 669
2021-12-08 10:14:27,297 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 648
2021-12-08 10:14:27,297 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 625
2021-12-08 10:14:27,297 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 627
2021-12-08 10:14:27,297 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 664
2021-12-08 10:14:27,297 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 628
2021-12-08 10:14:27,297 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 645
2021-12-08 10:14:27,297 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 634
2021-12-08 10:14:27,297 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 670
2021-12-08 10:14:27,297 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 674
2021-12-08 10:14:27,297 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 651
2021-12-08 10:14:27,297 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 637
2021-12-08 10:14:27,297 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 654
2021-12-08 10:14:27,297 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 639
2021-12-08 10:14:27,297 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 642
2021-12-08 10:14:27,297 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 657
2021-12-08 10:14:27,297 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 671
2021-12-08 10:14:27,297 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 667
2021-12-08 10:14:27,297 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 663
2021-12-08 10:14:27,297 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 658
2021-12-08 10:14:27,297 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 638
2021-12-08 10:14:27,297 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 652
2021-12-08 10:14:27,297 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 646
2021-12-08 10:14:27,297 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 655
2021-12-08 10:14:27,297 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 659
2021-12-08 10:14:27,297 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 673
2021-12-08 10:14:27,297 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 630
2021-12-08 10:14:27,297 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 650
2021-12-08 10:14:27,297 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 660
2021-12-08 10:14:27,297 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 643
2021-12-08 10:14:27,297 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 635
2021-12-08 10:14:27,297 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 632
2021-12-08 10:14:27,297 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 631
2021-12-08 10:14:27,297 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 653
2021-12-08 10:14:27,297 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 672
2021-12-08 10:14:41,172 [Executor task launch worker for task 308] INFO [org.apache.spark.storage.memory.MemoryStore] - Block rdd_129_0 stored as values in memory (estimated size 11.1 MB, free 1738.9 MB)
2021-12-08 10:14:41,172 [dispatcher-event-loop-5] INFO [org.apache.spark.storage.BlockManagerInfo] - Added rdd_129_0 in memory on qb:61292 (size: 11.1 MB, free: 1742.1 MB)
2021-12-08 10:14:41,260 [Executor task launch worker for task 316] INFO [org.apache.spark.storage.memory.MemoryStore] - Block rdd_129_8 stored as values in memory (estimated size 11.1 MB, free 1727.8 MB)
2021-12-08 10:14:41,261 [dispatcher-event-loop-1] INFO [org.apache.spark.storage.BlockManagerInfo] - Added rdd_129_8 in memory on qb:61292 (size: 11.1 MB, free: 1731.0 MB)
2021-12-08 10:14:41,263 [Executor task launch worker for task 311] INFO [org.apache.spark.storage.memory.MemoryStore] - Block rdd_129_3 stored as values in memory (estimated size 11.1 MB, free 1716.6 MB)
2021-12-08 10:14:41,263 [dispatcher-event-loop-7] INFO [org.apache.spark.storage.BlockManagerInfo] - Added rdd_129_3 in memory on qb:61292 (size: 11.1 MB, free: 1719.9 MB)
2021-12-08 10:14:41,317 [Executor task launch worker for task 314] INFO [org.apache.spark.storage.memory.MemoryStore] - Block rdd_129_6 stored as values in memory (estimated size 11.1 MB, free 1705.5 MB)
2021-12-08 10:14:41,318 [dispatcher-event-loop-11] INFO [org.apache.spark.storage.BlockManagerInfo] - Added rdd_129_6 in memory on qb:61292 (size: 11.1 MB, free: 1708.8 MB)
2021-12-08 10:14:41,374 [Executor task launch worker for task 319] INFO [org.apache.spark.storage.memory.MemoryStore] - Block rdd_129_11 stored as values in memory (estimated size 11.1 MB, free 1694.4 MB)
2021-12-08 10:14:41,375 [dispatcher-event-loop-6] INFO [org.apache.spark.storage.BlockManagerInfo] - Added rdd_129_11 in memory on qb:61292 (size: 11.1 MB, free: 1697.7 MB)
2021-12-08 10:14:41,479 [Executor task launch worker for task 313] INFO [org.apache.spark.storage.memory.MemoryStore] - Block rdd_129_5 stored as values in memory (estimated size 11.1 MB, free 1683.3 MB)
2021-12-08 10:14:41,479 [dispatcher-event-loop-3] INFO [org.apache.spark.storage.BlockManagerInfo] - Added rdd_129_5 in memory on qb:61292 (size: 11.1 MB, free: 1686.6 MB)
2021-12-08 10:14:41,518 [Executor task launch worker for task 308] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 115.0 (TID 308). 166054 bytes result sent to driver
2021-12-08 10:14:41,520 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 115.0 (TID 308) in 37346 ms on localhost (executor driver) (1/12)
2021-12-08 10:14:41,598 [Executor task launch worker for task 316] INFO [org.apache.spark.executor.Executor] - Finished task 8.0 in stage 115.0 (TID 316). 166054 bytes result sent to driver
2021-12-08 10:14:41,598 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 8.0 in stage 115.0 (TID 316) in 37424 ms on localhost (executor driver) (2/12)
2021-12-08 10:14:41,604 [Executor task launch worker for task 311] INFO [org.apache.spark.executor.Executor] - Finished task 3.0 in stage 115.0 (TID 311). 166054 bytes result sent to driver
2021-12-08 10:14:41,604 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 3.0 in stage 115.0 (TID 311) in 37430 ms on localhost (executor driver) (3/12)
2021-12-08 10:14:41,656 [Executor task launch worker for task 314] INFO [org.apache.spark.executor.Executor] - Finished task 6.0 in stage 115.0 (TID 314). 166054 bytes result sent to driver
2021-12-08 10:14:41,657 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 6.0 in stage 115.0 (TID 314) in 37483 ms on localhost (executor driver) (4/12)
2021-12-08 10:14:41,696 [Executor task launch worker for task 317] INFO [org.apache.spark.storage.memory.MemoryStore] - Block rdd_129_9 stored as values in memory (estimated size 11.1 MB, free 1672.2 MB)
2021-12-08 10:14:41,696 [dispatcher-event-loop-2] INFO [org.apache.spark.storage.BlockManagerInfo] - Added rdd_129_9 in memory on qb:61292 (size: 11.1 MB, free: 1675.5 MB)
2021-12-08 10:14:41,699 [Executor task launch worker for task 319] INFO [org.apache.spark.executor.Executor] - Finished task 11.0 in stage 115.0 (TID 319). 166054 bytes result sent to driver
2021-12-08 10:14:41,699 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 11.0 in stage 115.0 (TID 319) in 37525 ms on localhost (executor driver) (5/12)
2021-12-08 10:14:41,705 [Executor task launch worker for task 318] INFO [org.apache.spark.storage.memory.MemoryStore] - Block rdd_129_10 stored as values in memory (estimated size 11.1 MB, free 1661.1 MB)
2021-12-08 10:14:41,705 [dispatcher-event-loop-5] INFO [org.apache.spark.storage.BlockManagerInfo] - Added rdd_129_10 in memory on qb:61292 (size: 11.1 MB, free: 1664.4 MB)
2021-12-08 10:14:41,740 [Executor task launch worker for task 310] INFO [org.apache.spark.storage.memory.MemoryStore] - Block rdd_129_2 stored as values in memory (estimated size 11.1 MB, free 1650.0 MB)
2021-12-08 10:14:41,740 [dispatcher-event-loop-1] INFO [org.apache.spark.storage.BlockManagerInfo] - Added rdd_129_2 in memory on qb:61292 (size: 11.1 MB, free: 1653.3 MB)
2021-12-08 10:14:41,775 [Executor task launch worker for task 312] INFO [org.apache.spark.storage.memory.MemoryStore] - Block rdd_129_4 stored as values in memory (estimated size 11.1 MB, free 1638.9 MB)
2021-12-08 10:14:41,775 [dispatcher-event-loop-7] INFO [org.apache.spark.storage.BlockManagerInfo] - Added rdd_129_4 in memory on qb:61292 (size: 11.1 MB, free: 1642.2 MB)
2021-12-08 10:14:41,777 [Executor task launch worker for task 313] INFO [org.apache.spark.executor.Executor] - Finished task 5.0 in stage 115.0 (TID 313). 166054 bytes result sent to driver
2021-12-08 10:14:41,777 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 5.0 in stage 115.0 (TID 313) in 37603 ms on localhost (executor driver) (6/12)
2021-12-08 10:14:41,879 [Executor task launch worker for task 315] INFO [org.apache.spark.storage.memory.MemoryStore] - Block rdd_129_7 stored as values in memory (estimated size 11.1 MB, free 1627.8 MB)
2021-12-08 10:14:41,879 [dispatcher-event-loop-6] INFO [org.apache.spark.storage.BlockManagerInfo] - Added rdd_129_7 in memory on qb:61292 (size: 11.1 MB, free: 1631.1 MB)
2021-12-08 10:14:41,880 [Executor task launch worker for task 309] INFO [org.apache.spark.storage.memory.MemoryStore] - Block rdd_129_1 stored as values in memory (estimated size 11.1 MB, free 1616.7 MB)
2021-12-08 10:14:41,880 [dispatcher-event-loop-3] INFO [org.apache.spark.storage.BlockManagerInfo] - Added rdd_129_1 in memory on qb:61292 (size: 11.1 MB, free: 1620.0 MB)
2021-12-08 10:14:41,947 [Executor task launch worker for task 310] INFO [org.apache.spark.executor.Executor] - Finished task 2.0 in stage 115.0 (TID 310). 166097 bytes result sent to driver
2021-12-08 10:14:41,948 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 2.0 in stage 115.0 (TID 310) in 37773 ms on localhost (executor driver) (7/12)
2021-12-08 10:14:41,948 [Executor task launch worker for task 318] INFO [org.apache.spark.executor.Executor] - Finished task 10.0 in stage 115.0 (TID 318). 166097 bytes result sent to driver
2021-12-08 10:14:41,948 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 10.0 in stage 115.0 (TID 318) in 37774 ms on localhost (executor driver) (8/12)
2021-12-08 10:14:41,951 [Executor task launch worker for task 317] INFO [org.apache.spark.executor.Executor] - Finished task 9.0 in stage 115.0 (TID 317). 166054 bytes result sent to driver
2021-12-08 10:14:41,951 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 9.0 in stage 115.0 (TID 317) in 37777 ms on localhost (executor driver) (9/12)
2021-12-08 10:14:41,994 [Executor task launch worker for task 312] INFO [org.apache.spark.executor.Executor] - Finished task 4.0 in stage 115.0 (TID 312). 166054 bytes result sent to driver
2021-12-08 10:14:41,995 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 4.0 in stage 115.0 (TID 312) in 37821 ms on localhost (executor driver) (10/12)
2021-12-08 10:14:42,062 [Executor task launch worker for task 315] INFO [org.apache.spark.executor.Executor] - Finished task 7.0 in stage 115.0 (TID 315). 166054 bytes result sent to driver
2021-12-08 10:14:42,063 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 7.0 in stage 115.0 (TID 315) in 37889 ms on localhost (executor driver) (11/12)
2021-12-08 10:14:42,074 [Executor task launch worker for task 309] INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 115.0 (TID 309). 166054 bytes result sent to driver
2021-12-08 10:14:42,074 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 115.0 (TID 309) in 37900 ms on localhost (executor driver) (12/12)
2021-12-08 10:14:42,075 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 115.0, whose tasks have all completed, from pool 
2021-12-08 10:14:42,075 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 115 (aggregate at ALS.scala:1711) finished in 37.907 s
2021-12-08 10:14:42,075 [main] INFO [org.apache.spark.scheduler.DAGScheduler] - Job 14 finished: aggregate at ALS.scala:1711, took 39.279581 s
2021-12-08 10:14:42,091 [main] INFO [org.apache.spark.rdd.MapPartitionsRDD] - Removing RDD 119 from persistence list
2021-12-08 10:14:42,092 [block-manager-slave-async-thread-pool-1] INFO [org.apache.spark.storage.BlockManager] - Removing RDD 119
2021-12-08 10:14:42,098 [main] INFO [org.apache.spark.SparkContext] - Starting job: aggregate at ALS.scala:1711
2021-12-08 10:14:42,099 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 134 (flatMap at ALS.scala:1653)
2021-12-08 10:14:42,099 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 15 (aggregate at ALS.scala:1711) with 12 output partitions
2021-12-08 10:14:42,099 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 131 (aggregate at ALS.scala:1711)
2021-12-08 10:14:42,099 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 117, ShuffleMapStage 130)
2021-12-08 10:14:42,099 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List(ShuffleMapStage 130)
2021-12-08 10:14:42,100 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ShuffleMapStage 130 (MapPartitionsRDD[134] at flatMap at ALS.scala:1653), which has no missing parents
2021-12-08 10:14:42,102 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_34 stored as values in memory (estimated size 1622.0 KB, free 1663.0 MB)
2021-12-08 10:14:42,104 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_34_piece0 stored as bytes in memory (estimated size 1582.4 KB, free 1661.4 MB)
2021-12-08 10:14:42,105 [dispatcher-event-loop-4] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_34_piece0 in memory on qb:61292 (size: 1582.4 KB, free: 1666.3 MB)
2021-12-08 10:14:42,105 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 34 from broadcast at DAGScheduler.scala:1039
2021-12-08 10:14:42,105 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 12 missing tasks from ShuffleMapStage 130 (MapPartitionsRDD[134] at flatMap at ALS.scala:1653) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11))
2021-12-08 10:14:42,105 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 130.0 with 12 tasks
2021-12-08 10:14:42,105 [dispatcher-event-loop-10] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 130.0 (TID 320, localhost, executor driver, partition 0, PROCESS_LOCAL, 7928 bytes)
2021-12-08 10:14:42,105 [dispatcher-event-loop-10] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 130.0 (TID 321, localhost, executor driver, partition 1, PROCESS_LOCAL, 7928 bytes)
2021-12-08 10:14:42,106 [dispatcher-event-loop-10] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 2.0 in stage 130.0 (TID 322, localhost, executor driver, partition 2, PROCESS_LOCAL, 7928 bytes)
2021-12-08 10:14:42,106 [dispatcher-event-loop-10] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 3.0 in stage 130.0 (TID 323, localhost, executor driver, partition 3, PROCESS_LOCAL, 7928 bytes)
2021-12-08 10:14:42,106 [dispatcher-event-loop-10] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 4.0 in stage 130.0 (TID 324, localhost, executor driver, partition 4, PROCESS_LOCAL, 7928 bytes)
2021-12-08 10:14:42,106 [dispatcher-event-loop-10] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 5.0 in stage 130.0 (TID 325, localhost, executor driver, partition 5, PROCESS_LOCAL, 7928 bytes)
2021-12-08 10:14:42,106 [dispatcher-event-loop-10] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 6.0 in stage 130.0 (TID 326, localhost, executor driver, partition 6, PROCESS_LOCAL, 7928 bytes)
2021-12-08 10:14:42,106 [dispatcher-event-loop-10] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 7.0 in stage 130.0 (TID 327, localhost, executor driver, partition 7, PROCESS_LOCAL, 7928 bytes)
2021-12-08 10:14:42,106 [dispatcher-event-loop-10] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 8.0 in stage 130.0 (TID 328, localhost, executor driver, partition 8, PROCESS_LOCAL, 7928 bytes)
2021-12-08 10:14:42,106 [dispatcher-event-loop-10] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 9.0 in stage 130.0 (TID 329, localhost, executor driver, partition 9, PROCESS_LOCAL, 7928 bytes)
2021-12-08 10:14:42,106 [dispatcher-event-loop-10] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 10.0 in stage 130.0 (TID 330, localhost, executor driver, partition 10, PROCESS_LOCAL, 7928 bytes)
2021-12-08 10:14:42,106 [dispatcher-event-loop-10] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 11.0 in stage 130.0 (TID 331, localhost, executor driver, partition 11, PROCESS_LOCAL, 7928 bytes)
2021-12-08 10:14:42,106 [Executor task launch worker for task 321] INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 130.0 (TID 321)
2021-12-08 10:14:42,106 [Executor task launch worker for task 323] INFO [org.apache.spark.executor.Executor] - Running task 3.0 in stage 130.0 (TID 323)
2021-12-08 10:14:42,106 [Executor task launch worker for task 331] INFO [org.apache.spark.executor.Executor] - Running task 11.0 in stage 130.0 (TID 331)
2021-12-08 10:14:42,106 [Executor task launch worker for task 324] INFO [org.apache.spark.executor.Executor] - Running task 4.0 in stage 130.0 (TID 324)
2021-12-08 10:14:42,106 [Executor task launch worker for task 330] INFO [org.apache.spark.executor.Executor] - Running task 10.0 in stage 130.0 (TID 330)
2021-12-08 10:14:42,106 [Executor task launch worker for task 320] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 130.0 (TID 320)
2021-12-08 10:14:42,106 [Executor task launch worker for task 327] INFO [org.apache.spark.executor.Executor] - Running task 7.0 in stage 130.0 (TID 327)
2021-12-08 10:14:42,106 [Executor task launch worker for task 326] INFO [org.apache.spark.executor.Executor] - Running task 6.0 in stage 130.0 (TID 326)
2021-12-08 10:14:42,106 [Executor task launch worker for task 328] INFO [org.apache.spark.executor.Executor] - Running task 8.0 in stage 130.0 (TID 328)
2021-12-08 10:14:42,106 [Executor task launch worker for task 322] INFO [org.apache.spark.executor.Executor] - Running task 2.0 in stage 130.0 (TID 322)
2021-12-08 10:14:42,106 [Executor task launch worker for task 329] INFO [org.apache.spark.executor.Executor] - Running task 9.0 in stage 130.0 (TID 329)
2021-12-08 10:14:42,106 [Executor task launch worker for task 325] INFO [org.apache.spark.executor.Executor] - Running task 5.0 in stage 130.0 (TID 325)
2021-12-08 10:14:42,109 [Executor task launch worker for task 327] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_22_7 locally
2021-12-08 10:14:42,109 [Executor task launch worker for task 328] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_22_8 locally
2021-12-08 10:14:42,109 [Executor task launch worker for task 320] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_22_0 locally
2021-12-08 10:14:42,109 [Executor task launch worker for task 320] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_129_0 locally
2021-12-08 10:14:42,109 [Executor task launch worker for task 324] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_22_4 locally
2021-12-08 10:14:42,109 [Executor task launch worker for task 322] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_22_2 locally
2021-12-08 10:14:42,109 [Executor task launch worker for task 326] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_22_6 locally
2021-12-08 10:14:42,109 [Executor task launch worker for task 330] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_22_10 locally
2021-12-08 10:14:42,109 [Executor task launch worker for task 330] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_129_10 locally
2021-12-08 10:14:42,109 [Executor task launch worker for task 325] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_22_5 locally
2021-12-08 10:14:42,109 [Executor task launch worker for task 329] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_22_9 locally
2021-12-08 10:14:42,109 [Executor task launch worker for task 329] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_129_9 locally
2021-12-08 10:14:42,109 [Executor task launch worker for task 328] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_129_8 locally
2021-12-08 10:14:42,109 [Executor task launch worker for task 331] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_22_11 locally
2021-12-08 10:14:42,109 [Executor task launch worker for task 323] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_22_3 locally
2021-12-08 10:14:42,109 [Executor task launch worker for task 327] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_129_7 locally
2021-12-08 10:14:42,109 [Executor task launch worker for task 324] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_129_4 locally
2021-12-08 10:14:42,109 [Executor task launch worker for task 326] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_129_6 locally
2021-12-08 10:14:42,110 [Executor task launch worker for task 322] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_129_2 locally
2021-12-08 10:14:42,110 [Executor task launch worker for task 331] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_129_11 locally
2021-12-08 10:14:42,110 [Executor task launch worker for task 323] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_129_3 locally
2021-12-08 10:14:42,110 [Executor task launch worker for task 321] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_22_1 locally
2021-12-08 10:14:42,110 [Executor task launch worker for task 321] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_129_1 locally
2021-12-08 10:14:42,110 [Executor task launch worker for task 325] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_129_5 locally
2021-12-08 10:14:44,203 [Executor task launch worker for task 331] INFO [org.apache.spark.executor.Executor] - Finished task 11.0 in stage 130.0 (TID 331). 999 bytes result sent to driver
2021-12-08 10:14:44,203 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 11.0 in stage 130.0 (TID 331) in 2097 ms on localhost (executor driver) (1/12)
2021-12-08 10:14:44,343 [Executor task launch worker for task 322] INFO [org.apache.spark.executor.Executor] - Finished task 2.0 in stage 130.0 (TID 322). 999 bytes result sent to driver
2021-12-08 10:14:44,343 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 2.0 in stage 130.0 (TID 322) in 2237 ms on localhost (executor driver) (2/12)
2021-12-08 10:14:44,520 [Executor task launch worker for task 320] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 130.0 (TID 320). 1042 bytes result sent to driver
2021-12-08 10:14:44,524 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 130.0 (TID 320) in 2419 ms on localhost (executor driver) (3/12)
2021-12-08 10:14:44,616 [Executor task launch worker for task 321] INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 130.0 (TID 321). 999 bytes result sent to driver
2021-12-08 10:14:44,617 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 130.0 (TID 321) in 2512 ms on localhost (executor driver) (4/12)
2021-12-08 10:14:44,617 [Executor task launch worker for task 327] INFO [org.apache.spark.executor.Executor] - Finished task 7.0 in stage 130.0 (TID 327). 999 bytes result sent to driver
2021-12-08 10:14:44,617 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 7.0 in stage 130.0 (TID 327) in 2511 ms on localhost (executor driver) (5/12)
2021-12-08 10:14:44,618 [Executor task launch worker for task 329] INFO [org.apache.spark.executor.Executor] - Finished task 9.0 in stage 130.0 (TID 329). 999 bytes result sent to driver
2021-12-08 10:14:44,618 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 9.0 in stage 130.0 (TID 329) in 2512 ms on localhost (executor driver) (6/12)
2021-12-08 10:14:44,619 [Executor task launch worker for task 326] INFO [org.apache.spark.executor.Executor] - Finished task 6.0 in stage 130.0 (TID 326). 999 bytes result sent to driver
2021-12-08 10:14:44,619 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 6.0 in stage 130.0 (TID 326) in 2513 ms on localhost (executor driver) (7/12)
2021-12-08 10:14:44,620 [Executor task launch worker for task 324] INFO [org.apache.spark.executor.Executor] - Finished task 4.0 in stage 130.0 (TID 324). 999 bytes result sent to driver
2021-12-08 10:14:44,620 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 4.0 in stage 130.0 (TID 324) in 2514 ms on localhost (executor driver) (8/12)
2021-12-08 10:14:44,677 [Executor task launch worker for task 328] INFO [org.apache.spark.executor.Executor] - Finished task 8.0 in stage 130.0 (TID 328). 999 bytes result sent to driver
2021-12-08 10:14:44,682 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 8.0 in stage 130.0 (TID 328) in 2576 ms on localhost (executor driver) (9/12)
2021-12-08 10:14:44,750 [Executor task launch worker for task 323] INFO [org.apache.spark.executor.Executor] - Finished task 3.0 in stage 130.0 (TID 323). 999 bytes result sent to driver
2021-12-08 10:14:44,751 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 3.0 in stage 130.0 (TID 323) in 2645 ms on localhost (executor driver) (10/12)
2021-12-08 10:14:44,751 [Executor task launch worker for task 325] INFO [org.apache.spark.executor.Executor] - Finished task 5.0 in stage 130.0 (TID 325). 999 bytes result sent to driver
2021-12-08 10:14:44,752 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 5.0 in stage 130.0 (TID 325) in 2646 ms on localhost (executor driver) (11/12)
2021-12-08 10:14:44,752 [Executor task launch worker for task 330] INFO [org.apache.spark.executor.Executor] - Finished task 10.0 in stage 130.0 (TID 330). 999 bytes result sent to driver
2021-12-08 10:14:44,753 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 10.0 in stage 130.0 (TID 330) in 2647 ms on localhost (executor driver) (12/12)
2021-12-08 10:14:44,753 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 130.0, whose tasks have all completed, from pool 
2021-12-08 10:14:44,753 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ShuffleMapStage 130 (flatMap at ALS.scala:1653) finished in 2.653 s
2021-12-08 10:14:44,753 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - looking for newly runnable stages
2021-12-08 10:14:44,753 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - running: Set()
2021-12-08 10:14:44,753 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - waiting: Set(ResultStage 131)
2021-12-08 10:14:44,753 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - failed: Set()
2021-12-08 10:14:44,753 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 131 (MapPartitionsRDD[140] at values at ALS.scala:1711), which has no missing parents
2021-12-08 10:14:44,756 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_35 stored as values in memory (estimated size 1943.6 KB, free 1659.5 MB)
2021-12-08 10:14:44,759 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_35_piece0 stored as bytes in memory (estimated size 1741.1 KB, free 1657.8 MB)
2021-12-08 10:14:44,759 [dispatcher-event-loop-2] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_35_piece0 in memory on qb:61292 (size: 1741.1 KB, free: 1664.6 MB)
2021-12-08 10:14:44,759 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 35 from broadcast at DAGScheduler.scala:1039
2021-12-08 10:14:44,760 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 12 missing tasks from ResultStage 131 (MapPartitionsRDD[140] at values at ALS.scala:1711) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11))
2021-12-08 10:14:44,760 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 131.0 with 12 tasks
2021-12-08 10:14:44,760 [dispatcher-event-loop-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 131.0 (TID 332, localhost, executor driver, partition 0, PROCESS_LOCAL, 7888 bytes)
2021-12-08 10:14:44,760 [dispatcher-event-loop-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 131.0 (TID 333, localhost, executor driver, partition 1, PROCESS_LOCAL, 7888 bytes)
2021-12-08 10:14:44,760 [dispatcher-event-loop-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 2.0 in stage 131.0 (TID 334, localhost, executor driver, partition 2, PROCESS_LOCAL, 7888 bytes)
2021-12-08 10:14:44,760 [dispatcher-event-loop-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 3.0 in stage 131.0 (TID 335, localhost, executor driver, partition 3, PROCESS_LOCAL, 7888 bytes)
2021-12-08 10:14:44,760 [dispatcher-event-loop-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 4.0 in stage 131.0 (TID 336, localhost, executor driver, partition 4, PROCESS_LOCAL, 7888 bytes)
2021-12-08 10:14:44,760 [dispatcher-event-loop-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 5.0 in stage 131.0 (TID 337, localhost, executor driver, partition 5, PROCESS_LOCAL, 7888 bytes)
2021-12-08 10:14:44,760 [dispatcher-event-loop-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 6.0 in stage 131.0 (TID 338, localhost, executor driver, partition 6, PROCESS_LOCAL, 7888 bytes)
2021-12-08 10:14:44,760 [dispatcher-event-loop-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 7.0 in stage 131.0 (TID 339, localhost, executor driver, partition 7, PROCESS_LOCAL, 7888 bytes)
2021-12-08 10:14:44,760 [dispatcher-event-loop-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 8.0 in stage 131.0 (TID 340, localhost, executor driver, partition 8, PROCESS_LOCAL, 7888 bytes)
2021-12-08 10:14:44,760 [dispatcher-event-loop-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 9.0 in stage 131.0 (TID 341, localhost, executor driver, partition 9, PROCESS_LOCAL, 7888 bytes)
2021-12-08 10:14:44,761 [dispatcher-event-loop-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 10.0 in stage 131.0 (TID 342, localhost, executor driver, partition 10, PROCESS_LOCAL, 7888 bytes)
2021-12-08 10:14:44,761 [dispatcher-event-loop-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 11.0 in stage 131.0 (TID 343, localhost, executor driver, partition 11, PROCESS_LOCAL, 7888 bytes)
2021-12-08 10:14:44,761 [Executor task launch worker for task 333] INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 131.0 (TID 333)
2021-12-08 10:14:44,761 [Executor task launch worker for task 338] INFO [org.apache.spark.executor.Executor] - Running task 6.0 in stage 131.0 (TID 338)
2021-12-08 10:14:44,761 [Executor task launch worker for task 342] INFO [org.apache.spark.executor.Executor] - Running task 10.0 in stage 131.0 (TID 342)
2021-12-08 10:14:44,761 [Executor task launch worker for task 343] INFO [org.apache.spark.executor.Executor] - Running task 11.0 in stage 131.0 (TID 343)
2021-12-08 10:14:44,761 [Executor task launch worker for task 341] INFO [org.apache.spark.executor.Executor] - Running task 9.0 in stage 131.0 (TID 341)
2021-12-08 10:14:44,761 [Executor task launch worker for task 332] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 131.0 (TID 332)
2021-12-08 10:14:44,761 [Executor task launch worker for task 340] INFO [org.apache.spark.executor.Executor] - Running task 8.0 in stage 131.0 (TID 340)
2021-12-08 10:14:44,761 [Executor task launch worker for task 334] INFO [org.apache.spark.executor.Executor] - Running task 2.0 in stage 131.0 (TID 334)
2021-12-08 10:14:44,761 [Executor task launch worker for task 335] INFO [org.apache.spark.executor.Executor] - Running task 3.0 in stage 131.0 (TID 335)
2021-12-08 10:14:44,761 [Executor task launch worker for task 339] INFO [org.apache.spark.executor.Executor] - Running task 7.0 in stage 131.0 (TID 339)
2021-12-08 10:14:44,761 [Executor task launch worker for task 337] INFO [org.apache.spark.executor.Executor] - Running task 5.0 in stage 131.0 (TID 337)
2021-12-08 10:14:44,761 [Executor task launch worker for task 336] INFO [org.apache.spark.executor.Executor] - Running task 4.0 in stage 131.0 (TID 336)
2021-12-08 10:14:44,765 [Executor task launch worker for task 343] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_26_11 locally
2021-12-08 10:14:44,765 [Executor task launch worker for task 342] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_26_10 locally
2021-12-08 10:14:44,765 [Executor task launch worker for task 335] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_26_3 locally
2021-12-08 10:14:44,765 [Executor task launch worker for task 337] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_26_5 locally
2021-12-08 10:14:44,766 [Executor task launch worker for task 332] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_26_0 locally
2021-12-08 10:14:44,766 [Executor task launch worker for task 342] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 12 non-empty blocks out of 12 blocks
2021-12-08 10:14:44,766 [Executor task launch worker for task 340] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_26_8 locally
2021-12-08 10:14:44,766 [Executor task launch worker for task 342] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 1 ms
2021-12-08 10:14:44,766 [Executor task launch worker for task 339] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_26_7 locally
2021-12-08 10:14:44,766 [Executor task launch worker for task 337] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 12 non-empty blocks out of 12 blocks
2021-12-08 10:14:44,766 [Executor task launch worker for task 337] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-08 10:14:44,765 [Executor task launch worker for task 336] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_26_4 locally
2021-12-08 10:14:44,766 [Executor task launch worker for task 336] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 12 non-empty blocks out of 12 blocks
2021-12-08 10:14:44,766 [Executor task launch worker for task 336] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-08 10:14:44,766 [Executor task launch worker for task 332] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 12 non-empty blocks out of 12 blocks
2021-12-08 10:14:44,766 [Executor task launch worker for task 332] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-08 10:14:44,766 [Executor task launch worker for task 335] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 12 non-empty blocks out of 12 blocks
2021-12-08 10:14:44,766 [Executor task launch worker for task 343] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 12 non-empty blocks out of 12 blocks
2021-12-08 10:14:44,766 [Executor task launch worker for task 335] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-08 10:14:44,766 [Executor task launch worker for task 334] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_26_2 locally
2021-12-08 10:14:44,766 [Executor task launch worker for task 340] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 12 non-empty blocks out of 12 blocks
2021-12-08 10:14:44,766 [Executor task launch worker for task 339] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 12 non-empty blocks out of 12 blocks
2021-12-08 10:14:44,766 [Executor task launch worker for task 339] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-08 10:14:44,766 [Executor task launch worker for task 340] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-08 10:14:44,766 [Executor task launch worker for task 343] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 1 ms
2021-12-08 10:14:44,767 [Executor task launch worker for task 341] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_26_9 locally
2021-12-08 10:14:44,767 [Executor task launch worker for task 334] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 12 non-empty blocks out of 12 blocks
2021-12-08 10:14:44,767 [Executor task launch worker for task 334] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-08 10:14:44,767 [Executor task launch worker for task 333] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_26_1 locally
2021-12-08 10:14:44,767 [Executor task launch worker for task 341] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 12 non-empty blocks out of 12 blocks
2021-12-08 10:14:44,767 [Executor task launch worker for task 341] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-08 10:14:44,767 [Executor task launch worker for task 333] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 12 non-empty blocks out of 12 blocks
2021-12-08 10:14:44,767 [Executor task launch worker for task 333] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-08 10:14:44,767 [Executor task launch worker for task 338] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_26_6 locally
2021-12-08 10:14:44,767 [Executor task launch worker for task 338] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 12 non-empty blocks out of 12 blocks
2021-12-08 10:14:44,767 [Executor task launch worker for task 338] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-08 10:14:44,870 [dispatcher-event-loop-11] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_34_piece0 on qb:61292 in memory (size: 1582.4 KB, free: 1666.1 MB)
2021-12-08 10:14:45,367 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 685
2021-12-08 10:14:45,368 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 690
2021-12-08 10:14:45,368 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 706
2021-12-08 10:14:45,368 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 704
2021-12-08 10:14:45,369 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 718
2021-12-08 10:14:45,369 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 699
2021-12-08 10:14:45,369 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 702
2021-12-08 10:14:45,370 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 714
2021-12-08 10:14:45,370 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 682
2021-12-08 10:14:45,370 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 694
2021-12-08 10:14:45,370 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 719
2021-12-08 10:14:45,370 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 678
2021-12-08 10:14:45,370 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 717
2021-12-08 10:14:45,370 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 715
2021-12-08 10:14:45,371 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 684
2021-12-08 10:14:45,374 [dispatcher-event-loop-4] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_33_piece0 on qb:61292 in memory (size: 1583.4 KB, free: 1667.7 MB)
2021-12-08 10:14:45,377 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 681
2021-12-08 10:14:45,377 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 709
2021-12-08 10:14:45,377 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 707
2021-12-08 10:14:45,377 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 683
2021-12-08 10:14:45,377 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 708
2021-12-08 10:14:45,377 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 689
2021-12-08 10:14:45,377 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 720
2021-12-08 10:14:45,377 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 695
2021-12-08 10:14:45,377 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 721
2021-12-08 10:14:45,377 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 711
2021-12-08 10:14:45,377 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 679
2021-12-08 10:14:45,377 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 716
2021-12-08 10:14:45,377 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 696
2021-12-08 10:14:45,377 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 677
2021-12-08 10:14:45,377 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 697
2021-12-08 10:14:45,377 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 705
2021-12-08 10:14:45,377 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 701
2021-12-08 10:14:45,377 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 680
2021-12-08 10:14:45,377 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 686
2021-12-08 10:14:45,377 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 675
2021-12-08 10:14:45,377 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 713
2021-12-08 10:14:45,377 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 698
2021-12-08 10:14:45,377 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 724
2021-12-08 10:14:45,377 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 692
2021-12-08 10:14:45,377 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 687
2021-12-08 10:14:45,377 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 703
2021-12-08 10:14:45,377 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 693
2021-12-08 10:14:45,377 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 723
2021-12-08 10:14:45,377 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 710
2021-12-08 10:14:45,377 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 691
2021-12-08 10:14:45,377 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 722
2021-12-08 10:14:45,377 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 676
2021-12-08 10:14:45,377 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 700
2021-12-08 10:14:45,377 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 712
2021-12-08 10:14:45,377 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 688
2021-12-08 10:15:06,740 [Executor task launch worker for task 337] INFO [org.apache.spark.storage.memory.MemoryStore] - Block rdd_139_5 stored as values in memory (estimated size 4.0 MB, free 1660.3 MB)
2021-12-08 10:15:06,740 [dispatcher-event-loop-5] INFO [org.apache.spark.storage.BlockManagerInfo] - Added rdd_139_5 in memory on qb:61292 (size: 4.0 MB, free: 1663.7 MB)
2021-12-08 10:15:06,859 [Executor task launch worker for task 337] INFO [org.apache.spark.executor.Executor] - Finished task 5.0 in stage 131.0 (TID 337). 166097 bytes result sent to driver
2021-12-08 10:15:06,859 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 5.0 in stage 131.0 (TID 337) in 22099 ms on localhost (executor driver) (1/12)
2021-12-08 10:15:06,899 [Executor task launch worker for task 333] INFO [org.apache.spark.storage.memory.MemoryStore] - Block rdd_139_1 stored as values in memory (estimated size 4.0 MB, free 1656.3 MB)
2021-12-08 10:15:06,899 [dispatcher-event-loop-3] INFO [org.apache.spark.storage.BlockManagerInfo] - Added rdd_139_1 in memory on qb:61292 (size: 4.0 MB, free: 1659.7 MB)
2021-12-08 10:15:06,988 [Executor task launch worker for task 332] INFO [org.apache.spark.storage.memory.MemoryStore] - Block rdd_139_0 stored as values in memory (estimated size 4.0 MB, free 1652.3 MB)
2021-12-08 10:15:06,988 [dispatcher-event-loop-4] INFO [org.apache.spark.storage.BlockManagerInfo] - Added rdd_139_0 in memory on qb:61292 (size: 4.0 MB, free: 1655.7 MB)
2021-12-08 10:15:07,027 [Executor task launch worker for task 333] INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 131.0 (TID 333). 166097 bytes result sent to driver
2021-12-08 10:15:07,033 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 131.0 (TID 333) in 22273 ms on localhost (executor driver) (2/12)
2021-12-08 10:15:07,103 [Executor task launch worker for task 332] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 131.0 (TID 332). 166054 bytes result sent to driver
2021-12-08 10:15:07,104 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 131.0 (TID 332) in 22344 ms on localhost (executor driver) (3/12)
2021-12-08 10:15:07,160 [Executor task launch worker for task 343] INFO [org.apache.spark.storage.memory.MemoryStore] - Block rdd_139_11 stored as values in memory (estimated size 4.0 MB, free 1648.3 MB)
2021-12-08 10:15:07,160 [dispatcher-event-loop-8] INFO [org.apache.spark.storage.BlockManagerInfo] - Added rdd_139_11 in memory on qb:61292 (size: 4.0 MB, free: 1651.7 MB)
2021-12-08 10:15:07,280 [Executor task launch worker for task 343] INFO [org.apache.spark.executor.Executor] - Finished task 11.0 in stage 131.0 (TID 343). 166054 bytes result sent to driver
2021-12-08 10:15:07,281 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 11.0 in stage 131.0 (TID 343) in 22520 ms on localhost (executor driver) (4/12)
2021-12-08 10:15:07,378 [Executor task launch worker for task 336] INFO [org.apache.spark.storage.memory.MemoryStore] - Block rdd_139_4 stored as values in memory (estimated size 4.0 MB, free 1644.3 MB)
2021-12-08 10:15:07,379 [dispatcher-event-loop-2] INFO [org.apache.spark.storage.BlockManagerInfo] - Added rdd_139_4 in memory on qb:61292 (size: 4.0 MB, free: 1647.7 MB)
2021-12-08 10:15:07,482 [Executor task launch worker for task 336] INFO [org.apache.spark.executor.Executor] - Finished task 4.0 in stage 131.0 (TID 336). 166054 bytes result sent to driver
2021-12-08 10:15:07,482 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 4.0 in stage 131.0 (TID 336) in 22722 ms on localhost (executor driver) (5/12)
2021-12-08 10:15:07,610 [Executor task launch worker for task 342] INFO [org.apache.spark.storage.memory.MemoryStore] - Block rdd_139_10 stored as values in memory (estimated size 4.0 MB, free 1640.3 MB)
2021-12-08 10:15:07,610 [dispatcher-event-loop-0] INFO [org.apache.spark.storage.BlockManagerInfo] - Added rdd_139_10 in memory on qb:61292 (size: 4.0 MB, free: 1643.7 MB)
2021-12-08 10:15:07,688 [Executor task launch worker for task 342] INFO [org.apache.spark.executor.Executor] - Finished task 10.0 in stage 131.0 (TID 342). 166054 bytes result sent to driver
2021-12-08 10:15:07,689 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 10.0 in stage 131.0 (TID 342) in 22929 ms on localhost (executor driver) (6/12)
2021-12-08 10:15:07,872 [Executor task launch worker for task 339] INFO [org.apache.spark.storage.memory.MemoryStore] - Block rdd_139_7 stored as values in memory (estimated size 4.0 MB, free 1636.3 MB)
2021-12-08 10:15:07,872 [dispatcher-event-loop-5] INFO [org.apache.spark.storage.BlockManagerInfo] - Added rdd_139_7 in memory on qb:61292 (size: 4.0 MB, free: 1639.8 MB)
2021-12-08 10:15:07,943 [Executor task launch worker for task 339] INFO [org.apache.spark.executor.Executor] - Finished task 7.0 in stage 131.0 (TID 339). 166054 bytes result sent to driver
2021-12-08 10:15:07,944 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 7.0 in stage 131.0 (TID 339) in 23184 ms on localhost (executor driver) (7/12)
2021-12-08 10:15:08,045 [Executor task launch worker for task 340] INFO [org.apache.spark.storage.memory.MemoryStore] - Block rdd_139_8 stored as values in memory (estimated size 4.0 MB, free 1632.3 MB)
2021-12-08 10:15:08,045 [dispatcher-event-loop-3] INFO [org.apache.spark.storage.BlockManagerInfo] - Added rdd_139_8 in memory on qb:61292 (size: 4.0 MB, free: 1635.8 MB)
2021-12-08 10:15:08,131 [Executor task launch worker for task 340] INFO [org.apache.spark.executor.Executor] - Finished task 8.0 in stage 131.0 (TID 340). 166054 bytes result sent to driver
2021-12-08 10:15:08,131 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 8.0 in stage 131.0 (TID 340) in 23371 ms on localhost (executor driver) (8/12)
2021-12-08 10:15:08,593 [Executor task launch worker for task 341] INFO [org.apache.spark.storage.memory.MemoryStore] - Block rdd_139_9 stored as values in memory (estimated size 4.0 MB, free 1628.4 MB)
2021-12-08 10:15:08,593 [dispatcher-event-loop-10] INFO [org.apache.spark.storage.BlockManagerInfo] - Added rdd_139_9 in memory on qb:61292 (size: 4.0 MB, free: 1631.8 MB)
2021-12-08 10:15:08,596 [Executor task launch worker for task 335] INFO [org.apache.spark.storage.memory.MemoryStore] - Block rdd_139_3 stored as values in memory (estimated size 4.0 MB, free 1624.4 MB)
2021-12-08 10:15:08,597 [dispatcher-event-loop-6] INFO [org.apache.spark.storage.BlockManagerInfo] - Added rdd_139_3 in memory on qb:61292 (size: 4.0 MB, free: 1627.8 MB)
2021-12-08 10:15:08,662 [Executor task launch worker for task 341] INFO [org.apache.spark.executor.Executor] - Finished task 9.0 in stage 131.0 (TID 341). 166054 bytes result sent to driver
2021-12-08 10:15:08,662 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 9.0 in stage 131.0 (TID 341) in 23902 ms on localhost (executor driver) (9/12)
2021-12-08 10:15:08,664 [Executor task launch worker for task 335] INFO [org.apache.spark.executor.Executor] - Finished task 3.0 in stage 131.0 (TID 335). 166054 bytes result sent to driver
2021-12-08 10:15:08,665 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 3.0 in stage 131.0 (TID 335) in 23905 ms on localhost (executor driver) (10/12)
2021-12-08 10:15:08,986 [Executor task launch worker for task 338] INFO [org.apache.spark.storage.memory.MemoryStore] - Block rdd_139_6 stored as values in memory (estimated size 4.0 MB, free 1620.4 MB)
2021-12-08 10:15:08,986 [dispatcher-event-loop-2] INFO [org.apache.spark.storage.BlockManagerInfo] - Added rdd_139_6 in memory on qb:61292 (size: 4.0 MB, free: 1623.8 MB)
2021-12-08 10:15:09,032 [Executor task launch worker for task 334] INFO [org.apache.spark.storage.memory.MemoryStore] - Block rdd_139_2 stored as values in memory (estimated size 4.0 MB, free 1616.4 MB)
2021-12-08 10:15:09,032 [dispatcher-event-loop-9] INFO [org.apache.spark.storage.BlockManagerInfo] - Added rdd_139_2 in memory on qb:61292 (size: 4.0 MB, free: 1619.8 MB)
2021-12-08 10:15:09,049 [Executor task launch worker for task 338] INFO [org.apache.spark.executor.Executor] - Finished task 6.0 in stage 131.0 (TID 338). 166054 bytes result sent to driver
2021-12-08 10:15:09,050 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 6.0 in stage 131.0 (TID 338) in 24290 ms on localhost (executor driver) (11/12)
2021-12-08 10:15:09,095 [Executor task launch worker for task 334] INFO [org.apache.spark.executor.Executor] - Finished task 2.0 in stage 131.0 (TID 334). 166054 bytes result sent to driver
2021-12-08 10:15:09,095 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 2.0 in stage 131.0 (TID 334) in 24335 ms on localhost (executor driver) (12/12)
2021-12-08 10:15:09,095 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 131.0, whose tasks have all completed, from pool 
2021-12-08 10:15:09,095 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 131 (aggregate at ALS.scala:1711) finished in 24.341 s
2021-12-08 10:15:09,096 [main] INFO [org.apache.spark.scheduler.DAGScheduler] - Job 15 finished: aggregate at ALS.scala:1711, took 26.997727 s
2021-12-08 10:15:09,110 [main] INFO [org.apache.spark.rdd.MapPartitionsRDD] - Removing RDD 129 from persistence list
2021-12-08 10:15:09,110 [block-manager-slave-async-thread-pool-2] INFO [org.apache.spark.storage.BlockManager] - Removing RDD 129
2021-12-08 10:15:09,116 [main] INFO [org.apache.spark.SparkContext] - Starting job: aggregate at ALS.scala:1711
2021-12-08 10:15:09,117 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 144 (flatMap at ALS.scala:1653)
2021-12-08 10:15:09,118 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 16 (aggregate at ALS.scala:1711) with 12 output partitions
2021-12-08 10:15:09,118 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 148 (aggregate at ALS.scala:1711)
2021-12-08 10:15:09,118 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 147, ShuffleMapStage 133)
2021-12-08 10:15:09,118 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List(ShuffleMapStage 147)
2021-12-08 10:15:09,118 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ShuffleMapStage 147 (MapPartitionsRDD[144] at flatMap at ALS.scala:1653), which has no missing parents
2021-12-08 10:15:09,121 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_36 stored as values in memory (estimated size 1783.1 KB, free 1747.9 MB)
2021-12-08 10:15:09,123 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_36_piece0 stored as bytes in memory (estimated size 1740.1 KB, free 1746.2 MB)
2021-12-08 10:15:09,123 [dispatcher-event-loop-8] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_36_piece0 in memory on qb:61292 (size: 1740.1 KB, free: 1751.4 MB)
2021-12-08 10:15:09,123 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 36 from broadcast at DAGScheduler.scala:1039
2021-12-08 10:15:09,124 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 12 missing tasks from ShuffleMapStage 147 (MapPartitionsRDD[144] at flatMap at ALS.scala:1653) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11))
2021-12-08 10:15:09,124 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 147.0 with 12 tasks
2021-12-08 10:15:09,124 [dispatcher-event-loop-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 147.0 (TID 344, localhost, executor driver, partition 0, PROCESS_LOCAL, 7928 bytes)
2021-12-08 10:15:09,124 [dispatcher-event-loop-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 147.0 (TID 345, localhost, executor driver, partition 1, PROCESS_LOCAL, 7928 bytes)
2021-12-08 10:15:09,124 [dispatcher-event-loop-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 2.0 in stage 147.0 (TID 346, localhost, executor driver, partition 2, PROCESS_LOCAL, 7928 bytes)
2021-12-08 10:15:09,124 [dispatcher-event-loop-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 3.0 in stage 147.0 (TID 347, localhost, executor driver, partition 3, PROCESS_LOCAL, 7928 bytes)
2021-12-08 10:15:09,124 [dispatcher-event-loop-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 4.0 in stage 147.0 (TID 348, localhost, executor driver, partition 4, PROCESS_LOCAL, 7928 bytes)
2021-12-08 10:15:09,124 [dispatcher-event-loop-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 5.0 in stage 147.0 (TID 349, localhost, executor driver, partition 5, PROCESS_LOCAL, 7928 bytes)
2021-12-08 10:15:09,124 [dispatcher-event-loop-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 6.0 in stage 147.0 (TID 350, localhost, executor driver, partition 6, PROCESS_LOCAL, 7928 bytes)
2021-12-08 10:15:09,124 [dispatcher-event-loop-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 7.0 in stage 147.0 (TID 351, localhost, executor driver, partition 7, PROCESS_LOCAL, 7928 bytes)
2021-12-08 10:15:09,124 [dispatcher-event-loop-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 8.0 in stage 147.0 (TID 352, localhost, executor driver, partition 8, PROCESS_LOCAL, 7928 bytes)
2021-12-08 10:15:09,124 [dispatcher-event-loop-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 9.0 in stage 147.0 (TID 353, localhost, executor driver, partition 9, PROCESS_LOCAL, 7928 bytes)
2021-12-08 10:15:09,124 [dispatcher-event-loop-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 10.0 in stage 147.0 (TID 354, localhost, executor driver, partition 10, PROCESS_LOCAL, 7928 bytes)
2021-12-08 10:15:09,124 [dispatcher-event-loop-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 11.0 in stage 147.0 (TID 355, localhost, executor driver, partition 11, PROCESS_LOCAL, 7928 bytes)
2021-12-08 10:15:09,125 [Executor task launch worker for task 345] INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 147.0 (TID 345)
2021-12-08 10:15:09,125 [Executor task launch worker for task 347] INFO [org.apache.spark.executor.Executor] - Running task 3.0 in stage 147.0 (TID 347)
2021-12-08 10:15:09,125 [Executor task launch worker for task 354] INFO [org.apache.spark.executor.Executor] - Running task 10.0 in stage 147.0 (TID 354)
2021-12-08 10:15:09,125 [Executor task launch worker for task 351] INFO [org.apache.spark.executor.Executor] - Running task 7.0 in stage 147.0 (TID 351)
2021-12-08 10:15:09,125 [Executor task launch worker for task 353] INFO [org.apache.spark.executor.Executor] - Running task 9.0 in stage 147.0 (TID 353)
2021-12-08 10:15:09,125 [Executor task launch worker for task 352] INFO [org.apache.spark.executor.Executor] - Running task 8.0 in stage 147.0 (TID 352)
2021-12-08 10:15:09,125 [Executor task launch worker for task 344] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 147.0 (TID 344)
2021-12-08 10:15:09,125 [Executor task launch worker for task 349] INFO [org.apache.spark.executor.Executor] - Running task 5.0 in stage 147.0 (TID 349)
2021-12-08 10:15:09,125 [Executor task launch worker for task 350] INFO [org.apache.spark.executor.Executor] - Running task 6.0 in stage 147.0 (TID 350)
2021-12-08 10:15:09,125 [Executor task launch worker for task 348] INFO [org.apache.spark.executor.Executor] - Running task 4.0 in stage 147.0 (TID 348)
2021-12-08 10:15:09,125 [Executor task launch worker for task 346] INFO [org.apache.spark.executor.Executor] - Running task 2.0 in stage 147.0 (TID 346)
2021-12-08 10:15:09,125 [Executor task launch worker for task 355] INFO [org.apache.spark.executor.Executor] - Running task 11.0 in stage 147.0 (TID 355)
2021-12-08 10:15:09,128 [Executor task launch worker for task 348] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_27_4 locally
2021-12-08 10:15:09,128 [Executor task launch worker for task 348] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_139_4 locally
2021-12-08 10:15:09,128 [Executor task launch worker for task 345] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_27_1 locally
2021-12-08 10:15:09,128 [Executor task launch worker for task 349] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_27_5 locally
2021-12-08 10:15:09,128 [Executor task launch worker for task 350] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_27_6 locally
2021-12-08 10:15:09,128 [Executor task launch worker for task 353] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_27_9 locally
2021-12-08 10:15:09,128 [Executor task launch worker for task 346] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_27_2 locally
2021-12-08 10:15:09,128 [Executor task launch worker for task 347] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_27_3 locally
2021-12-08 10:15:09,128 [Executor task launch worker for task 350] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_139_6 locally
2021-12-08 10:15:09,128 [Executor task launch worker for task 352] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_27_8 locally
2021-12-08 10:15:09,128 [Executor task launch worker for task 345] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_139_1 locally
2021-12-08 10:15:09,128 [Executor task launch worker for task 355] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_27_11 locally
2021-12-08 10:15:09,128 [Executor task launch worker for task 347] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_139_3 locally
2021-12-08 10:15:09,128 [Executor task launch worker for task 353] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_139_9 locally
2021-12-08 10:15:09,128 [Executor task launch worker for task 354] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_27_10 locally
2021-12-08 10:15:09,128 [Executor task launch worker for task 346] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_139_2 locally
2021-12-08 10:15:09,128 [Executor task launch worker for task 349] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_139_5 locally
2021-12-08 10:15:09,128 [Executor task launch worker for task 344] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_27_0 locally
2021-12-08 10:15:09,129 [Executor task launch worker for task 344] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_139_0 locally
2021-12-08 10:15:09,129 [Executor task launch worker for task 355] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_139_11 locally
2021-12-08 10:15:09,129 [Executor task launch worker for task 354] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_139_10 locally
2021-12-08 10:15:09,129 [Executor task launch worker for task 352] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_139_8 locally
2021-12-08 10:15:09,130 [Executor task launch worker for task 351] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_27_7 locally
2021-12-08 10:15:09,130 [Executor task launch worker for task 351] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_139_7 locally
2021-12-08 10:15:10,070 [Executor task launch worker for task 350] INFO [org.apache.spark.executor.Executor] - Finished task 6.0 in stage 147.0 (TID 350). 1042 bytes result sent to driver
2021-12-08 10:15:10,070 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 6.0 in stage 147.0 (TID 350) in 946 ms on localhost (executor driver) (1/12)
2021-12-08 10:15:10,141 [Executor task launch worker for task 345] INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 147.0 (TID 345). 1042 bytes result sent to driver
2021-12-08 10:15:10,142 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 147.0 (TID 345) in 1018 ms on localhost (executor driver) (2/12)
2021-12-08 10:15:10,146 [Executor task launch worker for task 344] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 147.0 (TID 344). 1042 bytes result sent to driver
2021-12-08 10:15:10,146 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 147.0 (TID 344) in 1022 ms on localhost (executor driver) (3/12)
2021-12-08 10:15:10,148 [Executor task launch worker for task 351] INFO [org.apache.spark.executor.Executor] - Finished task 7.0 in stage 147.0 (TID 351). 1042 bytes result sent to driver
2021-12-08 10:15:10,149 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 7.0 in stage 147.0 (TID 351) in 1025 ms on localhost (executor driver) (4/12)
2021-12-08 10:15:10,155 [Executor task launch worker for task 352] INFO [org.apache.spark.executor.Executor] - Finished task 8.0 in stage 147.0 (TID 352). 1042 bytes result sent to driver
2021-12-08 10:15:10,156 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 8.0 in stage 147.0 (TID 352) in 1032 ms on localhost (executor driver) (5/12)
2021-12-08 10:15:10,158 [Executor task launch worker for task 346] INFO [org.apache.spark.executor.Executor] - Finished task 2.0 in stage 147.0 (TID 346). 1042 bytes result sent to driver
2021-12-08 10:15:10,158 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 2.0 in stage 147.0 (TID 346) in 1034 ms on localhost (executor driver) (6/12)
2021-12-08 10:15:10,168 [Executor task launch worker for task 349] INFO [org.apache.spark.executor.Executor] - Finished task 5.0 in stage 147.0 (TID 349). 1042 bytes result sent to driver
2021-12-08 10:15:10,168 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 5.0 in stage 147.0 (TID 349) in 1044 ms on localhost (executor driver) (7/12)
2021-12-08 10:15:10,230 [Executor task launch worker for task 347] INFO [org.apache.spark.executor.Executor] - Finished task 3.0 in stage 147.0 (TID 347). 1042 bytes result sent to driver
2021-12-08 10:15:10,230 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 3.0 in stage 147.0 (TID 347) in 1106 ms on localhost (executor driver) (8/12)
2021-12-08 10:15:10,237 [Executor task launch worker for task 353] INFO [org.apache.spark.executor.Executor] - Finished task 9.0 in stage 147.0 (TID 353). 1042 bytes result sent to driver
2021-12-08 10:15:10,237 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 9.0 in stage 147.0 (TID 353) in 1113 ms on localhost (executor driver) (9/12)
2021-12-08 10:15:10,238 [Executor task launch worker for task 348] INFO [org.apache.spark.executor.Executor] - Finished task 4.0 in stage 147.0 (TID 348). 1042 bytes result sent to driver
2021-12-08 10:15:10,238 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 4.0 in stage 147.0 (TID 348) in 1114 ms on localhost (executor driver) (10/12)
2021-12-08 10:15:10,239 [Executor task launch worker for task 354] INFO [org.apache.spark.executor.Executor] - Finished task 10.0 in stage 147.0 (TID 354). 1042 bytes result sent to driver
2021-12-08 10:15:10,239 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 10.0 in stage 147.0 (TID 354) in 1115 ms on localhost (executor driver) (11/12)
2021-12-08 10:15:10,331 [Executor task launch worker for task 355] INFO [org.apache.spark.executor.Executor] - Finished task 11.0 in stage 147.0 (TID 355). 1042 bytes result sent to driver
2021-12-08 10:15:10,331 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 11.0 in stage 147.0 (TID 355) in 1207 ms on localhost (executor driver) (12/12)
2021-12-08 10:15:10,331 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 147.0, whose tasks have all completed, from pool 
2021-12-08 10:15:10,331 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ShuffleMapStage 147 (flatMap at ALS.scala:1653) finished in 1.213 s
2021-12-08 10:15:10,331 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - looking for newly runnable stages
2021-12-08 10:15:10,331 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - running: Set()
2021-12-08 10:15:10,331 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - waiting: Set(ResultStage 148)
2021-12-08 10:15:10,331 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - failed: Set()
2021-12-08 10:15:10,332 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 148 (MapPartitionsRDD[150] at values at ALS.scala:1711), which has no missing parents
2021-12-08 10:15:10,334 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_37 stored as values in memory (estimated size 2.1 MB, free 1744.2 MB)
2021-12-08 10:15:10,337 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_37_piece0 stored as bytes in memory (estimated size 1898.8 KB, free 1742.3 MB)
2021-12-08 10:15:10,338 [dispatcher-event-loop-2] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_37_piece0 in memory on qb:61292 (size: 1898.8 KB, free: 1749.5 MB)
2021-12-08 10:15:10,338 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 37 from broadcast at DAGScheduler.scala:1039
2021-12-08 10:15:10,338 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 12 missing tasks from ResultStage 148 (MapPartitionsRDD[150] at values at ALS.scala:1711) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11))
2021-12-08 10:15:10,338 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 148.0 with 12 tasks
2021-12-08 10:15:10,338 [dispatcher-event-loop-7] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 148.0 (TID 356, localhost, executor driver, partition 0, PROCESS_LOCAL, 7888 bytes)
2021-12-08 10:15:10,338 [dispatcher-event-loop-7] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 148.0 (TID 357, localhost, executor driver, partition 1, PROCESS_LOCAL, 7888 bytes)
2021-12-08 10:15:10,338 [dispatcher-event-loop-7] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 2.0 in stage 148.0 (TID 358, localhost, executor driver, partition 2, PROCESS_LOCAL, 7888 bytes)
2021-12-08 10:15:10,339 [dispatcher-event-loop-7] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 3.0 in stage 148.0 (TID 359, localhost, executor driver, partition 3, PROCESS_LOCAL, 7888 bytes)
2021-12-08 10:15:10,339 [dispatcher-event-loop-7] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 4.0 in stage 148.0 (TID 360, localhost, executor driver, partition 4, PROCESS_LOCAL, 7888 bytes)
2021-12-08 10:15:10,339 [dispatcher-event-loop-7] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 5.0 in stage 148.0 (TID 361, localhost, executor driver, partition 5, PROCESS_LOCAL, 7888 bytes)
2021-12-08 10:15:10,339 [dispatcher-event-loop-7] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 6.0 in stage 148.0 (TID 362, localhost, executor driver, partition 6, PROCESS_LOCAL, 7888 bytes)
2021-12-08 10:15:10,339 [dispatcher-event-loop-7] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 7.0 in stage 148.0 (TID 363, localhost, executor driver, partition 7, PROCESS_LOCAL, 7888 bytes)
2021-12-08 10:15:10,339 [dispatcher-event-loop-7] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 8.0 in stage 148.0 (TID 364, localhost, executor driver, partition 8, PROCESS_LOCAL, 7888 bytes)
2021-12-08 10:15:10,339 [dispatcher-event-loop-7] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 9.0 in stage 148.0 (TID 365, localhost, executor driver, partition 9, PROCESS_LOCAL, 7888 bytes)
2021-12-08 10:15:10,339 [dispatcher-event-loop-7] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 10.0 in stage 148.0 (TID 366, localhost, executor driver, partition 10, PROCESS_LOCAL, 7888 bytes)
2021-12-08 10:15:10,339 [dispatcher-event-loop-7] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 11.0 in stage 148.0 (TID 367, localhost, executor driver, partition 11, PROCESS_LOCAL, 7888 bytes)
2021-12-08 10:15:10,339 [Executor task launch worker for task 357] INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 148.0 (TID 357)
2021-12-08 10:15:10,339 [Executor task launch worker for task 362] INFO [org.apache.spark.executor.Executor] - Running task 6.0 in stage 148.0 (TID 362)
2021-12-08 10:15:10,339 [Executor task launch worker for task 367] INFO [org.apache.spark.executor.Executor] - Running task 11.0 in stage 148.0 (TID 367)
2021-12-08 10:15:10,339 [Executor task launch worker for task 366] INFO [org.apache.spark.executor.Executor] - Running task 10.0 in stage 148.0 (TID 366)
2021-12-08 10:15:10,339 [Executor task launch worker for task 358] INFO [org.apache.spark.executor.Executor] - Running task 2.0 in stage 148.0 (TID 358)
2021-12-08 10:15:10,339 [Executor task launch worker for task 364] INFO [org.apache.spark.executor.Executor] - Running task 8.0 in stage 148.0 (TID 364)
2021-12-08 10:15:10,339 [Executor task launch worker for task 365] INFO [org.apache.spark.executor.Executor] - Running task 9.0 in stage 148.0 (TID 365)
2021-12-08 10:15:10,339 [Executor task launch worker for task 359] INFO [org.apache.spark.executor.Executor] - Running task 3.0 in stage 148.0 (TID 359)
2021-12-08 10:15:10,339 [Executor task launch worker for task 363] INFO [org.apache.spark.executor.Executor] - Running task 7.0 in stage 148.0 (TID 363)
2021-12-08 10:15:10,339 [Executor task launch worker for task 361] INFO [org.apache.spark.executor.Executor] - Running task 5.0 in stage 148.0 (TID 361)
2021-12-08 10:15:10,339 [Executor task launch worker for task 360] INFO [org.apache.spark.executor.Executor] - Running task 4.0 in stage 148.0 (TID 360)
2021-12-08 10:15:10,339 [Executor task launch worker for task 356] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 148.0 (TID 356)
2021-12-08 10:15:10,343 [Executor task launch worker for task 367] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_21_11 locally
2021-12-08 10:15:10,343 [Executor task launch worker for task 358] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_21_2 locally
2021-12-08 10:15:10,343 [Executor task launch worker for task 359] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_21_3 locally
2021-12-08 10:15:10,343 [Executor task launch worker for task 360] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_21_4 locally
2021-12-08 10:15:10,343 [Executor task launch worker for task 363] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_21_7 locally
2021-12-08 10:15:10,343 [Executor task launch worker for task 365] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_21_9 locally
2021-12-08 10:15:10,344 [Executor task launch worker for task 359] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 12 non-empty blocks out of 12 blocks
2021-12-08 10:15:10,344 [Executor task launch worker for task 359] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-08 10:15:10,344 [Executor task launch worker for task 360] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 12 non-empty blocks out of 12 blocks
2021-12-08 10:15:10,344 [Executor task launch worker for task 365] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 12 non-empty blocks out of 12 blocks
2021-12-08 10:15:10,344 [Executor task launch worker for task 358] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 12 non-empty blocks out of 12 blocks
2021-12-08 10:15:10,344 [Executor task launch worker for task 367] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 12 non-empty blocks out of 12 blocks
2021-12-08 10:15:10,344 [Executor task launch worker for task 358] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-08 10:15:10,344 [Executor task launch worker for task 365] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-08 10:15:10,344 [Executor task launch worker for task 360] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-08 10:15:10,344 [Executor task launch worker for task 363] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 12 non-empty blocks out of 12 blocks
2021-12-08 10:15:10,344 [Executor task launch worker for task 363] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-08 10:15:10,344 [Executor task launch worker for task 362] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_21_6 locally
2021-12-08 10:15:10,344 [Executor task launch worker for task 367] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-08 10:15:10,344 [Executor task launch worker for task 356] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_21_0 locally
2021-12-08 10:15:10,344 [Executor task launch worker for task 364] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_21_8 locally
2021-12-08 10:15:10,344 [Executor task launch worker for task 356] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 12 non-empty blocks out of 12 blocks
2021-12-08 10:15:10,344 [Executor task launch worker for task 356] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-08 10:15:10,344 [Executor task launch worker for task 357] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_21_1 locally
2021-12-08 10:15:10,344 [Executor task launch worker for task 364] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 12 non-empty blocks out of 12 blocks
2021-12-08 10:15:10,344 [Executor task launch worker for task 362] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 12 non-empty blocks out of 12 blocks
2021-12-08 10:15:10,344 [Executor task launch worker for task 362] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-08 10:15:10,344 [Executor task launch worker for task 357] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 12 non-empty blocks out of 12 blocks
2021-12-08 10:15:10,345 [Executor task launch worker for task 364] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 1 ms
2021-12-08 10:15:10,345 [Executor task launch worker for task 357] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 1 ms
2021-12-08 10:15:10,345 [Executor task launch worker for task 361] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_21_5 locally
2021-12-08 10:15:10,345 [Executor task launch worker for task 366] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_21_10 locally
2021-12-08 10:15:10,345 [Executor task launch worker for task 366] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 12 non-empty blocks out of 12 blocks
2021-12-08 10:15:10,345 [Executor task launch worker for task 361] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 12 non-empty blocks out of 12 blocks
2021-12-08 10:15:10,345 [Executor task launch worker for task 366] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-08 10:15:10,345 [Executor task launch worker for task 361] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-08 10:15:47,071 [Executor task launch worker for task 362] INFO [org.apache.spark.storage.memory.MemoryStore] - Block rdd_149_6 stored as values in memory (estimated size 11.1 MB, free 1731.2 MB)
2021-12-08 10:15:47,071 [dispatcher-event-loop-9] INFO [org.apache.spark.storage.BlockManagerInfo] - Added rdd_149_6 in memory on qb:61292 (size: 11.1 MB, free: 1738.4 MB)
2021-12-08 10:15:47,248 [Executor task launch worker for task 361] INFO [org.apache.spark.storage.memory.MemoryStore] - Block rdd_149_5 stored as values in memory (estimated size 11.1 MB, free 1720.1 MB)
2021-12-08 10:15:47,248 [dispatcher-event-loop-2] INFO [org.apache.spark.storage.BlockManagerInfo] - Added rdd_149_5 in memory on qb:61292 (size: 11.1 MB, free: 1727.3 MB)
2021-12-08 10:15:47,311 [Executor task launch worker for task 363] INFO [org.apache.spark.storage.memory.MemoryStore] - Block rdd_149_7 stored as values in memory (estimated size 11.1 MB, free 1709.0 MB)
2021-12-08 10:15:47,311 [dispatcher-event-loop-0] INFO [org.apache.spark.storage.BlockManagerInfo] - Added rdd_149_7 in memory on qb:61292 (size: 11.1 MB, free: 1716.2 MB)
2021-12-08 10:15:47,365 [Executor task launch worker for task 358] INFO [org.apache.spark.storage.memory.MemoryStore] - Block rdd_149_2 stored as values in memory (estimated size 11.1 MB, free 1697.9 MB)
2021-12-08 10:15:47,366 [dispatcher-event-loop-7] INFO [org.apache.spark.storage.BlockManagerInfo] - Added rdd_149_2 in memory on qb:61292 (size: 11.1 MB, free: 1705.1 MB)
2021-12-08 10:15:47,414 [Executor task launch worker for task 362] INFO [org.apache.spark.executor.Executor] - Finished task 6.0 in stage 148.0 (TID 362). 166054 bytes result sent to driver
2021-12-08 10:15:47,424 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 6.0 in stage 148.0 (TID 362) in 37085 ms on localhost (executor driver) (1/12)
2021-12-08 10:15:47,435 [Executor task launch worker for task 366] INFO [org.apache.spark.storage.memory.MemoryStore] - Block rdd_149_10 stored as values in memory (estimated size 11.1 MB, free 1686.8 MB)
2021-12-08 10:15:47,435 [dispatcher-event-loop-5] INFO [org.apache.spark.storage.BlockManagerInfo] - Added rdd_149_10 in memory on qb:61292 (size: 11.1 MB, free: 1694.0 MB)
2021-12-08 10:15:47,444 [Executor task launch worker for task 364] INFO [org.apache.spark.storage.memory.MemoryStore] - Block rdd_149_8 stored as values in memory (estimated size 11.1 MB, free 1675.7 MB)
2021-12-08 10:15:47,444 [dispatcher-event-loop-4] INFO [org.apache.spark.storage.BlockManagerInfo] - Added rdd_149_8 in memory on qb:61292 (size: 11.1 MB, free: 1682.9 MB)
2021-12-08 10:15:47,512 [Executor task launch worker for task 356] INFO [org.apache.spark.storage.memory.MemoryStore] - Block rdd_149_0 stored as values in memory (estimated size 11.1 MB, free 1664.6 MB)
2021-12-08 10:15:47,512 [dispatcher-event-loop-10] INFO [org.apache.spark.storage.BlockManagerInfo] - Added rdd_149_0 in memory on qb:61292 (size: 11.1 MB, free: 1671.8 MB)
2021-12-08 10:15:47,569 [Executor task launch worker for task 359] INFO [org.apache.spark.storage.memory.MemoryStore] - Block rdd_149_3 stored as values in memory (estimated size 11.1 MB, free 1653.5 MB)
2021-12-08 10:15:47,569 [dispatcher-event-loop-3] INFO [org.apache.spark.storage.BlockManagerInfo] - Added rdd_149_3 in memory on qb:61292 (size: 11.1 MB, free: 1660.7 MB)
2021-12-08 10:15:47,587 [Executor task launch worker for task 365] INFO [org.apache.spark.storage.memory.MemoryStore] - Block rdd_149_9 stored as values in memory (estimated size 11.1 MB, free 1642.4 MB)
2021-12-08 10:15:47,587 [dispatcher-event-loop-6] INFO [org.apache.spark.storage.BlockManagerInfo] - Added rdd_149_9 in memory on qb:61292 (size: 11.1 MB, free: 1649.6 MB)
2021-12-08 10:15:47,591 [Executor task launch worker for task 361] INFO [org.apache.spark.executor.Executor] - Finished task 5.0 in stage 148.0 (TID 361). 166054 bytes result sent to driver
2021-12-08 10:15:47,591 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 5.0 in stage 148.0 (TID 361) in 37252 ms on localhost (executor driver) (2/12)
2021-12-08 10:15:47,640 [Executor task launch worker for task 363] INFO [org.apache.spark.executor.Executor] - Finished task 7.0 in stage 148.0 (TID 363). 166054 bytes result sent to driver
2021-12-08 10:15:47,640 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 7.0 in stage 148.0 (TID 363) in 37301 ms on localhost (executor driver) (3/12)
2021-12-08 10:15:47,645 [Executor task launch worker for task 367] INFO [org.apache.spark.storage.memory.MemoryStore] - Block rdd_149_11 stored as values in memory (estimated size 11.1 MB, free 1631.3 MB)
2021-12-08 10:15:47,645 [dispatcher-event-loop-9] INFO [org.apache.spark.storage.BlockManagerInfo] - Added rdd_149_11 in memory on qb:61292 (size: 11.1 MB, free: 1638.5 MB)
2021-12-08 10:15:47,702 [Executor task launch worker for task 358] INFO [org.apache.spark.executor.Executor] - Finished task 2.0 in stage 148.0 (TID 358). 166054 bytes result sent to driver
2021-12-08 10:15:47,702 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 2.0 in stage 148.0 (TID 358) in 37364 ms on localhost (executor driver) (4/12)
2021-12-08 10:15:47,753 [Executor task launch worker for task 366] INFO [org.apache.spark.executor.Executor] - Finished task 10.0 in stage 148.0 (TID 366). 166054 bytes result sent to driver
2021-12-08 10:15:47,753 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 10.0 in stage 148.0 (TID 366) in 37414 ms on localhost (executor driver) (5/12)
2021-12-08 10:15:47,761 [Executor task launch worker for task 360] INFO [org.apache.spark.storage.memory.MemoryStore] - Block rdd_149_4 stored as values in memory (estimated size 11.1 MB, free 1620.1 MB)
2021-12-08 10:15:47,761 [dispatcher-event-loop-7] INFO [org.apache.spark.storage.BlockManagerInfo] - Added rdd_149_4 in memory on qb:61292 (size: 11.1 MB, free: 1627.4 MB)
2021-12-08 10:15:47,764 [Executor task launch worker for task 364] INFO [org.apache.spark.executor.Executor] - Finished task 8.0 in stage 148.0 (TID 364). 166054 bytes result sent to driver
2021-12-08 10:15:47,765 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 8.0 in stage 148.0 (TID 364) in 37426 ms on localhost (executor driver) (6/12)
2021-12-08 10:15:47,781 [Executor task launch worker for task 357] INFO [org.apache.spark.storage.memory.MemoryStore] - Block rdd_149_1 stored as values in memory (estimated size 11.1 MB, free 1609.0 MB)
2021-12-08 10:15:47,781 [dispatcher-event-loop-5] INFO [org.apache.spark.storage.BlockManagerInfo] - Added rdd_149_1 in memory on qb:61292 (size: 11.1 MB, free: 1616.3 MB)
2021-12-08 10:15:47,790 [Executor task launch worker for task 356] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 148.0 (TID 356). 166054 bytes result sent to driver
2021-12-08 10:15:47,791 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 148.0 (TID 356) in 37453 ms on localhost (executor driver) (7/12)
2021-12-08 10:15:47,822 [Executor task launch worker for task 359] INFO [org.apache.spark.executor.Executor] - Finished task 3.0 in stage 148.0 (TID 359). 166054 bytes result sent to driver
2021-12-08 10:15:47,823 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 3.0 in stage 148.0 (TID 359) in 37485 ms on localhost (executor driver) (8/12)
2021-12-08 10:15:47,837 [Executor task launch worker for task 365] INFO [org.apache.spark.executor.Executor] - Finished task 9.0 in stage 148.0 (TID 365). 166097 bytes result sent to driver
2021-12-08 10:15:47,837 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 9.0 in stage 148.0 (TID 365) in 37498 ms on localhost (executor driver) (9/12)
2021-12-08 10:15:47,852 [Executor task launch worker for task 367] INFO [org.apache.spark.executor.Executor] - Finished task 11.0 in stage 148.0 (TID 367). 166054 bytes result sent to driver
2021-12-08 10:15:47,853 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 11.0 in stage 148.0 (TID 367) in 37514 ms on localhost (executor driver) (10/12)
2021-12-08 10:15:47,960 [Executor task launch worker for task 360] INFO [org.apache.spark.executor.Executor] - Finished task 4.0 in stage 148.0 (TID 360). 166054 bytes result sent to driver
2021-12-08 10:15:47,961 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 4.0 in stage 148.0 (TID 360) in 37622 ms on localhost (executor driver) (11/12)
2021-12-08 10:15:47,975 [Executor task launch worker for task 357] INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 148.0 (TID 357). 166054 bytes result sent to driver
2021-12-08 10:15:47,975 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 148.0 (TID 357) in 37637 ms on localhost (executor driver) (12/12)
2021-12-08 10:15:47,975 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 148.0, whose tasks have all completed, from pool 
2021-12-08 10:15:47,975 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 148 (aggregate at ALS.scala:1711) finished in 37.643 s
2021-12-08 10:15:47,976 [main] INFO [org.apache.spark.scheduler.DAGScheduler] - Job 16 finished: aggregate at ALS.scala:1711, took 38.860035 s
2021-12-08 10:15:47,991 [main] INFO [org.apache.spark.rdd.MapPartitionsRDD] - Removing RDD 139 from persistence list
2021-12-08 10:15:47,991 [block-manager-slave-async-thread-pool-1] INFO [org.apache.spark.storage.BlockManager] - Removing RDD 139
2021-12-08 10:15:47,998 [main] INFO [org.apache.spark.SparkContext] - Starting job: aggregate at ALS.scala:1711
2021-12-08 10:15:47,999 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 154 (flatMap at ALS.scala:1653)
2021-12-08 10:15:47,999 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 17 (aggregate at ALS.scala:1711) with 12 output partitions
2021-12-08 10:15:47,999 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 166 (aggregate at ALS.scala:1711)
2021-12-08 10:15:47,999 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 150, ShuffleMapStage 165)
2021-12-08 10:15:47,999 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List(ShuffleMapStage 165)
2021-12-08 10:15:47,999 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ShuffleMapStage 165 (MapPartitionsRDD[154] at flatMap at ALS.scala:1653), which has no missing parents
2021-12-08 10:15:48,002 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_38 stored as values in memory (estimated size 1944.2 KB, free 1655.0 MB)
2021-12-08 10:15:48,006 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_38_piece0 stored as bytes in memory (estimated size 1897.8 KB, free 1653.2 MB)
2021-12-08 10:15:48,006 [dispatcher-event-loop-4] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_38_piece0 in memory on qb:61292 (size: 1897.8 KB, free: 1662.3 MB)
2021-12-08 10:15:48,006 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 38 from broadcast at DAGScheduler.scala:1039
2021-12-08 10:15:48,007 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 12 missing tasks from ShuffleMapStage 165 (MapPartitionsRDD[154] at flatMap at ALS.scala:1653) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11))
2021-12-08 10:15:48,007 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 165.0 with 12 tasks
2021-12-08 10:15:48,007 [dispatcher-event-loop-10] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 165.0 (TID 368, localhost, executor driver, partition 0, PROCESS_LOCAL, 7928 bytes)
2021-12-08 10:15:48,007 [dispatcher-event-loop-10] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 165.0 (TID 369, localhost, executor driver, partition 1, PROCESS_LOCAL, 7928 bytes)
2021-12-08 10:15:48,007 [dispatcher-event-loop-10] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 2.0 in stage 165.0 (TID 370, localhost, executor driver, partition 2, PROCESS_LOCAL, 7928 bytes)
2021-12-08 10:15:48,007 [dispatcher-event-loop-10] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 3.0 in stage 165.0 (TID 371, localhost, executor driver, partition 3, PROCESS_LOCAL, 7928 bytes)
2021-12-08 10:15:48,007 [dispatcher-event-loop-10] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 4.0 in stage 165.0 (TID 372, localhost, executor driver, partition 4, PROCESS_LOCAL, 7928 bytes)
2021-12-08 10:15:48,007 [dispatcher-event-loop-10] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 5.0 in stage 165.0 (TID 373, localhost, executor driver, partition 5, PROCESS_LOCAL, 7928 bytes)
2021-12-08 10:15:48,007 [dispatcher-event-loop-10] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 6.0 in stage 165.0 (TID 374, localhost, executor driver, partition 6, PROCESS_LOCAL, 7928 bytes)
2021-12-08 10:15:48,007 [dispatcher-event-loop-10] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 7.0 in stage 165.0 (TID 375, localhost, executor driver, partition 7, PROCESS_LOCAL, 7928 bytes)
2021-12-08 10:15:48,007 [dispatcher-event-loop-10] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 8.0 in stage 165.0 (TID 376, localhost, executor driver, partition 8, PROCESS_LOCAL, 7928 bytes)
2021-12-08 10:15:48,007 [dispatcher-event-loop-10] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 9.0 in stage 165.0 (TID 377, localhost, executor driver, partition 9, PROCESS_LOCAL, 7928 bytes)
2021-12-08 10:15:48,007 [dispatcher-event-loop-10] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 10.0 in stage 165.0 (TID 378, localhost, executor driver, partition 10, PROCESS_LOCAL, 7928 bytes)
2021-12-08 10:15:48,007 [dispatcher-event-loop-10] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 11.0 in stage 165.0 (TID 379, localhost, executor driver, partition 11, PROCESS_LOCAL, 7928 bytes)
2021-12-08 10:15:48,008 [Executor task launch worker for task 369] INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 165.0 (TID 369)
2021-12-08 10:15:48,008 [Executor task launch worker for task 375] INFO [org.apache.spark.executor.Executor] - Running task 7.0 in stage 165.0 (TID 375)
2021-12-08 10:15:48,008 [Executor task launch worker for task 379] INFO [org.apache.spark.executor.Executor] - Running task 11.0 in stage 165.0 (TID 379)
2021-12-08 10:15:48,008 [Executor task launch worker for task 378] INFO [org.apache.spark.executor.Executor] - Running task 10.0 in stage 165.0 (TID 378)
2021-12-08 10:15:48,008 [Executor task launch worker for task 374] INFO [org.apache.spark.executor.Executor] - Running task 6.0 in stage 165.0 (TID 374)
2021-12-08 10:15:48,008 [Executor task launch worker for task 376] INFO [org.apache.spark.executor.Executor] - Running task 8.0 in stage 165.0 (TID 376)
2021-12-08 10:15:48,008 [Executor task launch worker for task 377] INFO [org.apache.spark.executor.Executor] - Running task 9.0 in stage 165.0 (TID 377)
2021-12-08 10:15:48,008 [Executor task launch worker for task 372] INFO [org.apache.spark.executor.Executor] - Running task 4.0 in stage 165.0 (TID 372)
2021-12-08 10:15:48,008 [Executor task launch worker for task 371] INFO [org.apache.spark.executor.Executor] - Running task 3.0 in stage 165.0 (TID 371)
2021-12-08 10:15:48,008 [Executor task launch worker for task 370] INFO [org.apache.spark.executor.Executor] - Running task 2.0 in stage 165.0 (TID 370)
2021-12-08 10:15:48,008 [Executor task launch worker for task 368] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 165.0 (TID 368)
2021-12-08 10:15:48,008 [Executor task launch worker for task 373] INFO [org.apache.spark.executor.Executor] - Running task 5.0 in stage 165.0 (TID 373)
2021-12-08 10:15:48,011 [Executor task launch worker for task 368] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_22_0 locally
2021-12-08 10:15:48,011 [Executor task launch worker for task 376] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_22_8 locally
2021-12-08 10:15:48,011 [Executor task launch worker for task 373] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_22_5 locally
2021-12-08 10:15:48,011 [Executor task launch worker for task 374] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_22_6 locally
2021-12-08 10:15:48,011 [Executor task launch worker for task 378] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_22_10 locally
2021-12-08 10:15:48,011 [Executor task launch worker for task 370] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_22_2 locally
2021-12-08 10:15:48,011 [Executor task launch worker for task 371] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_22_3 locally
2021-12-08 10:15:48,011 [Executor task launch worker for task 371] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_149_3 locally
2021-12-08 10:15:48,011 [Executor task launch worker for task 376] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_149_8 locally
2021-12-08 10:15:48,011 [Executor task launch worker for task 369] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_22_1 locally
2021-12-08 10:15:48,011 [Executor task launch worker for task 379] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_22_11 locally
2021-12-08 10:15:48,011 [Executor task launch worker for task 368] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_149_0 locally
2021-12-08 10:15:48,011 [Executor task launch worker for task 373] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_149_5 locally
2021-12-08 10:15:48,011 [Executor task launch worker for task 374] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_149_6 locally
2021-12-08 10:15:48,011 [Executor task launch worker for task 375] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_22_7 locally
2021-12-08 10:15:48,011 [Executor task launch worker for task 370] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_149_2 locally
2021-12-08 10:15:48,011 [Executor task launch worker for task 379] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_149_11 locally
2021-12-08 10:15:48,012 [Executor task launch worker for task 369] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_149_1 locally
2021-12-08 10:15:48,012 [Executor task launch worker for task 375] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_149_7 locally
2021-12-08 10:15:48,011 [Executor task launch worker for task 378] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_149_10 locally
2021-12-08 10:15:48,013 [Executor task launch worker for task 372] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_22_4 locally
2021-12-08 10:15:48,013 [Executor task launch worker for task 372] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_149_4 locally
2021-12-08 10:15:48,013 [Executor task launch worker for task 377] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_22_9 locally
2021-12-08 10:15:48,013 [Executor task launch worker for task 377] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_149_9 locally
2021-12-08 10:15:49,648 [Executor task launch worker for task 379] INFO [org.apache.spark.executor.Executor] - Finished task 11.0 in stage 165.0 (TID 379). 1042 bytes result sent to driver
2021-12-08 10:15:49,648 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 11.0 in stage 165.0 (TID 379) in 1641 ms on localhost (executor driver) (1/12)
2021-12-08 10:15:49,712 [Executor task launch worker for task 370] INFO [org.apache.spark.executor.Executor] - Finished task 2.0 in stage 165.0 (TID 370). 1042 bytes result sent to driver
2021-12-08 10:15:49,712 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 2.0 in stage 165.0 (TID 370) in 1705 ms on localhost (executor driver) (2/12)
2021-12-08 10:15:49,793 [Executor task launch worker for task 369] INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 165.0 (TID 369). 1042 bytes result sent to driver
2021-12-08 10:15:49,793 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 165.0 (TID 369) in 1786 ms on localhost (executor driver) (3/12)
2021-12-08 10:15:49,794 [Executor task launch worker for task 368] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 165.0 (TID 368). 1042 bytes result sent to driver
2021-12-08 10:15:49,794 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 165.0 (TID 368) in 1787 ms on localhost (executor driver) (4/12)
2021-12-08 10:15:49,795 [Executor task launch worker for task 376] INFO [org.apache.spark.executor.Executor] - Finished task 8.0 in stage 165.0 (TID 376). 1042 bytes result sent to driver
2021-12-08 10:15:49,795 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 8.0 in stage 165.0 (TID 376) in 1788 ms on localhost (executor driver) (5/12)
2021-12-08 10:15:49,796 [Executor task launch worker for task 378] INFO [org.apache.spark.executor.Executor] - Finished task 10.0 in stage 165.0 (TID 378). 1042 bytes result sent to driver
2021-12-08 10:15:49,796 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 10.0 in stage 165.0 (TID 378) in 1789 ms on localhost (executor driver) (6/12)
2021-12-08 10:15:49,797 [Executor task launch worker for task 374] INFO [org.apache.spark.executor.Executor] - Finished task 6.0 in stage 165.0 (TID 374). 1042 bytes result sent to driver
2021-12-08 10:15:49,797 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 6.0 in stage 165.0 (TID 374) in 1790 ms on localhost (executor driver) (7/12)
2021-12-08 10:15:49,798 [Executor task launch worker for task 371] INFO [org.apache.spark.executor.Executor] - Finished task 3.0 in stage 165.0 (TID 371). 1042 bytes result sent to driver
2021-12-08 10:15:49,798 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 3.0 in stage 165.0 (TID 371) in 1791 ms on localhost (executor driver) (8/12)
2021-12-08 10:15:49,799 [Executor task launch worker for task 373] INFO [org.apache.spark.executor.Executor] - Finished task 5.0 in stage 165.0 (TID 373). 1042 bytes result sent to driver
2021-12-08 10:15:49,799 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 5.0 in stage 165.0 (TID 373) in 1792 ms on localhost (executor driver) (9/12)
2021-12-08 10:15:49,888 [Executor task launch worker for task 377] INFO [org.apache.spark.executor.Executor] - Finished task 9.0 in stage 165.0 (TID 377). 1042 bytes result sent to driver
2021-12-08 10:15:49,888 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 9.0 in stage 165.0 (TID 377) in 1881 ms on localhost (executor driver) (10/12)
2021-12-08 10:15:49,919 [Executor task launch worker for task 372] INFO [org.apache.spark.executor.Executor] - Finished task 4.0 in stage 165.0 (TID 372). 1042 bytes result sent to driver
2021-12-08 10:15:49,919 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 4.0 in stage 165.0 (TID 372) in 1912 ms on localhost (executor driver) (11/12)
2021-12-08 10:15:49,920 [Executor task launch worker for task 375] INFO [org.apache.spark.executor.Executor] - Finished task 7.0 in stage 165.0 (TID 375). 1042 bytes result sent to driver
2021-12-08 10:15:49,920 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 7.0 in stage 165.0 (TID 375) in 1913 ms on localhost (executor driver) (12/12)
2021-12-08 10:15:49,920 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 165.0, whose tasks have all completed, from pool 
2021-12-08 10:15:49,920 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ShuffleMapStage 165 (flatMap at ALS.scala:1653) finished in 1.920 s
2021-12-08 10:15:49,920 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - looking for newly runnable stages
2021-12-08 10:15:49,920 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - running: Set()
2021-12-08 10:15:49,920 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - waiting: Set(ResultStage 166)
2021-12-08 10:15:49,920 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - failed: Set()
2021-12-08 10:15:49,920 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 166 (MapPartitionsRDD[160] at values at ALS.scala:1711), which has no missing parents
2021-12-08 10:15:49,924 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_39 stored as values in memory (estimated size 2.2 MB, free 1650.9 MB)
2021-12-08 10:15:49,927 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_39_piece0 stored as bytes in memory (estimated size 2.0 MB, free 1648.9 MB)
2021-12-08 10:15:49,928 [dispatcher-event-loop-1] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_39_piece0 in memory on qb:61292 (size: 2.0 MB, free: 1660.3 MB)
2021-12-08 10:15:49,928 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 39 from broadcast at DAGScheduler.scala:1039
2021-12-08 10:15:49,928 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 12 missing tasks from ResultStage 166 (MapPartitionsRDD[160] at values at ALS.scala:1711) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11))
2021-12-08 10:15:49,928 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 166.0 with 12 tasks
2021-12-08 10:15:49,929 [dispatcher-event-loop-8] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 166.0 (TID 380, localhost, executor driver, partition 0, PROCESS_LOCAL, 7888 bytes)
2021-12-08 10:15:49,929 [dispatcher-event-loop-8] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 166.0 (TID 381, localhost, executor driver, partition 1, PROCESS_LOCAL, 7888 bytes)
2021-12-08 10:15:49,929 [dispatcher-event-loop-8] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 2.0 in stage 166.0 (TID 382, localhost, executor driver, partition 2, PROCESS_LOCAL, 7888 bytes)
2021-12-08 10:15:49,929 [dispatcher-event-loop-8] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 3.0 in stage 166.0 (TID 383, localhost, executor driver, partition 3, PROCESS_LOCAL, 7888 bytes)
2021-12-08 10:15:49,929 [dispatcher-event-loop-8] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 4.0 in stage 166.0 (TID 384, localhost, executor driver, partition 4, PROCESS_LOCAL, 7888 bytes)
2021-12-08 10:15:49,929 [dispatcher-event-loop-8] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 5.0 in stage 166.0 (TID 385, localhost, executor driver, partition 5, PROCESS_LOCAL, 7888 bytes)
2021-12-08 10:15:49,929 [dispatcher-event-loop-8] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 6.0 in stage 166.0 (TID 386, localhost, executor driver, partition 6, PROCESS_LOCAL, 7888 bytes)
2021-12-08 10:15:49,929 [dispatcher-event-loop-8] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 7.0 in stage 166.0 (TID 387, localhost, executor driver, partition 7, PROCESS_LOCAL, 7888 bytes)
2021-12-08 10:15:49,929 [dispatcher-event-loop-8] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 8.0 in stage 166.0 (TID 388, localhost, executor driver, partition 8, PROCESS_LOCAL, 7888 bytes)
2021-12-08 10:15:49,929 [dispatcher-event-loop-8] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 9.0 in stage 166.0 (TID 389, localhost, executor driver, partition 9, PROCESS_LOCAL, 7888 bytes)
2021-12-08 10:15:49,929 [dispatcher-event-loop-8] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 10.0 in stage 166.0 (TID 390, localhost, executor driver, partition 10, PROCESS_LOCAL, 7888 bytes)
2021-12-08 10:15:49,929 [dispatcher-event-loop-8] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 11.0 in stage 166.0 (TID 391, localhost, executor driver, partition 11, PROCESS_LOCAL, 7888 bytes)
2021-12-08 10:15:49,929 [Executor task launch worker for task 382] INFO [org.apache.spark.executor.Executor] - Running task 2.0 in stage 166.0 (TID 382)
2021-12-08 10:15:49,929 [Executor task launch worker for task 381] INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 166.0 (TID 381)
2021-12-08 10:15:49,929 [Executor task launch worker for task 391] INFO [org.apache.spark.executor.Executor] - Running task 11.0 in stage 166.0 (TID 391)
2021-12-08 10:15:49,929 [Executor task launch worker for task 389] INFO [org.apache.spark.executor.Executor] - Running task 9.0 in stage 166.0 (TID 389)
2021-12-08 10:15:49,929 [Executor task launch worker for task 390] INFO [org.apache.spark.executor.Executor] - Running task 10.0 in stage 166.0 (TID 390)
2021-12-08 10:15:49,929 [Executor task launch worker for task 380] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 166.0 (TID 380)
2021-12-08 10:15:49,929 [Executor task launch worker for task 388] INFO [org.apache.spark.executor.Executor] - Running task 8.0 in stage 166.0 (TID 388)
2021-12-08 10:15:49,929 [Executor task launch worker for task 387] INFO [org.apache.spark.executor.Executor] - Running task 7.0 in stage 166.0 (TID 387)
2021-12-08 10:15:49,929 [Executor task launch worker for task 386] INFO [org.apache.spark.executor.Executor] - Running task 6.0 in stage 166.0 (TID 386)
2021-12-08 10:15:49,929 [Executor task launch worker for task 385] INFO [org.apache.spark.executor.Executor] - Running task 5.0 in stage 166.0 (TID 385)
2021-12-08 10:15:49,929 [Executor task launch worker for task 383] INFO [org.apache.spark.executor.Executor] - Running task 3.0 in stage 166.0 (TID 383)
2021-12-08 10:15:49,929 [Executor task launch worker for task 384] INFO [org.apache.spark.executor.Executor] - Running task 4.0 in stage 166.0 (TID 384)
2021-12-08 10:15:49,933 [Executor task launch worker for task 386] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_26_6 locally
2021-12-08 10:15:49,933 [Executor task launch worker for task 389] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_26_9 locally
2021-12-08 10:15:49,933 [Executor task launch worker for task 384] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_26_4 locally
2021-12-08 10:15:49,933 [Executor task launch worker for task 388] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_26_8 locally
2021-12-08 10:15:49,934 [Executor task launch worker for task 380] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_26_0 locally
2021-12-08 10:15:49,934 [Executor task launch worker for task 387] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_26_7 locally
2021-12-08 10:15:49,935 [Executor task launch worker for task 389] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 12 non-empty blocks out of 12 blocks
2021-12-08 10:15:49,935 [Executor task launch worker for task 387] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 12 non-empty blocks out of 12 blocks
2021-12-08 10:15:49,934 [Executor task launch worker for task 383] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_26_3 locally
2021-12-08 10:15:49,935 [Executor task launch worker for task 387] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-08 10:15:49,935 [Executor task launch worker for task 388] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 12 non-empty blocks out of 12 blocks
2021-12-08 10:15:49,935 [Executor task launch worker for task 389] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 1 ms
2021-12-08 10:15:49,935 [Executor task launch worker for task 384] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 12 non-empty blocks out of 12 blocks
2021-12-08 10:15:49,935 [Executor task launch worker for task 384] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 1 ms
2021-12-08 10:15:49,935 [Executor task launch worker for task 386] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 12 non-empty blocks out of 12 blocks
2021-12-08 10:15:49,935 [Executor task launch worker for task 386] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 1 ms
2021-12-08 10:15:49,935 [Executor task launch worker for task 380] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 12 non-empty blocks out of 12 blocks
2021-12-08 10:15:49,935 [Executor task launch worker for task 380] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 1 ms
2021-12-08 10:15:49,935 [Executor task launch worker for task 388] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 1 ms
2021-12-08 10:15:49,935 [Executor task launch worker for task 383] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 12 non-empty blocks out of 12 blocks
2021-12-08 10:15:49,935 [Executor task launch worker for task 383] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-08 10:15:49,936 [Executor task launch worker for task 385] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_26_5 locally
2021-12-08 10:15:49,936 [Executor task launch worker for task 385] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 12 non-empty blocks out of 12 blocks
2021-12-08 10:15:49,937 [Executor task launch worker for task 385] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 1 ms
2021-12-08 10:15:49,937 [Executor task launch worker for task 382] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_26_2 locally
2021-12-08 10:15:49,937 [Executor task launch worker for task 382] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 12 non-empty blocks out of 12 blocks
2021-12-08 10:15:49,937 [Executor task launch worker for task 382] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-08 10:15:49,937 [Executor task launch worker for task 381] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_26_1 locally
2021-12-08 10:15:49,937 [Executor task launch worker for task 390] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_26_10 locally
2021-12-08 10:15:49,937 [Executor task launch worker for task 391] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_26_11 locally
2021-12-08 10:15:49,937 [Executor task launch worker for task 381] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 12 non-empty blocks out of 12 blocks
2021-12-08 10:15:49,937 [Executor task launch worker for task 381] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-08 10:15:49,937 [Executor task launch worker for task 391] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 12 non-empty blocks out of 12 blocks
2021-12-08 10:15:49,937 [Executor task launch worker for task 391] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-08 10:15:49,937 [Executor task launch worker for task 390] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 12 non-empty blocks out of 12 blocks
2021-12-08 10:15:49,937 [Executor task launch worker for task 390] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-08 10:15:50,486 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 793
2021-12-08 10:15:50,487 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 808
2021-12-08 10:15:50,487 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 811
2021-12-08 10:15:50,487 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 790
2021-12-08 10:15:50,487 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 816
2021-12-08 10:15:50,487 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 801
2021-12-08 10:15:50,487 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 819
2021-12-08 10:15:50,487 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 754
2021-12-08 10:15:50,487 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 776
2021-12-08 10:15:50,487 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 792
2021-12-08 10:15:50,487 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 785
2021-12-08 10:15:50,487 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 752
2021-12-08 10:15:50,487 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 784
2021-12-08 10:15:50,487 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 735
2021-12-08 10:15:50,487 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 791
2021-12-08 10:15:50,487 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 809
2021-12-08 10:15:50,487 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 743
2021-12-08 10:15:50,487 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 749
2021-12-08 10:15:50,487 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 730
2021-12-08 10:15:50,487 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 750
2021-12-08 10:15:50,487 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 751
2021-12-08 10:15:50,487 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 731
2021-12-08 10:15:50,487 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 823
2021-12-08 10:15:50,487 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 727
2021-12-08 10:15:50,487 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 766
2021-12-08 10:15:50,487 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 739
2021-12-08 10:15:50,487 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 806
2021-12-08 10:15:50,487 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 738
2021-12-08 10:15:50,487 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 729
2021-12-08 10:15:50,487 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 741
2021-12-08 10:15:50,487 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 733
2021-12-08 10:15:50,487 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 797
2021-12-08 10:15:50,487 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 805
2021-12-08 10:15:50,487 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 758
2021-12-08 10:15:50,487 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 782
2021-12-08 10:15:50,487 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 747
2021-12-08 10:15:50,487 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 742
2021-12-08 10:15:50,487 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 795
2021-12-08 10:15:50,487 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 757
2021-12-08 10:15:50,487 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 817
2021-12-08 10:15:50,487 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 821
2021-12-08 10:15:50,487 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 789
2021-12-08 10:15:50,487 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 803
2021-12-08 10:15:50,487 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 768
2021-12-08 10:15:50,487 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 732
2021-12-08 10:15:50,487 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 767
2021-12-08 10:15:50,487 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 737
2021-12-08 10:15:50,487 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 781
2021-12-08 10:15:50,487 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 753
2021-12-08 10:15:50,487 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 778
2021-12-08 10:15:50,487 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 812
2021-12-08 10:15:50,489 [dispatcher-event-loop-7] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_37_piece0 on qb:61292 in memory (size: 1898.8 KB, free: 1662.1 MB)
2021-12-08 10:15:50,489 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 756
2021-12-08 10:15:50,489 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 744
2021-12-08 10:15:50,489 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 769
2021-12-08 10:15:50,489 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 794
2021-12-08 10:15:50,489 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 822
2021-12-08 10:15:50,489 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 802
2021-12-08 10:15:50,489 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 804
2021-12-08 10:15:50,489 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 771
2021-12-08 10:15:50,489 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 820
2021-12-08 10:15:50,490 [dispatcher-event-loop-4] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_36_piece0 on qb:61292 in memory (size: 1740.1 KB, free: 1663.8 MB)
2021-12-08 10:15:50,490 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 788
2021-12-08 10:15:50,490 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 762
2021-12-08 10:15:50,490 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 759
2021-12-08 10:15:50,490 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 760
2021-12-08 10:15:50,490 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 726
2021-12-08 10:15:50,491 [dispatcher-event-loop-3] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_38_piece0 on qb:61292 in memory (size: 1897.8 KB, free: 1665.7 MB)
2021-12-08 10:15:50,491 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 764
2021-12-08 10:15:50,491 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 799
2021-12-08 10:15:50,491 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 796
2021-12-08 10:15:50,491 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 779
2021-12-08 10:15:50,491 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 736
2021-12-08 10:15:50,491 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 815
2021-12-08 10:15:50,491 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 740
2021-12-08 10:15:50,491 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 775
2021-12-08 10:15:50,491 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 818
2021-12-08 10:15:50,491 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 824
2021-12-08 10:15:50,491 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 810
2021-12-08 10:15:50,491 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 748
2021-12-08 10:15:50,491 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 777
2021-12-08 10:15:50,491 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 728
2021-12-08 10:15:50,491 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 745
2021-12-08 10:15:50,491 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 773
2021-12-08 10:15:50,491 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 800
2021-12-08 10:15:50,491 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 774
2021-12-08 10:15:50,491 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 798
2021-12-08 10:15:50,491 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 763
2021-12-08 10:15:50,491 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 783
2021-12-08 10:15:50,491 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 765
2021-12-08 10:15:50,491 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 746
2021-12-08 10:15:50,491 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 734
2021-12-08 10:15:50,491 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 786
2021-12-08 10:15:50,491 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 813
2021-12-08 10:15:50,491 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 807
2021-12-08 10:15:50,491 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 780
2021-12-08 10:15:50,491 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 755
2021-12-08 10:15:50,491 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 772
2021-12-08 10:15:50,491 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 725
2021-12-08 10:15:50,491 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 787
2021-12-08 10:15:50,491 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 761
2021-12-08 10:15:50,492 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 814
2021-12-08 10:15:50,492 [dispatcher-event-loop-6] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_35_piece0 on qb:61292 in memory (size: 1741.1 KB, free: 1667.4 MB)
2021-12-08 10:15:50,492 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 770
2021-12-08 10:16:11,080 [Executor task launch worker for task 381] INFO [org.apache.spark.storage.memory.MemoryStore] - Block rdd_159_1 stored as values in memory (estimated size 4.0 MB, free 1659.6 MB)
2021-12-08 10:16:11,080 [dispatcher-event-loop-4] INFO [org.apache.spark.storage.BlockManagerInfo] - Added rdd_159_1 in memory on qb:61292 (size: 4.0 MB, free: 1663.4 MB)
2021-12-08 10:16:11,090 [Executor task launch worker for task 385] INFO [org.apache.spark.storage.memory.MemoryStore] - Block rdd_159_5 stored as values in memory (estimated size 4.0 MB, free 1655.7 MB)
2021-12-08 10:16:11,090 [dispatcher-event-loop-10] INFO [org.apache.spark.storage.BlockManagerInfo] - Added rdd_159_5 in memory on qb:61292 (size: 4.0 MB, free: 1659.4 MB)
2021-12-08 10:16:11,202 [Executor task launch worker for task 381] INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 166.0 (TID 381). 166097 bytes result sent to driver
2021-12-08 10:16:11,206 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 166.0 (TID 381) in 21277 ms on localhost (executor driver) (1/12)
2021-12-08 10:16:11,212 [Executor task launch worker for task 385] INFO [org.apache.spark.executor.Executor] - Finished task 5.0 in stage 166.0 (TID 385). 166097 bytes result sent to driver
2021-12-08 10:16:11,213 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 5.0 in stage 166.0 (TID 385) in 21284 ms on localhost (executor driver) (2/12)
2021-12-08 10:16:11,842 [Executor task launch worker for task 380] INFO [org.apache.spark.storage.memory.MemoryStore] - Block rdd_159_0 stored as values in memory (estimated size 4.0 MB, free 1651.7 MB)
2021-12-08 10:16:11,843 [dispatcher-event-loop-8] INFO [org.apache.spark.storage.BlockManagerInfo] - Added rdd_159_0 in memory on qb:61292 (size: 4.0 MB, free: 1655.4 MB)
2021-12-08 10:16:11,895 [Executor task launch worker for task 384] INFO [org.apache.spark.storage.memory.MemoryStore] - Block rdd_159_4 stored as values in memory (estimated size 4.0 MB, free 1647.7 MB)
2021-12-08 10:16:11,896 [dispatcher-event-loop-1] INFO [org.apache.spark.storage.BlockManagerInfo] - Added rdd_159_4 in memory on qb:61292 (size: 4.0 MB, free: 1651.4 MB)
2021-12-08 10:16:11,917 [Executor task launch worker for task 391] INFO [org.apache.spark.storage.memory.MemoryStore] - Block rdd_159_11 stored as values in memory (estimated size 4.0 MB, free 1643.7 MB)
2021-12-08 10:16:11,918 [dispatcher-event-loop-6] INFO [org.apache.spark.storage.BlockManagerInfo] - Added rdd_159_11 in memory on qb:61292 (size: 4.0 MB, free: 1647.4 MB)
2021-12-08 10:16:11,945 [Executor task launch worker for task 380] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 166.0 (TID 380). 166097 bytes result sent to driver
2021-12-08 10:16:11,946 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 166.0 (TID 380) in 22017 ms on localhost (executor driver) (3/12)
2021-12-08 10:16:11,989 [Executor task launch worker for task 384] INFO [org.apache.spark.executor.Executor] - Finished task 4.0 in stage 166.0 (TID 384). 166054 bytes result sent to driver
2021-12-08 10:16:11,990 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 4.0 in stage 166.0 (TID 384) in 22061 ms on localhost (executor driver) (4/12)
2021-12-08 10:16:12,026 [Executor task launch worker for task 391] INFO [org.apache.spark.executor.Executor] - Finished task 11.0 in stage 166.0 (TID 391). 166054 bytes result sent to driver
2021-12-08 10:16:12,027 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 11.0 in stage 166.0 (TID 391) in 22098 ms on localhost (executor driver) (5/12)
2021-12-08 10:16:12,272 [Executor task launch worker for task 390] INFO [org.apache.spark.storage.memory.MemoryStore] - Block rdd_159_10 stored as values in memory (estimated size 4.0 MB, free 1639.7 MB)
2021-12-08 10:16:12,272 [dispatcher-event-loop-5] INFO [org.apache.spark.storage.BlockManagerInfo] - Added rdd_159_10 in memory on qb:61292 (size: 4.0 MB, free: 1643.4 MB)
2021-12-08 10:16:12,351 [Executor task launch worker for task 390] INFO [org.apache.spark.executor.Executor] - Finished task 10.0 in stage 166.0 (TID 390). 166054 bytes result sent to driver
2021-12-08 10:16:12,351 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 10.0 in stage 166.0 (TID 390) in 22422 ms on localhost (executor driver) (6/12)
2021-12-08 10:16:12,477 [Executor task launch worker for task 388] INFO [org.apache.spark.storage.memory.MemoryStore] - Block rdd_159_8 stored as values in memory (estimated size 4.0 MB, free 1635.7 MB)
2021-12-08 10:16:12,477 [dispatcher-event-loop-4] INFO [org.apache.spark.storage.BlockManagerInfo] - Added rdd_159_8 in memory on qb:61292 (size: 4.0 MB, free: 1639.5 MB)
2021-12-08 10:16:12,554 [Executor task launch worker for task 388] INFO [org.apache.spark.executor.Executor] - Finished task 8.0 in stage 166.0 (TID 388). 166097 bytes result sent to driver
2021-12-08 10:16:12,554 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 8.0 in stage 166.0 (TID 388) in 22625 ms on localhost (executor driver) (7/12)
2021-12-08 10:16:12,774 [Executor task launch worker for task 387] INFO [org.apache.spark.storage.memory.MemoryStore] - Block rdd_159_7 stored as values in memory (estimated size 4.0 MB, free 1631.7 MB)
2021-12-08 10:16:12,774 [dispatcher-event-loop-2] INFO [org.apache.spark.storage.BlockManagerInfo] - Added rdd_159_7 in memory on qb:61292 (size: 4.0 MB, free: 1635.5 MB)
2021-12-08 10:16:12,840 [Executor task launch worker for task 387] INFO [org.apache.spark.executor.Executor] - Finished task 7.0 in stage 166.0 (TID 387). 166054 bytes result sent to driver
2021-12-08 10:16:12,840 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 7.0 in stage 166.0 (TID 387) in 22911 ms on localhost (executor driver) (8/12)
2021-12-08 10:16:13,214 [Executor task launch worker for task 383] INFO [org.apache.spark.storage.memory.MemoryStore] - Block rdd_159_3 stored as values in memory (estimated size 4.0 MB, free 1627.7 MB)
2021-12-08 10:16:13,214 [dispatcher-event-loop-8] INFO [org.apache.spark.storage.BlockManagerInfo] - Added rdd_159_3 in memory on qb:61292 (size: 4.0 MB, free: 1631.5 MB)
2021-12-08 10:16:13,229 [Executor task launch worker for task 389] INFO [org.apache.spark.storage.memory.MemoryStore] - Block rdd_159_9 stored as values in memory (estimated size 4.0 MB, free 1623.7 MB)
2021-12-08 10:16:13,229 [dispatcher-event-loop-1] INFO [org.apache.spark.storage.BlockManagerInfo] - Added rdd_159_9 in memory on qb:61292 (size: 4.0 MB, free: 1627.5 MB)
2021-12-08 10:16:13,292 [Executor task launch worker for task 383] INFO [org.apache.spark.executor.Executor] - Finished task 3.0 in stage 166.0 (TID 383). 166097 bytes result sent to driver
2021-12-08 10:16:13,292 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 3.0 in stage 166.0 (TID 383) in 23363 ms on localhost (executor driver) (9/12)
2021-12-08 10:16:13,294 [Executor task launch worker for task 389] INFO [org.apache.spark.executor.Executor] - Finished task 9.0 in stage 166.0 (TID 389). 166054 bytes result sent to driver
2021-12-08 10:16:13,294 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 9.0 in stage 166.0 (TID 389) in 23365 ms on localhost (executor driver) (10/12)
2021-12-08 10:16:13,491 [Executor task launch worker for task 386] INFO [org.apache.spark.storage.memory.MemoryStore] - Block rdd_159_6 stored as values in memory (estimated size 4.0 MB, free 1619.8 MB)
2021-12-08 10:16:13,491 [dispatcher-event-loop-9] INFO [org.apache.spark.storage.BlockManagerInfo] - Added rdd_159_6 in memory on qb:61292 (size: 4.0 MB, free: 1623.5 MB)
2021-12-08 10:16:13,576 [Executor task launch worker for task 386] INFO [org.apache.spark.executor.Executor] - Finished task 6.0 in stage 166.0 (TID 386). 166097 bytes result sent to driver
2021-12-08 10:16:13,576 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 6.0 in stage 166.0 (TID 386) in 23647 ms on localhost (executor driver) (11/12)
2021-12-08 10:16:13,795 [Executor task launch worker for task 382] INFO [org.apache.spark.storage.memory.MemoryStore] - Block rdd_159_2 stored as values in memory (estimated size 4.0 MB, free 1615.8 MB)
2021-12-08 10:16:13,795 [dispatcher-event-loop-5] INFO [org.apache.spark.storage.BlockManagerInfo] - Added rdd_159_2 in memory on qb:61292 (size: 4.0 MB, free: 1619.5 MB)
2021-12-08 10:16:13,857 [Executor task launch worker for task 382] INFO [org.apache.spark.executor.Executor] - Finished task 2.0 in stage 166.0 (TID 382). 166054 bytes result sent to driver
2021-12-08 10:16:13,857 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 2.0 in stage 166.0 (TID 382) in 23928 ms on localhost (executor driver) (12/12)
2021-12-08 10:16:13,857 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 166.0, whose tasks have all completed, from pool 
2021-12-08 10:16:13,857 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 166 (aggregate at ALS.scala:1711) finished in 23.936 s
2021-12-08 10:16:13,858 [main] INFO [org.apache.spark.scheduler.DAGScheduler] - Job 17 finished: aggregate at ALS.scala:1711, took 25.860169 s
2021-12-08 10:16:13,872 [main] INFO [org.apache.spark.rdd.MapPartitionsRDD] - Removing RDD 149 from persistence list
2021-12-08 10:16:13,872 [block-manager-slave-async-thread-pool-2] INFO [org.apache.spark.storage.BlockManager] - Removing RDD 149
2021-12-08 10:16:13,878 [main] INFO [org.apache.spark.SparkContext] - Starting job: aggregate at ALS.scala:1711
2021-12-08 10:16:13,879 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 164 (flatMap at ALS.scala:1653)
2021-12-08 10:16:13,879 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 18 (aggregate at ALS.scala:1711) with 12 output partitions
2021-12-08 10:16:13,879 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 185 (aggregate at ALS.scala:1711)
2021-12-08 10:16:13,879 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 168, ShuffleMapStage 184)
2021-12-08 10:16:13,880 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List(ShuffleMapStage 184)
2021-12-08 10:16:13,880 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ShuffleMapStage 184 (MapPartitionsRDD[164] at flatMap at ALS.scala:1653), which has no missing parents
2021-12-08 10:16:13,883 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_40 stored as values in memory (estimated size 2.1 MB, free 1747.0 MB)
2021-12-08 10:16:13,886 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_40_piece0 stored as bytes in memory (estimated size 2.0 MB, free 1745.0 MB)
2021-12-08 10:16:13,886 [dispatcher-event-loop-6] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_40_piece0 in memory on qb:61292 (size: 2.0 MB, free: 1750.8 MB)
2021-12-08 10:16:13,887 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 40 from broadcast at DAGScheduler.scala:1039
2021-12-08 10:16:13,887 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 12 missing tasks from ShuffleMapStage 184 (MapPartitionsRDD[164] at flatMap at ALS.scala:1653) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11))
2021-12-08 10:16:13,887 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 184.0 with 12 tasks
2021-12-08 10:16:13,887 [dispatcher-event-loop-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 184.0 (TID 392, localhost, executor driver, partition 0, PROCESS_LOCAL, 7928 bytes)
2021-12-08 10:16:13,887 [dispatcher-event-loop-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 184.0 (TID 393, localhost, executor driver, partition 1, PROCESS_LOCAL, 7928 bytes)
2021-12-08 10:16:13,887 [dispatcher-event-loop-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 2.0 in stage 184.0 (TID 394, localhost, executor driver, partition 2, PROCESS_LOCAL, 7928 bytes)
2021-12-08 10:16:13,887 [dispatcher-event-loop-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 3.0 in stage 184.0 (TID 395, localhost, executor driver, partition 3, PROCESS_LOCAL, 7928 bytes)
2021-12-08 10:16:13,887 [dispatcher-event-loop-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 4.0 in stage 184.0 (TID 396, localhost, executor driver, partition 4, PROCESS_LOCAL, 7928 bytes)
2021-12-08 10:16:13,887 [dispatcher-event-loop-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 5.0 in stage 184.0 (TID 397, localhost, executor driver, partition 5, PROCESS_LOCAL, 7928 bytes)
2021-12-08 10:16:13,887 [dispatcher-event-loop-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 6.0 in stage 184.0 (TID 398, localhost, executor driver, partition 6, PROCESS_LOCAL, 7928 bytes)
2021-12-08 10:16:13,887 [dispatcher-event-loop-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 7.0 in stage 184.0 (TID 399, localhost, executor driver, partition 7, PROCESS_LOCAL, 7928 bytes)
2021-12-08 10:16:13,887 [dispatcher-event-loop-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 8.0 in stage 184.0 (TID 400, localhost, executor driver, partition 8, PROCESS_LOCAL, 7928 bytes)
2021-12-08 10:16:13,888 [dispatcher-event-loop-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 9.0 in stage 184.0 (TID 401, localhost, executor driver, partition 9, PROCESS_LOCAL, 7928 bytes)
2021-12-08 10:16:13,888 [dispatcher-event-loop-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 10.0 in stage 184.0 (TID 402, localhost, executor driver, partition 10, PROCESS_LOCAL, 7928 bytes)
2021-12-08 10:16:13,888 [dispatcher-event-loop-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 11.0 in stage 184.0 (TID 403, localhost, executor driver, partition 11, PROCESS_LOCAL, 7928 bytes)
2021-12-08 10:16:13,888 [Executor task launch worker for task 399] INFO [org.apache.spark.executor.Executor] - Running task 7.0 in stage 184.0 (TID 399)
2021-12-08 10:16:13,888 [Executor task launch worker for task 398] INFO [org.apache.spark.executor.Executor] - Running task 6.0 in stage 184.0 (TID 398)
2021-12-08 10:16:13,888 [Executor task launch worker for task 402] INFO [org.apache.spark.executor.Executor] - Running task 10.0 in stage 184.0 (TID 402)
2021-12-08 10:16:13,888 [Executor task launch worker for task 403] INFO [org.apache.spark.executor.Executor] - Running task 11.0 in stage 184.0 (TID 403)
2021-12-08 10:16:13,888 [Executor task launch worker for task 400] INFO [org.apache.spark.executor.Executor] - Running task 8.0 in stage 184.0 (TID 400)
2021-12-08 10:16:13,888 [Executor task launch worker for task 393] INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 184.0 (TID 393)
2021-12-08 10:16:13,888 [Executor task launch worker for task 401] INFO [org.apache.spark.executor.Executor] - Running task 9.0 in stage 184.0 (TID 401)
2021-12-08 10:16:13,888 [Executor task launch worker for task 395] INFO [org.apache.spark.executor.Executor] - Running task 3.0 in stage 184.0 (TID 395)
2021-12-08 10:16:13,888 [Executor task launch worker for task 394] INFO [org.apache.spark.executor.Executor] - Running task 2.0 in stage 184.0 (TID 394)
2021-12-08 10:16:13,888 [Executor task launch worker for task 392] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 184.0 (TID 392)
2021-12-08 10:16:13,888 [Executor task launch worker for task 397] INFO [org.apache.spark.executor.Executor] - Running task 5.0 in stage 184.0 (TID 397)
2021-12-08 10:16:13,888 [Executor task launch worker for task 396] INFO [org.apache.spark.executor.Executor] - Running task 4.0 in stage 184.0 (TID 396)
2021-12-08 10:16:13,891 [Executor task launch worker for task 398] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_27_6 locally
2021-12-08 10:16:13,891 [Executor task launch worker for task 393] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_27_1 locally
2021-12-08 10:16:13,891 [Executor task launch worker for task 393] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_159_1 locally
2021-12-08 10:16:13,891 [Executor task launch worker for task 392] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_27_0 locally
2021-12-08 10:16:13,891 [Executor task launch worker for task 402] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_27_10 locally
2021-12-08 10:16:13,891 [Executor task launch worker for task 397] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_27_5 locally
2021-12-08 10:16:13,891 [Executor task launch worker for task 400] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_27_8 locally
2021-12-08 10:16:13,891 [Executor task launch worker for task 403] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_27_11 locally
2021-12-08 10:16:13,891 [Executor task launch worker for task 399] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_27_7 locally
2021-12-08 10:16:13,892 [Executor task launch worker for task 400] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_159_8 locally
2021-12-08 10:16:13,892 [Executor task launch worker for task 397] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_159_5 locally
2021-12-08 10:16:13,892 [Executor task launch worker for task 392] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_159_0 locally
2021-12-08 10:16:13,891 [Executor task launch worker for task 396] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_27_4 locally
2021-12-08 10:16:13,892 [Executor task launch worker for task 398] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_159_6 locally
2021-12-08 10:16:13,892 [Executor task launch worker for task 402] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_159_10 locally
2021-12-08 10:16:13,892 [Executor task launch worker for task 403] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_159_11 locally
2021-12-08 10:16:13,892 [Executor task launch worker for task 401] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_27_9 locally
2021-12-08 10:16:13,892 [Executor task launch worker for task 401] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_159_9 locally
2021-12-08 10:16:13,892 [Executor task launch worker for task 399] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_159_7 locally
2021-12-08 10:16:13,892 [Executor task launch worker for task 396] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_159_4 locally
2021-12-08 10:16:13,893 [Executor task launch worker for task 394] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_27_2 locally
2021-12-08 10:16:13,893 [Executor task launch worker for task 394] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_159_2 locally
2021-12-08 10:16:13,893 [Executor task launch worker for task 395] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_27_3 locally
2021-12-08 10:16:13,894 [Executor task launch worker for task 395] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_159_3 locally
2021-12-08 10:16:15,065 [Executor task launch worker for task 402] INFO [org.apache.spark.executor.Executor] - Finished task 10.0 in stage 184.0 (TID 402). 999 bytes result sent to driver
2021-12-08 10:16:15,065 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 10.0 in stage 184.0 (TID 402) in 1177 ms on localhost (executor driver) (1/12)
2021-12-08 10:16:15,066 [Executor task launch worker for task 398] INFO [org.apache.spark.executor.Executor] - Finished task 6.0 in stage 184.0 (TID 398). 999 bytes result sent to driver
2021-12-08 10:16:15,066 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 6.0 in stage 184.0 (TID 398) in 1179 ms on localhost (executor driver) (2/12)
2021-12-08 10:16:15,076 [Executor task launch worker for task 392] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 184.0 (TID 392). 999 bytes result sent to driver
2021-12-08 10:16:15,076 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 184.0 (TID 392) in 1189 ms on localhost (executor driver) (3/12)
2021-12-08 10:16:15,076 [Executor task launch worker for task 395] INFO [org.apache.spark.executor.Executor] - Finished task 3.0 in stage 184.0 (TID 395). 999 bytes result sent to driver
2021-12-08 10:16:15,077 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 3.0 in stage 184.0 (TID 395) in 1190 ms on localhost (executor driver) (4/12)
2021-12-08 10:16:15,080 [Executor task launch worker for task 401] INFO [org.apache.spark.executor.Executor] - Finished task 9.0 in stage 184.0 (TID 401). 999 bytes result sent to driver
2021-12-08 10:16:15,080 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 9.0 in stage 184.0 (TID 401) in 1193 ms on localhost (executor driver) (5/12)
2021-12-08 10:16:15,086 [Executor task launch worker for task 399] INFO [org.apache.spark.executor.Executor] - Finished task 7.0 in stage 184.0 (TID 399). 999 bytes result sent to driver
2021-12-08 10:16:15,086 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 7.0 in stage 184.0 (TID 399) in 1199 ms on localhost (executor driver) (6/12)
2021-12-08 10:16:15,115 [Executor task launch worker for task 394] INFO [org.apache.spark.executor.Executor] - Finished task 2.0 in stage 184.0 (TID 394). 999 bytes result sent to driver
2021-12-08 10:16:15,115 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 2.0 in stage 184.0 (TID 394) in 1228 ms on localhost (executor driver) (7/12)
2021-12-08 10:16:15,134 [Executor task launch worker for task 397] INFO [org.apache.spark.executor.Executor] - Finished task 5.0 in stage 184.0 (TID 397). 999 bytes result sent to driver
2021-12-08 10:16:15,134 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 5.0 in stage 184.0 (TID 397) in 1247 ms on localhost (executor driver) (8/12)
2021-12-08 10:16:15,135 [Executor task launch worker for task 400] INFO [org.apache.spark.executor.Executor] - Finished task 8.0 in stage 184.0 (TID 400). 999 bytes result sent to driver
2021-12-08 10:16:15,135 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 8.0 in stage 184.0 (TID 400) in 1248 ms on localhost (executor driver) (9/12)
2021-12-08 10:16:15,136 [Executor task launch worker for task 403] INFO [org.apache.spark.executor.Executor] - Finished task 11.0 in stage 184.0 (TID 403). 999 bytes result sent to driver
2021-12-08 10:16:15,136 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 11.0 in stage 184.0 (TID 403) in 1248 ms on localhost (executor driver) (10/12)
2021-12-08 10:16:15,136 [Executor task launch worker for task 393] INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 184.0 (TID 393). 999 bytes result sent to driver
2021-12-08 10:16:15,137 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 184.0 (TID 393) in 1250 ms on localhost (executor driver) (11/12)
2021-12-08 10:16:15,285 [Executor task launch worker for task 396] INFO [org.apache.spark.executor.Executor] - Finished task 4.0 in stage 184.0 (TID 396). 999 bytes result sent to driver
2021-12-08 10:16:15,285 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 4.0 in stage 184.0 (TID 396) in 1398 ms on localhost (executor driver) (12/12)
2021-12-08 10:16:15,285 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 184.0, whose tasks have all completed, from pool 
2021-12-08 10:16:15,285 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ShuffleMapStage 184 (flatMap at ALS.scala:1653) finished in 1.405 s
2021-12-08 10:16:15,285 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - looking for newly runnable stages
2021-12-08 10:16:15,285 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - running: Set()
2021-12-08 10:16:15,285 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - waiting: Set(ResultStage 185)
2021-12-08 10:16:15,285 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - failed: Set()
2021-12-08 10:16:15,286 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 185 (MapPartitionsRDD[170] at values at ALS.scala:1711), which has no missing parents
2021-12-08 10:16:15,289 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_41 stored as values in memory (estimated size 2.4 MB, free 1742.6 MB)
2021-12-08 10:16:15,293 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_41_piece0 stored as bytes in memory (estimated size 2.2 MB, free 1740.4 MB)
2021-12-08 10:16:15,293 [dispatcher-event-loop-4] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_41_piece0 in memory on qb:61292 (size: 2.2 MB, free: 1748.6 MB)
2021-12-08 10:16:15,293 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 41 from broadcast at DAGScheduler.scala:1039
2021-12-08 10:16:15,293 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 12 missing tasks from ResultStage 185 (MapPartitionsRDD[170] at values at ALS.scala:1711) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11))
2021-12-08 10:16:15,293 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 185.0 with 12 tasks
2021-12-08 10:16:15,294 [dispatcher-event-loop-10] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 185.0 (TID 404, localhost, executor driver, partition 0, PROCESS_LOCAL, 7888 bytes)
2021-12-08 10:16:15,294 [dispatcher-event-loop-10] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 185.0 (TID 405, localhost, executor driver, partition 1, PROCESS_LOCAL, 7888 bytes)
2021-12-08 10:16:15,294 [dispatcher-event-loop-10] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 2.0 in stage 185.0 (TID 406, localhost, executor driver, partition 2, PROCESS_LOCAL, 7888 bytes)
2021-12-08 10:16:15,294 [dispatcher-event-loop-10] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 3.0 in stage 185.0 (TID 407, localhost, executor driver, partition 3, PROCESS_LOCAL, 7888 bytes)
2021-12-08 10:16:15,294 [dispatcher-event-loop-10] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 4.0 in stage 185.0 (TID 408, localhost, executor driver, partition 4, PROCESS_LOCAL, 7888 bytes)
2021-12-08 10:16:15,294 [dispatcher-event-loop-10] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 5.0 in stage 185.0 (TID 409, localhost, executor driver, partition 5, PROCESS_LOCAL, 7888 bytes)
2021-12-08 10:16:15,294 [dispatcher-event-loop-10] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 6.0 in stage 185.0 (TID 410, localhost, executor driver, partition 6, PROCESS_LOCAL, 7888 bytes)
2021-12-08 10:16:15,294 [dispatcher-event-loop-10] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 7.0 in stage 185.0 (TID 411, localhost, executor driver, partition 7, PROCESS_LOCAL, 7888 bytes)
2021-12-08 10:16:15,294 [dispatcher-event-loop-10] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 8.0 in stage 185.0 (TID 412, localhost, executor driver, partition 8, PROCESS_LOCAL, 7888 bytes)
2021-12-08 10:16:15,294 [dispatcher-event-loop-10] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 9.0 in stage 185.0 (TID 413, localhost, executor driver, partition 9, PROCESS_LOCAL, 7888 bytes)
2021-12-08 10:16:15,294 [dispatcher-event-loop-10] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 10.0 in stage 185.0 (TID 414, localhost, executor driver, partition 10, PROCESS_LOCAL, 7888 bytes)
2021-12-08 10:16:15,294 [dispatcher-event-loop-10] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 11.0 in stage 185.0 (TID 415, localhost, executor driver, partition 11, PROCESS_LOCAL, 7888 bytes)
2021-12-08 10:16:15,294 [Executor task launch worker for task 409] INFO [org.apache.spark.executor.Executor] - Running task 5.0 in stage 185.0 (TID 409)
2021-12-08 10:16:15,294 [Executor task launch worker for task 412] INFO [org.apache.spark.executor.Executor] - Running task 8.0 in stage 185.0 (TID 412)
2021-12-08 10:16:15,294 [Executor task launch worker for task 411] INFO [org.apache.spark.executor.Executor] - Running task 7.0 in stage 185.0 (TID 411)
2021-12-08 10:16:15,294 [Executor task launch worker for task 415] INFO [org.apache.spark.executor.Executor] - Running task 11.0 in stage 185.0 (TID 415)
2021-12-08 10:16:15,294 [Executor task launch worker for task 405] INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 185.0 (TID 405)
2021-12-08 10:16:15,294 [Executor task launch worker for task 413] INFO [org.apache.spark.executor.Executor] - Running task 9.0 in stage 185.0 (TID 413)
2021-12-08 10:16:15,294 [Executor task launch worker for task 406] INFO [org.apache.spark.executor.Executor] - Running task 2.0 in stage 185.0 (TID 406)
2021-12-08 10:16:15,294 [Executor task launch worker for task 414] INFO [org.apache.spark.executor.Executor] - Running task 10.0 in stage 185.0 (TID 414)
2021-12-08 10:16:15,294 [Executor task launch worker for task 408] INFO [org.apache.spark.executor.Executor] - Running task 4.0 in stage 185.0 (TID 408)
2021-12-08 10:16:15,295 [Executor task launch worker for task 407] INFO [org.apache.spark.executor.Executor] - Running task 3.0 in stage 185.0 (TID 407)
2021-12-08 10:16:15,294 [Executor task launch worker for task 404] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 185.0 (TID 404)
2021-12-08 10:16:15,294 [Executor task launch worker for task 410] INFO [org.apache.spark.executor.Executor] - Running task 6.0 in stage 185.0 (TID 410)
2021-12-08 10:16:15,299 [Executor task launch worker for task 415] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_21_11 locally
2021-12-08 10:16:15,299 [Executor task launch worker for task 413] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_21_9 locally
2021-12-08 10:16:15,299 [Executor task launch worker for task 410] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_21_6 locally
2021-12-08 10:16:15,299 [Executor task launch worker for task 411] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_21_7 locally
2021-12-08 10:16:15,299 [Executor task launch worker for task 407] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_21_3 locally
2021-12-08 10:16:15,300 [Executor task launch worker for task 411] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 12 non-empty blocks out of 12 blocks
2021-12-08 10:16:15,299 [Executor task launch worker for task 406] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_21_2 locally
2021-12-08 10:16:15,300 [Executor task launch worker for task 411] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-08 10:16:15,300 [Executor task launch worker for task 415] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 12 non-empty blocks out of 12 blocks
2021-12-08 10:16:15,300 [Executor task launch worker for task 413] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 12 non-empty blocks out of 12 blocks
2021-12-08 10:16:15,300 [Executor task launch worker for task 410] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 12 non-empty blocks out of 12 blocks
2021-12-08 10:16:15,300 [Executor task launch worker for task 413] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-08 10:16:15,300 [Executor task launch worker for task 415] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-08 10:16:15,300 [Executor task launch worker for task 409] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_21_5 locally
2021-12-08 10:16:15,301 [Executor task launch worker for task 406] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 12 non-empty blocks out of 12 blocks
2021-12-08 10:16:15,301 [Executor task launch worker for task 410] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 1 ms
2021-12-08 10:16:15,301 [Executor task launch worker for task 406] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 1 ms
2021-12-08 10:16:15,301 [Executor task launch worker for task 407] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 12 non-empty blocks out of 12 blocks
2021-12-08 10:16:15,301 [Executor task launch worker for task 408] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_21_4 locally
2021-12-08 10:16:15,301 [Executor task launch worker for task 407] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 1 ms
2021-12-08 10:16:15,301 [Executor task launch worker for task 409] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 12 non-empty blocks out of 12 blocks
2021-12-08 10:16:15,301 [Executor task launch worker for task 409] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-08 10:16:15,301 [Executor task launch worker for task 412] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_21_8 locally
2021-12-08 10:16:15,301 [Executor task launch worker for task 408] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 12 non-empty blocks out of 12 blocks
2021-12-08 10:16:15,301 [Executor task launch worker for task 408] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-08 10:16:15,301 [Executor task launch worker for task 405] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_21_1 locally
2021-12-08 10:16:15,301 [Executor task launch worker for task 412] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 12 non-empty blocks out of 12 blocks
2021-12-08 10:16:15,301 [Executor task launch worker for task 412] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-08 10:16:15,301 [Executor task launch worker for task 405] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 12 non-empty blocks out of 12 blocks
2021-12-08 10:16:15,301 [Executor task launch worker for task 405] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-08 10:16:15,302 [Executor task launch worker for task 404] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_21_0 locally
2021-12-08 10:16:15,302 [Executor task launch worker for task 404] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 12 non-empty blocks out of 12 blocks
2021-12-08 10:16:15,302 [Executor task launch worker for task 404] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-08 10:16:15,303 [Executor task launch worker for task 414] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_21_10 locally
2021-12-08 10:16:15,303 [Executor task launch worker for task 414] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 12 non-empty blocks out of 12 blocks
2021-12-08 10:16:15,303 [Executor task launch worker for task 414] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-08 10:16:15,484 [dispatcher-event-loop-8] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_40_piece0 on qb:61292 in memory (size: 2.0 MB, free: 1750.6 MB)
2021-12-08 10:16:15,798 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 845
2021-12-08 10:16:15,798 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 855
2021-12-08 10:16:15,798 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 851
2021-12-08 10:16:15,798 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 856
2021-12-08 10:16:15,798 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 848
2021-12-08 10:16:15,798 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 870
2021-12-08 10:16:15,798 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 858
2021-12-08 10:16:15,798 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 827
2021-12-08 10:16:15,798 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 841
2021-12-08 10:16:15,798 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 830
2021-12-08 10:16:15,798 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 836
2021-12-08 10:16:15,798 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 847
2021-12-08 10:16:15,798 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 869
2021-12-08 10:16:15,798 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 859
2021-12-08 10:16:15,798 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 846
2021-12-08 10:16:15,798 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 864
2021-12-08 10:16:15,798 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 832
2021-12-08 10:16:15,799 [dispatcher-event-loop-1] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_39_piece0 on qb:61292 in memory (size: 2.0 MB, free: 1752.6 MB)
2021-12-08 10:16:15,831 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 850
2021-12-08 10:16:15,831 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 861
2021-12-08 10:16:15,831 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 857
2021-12-08 10:16:15,831 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 849
2021-12-08 10:16:15,831 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 837
2021-12-08 10:16:15,831 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 853
2021-12-08 10:16:15,831 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 835
2021-12-08 10:16:15,831 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 833
2021-12-08 10:16:15,831 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 826
2021-12-08 10:16:15,831 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 874
2021-12-08 10:16:15,831 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 829
2021-12-08 10:16:15,831 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 828
2021-12-08 10:16:15,831 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 868
2021-12-08 10:16:15,831 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 839
2021-12-08 10:16:15,831 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 866
2021-12-08 10:16:15,831 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 852
2021-12-08 10:16:15,831 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 854
2021-12-08 10:16:15,831 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 843
2021-12-08 10:16:15,831 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 863
2021-12-08 10:16:15,831 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 865
2021-12-08 10:16:15,831 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 842
2021-12-08 10:16:15,831 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 862
2021-12-08 10:16:15,831 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 873
2021-12-08 10:16:15,831 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 871
2021-12-08 10:16:15,831 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 872
2021-12-08 10:16:15,831 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 825
2021-12-08 10:16:15,831 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 840
2021-12-08 10:16:15,831 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 838
2021-12-08 10:16:15,831 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 844
2021-12-08 10:16:15,832 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 834
2021-12-08 10:16:15,832 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 867
2021-12-08 10:16:15,832 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 860
2021-12-08 10:16:15,832 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 831
2021-12-08 10:16:52,440 [Executor task launch worker for task 406] INFO [org.apache.spark.storage.memory.MemoryStore] - Block rdd_169_2 stored as values in memory (estimated size 11.1 MB, free 1737.6 MB)
2021-12-08 10:16:52,441 [dispatcher-event-loop-3] INFO [org.apache.spark.storage.BlockManagerInfo] - Added rdd_169_2 in memory on qb:61292 (size: 11.1 MB, free: 1741.5 MB)
2021-12-08 10:16:52,550 [Executor task launch worker for task 405] INFO [org.apache.spark.storage.memory.MemoryStore] - Block rdd_169_1 stored as values in memory (estimated size 11.1 MB, free 1726.5 MB)
2021-12-08 10:16:52,551 [dispatcher-event-loop-2] INFO [org.apache.spark.storage.BlockManagerInfo] - Added rdd_169_1 in memory on qb:61292 (size: 11.1 MB, free: 1730.4 MB)
2021-12-08 10:16:52,558 [Executor task launch worker for task 413] INFO [org.apache.spark.storage.memory.MemoryStore] - Block rdd_169_9 stored as values in memory (estimated size 11.1 MB, free 1715.4 MB)
2021-12-08 10:16:52,558 [dispatcher-event-loop-8] INFO [org.apache.spark.storage.BlockManagerInfo] - Added rdd_169_9 in memory on qb:61292 (size: 11.1 MB, free: 1719.3 MB)
2021-12-08 10:16:52,564 [Executor task launch worker for task 415] INFO [org.apache.spark.storage.memory.MemoryStore] - Block rdd_169_11 stored as values in memory (estimated size 11.1 MB, free 1704.3 MB)
2021-12-08 10:16:52,565 [dispatcher-event-loop-6] INFO [org.apache.spark.storage.BlockManagerInfo] - Added rdd_169_11 in memory on qb:61292 (size: 11.1 MB, free: 1708.2 MB)
2021-12-08 10:16:52,565 [Executor task launch worker for task 410] INFO [org.apache.spark.storage.memory.MemoryStore] - Block rdd_169_6 stored as values in memory (estimated size 11.1 MB, free 1693.2 MB)
2021-12-08 10:16:52,565 [dispatcher-event-loop-1] INFO [org.apache.spark.storage.BlockManagerInfo] - Added rdd_169_6 in memory on qb:61292 (size: 11.1 MB, free: 1697.1 MB)
2021-12-08 10:16:52,603 [Executor task launch worker for task 412] INFO [org.apache.spark.storage.memory.MemoryStore] - Block rdd_169_8 stored as values in memory (estimated size 11.1 MB, free 1682.1 MB)
2021-12-08 10:16:52,603 [dispatcher-event-loop-0] INFO [org.apache.spark.storage.BlockManagerInfo] - Added rdd_169_8 in memory on qb:61292 (size: 11.1 MB, free: 1686.0 MB)
2021-12-08 10:16:52,750 [Executor task launch worker for task 411] INFO [org.apache.spark.storage.memory.MemoryStore] - Block rdd_169_7 stored as values in memory (estimated size 11.1 MB, free 1671.0 MB)
2021-12-08 10:16:52,750 [dispatcher-event-loop-7] INFO [org.apache.spark.storage.BlockManagerInfo] - Added rdd_169_7 in memory on qb:61292 (size: 11.1 MB, free: 1674.9 MB)
2021-12-08 10:16:52,790 [Executor task launch worker for task 406] INFO [org.apache.spark.executor.Executor] - Finished task 2.0 in stage 185.0 (TID 406). 166054 bytes result sent to driver
2021-12-08 10:16:52,796 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 2.0 in stage 185.0 (TID 406) in 37502 ms on localhost (executor driver) (1/12)
2021-12-08 10:16:52,890 [Executor task launch worker for task 405] INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 185.0 (TID 405). 166054 bytes result sent to driver
2021-12-08 10:16:52,890 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 185.0 (TID 405) in 37596 ms on localhost (executor driver) (2/12)
2021-12-08 10:16:52,897 [Executor task launch worker for task 410] INFO [org.apache.spark.executor.Executor] - Finished task 6.0 in stage 185.0 (TID 410). 166054 bytes result sent to driver
2021-12-08 10:16:52,897 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 6.0 in stage 185.0 (TID 410) in 37603 ms on localhost (executor driver) (3/12)
2021-12-08 10:16:52,898 [Executor task launch worker for task 413] INFO [org.apache.spark.executor.Executor] - Finished task 9.0 in stage 185.0 (TID 413). 166054 bytes result sent to driver
2021-12-08 10:16:52,898 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 9.0 in stage 185.0 (TID 413) in 37604 ms on localhost (executor driver) (4/12)
2021-12-08 10:16:52,902 [Executor task launch worker for task 404] INFO [org.apache.spark.storage.memory.MemoryStore] - Block rdd_169_0 stored as values in memory (estimated size 11.1 MB, free 1659.9 MB)
2021-12-08 10:16:52,902 [dispatcher-event-loop-10] INFO [org.apache.spark.storage.BlockManagerInfo] - Added rdd_169_0 in memory on qb:61292 (size: 11.1 MB, free: 1663.8 MB)
2021-12-08 10:16:52,908 [Executor task launch worker for task 409] INFO [org.apache.spark.storage.memory.MemoryStore] - Block rdd_169_5 stored as values in memory (estimated size 11.1 MB, free 1648.8 MB)
2021-12-08 10:16:52,908 [dispatcher-event-loop-3] INFO [org.apache.spark.storage.BlockManagerInfo] - Added rdd_169_5 in memory on qb:61292 (size: 11.1 MB, free: 1652.7 MB)
2021-12-08 10:16:52,922 [Executor task launch worker for task 415] INFO [org.apache.spark.executor.Executor] - Finished task 11.0 in stage 185.0 (TID 415). 166054 bytes result sent to driver
2021-12-08 10:16:52,923 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 11.0 in stage 185.0 (TID 415) in 37629 ms on localhost (executor driver) (5/12)
2021-12-08 10:16:52,938 [Executor task launch worker for task 412] INFO [org.apache.spark.executor.Executor] - Finished task 8.0 in stage 185.0 (TID 412). 166054 bytes result sent to driver
2021-12-08 10:16:52,939 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 8.0 in stage 185.0 (TID 412) in 37645 ms on localhost (executor driver) (6/12)
2021-12-08 10:16:53,024 [Executor task launch worker for task 414] INFO [org.apache.spark.storage.memory.MemoryStore] - Block rdd_169_10 stored as values in memory (estimated size 11.1 MB, free 1637.7 MB)
2021-12-08 10:16:53,024 [dispatcher-event-loop-6] INFO [org.apache.spark.storage.BlockManagerInfo] - Added rdd_169_10 in memory on qb:61292 (size: 11.1 MB, free: 1641.6 MB)
2021-12-08 10:16:53,031 [Executor task launch worker for task 411] INFO [org.apache.spark.executor.Executor] - Finished task 7.0 in stage 185.0 (TID 411). 166054 bytes result sent to driver
2021-12-08 10:16:53,032 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 7.0 in stage 185.0 (TID 411) in 37738 ms on localhost (executor driver) (7/12)
2021-12-08 10:16:53,057 [Executor task launch worker for task 408] INFO [org.apache.spark.storage.memory.MemoryStore] - Block rdd_169_4 stored as values in memory (estimated size 11.1 MB, free 1626.6 MB)
2021-12-08 10:16:53,058 [dispatcher-event-loop-0] INFO [org.apache.spark.storage.BlockManagerInfo] - Added rdd_169_4 in memory on qb:61292 (size: 11.1 MB, free: 1630.5 MB)
2021-12-08 10:16:53,114 [Executor task launch worker for task 407] INFO [org.apache.spark.storage.memory.MemoryStore] - Block rdd_169_3 stored as values in memory (estimated size 11.1 MB, free 1615.5 MB)
2021-12-08 10:16:53,115 [dispatcher-event-loop-7] INFO [org.apache.spark.storage.BlockManagerInfo] - Added rdd_169_3 in memory on qb:61292 (size: 11.1 MB, free: 1619.4 MB)
2021-12-08 10:16:53,115 [Executor task launch worker for task 404] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 185.0 (TID 404). 166054 bytes result sent to driver
2021-12-08 10:16:53,115 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 185.0 (TID 404) in 37821 ms on localhost (executor driver) (8/12)
2021-12-08 10:16:53,124 [Executor task launch worker for task 409] INFO [org.apache.spark.executor.Executor] - Finished task 5.0 in stage 185.0 (TID 409). 166054 bytes result sent to driver
2021-12-08 10:16:53,124 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 5.0 in stage 185.0 (TID 409) in 37830 ms on localhost (executor driver) (9/12)
2021-12-08 10:16:53,226 [Executor task launch worker for task 414] INFO [org.apache.spark.executor.Executor] - Finished task 10.0 in stage 185.0 (TID 414). 166054 bytes result sent to driver
2021-12-08 10:16:53,227 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 10.0 in stage 185.0 (TID 414) in 37933 ms on localhost (executor driver) (10/12)
2021-12-08 10:16:53,235 [Executor task launch worker for task 408] INFO [org.apache.spark.executor.Executor] - Finished task 4.0 in stage 185.0 (TID 408). 166097 bytes result sent to driver
2021-12-08 10:16:53,235 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 4.0 in stage 185.0 (TID 408) in 37941 ms on localhost (executor driver) (11/12)
2021-12-08 10:16:53,292 [Executor task launch worker for task 407] INFO [org.apache.spark.executor.Executor] - Finished task 3.0 in stage 185.0 (TID 407). 166097 bytes result sent to driver
2021-12-08 10:16:53,292 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 3.0 in stage 185.0 (TID 407) in 37998 ms on localhost (executor driver) (12/12)
2021-12-08 10:16:53,292 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 185.0, whose tasks have all completed, from pool 
2021-12-08 10:16:53,292 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 185 (aggregate at ALS.scala:1711) finished in 38.006 s
2021-12-08 10:16:53,293 [main] INFO [org.apache.spark.scheduler.DAGScheduler] - Job 18 finished: aggregate at ALS.scala:1711, took 39.414210 s
2021-12-08 10:16:53,308 [main] INFO [org.apache.spark.rdd.MapPartitionsRDD] - Removing RDD 159 from persistence list
2021-12-08 10:16:53,309 [block-manager-slave-async-thread-pool-0] INFO [org.apache.spark.storage.BlockManager] - Removing RDD 159
2021-12-08 10:16:53,316 [main] INFO [org.apache.spark.SparkContext] - Starting job: aggregate at ALS.scala:1711
2021-12-08 10:16:53,317 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 174 (flatMap at ALS.scala:1653)
2021-12-08 10:16:53,317 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 19 (aggregate at ALS.scala:1711) with 12 output partitions
2021-12-08 10:16:53,317 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 205 (aggregate at ALS.scala:1711)
2021-12-08 10:16:53,317 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 204, ShuffleMapStage 190)
2021-12-08 10:16:53,318 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List(ShuffleMapStage 204)
2021-12-08 10:16:53,318 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ShuffleMapStage 204 (MapPartitionsRDD[174] at flatMap at ALS.scala:1653), which has no missing parents
2021-12-08 10:16:53,321 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_42 stored as values in memory (estimated size 2.2 MB, free 1661.1 MB)
2021-12-08 10:16:53,325 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_42_piece0 stored as bytes in memory (estimated size 2.2 MB, free 1658.9 MB)
2021-12-08 10:16:53,325 [dispatcher-event-loop-7] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_42_piece0 in memory on qb:61292 (size: 2.2 MB, free: 1665.1 MB)
2021-12-08 10:16:53,325 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 42 from broadcast at DAGScheduler.scala:1039
2021-12-08 10:16:53,325 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 12 missing tasks from ShuffleMapStage 204 (MapPartitionsRDD[174] at flatMap at ALS.scala:1653) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11))
2021-12-08 10:16:53,325 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 204.0 with 12 tasks
2021-12-08 10:16:53,326 [dispatcher-event-loop-9] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 204.0 (TID 416, localhost, executor driver, partition 0, PROCESS_LOCAL, 7928 bytes)
2021-12-08 10:16:53,326 [dispatcher-event-loop-9] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 204.0 (TID 417, localhost, executor driver, partition 1, PROCESS_LOCAL, 7928 bytes)
2021-12-08 10:16:53,326 [dispatcher-event-loop-9] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 2.0 in stage 204.0 (TID 418, localhost, executor driver, partition 2, PROCESS_LOCAL, 7928 bytes)
2021-12-08 10:16:53,326 [dispatcher-event-loop-9] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 3.0 in stage 204.0 (TID 419, localhost, executor driver, partition 3, PROCESS_LOCAL, 7928 bytes)
2021-12-08 10:16:53,326 [dispatcher-event-loop-9] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 4.0 in stage 204.0 (TID 420, localhost, executor driver, partition 4, PROCESS_LOCAL, 7928 bytes)
2021-12-08 10:16:53,326 [dispatcher-event-loop-9] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 5.0 in stage 204.0 (TID 421, localhost, executor driver, partition 5, PROCESS_LOCAL, 7928 bytes)
2021-12-08 10:16:53,326 [dispatcher-event-loop-9] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 6.0 in stage 204.0 (TID 422, localhost, executor driver, partition 6, PROCESS_LOCAL, 7928 bytes)
2021-12-08 10:16:53,326 [dispatcher-event-loop-9] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 7.0 in stage 204.0 (TID 423, localhost, executor driver, partition 7, PROCESS_LOCAL, 7928 bytes)
2021-12-08 10:16:53,326 [dispatcher-event-loop-9] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 8.0 in stage 204.0 (TID 424, localhost, executor driver, partition 8, PROCESS_LOCAL, 7928 bytes)
2021-12-08 10:16:53,326 [dispatcher-event-loop-9] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 9.0 in stage 204.0 (TID 425, localhost, executor driver, partition 9, PROCESS_LOCAL, 7928 bytes)
2021-12-08 10:16:53,326 [dispatcher-event-loop-9] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 10.0 in stage 204.0 (TID 426, localhost, executor driver, partition 10, PROCESS_LOCAL, 7928 bytes)
2021-12-08 10:16:53,326 [dispatcher-event-loop-9] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 11.0 in stage 204.0 (TID 427, localhost, executor driver, partition 11, PROCESS_LOCAL, 7928 bytes)
2021-12-08 10:16:53,326 [Executor task launch worker for task 420] INFO [org.apache.spark.executor.Executor] - Running task 4.0 in stage 204.0 (TID 420)
2021-12-08 10:16:53,326 [Executor task launch worker for task 422] INFO [org.apache.spark.executor.Executor] - Running task 6.0 in stage 204.0 (TID 422)
2021-12-08 10:16:53,326 [Executor task launch worker for task 427] INFO [org.apache.spark.executor.Executor] - Running task 11.0 in stage 204.0 (TID 427)
2021-12-08 10:16:53,326 [Executor task launch worker for task 416] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 204.0 (TID 416)
2021-12-08 10:16:53,326 [Executor task launch worker for task 426] INFO [org.apache.spark.executor.Executor] - Running task 10.0 in stage 204.0 (TID 426)
2021-12-08 10:16:53,326 [Executor task launch worker for task 425] INFO [org.apache.spark.executor.Executor] - Running task 9.0 in stage 204.0 (TID 425)
2021-12-08 10:16:53,326 [Executor task launch worker for task 423] INFO [org.apache.spark.executor.Executor] - Running task 7.0 in stage 204.0 (TID 423)
2021-12-08 10:16:53,326 [Executor task launch worker for task 418] INFO [org.apache.spark.executor.Executor] - Running task 2.0 in stage 204.0 (TID 418)
2021-12-08 10:16:53,326 [Executor task launch worker for task 424] INFO [org.apache.spark.executor.Executor] - Running task 8.0 in stage 204.0 (TID 424)
2021-12-08 10:16:53,326 [Executor task launch worker for task 417] INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 204.0 (TID 417)
2021-12-08 10:16:53,326 [Executor task launch worker for task 421] INFO [org.apache.spark.executor.Executor] - Running task 5.0 in stage 204.0 (TID 421)
2021-12-08 10:16:53,326 [Executor task launch worker for task 419] INFO [org.apache.spark.executor.Executor] - Running task 3.0 in stage 204.0 (TID 419)
2021-12-08 10:16:53,330 [Executor task launch worker for task 427] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_22_11 locally
2021-12-08 10:16:53,331 [Executor task launch worker for task 427] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_169_11 locally
2021-12-08 10:16:53,331 [Executor task launch worker for task 422] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_22_6 locally
2021-12-08 10:16:53,331 [Executor task launch worker for task 420] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_22_4 locally
2021-12-08 10:16:53,331 [Executor task launch worker for task 421] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_22_5 locally
2021-12-08 10:16:53,331 [Executor task launch worker for task 426] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_22_10 locally
2021-12-08 10:16:53,331 [Executor task launch worker for task 417] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_22_1 locally
2021-12-08 10:16:53,331 [Executor task launch worker for task 417] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_169_1 locally
2021-12-08 10:16:53,331 [Executor task launch worker for task 420] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_169_4 locally
2021-12-08 10:16:53,331 [Executor task launch worker for task 418] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_22_2 locally
2021-12-08 10:16:53,331 [Executor task launch worker for task 418] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_169_2 locally
2021-12-08 10:16:53,331 [Executor task launch worker for task 422] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_169_6 locally
2021-12-08 10:16:53,331 [Executor task launch worker for task 421] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_169_5 locally
2021-12-08 10:16:53,332 [Executor task launch worker for task 426] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_169_10 locally
2021-12-08 10:16:53,333 [Executor task launch worker for task 424] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_22_8 locally
2021-12-08 10:16:53,333 [Executor task launch worker for task 424] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_169_8 locally
2021-12-08 10:16:53,333 [Executor task launch worker for task 416] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_22_0 locally
2021-12-08 10:16:53,333 [Executor task launch worker for task 416] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_169_0 locally
2021-12-08 10:16:53,333 [Executor task launch worker for task 425] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_22_9 locally
2021-12-08 10:16:53,333 [Executor task launch worker for task 425] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_169_9 locally
2021-12-08 10:16:53,334 [Executor task launch worker for task 423] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_22_7 locally
2021-12-08 10:16:53,334 [Executor task launch worker for task 423] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_169_7 locally
2021-12-08 10:16:53,333 [Executor task launch worker for task 419] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_22_3 locally
2021-12-08 10:16:53,335 [Executor task launch worker for task 419] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_169_3 locally
2021-12-08 10:16:54,960 [Executor task launch worker for task 418] INFO [org.apache.spark.executor.Executor] - Finished task 2.0 in stage 204.0 (TID 418). 999 bytes result sent to driver
2021-12-08 10:16:54,960 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 2.0 in stage 204.0 (TID 418) in 1634 ms on localhost (executor driver) (1/12)
2021-12-08 10:16:54,977 [Executor task launch worker for task 427] INFO [org.apache.spark.executor.Executor] - Finished task 11.0 in stage 204.0 (TID 427). 999 bytes result sent to driver
2021-12-08 10:16:54,977 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 11.0 in stage 204.0 (TID 427) in 1651 ms on localhost (executor driver) (2/12)
2021-12-08 10:16:55,008 [Executor task launch worker for task 420] INFO [org.apache.spark.executor.Executor] - Finished task 4.0 in stage 204.0 (TID 420). 999 bytes result sent to driver
2021-12-08 10:16:55,008 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 4.0 in stage 204.0 (TID 420) in 1682 ms on localhost (executor driver) (3/12)
2021-12-08 10:16:55,017 [Executor task launch worker for task 422] INFO [org.apache.spark.executor.Executor] - Finished task 6.0 in stage 204.0 (TID 422). 999 bytes result sent to driver
2021-12-08 10:16:55,017 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 6.0 in stage 204.0 (TID 422) in 1691 ms on localhost (executor driver) (4/12)
2021-12-08 10:16:55,028 [Executor task launch worker for task 426] INFO [org.apache.spark.executor.Executor] - Finished task 10.0 in stage 204.0 (TID 426). 999 bytes result sent to driver
2021-12-08 10:16:55,028 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 10.0 in stage 204.0 (TID 426) in 1702 ms on localhost (executor driver) (5/12)
2021-12-08 10:16:55,029 [Executor task launch worker for task 424] INFO [org.apache.spark.executor.Executor] - Finished task 8.0 in stage 204.0 (TID 424). 999 bytes result sent to driver
2021-12-08 10:16:55,029 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 8.0 in stage 204.0 (TID 424) in 1703 ms on localhost (executor driver) (6/12)
2021-12-08 10:16:55,050 [Executor task launch worker for task 423] INFO [org.apache.spark.executor.Executor] - Finished task 7.0 in stage 204.0 (TID 423). 999 bytes result sent to driver
2021-12-08 10:16:55,051 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 7.0 in stage 204.0 (TID 423) in 1725 ms on localhost (executor driver) (7/12)
2021-12-08 10:16:55,062 [Executor task launch worker for task 421] INFO [org.apache.spark.executor.Executor] - Finished task 5.0 in stage 204.0 (TID 421). 999 bytes result sent to driver
2021-12-08 10:16:55,062 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 5.0 in stage 204.0 (TID 421) in 1736 ms on localhost (executor driver) (8/12)
2021-12-08 10:16:55,187 [Executor task launch worker for task 416] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 204.0 (TID 416). 999 bytes result sent to driver
2021-12-08 10:16:55,188 [Executor task launch worker for task 425] INFO [org.apache.spark.executor.Executor] - Finished task 9.0 in stage 204.0 (TID 425). 999 bytes result sent to driver
2021-12-08 10:16:55,190 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 204.0 (TID 416) in 1864 ms on localhost (executor driver) (9/12)
2021-12-08 10:16:55,190 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 9.0 in stage 204.0 (TID 425) in 1864 ms on localhost (executor driver) (10/12)
2021-12-08 10:16:55,273 [Executor task launch worker for task 417] INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 204.0 (TID 417). 999 bytes result sent to driver
2021-12-08 10:16:55,273 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 204.0 (TID 417) in 1947 ms on localhost (executor driver) (11/12)
2021-12-08 10:16:55,273 [Executor task launch worker for task 419] INFO [org.apache.spark.executor.Executor] - Finished task 3.0 in stage 204.0 (TID 419). 999 bytes result sent to driver
2021-12-08 10:16:55,273 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 3.0 in stage 204.0 (TID 419) in 1947 ms on localhost (executor driver) (12/12)
2021-12-08 10:16:55,273 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 204.0, whose tasks have all completed, from pool 
2021-12-08 10:16:55,274 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ShuffleMapStage 204 (flatMap at ALS.scala:1653) finished in 1.955 s
2021-12-08 10:16:55,274 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - looking for newly runnable stages
2021-12-08 10:16:55,274 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - running: Set()
2021-12-08 10:16:55,274 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - waiting: Set(ResultStage 205)
2021-12-08 10:16:55,274 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - failed: Set()
2021-12-08 10:16:55,274 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 205 (MapPartitionsRDD[180] at values at ALS.scala:1711), which has no missing parents
2021-12-08 10:16:55,277 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_43 stored as values in memory (estimated size 2.5 MB, free 1656.4 MB)
2021-12-08 10:16:55,281 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_43_piece0 stored as bytes in memory (estimated size 2.3 MB, free 1654.1 MB)
2021-12-08 10:16:55,281 [dispatcher-event-loop-3] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_43_piece0 in memory on qb:61292 (size: 2.3 MB, free: 1662.7 MB)
2021-12-08 10:16:55,282 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 43 from broadcast at DAGScheduler.scala:1039
2021-12-08 10:16:55,282 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 12 missing tasks from ResultStage 205 (MapPartitionsRDD[180] at values at ALS.scala:1711) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11))
2021-12-08 10:16:55,282 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 205.0 with 12 tasks
2021-12-08 10:16:55,282 [dispatcher-event-loop-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 205.0 (TID 428, localhost, executor driver, partition 0, PROCESS_LOCAL, 7888 bytes)
2021-12-08 10:16:55,282 [dispatcher-event-loop-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 205.0 (TID 429, localhost, executor driver, partition 1, PROCESS_LOCAL, 7888 bytes)
2021-12-08 10:16:55,282 [dispatcher-event-loop-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 2.0 in stage 205.0 (TID 430, localhost, executor driver, partition 2, PROCESS_LOCAL, 7888 bytes)
2021-12-08 10:16:55,282 [dispatcher-event-loop-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 3.0 in stage 205.0 (TID 431, localhost, executor driver, partition 3, PROCESS_LOCAL, 7888 bytes)
2021-12-08 10:16:55,283 [dispatcher-event-loop-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 4.0 in stage 205.0 (TID 432, localhost, executor driver, partition 4, PROCESS_LOCAL, 7888 bytes)
2021-12-08 10:16:55,283 [dispatcher-event-loop-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 5.0 in stage 205.0 (TID 433, localhost, executor driver, partition 5, PROCESS_LOCAL, 7888 bytes)
2021-12-08 10:16:55,283 [dispatcher-event-loop-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 6.0 in stage 205.0 (TID 434, localhost, executor driver, partition 6, PROCESS_LOCAL, 7888 bytes)
2021-12-08 10:16:55,283 [dispatcher-event-loop-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 7.0 in stage 205.0 (TID 435, localhost, executor driver, partition 7, PROCESS_LOCAL, 7888 bytes)
2021-12-08 10:16:55,283 [dispatcher-event-loop-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 8.0 in stage 205.0 (TID 436, localhost, executor driver, partition 8, PROCESS_LOCAL, 7888 bytes)
2021-12-08 10:16:55,283 [dispatcher-event-loop-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 9.0 in stage 205.0 (TID 437, localhost, executor driver, partition 9, PROCESS_LOCAL, 7888 bytes)
2021-12-08 10:16:55,283 [dispatcher-event-loop-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 10.0 in stage 205.0 (TID 438, localhost, executor driver, partition 10, PROCESS_LOCAL, 7888 bytes)
2021-12-08 10:16:55,283 [dispatcher-event-loop-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 11.0 in stage 205.0 (TID 439, localhost, executor driver, partition 11, PROCESS_LOCAL, 7888 bytes)
2021-12-08 10:16:55,283 [Executor task launch worker for task 432] INFO [org.apache.spark.executor.Executor] - Running task 4.0 in stage 205.0 (TID 432)
2021-12-08 10:16:55,283 [Executor task launch worker for task 439] INFO [org.apache.spark.executor.Executor] - Running task 11.0 in stage 205.0 (TID 439)
2021-12-08 10:16:55,283 [Executor task launch worker for task 433] INFO [org.apache.spark.executor.Executor] - Running task 5.0 in stage 205.0 (TID 433)
2021-12-08 10:16:55,283 [Executor task launch worker for task 435] INFO [org.apache.spark.executor.Executor] - Running task 7.0 in stage 205.0 (TID 435)
2021-12-08 10:16:55,283 [Executor task launch worker for task 437] INFO [org.apache.spark.executor.Executor] - Running task 9.0 in stage 205.0 (TID 437)
2021-12-08 10:16:55,283 [Executor task launch worker for task 428] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 205.0 (TID 428)
2021-12-08 10:16:55,283 [Executor task launch worker for task 429] INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 205.0 (TID 429)
2021-12-08 10:16:55,283 [Executor task launch worker for task 431] INFO [org.apache.spark.executor.Executor] - Running task 3.0 in stage 205.0 (TID 431)
2021-12-08 10:16:55,283 [Executor task launch worker for task 438] INFO [org.apache.spark.executor.Executor] - Running task 10.0 in stage 205.0 (TID 438)
2021-12-08 10:16:55,283 [Executor task launch worker for task 430] INFO [org.apache.spark.executor.Executor] - Running task 2.0 in stage 205.0 (TID 430)
2021-12-08 10:16:55,283 [Executor task launch worker for task 436] INFO [org.apache.spark.executor.Executor] - Running task 8.0 in stage 205.0 (TID 436)
2021-12-08 10:16:55,283 [Executor task launch worker for task 434] INFO [org.apache.spark.executor.Executor] - Running task 6.0 in stage 205.0 (TID 434)
2021-12-08 10:16:55,287 [Executor task launch worker for task 431] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_26_3 locally
2021-12-08 10:16:55,287 [Executor task launch worker for task 430] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_26_2 locally
2021-12-08 10:16:55,287 [Executor task launch worker for task 436] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_26_8 locally
2021-12-08 10:16:55,287 [Executor task launch worker for task 435] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_26_7 locally
2021-12-08 10:16:55,288 [Executor task launch worker for task 439] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_26_11 locally
2021-12-08 10:16:55,287 [Executor task launch worker for task 429] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_26_1 locally
2021-12-08 10:16:55,288 [Executor task launch worker for task 431] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 12 non-empty blocks out of 12 blocks
2021-12-08 10:16:55,287 [Executor task launch worker for task 433] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_26_5 locally
2021-12-08 10:16:55,287 [Executor task launch worker for task 428] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_26_0 locally
2021-12-08 10:16:55,288 [Executor task launch worker for task 431] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-08 10:16:55,288 [Executor task launch worker for task 436] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 12 non-empty blocks out of 12 blocks
2021-12-08 10:16:55,288 [Executor task launch worker for task 430] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 12 non-empty blocks out of 12 blocks
2021-12-08 10:16:55,288 [Executor task launch worker for task 439] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 12 non-empty blocks out of 12 blocks
2021-12-08 10:16:55,288 [Executor task launch worker for task 430] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-08 10:16:55,288 [Executor task launch worker for task 436] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-08 10:16:55,288 [Executor task launch worker for task 433] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 12 non-empty blocks out of 12 blocks
2021-12-08 10:16:55,288 [Executor task launch worker for task 429] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 12 non-empty blocks out of 12 blocks
2021-12-08 10:16:55,288 [Executor task launch worker for task 435] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 12 non-empty blocks out of 12 blocks
2021-12-08 10:16:55,288 [Executor task launch worker for task 429] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-08 10:16:55,288 [Executor task launch worker for task 433] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-08 10:16:55,288 [Executor task launch worker for task 437] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_26_9 locally
2021-12-08 10:16:55,288 [Executor task launch worker for task 428] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 12 non-empty blocks out of 12 blocks
2021-12-08 10:16:55,288 [Executor task launch worker for task 439] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-08 10:16:55,288 [Executor task launch worker for task 428] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-08 10:16:55,288 [Executor task launch worker for task 435] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-08 10:16:55,289 [Executor task launch worker for task 438] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_26_10 locally
2021-12-08 10:16:55,289 [Executor task launch worker for task 437] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 12 non-empty blocks out of 12 blocks
2021-12-08 10:16:55,289 [Executor task launch worker for task 437] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-08 10:16:55,289 [Executor task launch worker for task 438] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 12 non-empty blocks out of 12 blocks
2021-12-08 10:16:55,289 [Executor task launch worker for task 438] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-08 10:16:55,290 [Executor task launch worker for task 434] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_26_6 locally
2021-12-08 10:16:55,290 [Executor task launch worker for task 434] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 12 non-empty blocks out of 12 blocks
2021-12-08 10:16:55,290 [Executor task launch worker for task 434] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-08 10:16:55,290 [Executor task launch worker for task 432] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_26_4 locally
2021-12-08 10:16:55,290 [Executor task launch worker for task 432] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 12 non-empty blocks out of 12 blocks
2021-12-08 10:16:55,290 [Executor task launch worker for task 432] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-08 10:16:55,364 [dispatcher-event-loop-1] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_42_piece0 on qb:61292 in memory (size: 2.2 MB, free: 1664.9 MB)
2021-12-08 10:16:55,872 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 911
2021-12-08 10:16:55,872 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 916
2021-12-08 10:16:55,872 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 920
2021-12-08 10:16:55,872 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 902
2021-12-08 10:16:55,872 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 896
2021-12-08 10:16:55,872 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 882
2021-12-08 10:16:55,872 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 885
2021-12-08 10:16:55,872 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 889
2021-12-08 10:16:55,872 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 914
2021-12-08 10:16:55,872 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 913
2021-12-08 10:16:55,872 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 878
2021-12-08 10:16:55,872 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 880
2021-12-08 10:16:55,872 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 879
2021-12-08 10:16:55,872 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 912
2021-12-08 10:16:55,872 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 919
2021-12-08 10:16:55,872 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 899
2021-12-08 10:16:55,872 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 887
2021-12-08 10:16:55,872 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 884
2021-12-08 10:16:55,872 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 918
2021-12-08 10:16:55,872 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 877
2021-12-08 10:16:55,876 [dispatcher-event-loop-5] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_41_piece0 on qb:61292 in memory (size: 2.2 MB, free: 1667.1 MB)
2021-12-08 10:16:55,876 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 881
2021-12-08 10:16:55,876 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 922
2021-12-08 10:16:55,876 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 895
2021-12-08 10:16:55,876 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 904
2021-12-08 10:16:55,876 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 888
2021-12-08 10:16:55,876 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 906
2021-12-08 10:16:55,876 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 907
2021-12-08 10:16:55,876 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 875
2021-12-08 10:16:55,876 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 908
2021-12-08 10:16:55,876 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 898
2021-12-08 10:16:55,876 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 905
2021-12-08 10:16:55,876 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 901
2021-12-08 10:16:55,876 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 886
2021-12-08 10:16:55,876 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 900
2021-12-08 10:16:55,876 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 924
2021-12-08 10:16:55,877 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 891
2021-12-08 10:16:55,877 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 893
2021-12-08 10:16:55,877 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 897
2021-12-08 10:16:55,877 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 923
2021-12-08 10:16:55,877 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 903
2021-12-08 10:16:55,877 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 921
2021-12-08 10:16:55,877 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 909
2021-12-08 10:16:55,877 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 892
2021-12-08 10:16:55,877 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 890
2021-12-08 10:16:55,877 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 883
2021-12-08 10:16:55,877 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 894
2021-12-08 10:16:55,877 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 917
2021-12-08 10:16:55,877 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 876
2021-12-08 10:16:55,877 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 910
2021-12-08 10:16:55,877 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 915
2021-12-08 10:17:16,633 [Executor task launch worker for task 433] INFO [org.apache.spark.storage.memory.MemoryStore] - Block rdd_179_5 stored as values in memory (estimated size 4.0 MB, free 1659.0 MB)
2021-12-08 10:17:16,633 [dispatcher-event-loop-2] INFO [org.apache.spark.storage.BlockManagerInfo] - Added rdd_179_5 in memory on qb:61292 (size: 4.0 MB, free: 1663.1 MB)
2021-12-08 10:17:16,756 [Executor task launch worker for task 433] INFO [org.apache.spark.executor.Executor] - Finished task 5.0 in stage 205.0 (TID 433). 166097 bytes result sent to driver
2021-12-08 10:17:16,767 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 5.0 in stage 205.0 (TID 433) in 21484 ms on localhost (executor driver) (1/12)
2021-12-08 10:17:16,891 [Executor task launch worker for task 429] INFO [org.apache.spark.storage.memory.MemoryStore] - Block rdd_179_1 stored as values in memory (estimated size 4.0 MB, free 1655.0 MB)
2021-12-08 10:17:16,891 [dispatcher-event-loop-6] INFO [org.apache.spark.storage.BlockManagerInfo] - Added rdd_179_1 in memory on qb:61292 (size: 4.0 MB, free: 1659.1 MB)
2021-12-08 10:17:17,009 [Executor task launch worker for task 429] INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 205.0 (TID 429). 166140 bytes result sent to driver
2021-12-08 10:17:17,011 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 205.0 (TID 429) in 21729 ms on localhost (executor driver) (2/12)
2021-12-08 10:17:17,526 [Executor task launch worker for task 432] INFO [org.apache.spark.storage.memory.MemoryStore] - Block rdd_179_4 stored as values in memory (estimated size 4.0 MB, free 1651.0 MB)
2021-12-08 10:17:17,526 [dispatcher-event-loop-7] INFO [org.apache.spark.storage.BlockManagerInfo] - Added rdd_179_4 in memory on qb:61292 (size: 4.0 MB, free: 1655.1 MB)
2021-12-08 10:17:17,628 [Executor task launch worker for task 432] INFO [org.apache.spark.executor.Executor] - Finished task 4.0 in stage 205.0 (TID 432). 166054 bytes result sent to driver
2021-12-08 10:17:17,629 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 4.0 in stage 205.0 (TID 432) in 22346 ms on localhost (executor driver) (3/12)
2021-12-08 10:17:17,702 [Executor task launch worker for task 428] INFO [org.apache.spark.storage.memory.MemoryStore] - Block rdd_179_0 stored as values in memory (estimated size 4.0 MB, free 1647.1 MB)
2021-12-08 10:17:17,702 [dispatcher-event-loop-11] INFO [org.apache.spark.storage.BlockManagerInfo] - Added rdd_179_0 in memory on qb:61292 (size: 4.0 MB, free: 1651.1 MB)
2021-12-08 10:17:17,820 [Executor task launch worker for task 439] INFO [org.apache.spark.storage.memory.MemoryStore] - Block rdd_179_11 stored as values in memory (estimated size 4.0 MB, free 1643.1 MB)
2021-12-08 10:17:17,820 [dispatcher-event-loop-4] INFO [org.apache.spark.storage.BlockManagerInfo] - Added rdd_179_11 in memory on qb:61292 (size: 4.0 MB, free: 1647.1 MB)
2021-12-08 10:17:17,827 [Executor task launch worker for task 428] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 205.0 (TID 428). 166140 bytes result sent to driver
2021-12-08 10:17:17,827 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 205.0 (TID 428) in 22545 ms on localhost (executor driver) (4/12)
2021-12-08 10:17:17,888 [Executor task launch worker for task 436] INFO [org.apache.spark.storage.memory.MemoryStore] - Block rdd_179_8 stored as values in memory (estimated size 4.0 MB, free 1639.1 MB)
2021-12-08 10:17:17,889 [dispatcher-event-loop-9] INFO [org.apache.spark.storage.BlockManagerInfo] - Added rdd_179_8 in memory on qb:61292 (size: 4.0 MB, free: 1643.1 MB)
2021-12-08 10:17:17,928 [Executor task launch worker for task 439] INFO [org.apache.spark.executor.Executor] - Finished task 11.0 in stage 205.0 (TID 439). 166140 bytes result sent to driver
2021-12-08 10:17:17,928 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 11.0 in stage 205.0 (TID 439) in 22645 ms on localhost (executor driver) (5/12)
2021-12-08 10:17:17,980 [Executor task launch worker for task 436] INFO [org.apache.spark.executor.Executor] - Finished task 8.0 in stage 205.0 (TID 436). 166097 bytes result sent to driver
2021-12-08 10:17:17,980 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 8.0 in stage 205.0 (TID 436) in 22697 ms on localhost (executor driver) (6/12)
2021-12-08 10:17:18,212 [Executor task launch worker for task 438] INFO [org.apache.spark.storage.memory.MemoryStore] - Block rdd_179_10 stored as values in memory (estimated size 4.0 MB, free 1635.1 MB)
2021-12-08 10:17:18,212 [dispatcher-event-loop-2] INFO [org.apache.spark.storage.BlockManagerInfo] - Added rdd_179_10 in memory on qb:61292 (size: 4.0 MB, free: 1639.1 MB)
2021-12-08 10:17:18,315 [Executor task launch worker for task 438] INFO [org.apache.spark.executor.Executor] - Finished task 10.0 in stage 205.0 (TID 438). 166054 bytes result sent to driver
2021-12-08 10:17:18,316 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 10.0 in stage 205.0 (TID 438) in 23033 ms on localhost (executor driver) (7/12)
2021-12-08 10:17:18,520 [Executor task launch worker for task 435] INFO [org.apache.spark.storage.memory.MemoryStore] - Block rdd_179_7 stored as values in memory (estimated size 4.0 MB, free 1631.1 MB)
2021-12-08 10:17:18,520 [dispatcher-event-loop-6] INFO [org.apache.spark.storage.BlockManagerInfo] - Added rdd_179_7 in memory on qb:61292 (size: 4.0 MB, free: 1635.2 MB)
2021-12-08 10:17:18,606 [Executor task launch worker for task 435] INFO [org.apache.spark.executor.Executor] - Finished task 7.0 in stage 205.0 (TID 435). 166097 bytes result sent to driver
2021-12-08 10:17:18,607 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 7.0 in stage 205.0 (TID 435) in 23324 ms on localhost (executor driver) (8/12)
2021-12-08 10:17:18,760 [Executor task launch worker for task 437] INFO [org.apache.spark.storage.memory.MemoryStore] - Block rdd_179_9 stored as values in memory (estimated size 4.0 MB, free 1627.1 MB)
2021-12-08 10:17:18,760 [dispatcher-event-loop-7] INFO [org.apache.spark.storage.BlockManagerInfo] - Added rdd_179_9 in memory on qb:61292 (size: 4.0 MB, free: 1631.2 MB)
2021-12-08 10:17:18,821 [Executor task launch worker for task 437] INFO [org.apache.spark.executor.Executor] - Finished task 9.0 in stage 205.0 (TID 437). 166097 bytes result sent to driver
2021-12-08 10:17:18,822 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 9.0 in stage 205.0 (TID 437) in 23539 ms on localhost (executor driver) (9/12)
2021-12-08 10:17:19,004 [Executor task launch worker for task 431] INFO [org.apache.spark.storage.memory.MemoryStore] - Block rdd_179_3 stored as values in memory (estimated size 4.0 MB, free 1623.1 MB)
2021-12-08 10:17:19,004 [dispatcher-event-loop-11] INFO [org.apache.spark.storage.BlockManagerInfo] - Added rdd_179_3 in memory on qb:61292 (size: 4.0 MB, free: 1627.2 MB)
2021-12-08 10:17:19,083 [Executor task launch worker for task 431] INFO [org.apache.spark.executor.Executor] - Finished task 3.0 in stage 205.0 (TID 431). 166097 bytes result sent to driver
2021-12-08 10:17:19,083 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 3.0 in stage 205.0 (TID 431) in 23801 ms on localhost (executor driver) (10/12)
2021-12-08 10:17:19,323 [Executor task launch worker for task 434] INFO [org.apache.spark.storage.memory.MemoryStore] - Block rdd_179_6 stored as values in memory (estimated size 4.0 MB, free 1619.1 MB)
2021-12-08 10:17:19,323 [dispatcher-event-loop-8] INFO [org.apache.spark.storage.BlockManagerInfo] - Added rdd_179_6 in memory on qb:61292 (size: 4.0 MB, free: 1623.2 MB)
2021-12-08 10:17:19,385 [Executor task launch worker for task 434] INFO [org.apache.spark.executor.Executor] - Finished task 6.0 in stage 205.0 (TID 434). 166054 bytes result sent to driver
2021-12-08 10:17:19,386 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 6.0 in stage 205.0 (TID 434) in 24103 ms on localhost (executor driver) (11/12)
2021-12-08 10:17:19,414 [Executor task launch worker for task 430] INFO [org.apache.spark.storage.memory.MemoryStore] - Block rdd_179_2 stored as values in memory (estimated size 4.0 MB, free 1615.1 MB)
2021-12-08 10:17:19,414 [dispatcher-event-loop-10] INFO [org.apache.spark.storage.BlockManagerInfo] - Added rdd_179_2 in memory on qb:61292 (size: 4.0 MB, free: 1619.2 MB)
2021-12-08 10:17:19,476 [Executor task launch worker for task 430] INFO [org.apache.spark.executor.Executor] - Finished task 2.0 in stage 205.0 (TID 430). 166097 bytes result sent to driver
2021-12-08 10:17:19,477 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 2.0 in stage 205.0 (TID 430) in 24195 ms on localhost (executor driver) (12/12)
2021-12-08 10:17:19,477 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 205.0, whose tasks have all completed, from pool 
2021-12-08 10:17:19,477 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 205 (aggregate at ALS.scala:1711) finished in 24.203 s
2021-12-08 10:17:19,477 [main] INFO [org.apache.spark.scheduler.DAGScheduler] - Job 19 finished: aggregate at ALS.scala:1711, took 26.160966 s
2021-12-08 10:17:19,491 [main] INFO [org.apache.spark.rdd.MapPartitionsRDD] - Removing RDD 169 from persistence list
2021-12-08 10:17:19,492 [block-manager-slave-async-thread-pool-2] INFO [org.apache.spark.storage.BlockManager] - Removing RDD 169
2021-12-08 10:17:19,498 [main] INFO [org.apache.spark.SparkContext] - Starting job: aggregate at ALS.scala:1711
2021-12-08 10:17:19,499 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 184 (flatMap at ALS.scala:1653)
2021-12-08 10:17:19,499 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 20 (aggregate at ALS.scala:1711) with 12 output partitions
2021-12-08 10:17:19,499 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 226 (aggregate at ALS.scala:1711)
2021-12-08 10:17:19,499 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 207, ShuffleMapStage 225)
2021-12-08 10:17:19,500 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List(ShuffleMapStage 225)
2021-12-08 10:17:19,500 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ShuffleMapStage 225 (MapPartitionsRDD[184] at flatMap at ALS.scala:1653), which has no missing parents
2021-12-08 10:17:19,504 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_44 stored as values in memory (estimated size 2.4 MB, free 1746.0 MB)
2021-12-08 10:17:19,547 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_44_piece0 stored as bytes in memory (estimated size 2.3 MB, free 1743.7 MB)
2021-12-08 10:17:19,547 [dispatcher-event-loop-11] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_44_piece0 in memory on qb:61292 (size: 2.3 MB, free: 1750.1 MB)
2021-12-08 10:17:19,547 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 44 from broadcast at DAGScheduler.scala:1039
2021-12-08 10:17:19,547 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 12 missing tasks from ShuffleMapStage 225 (MapPartitionsRDD[184] at flatMap at ALS.scala:1653) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11))
2021-12-08 10:17:19,547 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 225.0 with 12 tasks
2021-12-08 10:17:19,548 [dispatcher-event-loop-4] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 225.0 (TID 440, localhost, executor driver, partition 0, PROCESS_LOCAL, 7928 bytes)
2021-12-08 10:17:19,548 [dispatcher-event-loop-4] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 225.0 (TID 441, localhost, executor driver, partition 1, PROCESS_LOCAL, 7928 bytes)
2021-12-08 10:17:19,548 [dispatcher-event-loop-4] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 2.0 in stage 225.0 (TID 442, localhost, executor driver, partition 2, PROCESS_LOCAL, 7928 bytes)
2021-12-08 10:17:19,548 [dispatcher-event-loop-4] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 3.0 in stage 225.0 (TID 443, localhost, executor driver, partition 3, PROCESS_LOCAL, 7928 bytes)
2021-12-08 10:17:19,548 [dispatcher-event-loop-4] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 4.0 in stage 225.0 (TID 444, localhost, executor driver, partition 4, PROCESS_LOCAL, 7928 bytes)
2021-12-08 10:17:19,548 [dispatcher-event-loop-4] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 5.0 in stage 225.0 (TID 445, localhost, executor driver, partition 5, PROCESS_LOCAL, 7928 bytes)
2021-12-08 10:17:19,548 [dispatcher-event-loop-4] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 6.0 in stage 225.0 (TID 446, localhost, executor driver, partition 6, PROCESS_LOCAL, 7928 bytes)
2021-12-08 10:17:19,548 [dispatcher-event-loop-4] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 7.0 in stage 225.0 (TID 447, localhost, executor driver, partition 7, PROCESS_LOCAL, 7928 bytes)
2021-12-08 10:17:19,548 [dispatcher-event-loop-4] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 8.0 in stage 225.0 (TID 448, localhost, executor driver, partition 8, PROCESS_LOCAL, 7928 bytes)
2021-12-08 10:17:19,548 [dispatcher-event-loop-4] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 9.0 in stage 225.0 (TID 449, localhost, executor driver, partition 9, PROCESS_LOCAL, 7928 bytes)
2021-12-08 10:17:19,548 [dispatcher-event-loop-4] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 10.0 in stage 225.0 (TID 450, localhost, executor driver, partition 10, PROCESS_LOCAL, 7928 bytes)
2021-12-08 10:17:19,548 [dispatcher-event-loop-4] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 11.0 in stage 225.0 (TID 451, localhost, executor driver, partition 11, PROCESS_LOCAL, 7928 bytes)
2021-12-08 10:17:19,548 [Executor task launch worker for task 442] INFO [org.apache.spark.executor.Executor] - Running task 2.0 in stage 225.0 (TID 442)
2021-12-08 10:17:19,548 [Executor task launch worker for task 440] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 225.0 (TID 440)
2021-12-08 10:17:19,548 [Executor task launch worker for task 450] INFO [org.apache.spark.executor.Executor] - Running task 10.0 in stage 225.0 (TID 450)
2021-12-08 10:17:19,548 [Executor task launch worker for task 447] INFO [org.apache.spark.executor.Executor] - Running task 7.0 in stage 225.0 (TID 447)
2021-12-08 10:17:19,548 [Executor task launch worker for task 449] INFO [org.apache.spark.executor.Executor] - Running task 9.0 in stage 225.0 (TID 449)
2021-12-08 10:17:19,548 [Executor task launch worker for task 445] INFO [org.apache.spark.executor.Executor] - Running task 5.0 in stage 225.0 (TID 445)
2021-12-08 10:17:19,548 [Executor task launch worker for task 448] INFO [org.apache.spark.executor.Executor] - Running task 8.0 in stage 225.0 (TID 448)
2021-12-08 10:17:19,548 [Executor task launch worker for task 446] INFO [org.apache.spark.executor.Executor] - Running task 6.0 in stage 225.0 (TID 446)
2021-12-08 10:17:19,548 [Executor task launch worker for task 443] INFO [org.apache.spark.executor.Executor] - Running task 3.0 in stage 225.0 (TID 443)
2021-12-08 10:17:19,548 [Executor task launch worker for task 444] INFO [org.apache.spark.executor.Executor] - Running task 4.0 in stage 225.0 (TID 444)
2021-12-08 10:17:19,548 [Executor task launch worker for task 441] INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 225.0 (TID 441)
2021-12-08 10:17:19,548 [Executor task launch worker for task 451] INFO [org.apache.spark.executor.Executor] - Running task 11.0 in stage 225.0 (TID 451)
2021-12-08 10:17:19,552 [Executor task launch worker for task 448] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_27_8 locally
2021-12-08 10:17:19,552 [Executor task launch worker for task 451] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_27_11 locally
2021-12-08 10:17:19,552 [Executor task launch worker for task 447] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_27_7 locally
2021-12-08 10:17:19,552 [Executor task launch worker for task 440] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_27_0 locally
2021-12-08 10:17:19,552 [Executor task launch worker for task 440] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_179_0 locally
2021-12-08 10:17:19,552 [Executor task launch worker for task 449] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_27_9 locally
2021-12-08 10:17:19,552 [Executor task launch worker for task 449] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_179_9 locally
2021-12-08 10:17:19,553 [Executor task launch worker for task 443] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_27_3 locally
2021-12-08 10:17:19,553 [Executor task launch worker for task 441] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_27_1 locally
2021-12-08 10:17:19,553 [Executor task launch worker for task 441] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_179_1 locally
2021-12-08 10:17:19,553 [Executor task launch worker for task 443] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_179_3 locally
2021-12-08 10:17:19,553 [Executor task launch worker for task 445] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_27_5 locally
2021-12-08 10:17:19,553 [Executor task launch worker for task 445] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_179_5 locally
2021-12-08 10:17:19,552 [Executor task launch worker for task 447] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_179_7 locally
2021-12-08 10:17:19,553 [Executor task launch worker for task 451] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_179_11 locally
2021-12-08 10:17:19,554 [Executor task launch worker for task 448] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_179_8 locally
2021-12-08 10:17:19,554 [Executor task launch worker for task 442] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_27_2 locally
2021-12-08 10:17:19,554 [Executor task launch worker for task 442] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_179_2 locally
2021-12-08 10:17:19,554 [Executor task launch worker for task 450] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_27_10 locally
2021-12-08 10:17:19,554 [Executor task launch worker for task 450] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_179_10 locally
2021-12-08 10:17:19,554 [Executor task launch worker for task 446] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_27_6 locally
2021-12-08 10:17:19,554 [Executor task launch worker for task 446] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_179_6 locally
2021-12-08 10:17:19,554 [Executor task launch worker for task 444] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_27_4 locally
2021-12-08 10:17:19,554 [Executor task launch worker for task 444] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_179_4 locally
2021-12-08 10:17:19,935 [Executor task launch worker for task 442] ERROR [org.apache.spark.executor.Executor] - Exception in task 2.0 in stage 225.0 (TID 442)
java.io.IOException: 磁盘空间不足。
	at sun.nio.ch.FileDispatcherImpl.write0(Native Method)
	at sun.nio.ch.FileDispatcherImpl.write(FileDispatcherImpl.java:75)
	at sun.nio.ch.IOUtil.writeFromNativeBuffer(IOUtil.java:93)
	at sun.nio.ch.IOUtil.write(IOUtil.java:51)
	at sun.nio.ch.FileChannelImpl.write(FileChannelImpl.java:211)
	at sun.nio.ch.FileChannelImpl.transferToTrustedChannel(FileChannelImpl.java:516)
	at sun.nio.ch.FileChannelImpl.transferTo(FileChannelImpl.java:612)
	at org.apache.spark.util.Utils$.copyFileStreamNIO(Utils.scala:373)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply$mcJ$sp(Utils.scala:338)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply(Utils.scala:332)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply(Utils.scala:332)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1377)
	at org.apache.spark.util.Utils$.copyStream(Utils.scala:353)
	at org.apache.spark.util.Utils.copyStream(Utils.scala)
	at org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.writePartitionedFile(BypassMergeSortShuffleWriter.java:201)
	at org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.write(BypassMergeSortShuffleWriter.java:163)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53)
	at org.apache.spark.scheduler.Task.run(Task.scala:109)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:345)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
2021-12-08 10:17:19,971 [Executor task launch worker for task 451] INFO [org.apache.spark.executor.Executor] - Finished task 11.0 in stage 225.0 (TID 451). 999 bytes result sent to driver
2021-12-08 10:17:19,967 [Executor task launch worker for task 450] INFO [org.apache.spark.executor.Executor] - Finished task 10.0 in stage 225.0 (TID 450). 1042 bytes result sent to driver
2021-12-08 10:17:19,964 [Executor task launch worker for task 446] INFO [org.apache.spark.executor.Executor] - Finished task 6.0 in stage 225.0 (TID 446). 1042 bytes result sent to driver
2021-12-08 10:17:19,963 [Executor task launch worker for task 444] INFO [org.apache.spark.executor.Executor] - Finished task 4.0 in stage 225.0 (TID 444). 1042 bytes result sent to driver
2021-12-08 10:17:19,978 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 10.0 in stage 225.0 (TID 450) in 430 ms on localhost (executor driver) (1/12)
2021-12-08 10:17:19,978 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 6.0 in stage 225.0 (TID 446) in 430 ms on localhost (executor driver) (2/12)
2021-12-08 10:17:19,978 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 11.0 in stage 225.0 (TID 451) in 430 ms on localhost (executor driver) (3/12)
2021-12-08 10:17:19,978 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 4.0 in stage 225.0 (TID 444) in 430 ms on localhost (executor driver) (4/12)
2021-12-08 10:17:19,980 [Executor task launch worker for task 445] INFO [org.apache.spark.executor.Executor] - Finished task 5.0 in stage 225.0 (TID 445). 999 bytes result sent to driver
2021-12-08 10:17:19,981 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 5.0 in stage 225.0 (TID 445) in 433 ms on localhost (executor driver) (5/12)
2021-12-08 10:17:19,982 [Executor task launch worker for task 449] INFO [org.apache.spark.executor.Executor] - Finished task 9.0 in stage 225.0 (TID 449). 999 bytes result sent to driver
2021-12-08 10:17:19,982 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 9.0 in stage 225.0 (TID 449) in 434 ms on localhost (executor driver) (6/12)
2021-12-08 10:17:19,997 [Executor task launch worker for task 448] INFO [org.apache.spark.executor.Executor] - Finished task 8.0 in stage 225.0 (TID 448). 999 bytes result sent to driver
2021-12-08 10:17:19,997 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 8.0 in stage 225.0 (TID 448) in 449 ms on localhost (executor driver) (7/12)
2021-12-08 10:17:19,998 [Executor task launch worker for task 443] INFO [org.apache.spark.executor.Executor] - Finished task 3.0 in stage 225.0 (TID 443). 999 bytes result sent to driver
2021-12-08 10:17:19,998 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 3.0 in stage 225.0 (TID 443) in 450 ms on localhost (executor driver) (8/12)
2021-12-08 10:17:20,004 [Executor task launch worker for task 447] INFO [org.apache.spark.executor.Executor] - Finished task 7.0 in stage 225.0 (TID 447). 999 bytes result sent to driver
2021-12-08 10:17:20,004 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 7.0 in stage 225.0 (TID 447) in 456 ms on localhost (executor driver) (9/12)
2021-12-08 10:17:20,008 [Executor task launch worker for task 440] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 225.0 (TID 440). 999 bytes result sent to driver
2021-12-08 10:17:20,008 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 225.0 (TID 440) in 460 ms on localhost (executor driver) (10/12)
2021-12-08 10:17:20,010 [Executor task launch worker for task 441] INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 225.0 (TID 441). 999 bytes result sent to driver
2021-12-08 10:17:20,010 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 225.0 (TID 441) in 462 ms on localhost (executor driver) (11/12)
2021-12-08 10:17:20,239 [task-result-getter-2] WARN [org.apache.spark.scheduler.TaskSetManager] - Lost task 2.0 in stage 225.0 (TID 442, localhost, executor driver): java.io.IOException: 磁盘空间不足。
	at sun.nio.ch.FileDispatcherImpl.write0(Native Method)
	at sun.nio.ch.FileDispatcherImpl.write(FileDispatcherImpl.java:75)
	at sun.nio.ch.IOUtil.writeFromNativeBuffer(IOUtil.java:93)
	at sun.nio.ch.IOUtil.write(IOUtil.java:51)
	at sun.nio.ch.FileChannelImpl.write(FileChannelImpl.java:211)
	at sun.nio.ch.FileChannelImpl.transferToTrustedChannel(FileChannelImpl.java:516)
	at sun.nio.ch.FileChannelImpl.transferTo(FileChannelImpl.java:612)
	at org.apache.spark.util.Utils$.copyFileStreamNIO(Utils.scala:373)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply$mcJ$sp(Utils.scala:338)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply(Utils.scala:332)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply(Utils.scala:332)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1377)
	at org.apache.spark.util.Utils$.copyStream(Utils.scala:353)
	at org.apache.spark.util.Utils.copyStream(Utils.scala)
	at org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.writePartitionedFile(BypassMergeSortShuffleWriter.java:201)
	at org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.write(BypassMergeSortShuffleWriter.java:163)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53)
	at org.apache.spark.scheduler.Task.run(Task.scala:109)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:345)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)

2021-12-08 10:17:20,279 [task-result-getter-2] ERROR [org.apache.spark.scheduler.TaskSetManager] - Task 2 in stage 225.0 failed 1 times; aborting job
2021-12-08 10:17:20,288 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 225.0, whose tasks have all completed, from pool 
2021-12-08 10:17:20,294 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Cancelling stage 225
2021-12-08 10:17:20,296 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ShuffleMapStage 225 (flatMap at ALS.scala:1653) failed in 0.795 s due to Job aborted due to stage failure: Task 2 in stage 225.0 failed 1 times, most recent failure: Lost task 2.0 in stage 225.0 (TID 442, localhost, executor driver): java.io.IOException: 磁盘空间不足。
	at sun.nio.ch.FileDispatcherImpl.write0(Native Method)
	at sun.nio.ch.FileDispatcherImpl.write(FileDispatcherImpl.java:75)
	at sun.nio.ch.IOUtil.writeFromNativeBuffer(IOUtil.java:93)
	at sun.nio.ch.IOUtil.write(IOUtil.java:51)
	at sun.nio.ch.FileChannelImpl.write(FileChannelImpl.java:211)
	at sun.nio.ch.FileChannelImpl.transferToTrustedChannel(FileChannelImpl.java:516)
	at sun.nio.ch.FileChannelImpl.transferTo(FileChannelImpl.java:612)
	at org.apache.spark.util.Utils$.copyFileStreamNIO(Utils.scala:373)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply$mcJ$sp(Utils.scala:338)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply(Utils.scala:332)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply(Utils.scala:332)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1377)
	at org.apache.spark.util.Utils$.copyStream(Utils.scala:353)
	at org.apache.spark.util.Utils.copyStream(Utils.scala)
	at org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.writePartitionedFile(BypassMergeSortShuffleWriter.java:201)
	at org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.write(BypassMergeSortShuffleWriter.java:163)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53)
	at org.apache.spark.scheduler.Task.run(Task.scala:109)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:345)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)

Driver stacktrace:
2021-12-08 10:17:20,298 [main] INFO [org.apache.spark.scheduler.DAGScheduler] - Job 20 failed: aggregate at ALS.scala:1711, took 0.799771 s
2021-12-08 10:17:20,302 [Thread-1] INFO [org.apache.spark.SparkContext] - Invoking stop() from shutdown hook
2021-12-08 10:17:20,309 [Thread-1] INFO [org.spark_project.jetty.server.AbstractConnector] - Stopped Spark@5f7f2382{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2021-12-08 10:17:20,311 [Thread-1] INFO [org.apache.spark.ui.SparkUI] - Stopped Spark web UI at http://qb:4040
2021-12-08 10:17:20,323 [dispatcher-event-loop-9] INFO [org.apache.spark.MapOutputTrackerMasterEndpoint] - MapOutputTrackerMasterEndpoint stopped!
2021-12-08 10:17:20,758 [Thread-1] INFO [org.apache.spark.storage.memory.MemoryStore] - MemoryStore cleared
2021-12-08 10:17:20,759 [Thread-1] INFO [org.apache.spark.storage.BlockManager] - BlockManager stopped
2021-12-08 10:17:20,759 [Thread-1] INFO [org.apache.spark.storage.BlockManagerMaster] - BlockManagerMaster stopped
2021-12-08 10:17:20,762 [dispatcher-event-loop-1] INFO [org.apache.spark.scheduler.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint] - OutputCommitCoordinator stopped!
2021-12-08 10:17:20,765 [Thread-1] INFO [org.apache.spark.SparkContext] - Successfully stopped SparkContext
2021-12-08 10:17:20,765 [Thread-1] INFO [org.apache.spark.util.ShutdownHookManager] - Shutdown hook called
2021-12-08 10:17:20,766 [Thread-1] INFO [org.apache.spark.util.ShutdownHookManager] - Deleting directory C:\Users\ACER\AppData\Local\Temp\spark-5d3b597b-06ae-4e7c-bd5c-8fcac7f7e224
2021-12-08 10:35:02,231 [main] INFO [org.apache.spark.SparkContext] - Running Spark version 2.3.0
2021-12-08 10:35:02,516 [main] INFO [org.apache.spark.SparkContext] - Submitted application: PaidPromotionAdjustParameter
2021-12-08 10:35:02,579 [main] INFO [org.apache.spark.SecurityManager] - Changing view acls to: ACER,root
2021-12-08 10:35:02,579 [main] INFO [org.apache.spark.SecurityManager] - Changing modify acls to: ACER,root
2021-12-08 10:35:02,580 [main] INFO [org.apache.spark.SecurityManager] - Changing view acls groups to: 
2021-12-08 10:35:02,580 [main] INFO [org.apache.spark.SecurityManager] - Changing modify acls groups to: 
2021-12-08 10:35:02,581 [main] INFO [org.apache.spark.SecurityManager] - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(ACER, root); groups with view permissions: Set(); users  with modify permissions: Set(ACER, root); groups with modify permissions: Set()
2021-12-08 10:35:03,181 [main] INFO [org.apache.spark.util.Utils] - Successfully started service 'sparkDriver' on port 55611.
2021-12-08 10:35:03,202 [main] INFO [org.apache.spark.SparkEnv] - Registering MapOutputTracker
2021-12-08 10:35:03,225 [main] INFO [org.apache.spark.SparkEnv] - Registering BlockManagerMaster
2021-12-08 10:35:03,229 [main] INFO [org.apache.spark.storage.BlockManagerMasterEndpoint] - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2021-12-08 10:35:03,229 [main] INFO [org.apache.spark.storage.BlockManagerMasterEndpoint] - BlockManagerMasterEndpoint up
2021-12-08 10:35:03,241 [main] INFO [org.apache.spark.storage.DiskBlockManager] - Created local directory at C:\Users\ACER\AppData\Local\Temp\blockmgr-dfed5075-df19-4290-95ed-bfc4d93c7407
2021-12-08 10:35:03,262 [main] INFO [org.apache.spark.storage.memory.MemoryStore] - MemoryStore started with capacity 1990.8 MB
2021-12-08 10:35:03,274 [main] INFO [org.apache.spark.SparkEnv] - Registering OutputCommitCoordinator
2021-12-08 10:35:03,343 [main] INFO [org.spark_project.jetty.util.log] - Logging initialized @1969ms
2021-12-08 10:35:03,402 [main] INFO [org.spark_project.jetty.server.Server] - jetty-9.3.z-SNAPSHOT
2021-12-08 10:35:03,416 [main] INFO [org.spark_project.jetty.server.Server] - Started @2044ms
2021-12-08 10:35:03,446 [main] INFO [org.spark_project.jetty.server.AbstractConnector] - Started ServerConnector@5b800468{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2021-12-08 10:35:03,446 [main] INFO [org.apache.spark.util.Utils] - Successfully started service 'SparkUI' on port 4040.
2021-12-08 10:35:03,468 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@1568159{/jobs,null,AVAILABLE,@Spark}
2021-12-08 10:35:03,469 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@63cd604c{/jobs/json,null,AVAILABLE,@Spark}
2021-12-08 10:35:03,470 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@3954d008{/jobs/job,null,AVAILABLE,@Spark}
2021-12-08 10:35:03,471 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@6d8792db{/jobs/job/json,null,AVAILABLE,@Spark}
2021-12-08 10:35:03,472 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@3a1d593e{/stages,null,AVAILABLE,@Spark}
2021-12-08 10:35:03,473 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@285d851a{/stages/json,null,AVAILABLE,@Spark}
2021-12-08 10:35:03,474 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@7876d598{/stages/stage,null,AVAILABLE,@Spark}
2021-12-08 10:35:03,476 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@4985cbcb{/stages/stage/json,null,AVAILABLE,@Spark}
2021-12-08 10:35:03,477 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@54361a9{/stages/pool,null,AVAILABLE,@Spark}
2021-12-08 10:35:03,478 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@293bb8a5{/stages/pool/json,null,AVAILABLE,@Spark}
2021-12-08 10:35:03,479 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@290b1b2e{/storage,null,AVAILABLE,@Spark}
2021-12-08 10:35:03,480 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@5db4c359{/storage/json,null,AVAILABLE,@Spark}
2021-12-08 10:35:03,481 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@6fefce9e{/storage/rdd,null,AVAILABLE,@Spark}
2021-12-08 10:35:03,482 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@8a589a2{/storage/rdd/json,null,AVAILABLE,@Spark}
2021-12-08 10:35:03,483 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@5cc69cfe{/environment,null,AVAILABLE,@Spark}
2021-12-08 10:35:03,485 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@11dee337{/environment/json,null,AVAILABLE,@Spark}
2021-12-08 10:35:03,486 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@74bdc168{/executors,null,AVAILABLE,@Spark}
2021-12-08 10:35:03,487 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@7bb3a9fe{/executors/json,null,AVAILABLE,@Spark}
2021-12-08 10:35:03,489 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@f19c9d2{/executors/threadDump,null,AVAILABLE,@Spark}
2021-12-08 10:35:03,490 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@a77614d{/executors/threadDump/json,null,AVAILABLE,@Spark}
2021-12-08 10:35:03,496 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@523424b5{/static,null,AVAILABLE,@Spark}
2021-12-08 10:35:03,497 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@12cd9150{/,null,AVAILABLE,@Spark}
2021-12-08 10:35:03,499 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@32fe9d0a{/api,null,AVAILABLE,@Spark}
2021-12-08 10:35:03,500 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@59fc684e{/jobs/job/kill,null,AVAILABLE,@Spark}
2021-12-08 10:35:03,501 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@355e34c7{/stages/stage/kill,null,AVAILABLE,@Spark}
2021-12-08 10:35:03,503 [main] INFO [org.apache.spark.ui.SparkUI] - Bound SparkUI to 0.0.0.0, and started at http://qb:4040
2021-12-08 10:35:03,586 [main] INFO [org.apache.spark.executor.Executor] - Starting executor ID driver on host localhost
2021-12-08 10:35:03,638 [main] INFO [org.apache.spark.util.Utils] - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 55657.
2021-12-08 10:35:03,639 [main] INFO [org.apache.spark.network.netty.NettyBlockTransferService] - Server created on qb:55657
2021-12-08 10:35:03,640 [main] INFO [org.apache.spark.storage.BlockManager] - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2021-12-08 10:35:03,642 [main] INFO [org.apache.spark.storage.BlockManagerMaster] - Registering BlockManager BlockManagerId(driver, qb, 55657, None)
2021-12-08 10:35:03,644 [dispatcher-event-loop-11] INFO [org.apache.spark.storage.BlockManagerMasterEndpoint] - Registering block manager qb:55657 with 1990.8 MB RAM, BlockManagerId(driver, qb, 55657, None)
2021-12-08 10:35:03,647 [main] INFO [org.apache.spark.storage.BlockManagerMaster] - Registered BlockManager BlockManagerId(driver, qb, 55657, None)
2021-12-08 10:35:03,647 [main] INFO [org.apache.spark.storage.BlockManager] - Initialized BlockManager: BlockManagerId(driver, qb, 55657, None)
2021-12-08 10:35:03,792 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@6fe46b62{/metrics/json,null,AVAILABLE,@Spark}
2021-12-08 10:35:04,342 [main] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_0 stored as values in memory (estimated size 312.7 KB, free 1990.5 MB)
2021-12-08 10:35:04,641 [main] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_0_piece0 stored as bytes in memory (estimated size 27.3 KB, free 1990.5 MB)
2021-12-08 10:35:04,643 [dispatcher-event-loop-0] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_0_piece0 in memory on qb:55657 (size: 27.3 KB, free: 1990.8 MB)
2021-12-08 10:35:04,648 [main] INFO [org.apache.spark.SparkContext] - Created broadcast 0 from textFile at PaidPromotionAdjustParameter.scala:320
2021-12-08 10:35:05,063 [main] WARN [org.apache.hadoop.hdfs.shortcircuit.DomainSocketFactory] - The short-circuit local reads feature cannot be used because UNIX Domain sockets are not available on Windows.
2021-12-08 10:35:05,175 [main] INFO [org.apache.hadoop.mapred.FileInputFormat] - Total input paths to process : 10
2021-12-08 10:35:05,209 [main] INFO [org.apache.spark.SparkContext] - Starting job: isEmpty at ALS.scala:240
2021-12-08 10:35:05,221 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 0 (isEmpty at ALS.scala:240) with 1 output partitions
2021-12-08 10:35:05,221 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 0 (isEmpty at ALS.scala:240)
2021-12-08 10:35:05,221 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List()
2021-12-08 10:35:05,222 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2021-12-08 10:35:05,227 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 0 (MapPartitionsRDD[2] at map at PaidPromotionAdjustParameter.scala:321), which has no missing parents
2021-12-08 10:35:05,246 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_1 stored as values in memory (estimated size 3.5 KB, free 1990.5 MB)
2021-12-08 10:35:05,252 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_1_piece0 stored as bytes in memory (estimated size 2.1 KB, free 1990.5 MB)
2021-12-08 10:35:05,252 [dispatcher-event-loop-1] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_1_piece0 in memory on qb:55657 (size: 2.1 KB, free: 1990.8 MB)
2021-12-08 10:35:05,253 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 1 from broadcast at DAGScheduler.scala:1039
2021-12-08 10:35:05,261 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[2] at map at PaidPromotionAdjustParameter.scala:321) (first 15 tasks are for partitions Vector(0))
2021-12-08 10:35:05,262 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 0.0 with 1 tasks
2021-12-08 10:35:05,301 [dispatcher-event-loop-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 0.0 (TID 0, localhost, executor driver, partition 0, ANY, 7906 bytes)
2021-12-08 10:35:05,309 [Executor task launch worker for task 0] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 0.0 (TID 0)
2021-12-08 10:35:05,348 [Executor task launch worker for task 0] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/model/input/rating/part-00000:0+132087
2021-12-08 10:35:05,518 [Executor task launch worker for task 0] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 0.0 (TID 0). 817 bytes result sent to driver
2021-12-08 10:35:05,533 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 0.0 (TID 0) in 241 ms on localhost (executor driver) (1/1)
2021-12-08 10:35:05,535 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 0.0, whose tasks have all completed, from pool 
2021-12-08 10:35:05,539 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 0 (isEmpty at ALS.scala:240) finished in 0.293 s
2021-12-08 10:35:05,543 [main] INFO [org.apache.spark.scheduler.DAGScheduler] - Job 0 finished: isEmpty at ALS.scala:240, took 0.334203 s
2021-12-08 10:35:05,559 [main] INFO [org.apache.spark.SparkContext] - Starting job: isEmpty at ALS.scala:918
2021-12-08 10:35:05,560 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 1 (isEmpty at ALS.scala:918) with 1 output partitions
2021-12-08 10:35:05,560 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 1 (isEmpty at ALS.scala:918)
2021-12-08 10:35:05,560 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List()
2021-12-08 10:35:05,560 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2021-12-08 10:35:05,560 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 1 (MapPartitionsRDD[3] at map at ALS.scala:256), which has no missing parents
2021-12-08 10:35:05,562 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_2 stored as values in memory (estimated size 3.7 KB, free 1990.5 MB)
2021-12-08 10:35:05,565 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_2_piece0 stored as bytes in memory (estimated size 2.2 KB, free 1990.5 MB)
2021-12-08 10:35:05,566 [dispatcher-event-loop-5] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_2_piece0 in memory on qb:55657 (size: 2.2 KB, free: 1990.8 MB)
2021-12-08 10:35:05,566 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 2 from broadcast at DAGScheduler.scala:1039
2021-12-08 10:35:05,567 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[3] at map at ALS.scala:256) (first 15 tasks are for partitions Vector(0))
2021-12-08 10:35:05,567 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 1.0 with 1 tasks
2021-12-08 10:35:05,567 [dispatcher-event-loop-8] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 1.0 (TID 1, localhost, executor driver, partition 0, ANY, 7906 bytes)
2021-12-08 10:35:05,568 [Executor task launch worker for task 1] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 1.0 (TID 1)
2021-12-08 10:35:05,571 [Executor task launch worker for task 1] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/model/input/rating/part-00000:0+132087
2021-12-08 10:35:05,686 [Executor task launch worker for task 1] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 1.0 (TID 1). 867 bytes result sent to driver
2021-12-08 10:35:05,690 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 1.0 (TID 1) in 123 ms on localhost (executor driver) (1/1)
2021-12-08 10:35:05,690 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 1.0, whose tasks have all completed, from pool 
2021-12-08 10:35:05,690 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 1 (isEmpty at ALS.scala:918) finished in 0.129 s
2021-12-08 10:35:05,690 [main] INFO [org.apache.spark.scheduler.DAGScheduler] - Job 1 finished: isEmpty at ALS.scala:918, took 0.131755 s
2021-12-08 10:35:05,764 [main] INFO [org.apache.spark.SparkContext] - Starting job: count at ALS.scala:931
2021-12-08 10:35:05,769 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 4 (mapPartitions at ALS.scala:1321)
2021-12-08 10:35:05,770 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 7 (map at ALS.scala:1564)
2021-12-08 10:35:05,770 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 2 (count at ALS.scala:931) with 12 output partitions
2021-12-08 10:35:05,770 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 4 (count at ALS.scala:931)
2021-12-08 10:35:05,770 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 3)
2021-12-08 10:35:05,775 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List(ShuffleMapStage 3)
2021-12-08 10:35:05,776 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ShuffleMapStage 2 (MapPartitionsRDD[4] at mapPartitions at ALS.scala:1321), which has no missing parents
2021-12-08 10:35:05,783 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_3 stored as values in memory (estimated size 6.3 KB, free 1990.5 MB)
2021-12-08 10:35:05,788 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_3_piece0 stored as bytes in memory (estimated size 3.5 KB, free 1990.4 MB)
2021-12-08 10:35:05,789 [dispatcher-event-loop-0] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_3_piece0 in memory on qb:55657 (size: 3.5 KB, free: 1990.8 MB)
2021-12-08 10:35:05,789 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 3 from broadcast at DAGScheduler.scala:1039
2021-12-08 10:35:05,791 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 10 missing tasks from ShuffleMapStage 2 (MapPartitionsRDD[4] at mapPartitions at ALS.scala:1321) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
2021-12-08 10:35:05,791 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 2.0 with 10 tasks
2021-12-08 10:35:05,792 [dispatcher-event-loop-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 2.0 (TID 2, localhost, executor driver, partition 0, ANY, 7895 bytes)
2021-12-08 10:35:05,792 [dispatcher-event-loop-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 2.0 (TID 3, localhost, executor driver, partition 1, ANY, 7895 bytes)
2021-12-08 10:35:05,792 [dispatcher-event-loop-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 2.0 in stage 2.0 (TID 4, localhost, executor driver, partition 2, ANY, 7895 bytes)
2021-12-08 10:35:05,792 [dispatcher-event-loop-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 3.0 in stage 2.0 (TID 5, localhost, executor driver, partition 3, ANY, 7895 bytes)
2021-12-08 10:35:05,793 [dispatcher-event-loop-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 4.0 in stage 2.0 (TID 6, localhost, executor driver, partition 4, ANY, 7895 bytes)
2021-12-08 10:35:05,793 [dispatcher-event-loop-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 5.0 in stage 2.0 (TID 7, localhost, executor driver, partition 5, ANY, 7895 bytes)
2021-12-08 10:35:05,793 [dispatcher-event-loop-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 6.0 in stage 2.0 (TID 8, localhost, executor driver, partition 6, ANY, 7895 bytes)
2021-12-08 10:35:05,793 [dispatcher-event-loop-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 7.0 in stage 2.0 (TID 9, localhost, executor driver, partition 7, ANY, 7895 bytes)
2021-12-08 10:35:05,793 [dispatcher-event-loop-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 8.0 in stage 2.0 (TID 10, localhost, executor driver, partition 8, ANY, 7895 bytes)
2021-12-08 10:35:05,794 [dispatcher-event-loop-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 9.0 in stage 2.0 (TID 11, localhost, executor driver, partition 9, ANY, 7895 bytes)
2021-12-08 10:35:05,794 [Executor task launch worker for task 2] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 2.0 (TID 2)
2021-12-08 10:35:05,794 [Executor task launch worker for task 3] INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 2.0 (TID 3)
2021-12-08 10:35:05,794 [Executor task launch worker for task 4] INFO [org.apache.spark.executor.Executor] - Running task 2.0 in stage 2.0 (TID 4)
2021-12-08 10:35:05,794 [Executor task launch worker for task 5] INFO [org.apache.spark.executor.Executor] - Running task 3.0 in stage 2.0 (TID 5)
2021-12-08 10:35:05,794 [Executor task launch worker for task 6] INFO [org.apache.spark.executor.Executor] - Running task 4.0 in stage 2.0 (TID 6)
2021-12-08 10:35:05,794 [Executor task launch worker for task 7] INFO [org.apache.spark.executor.Executor] - Running task 5.0 in stage 2.0 (TID 7)
2021-12-08 10:35:05,794 [Executor task launch worker for task 8] INFO [org.apache.spark.executor.Executor] - Running task 6.0 in stage 2.0 (TID 8)
2021-12-08 10:35:05,794 [Executor task launch worker for task 9] INFO [org.apache.spark.executor.Executor] - Running task 7.0 in stage 2.0 (TID 9)
2021-12-08 10:35:05,794 [Executor task launch worker for task 10] INFO [org.apache.spark.executor.Executor] - Running task 8.0 in stage 2.0 (TID 10)
2021-12-08 10:35:05,795 [Executor task launch worker for task 11] INFO [org.apache.spark.executor.Executor] - Running task 9.0 in stage 2.0 (TID 11)
2021-12-08 10:35:05,801 [Executor task launch worker for task 2] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/model/input/rating/part-00000:0+132087
2021-12-08 10:35:05,801 [Executor task launch worker for task 7] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/model/input/rating/part-00005:0+14679212
2021-12-08 10:35:05,802 [Executor task launch worker for task 10] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/model/input/rating/part-00008:0+7396167
2021-12-08 10:35:05,802 [Executor task launch worker for task 9] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/model/input/rating/part-00007:0+13862185
2021-12-08 10:35:05,802 [Executor task launch worker for task 4] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/model/input/rating/part-00002:0+6206649
2021-12-08 10:35:05,802 [Executor task launch worker for task 8] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/model/input/rating/part-00006:0+6530115
2021-12-08 10:35:05,802 [Executor task launch worker for task 11] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/model/input/rating/part-00009:0+12581480
2021-12-08 10:35:05,802 [Executor task launch worker for task 6] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/model/input/rating/part-00004:0+6736990
2021-12-08 10:35:05,802 [Executor task launch worker for task 3] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/model/input/rating/part-00001:0+864992
2021-12-08 10:35:05,804 [Executor task launch worker for task 5] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/model/input/rating/part-00003:0+13046026
2021-12-08 10:35:05,816 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 12
2021-12-08 10:35:05,816 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 45
2021-12-08 10:35:05,831 [dispatcher-event-loop-3] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_2_piece0 on qb:55657 in memory (size: 2.2 KB, free: 1990.8 MB)
2021-12-08 10:35:05,833 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 18
2021-12-08 10:35:05,833 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 25
2021-12-08 10:35:05,833 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 29
2021-12-08 10:35:05,833 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 17
2021-12-08 10:35:05,833 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 27
2021-12-08 10:35:05,833 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 33
2021-12-08 10:35:05,833 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 35
2021-12-08 10:35:05,833 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 46
2021-12-08 10:35:05,833 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 14
2021-12-08 10:35:05,833 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 23
2021-12-08 10:35:05,833 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 19
2021-12-08 10:35:05,833 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 39
2021-12-08 10:35:05,833 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 44
2021-12-08 10:35:05,833 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 8
2021-12-08 10:35:05,833 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 15
2021-12-08 10:35:05,833 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 37
2021-12-08 10:35:05,834 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 42
2021-12-08 10:35:05,834 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 3
2021-12-08 10:35:05,834 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 22
2021-12-08 10:35:05,835 [dispatcher-event-loop-8] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_1_piece0 on qb:55657 in memory (size: 2.1 KB, free: 1990.8 MB)
2021-12-08 10:35:05,836 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 6
2021-12-08 10:35:05,837 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 26
2021-12-08 10:35:05,837 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 28
2021-12-08 10:35:05,837 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 49
2021-12-08 10:35:05,837 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 2
2021-12-08 10:35:05,837 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 5
2021-12-08 10:35:05,837 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 32
2021-12-08 10:35:05,837 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 47
2021-12-08 10:35:05,837 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 30
2021-12-08 10:35:05,837 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 24
2021-12-08 10:35:05,837 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 48
2021-12-08 10:35:05,837 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 38
2021-12-08 10:35:05,837 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1
2021-12-08 10:35:05,837 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 20
2021-12-08 10:35:05,838 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 13
2021-12-08 10:35:05,838 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 16
2021-12-08 10:35:05,838 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 36
2021-12-08 10:35:05,838 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 40
2021-12-08 10:35:05,838 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 31
2021-12-08 10:35:05,838 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 0
2021-12-08 10:35:05,838 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 4
2021-12-08 10:35:05,838 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 34
2021-12-08 10:35:05,838 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 7
2021-12-08 10:35:05,838 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 41
2021-12-08 10:35:05,838 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 11
2021-12-08 10:35:05,838 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 9
2021-12-08 10:35:05,838 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 43
2021-12-08 10:35:05,838 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 21
2021-12-08 10:35:05,838 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 10
2021-12-08 10:35:06,208 [Executor task launch worker for task 2] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 2.0 (TID 2). 911 bytes result sent to driver
2021-12-08 10:35:06,225 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 2.0 (TID 2) in 434 ms on localhost (executor driver) (1/10)
2021-12-08 10:35:07,130 [Executor task launch worker for task 3] INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 2.0 (TID 3). 911 bytes result sent to driver
2021-12-08 10:35:07,133 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 2.0 (TID 3) in 1340 ms on localhost (executor driver) (2/10)
2021-12-08 10:35:09,332 [Executor task launch worker for task 8] INFO [org.apache.spark.executor.Executor] - Finished task 6.0 in stage 2.0 (TID 8). 911 bytes result sent to driver
2021-12-08 10:35:09,333 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 6.0 in stage 2.0 (TID 8) in 3540 ms on localhost (executor driver) (3/10)
2021-12-08 10:35:09,372 [Executor task launch worker for task 6] INFO [org.apache.spark.executor.Executor] - Finished task 4.0 in stage 2.0 (TID 6). 911 bytes result sent to driver
2021-12-08 10:35:09,373 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 4.0 in stage 2.0 (TID 6) in 3580 ms on localhost (executor driver) (4/10)
2021-12-08 10:35:11,280 [Executor task launch worker for task 11] INFO [org.apache.spark.executor.Executor] - Finished task 9.0 in stage 2.0 (TID 11). 911 bytes result sent to driver
2021-12-08 10:35:11,280 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 9.0 in stage 2.0 (TID 11) in 5487 ms on localhost (executor driver) (5/10)
2021-12-08 10:35:11,947 [Executor task launch worker for task 4] INFO [org.apache.spark.executor.Executor] - Finished task 2.0 in stage 2.0 (TID 4). 911 bytes result sent to driver
2021-12-08 10:35:11,948 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 2.0 in stage 2.0 (TID 4) in 6156 ms on localhost (executor driver) (6/10)
2021-12-08 10:35:12,016 [Executor task launch worker for task 7] INFO [org.apache.spark.executor.Executor] - Finished task 5.0 in stage 2.0 (TID 7). 911 bytes result sent to driver
2021-12-08 10:35:12,017 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 5.0 in stage 2.0 (TID 7) in 6224 ms on localhost (executor driver) (7/10)
2021-12-08 10:35:14,231 [Executor task launch worker for task 10] INFO [org.apache.spark.executor.Executor] - Finished task 8.0 in stage 2.0 (TID 10). 911 bytes result sent to driver
2021-12-08 10:35:14,231 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 8.0 in stage 2.0 (TID 10) in 8438 ms on localhost (executor driver) (8/10)
2021-12-08 10:35:14,552 [Executor task launch worker for task 9] INFO [org.apache.spark.executor.Executor] - Finished task 7.0 in stage 2.0 (TID 9). 911 bytes result sent to driver
2021-12-08 10:35:14,553 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 7.0 in stage 2.0 (TID 9) in 8760 ms on localhost (executor driver) (9/10)
2021-12-08 10:35:14,915 [Executor task launch worker for task 5] INFO [org.apache.spark.executor.Executor] - Finished task 3.0 in stage 2.0 (TID 5). 954 bytes result sent to driver
2021-12-08 10:35:14,916 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 3.0 in stage 2.0 (TID 5) in 9124 ms on localhost (executor driver) (10/10)
2021-12-08 10:35:14,916 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 2.0, whose tasks have all completed, from pool 
2021-12-08 10:35:14,916 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ShuffleMapStage 2 (mapPartitions at ALS.scala:1321) finished in 9.137 s
2021-12-08 10:35:14,917 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - looking for newly runnable stages
2021-12-08 10:35:14,917 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - running: Set()
2021-12-08 10:35:14,917 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - waiting: Set(ShuffleMapStage 3, ResultStage 4)
2021-12-08 10:35:14,918 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - failed: Set()
2021-12-08 10:35:14,920 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ShuffleMapStage 3 (MapPartitionsRDD[7] at map at ALS.scala:1564), which has no missing parents
2021-12-08 10:35:14,923 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_4 stored as values in memory (estimated size 7.6 KB, free 1990.5 MB)
2021-12-08 10:35:14,925 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_4_piece0 stored as bytes in memory (estimated size 4.0 KB, free 1990.4 MB)
2021-12-08 10:35:14,926 [dispatcher-event-loop-8] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_4_piece0 in memory on qb:55657 (size: 4.0 KB, free: 1990.8 MB)
2021-12-08 10:35:14,927 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 4 from broadcast at DAGScheduler.scala:1039
2021-12-08 10:35:14,927 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 10 missing tasks from ShuffleMapStage 3 (MapPartitionsRDD[7] at map at ALS.scala:1564) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
2021-12-08 10:35:14,927 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 3.0 with 10 tasks
2021-12-08 10:35:14,928 [dispatcher-event-loop-7] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 3.0 (TID 12, localhost, executor driver, partition 0, ANY, 7638 bytes)
2021-12-08 10:35:14,928 [dispatcher-event-loop-7] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 3.0 (TID 13, localhost, executor driver, partition 1, ANY, 7638 bytes)
2021-12-08 10:35:14,928 [dispatcher-event-loop-7] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 2.0 in stage 3.0 (TID 14, localhost, executor driver, partition 2, ANY, 7638 bytes)
2021-12-08 10:35:14,928 [dispatcher-event-loop-7] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 3.0 in stage 3.0 (TID 15, localhost, executor driver, partition 3, ANY, 7638 bytes)
2021-12-08 10:35:14,929 [dispatcher-event-loop-7] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 4.0 in stage 3.0 (TID 16, localhost, executor driver, partition 4, ANY, 7638 bytes)
2021-12-08 10:35:14,929 [dispatcher-event-loop-7] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 5.0 in stage 3.0 (TID 17, localhost, executor driver, partition 5, ANY, 7638 bytes)
2021-12-08 10:35:14,929 [dispatcher-event-loop-7] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 6.0 in stage 3.0 (TID 18, localhost, executor driver, partition 6, ANY, 7638 bytes)
2021-12-08 10:35:14,929 [dispatcher-event-loop-7] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 7.0 in stage 3.0 (TID 19, localhost, executor driver, partition 7, ANY, 7638 bytes)
2021-12-08 10:35:14,929 [dispatcher-event-loop-7] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 8.0 in stage 3.0 (TID 20, localhost, executor driver, partition 8, ANY, 7638 bytes)
2021-12-08 10:35:14,929 [dispatcher-event-loop-7] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 9.0 in stage 3.0 (TID 21, localhost, executor driver, partition 9, ANY, 7638 bytes)
2021-12-08 10:35:14,929 [Executor task launch worker for task 14] INFO [org.apache.spark.executor.Executor] - Running task 2.0 in stage 3.0 (TID 14)
2021-12-08 10:35:14,929 [Executor task launch worker for task 17] INFO [org.apache.spark.executor.Executor] - Running task 5.0 in stage 3.0 (TID 17)
2021-12-08 10:35:14,929 [Executor task launch worker for task 19] INFO [org.apache.spark.executor.Executor] - Running task 7.0 in stage 3.0 (TID 19)
2021-12-08 10:35:14,929 [Executor task launch worker for task 21] INFO [org.apache.spark.executor.Executor] - Running task 9.0 in stage 3.0 (TID 21)
2021-12-08 10:35:14,929 [Executor task launch worker for task 20] INFO [org.apache.spark.executor.Executor] - Running task 8.0 in stage 3.0 (TID 20)
2021-12-08 10:35:14,929 [Executor task launch worker for task 18] INFO [org.apache.spark.executor.Executor] - Running task 6.0 in stage 3.0 (TID 18)
2021-12-08 10:35:14,929 [Executor task launch worker for task 15] INFO [org.apache.spark.executor.Executor] - Running task 3.0 in stage 3.0 (TID 15)
2021-12-08 10:35:14,929 [Executor task launch worker for task 16] INFO [org.apache.spark.executor.Executor] - Running task 4.0 in stage 3.0 (TID 16)
2021-12-08 10:35:14,929 [Executor task launch worker for task 13] INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 3.0 (TID 13)
2021-12-08 10:35:14,929 [Executor task launch worker for task 12] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 3.0 (TID 12)
2021-12-08 10:35:14,952 [Executor task launch worker for task 18] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 10 non-empty blocks out of 10 blocks
2021-12-08 10:35:14,952 [Executor task launch worker for task 12] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 10 non-empty blocks out of 10 blocks
2021-12-08 10:35:14,952 [Executor task launch worker for task 17] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 10 non-empty blocks out of 10 blocks
2021-12-08 10:35:14,952 [Executor task launch worker for task 19] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 10 non-empty blocks out of 10 blocks
2021-12-08 10:35:14,952 [Executor task launch worker for task 16] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 10 non-empty blocks out of 10 blocks
2021-12-08 10:35:14,952 [Executor task launch worker for task 20] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 10 non-empty blocks out of 10 blocks
2021-12-08 10:35:14,952 [Executor task launch worker for task 13] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 10 non-empty blocks out of 10 blocks
2021-12-08 10:35:14,952 [Executor task launch worker for task 15] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 10 non-empty blocks out of 10 blocks
2021-12-08 10:35:14,952 [Executor task launch worker for task 14] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 10 non-empty blocks out of 10 blocks
2021-12-08 10:35:14,952 [Executor task launch worker for task 21] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 10 non-empty blocks out of 10 blocks
2021-12-08 10:35:14,954 [Executor task launch worker for task 15] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 5 ms
2021-12-08 10:35:14,954 [Executor task launch worker for task 12] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 5 ms
2021-12-08 10:35:14,954 [Executor task launch worker for task 16] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 5 ms
2021-12-08 10:35:14,954 [Executor task launch worker for task 20] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 5 ms
2021-12-08 10:35:14,954 [Executor task launch worker for task 13] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 5 ms
2021-12-08 10:35:14,954 [Executor task launch worker for task 17] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 5 ms
2021-12-08 10:35:14,954 [Executor task launch worker for task 21] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 5 ms
2021-12-08 10:35:14,954 [Executor task launch worker for task 19] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 5 ms
2021-12-08 10:35:14,954 [Executor task launch worker for task 14] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 5 ms
2021-12-08 10:35:14,954 [Executor task launch worker for task 18] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 5 ms
2021-12-08 10:35:15,277 [Executor task launch worker for task 16] INFO [org.apache.spark.storage.memory.MemoryStore] - Block rdd_6_4 stored as values in memory (estimated size 5.5 MB, free 1939.2 MB)
2021-12-08 10:35:15,278 [dispatcher-event-loop-5] INFO [org.apache.spark.storage.BlockManagerInfo] - Added rdd_6_4 in memory on qb:55657 (size: 5.5 MB, free: 1985.3 MB)
2021-12-08 10:35:15,292 [Executor task launch worker for task 19] INFO [org.apache.spark.storage.memory.MemoryStore] - Block rdd_6_7 stored as values in memory (estimated size 5.5 MB, free 1939.9 MB)
2021-12-08 10:35:15,293 [dispatcher-event-loop-4] INFO [org.apache.spark.storage.BlockManagerInfo] - Added rdd_6_7 in memory on qb:55657 (size: 5.5 MB, free: 1979.7 MB)
2021-12-08 10:35:15,296 [Executor task launch worker for task 13] INFO [org.apache.spark.storage.memory.MemoryStore] - Block rdd_6_1 stored as values in memory (estimated size 7.1 MB, free 1938.8 MB)
2021-12-08 10:35:15,297 [dispatcher-event-loop-6] INFO [org.apache.spark.storage.BlockManagerInfo] - Added rdd_6_1 in memory on qb:55657 (size: 7.1 MB, free: 1972.6 MB)
2021-12-08 10:35:15,304 [Executor task launch worker for task 21] INFO [org.apache.spark.storage.memory.MemoryStore] - Block rdd_6_9 stored as values in memory (estimated size 6.1 MB, free 1938.5 MB)
2021-12-08 10:35:15,304 [dispatcher-event-loop-9] INFO [org.apache.spark.storage.BlockManagerInfo] - Added rdd_6_9 in memory on qb:55657 (size: 6.1 MB, free: 1966.5 MB)
2021-12-08 10:35:15,306 [Executor task launch worker for task 12] INFO [org.apache.spark.storage.memory.MemoryStore] - Block rdd_6_0 stored as values in memory (estimated size 4.6 MB, free 1933.9 MB)
2021-12-08 10:35:15,307 [dispatcher-event-loop-11] INFO [org.apache.spark.storage.BlockManagerInfo] - Added rdd_6_0 in memory on qb:55657 (size: 4.6 MB, free: 1961.8 MB)
2021-12-08 10:35:15,314 [Executor task launch worker for task 15] INFO [org.apache.spark.storage.memory.MemoryStore] - Block rdd_6_3 stored as values in memory (estimated size 9.5 MB, free 1929.7 MB)
2021-12-08 10:35:15,315 [dispatcher-event-loop-10] INFO [org.apache.spark.storage.BlockManagerInfo] - Added rdd_6_3 in memory on qb:55657 (size: 9.5 MB, free: 1952.4 MB)
2021-12-08 10:35:15,335 [Executor task launch worker for task 14] INFO [org.apache.spark.storage.memory.MemoryStore] - Block rdd_6_2 stored as values in memory (estimated size 10.6 MB, free 1924.6 MB)
2021-12-08 10:35:15,336 [dispatcher-event-loop-0] INFO [org.apache.spark.storage.BlockManagerInfo] - Added rdd_6_2 in memory on qb:55657 (size: 10.6 MB, free: 1941.7 MB)
2021-12-08 10:35:15,344 [Executor task launch worker for task 17] INFO [org.apache.spark.storage.memory.MemoryStore] - Block rdd_6_5 stored as values in memory (estimated size 8.9 MB, free 1921.1 MB)
2021-12-08 10:35:15,344 [dispatcher-event-loop-7] INFO [org.apache.spark.storage.BlockManagerInfo] - Added rdd_6_5 in memory on qb:55657 (size: 8.9 MB, free: 1932.8 MB)
2021-12-08 10:35:15,346 [Executor task launch worker for task 20] INFO [org.apache.spark.storage.memory.MemoryStore] - Block rdd_6_8 stored as values in memory (estimated size 10.4 MB, free 1916.4 MB)
2021-12-08 10:35:15,346 [dispatcher-event-loop-2] INFO [org.apache.spark.storage.BlockManagerInfo] - Added rdd_6_8 in memory on qb:55657 (size: 10.4 MB, free: 1922.4 MB)
2021-12-08 10:35:15,347 [Executor task launch worker for task 18] INFO [org.apache.spark.storage.memory.MemoryStore] - Block rdd_6_6 stored as values in memory (estimated size 9.1 MB, free 1913.0 MB)
2021-12-08 10:35:15,347 [dispatcher-event-loop-3] INFO [org.apache.spark.storage.BlockManagerInfo] - Added rdd_6_6 in memory on qb:55657 (size: 9.1 MB, free: 1913.3 MB)
2021-12-08 10:35:15,494 [dispatcher-event-loop-8] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_3_piece0 on qb:55657 in memory (size: 3.5 KB, free: 1913.3 MB)
2021-12-08 10:35:15,798 [Executor task launch worker for task 19] INFO [org.apache.spark.executor.Executor] - Finished task 7.0 in stage 3.0 (TID 19). 1257 bytes result sent to driver
2021-12-08 10:35:15,799 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 7.0 in stage 3.0 (TID 19) in 870 ms on localhost (executor driver) (1/10)
2021-12-08 10:35:15,805 [Executor task launch worker for task 16] INFO [org.apache.spark.executor.Executor] - Finished task 4.0 in stage 3.0 (TID 16). 1257 bytes result sent to driver
2021-12-08 10:35:15,805 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 4.0 in stage 3.0 (TID 16) in 877 ms on localhost (executor driver) (2/10)
2021-12-08 10:35:15,863 [Executor task launch worker for task 13] INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 3.0 (TID 13). 1257 bytes result sent to driver
2021-12-08 10:35:15,864 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 3.0 (TID 13) in 936 ms on localhost (executor driver) (3/10)
2021-12-08 10:35:15,895 [Executor task launch worker for task 12] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 3.0 (TID 12). 1257 bytes result sent to driver
2021-12-08 10:35:15,896 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 3.0 (TID 12) in 967 ms on localhost (executor driver) (4/10)
2021-12-08 10:35:15,902 [Executor task launch worker for task 21] INFO [org.apache.spark.executor.Executor] - Finished task 9.0 in stage 3.0 (TID 21). 1257 bytes result sent to driver
2021-12-08 10:35:15,903 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 9.0 in stage 3.0 (TID 21) in 974 ms on localhost (executor driver) (5/10)
2021-12-08 10:35:15,906 [Executor task launch worker for task 15] INFO [org.apache.spark.executor.Executor] - Finished task 3.0 in stage 3.0 (TID 15). 1257 bytes result sent to driver
2021-12-08 10:35:15,906 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 3.0 in stage 3.0 (TID 15) in 978 ms on localhost (executor driver) (6/10)
2021-12-08 10:35:15,910 [Executor task launch worker for task 14] INFO [org.apache.spark.executor.Executor] - Finished task 2.0 in stage 3.0 (TID 14). 1257 bytes result sent to driver
2021-12-08 10:35:15,910 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 2.0 in stage 3.0 (TID 14) in 982 ms on localhost (executor driver) (7/10)
2021-12-08 10:35:15,920 [Executor task launch worker for task 17] INFO [org.apache.spark.executor.Executor] - Finished task 5.0 in stage 3.0 (TID 17). 1257 bytes result sent to driver
2021-12-08 10:35:15,921 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 5.0 in stage 3.0 (TID 17) in 992 ms on localhost (executor driver) (8/10)
2021-12-08 10:35:15,932 [Executor task launch worker for task 18] INFO [org.apache.spark.executor.Executor] - Finished task 6.0 in stage 3.0 (TID 18). 1257 bytes result sent to driver
2021-12-08 10:35:15,932 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 6.0 in stage 3.0 (TID 18) in 1003 ms on localhost (executor driver) (9/10)
2021-12-08 10:35:15,938 [Executor task launch worker for task 20] INFO [org.apache.spark.executor.Executor] - Finished task 8.0 in stage 3.0 (TID 20). 1257 bytes result sent to driver
2021-12-08 10:35:15,939 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 8.0 in stage 3.0 (TID 20) in 1010 ms on localhost (executor driver) (10/10)
2021-12-08 10:35:15,939 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 3.0, whose tasks have all completed, from pool 
2021-12-08 10:35:15,939 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ShuffleMapStage 3 (map at ALS.scala:1564) finished in 1.017 s
2021-12-08 10:35:15,939 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - looking for newly runnable stages
2021-12-08 10:35:15,939 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - running: Set()
2021-12-08 10:35:15,939 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - waiting: Set(ResultStage 4)
2021-12-08 10:35:15,939 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - failed: Set()
2021-12-08 10:35:15,940 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 4 (userOutBlocks MapPartitionsRDD[10] at mapValues at ALS.scala:1601), which has no missing parents
2021-12-08 10:35:15,942 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_5 stored as values in memory (estimated size 8.2 KB, free 1913.0 MB)
2021-12-08 10:35:15,944 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_5_piece0 stored as bytes in memory (estimated size 4.2 KB, free 1913.0 MB)
2021-12-08 10:35:15,944 [dispatcher-event-loop-4] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_5_piece0 in memory on qb:55657 (size: 4.2 KB, free: 1913.3 MB)
2021-12-08 10:35:15,944 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 5 from broadcast at DAGScheduler.scala:1039
2021-12-08 10:35:15,945 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 12 missing tasks from ResultStage 4 (userOutBlocks MapPartitionsRDD[10] at mapValues at ALS.scala:1601) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11))
2021-12-08 10:35:15,945 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 4.0 with 12 tasks
2021-12-08 10:35:15,945 [dispatcher-event-loop-6] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 4.0 (TID 22, localhost, executor driver, partition 0, ANY, 7649 bytes)
2021-12-08 10:35:15,946 [dispatcher-event-loop-6] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 4.0 (TID 23, localhost, executor driver, partition 1, ANY, 7649 bytes)
2021-12-08 10:35:15,946 [dispatcher-event-loop-6] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 2.0 in stage 4.0 (TID 24, localhost, executor driver, partition 2, ANY, 7649 bytes)
2021-12-08 10:35:15,946 [dispatcher-event-loop-6] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 3.0 in stage 4.0 (TID 25, localhost, executor driver, partition 3, ANY, 7649 bytes)
2021-12-08 10:35:15,946 [dispatcher-event-loop-6] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 4.0 in stage 4.0 (TID 26, localhost, executor driver, partition 4, ANY, 7649 bytes)
2021-12-08 10:35:15,946 [dispatcher-event-loop-6] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 5.0 in stage 4.0 (TID 27, localhost, executor driver, partition 5, ANY, 7649 bytes)
2021-12-08 10:35:15,946 [dispatcher-event-loop-6] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 6.0 in stage 4.0 (TID 28, localhost, executor driver, partition 6, ANY, 7649 bytes)
2021-12-08 10:35:15,946 [dispatcher-event-loop-6] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 7.0 in stage 4.0 (TID 29, localhost, executor driver, partition 7, ANY, 7649 bytes)
2021-12-08 10:35:15,946 [dispatcher-event-loop-6] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 8.0 in stage 4.0 (TID 30, localhost, executor driver, partition 8, ANY, 7649 bytes)
2021-12-08 10:35:15,947 [dispatcher-event-loop-6] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 9.0 in stage 4.0 (TID 31, localhost, executor driver, partition 9, ANY, 7649 bytes)
2021-12-08 10:35:15,947 [dispatcher-event-loop-6] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 10.0 in stage 4.0 (TID 32, localhost, executor driver, partition 10, ANY, 7649 bytes)
2021-12-08 10:35:15,947 [dispatcher-event-loop-6] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 11.0 in stage 4.0 (TID 33, localhost, executor driver, partition 11, ANY, 7649 bytes)
2021-12-08 10:35:15,947 [Executor task launch worker for task 23] INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 4.0 (TID 23)
2021-12-08 10:35:15,947 [Executor task launch worker for task 22] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 4.0 (TID 22)
2021-12-08 10:35:15,947 [Executor task launch worker for task 29] INFO [org.apache.spark.executor.Executor] - Running task 7.0 in stage 4.0 (TID 29)
2021-12-08 10:35:15,947 [Executor task launch worker for task 28] INFO [org.apache.spark.executor.Executor] - Running task 6.0 in stage 4.0 (TID 28)
2021-12-08 10:35:15,947 [Executor task launch worker for task 26] INFO [org.apache.spark.executor.Executor] - Running task 4.0 in stage 4.0 (TID 26)
2021-12-08 10:35:15,947 [Executor task launch worker for task 25] INFO [org.apache.spark.executor.Executor] - Running task 3.0 in stage 4.0 (TID 25)
2021-12-08 10:35:15,947 [Executor task launch worker for task 24] INFO [org.apache.spark.executor.Executor] - Running task 2.0 in stage 4.0 (TID 24)
2021-12-08 10:35:15,947 [Executor task launch worker for task 31] INFO [org.apache.spark.executor.Executor] - Running task 9.0 in stage 4.0 (TID 31)
2021-12-08 10:35:15,947 [Executor task launch worker for task 27] INFO [org.apache.spark.executor.Executor] - Running task 5.0 in stage 4.0 (TID 27)
2021-12-08 10:35:15,947 [Executor task launch worker for task 30] INFO [org.apache.spark.executor.Executor] - Running task 8.0 in stage 4.0 (TID 30)
2021-12-08 10:35:15,949 [Executor task launch worker for task 32] INFO [org.apache.spark.executor.Executor] - Running task 10.0 in stage 4.0 (TID 32)
2021-12-08 10:35:15,950 [Executor task launch worker for task 33] INFO [org.apache.spark.executor.Executor] - Running task 11.0 in stage 4.0 (TID 33)
2021-12-08 10:35:15,951 [Executor task launch worker for task 31] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 8 non-empty blocks out of 10 blocks
2021-12-08 10:35:15,951 [Executor task launch worker for task 31] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-08 10:35:15,951 [Executor task launch worker for task 29] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 7 non-empty blocks out of 10 blocks
2021-12-08 10:35:15,951 [Executor task launch worker for task 26] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 5 non-empty blocks out of 10 blocks
2021-12-08 10:35:15,951 [Executor task launch worker for task 26] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-08 10:35:15,951 [Executor task launch worker for task 29] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-08 10:35:15,951 [Executor task launch worker for task 24] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 7 non-empty blocks out of 10 blocks
2021-12-08 10:35:15,951 [Executor task launch worker for task 24] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-08 10:35:15,951 [Executor task launch worker for task 23] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 5 non-empty blocks out of 10 blocks
2021-12-08 10:35:15,951 [Executor task launch worker for task 23] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-08 10:35:15,951 [Executor task launch worker for task 30] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 9 non-empty blocks out of 10 blocks
2021-12-08 10:35:15,951 [Executor task launch worker for task 30] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-08 10:35:15,952 [Executor task launch worker for task 32] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 5 non-empty blocks out of 10 blocks
2021-12-08 10:35:15,952 [Executor task launch worker for task 32] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-08 10:35:15,952 [Executor task launch worker for task 25] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 8 non-empty blocks out of 10 blocks
2021-12-08 10:35:15,952 [Executor task launch worker for task 25] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-08 10:35:15,952 [Executor task launch worker for task 22] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 9 non-empty blocks out of 10 blocks
2021-12-08 10:35:15,952 [Executor task launch worker for task 22] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-08 10:35:15,952 [Executor task launch worker for task 28] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 7 non-empty blocks out of 10 blocks
2021-12-08 10:35:15,952 [Executor task launch worker for task 28] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-08 10:35:15,952 [Executor task launch worker for task 27] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 6 non-empty blocks out of 10 blocks
2021-12-08 10:35:15,952 [Executor task launch worker for task 27] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-08 10:35:15,952 [Executor task launch worker for task 33] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 7 non-empty blocks out of 10 blocks
2021-12-08 10:35:15,952 [Executor task launch worker for task 33] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-08 10:35:16,629 [dispatcher-event-loop-7] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_4_piece0 on qb:55657 in memory (size: 4.0 KB, free: 1913.3 MB)
2021-12-08 10:35:17,315 [Executor task launch worker for task 24] INFO [org.apache.spark.storage.memory.MemoryStore] - Block rdd_9_2 stored as values in memory (estimated size 4.3 MB, free 1904.3 MB)
2021-12-08 10:35:17,315 [Executor task launch worker for task 28] INFO [org.apache.spark.storage.memory.MemoryStore] - Block rdd_9_6 stored as values in memory (estimated size 4.4 MB, free 1904.3 MB)
2021-12-08 10:35:17,315 [dispatcher-event-loop-2] INFO [org.apache.spark.storage.BlockManagerInfo] - Added rdd_9_6 in memory on qb:55657 (size: 4.4 MB, free: 1908.9 MB)
2021-12-08 10:35:17,316 [dispatcher-event-loop-2] INFO [org.apache.spark.storage.BlockManagerInfo] - Added rdd_9_2 in memory on qb:55657 (size: 4.3 MB, free: 1904.6 MB)
2021-12-08 10:35:17,329 [Executor task launch worker for task 26] INFO [org.apache.spark.storage.memory.MemoryStore] - Block rdd_9_4 stored as values in memory (estimated size 4.4 MB, free 1899.9 MB)
2021-12-08 10:35:17,329 [dispatcher-event-loop-6] INFO [org.apache.spark.storage.BlockManagerInfo] - Added rdd_9_4 in memory on qb:55657 (size: 4.4 MB, free: 1900.2 MB)
2021-12-08 10:35:17,341 [Executor task launch worker for task 26] INFO [org.apache.spark.storage.memory.MemoryStore] - Block rdd_10_4 stored as values in memory (estimated size 343.9 KB, free 1899.5 MB)
2021-12-08 10:35:17,341 [dispatcher-event-loop-5] INFO [org.apache.spark.storage.BlockManagerInfo] - Added rdd_10_4 in memory on qb:55657 (size: 343.9 KB, free: 1899.8 MB)
2021-12-08 10:35:17,344 [Executor task launch worker for task 28] INFO [org.apache.spark.storage.memory.MemoryStore] - Block rdd_10_6 stored as values in memory (estimated size 341.6 KB, free 1899.2 MB)
2021-12-08 10:35:17,344 [Executor task launch worker for task 26] INFO [org.apache.spark.executor.Executor] - Finished task 4.0 in stage 4.0 (TID 26). 1096 bytes result sent to driver
2021-12-08 10:35:17,345 [dispatcher-event-loop-1] INFO [org.apache.spark.storage.BlockManagerInfo] - Added rdd_10_6 in memory on qb:55657 (size: 341.6 KB, free: 1899.5 MB)
2021-12-08 10:35:17,345 [Executor task launch worker for task 24] INFO [org.apache.spark.storage.memory.MemoryStore] - Block rdd_10_2 stored as values in memory (estimated size 338.6 KB, free 1898.9 MB)
2021-12-08 10:35:17,345 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 4.0 in stage 4.0 (TID 26) in 1399 ms on localhost (executor driver) (1/12)
2021-12-08 10:35:17,346 [dispatcher-event-loop-4] INFO [org.apache.spark.storage.BlockManagerInfo] - Added rdd_10_2 in memory on qb:55657 (size: 338.6 KB, free: 1899.2 MB)
2021-12-08 10:35:17,347 [Executor task launch worker for task 28] INFO [org.apache.spark.executor.Executor] - Finished task 6.0 in stage 4.0 (TID 28). 1096 bytes result sent to driver
2021-12-08 10:35:17,347 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 6.0 in stage 4.0 (TID 28) in 1401 ms on localhost (executor driver) (2/12)
2021-12-08 10:35:17,348 [Executor task launch worker for task 24] INFO [org.apache.spark.executor.Executor] - Finished task 2.0 in stage 4.0 (TID 24). 1096 bytes result sent to driver
2021-12-08 10:35:17,349 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 2.0 in stage 4.0 (TID 24) in 1403 ms on localhost (executor driver) (3/12)
2021-12-08 10:35:17,356 [Executor task launch worker for task 33] INFO [org.apache.spark.storage.memory.MemoryStore] - Block rdd_9_11 stored as values in memory (estimated size 4.4 MB, free 1894.5 MB)
2021-12-08 10:35:17,356 [dispatcher-event-loop-11] INFO [org.apache.spark.storage.BlockManagerInfo] - Added rdd_9_11 in memory on qb:55657 (size: 4.4 MB, free: 1894.8 MB)
2021-12-08 10:35:17,358 [Executor task launch worker for task 29] INFO [org.apache.spark.storage.memory.MemoryStore] - Block rdd_9_7 stored as values in memory (estimated size 4.4 MB, free 1890.0 MB)
2021-12-08 10:35:17,358 [dispatcher-event-loop-0] INFO [org.apache.spark.storage.BlockManagerInfo] - Added rdd_9_7 in memory on qb:55657 (size: 4.4 MB, free: 1890.3 MB)
2021-12-08 10:35:17,359 [Executor task launch worker for task 31] INFO [org.apache.spark.storage.memory.MemoryStore] - Block rdd_9_9 stored as values in memory (estimated size 4.4 MB, free 1881.2 MB)
2021-12-08 10:35:17,359 [Executor task launch worker for task 23] INFO [org.apache.spark.storage.memory.MemoryStore] - Block rdd_9_1 stored as values in memory (estimated size 4.4 MB, free 1881.2 MB)
2021-12-08 10:35:17,359 [dispatcher-event-loop-7] INFO [org.apache.spark.storage.BlockManagerInfo] - Added rdd_9_9 in memory on qb:55657 (size: 4.4 MB, free: 1886.0 MB)
2021-12-08 10:35:17,360 [dispatcher-event-loop-7] INFO [org.apache.spark.storage.BlockManagerInfo] - Added rdd_9_1 in memory on qb:55657 (size: 4.4 MB, free: 1881.5 MB)
2021-12-08 10:35:17,365 [Executor task launch worker for task 23] INFO [org.apache.spark.storage.memory.MemoryStore] - Block rdd_10_1 stored as values in memory (estimated size 343.3 KB, free 1880.9 MB)
2021-12-08 10:35:17,365 [Executor task launch worker for task 31] INFO [org.apache.spark.storage.memory.MemoryStore] - Block rdd_10_9 stored as values in memory (estimated size 344.5 KB, free 1880.6 MB)
2021-12-08 10:35:17,366 [dispatcher-event-loop-2] INFO [org.apache.spark.storage.BlockManagerInfo] - Added rdd_10_9 in memory on qb:55657 (size: 344.5 KB, free: 1881.2 MB)
2021-12-08 10:35:17,366 [Executor task launch worker for task 27] INFO [org.apache.spark.storage.memory.MemoryStore] - Block rdd_9_5 stored as values in memory (estimated size 4.4 MB, free 1876.2 MB)
2021-12-08 10:35:17,366 [dispatcher-event-loop-2] INFO [org.apache.spark.storage.BlockManagerInfo] - Added rdd_10_1 in memory on qb:55657 (size: 343.3 KB, free: 1880.9 MB)
2021-12-08 10:35:17,366 [dispatcher-event-loop-2] INFO [org.apache.spark.storage.BlockManagerInfo] - Added rdd_9_5 in memory on qb:55657 (size: 4.4 MB, free: 1876.5 MB)
2021-12-08 10:35:17,367 [Executor task launch worker for task 22] INFO [org.apache.spark.storage.memory.MemoryStore] - Block rdd_9_0 stored as values in memory (estimated size 4.4 MB, free 1871.8 MB)
2021-12-08 10:35:17,368 [dispatcher-event-loop-8] INFO [org.apache.spark.storage.BlockManagerInfo] - Added rdd_9_0 in memory on qb:55657 (size: 4.4 MB, free: 1872.1 MB)
2021-12-08 10:35:17,368 [Executor task launch worker for task 23] INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 4.0 (TID 23). 1096 bytes result sent to driver
2021-12-08 10:35:17,369 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 4.0 (TID 23) in 1424 ms on localhost (executor driver) (4/12)
2021-12-08 10:35:17,369 [Executor task launch worker for task 31] INFO [org.apache.spark.executor.Executor] - Finished task 9.0 in stage 4.0 (TID 31). 1096 bytes result sent to driver
2021-12-08 10:35:17,370 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 9.0 in stage 4.0 (TID 31) in 1423 ms on localhost (executor driver) (5/12)
2021-12-08 10:35:17,370 [Executor task launch worker for task 32] INFO [org.apache.spark.storage.memory.MemoryStore] - Block rdd_9_10 stored as values in memory (estimated size 4.5 MB, free 1867.3 MB)
2021-12-08 10:35:17,371 [dispatcher-event-loop-9] INFO [org.apache.spark.storage.BlockManagerInfo] - Added rdd_9_10 in memory on qb:55657 (size: 4.5 MB, free: 1867.6 MB)
2021-12-08 10:35:17,375 [Executor task launch worker for task 30] INFO [org.apache.spark.storage.memory.MemoryStore] - Block rdd_9_8 stored as values in memory (estimated size 4.4 MB, free 1862.9 MB)
2021-12-08 10:35:17,375 [dispatcher-event-loop-10] INFO [org.apache.spark.storage.BlockManagerInfo] - Added rdd_9_8 in memory on qb:55657 (size: 4.4 MB, free: 1863.2 MB)
2021-12-08 10:35:17,378 [Executor task launch worker for task 25] INFO [org.apache.spark.storage.memory.MemoryStore] - Block rdd_9_3 stored as values in memory (estimated size 4.5 MB, free 1858.5 MB)
2021-12-08 10:35:17,379 [dispatcher-event-loop-11] INFO [org.apache.spark.storage.BlockManagerInfo] - Added rdd_9_3 in memory on qb:55657 (size: 4.5 MB, free: 1858.8 MB)
2021-12-08 10:35:17,386 [Executor task launch worker for task 33] INFO [org.apache.spark.storage.memory.MemoryStore] - Block rdd_10_11 stored as values in memory (estimated size 338.4 KB, free 1858.1 MB)
2021-12-08 10:35:17,386 [Executor task launch worker for task 27] INFO [org.apache.spark.storage.memory.MemoryStore] - Block rdd_10_5 stored as values in memory (estimated size 340.8 KB, free 1857.8 MB)
2021-12-08 10:35:17,386 [Executor task launch worker for task 22] INFO [org.apache.spark.storage.memory.MemoryStore] - Block rdd_10_0 stored as values in memory (estimated size 342.9 KB, free 1857.1 MB)
2021-12-08 10:35:17,386 [Executor task launch worker for task 32] INFO [org.apache.spark.storage.memory.MemoryStore] - Block rdd_10_10 stored as values in memory (estimated size 342.7 KB, free 1857.1 MB)
2021-12-08 10:35:17,386 [Executor task launch worker for task 30] INFO [org.apache.spark.storage.memory.MemoryStore] - Block rdd_10_8 stored as values in memory (estimated size 343.2 KB, free 1856.5 MB)
2021-12-08 10:35:17,386 [Executor task launch worker for task 25] INFO [org.apache.spark.storage.memory.MemoryStore] - Block rdd_10_3 stored as values in memory (estimated size 342.3 KB, free 1856.5 MB)
2021-12-08 10:35:17,387 [dispatcher-event-loop-0] INFO [org.apache.spark.storage.BlockManagerInfo] - Added rdd_10_11 in memory on qb:55657 (size: 338.4 KB, free: 1858.4 MB)
2021-12-08 10:35:17,387 [dispatcher-event-loop-0] INFO [org.apache.spark.storage.BlockManagerInfo] - Added rdd_10_5 in memory on qb:55657 (size: 340.8 KB, free: 1858.1 MB)
2021-12-08 10:35:17,387 [dispatcher-event-loop-0] INFO [org.apache.spark.storage.BlockManagerInfo] - Added rdd_10_0 in memory on qb:55657 (size: 342.9 KB, free: 1857.8 MB)
2021-12-08 10:35:17,387 [Executor task launch worker for task 29] INFO [org.apache.spark.storage.memory.MemoryStore] - Block rdd_10_7 stored as values in memory (estimated size 343.9 KB, free 1856.1 MB)
2021-12-08 10:35:17,387 [dispatcher-event-loop-0] INFO [org.apache.spark.storage.BlockManagerInfo] - Added rdd_10_10 in memory on qb:55657 (size: 342.7 KB, free: 1857.4 MB)
2021-12-08 10:35:17,388 [dispatcher-event-loop-0] INFO [org.apache.spark.storage.BlockManagerInfo] - Added rdd_10_8 in memory on qb:55657 (size: 343.2 KB, free: 1857.1 MB)
2021-12-08 10:35:17,388 [dispatcher-event-loop-0] INFO [org.apache.spark.storage.BlockManagerInfo] - Added rdd_10_3 in memory on qb:55657 (size: 342.3 KB, free: 1856.8 MB)
2021-12-08 10:35:17,388 [dispatcher-event-loop-0] INFO [org.apache.spark.storage.BlockManagerInfo] - Added rdd_10_7 in memory on qb:55657 (size: 343.9 KB, free: 1856.4 MB)
2021-12-08 10:35:17,389 [Executor task launch worker for task 33] INFO [org.apache.spark.executor.Executor] - Finished task 11.0 in stage 4.0 (TID 33). 1053 bytes result sent to driver
2021-12-08 10:35:17,389 [Executor task launch worker for task 27] INFO [org.apache.spark.executor.Executor] - Finished task 5.0 in stage 4.0 (TID 27). 1096 bytes result sent to driver
2021-12-08 10:35:17,389 [Executor task launch worker for task 22] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 4.0 (TID 22). 1096 bytes result sent to driver
2021-12-08 10:35:17,389 [Executor task launch worker for task 30] INFO [org.apache.spark.executor.Executor] - Finished task 8.0 in stage 4.0 (TID 30). 1096 bytes result sent to driver
2021-12-08 10:35:17,389 [Executor task launch worker for task 25] INFO [org.apache.spark.executor.Executor] - Finished task 3.0 in stage 4.0 (TID 25). 1096 bytes result sent to driver
2021-12-08 10:35:17,390 [Executor task launch worker for task 32] INFO [org.apache.spark.executor.Executor] - Finished task 10.0 in stage 4.0 (TID 32). 1096 bytes result sent to driver
2021-12-08 10:35:17,391 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 4.0 (TID 22) in 1446 ms on localhost (executor driver) (6/12)
2021-12-08 10:35:17,391 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 11.0 in stage 4.0 (TID 33) in 1444 ms on localhost (executor driver) (7/12)
2021-12-08 10:35:17,391 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 5.0 in stage 4.0 (TID 27) in 1445 ms on localhost (executor driver) (8/12)
2021-12-08 10:35:17,391 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 8.0 in stage 4.0 (TID 30) in 1445 ms on localhost (executor driver) (9/12)
2021-12-08 10:35:17,391 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 3.0 in stage 4.0 (TID 25) in 1445 ms on localhost (executor driver) (10/12)
2021-12-08 10:35:17,392 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 10.0 in stage 4.0 (TID 32) in 1445 ms on localhost (executor driver) (11/12)
2021-12-08 10:35:17,392 [Executor task launch worker for task 29] INFO [org.apache.spark.executor.Executor] - Finished task 7.0 in stage 4.0 (TID 29). 1096 bytes result sent to driver
2021-12-08 10:35:17,392 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 7.0 in stage 4.0 (TID 29) in 1446 ms on localhost (executor driver) (12/12)
2021-12-08 10:35:17,392 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 4.0, whose tasks have all completed, from pool 
2021-12-08 10:35:17,392 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 4 (count at ALS.scala:931) finished in 1.451 s
2021-12-08 10:35:17,393 [main] INFO [org.apache.spark.scheduler.DAGScheduler] - Job 2 finished: count at ALS.scala:931, took 11.628000 s
2021-12-08 10:35:17,418 [main] INFO [org.apache.spark.SparkContext] - Starting job: count at ALS.scala:938
2021-12-08 10:35:17,418 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 12 (map at ALS.scala:1564)
2021-12-08 10:35:17,418 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 3 (count at ALS.scala:938) with 12 output partitions
2021-12-08 10:35:17,418 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 7 (count at ALS.scala:938)
2021-12-08 10:35:17,418 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 6)
2021-12-08 10:35:17,419 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List(ShuffleMapStage 6)
2021-12-08 10:35:17,419 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ShuffleMapStage 6 (MapPartitionsRDD[12] at map at ALS.scala:1564), which has no missing parents
2021-12-08 10:35:17,420 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_6 stored as values in memory (estimated size 7.8 KB, free 1856.1 MB)
2021-12-08 10:35:17,422 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_6_piece0 stored as bytes in memory (estimated size 4.0 KB, free 1856.1 MB)
2021-12-08 10:35:17,422 [dispatcher-event-loop-8] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_6_piece0 in memory on qb:55657 (size: 4.0 KB, free: 1856.4 MB)
2021-12-08 10:35:17,422 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 6 from broadcast at DAGScheduler.scala:1039
2021-12-08 10:35:17,422 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 10 missing tasks from ShuffleMapStage 6 (MapPartitionsRDD[12] at map at ALS.scala:1564) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
2021-12-08 10:35:17,423 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 6.0 with 10 tasks
2021-12-08 10:35:17,425 [dispatcher-event-loop-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 6.0 (TID 34, localhost, executor driver, partition 0, PROCESS_LOCAL, 7638 bytes)
2021-12-08 10:35:17,425 [dispatcher-event-loop-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 6.0 (TID 35, localhost, executor driver, partition 1, PROCESS_LOCAL, 7638 bytes)
2021-12-08 10:35:17,425 [dispatcher-event-loop-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 2.0 in stage 6.0 (TID 36, localhost, executor driver, partition 2, PROCESS_LOCAL, 7638 bytes)
2021-12-08 10:35:17,426 [dispatcher-event-loop-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 3.0 in stage 6.0 (TID 37, localhost, executor driver, partition 3, PROCESS_LOCAL, 7638 bytes)
2021-12-08 10:35:17,426 [dispatcher-event-loop-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 4.0 in stage 6.0 (TID 38, localhost, executor driver, partition 4, PROCESS_LOCAL, 7638 bytes)
2021-12-08 10:35:17,426 [dispatcher-event-loop-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 5.0 in stage 6.0 (TID 39, localhost, executor driver, partition 5, PROCESS_LOCAL, 7638 bytes)
2021-12-08 10:35:17,426 [dispatcher-event-loop-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 6.0 in stage 6.0 (TID 40, localhost, executor driver, partition 6, PROCESS_LOCAL, 7638 bytes)
2021-12-08 10:35:17,426 [dispatcher-event-loop-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 7.0 in stage 6.0 (TID 41, localhost, executor driver, partition 7, PROCESS_LOCAL, 7638 bytes)
2021-12-08 10:35:17,426 [dispatcher-event-loop-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 8.0 in stage 6.0 (TID 42, localhost, executor driver, partition 8, PROCESS_LOCAL, 7638 bytes)
2021-12-08 10:35:17,426 [dispatcher-event-loop-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 9.0 in stage 6.0 (TID 43, localhost, executor driver, partition 9, PROCESS_LOCAL, 7638 bytes)
2021-12-08 10:35:17,427 [Executor task launch worker for task 34] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 6.0 (TID 34)
2021-12-08 10:35:17,427 [Executor task launch worker for task 35] INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 6.0 (TID 35)
2021-12-08 10:35:17,427 [Executor task launch worker for task 41] INFO [org.apache.spark.executor.Executor] - Running task 7.0 in stage 6.0 (TID 41)
2021-12-08 10:35:17,427 [Executor task launch worker for task 37] INFO [org.apache.spark.executor.Executor] - Running task 3.0 in stage 6.0 (TID 37)
2021-12-08 10:35:17,427 [Executor task launch worker for task 39] INFO [org.apache.spark.executor.Executor] - Running task 5.0 in stage 6.0 (TID 39)
2021-12-08 10:35:17,427 [Executor task launch worker for task 38] INFO [org.apache.spark.executor.Executor] - Running task 4.0 in stage 6.0 (TID 38)
2021-12-08 10:35:17,427 [Executor task launch worker for task 36] INFO [org.apache.spark.executor.Executor] - Running task 2.0 in stage 6.0 (TID 36)
2021-12-08 10:35:17,427 [Executor task launch worker for task 40] INFO [org.apache.spark.executor.Executor] - Running task 6.0 in stage 6.0 (TID 40)
2021-12-08 10:35:17,427 [Executor task launch worker for task 43] INFO [org.apache.spark.executor.Executor] - Running task 9.0 in stage 6.0 (TID 43)
2021-12-08 10:35:17,427 [Executor task launch worker for task 42] INFO [org.apache.spark.executor.Executor] - Running task 8.0 in stage 6.0 (TID 42)
2021-12-08 10:35:17,430 [Executor task launch worker for task 34] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_6_0 locally
2021-12-08 10:35:17,430 [Executor task launch worker for task 37] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_6_3 locally
2021-12-08 10:35:17,430 [Executor task launch worker for task 38] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_6_4 locally
2021-12-08 10:35:17,430 [Executor task launch worker for task 43] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_6_9 locally
2021-12-08 10:35:17,430 [Executor task launch worker for task 41] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_6_7 locally
2021-12-08 10:35:17,430 [Executor task launch worker for task 36] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_6_2 locally
2021-12-08 10:35:17,431 [Executor task launch worker for task 39] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_6_5 locally
2021-12-08 10:35:17,430 [Executor task launch worker for task 35] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_6_1 locally
2021-12-08 10:35:17,430 [Executor task launch worker for task 42] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_6_8 locally
2021-12-08 10:35:17,431 [Executor task launch worker for task 40] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_6_6 locally
2021-12-08 10:35:17,702 [Executor task launch worker for task 34] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 6.0 (TID 34). 913 bytes result sent to driver
2021-12-08 10:35:17,703 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 6.0 (TID 34) in 279 ms on localhost (executor driver) (1/10)
2021-12-08 10:35:17,713 [Executor task launch worker for task 38] INFO [org.apache.spark.executor.Executor] - Finished task 4.0 in stage 6.0 (TID 38). 913 bytes result sent to driver
2021-12-08 10:35:17,714 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 4.0 in stage 6.0 (TID 38) in 288 ms on localhost (executor driver) (2/10)
2021-12-08 10:35:17,729 [Executor task launch worker for task 43] INFO [org.apache.spark.executor.Executor] - Finished task 9.0 in stage 6.0 (TID 43). 913 bytes result sent to driver
2021-12-08 10:35:17,730 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 9.0 in stage 6.0 (TID 43) in 304 ms on localhost (executor driver) (3/10)
2021-12-08 10:35:17,755 [Executor task launch worker for task 41] INFO [org.apache.spark.executor.Executor] - Finished task 7.0 in stage 6.0 (TID 41). 913 bytes result sent to driver
2021-12-08 10:35:17,755 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 7.0 in stage 6.0 (TID 41) in 329 ms on localhost (executor driver) (4/10)
2021-12-08 10:35:17,789 [Executor task launch worker for task 39] INFO [org.apache.spark.executor.Executor] - Finished task 5.0 in stage 6.0 (TID 39). 913 bytes result sent to driver
2021-12-08 10:35:17,790 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 5.0 in stage 6.0 (TID 39) in 364 ms on localhost (executor driver) (5/10)
2021-12-08 10:35:17,791 [Executor task launch worker for task 35] INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 6.0 (TID 35). 913 bytes result sent to driver
2021-12-08 10:35:17,791 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 6.0 (TID 35) in 366 ms on localhost (executor driver) (6/10)
2021-12-08 10:35:17,804 [Executor task launch worker for task 37] INFO [org.apache.spark.executor.Executor] - Finished task 3.0 in stage 6.0 (TID 37). 913 bytes result sent to driver
2021-12-08 10:35:17,805 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 3.0 in stage 6.0 (TID 37) in 380 ms on localhost (executor driver) (7/10)
2021-12-08 10:35:17,812 [Executor task launch worker for task 40] INFO [org.apache.spark.executor.Executor] - Finished task 6.0 in stage 6.0 (TID 40). 913 bytes result sent to driver
2021-12-08 10:35:17,813 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 6.0 in stage 6.0 (TID 40) in 387 ms on localhost (executor driver) (8/10)
2021-12-08 10:35:17,835 [Executor task launch worker for task 42] INFO [org.apache.spark.executor.Executor] - Finished task 8.0 in stage 6.0 (TID 42). 913 bytes result sent to driver
2021-12-08 10:35:17,836 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 8.0 in stage 6.0 (TID 42) in 410 ms on localhost (executor driver) (9/10)
2021-12-08 10:35:17,836 [Executor task launch worker for task 36] INFO [org.apache.spark.executor.Executor] - Finished task 2.0 in stage 6.0 (TID 36). 913 bytes result sent to driver
2021-12-08 10:35:17,836 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 2.0 in stage 6.0 (TID 36) in 411 ms on localhost (executor driver) (10/10)
2021-12-08 10:35:17,836 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 6.0, whose tasks have all completed, from pool 
2021-12-08 10:35:17,836 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ShuffleMapStage 6 (map at ALS.scala:1564) finished in 0.416 s
2021-12-08 10:35:17,836 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - looking for newly runnable stages
2021-12-08 10:35:17,836 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - running: Set()
2021-12-08 10:35:17,836 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - waiting: Set(ResultStage 7)
2021-12-08 10:35:17,836 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - failed: Set()
2021-12-08 10:35:17,837 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 7 (itemOutBlocks MapPartitionsRDD[15] at mapValues at ALS.scala:1601), which has no missing parents
2021-12-08 10:35:17,838 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_7 stored as values in memory (estimated size 8.4 KB, free 1856.1 MB)
2021-12-08 10:35:17,840 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_7_piece0 stored as bytes in memory (estimated size 4.2 KB, free 1856.1 MB)
2021-12-08 10:35:17,840 [dispatcher-event-loop-8] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_7_piece0 in memory on qb:55657 (size: 4.2 KB, free: 1856.4 MB)
2021-12-08 10:35:17,840 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 7 from broadcast at DAGScheduler.scala:1039
2021-12-08 10:35:17,840 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 12 missing tasks from ResultStage 7 (itemOutBlocks MapPartitionsRDD[15] at mapValues at ALS.scala:1601) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11))
2021-12-08 10:35:17,840 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 7.0 with 12 tasks
2021-12-08 10:35:17,841 [dispatcher-event-loop-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 7.0 (TID 44, localhost, executor driver, partition 0, ANY, 7649 bytes)
2021-12-08 10:35:17,841 [dispatcher-event-loop-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 7.0 (TID 45, localhost, executor driver, partition 1, ANY, 7649 bytes)
2021-12-08 10:35:17,841 [dispatcher-event-loop-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 2.0 in stage 7.0 (TID 46, localhost, executor driver, partition 2, ANY, 7649 bytes)
2021-12-08 10:35:17,841 [dispatcher-event-loop-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 3.0 in stage 7.0 (TID 47, localhost, executor driver, partition 3, ANY, 7649 bytes)
2021-12-08 10:35:17,841 [dispatcher-event-loop-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 4.0 in stage 7.0 (TID 48, localhost, executor driver, partition 4, ANY, 7649 bytes)
2021-12-08 10:35:17,841 [dispatcher-event-loop-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 5.0 in stage 7.0 (TID 49, localhost, executor driver, partition 5, ANY, 7649 bytes)
2021-12-08 10:35:17,841 [dispatcher-event-loop-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 6.0 in stage 7.0 (TID 50, localhost, executor driver, partition 6, ANY, 7649 bytes)
2021-12-08 10:35:17,841 [dispatcher-event-loop-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 7.0 in stage 7.0 (TID 51, localhost, executor driver, partition 7, ANY, 7649 bytes)
2021-12-08 10:35:17,841 [dispatcher-event-loop-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 8.0 in stage 7.0 (TID 52, localhost, executor driver, partition 8, ANY, 7649 bytes)
2021-12-08 10:35:17,842 [dispatcher-event-loop-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 9.0 in stage 7.0 (TID 53, localhost, executor driver, partition 9, ANY, 7649 bytes)
2021-12-08 10:35:17,842 [dispatcher-event-loop-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 10.0 in stage 7.0 (TID 54, localhost, executor driver, partition 10, ANY, 7649 bytes)
2021-12-08 10:35:17,842 [dispatcher-event-loop-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 11.0 in stage 7.0 (TID 55, localhost, executor driver, partition 11, ANY, 7649 bytes)
2021-12-08 10:35:17,842 [Executor task launch worker for task 45] INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 7.0 (TID 45)
2021-12-08 10:35:17,842 [Executor task launch worker for task 46] INFO [org.apache.spark.executor.Executor] - Running task 2.0 in stage 7.0 (TID 46)
2021-12-08 10:35:17,842 [Executor task launch worker for task 51] INFO [org.apache.spark.executor.Executor] - Running task 7.0 in stage 7.0 (TID 51)
2021-12-08 10:35:17,842 [Executor task launch worker for task 48] INFO [org.apache.spark.executor.Executor] - Running task 4.0 in stage 7.0 (TID 48)
2021-12-08 10:35:17,842 [Executor task launch worker for task 53] INFO [org.apache.spark.executor.Executor] - Running task 9.0 in stage 7.0 (TID 53)
2021-12-08 10:35:17,842 [Executor task launch worker for task 52] INFO [org.apache.spark.executor.Executor] - Running task 8.0 in stage 7.0 (TID 52)
2021-12-08 10:35:17,842 [Executor task launch worker for task 49] INFO [org.apache.spark.executor.Executor] - Running task 5.0 in stage 7.0 (TID 49)
2021-12-08 10:35:17,842 [Executor task launch worker for task 47] INFO [org.apache.spark.executor.Executor] - Running task 3.0 in stage 7.0 (TID 47)
2021-12-08 10:35:17,842 [Executor task launch worker for task 44] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 7.0 (TID 44)
2021-12-08 10:35:17,842 [Executor task launch worker for task 55] INFO [org.apache.spark.executor.Executor] - Running task 11.0 in stage 7.0 (TID 55)
2021-12-08 10:35:17,842 [Executor task launch worker for task 50] INFO [org.apache.spark.executor.Executor] - Running task 6.0 in stage 7.0 (TID 50)
2021-12-08 10:35:17,842 [Executor task launch worker for task 54] INFO [org.apache.spark.executor.Executor] - Running task 10.0 in stage 7.0 (TID 54)
2021-12-08 10:35:17,844 [Executor task launch worker for task 52] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 8 non-empty blocks out of 10 blocks
2021-12-08 10:35:17,844 [Executor task launch worker for task 52] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-08 10:35:17,844 [Executor task launch worker for task 54] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 8 non-empty blocks out of 10 blocks
2021-12-08 10:35:17,844 [Executor task launch worker for task 54] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-08 10:35:17,844 [Executor task launch worker for task 47] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 7 non-empty blocks out of 10 blocks
2021-12-08 10:35:17,844 [Executor task launch worker for task 47] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-08 10:35:17,844 [Executor task launch worker for task 45] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 8 non-empty blocks out of 10 blocks
2021-12-08 10:35:17,845 [Executor task launch worker for task 45] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 1 ms
2021-12-08 10:35:17,845 [Executor task launch worker for task 50] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 6 non-empty blocks out of 10 blocks
2021-12-08 10:35:17,845 [Executor task launch worker for task 50] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-08 10:35:17,845 [Executor task launch worker for task 55] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 5 non-empty blocks out of 10 blocks
2021-12-08 10:35:17,845 [Executor task launch worker for task 55] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 1 ms
2021-12-08 10:35:17,845 [Executor task launch worker for task 46] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 8 non-empty blocks out of 10 blocks
2021-12-08 10:35:17,845 [Executor task launch worker for task 46] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 1 ms
2021-12-08 10:35:17,845 [Executor task launch worker for task 49] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 7 non-empty blocks out of 10 blocks
2021-12-08 10:35:17,845 [Executor task launch worker for task 49] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-08 10:35:17,845 [Executor task launch worker for task 53] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 6 non-empty blocks out of 10 blocks
2021-12-08 10:35:17,845 [Executor task launch worker for task 53] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-08 10:35:17,845 [Executor task launch worker for task 44] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 7 non-empty blocks out of 10 blocks
2021-12-08 10:35:17,845 [Executor task launch worker for task 44] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-08 10:35:17,846 [Executor task launch worker for task 48] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 9 non-empty blocks out of 10 blocks
2021-12-08 10:35:17,846 [Executor task launch worker for task 48] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-08 10:35:17,846 [Executor task launch worker for task 51] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 9 non-empty blocks out of 10 blocks
2021-12-08 10:35:17,846 [Executor task launch worker for task 51] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-08 10:35:18,063 [Executor task launch worker for task 44] INFO [org.apache.spark.storage.memory.MemoryStore] - Block rdd_14_0 stored as values in memory (estimated size 4.1 MB, free 1852.0 MB)
2021-12-08 10:35:18,067 [dispatcher-event-loop-4] INFO [org.apache.spark.storage.BlockManagerInfo] - Added rdd_14_0 in memory on qb:55657 (size: 4.1 MB, free: 1852.3 MB)
2021-12-08 10:35:18,072 [Executor task launch worker for task 44] INFO [org.apache.spark.storage.memory.MemoryStore] - Block rdd_15_0 stored as values in memory (estimated size 136.3 KB, free 1851.9 MB)
2021-12-08 10:35:18,076 [dispatcher-event-loop-10] INFO [org.apache.spark.storage.BlockManagerInfo] - Added rdd_15_0 in memory on qb:55657 (size: 136.3 KB, free: 1852.2 MB)
2021-12-08 10:35:18,079 [Executor task launch worker for task 44] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 7.0 (TID 44). 1096 bytes result sent to driver
2021-12-08 10:35:18,080 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 7.0 (TID 44) in 239 ms on localhost (executor driver) (1/12)
2021-12-08 10:35:18,106 [Executor task launch worker for task 53] INFO [org.apache.spark.storage.memory.MemoryStore] - Block rdd_14_9 stored as values in memory (estimated size 4.6 MB, free 1847.3 MB)
2021-12-08 10:35:18,107 [dispatcher-event-loop-11] INFO [org.apache.spark.storage.BlockManagerInfo] - Added rdd_14_9 in memory on qb:55657 (size: 4.6 MB, free: 1847.6 MB)
2021-12-08 10:35:18,109 [Executor task launch worker for task 49] INFO [org.apache.spark.storage.memory.MemoryStore] - Block rdd_14_5 stored as values in memory (estimated size 3.9 MB, free 1843.4 MB)
2021-12-08 10:35:18,110 [dispatcher-event-loop-9] INFO [org.apache.spark.storage.BlockManagerInfo] - Added rdd_14_5 in memory on qb:55657 (size: 3.9 MB, free: 1843.7 MB)
2021-12-08 10:35:18,113 [Executor task launch worker for task 53] INFO [org.apache.spark.storage.memory.MemoryStore] - Block rdd_15_9 stored as values in memory (estimated size 136.9 KB, free 1843.3 MB)
2021-12-08 10:35:18,113 [dispatcher-event-loop-1] INFO [org.apache.spark.storage.BlockManagerInfo] - Added rdd_15_9 in memory on qb:55657 (size: 136.9 KB, free: 1843.6 MB)
2021-12-08 10:35:18,116 [Executor task launch worker for task 53] INFO [org.apache.spark.executor.Executor] - Finished task 9.0 in stage 7.0 (TID 53). 1096 bytes result sent to driver
2021-12-08 10:35:18,116 [Executor task launch worker for task 49] INFO [org.apache.spark.storage.memory.MemoryStore] - Block rdd_15_5 stored as values in memory (estimated size 137.8 KB, free 1843.1 MB)
2021-12-08 10:35:18,116 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 9.0 in stage 7.0 (TID 53) in 275 ms on localhost (executor driver) (2/12)
2021-12-08 10:35:18,117 [dispatcher-event-loop-2] INFO [org.apache.spark.storage.BlockManagerInfo] - Added rdd_15_5 in memory on qb:55657 (size: 137.8 KB, free: 1843.5 MB)
2021-12-08 10:35:18,121 [Executor task launch worker for task 49] INFO [org.apache.spark.executor.Executor] - Finished task 5.0 in stage 7.0 (TID 49). 1096 bytes result sent to driver
2021-12-08 10:35:18,121 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 5.0 in stage 7.0 (TID 49) in 280 ms on localhost (executor driver) (3/12)
2021-12-08 10:35:18,122 [Executor task launch worker for task 52] INFO [org.apache.spark.storage.memory.MemoryStore] - Block rdd_14_8 stored as values in memory (estimated size 4.3 MB, free 1838.8 MB)
2021-12-08 10:35:18,123 [dispatcher-event-loop-6] INFO [org.apache.spark.storage.BlockManagerInfo] - Added rdd_14_8 in memory on qb:55657 (size: 4.3 MB, free: 1839.2 MB)
2021-12-08 10:35:18,124 [Executor task launch worker for task 54] INFO [org.apache.spark.storage.memory.MemoryStore] - Block rdd_14_10 stored as values in memory (estimated size 4.3 MB, free 1834.6 MB)
2021-12-08 10:35:18,125 [dispatcher-event-loop-8] INFO [org.apache.spark.storage.BlockManagerInfo] - Added rdd_14_10 in memory on qb:55657 (size: 4.3 MB, free: 1834.9 MB)
2021-12-08 10:35:18,128 [Executor task launch worker for task 52] INFO [org.apache.spark.storage.memory.MemoryStore] - Block rdd_15_8 stored as values in memory (estimated size 137.0 KB, free 1834.5 MB)
2021-12-08 10:35:18,129 [dispatcher-event-loop-0] INFO [org.apache.spark.storage.BlockManagerInfo] - Added rdd_15_8 in memory on qb:55657 (size: 137.0 KB, free: 1834.8 MB)
2021-12-08 10:35:18,129 [Executor task launch worker for task 54] INFO [org.apache.spark.storage.memory.MemoryStore] - Block rdd_15_10 stored as values in memory (estimated size 138.7 KB, free 1834.3 MB)
2021-12-08 10:35:18,130 [dispatcher-event-loop-4] INFO [org.apache.spark.storage.BlockManagerInfo] - Added rdd_15_10 in memory on qb:55657 (size: 138.7 KB, free: 1834.6 MB)
2021-12-08 10:35:18,132 [Executor task launch worker for task 54] INFO [org.apache.spark.executor.Executor] - Finished task 10.0 in stage 7.0 (TID 54). 1096 bytes result sent to driver
2021-12-08 10:35:18,132 [Executor task launch worker for task 52] INFO [org.apache.spark.executor.Executor] - Finished task 8.0 in stage 7.0 (TID 52). 1096 bytes result sent to driver
2021-12-08 10:35:18,133 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 10.0 in stage 7.0 (TID 54) in 291 ms on localhost (executor driver) (4/12)
2021-12-08 10:35:18,133 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 8.0 in stage 7.0 (TID 52) in 292 ms on localhost (executor driver) (5/12)
2021-12-08 10:35:18,139 [Executor task launch worker for task 47] INFO [org.apache.spark.storage.memory.MemoryStore] - Block rdd_14_3 stored as values in memory (estimated size 4.7 MB, free 1829.6 MB)
2021-12-08 10:35:18,140 [dispatcher-event-loop-11] INFO [org.apache.spark.storage.BlockManagerInfo] - Added rdd_14_3 in memory on qb:55657 (size: 4.7 MB, free: 1829.9 MB)
2021-12-08 10:35:18,165 [Executor task launch worker for task 55] INFO [org.apache.spark.storage.memory.MemoryStore] - Block rdd_14_11 stored as values in memory (estimated size 4.2 MB, free 1825.5 MB)
2021-12-08 10:35:18,166 [Executor task launch worker for task 47] INFO [org.apache.spark.storage.memory.MemoryStore] - Block rdd_15_3 stored as values in memory (estimated size 139.4 KB, free 1825.3 MB)
2021-12-08 10:35:18,166 [dispatcher-event-loop-9] INFO [org.apache.spark.storage.BlockManagerInfo] - Added rdd_14_11 in memory on qb:55657 (size: 4.2 MB, free: 1825.8 MB)
2021-12-08 10:35:18,167 [dispatcher-event-loop-9] INFO [org.apache.spark.storage.BlockManagerInfo] - Added rdd_15_3 in memory on qb:55657 (size: 139.4 KB, free: 1825.6 MB)
2021-12-08 10:35:18,167 [Executor task launch worker for task 46] INFO [org.apache.spark.storage.memory.MemoryStore] - Block rdd_14_2 stored as values in memory (estimated size 4.9 MB, free 1820.4 MB)
2021-12-08 10:35:18,168 [dispatcher-event-loop-7] INFO [org.apache.spark.storage.BlockManagerInfo] - Added rdd_14_2 in memory on qb:55657 (size: 4.9 MB, free: 1820.7 MB)
2021-12-08 10:35:18,169 [Executor task launch worker for task 47] INFO [org.apache.spark.executor.Executor] - Finished task 3.0 in stage 7.0 (TID 47). 1053 bytes result sent to driver
2021-12-08 10:35:18,170 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 3.0 in stage 7.0 (TID 47) in 329 ms on localhost (executor driver) (6/12)
2021-12-08 10:35:18,171 [Executor task launch worker for task 55] INFO [org.apache.spark.storage.memory.MemoryStore] - Block rdd_15_11 stored as values in memory (estimated size 138.1 KB, free 1820.3 MB)
2021-12-08 10:35:18,172 [dispatcher-event-loop-5] INFO [org.apache.spark.storage.BlockManagerInfo] - Added rdd_15_11 in memory on qb:55657 (size: 138.1 KB, free: 1820.6 MB)
2021-12-08 10:35:18,172 [Executor task launch worker for task 46] INFO [org.apache.spark.storage.memory.MemoryStore] - Block rdd_15_2 stored as values in memory (estimated size 137.0 KB, free 1820.1 MB)
2021-12-08 10:35:18,172 [dispatcher-event-loop-6] INFO [org.apache.spark.storage.BlockManagerInfo] - Added rdd_15_2 in memory on qb:55657 (size: 137.0 KB, free: 1820.5 MB)
2021-12-08 10:35:18,175 [Executor task launch worker for task 55] INFO [org.apache.spark.executor.Executor] - Finished task 11.0 in stage 7.0 (TID 55). 1096 bytes result sent to driver
2021-12-08 10:35:18,175 [Executor task launch worker for task 46] INFO [org.apache.spark.executor.Executor] - Finished task 2.0 in stage 7.0 (TID 46). 1096 bytes result sent to driver
2021-12-08 10:35:18,176 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 11.0 in stage 7.0 (TID 55) in 334 ms on localhost (executor driver) (7/12)
2021-12-08 10:35:18,176 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 2.0 in stage 7.0 (TID 46) in 335 ms on localhost (executor driver) (8/12)
2021-12-08 10:35:18,179 [Executor task launch worker for task 51] INFO [org.apache.spark.storage.memory.MemoryStore] - Block rdd_14_7 stored as values in memory (estimated size 4.4 MB, free 1815.7 MB)
2021-12-08 10:35:18,179 [Executor task launch worker for task 48] INFO [org.apache.spark.storage.memory.MemoryStore] - Block rdd_14_4 stored as values in memory (estimated size 4.1 MB, free 1811.7 MB)
2021-12-08 10:35:18,179 [dispatcher-event-loop-4] INFO [org.apache.spark.storage.BlockManagerInfo] - Added rdd_14_7 in memory on qb:55657 (size: 4.4 MB, free: 1816.1 MB)
2021-12-08 10:35:18,179 [dispatcher-event-loop-4] INFO [org.apache.spark.storage.BlockManagerInfo] - Added rdd_14_4 in memory on qb:55657 (size: 4.1 MB, free: 1812.0 MB)
2021-12-08 10:35:18,183 [Executor task launch worker for task 48] INFO [org.apache.spark.storage.memory.MemoryStore] - Block rdd_15_4 stored as values in memory (estimated size 138.3 KB, free 1811.4 MB)
2021-12-08 10:35:18,183 [Executor task launch worker for task 51] INFO [org.apache.spark.storage.memory.MemoryStore] - Block rdd_15_7 stored as values in memory (estimated size 138.3 KB, free 1811.4 MB)
2021-12-08 10:35:18,184 [dispatcher-event-loop-10] INFO [org.apache.spark.storage.BlockManagerInfo] - Added rdd_15_7 in memory on qb:55657 (size: 138.3 KB, free: 1811.9 MB)
2021-12-08 10:35:18,184 [Executor task launch worker for task 45] INFO [org.apache.spark.storage.memory.MemoryStore] - Block rdd_14_1 stored as values in memory (estimated size 3.9 MB, free 1807.5 MB)
2021-12-08 10:35:18,184 [dispatcher-event-loop-10] INFO [org.apache.spark.storage.BlockManagerInfo] - Added rdd_15_4 in memory on qb:55657 (size: 138.3 KB, free: 1811.7 MB)
2021-12-08 10:35:18,185 [dispatcher-event-loop-1] INFO [org.apache.spark.storage.BlockManagerInfo] - Added rdd_14_1 in memory on qb:55657 (size: 3.9 MB, free: 1807.9 MB)
2021-12-08 10:35:18,186 [Executor task launch worker for task 48] INFO [org.apache.spark.executor.Executor] - Finished task 4.0 in stage 7.0 (TID 48). 1096 bytes result sent to driver
2021-12-08 10:35:18,186 [Executor task launch worker for task 51] INFO [org.apache.spark.executor.Executor] - Finished task 7.0 in stage 7.0 (TID 51). 1096 bytes result sent to driver
2021-12-08 10:35:18,187 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 4.0 in stage 7.0 (TID 48) in 346 ms on localhost (executor driver) (9/12)
2021-12-08 10:35:18,187 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 7.0 in stage 7.0 (TID 51) in 346 ms on localhost (executor driver) (10/12)
2021-12-08 10:35:18,189 [Executor task launch worker for task 45] INFO [org.apache.spark.storage.memory.MemoryStore] - Block rdd_15_1 stored as values in memory (estimated size 139.2 KB, free 1807.4 MB)
2021-12-08 10:35:18,189 [dispatcher-event-loop-2] INFO [org.apache.spark.storage.BlockManagerInfo] - Added rdd_15_1 in memory on qb:55657 (size: 139.2 KB, free: 1807.7 MB)
2021-12-08 10:35:18,191 [Executor task launch worker for task 45] INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 7.0 (TID 45). 1053 bytes result sent to driver
2021-12-08 10:35:18,192 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 7.0 (TID 45) in 351 ms on localhost (executor driver) (11/12)
2021-12-08 10:35:18,195 [Executor task launch worker for task 50] INFO [org.apache.spark.storage.memory.MemoryStore] - Block rdd_14_6 stored as values in memory (estimated size 4.9 MB, free 1802.5 MB)
2021-12-08 10:35:18,196 [dispatcher-event-loop-6] INFO [org.apache.spark.storage.BlockManagerInfo] - Added rdd_14_6 in memory on qb:55657 (size: 4.9 MB, free: 1802.9 MB)
2021-12-08 10:35:18,200 [Executor task launch worker for task 50] INFO [org.apache.spark.storage.memory.MemoryStore] - Block rdd_15_6 stored as values in memory (estimated size 138.5 KB, free 1802.4 MB)
2021-12-08 10:35:18,201 [dispatcher-event-loop-0] INFO [org.apache.spark.storage.BlockManagerInfo] - Added rdd_15_6 in memory on qb:55657 (size: 138.5 KB, free: 1802.7 MB)
2021-12-08 10:35:18,203 [Executor task launch worker for task 50] INFO [org.apache.spark.executor.Executor] - Finished task 6.0 in stage 7.0 (TID 50). 1096 bytes result sent to driver
2021-12-08 10:35:18,203 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 6.0 in stage 7.0 (TID 50) in 362 ms on localhost (executor driver) (12/12)
2021-12-08 10:35:18,203 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 7.0, whose tasks have all completed, from pool 
2021-12-08 10:35:18,203 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 7 (count at ALS.scala:938) finished in 0.365 s
2021-12-08 10:35:18,204 [main] INFO [org.apache.spark.scheduler.DAGScheduler] - Job 3 finished: count at ALS.scala:938, took 0.786074 s
2021-12-08 10:35:18,239 [main] INFO [org.apache.spark.SparkContext] - Starting job: aggregate at ALS.scala:1711
2021-12-08 10:35:18,240 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 4 (aggregate at ALS.scala:1711) with 12 output partitions
2021-12-08 10:35:18,240 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 10 (aggregate at ALS.scala:1711)
2021-12-08 10:35:18,240 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 9)
2021-12-08 10:35:18,241 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2021-12-08 10:35:18,241 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 10 (MapPartitionsRDD[18] at values at ALS.scala:1711), which has no missing parents
2021-12-08 10:35:18,243 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_8 stored as values in memory (estimated size 169.2 KB, free 1802.2 MB)
2021-12-08 10:35:18,246 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_8_piece0 stored as bytes in memory (estimated size 5.3 KB, free 1802.2 MB)
2021-12-08 10:35:18,246 [dispatcher-event-loop-11] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_8_piece0 in memory on qb:55657 (size: 5.3 KB, free: 1802.7 MB)
2021-12-08 10:35:18,246 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 8 from broadcast at DAGScheduler.scala:1039
2021-12-08 10:35:18,247 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 12 missing tasks from ResultStage 10 (MapPartitionsRDD[18] at values at ALS.scala:1711) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11))
2021-12-08 10:35:18,247 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 10.0 with 12 tasks
2021-12-08 10:35:18,247 [dispatcher-event-loop-10] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 10.0 (TID 56, localhost, executor driver, partition 0, PROCESS_LOCAL, 7649 bytes)
2021-12-08 10:35:18,248 [dispatcher-event-loop-10] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 10.0 (TID 57, localhost, executor driver, partition 1, PROCESS_LOCAL, 7649 bytes)
2021-12-08 10:35:18,248 [dispatcher-event-loop-10] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 2.0 in stage 10.0 (TID 58, localhost, executor driver, partition 2, PROCESS_LOCAL, 7649 bytes)
2021-12-08 10:35:18,248 [dispatcher-event-loop-10] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 3.0 in stage 10.0 (TID 59, localhost, executor driver, partition 3, PROCESS_LOCAL, 7649 bytes)
2021-12-08 10:35:18,248 [dispatcher-event-loop-10] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 4.0 in stage 10.0 (TID 60, localhost, executor driver, partition 4, PROCESS_LOCAL, 7649 bytes)
2021-12-08 10:35:18,248 [dispatcher-event-loop-10] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 5.0 in stage 10.0 (TID 61, localhost, executor driver, partition 5, PROCESS_LOCAL, 7649 bytes)
2021-12-08 10:35:18,248 [dispatcher-event-loop-10] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 6.0 in stage 10.0 (TID 62, localhost, executor driver, partition 6, PROCESS_LOCAL, 7649 bytes)
2021-12-08 10:35:18,248 [dispatcher-event-loop-10] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 7.0 in stage 10.0 (TID 63, localhost, executor driver, partition 7, PROCESS_LOCAL, 7649 bytes)
2021-12-08 10:35:18,248 [dispatcher-event-loop-10] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 8.0 in stage 10.0 (TID 64, localhost, executor driver, partition 8, PROCESS_LOCAL, 7649 bytes)
2021-12-08 10:35:18,248 [dispatcher-event-loop-10] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 9.0 in stage 10.0 (TID 65, localhost, executor driver, partition 9, PROCESS_LOCAL, 7649 bytes)
2021-12-08 10:35:18,249 [dispatcher-event-loop-10] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 10.0 in stage 10.0 (TID 66, localhost, executor driver, partition 10, PROCESS_LOCAL, 7649 bytes)
2021-12-08 10:35:18,249 [dispatcher-event-loop-10] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 11.0 in stage 10.0 (TID 67, localhost, executor driver, partition 11, PROCESS_LOCAL, 7649 bytes)
2021-12-08 10:35:18,249 [Executor task launch worker for task 57] INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 10.0 (TID 57)
2021-12-08 10:35:18,249 [Executor task launch worker for task 62] INFO [org.apache.spark.executor.Executor] - Running task 6.0 in stage 10.0 (TID 62)
2021-12-08 10:35:18,249 [Executor task launch worker for task 60] INFO [org.apache.spark.executor.Executor] - Running task 4.0 in stage 10.0 (TID 60)
2021-12-08 10:35:18,249 [Executor task launch worker for task 56] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 10.0 (TID 56)
2021-12-08 10:35:18,249 [Executor task launch worker for task 59] INFO [org.apache.spark.executor.Executor] - Running task 3.0 in stage 10.0 (TID 59)
2021-12-08 10:35:18,249 [Executor task launch worker for task 58] INFO [org.apache.spark.executor.Executor] - Running task 2.0 in stage 10.0 (TID 58)
2021-12-08 10:35:18,249 [Executor task launch worker for task 61] INFO [org.apache.spark.executor.Executor] - Running task 5.0 in stage 10.0 (TID 61)
2021-12-08 10:35:18,249 [Executor task launch worker for task 65] INFO [org.apache.spark.executor.Executor] - Running task 9.0 in stage 10.0 (TID 65)
2021-12-08 10:35:18,249 [Executor task launch worker for task 67] INFO [org.apache.spark.executor.Executor] - Running task 11.0 in stage 10.0 (TID 67)
2021-12-08 10:35:18,249 [Executor task launch worker for task 63] INFO [org.apache.spark.executor.Executor] - Running task 7.0 in stage 10.0 (TID 63)
2021-12-08 10:35:18,249 [Executor task launch worker for task 64] INFO [org.apache.spark.executor.Executor] - Running task 8.0 in stage 10.0 (TID 64)
2021-12-08 10:35:18,249 [Executor task launch worker for task 66] INFO [org.apache.spark.executor.Executor] - Running task 10.0 in stage 10.0 (TID 66)
2021-12-08 10:35:18,252 [Executor task launch worker for task 67] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_9_11 locally
2021-12-08 10:35:18,252 [Executor task launch worker for task 59] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_9_3 locally
2021-12-08 10:35:18,252 [Executor task launch worker for task 60] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_9_4 locally
2021-12-08 10:35:18,252 [Executor task launch worker for task 65] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_9_9 locally
2021-12-08 10:35:18,253 [Executor task launch worker for task 57] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_9_1 locally
2021-12-08 10:35:18,253 [Executor task launch worker for task 66] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_9_10 locally
2021-12-08 10:35:18,253 [Executor task launch worker for task 63] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_9_7 locally
2021-12-08 10:35:18,253 [Executor task launch worker for task 61] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_9_5 locally
2021-12-08 10:35:18,253 [Executor task launch worker for task 64] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_9_8 locally
2021-12-08 10:35:18,253 [Executor task launch worker for task 58] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_9_2 locally
2021-12-08 10:35:18,253 [Executor task launch worker for task 56] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_9_0 locally
2021-12-08 10:35:18,253 [Executor task launch worker for task 62] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_9_6 locally
2021-12-08 10:35:18,257 [Executor task launch worker for task 64] WARN [com.github.fommil.netlib.BLAS] - Failed to load implementation from: com.github.fommil.netlib.NativeSystemBLAS
2021-12-08 10:35:18,257 [Executor task launch worker for task 64] WARN [com.github.fommil.netlib.BLAS] - Failed to load implementation from: com.github.fommil.netlib.NativeRefBLAS
2021-12-08 10:35:18,454 [Executor task launch worker for task 56] INFO [org.apache.spark.storage.memory.MemoryStore] - Block rdd_16_0 stored as values in memory (estimated size 11.1 MB, free 1780.0 MB)
2021-12-08 10:35:18,454 [Executor task launch worker for task 57] INFO [org.apache.spark.storage.memory.MemoryStore] - Block rdd_16_1 stored as values in memory (estimated size 11.1 MB, free 1780.0 MB)
2021-12-08 10:35:18,454 [dispatcher-event-loop-9] INFO [org.apache.spark.storage.BlockManagerInfo] - Added rdd_16_0 in memory on qb:55657 (size: 11.1 MB, free: 1791.6 MB)
2021-12-08 10:35:18,455 [dispatcher-event-loop-9] INFO [org.apache.spark.storage.BlockManagerInfo] - Added rdd_16_1 in memory on qb:55657 (size: 11.1 MB, free: 1780.5 MB)
2021-12-08 10:35:18,456 [Executor task launch worker for task 65] INFO [org.apache.spark.storage.memory.MemoryStore] - Block rdd_16_9 stored as values in memory (estimated size 11.1 MB, free 1768.9 MB)
2021-12-08 10:35:18,457 [dispatcher-event-loop-1] INFO [org.apache.spark.storage.BlockManagerInfo] - Added rdd_16_9 in memory on qb:55657 (size: 11.1 MB, free: 1769.4 MB)
2021-12-08 10:35:18,459 [Executor task launch worker for task 63] INFO [org.apache.spark.storage.memory.MemoryStore] - Block rdd_16_7 stored as values in memory (estimated size 11.1 MB, free 1757.8 MB)
2021-12-08 10:35:18,460 [dispatcher-event-loop-2] INFO [org.apache.spark.storage.BlockManagerInfo] - Added rdd_16_7 in memory on qb:55657 (size: 11.1 MB, free: 1758.3 MB)
2021-12-08 10:35:18,460 [Executor task launch worker for task 61] INFO [org.apache.spark.storage.memory.MemoryStore] - Block rdd_16_5 stored as values in memory (estimated size 11.1 MB, free 1746.7 MB)
2021-12-08 10:35:18,460 [dispatcher-event-loop-6] INFO [org.apache.spark.storage.BlockManagerInfo] - Added rdd_16_5 in memory on qb:55657 (size: 11.1 MB, free: 1747.2 MB)
2021-12-08 10:35:18,467 [Executor task launch worker for task 59] INFO [org.apache.spark.storage.memory.MemoryStore] - Block rdd_16_3 stored as values in memory (estimated size 11.1 MB, free 1735.6 MB)
2021-12-08 10:35:18,468 [dispatcher-event-loop-8] INFO [org.apache.spark.storage.BlockManagerInfo] - Added rdd_16_3 in memory on qb:55657 (size: 11.1 MB, free: 1736.1 MB)
2021-12-08 10:35:18,489 [Executor task launch worker for task 64] INFO [org.apache.spark.storage.memory.MemoryStore] - Block rdd_16_8 stored as values in memory (estimated size 11.1 MB, free 1724.5 MB)
2021-12-08 10:35:18,490 [Executor task launch worker for task 58] INFO [org.apache.spark.storage.memory.MemoryStore] - Block rdd_16_2 stored as values in memory (estimated size 11.1 MB, free 1713.4 MB)
2021-12-08 10:35:18,492 [Executor task launch worker for task 67] INFO [org.apache.spark.storage.memory.MemoryStore] - Block rdd_16_11 stored as values in memory (estimated size 11.1 MB, free 1702.3 MB)
2021-12-08 10:35:18,493 [dispatcher-event-loop-5] INFO [org.apache.spark.storage.BlockManagerInfo] - Added rdd_16_8 in memory on qb:55657 (size: 11.1 MB, free: 1725.0 MB)
2021-12-08 10:35:18,494 [dispatcher-event-loop-5] INFO [org.apache.spark.storage.BlockManagerInfo] - Added rdd_16_2 in memory on qb:55657 (size: 11.1 MB, free: 1713.9 MB)
2021-12-08 10:35:18,494 [dispatcher-event-loop-5] INFO [org.apache.spark.storage.BlockManagerInfo] - Added rdd_16_11 in memory on qb:55657 (size: 11.1 MB, free: 1702.8 MB)
2021-12-08 10:35:18,506 [Executor task launch worker for task 60] INFO [org.apache.spark.storage.memory.MemoryStore] - Block rdd_16_4 stored as values in memory (estimated size 11.1 MB, free 1691.2 MB)
2021-12-08 10:35:18,506 [dispatcher-event-loop-11] INFO [org.apache.spark.storage.BlockManagerInfo] - Added rdd_16_4 in memory on qb:55657 (size: 11.1 MB, free: 1691.7 MB)
2021-12-08 10:35:18,511 [Executor task launch worker for task 62] INFO [org.apache.spark.storage.memory.MemoryStore] - Block rdd_16_6 stored as values in memory (estimated size 11.1 MB, free 1680.1 MB)
2021-12-08 10:35:18,512 [dispatcher-event-loop-0] INFO [org.apache.spark.storage.BlockManagerInfo] - Added rdd_16_6 in memory on qb:55657 (size: 11.1 MB, free: 1680.6 MB)
2021-12-08 10:35:18,521 [Executor task launch worker for task 66] INFO [org.apache.spark.storage.memory.MemoryStore] - Block rdd_16_10 stored as values in memory (estimated size 11.1 MB, free 1669.0 MB)
2021-12-08 10:35:18,522 [dispatcher-event-loop-10] INFO [org.apache.spark.storage.BlockManagerInfo] - Added rdd_16_10 in memory on qb:55657 (size: 11.1 MB, free: 1669.5 MB)
2021-12-08 10:35:18,834 [Executor task launch worker for task 57] INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 10.0 (TID 57). 165624 bytes result sent to driver
2021-12-08 10:35:18,835 [Executor task launch worker for task 58] INFO [org.apache.spark.executor.Executor] - Finished task 2.0 in stage 10.0 (TID 58). 165624 bytes result sent to driver
2021-12-08 10:35:18,838 [Executor task launch worker for task 65] INFO [org.apache.spark.executor.Executor] - Finished task 9.0 in stage 10.0 (TID 65). 165624 bytes result sent to driver
2021-12-08 10:35:18,840 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 10.0 (TID 57) in 593 ms on localhost (executor driver) (1/12)
2021-12-08 10:35:18,841 [Executor task launch worker for task 63] INFO [org.apache.spark.executor.Executor] - Finished task 7.0 in stage 10.0 (TID 63). 165624 bytes result sent to driver
2021-12-08 10:35:18,841 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 2.0 in stage 10.0 (TID 58) in 593 ms on localhost (executor driver) (2/12)
2021-12-08 10:35:18,846 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 9.0 in stage 10.0 (TID 65) in 598 ms on localhost (executor driver) (3/12)
2021-12-08 10:35:18,846 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 7.0 in stage 10.0 (TID 63) in 598 ms on localhost (executor driver) (4/12)
2021-12-08 10:35:18,864 [Executor task launch worker for task 64] INFO [org.apache.spark.executor.Executor] - Finished task 8.0 in stage 10.0 (TID 64). 165624 bytes result sent to driver
2021-12-08 10:35:18,869 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 8.0 in stage 10.0 (TID 64) in 621 ms on localhost (executor driver) (5/12)
2021-12-08 10:35:18,869 [Executor task launch worker for task 67] INFO [org.apache.spark.executor.Executor] - Finished task 11.0 in stage 10.0 (TID 67). 165624 bytes result sent to driver
2021-12-08 10:35:18,870 [Executor task launch worker for task 56] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 10.0 (TID 56). 165624 bytes result sent to driver
2021-12-08 10:35:18,871 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 11.0 in stage 10.0 (TID 67) in 622 ms on localhost (executor driver) (6/12)
2021-12-08 10:35:18,871 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 10.0 (TID 56) in 624 ms on localhost (executor driver) (7/12)
2021-12-08 10:35:18,873 [Executor task launch worker for task 59] INFO [org.apache.spark.executor.Executor] - Finished task 3.0 in stage 10.0 (TID 59). 165581 bytes result sent to driver
2021-12-08 10:35:18,874 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 3.0 in stage 10.0 (TID 59) in 626 ms on localhost (executor driver) (8/12)
2021-12-08 10:35:18,876 [Executor task launch worker for task 60] INFO [org.apache.spark.executor.Executor] - Finished task 4.0 in stage 10.0 (TID 60). 165581 bytes result sent to driver
2021-12-08 10:35:18,876 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 4.0 in stage 10.0 (TID 60) in 628 ms on localhost (executor driver) (9/12)
2021-12-08 10:35:18,885 [Executor task launch worker for task 61] INFO [org.apache.spark.executor.Executor] - Finished task 5.0 in stage 10.0 (TID 61). 165581 bytes result sent to driver
2021-12-08 10:35:18,886 [Executor task launch worker for task 62] INFO [org.apache.spark.executor.Executor] - Finished task 6.0 in stage 10.0 (TID 62). 165581 bytes result sent to driver
2021-12-08 10:35:18,886 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 5.0 in stage 10.0 (TID 61) in 638 ms on localhost (executor driver) (10/12)
2021-12-08 10:35:18,886 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 6.0 in stage 10.0 (TID 62) in 638 ms on localhost (executor driver) (11/12)
2021-12-08 10:35:18,897 [Executor task launch worker for task 66] INFO [org.apache.spark.executor.Executor] - Finished task 10.0 in stage 10.0 (TID 66). 165624 bytes result sent to driver
2021-12-08 10:35:18,897 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 10.0 in stage 10.0 (TID 66) in 649 ms on localhost (executor driver) (12/12)
2021-12-08 10:35:18,898 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 10.0, whose tasks have all completed, from pool 
2021-12-08 10:35:18,898 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 10 (aggregate at ALS.scala:1711) finished in 0.656 s
2021-12-08 10:35:18,898 [main] INFO [org.apache.spark.scheduler.DAGScheduler] - Job 4 finished: aggregate at ALS.scala:1711, took 0.659335 s
2021-12-08 10:35:18,929 [main] INFO [org.apache.spark.rdd.MapPartitionsRDD] - Removing RDD 17 from persistence list
2021-12-08 10:35:18,931 [block-manager-slave-async-thread-pool-0] INFO [org.apache.spark.storage.BlockManager] - Removing RDD 17
2021-12-08 10:35:18,942 [main] INFO [org.apache.spark.SparkContext] - Starting job: aggregate at ALS.scala:1711
2021-12-08 10:35:18,944 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 16 (map at ALS.scala:1231)
2021-12-08 10:35:18,944 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 22 (flatMap at ALS.scala:1653)
2021-12-08 10:35:18,944 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 5 (aggregate at ALS.scala:1711) with 12 output partitions
2021-12-08 10:35:18,945 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 16 (aggregate at ALS.scala:1711)
2021-12-08 10:35:18,945 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 15, ShuffleMapStage 12)
2021-12-08 10:35:18,945 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List(ShuffleMapStage 15)
2021-12-08 10:35:18,945 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ShuffleMapStage 14 (userFactors-1 MapPartitionsRDD[16] at map at ALS.scala:1231), which has no missing parents
2021-12-08 10:35:18,946 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_9 stored as values in memory (estimated size 8.2 KB, free 1669.0 MB)
2021-12-08 10:35:18,948 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_9_piece0 stored as bytes in memory (estimated size 4.2 KB, free 1669.0 MB)
2021-12-08 10:35:18,949 [dispatcher-event-loop-5] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_9_piece0 in memory on qb:55657 (size: 4.2 KB, free: 1669.5 MB)
2021-12-08 10:35:18,949 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 9 from broadcast at DAGScheduler.scala:1039
2021-12-08 10:35:18,949 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 12 missing tasks from ShuffleMapStage 14 (userFactors-1 MapPartitionsRDD[16] at map at ALS.scala:1231) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11))
2021-12-08 10:35:18,949 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 14.0 with 12 tasks
2021-12-08 10:35:18,950 [dispatcher-event-loop-11] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 14.0 (TID 68, localhost, executor driver, partition 0, PROCESS_LOCAL, 7638 bytes)
2021-12-08 10:35:18,950 [dispatcher-event-loop-11] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 14.0 (TID 69, localhost, executor driver, partition 1, PROCESS_LOCAL, 7638 bytes)
2021-12-08 10:35:18,950 [dispatcher-event-loop-11] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 2.0 in stage 14.0 (TID 70, localhost, executor driver, partition 2, PROCESS_LOCAL, 7638 bytes)
2021-12-08 10:35:18,950 [dispatcher-event-loop-11] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 3.0 in stage 14.0 (TID 71, localhost, executor driver, partition 3, PROCESS_LOCAL, 7638 bytes)
2021-12-08 10:35:18,950 [dispatcher-event-loop-11] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 4.0 in stage 14.0 (TID 72, localhost, executor driver, partition 4, PROCESS_LOCAL, 7638 bytes)
2021-12-08 10:35:18,950 [dispatcher-event-loop-11] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 5.0 in stage 14.0 (TID 73, localhost, executor driver, partition 5, PROCESS_LOCAL, 7638 bytes)
2021-12-08 10:35:18,951 [dispatcher-event-loop-11] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 6.0 in stage 14.0 (TID 74, localhost, executor driver, partition 6, PROCESS_LOCAL, 7638 bytes)
2021-12-08 10:35:18,951 [dispatcher-event-loop-11] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 7.0 in stage 14.0 (TID 75, localhost, executor driver, partition 7, PROCESS_LOCAL, 7638 bytes)
2021-12-08 10:35:18,951 [dispatcher-event-loop-11] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 8.0 in stage 14.0 (TID 76, localhost, executor driver, partition 8, PROCESS_LOCAL, 7638 bytes)
2021-12-08 10:35:18,951 [dispatcher-event-loop-11] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 9.0 in stage 14.0 (TID 77, localhost, executor driver, partition 9, PROCESS_LOCAL, 7638 bytes)
2021-12-08 10:35:18,951 [dispatcher-event-loop-11] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 10.0 in stage 14.0 (TID 78, localhost, executor driver, partition 10, PROCESS_LOCAL, 7638 bytes)
2021-12-08 10:35:18,951 [dispatcher-event-loop-11] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 11.0 in stage 14.0 (TID 79, localhost, executor driver, partition 11, PROCESS_LOCAL, 7638 bytes)
2021-12-08 10:35:18,951 [Executor task launch worker for task 68] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 14.0 (TID 68)
2021-12-08 10:35:18,951 [Executor task launch worker for task 69] INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 14.0 (TID 69)
2021-12-08 10:35:18,951 [Executor task launch worker for task 72] INFO [org.apache.spark.executor.Executor] - Running task 4.0 in stage 14.0 (TID 72)
2021-12-08 10:35:18,951 [Executor task launch worker for task 70] INFO [org.apache.spark.executor.Executor] - Running task 2.0 in stage 14.0 (TID 70)
2021-12-08 10:35:18,952 [Executor task launch worker for task 78] INFO [org.apache.spark.executor.Executor] - Running task 10.0 in stage 14.0 (TID 78)
2021-12-08 10:35:18,952 [Executor task launch worker for task 77] INFO [org.apache.spark.executor.Executor] - Running task 9.0 in stage 14.0 (TID 77)
2021-12-08 10:35:18,951 [Executor task launch worker for task 75] INFO [org.apache.spark.executor.Executor] - Running task 7.0 in stage 14.0 (TID 75)
2021-12-08 10:35:18,951 [Executor task launch worker for task 73] INFO [org.apache.spark.executor.Executor] - Running task 5.0 in stage 14.0 (TID 73)
2021-12-08 10:35:18,951 [Executor task launch worker for task 76] INFO [org.apache.spark.executor.Executor] - Running task 8.0 in stage 14.0 (TID 76)
2021-12-08 10:35:18,951 [Executor task launch worker for task 74] INFO [org.apache.spark.executor.Executor] - Running task 6.0 in stage 14.0 (TID 74)
2021-12-08 10:35:18,951 [Executor task launch worker for task 71] INFO [org.apache.spark.executor.Executor] - Running task 3.0 in stage 14.0 (TID 71)
2021-12-08 10:35:18,952 [Executor task launch worker for task 79] INFO [org.apache.spark.executor.Executor] - Running task 11.0 in stage 14.0 (TID 79)
2021-12-08 10:35:18,953 [Executor task launch worker for task 78] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_16_10 locally
2021-12-08 10:35:18,953 [Executor task launch worker for task 73] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_16_5 locally
2021-12-08 10:35:18,953 [Executor task launch worker for task 71] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_16_3 locally
2021-12-08 10:35:18,953 [Executor task launch worker for task 75] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_16_7 locally
2021-12-08 10:35:18,953 [Executor task launch worker for task 76] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_16_8 locally
2021-12-08 10:35:18,953 [Executor task launch worker for task 79] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_16_11 locally
2021-12-08 10:35:18,953 [Executor task launch worker for task 77] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_16_9 locally
2021-12-08 10:35:18,953 [Executor task launch worker for task 74] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_16_6 locally
2021-12-08 10:35:18,954 [Executor task launch worker for task 70] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_16_2 locally
2021-12-08 10:35:18,954 [Executor task launch worker for task 72] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_16_4 locally
2021-12-08 10:35:18,955 [Executor task launch worker for task 69] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_16_1 locally
2021-12-08 10:35:18,957 [Executor task launch worker for task 68] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_16_0 locally
2021-12-08 10:35:19,061 [Executor task launch worker for task 75] INFO [org.apache.spark.executor.Executor] - Finished task 7.0 in stage 14.0 (TID 75). 870 bytes result sent to driver
2021-12-08 10:35:19,066 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 7.0 in stage 14.0 (TID 75) in 115 ms on localhost (executor driver) (1/12)
2021-12-08 10:35:19,069 [Executor task launch worker for task 68] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 14.0 (TID 68). 870 bytes result sent to driver
2021-12-08 10:35:19,070 [Executor task launch worker for task 71] INFO [org.apache.spark.executor.Executor] - Finished task 3.0 in stage 14.0 (TID 71). 870 bytes result sent to driver
2021-12-08 10:35:19,070 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 14.0 (TID 68) in 121 ms on localhost (executor driver) (2/12)
2021-12-08 10:35:19,071 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 3.0 in stage 14.0 (TID 71) in 121 ms on localhost (executor driver) (3/12)
2021-12-08 10:35:19,076 [Executor task launch worker for task 69] INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 14.0 (TID 69). 913 bytes result sent to driver
2021-12-08 10:35:19,076 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 14.0 (TID 69) in 126 ms on localhost (executor driver) (4/12)
2021-12-08 10:35:19,077 [Executor task launch worker for task 74] INFO [org.apache.spark.executor.Executor] - Finished task 6.0 in stage 14.0 (TID 74). 870 bytes result sent to driver
2021-12-08 10:35:19,078 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 6.0 in stage 14.0 (TID 74) in 128 ms on localhost (executor driver) (5/12)
2021-12-08 10:35:19,083 [Executor task launch worker for task 79] INFO [org.apache.spark.executor.Executor] - Finished task 11.0 in stage 14.0 (TID 79). 827 bytes result sent to driver
2021-12-08 10:35:19,084 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 11.0 in stage 14.0 (TID 79) in 133 ms on localhost (executor driver) (6/12)
2021-12-08 10:35:19,086 [Executor task launch worker for task 76] INFO [org.apache.spark.executor.Executor] - Finished task 8.0 in stage 14.0 (TID 76). 870 bytes result sent to driver
2021-12-08 10:35:19,088 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 8.0 in stage 14.0 (TID 76) in 137 ms on localhost (executor driver) (7/12)
2021-12-08 10:35:19,089 [Executor task launch worker for task 77] INFO [org.apache.spark.executor.Executor] - Finished task 9.0 in stage 14.0 (TID 77). 870 bytes result sent to driver
2021-12-08 10:35:19,089 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 9.0 in stage 14.0 (TID 77) in 138 ms on localhost (executor driver) (8/12)
2021-12-08 10:35:19,091 [Executor task launch worker for task 70] INFO [org.apache.spark.executor.Executor] - Finished task 2.0 in stage 14.0 (TID 70). 870 bytes result sent to driver
2021-12-08 10:35:19,091 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 2.0 in stage 14.0 (TID 70) in 141 ms on localhost (executor driver) (9/12)
2021-12-08 10:35:19,092 [Executor task launch worker for task 78] INFO [org.apache.spark.executor.Executor] - Finished task 10.0 in stage 14.0 (TID 78). 870 bytes result sent to driver
2021-12-08 10:35:19,093 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 10.0 in stage 14.0 (TID 78) in 142 ms on localhost (executor driver) (10/12)
2021-12-08 10:35:19,096 [Executor task launch worker for task 72] INFO [org.apache.spark.executor.Executor] - Finished task 4.0 in stage 14.0 (TID 72). 913 bytes result sent to driver
2021-12-08 10:35:19,096 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 4.0 in stage 14.0 (TID 72) in 146 ms on localhost (executor driver) (11/12)
2021-12-08 10:35:19,096 [Executor task launch worker for task 73] INFO [org.apache.spark.executor.Executor] - Finished task 5.0 in stage 14.0 (TID 73). 870 bytes result sent to driver
2021-12-08 10:35:19,097 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 5.0 in stage 14.0 (TID 73) in 147 ms on localhost (executor driver) (12/12)
2021-12-08 10:35:19,097 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 14.0, whose tasks have all completed, from pool 
2021-12-08 10:35:19,097 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ShuffleMapStage 14 (map at ALS.scala:1231) finished in 0.151 s
2021-12-08 10:35:19,097 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - looking for newly runnable stages
2021-12-08 10:35:19,097 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - running: Set()
2021-12-08 10:35:19,097 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - waiting: Set(ShuffleMapStage 15, ResultStage 16)
2021-12-08 10:35:19,097 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - failed: Set()
2021-12-08 10:35:19,097 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ShuffleMapStage 15 (MapPartitionsRDD[22] at flatMap at ALS.scala:1653), which has no missing parents
2021-12-08 10:35:19,099 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_10 stored as values in memory (estimated size 9.3 KB, free 1669.0 MB)
2021-12-08 10:35:19,100 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_10_piece0 stored as bytes in memory (estimated size 4.5 KB, free 1668.9 MB)
2021-12-08 10:35:19,101 [dispatcher-event-loop-7] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_10_piece0 in memory on qb:55657 (size: 4.5 KB, free: 1669.5 MB)
2021-12-08 10:35:19,101 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 10 from broadcast at DAGScheduler.scala:1039
2021-12-08 10:35:19,102 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 12 missing tasks from ShuffleMapStage 15 (MapPartitionsRDD[22] at flatMap at ALS.scala:1653) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11))
2021-12-08 10:35:19,102 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 15.0 with 12 tasks
2021-12-08 10:35:19,104 [dispatcher-event-loop-10] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 15.0 (TID 80, localhost, executor driver, partition 0, PROCESS_LOCAL, 7855 bytes)
2021-12-08 10:35:19,104 [dispatcher-event-loop-10] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 15.0 (TID 81, localhost, executor driver, partition 1, PROCESS_LOCAL, 7855 bytes)
2021-12-08 10:35:19,104 [dispatcher-event-loop-10] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 2.0 in stage 15.0 (TID 82, localhost, executor driver, partition 2, PROCESS_LOCAL, 7855 bytes)
2021-12-08 10:35:19,104 [dispatcher-event-loop-10] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 3.0 in stage 15.0 (TID 83, localhost, executor driver, partition 3, PROCESS_LOCAL, 7855 bytes)
2021-12-08 10:35:19,105 [dispatcher-event-loop-10] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 4.0 in stage 15.0 (TID 84, localhost, executor driver, partition 4, PROCESS_LOCAL, 7855 bytes)
2021-12-08 10:35:19,105 [dispatcher-event-loop-10] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 5.0 in stage 15.0 (TID 85, localhost, executor driver, partition 5, PROCESS_LOCAL, 7855 bytes)
2021-12-08 10:35:19,105 [dispatcher-event-loop-10] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 6.0 in stage 15.0 (TID 86, localhost, executor driver, partition 6, PROCESS_LOCAL, 7855 bytes)
2021-12-08 10:35:19,105 [dispatcher-event-loop-10] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 7.0 in stage 15.0 (TID 87, localhost, executor driver, partition 7, PROCESS_LOCAL, 7855 bytes)
2021-12-08 10:35:19,105 [dispatcher-event-loop-10] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 8.0 in stage 15.0 (TID 88, localhost, executor driver, partition 8, PROCESS_LOCAL, 7855 bytes)
2021-12-08 10:35:19,105 [dispatcher-event-loop-10] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 9.0 in stage 15.0 (TID 89, localhost, executor driver, partition 9, PROCESS_LOCAL, 7855 bytes)
2021-12-08 10:35:19,105 [dispatcher-event-loop-10] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 10.0 in stage 15.0 (TID 90, localhost, executor driver, partition 10, PROCESS_LOCAL, 7855 bytes)
2021-12-08 10:35:19,105 [dispatcher-event-loop-10] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 11.0 in stage 15.0 (TID 91, localhost, executor driver, partition 11, PROCESS_LOCAL, 7855 bytes)
2021-12-08 10:35:19,105 [Executor task launch worker for task 81] INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 15.0 (TID 81)
2021-12-08 10:35:19,105 [Executor task launch worker for task 83] INFO [org.apache.spark.executor.Executor] - Running task 3.0 in stage 15.0 (TID 83)
2021-12-08 10:35:19,106 [Executor task launch worker for task 89] INFO [org.apache.spark.executor.Executor] - Running task 9.0 in stage 15.0 (TID 89)
2021-12-08 10:35:19,106 [Executor task launch worker for task 86] INFO [org.apache.spark.executor.Executor] - Running task 6.0 in stage 15.0 (TID 86)
2021-12-08 10:35:19,105 [Executor task launch worker for task 82] INFO [org.apache.spark.executor.Executor] - Running task 2.0 in stage 15.0 (TID 82)
2021-12-08 10:35:19,105 [Executor task launch worker for task 80] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 15.0 (TID 80)
2021-12-08 10:35:19,106 [Executor task launch worker for task 90] INFO [org.apache.spark.executor.Executor] - Running task 10.0 in stage 15.0 (TID 90)
2021-12-08 10:35:19,106 [Executor task launch worker for task 91] INFO [org.apache.spark.executor.Executor] - Running task 11.0 in stage 15.0 (TID 91)
2021-12-08 10:35:19,106 [Executor task launch worker for task 87] INFO [org.apache.spark.executor.Executor] - Running task 7.0 in stage 15.0 (TID 87)
2021-12-08 10:35:19,106 [Executor task launch worker for task 88] INFO [org.apache.spark.executor.Executor] - Running task 8.0 in stage 15.0 (TID 88)
2021-12-08 10:35:19,105 [Executor task launch worker for task 85] INFO [org.apache.spark.executor.Executor] - Running task 5.0 in stage 15.0 (TID 85)
2021-12-08 10:35:19,105 [Executor task launch worker for task 84] INFO [org.apache.spark.executor.Executor] - Running task 4.0 in stage 15.0 (TID 84)
2021-12-08 10:35:19,108 [Executor task launch worker for task 80] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_10_0 locally
2021-12-08 10:35:19,108 [Executor task launch worker for task 81] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_10_1 locally
2021-12-08 10:35:19,108 [Executor task launch worker for task 85] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_10_5 locally
2021-12-08 10:35:19,109 [Executor task launch worker for task 82] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_10_2 locally
2021-12-08 10:35:19,109 [Executor task launch worker for task 83] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_10_3 locally
2021-12-08 10:35:19,109 [Executor task launch worker for task 84] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_10_4 locally
2021-12-08 10:35:19,109 [Executor task launch worker for task 85] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 12 blocks
2021-12-08 10:35:19,108 [Executor task launch worker for task 86] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_10_6 locally
2021-12-08 10:35:19,108 [Executor task launch worker for task 89] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_10_9 locally
2021-12-08 10:35:19,108 [Executor task launch worker for task 90] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_10_10 locally
2021-12-08 10:35:19,108 [Executor task launch worker for task 91] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_10_11 locally
2021-12-08 10:35:19,108 [Executor task launch worker for task 88] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_10_8 locally
2021-12-08 10:35:19,109 [Executor task launch worker for task 82] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 12 blocks
2021-12-08 10:35:19,109 [Executor task launch worker for task 82] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-08 10:35:19,109 [Executor task launch worker for task 85] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-08 10:35:19,109 [Executor task launch worker for task 89] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 12 blocks
2021-12-08 10:35:19,109 [Executor task launch worker for task 83] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 12 blocks
2021-12-08 10:35:19,109 [Executor task launch worker for task 80] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 12 blocks
2021-12-08 10:35:19,109 [Executor task launch worker for task 83] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-08 10:35:19,109 [Executor task launch worker for task 81] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 12 blocks
2021-12-08 10:35:19,109 [Executor task launch worker for task 87] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_10_7 locally
2021-12-08 10:35:19,109 [Executor task launch worker for task 81] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-08 10:35:19,109 [Executor task launch worker for task 80] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-08 10:35:19,109 [Executor task launch worker for task 89] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-08 10:35:19,109 [Executor task launch worker for task 84] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 12 blocks
2021-12-08 10:35:19,109 [Executor task launch worker for task 86] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 12 blocks
2021-12-08 10:35:19,109 [Executor task launch worker for task 91] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 12 blocks
2021-12-08 10:35:19,109 [Executor task launch worker for task 84] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-08 10:35:19,109 [Executor task launch worker for task 91] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-08 10:35:19,109 [Executor task launch worker for task 88] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 12 blocks
2021-12-08 10:35:19,109 [Executor task launch worker for task 90] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 12 blocks
2021-12-08 10:35:19,109 [Executor task launch worker for task 88] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-08 10:35:19,110 [Executor task launch worker for task 87] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 12 blocks
2021-12-08 10:35:19,110 [Executor task launch worker for task 87] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-08 10:35:19,109 [Executor task launch worker for task 86] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-08 10:35:19,109 [Executor task launch worker for task 90] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-08 10:35:19,292 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 132
2021-12-08 10:35:19,292 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 194
2021-12-08 10:35:19,292 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 184
2021-12-08 10:35:19,292 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 187
2021-12-08 10:35:19,292 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 192
2021-12-08 10:35:19,339 [dispatcher-event-loop-6] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_9_piece0 on qb:55657 in memory (size: 4.2 KB, free: 1669.5 MB)
2021-12-08 10:35:19,356 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 199
2021-12-08 10:35:19,356 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 183
2021-12-08 10:35:19,356 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 176
2021-12-08 10:35:19,356 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 195
2021-12-08 10:35:19,356 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 177
2021-12-08 10:35:19,356 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 175
2021-12-08 10:35:19,356 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 197
2021-12-08 10:35:19,356 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 196
2021-12-08 10:35:19,356 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 193
2021-12-08 10:35:19,360 [dispatcher-event-loop-3] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_8_piece0 on qb:55657 in memory (size: 5.3 KB, free: 1669.5 MB)
2021-12-08 10:35:19,364 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 189
2021-12-08 10:35:19,364 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 178
2021-12-08 10:35:19,364 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 198
2021-12-08 10:35:19,364 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 181
2021-12-08 10:35:19,364 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 190
2021-12-08 10:35:19,365 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 188
2021-12-08 10:35:19,365 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 180
2021-12-08 10:35:19,365 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 191
2021-12-08 10:35:19,365 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 179
2021-12-08 10:35:19,365 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 186
2021-12-08 10:35:19,365 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 185
2021-12-08 10:35:19,365 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 182
2021-12-08 10:35:19,365 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 144
2021-12-08 10:35:19,365 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 75
2021-12-08 10:35:19,365 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 124
2021-12-08 10:35:19,365 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 157
2021-12-08 10:35:19,365 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 115
2021-12-08 10:35:19,365 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 93
2021-12-08 10:35:19,365 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 174
2021-12-08 10:35:19,365 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 81
2021-12-08 10:35:19,365 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 66
2021-12-08 10:35:19,365 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 129
2021-12-08 10:35:19,365 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 159
2021-12-08 10:35:19,365 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 103
2021-12-08 10:35:19,365 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 105
2021-12-08 10:35:19,366 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 86
2021-12-08 10:35:19,366 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 68
2021-12-08 10:35:19,366 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 73
2021-12-08 10:35:19,366 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 91
2021-12-08 10:35:19,366 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 61
2021-12-08 10:35:19,366 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 165
2021-12-08 10:35:19,366 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 62
2021-12-08 10:35:19,366 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 60
2021-12-08 10:35:19,366 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 87
2021-12-08 10:35:19,366 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 97
2021-12-08 10:35:19,366 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 100
2021-12-08 10:35:19,366 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 170
2021-12-08 10:35:19,366 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 125
2021-12-08 10:35:19,366 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 152
2021-12-08 10:35:19,366 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 156
2021-12-08 10:35:19,366 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 50
2021-12-08 10:35:19,366 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 111
2021-12-08 10:35:19,366 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 169
2021-12-08 10:35:19,366 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 54
2021-12-08 10:35:19,366 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 139
2021-12-08 10:35:19,366 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 137
2021-12-08 10:35:19,366 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 126
2021-12-08 10:35:19,366 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 168
2021-12-08 10:35:19,366 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 79
2021-12-08 10:35:19,366 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 76
2021-12-08 10:35:19,366 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 84
2021-12-08 10:35:19,366 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 128
2021-12-08 10:35:19,366 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 89
2021-12-08 10:35:19,366 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 127
2021-12-08 10:35:19,366 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 162
2021-12-08 10:35:19,366 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 134
2021-12-08 10:35:19,366 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 104
2021-12-08 10:35:19,366 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 101
2021-12-08 10:35:19,366 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 143
2021-12-08 10:35:19,367 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 158
2021-12-08 10:35:19,367 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 173
2021-12-08 10:35:19,367 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 116
2021-12-08 10:35:19,367 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 163
2021-12-08 10:35:19,367 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 147
2021-12-08 10:35:19,367 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 107
2021-12-08 10:35:19,367 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 102
2021-12-08 10:35:19,367 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 58
2021-12-08 10:35:19,367 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 71
2021-12-08 10:35:19,367 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 155
2021-12-08 10:35:19,367 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 78
2021-12-08 10:35:19,367 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 151
2021-12-08 10:35:19,367 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 57
2021-12-08 10:35:19,367 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 171
2021-12-08 10:35:19,367 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 77
2021-12-08 10:35:19,367 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 70
2021-12-08 10:35:19,367 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 95
2021-12-08 10:35:19,367 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 146
2021-12-08 10:35:19,368 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 55
2021-12-08 10:35:19,368 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 114
2021-12-08 10:35:19,368 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 164
2021-12-08 10:35:19,368 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 112
2021-12-08 10:35:19,368 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 88
2021-12-08 10:35:19,368 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 121
2021-12-08 10:35:19,368 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 145
2021-12-08 10:35:19,368 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 83
2021-12-08 10:35:19,368 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 56
2021-12-08 10:35:19,368 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 118
2021-12-08 10:35:19,368 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 141
2021-12-08 10:35:19,368 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 80
2021-12-08 10:35:19,368 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 98
2021-12-08 10:35:19,368 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 108
2021-12-08 10:35:19,368 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 120
2021-12-08 10:35:19,368 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 160
2021-12-08 10:35:19,368 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 119
2021-12-08 10:35:19,369 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 113
2021-12-08 10:35:19,369 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 110
2021-12-08 10:35:19,369 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 154
2021-12-08 10:35:19,369 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 74
2021-12-08 10:35:19,369 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 153
2021-12-08 10:35:19,369 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 172
2021-12-08 10:35:19,369 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 109
2021-12-08 10:35:19,369 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 63
2021-12-08 10:35:19,369 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 133
2021-12-08 10:35:19,371 [dispatcher-event-loop-0] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_6_piece0 on qb:55657 in memory (size: 4.0 KB, free: 1669.5 MB)
2021-12-08 10:35:19,372 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 65
2021-12-08 10:35:19,372 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 106
2021-12-08 10:35:19,372 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 94
2021-12-08 10:35:19,372 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 85
2021-12-08 10:35:19,372 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 96
2021-12-08 10:35:19,372 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 135
2021-12-08 10:35:19,372 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 148
2021-12-08 10:35:19,372 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 53
2021-12-08 10:35:19,372 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 117
2021-12-08 10:35:19,372 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 138
2021-12-08 10:35:19,372 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 82
2021-12-08 10:35:19,372 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 123
2021-12-08 10:35:19,375 [dispatcher-event-loop-10] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_5_piece0 on qb:55657 in memory (size: 4.2 KB, free: 1669.5 MB)
2021-12-08 10:35:19,376 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 149
2021-12-08 10:35:19,377 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 52
2021-12-08 10:35:19,377 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 92
2021-12-08 10:35:19,377 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 90
2021-12-08 10:35:19,377 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 59
2021-12-08 10:35:19,377 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 67
2021-12-08 10:35:19,377 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 99
2021-12-08 10:35:19,377 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 131
2021-12-08 10:35:19,377 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 166
2021-12-08 10:35:19,377 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 140
2021-12-08 10:35:19,377 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 72
2021-12-08 10:35:19,377 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 51
2021-12-08 10:35:19,380 [dispatcher-event-loop-6] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_7_piece0 on qb:55657 in memory (size: 4.2 KB, free: 1669.5 MB)
2021-12-08 10:35:19,386 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 136
2021-12-08 10:35:19,386 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 150
2021-12-08 10:35:19,386 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 142
2021-12-08 10:35:19,386 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 167
2021-12-08 10:35:19,386 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 69
2021-12-08 10:35:19,386 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 122
2021-12-08 10:35:19,386 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 64
2021-12-08 10:35:19,386 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 161
2021-12-08 10:35:19,386 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 130
2021-12-08 10:35:20,775 [Executor task launch worker for task 91] INFO [org.apache.spark.executor.Executor] - Finished task 11.0 in stage 15.0 (TID 91). 1343 bytes result sent to driver
2021-12-08 10:35:20,776 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 11.0 in stage 15.0 (TID 91) in 1671 ms on localhost (executor driver) (1/12)
2021-12-08 10:35:20,838 [Executor task launch worker for task 90] INFO [org.apache.spark.executor.Executor] - Finished task 10.0 in stage 15.0 (TID 90). 1343 bytes result sent to driver
2021-12-08 10:35:20,839 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 10.0 in stage 15.0 (TID 90) in 1734 ms on localhost (executor driver) (2/12)
2021-12-08 10:35:20,841 [Executor task launch worker for task 88] INFO [org.apache.spark.executor.Executor] - Finished task 8.0 in stage 15.0 (TID 88). 1386 bytes result sent to driver
2021-12-08 10:35:20,841 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 8.0 in stage 15.0 (TID 88) in 1736 ms on localhost (executor driver) (3/12)
2021-12-08 10:35:20,894 [Executor task launch worker for task 84] INFO [org.apache.spark.executor.Executor] - Finished task 4.0 in stage 15.0 (TID 84). 1343 bytes result sent to driver
2021-12-08 10:35:20,895 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 4.0 in stage 15.0 (TID 84) in 1790 ms on localhost (executor driver) (4/12)
2021-12-08 10:35:20,896 [Executor task launch worker for task 80] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 15.0 (TID 80). 1343 bytes result sent to driver
2021-12-08 10:35:20,897 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 15.0 (TID 80) in 1795 ms on localhost (executor driver) (5/12)
2021-12-08 10:35:21,314 [Executor task launch worker for task 85] INFO [org.apache.spark.executor.Executor] - Finished task 5.0 in stage 15.0 (TID 85). 1343 bytes result sent to driver
2021-12-08 10:35:21,315 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 5.0 in stage 15.0 (TID 85) in 2210 ms on localhost (executor driver) (6/12)
2021-12-08 10:35:21,579 [Executor task launch worker for task 82] INFO [org.apache.spark.executor.Executor] - Finished task 2.0 in stage 15.0 (TID 82). 1343 bytes result sent to driver
2021-12-08 10:35:21,579 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 2.0 in stage 15.0 (TID 82) in 2475 ms on localhost (executor driver) (7/12)
2021-12-08 10:35:21,998 [Executor task launch worker for task 87] INFO [org.apache.spark.executor.Executor] - Finished task 7.0 in stage 15.0 (TID 87). 1343 bytes result sent to driver
2021-12-08 10:35:21,998 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 7.0 in stage 15.0 (TID 87) in 2893 ms on localhost (executor driver) (8/12)
2021-12-08 10:35:21,999 [Executor task launch worker for task 89] INFO [org.apache.spark.executor.Executor] - Finished task 9.0 in stage 15.0 (TID 89). 1343 bytes result sent to driver
2021-12-08 10:35:21,999 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 9.0 in stage 15.0 (TID 89) in 2894 ms on localhost (executor driver) (9/12)
2021-12-08 10:35:22,190 [Executor task launch worker for task 81] INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 15.0 (TID 81). 1343 bytes result sent to driver
2021-12-08 10:35:22,191 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 15.0 (TID 81) in 3087 ms on localhost (executor driver) (10/12)
2021-12-08 10:35:22,191 [Executor task launch worker for task 86] INFO [org.apache.spark.executor.Executor] - Finished task 6.0 in stage 15.0 (TID 86). 1343 bytes result sent to driver
2021-12-08 10:35:22,192 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 6.0 in stage 15.0 (TID 86) in 3087 ms on localhost (executor driver) (11/12)
2021-12-08 10:35:22,193 [Executor task launch worker for task 83] INFO [org.apache.spark.executor.Executor] - Finished task 3.0 in stage 15.0 (TID 83). 1343 bytes result sent to driver
2021-12-08 10:35:22,193 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 3.0 in stage 15.0 (TID 83) in 3089 ms on localhost (executor driver) (12/12)
2021-12-08 10:35:22,193 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 15.0, whose tasks have all completed, from pool 
2021-12-08 10:35:22,193 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ShuffleMapStage 15 (flatMap at ALS.scala:1653) finished in 3.095 s
2021-12-08 10:35:22,193 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - looking for newly runnable stages
2021-12-08 10:35:22,193 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - running: Set()
2021-12-08 10:35:22,193 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - waiting: Set(ResultStage 16)
2021-12-08 10:35:22,193 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - failed: Set()
2021-12-08 10:35:22,194 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 16 (MapPartitionsRDD[28] at values at ALS.scala:1711), which has no missing parents
2021-12-08 10:35:22,196 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_11 stored as values in memory (estimated size 332.3 KB, free 1668.8 MB)
2021-12-08 10:35:22,197 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_11_piece0 stored as bytes in memory (estimated size 163.9 KB, free 1668.7 MB)
2021-12-08 10:35:22,197 [dispatcher-event-loop-3] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_11_piece0 in memory on qb:55657 (size: 163.9 KB, free: 1669.3 MB)
2021-12-08 10:35:22,198 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 11 from broadcast at DAGScheduler.scala:1039
2021-12-08 10:35:22,198 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 12 missing tasks from ResultStage 16 (MapPartitionsRDD[28] at values at ALS.scala:1711) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11))
2021-12-08 10:35:22,198 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 16.0 with 12 tasks
2021-12-08 10:35:22,199 [dispatcher-event-loop-11] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 16.0 (TID 92, localhost, executor driver, partition 0, PROCESS_LOCAL, 7888 bytes)
2021-12-08 10:35:22,199 [dispatcher-event-loop-11] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 16.0 (TID 93, localhost, executor driver, partition 1, PROCESS_LOCAL, 7888 bytes)
2021-12-08 10:35:22,199 [dispatcher-event-loop-11] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 2.0 in stage 16.0 (TID 94, localhost, executor driver, partition 2, PROCESS_LOCAL, 7888 bytes)
2021-12-08 10:35:22,200 [dispatcher-event-loop-11] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 3.0 in stage 16.0 (TID 95, localhost, executor driver, partition 3, PROCESS_LOCAL, 7888 bytes)
2021-12-08 10:35:22,200 [dispatcher-event-loop-11] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 4.0 in stage 16.0 (TID 96, localhost, executor driver, partition 4, PROCESS_LOCAL, 7888 bytes)
2021-12-08 10:35:22,200 [dispatcher-event-loop-11] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 5.0 in stage 16.0 (TID 97, localhost, executor driver, partition 5, PROCESS_LOCAL, 7888 bytes)
2021-12-08 10:35:22,200 [dispatcher-event-loop-11] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 6.0 in stage 16.0 (TID 98, localhost, executor driver, partition 6, PROCESS_LOCAL, 7888 bytes)
2021-12-08 10:35:22,200 [dispatcher-event-loop-11] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 7.0 in stage 16.0 (TID 99, localhost, executor driver, partition 7, PROCESS_LOCAL, 7888 bytes)
2021-12-08 10:35:22,200 [dispatcher-event-loop-11] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 8.0 in stage 16.0 (TID 100, localhost, executor driver, partition 8, PROCESS_LOCAL, 7888 bytes)
2021-12-08 10:35:22,200 [dispatcher-event-loop-11] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 9.0 in stage 16.0 (TID 101, localhost, executor driver, partition 9, PROCESS_LOCAL, 7888 bytes)
2021-12-08 10:35:22,201 [dispatcher-event-loop-11] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 10.0 in stage 16.0 (TID 102, localhost, executor driver, partition 10, PROCESS_LOCAL, 7888 bytes)
2021-12-08 10:35:22,201 [dispatcher-event-loop-11] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 11.0 in stage 16.0 (TID 103, localhost, executor driver, partition 11, PROCESS_LOCAL, 7888 bytes)
2021-12-08 10:35:22,201 [Executor task launch worker for task 92] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 16.0 (TID 92)
2021-12-08 10:35:22,201 [Executor task launch worker for task 93] INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 16.0 (TID 93)
2021-12-08 10:35:22,201 [Executor task launch worker for task 101] INFO [org.apache.spark.executor.Executor] - Running task 9.0 in stage 16.0 (TID 101)
2021-12-08 10:35:22,201 [Executor task launch worker for task 100] INFO [org.apache.spark.executor.Executor] - Running task 8.0 in stage 16.0 (TID 100)
2021-12-08 10:35:22,201 [Executor task launch worker for task 102] INFO [org.apache.spark.executor.Executor] - Running task 10.0 in stage 16.0 (TID 102)
2021-12-08 10:35:22,201 [Executor task launch worker for task 103] INFO [org.apache.spark.executor.Executor] - Running task 11.0 in stage 16.0 (TID 103)
2021-12-08 10:35:22,201 [Executor task launch worker for task 99] INFO [org.apache.spark.executor.Executor] - Running task 7.0 in stage 16.0 (TID 99)
2021-12-08 10:35:22,201 [Executor task launch worker for task 98] INFO [org.apache.spark.executor.Executor] - Running task 6.0 in stage 16.0 (TID 98)
2021-12-08 10:35:22,201 [Executor task launch worker for task 95] INFO [org.apache.spark.executor.Executor] - Running task 3.0 in stage 16.0 (TID 95)
2021-12-08 10:35:22,201 [Executor task launch worker for task 94] INFO [org.apache.spark.executor.Executor] - Running task 2.0 in stage 16.0 (TID 94)
2021-12-08 10:35:22,201 [Executor task launch worker for task 97] INFO [org.apache.spark.executor.Executor] - Running task 5.0 in stage 16.0 (TID 97)
2021-12-08 10:35:22,201 [Executor task launch worker for task 96] INFO [org.apache.spark.executor.Executor] - Running task 4.0 in stage 16.0 (TID 96)
2021-12-08 10:35:22,203 [Executor task launch worker for task 103] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_14_11 locally
2021-12-08 10:35:22,203 [Executor task launch worker for task 101] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_14_9 locally
2021-12-08 10:35:22,204 [Executor task launch worker for task 95] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_14_3 locally
2021-12-08 10:35:22,204 [Executor task launch worker for task 97] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_14_5 locally
2021-12-08 10:35:22,203 [Executor task launch worker for task 100] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_14_8 locally
2021-12-08 10:35:22,204 [Executor task launch worker for task 103] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 12 non-empty blocks out of 12 blocks
2021-12-08 10:35:22,204 [Executor task launch worker for task 95] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 12 non-empty blocks out of 12 blocks
2021-12-08 10:35:22,204 [Executor task launch worker for task 103] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-08 10:35:22,204 [Executor task launch worker for task 102] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_14_10 locally
2021-12-08 10:35:22,204 [Executor task launch worker for task 98] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_14_6 locally
2021-12-08 10:35:22,204 [Executor task launch worker for task 102] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 12 non-empty blocks out of 12 blocks
2021-12-08 10:35:22,204 [Executor task launch worker for task 102] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-08 10:35:22,204 [Executor task launch worker for task 98] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 12 non-empty blocks out of 12 blocks
2021-12-08 10:35:22,204 [Executor task launch worker for task 98] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-08 10:35:22,204 [Executor task launch worker for task 101] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 12 non-empty blocks out of 12 blocks
2021-12-08 10:35:22,204 [Executor task launch worker for task 101] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-08 10:35:22,204 [Executor task launch worker for task 97] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 12 non-empty blocks out of 12 blocks
2021-12-08 10:35:22,204 [Executor task launch worker for task 95] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-08 10:35:22,205 [Executor task launch worker for task 97] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 1 ms
2021-12-08 10:35:22,204 [Executor task launch worker for task 96] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_14_4 locally
2021-12-08 10:35:22,205 [Executor task launch worker for task 92] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_14_0 locally
2021-12-08 10:35:22,205 [Executor task launch worker for task 100] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 12 non-empty blocks out of 12 blocks
2021-12-08 10:35:22,205 [Executor task launch worker for task 100] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-08 10:35:22,205 [Executor task launch worker for task 93] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_14_1 locally
2021-12-08 10:35:22,205 [Executor task launch worker for task 99] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_14_7 locally
2021-12-08 10:35:22,205 [Executor task launch worker for task 94] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_14_2 locally
2021-12-08 10:35:22,205 [Executor task launch worker for task 96] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 12 non-empty blocks out of 12 blocks
2021-12-08 10:35:22,205 [Executor task launch worker for task 93] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 12 non-empty blocks out of 12 blocks
2021-12-08 10:35:22,205 [Executor task launch worker for task 96] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-08 10:35:22,205 [Executor task launch worker for task 93] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-08 10:35:22,205 [Executor task launch worker for task 92] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 12 non-empty blocks out of 12 blocks
2021-12-08 10:35:22,205 [Executor task launch worker for task 92] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-08 10:35:22,205 [Executor task launch worker for task 99] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 12 non-empty blocks out of 12 blocks
2021-12-08 10:35:22,205 [Executor task launch worker for task 99] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-08 10:35:22,205 [Executor task launch worker for task 94] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 12 non-empty blocks out of 12 blocks
2021-12-08 10:35:22,205 [Executor task launch worker for task 94] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-08 10:35:22,852 [dispatcher-event-loop-4] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_10_piece0 on qb:55657 in memory (size: 4.5 KB, free: 1669.3 MB)
2021-12-08 10:35:22,997 [Executor task launch worker for task 95] WARN [com.github.fommil.netlib.LAPACK] - Failed to load implementation from: com.github.fommil.netlib.NativeSystemLAPACK
2021-12-08 10:35:22,998 [Executor task launch worker for task 95] WARN [com.github.fommil.netlib.LAPACK] - Failed to load implementation from: com.github.fommil.netlib.NativeRefLAPACK
2021-12-08 10:35:43,994 [Executor task launch worker for task 93] INFO [org.apache.spark.storage.memory.MemoryStore] - Block rdd_27_1 stored as values in memory (estimated size 4.0 MB, free 1664.7 MB)
2021-12-08 10:35:43,994 [dispatcher-event-loop-6] INFO [org.apache.spark.storage.BlockManagerInfo] - Added rdd_27_1 in memory on qb:55657 (size: 4.0 MB, free: 1665.3 MB)
2021-12-08 10:35:44,084 [Executor task launch worker for task 97] INFO [org.apache.spark.storage.memory.MemoryStore] - Block rdd_27_5 stored as values in memory (estimated size 4.0 MB, free 1660.7 MB)
2021-12-08 10:35:44,085 [dispatcher-event-loop-8] INFO [org.apache.spark.storage.BlockManagerInfo] - Added rdd_27_5 in memory on qb:55657 (size: 4.0 MB, free: 1661.3 MB)
2021-12-08 10:35:44,158 [Executor task launch worker for task 93] INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 16.0 (TID 93). 166097 bytes result sent to driver
2021-12-08 10:35:44,159 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 16.0 (TID 93) in 21960 ms on localhost (executor driver) (1/12)
2021-12-08 10:35:44,227 [Executor task launch worker for task 97] INFO [org.apache.spark.executor.Executor] - Finished task 5.0 in stage 16.0 (TID 97). 166054 bytes result sent to driver
2021-12-08 10:35:44,228 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 5.0 in stage 16.0 (TID 97) in 22028 ms on localhost (executor driver) (2/12)
2021-12-08 10:35:45,279 [Executor task launch worker for task 92] INFO [org.apache.spark.storage.memory.MemoryStore] - Block rdd_27_0 stored as values in memory (estimated size 4.0 MB, free 1656.7 MB)
2021-12-08 10:35:45,279 [dispatcher-event-loop-11] INFO [org.apache.spark.storage.BlockManagerInfo] - Added rdd_27_0 in memory on qb:55657 (size: 4.0 MB, free: 1657.4 MB)
2021-12-08 10:35:45,410 [Executor task launch worker for task 92] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 16.0 (TID 92). 166097 bytes result sent to driver
2021-12-08 10:35:45,411 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 16.0 (TID 92) in 23212 ms on localhost (executor driver) (3/12)
2021-12-08 10:35:45,487 [Executor task launch worker for task 100] INFO [org.apache.spark.storage.memory.MemoryStore] - Block rdd_27_8 stored as values in memory (estimated size 4.0 MB, free 1652.7 MB)
2021-12-08 10:35:45,487 [dispatcher-event-loop-7] INFO [org.apache.spark.storage.BlockManagerInfo] - Added rdd_27_8 in memory on qb:55657 (size: 4.0 MB, free: 1653.4 MB)
2021-12-08 10:35:45,609 [Executor task launch worker for task 100] INFO [org.apache.spark.executor.Executor] - Finished task 8.0 in stage 16.0 (TID 100). 166054 bytes result sent to driver
2021-12-08 10:35:45,610 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 8.0 in stage 16.0 (TID 100) in 23410 ms on localhost (executor driver) (4/12)
2021-12-08 10:35:46,455 [Executor task launch worker for task 99] INFO [org.apache.spark.storage.memory.MemoryStore] - Block rdd_27_7 stored as values in memory (estimated size 4.0 MB, free 1648.8 MB)
2021-12-08 10:35:46,459 [dispatcher-event-loop-10] INFO [org.apache.spark.storage.BlockManagerInfo] - Added rdd_27_7 in memory on qb:55657 (size: 4.0 MB, free: 1649.4 MB)
2021-12-08 10:35:46,527 [Executor task launch worker for task 96] INFO [org.apache.spark.storage.memory.MemoryStore] - Block rdd_27_4 stored as values in memory (estimated size 4.0 MB, free 1644.8 MB)
2021-12-08 10:35:46,528 [dispatcher-event-loop-2] INFO [org.apache.spark.storage.BlockManagerInfo] - Added rdd_27_4 in memory on qb:55657 (size: 4.0 MB, free: 1645.4 MB)
2021-12-08 10:35:46,581 [Executor task launch worker for task 99] INFO [org.apache.spark.executor.Executor] - Finished task 7.0 in stage 16.0 (TID 99). 166054 bytes result sent to driver
2021-12-08 10:35:46,583 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 7.0 in stage 16.0 (TID 99) in 24383 ms on localhost (executor driver) (5/12)
2021-12-08 10:35:46,603 [Executor task launch worker for task 102] INFO [org.apache.spark.storage.memory.MemoryStore] - Block rdd_27_10 stored as values in memory (estimated size 4.0 MB, free 1640.8 MB)
2021-12-08 10:35:46,603 [dispatcher-event-loop-0] INFO [org.apache.spark.storage.BlockManagerInfo] - Added rdd_27_10 in memory on qb:55657 (size: 4.0 MB, free: 1641.4 MB)
2021-12-08 10:35:46,647 [Executor task launch worker for task 96] INFO [org.apache.spark.executor.Executor] - Finished task 4.0 in stage 16.0 (TID 96). 166054 bytes result sent to driver
2021-12-08 10:35:46,648 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 4.0 in stage 16.0 (TID 96) in 24448 ms on localhost (executor driver) (6/12)
2021-12-08 10:35:46,727 [Executor task launch worker for task 102] INFO [org.apache.spark.executor.Executor] - Finished task 10.0 in stage 16.0 (TID 102). 166054 bytes result sent to driver
2021-12-08 10:35:46,738 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 10.0 in stage 16.0 (TID 102) in 24538 ms on localhost (executor driver) (7/12)
2021-12-08 10:35:47,023 [Executor task launch worker for task 103] INFO [org.apache.spark.storage.memory.MemoryStore] - Block rdd_27_11 stored as values in memory (estimated size 4.0 MB, free 1636.8 MB)
2021-12-08 10:35:47,024 [dispatcher-event-loop-9] INFO [org.apache.spark.storage.BlockManagerInfo] - Added rdd_27_11 in memory on qb:55657 (size: 4.0 MB, free: 1637.4 MB)
2021-12-08 10:35:47,118 [Executor task launch worker for task 103] INFO [org.apache.spark.executor.Executor] - Finished task 11.0 in stage 16.0 (TID 103). 166054 bytes result sent to driver
2021-12-08 10:35:47,118 [Executor task launch worker for task 98] INFO [org.apache.spark.storage.memory.MemoryStore] - Block rdd_27_6 stored as values in memory (estimated size 4.0 MB, free 1632.8 MB)
2021-12-08 10:35:47,118 [dispatcher-event-loop-11] INFO [org.apache.spark.storage.BlockManagerInfo] - Added rdd_27_6 in memory on qb:55657 (size: 4.0 MB, free: 1633.4 MB)
2021-12-08 10:35:47,119 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 11.0 in stage 16.0 (TID 103) in 24918 ms on localhost (executor driver) (8/12)
2021-12-08 10:35:47,216 [Executor task launch worker for task 98] INFO [org.apache.spark.executor.Executor] - Finished task 6.0 in stage 16.0 (TID 98). 166097 bytes result sent to driver
2021-12-08 10:35:47,217 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 6.0 in stage 16.0 (TID 98) in 25017 ms on localhost (executor driver) (9/12)
2021-12-08 10:35:47,705 [Executor task launch worker for task 94] INFO [org.apache.spark.storage.memory.MemoryStore] - Block rdd_27_2 stored as values in memory (estimated size 4.0 MB, free 1628.8 MB)
2021-12-08 10:35:47,706 [dispatcher-event-loop-7] INFO [org.apache.spark.storage.BlockManagerInfo] - Added rdd_27_2 in memory on qb:55657 (size: 4.0 MB, free: 1629.4 MB)
2021-12-08 10:35:47,780 [Executor task launch worker for task 94] INFO [org.apache.spark.executor.Executor] - Finished task 2.0 in stage 16.0 (TID 94). 166054 bytes result sent to driver
2021-12-08 10:35:47,780 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 2.0 in stage 16.0 (TID 94) in 25581 ms on localhost (executor driver) (10/12)
2021-12-08 10:35:48,026 [Executor task launch worker for task 101] INFO [org.apache.spark.storage.memory.MemoryStore] - Block rdd_27_9 stored as values in memory (estimated size 4.0 MB, free 1624.8 MB)
2021-12-08 10:35:48,026 [dispatcher-event-loop-10] INFO [org.apache.spark.storage.BlockManagerInfo] - Added rdd_27_9 in memory on qb:55657 (size: 4.0 MB, free: 1625.5 MB)
2021-12-08 10:35:48,047 [Executor task launch worker for task 95] INFO [org.apache.spark.storage.memory.MemoryStore] - Block rdd_27_3 stored as values in memory (estimated size 4.0 MB, free 1620.8 MB)
2021-12-08 10:35:48,048 [dispatcher-event-loop-2] INFO [org.apache.spark.storage.BlockManagerInfo] - Added rdd_27_3 in memory on qb:55657 (size: 4.0 MB, free: 1621.5 MB)
2021-12-08 10:35:48,089 [Executor task launch worker for task 101] INFO [org.apache.spark.executor.Executor] - Finished task 9.0 in stage 16.0 (TID 101). 166054 bytes result sent to driver
2021-12-08 10:35:48,090 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 9.0 in stage 16.0 (TID 101) in 25890 ms on localhost (executor driver) (11/12)
2021-12-08 10:35:48,110 [Executor task launch worker for task 95] INFO [org.apache.spark.executor.Executor] - Finished task 3.0 in stage 16.0 (TID 95). 166054 bytes result sent to driver
2021-12-08 10:35:48,111 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 3.0 in stage 16.0 (TID 95) in 25911 ms on localhost (executor driver) (12/12)
2021-12-08 10:35:48,111 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 16.0, whose tasks have all completed, from pool 
2021-12-08 10:35:48,111 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 16 (aggregate at ALS.scala:1711) finished in 25.917 s
2021-12-08 10:35:48,111 [main] INFO [org.apache.spark.scheduler.DAGScheduler] - Job 5 finished: aggregate at ALS.scala:1711, took 29.169137 s
2021-12-08 10:35:48,128 [main] INFO [org.apache.spark.rdd.MapPartitionsRDD] - Removing RDD 16 from persistence list
2021-12-08 10:35:48,130 [block-manager-slave-async-thread-pool-2] INFO [org.apache.spark.storage.BlockManager] - Removing RDD 16
2021-12-08 10:35:48,137 [main] INFO [org.apache.spark.SparkContext] - Starting job: aggregate at ALS.scala:1711
2021-12-08 10:35:48,138 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 32 (flatMap at ALS.scala:1653)
2021-12-08 10:35:48,138 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 6 (aggregate at ALS.scala:1711) with 12 output partitions
2021-12-08 10:35:48,138 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 23 (aggregate at ALS.scala:1711)
2021-12-08 10:35:48,138 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 18, ShuffleMapStage 22)
2021-12-08 10:35:48,139 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List(ShuffleMapStage 22)
2021-12-08 10:35:48,139 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ShuffleMapStage 22 (MapPartitionsRDD[32] at flatMap at ALS.scala:1653), which has no missing parents
2021-12-08 10:35:48,140 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_12 stored as values in memory (estimated size 171.9 KB, free 1753.9 MB)
2021-12-08 10:35:48,142 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_12_piece0 stored as bytes in memory (estimated size 162.9 KB, free 1753.8 MB)
2021-12-08 10:35:48,142 [dispatcher-event-loop-7] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_12_piece0 in memory on qb:55657 (size: 162.9 KB, free: 1754.6 MB)
2021-12-08 10:35:48,143 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 12 from broadcast at DAGScheduler.scala:1039
2021-12-08 10:35:48,143 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 12 missing tasks from ShuffleMapStage 22 (MapPartitionsRDD[32] at flatMap at ALS.scala:1653) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11))
2021-12-08 10:35:48,143 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 22.0 with 12 tasks
2021-12-08 10:35:48,143 [dispatcher-event-loop-4] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 22.0 (TID 104, localhost, executor driver, partition 0, PROCESS_LOCAL, 7928 bytes)
2021-12-08 10:35:48,144 [dispatcher-event-loop-4] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 22.0 (TID 105, localhost, executor driver, partition 1, PROCESS_LOCAL, 7928 bytes)
2021-12-08 10:35:48,144 [dispatcher-event-loop-4] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 2.0 in stage 22.0 (TID 106, localhost, executor driver, partition 2, PROCESS_LOCAL, 7928 bytes)
2021-12-08 10:35:48,144 [dispatcher-event-loop-4] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 3.0 in stage 22.0 (TID 107, localhost, executor driver, partition 3, PROCESS_LOCAL, 7928 bytes)
2021-12-08 10:35:48,144 [dispatcher-event-loop-4] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 4.0 in stage 22.0 (TID 108, localhost, executor driver, partition 4, PROCESS_LOCAL, 7928 bytes)
2021-12-08 10:35:48,144 [dispatcher-event-loop-4] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 5.0 in stage 22.0 (TID 109, localhost, executor driver, partition 5, PROCESS_LOCAL, 7928 bytes)
2021-12-08 10:35:48,144 [dispatcher-event-loop-4] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 6.0 in stage 22.0 (TID 110, localhost, executor driver, partition 6, PROCESS_LOCAL, 7928 bytes)
2021-12-08 10:35:48,144 [dispatcher-event-loop-4] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 7.0 in stage 22.0 (TID 111, localhost, executor driver, partition 7, PROCESS_LOCAL, 7928 bytes)
2021-12-08 10:35:48,144 [dispatcher-event-loop-4] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 8.0 in stage 22.0 (TID 112, localhost, executor driver, partition 8, PROCESS_LOCAL, 7928 bytes)
2021-12-08 10:35:48,144 [dispatcher-event-loop-4] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 9.0 in stage 22.0 (TID 113, localhost, executor driver, partition 9, PROCESS_LOCAL, 7928 bytes)
2021-12-08 10:35:48,144 [dispatcher-event-loop-4] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 10.0 in stage 22.0 (TID 114, localhost, executor driver, partition 10, PROCESS_LOCAL, 7928 bytes)
2021-12-08 10:35:48,144 [dispatcher-event-loop-4] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 11.0 in stage 22.0 (TID 115, localhost, executor driver, partition 11, PROCESS_LOCAL, 7928 bytes)
2021-12-08 10:35:48,144 [Executor task launch worker for task 104] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 22.0 (TID 104)
2021-12-08 10:35:48,144 [Executor task launch worker for task 108] INFO [org.apache.spark.executor.Executor] - Running task 4.0 in stage 22.0 (TID 108)
2021-12-08 10:35:48,144 [Executor task launch worker for task 111] INFO [org.apache.spark.executor.Executor] - Running task 7.0 in stage 22.0 (TID 111)
2021-12-08 10:35:48,144 [Executor task launch worker for task 105] INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 22.0 (TID 105)
2021-12-08 10:35:48,144 [Executor task launch worker for task 107] INFO [org.apache.spark.executor.Executor] - Running task 3.0 in stage 22.0 (TID 107)
2021-12-08 10:35:48,144 [Executor task launch worker for task 109] INFO [org.apache.spark.executor.Executor] - Running task 5.0 in stage 22.0 (TID 109)
2021-12-08 10:35:48,144 [Executor task launch worker for task 106] INFO [org.apache.spark.executor.Executor] - Running task 2.0 in stage 22.0 (TID 106)
2021-12-08 10:35:48,144 [Executor task launch worker for task 114] INFO [org.apache.spark.executor.Executor] - Running task 10.0 in stage 22.0 (TID 114)
2021-12-08 10:35:48,144 [Executor task launch worker for task 115] INFO [org.apache.spark.executor.Executor] - Running task 11.0 in stage 22.0 (TID 115)
2021-12-08 10:35:48,144 [Executor task launch worker for task 113] INFO [org.apache.spark.executor.Executor] - Running task 9.0 in stage 22.0 (TID 113)
2021-12-08 10:35:48,144 [Executor task launch worker for task 110] INFO [org.apache.spark.executor.Executor] - Running task 6.0 in stage 22.0 (TID 110)
2021-12-08 10:35:48,146 [Executor task launch worker for task 110] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_15_6 locally
2021-12-08 10:35:48,146 [Executor task launch worker for task 110] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_27_6 locally
2021-12-08 10:35:48,146 [Executor task launch worker for task 114] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_15_10 locally
2021-12-08 10:35:48,146 [Executor task launch worker for task 104] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_15_0 locally
2021-12-08 10:35:48,146 [Executor task launch worker for task 107] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_15_3 locally
2021-12-08 10:35:48,146 [Executor task launch worker for task 113] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_15_9 locally
2021-12-08 10:35:48,147 [Executor task launch worker for task 107] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_27_3 locally
2021-12-08 10:35:48,146 [Executor task launch worker for task 115] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_15_11 locally
2021-12-08 10:35:48,147 [Executor task launch worker for task 115] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_27_11 locally
2021-12-08 10:35:48,147 [Executor task launch worker for task 114] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_27_10 locally
2021-12-08 10:35:48,146 [Executor task launch worker for task 104] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_27_0 locally
2021-12-08 10:35:48,146 [Executor task launch worker for task 106] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_15_2 locally
2021-12-08 10:35:48,147 [Executor task launch worker for task 106] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_27_2 locally
2021-12-08 10:35:48,147 [Executor task launch worker for task 109] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_15_5 locally
2021-12-08 10:35:48,147 [Executor task launch worker for task 113] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_27_9 locally
2021-12-08 10:35:48,147 [Executor task launch worker for task 105] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_15_1 locally
2021-12-08 10:35:48,147 [Executor task launch worker for task 105] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_27_1 locally
2021-12-08 10:35:48,150 [Executor task launch worker for task 112] INFO [org.apache.spark.executor.Executor] - Running task 8.0 in stage 22.0 (TID 112)
2021-12-08 10:35:48,152 [Executor task launch worker for task 112] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_15_8 locally
2021-12-08 10:35:48,153 [Executor task launch worker for task 112] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_27_8 locally
2021-12-08 10:35:48,154 [Executor task launch worker for task 111] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_15_7 locally
2021-12-08 10:35:48,154 [Executor task launch worker for task 111] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_27_7 locally
2021-12-08 10:35:48,154 [Executor task launch worker for task 109] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_27_5 locally
2021-12-08 10:35:48,147 [Executor task launch worker for task 108] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_15_4 locally
2021-12-08 10:35:48,155 [Executor task launch worker for task 108] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_27_4 locally
2021-12-08 10:35:48,570 [Executor task launch worker for task 107] INFO [org.apache.spark.executor.Executor] - Finished task 3.0 in stage 22.0 (TID 107). 999 bytes result sent to driver
2021-12-08 10:35:48,570 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 3.0 in stage 22.0 (TID 107) in 426 ms on localhost (executor driver) (1/12)
2021-12-08 10:35:48,577 [Executor task launch worker for task 110] INFO [org.apache.spark.executor.Executor] - Finished task 6.0 in stage 22.0 (TID 110). 999 bytes result sent to driver
2021-12-08 10:35:48,577 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 6.0 in stage 22.0 (TID 110) in 433 ms on localhost (executor driver) (2/12)
2021-12-08 10:35:48,671 [Executor task launch worker for task 114] INFO [org.apache.spark.executor.Executor] - Finished task 10.0 in stage 22.0 (TID 114). 999 bytes result sent to driver
2021-12-08 10:35:48,672 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 10.0 in stage 22.0 (TID 114) in 528 ms on localhost (executor driver) (3/12)
2021-12-08 10:35:48,678 [Executor task launch worker for task 105] INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 22.0 (TID 105). 999 bytes result sent to driver
2021-12-08 10:35:48,678 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 22.0 (TID 105) in 535 ms on localhost (executor driver) (4/12)
2021-12-08 10:35:48,679 [Executor task launch worker for task 115] INFO [org.apache.spark.executor.Executor] - Finished task 11.0 in stage 22.0 (TID 115). 999 bytes result sent to driver
2021-12-08 10:35:48,680 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 11.0 in stage 22.0 (TID 115) in 536 ms on localhost (executor driver) (5/12)
2021-12-08 10:35:48,681 [Executor task launch worker for task 111] INFO [org.apache.spark.executor.Executor] - Finished task 7.0 in stage 22.0 (TID 111). 1042 bytes result sent to driver
2021-12-08 10:35:48,681 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 7.0 in stage 22.0 (TID 111) in 537 ms on localhost (executor driver) (6/12)
2021-12-08 10:35:48,683 [Executor task launch worker for task 104] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 22.0 (TID 104). 999 bytes result sent to driver
2021-12-08 10:35:48,683 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 22.0 (TID 104) in 540 ms on localhost (executor driver) (7/12)
2021-12-08 10:35:48,688 [Executor task launch worker for task 106] INFO [org.apache.spark.executor.Executor] - Finished task 2.0 in stage 22.0 (TID 106). 999 bytes result sent to driver
2021-12-08 10:35:48,688 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 2.0 in stage 22.0 (TID 106) in 544 ms on localhost (executor driver) (8/12)
2021-12-08 10:35:48,693 [Executor task launch worker for task 108] INFO [org.apache.spark.executor.Executor] - Finished task 4.0 in stage 22.0 (TID 108). 1042 bytes result sent to driver
2021-12-08 10:35:48,694 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 4.0 in stage 22.0 (TID 108) in 550 ms on localhost (executor driver) (9/12)
2021-12-08 10:35:48,718 [Executor task launch worker for task 112] INFO [org.apache.spark.executor.Executor] - Finished task 8.0 in stage 22.0 (TID 112). 999 bytes result sent to driver
2021-12-08 10:35:48,718 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 8.0 in stage 22.0 (TID 112) in 574 ms on localhost (executor driver) (10/12)
2021-12-08 10:35:48,780 [Executor task launch worker for task 113] INFO [org.apache.spark.executor.Executor] - Finished task 9.0 in stage 22.0 (TID 113). 999 bytes result sent to driver
2021-12-08 10:35:48,781 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 9.0 in stage 22.0 (TID 113) in 637 ms on localhost (executor driver) (11/12)
2021-12-08 10:35:48,874 [Executor task launch worker for task 109] INFO [org.apache.spark.executor.Executor] - Finished task 5.0 in stage 22.0 (TID 109). 1042 bytes result sent to driver
2021-12-08 10:35:48,874 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 5.0 in stage 22.0 (TID 109) in 730 ms on localhost (executor driver) (12/12)
2021-12-08 10:35:48,875 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 22.0, whose tasks have all completed, from pool 
2021-12-08 10:35:48,875 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ShuffleMapStage 22 (flatMap at ALS.scala:1653) finished in 0.735 s
2021-12-08 10:35:48,875 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - looking for newly runnable stages
2021-12-08 10:35:48,875 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - running: Set()
2021-12-08 10:35:48,875 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - waiting: Set(ResultStage 23)
2021-12-08 10:35:48,875 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - failed: Set()
2021-12-08 10:35:48,875 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 23 (MapPartitionsRDD[38] at values at ALS.scala:1711), which has no missing parents
2021-12-08 10:35:48,877 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_13 stored as values in memory (estimated size 493.5 KB, free 1753.3 MB)
2021-12-08 10:35:48,879 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_13_piece0 stored as bytes in memory (estimated size 321.7 KB, free 1753.0 MB)
2021-12-08 10:35:48,879 [dispatcher-event-loop-0] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_13_piece0 in memory on qb:55657 (size: 321.7 KB, free: 1754.2 MB)
2021-12-08 10:35:48,879 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 13 from broadcast at DAGScheduler.scala:1039
2021-12-08 10:35:48,880 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 12 missing tasks from ResultStage 23 (MapPartitionsRDD[38] at values at ALS.scala:1711) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11))
2021-12-08 10:35:48,880 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 23.0 with 12 tasks
2021-12-08 10:35:48,880 [dispatcher-event-loop-6] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 23.0 (TID 116, localhost, executor driver, partition 0, PROCESS_LOCAL, 7888 bytes)
2021-12-08 10:35:48,880 [dispatcher-event-loop-6] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 23.0 (TID 117, localhost, executor driver, partition 1, PROCESS_LOCAL, 7888 bytes)
2021-12-08 10:35:48,880 [dispatcher-event-loop-6] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 2.0 in stage 23.0 (TID 118, localhost, executor driver, partition 2, PROCESS_LOCAL, 7888 bytes)
2021-12-08 10:35:48,881 [dispatcher-event-loop-6] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 3.0 in stage 23.0 (TID 119, localhost, executor driver, partition 3, PROCESS_LOCAL, 7888 bytes)
2021-12-08 10:35:48,881 [dispatcher-event-loop-6] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 4.0 in stage 23.0 (TID 120, localhost, executor driver, partition 4, PROCESS_LOCAL, 7888 bytes)
2021-12-08 10:35:48,881 [dispatcher-event-loop-6] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 5.0 in stage 23.0 (TID 121, localhost, executor driver, partition 5, PROCESS_LOCAL, 7888 bytes)
2021-12-08 10:35:48,881 [dispatcher-event-loop-6] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 6.0 in stage 23.0 (TID 122, localhost, executor driver, partition 6, PROCESS_LOCAL, 7888 bytes)
2021-12-08 10:35:48,881 [dispatcher-event-loop-6] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 7.0 in stage 23.0 (TID 123, localhost, executor driver, partition 7, PROCESS_LOCAL, 7888 bytes)
2021-12-08 10:35:48,881 [dispatcher-event-loop-6] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 8.0 in stage 23.0 (TID 124, localhost, executor driver, partition 8, PROCESS_LOCAL, 7888 bytes)
2021-12-08 10:35:48,881 [dispatcher-event-loop-6] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 9.0 in stage 23.0 (TID 125, localhost, executor driver, partition 9, PROCESS_LOCAL, 7888 bytes)
2021-12-08 10:35:48,881 [dispatcher-event-loop-6] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 10.0 in stage 23.0 (TID 126, localhost, executor driver, partition 10, PROCESS_LOCAL, 7888 bytes)
2021-12-08 10:35:48,881 [dispatcher-event-loop-6] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 11.0 in stage 23.0 (TID 127, localhost, executor driver, partition 11, PROCESS_LOCAL, 7888 bytes)
2021-12-08 10:35:48,881 [Executor task launch worker for task 116] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 23.0 (TID 116)
2021-12-08 10:35:48,881 [Executor task launch worker for task 119] INFO [org.apache.spark.executor.Executor] - Running task 3.0 in stage 23.0 (TID 119)
2021-12-08 10:35:48,881 [Executor task launch worker for task 125] INFO [org.apache.spark.executor.Executor] - Running task 9.0 in stage 23.0 (TID 125)
2021-12-08 10:35:48,881 [Executor task launch worker for task 124] INFO [org.apache.spark.executor.Executor] - Running task 8.0 in stage 23.0 (TID 124)
2021-12-08 10:35:48,881 [Executor task launch worker for task 123] INFO [org.apache.spark.executor.Executor] - Running task 7.0 in stage 23.0 (TID 123)
2021-12-08 10:35:48,881 [Executor task launch worker for task 118] INFO [org.apache.spark.executor.Executor] - Running task 2.0 in stage 23.0 (TID 118)
2021-12-08 10:35:48,881 [Executor task launch worker for task 122] INFO [org.apache.spark.executor.Executor] - Running task 6.0 in stage 23.0 (TID 122)
2021-12-08 10:35:48,881 [Executor task launch worker for task 117] INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 23.0 (TID 117)
2021-12-08 10:35:48,881 [Executor task launch worker for task 120] INFO [org.apache.spark.executor.Executor] - Running task 4.0 in stage 23.0 (TID 120)
2021-12-08 10:35:48,881 [Executor task launch worker for task 121] INFO [org.apache.spark.executor.Executor] - Running task 5.0 in stage 23.0 (TID 121)
2021-12-08 10:35:48,881 [Executor task launch worker for task 127] INFO [org.apache.spark.executor.Executor] - Running task 11.0 in stage 23.0 (TID 127)
2021-12-08 10:35:48,881 [Executor task launch worker for task 126] INFO [org.apache.spark.executor.Executor] - Running task 10.0 in stage 23.0 (TID 126)
2021-12-08 10:35:48,883 [Executor task launch worker for task 118] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_9_2 locally
2021-12-08 10:35:48,883 [Executor task launch worker for task 119] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_9_3 locally
2021-12-08 10:35:48,884 [Executor task launch worker for task 127] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_9_11 locally
2021-12-08 10:35:48,884 [Executor task launch worker for task 121] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_9_5 locally
2021-12-08 10:35:48,884 [Executor task launch worker for task 123] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_9_7 locally
2021-12-08 10:35:48,883 [Executor task launch worker for task 126] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_9_10 locally
2021-12-08 10:35:48,884 [Executor task launch worker for task 125] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_9_9 locally
2021-12-08 10:35:48,884 [Executor task launch worker for task 122] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_9_6 locally
2021-12-08 10:35:48,884 [Executor task launch worker for task 120] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_9_4 locally
2021-12-08 10:35:48,884 [Executor task launch worker for task 124] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_9_8 locally
2021-12-08 10:35:48,884 [Executor task launch worker for task 118] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 12 non-empty blocks out of 12 blocks
2021-12-08 10:35:48,884 [Executor task launch worker for task 117] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_9_1 locally
2021-12-08 10:35:48,884 [Executor task launch worker for task 122] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 12 non-empty blocks out of 12 blocks
2021-12-08 10:35:48,884 [Executor task launch worker for task 122] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-08 10:35:48,884 [Executor task launch worker for task 119] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 12 non-empty blocks out of 12 blocks
2021-12-08 10:35:48,884 [Executor task launch worker for task 117] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 12 non-empty blocks out of 12 blocks
2021-12-08 10:35:48,884 [Executor task launch worker for task 118] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-08 10:35:48,884 [Executor task launch worker for task 117] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-08 10:35:48,884 [Executor task launch worker for task 127] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 12 non-empty blocks out of 12 blocks
2021-12-08 10:35:48,884 [Executor task launch worker for task 123] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 12 non-empty blocks out of 12 blocks
2021-12-08 10:35:48,884 [Executor task launch worker for task 121] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 12 non-empty blocks out of 12 blocks
2021-12-08 10:35:48,884 [Executor task launch worker for task 123] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-08 10:35:48,884 [Executor task launch worker for task 127] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-08 10:35:48,884 [Executor task launch worker for task 126] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 12 non-empty blocks out of 12 blocks
2021-12-08 10:35:48,884 [Executor task launch worker for task 125] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 12 non-empty blocks out of 12 blocks
2021-12-08 10:35:48,884 [Executor task launch worker for task 119] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-08 10:35:48,884 [Executor task launch worker for task 125] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-08 10:35:48,884 [Executor task launch worker for task 126] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-08 10:35:48,884 [Executor task launch worker for task 120] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 12 non-empty blocks out of 12 blocks
2021-12-08 10:35:48,885 [Executor task launch worker for task 120] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 1 ms
2021-12-08 10:35:48,884 [Executor task launch worker for task 121] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-08 10:35:48,885 [Executor task launch worker for task 124] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 12 non-empty blocks out of 12 blocks
2021-12-08 10:35:48,885 [Executor task launch worker for task 124] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 1 ms
2021-12-08 10:35:48,885 [Executor task launch worker for task 116] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_9_0 locally
2021-12-08 10:35:48,885 [Executor task launch worker for task 116] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 12 non-empty blocks out of 12 blocks
2021-12-08 10:35:48,885 [Executor task launch worker for task 116] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-08 10:35:49,101 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 200
2021-12-08 10:35:49,107 [dispatcher-event-loop-4] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_12_piece0 on qb:55657 in memory (size: 162.9 KB, free: 1754.4 MB)
2021-12-08 10:35:49,107 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 246
2021-12-08 10:35:49,107 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 218
2021-12-08 10:35:49,107 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 267
2021-12-08 10:35:49,107 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 268
2021-12-08 10:35:49,107 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 239
2021-12-08 10:35:49,107 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 210
2021-12-08 10:35:49,107 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 226
2021-12-08 10:35:49,107 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 247
2021-12-08 10:35:49,107 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 229
2021-12-08 10:35:49,108 [dispatcher-event-loop-1] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_11_piece0 on qb:55657 in memory (size: 163.9 KB, free: 1754.6 MB)
2021-12-08 10:35:49,108 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 220
2021-12-08 10:35:49,108 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 242
2021-12-08 10:35:49,108 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 261
2021-12-08 10:35:49,108 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 237
2021-12-08 10:35:49,108 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 271
2021-12-08 10:35:49,108 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 201
2021-12-08 10:35:49,108 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 204
2021-12-08 10:35:49,108 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 213
2021-12-08 10:35:49,108 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 254
2021-12-08 10:35:49,108 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 244
2021-12-08 10:35:49,108 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 251
2021-12-08 10:35:49,108 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 235
2021-12-08 10:35:49,108 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 266
2021-12-08 10:35:49,108 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 260
2021-12-08 10:35:49,108 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 273
2021-12-08 10:35:49,108 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 256
2021-12-08 10:35:49,108 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 232
2021-12-08 10:35:49,108 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 263
2021-12-08 10:35:49,108 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 240
2021-12-08 10:35:49,108 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 211
2021-12-08 10:35:49,108 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 257
2021-12-08 10:35:49,108 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 219
2021-12-08 10:35:49,108 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 258
2021-12-08 10:35:49,109 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 227
2021-12-08 10:35:49,109 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 231
2021-12-08 10:35:49,109 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 262
2021-12-08 10:35:49,109 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 272
2021-12-08 10:35:49,109 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 202
2021-12-08 10:35:49,109 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 215
2021-12-08 10:35:49,109 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 248
2021-12-08 10:35:49,109 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 216
2021-12-08 10:35:49,109 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 243
2021-12-08 10:35:49,109 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 255
2021-12-08 10:35:49,109 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 270
2021-12-08 10:35:49,109 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 252
2021-12-08 10:35:49,109 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 264
2021-12-08 10:35:49,109 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 238
2021-12-08 10:35:49,109 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 245
2021-12-08 10:35:49,109 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 236
2021-12-08 10:35:49,109 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 224
2021-12-08 10:35:49,109 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 249
2021-12-08 10:35:49,109 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 203
2021-12-08 10:35:49,109 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 259
2021-12-08 10:35:49,109 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 230
2021-12-08 10:35:49,109 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 205
2021-12-08 10:35:49,109 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 253
2021-12-08 10:35:49,109 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 234
2021-12-08 10:35:49,109 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 212
2021-12-08 10:35:49,109 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 222
2021-12-08 10:35:49,109 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 209
2021-12-08 10:35:49,109 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 208
2021-12-08 10:35:49,109 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 241
2021-12-08 10:35:49,109 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 225
2021-12-08 10:35:49,109 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 223
2021-12-08 10:35:49,109 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 265
2021-12-08 10:35:49,109 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 250
2021-12-08 10:35:49,109 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 228
2021-12-08 10:35:49,109 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 274
2021-12-08 10:35:49,109 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 233
2021-12-08 10:35:49,109 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 207
2021-12-08 10:35:49,109 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 221
2021-12-08 10:35:49,109 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 269
2021-12-08 10:35:49,109 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 214
2021-12-08 10:35:49,109 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 217
2021-12-08 10:35:49,109 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 206
2021-12-08 10:36:26,906 [Executor task launch worker for task 118] INFO [org.apache.spark.storage.memory.MemoryStore] - Block rdd_37_2 stored as values in memory (estimated size 11.1 MB, free 1742.7 MB)
2021-12-08 10:36:26,907 [dispatcher-event-loop-11] INFO [org.apache.spark.storage.BlockManagerInfo] - Added rdd_37_2 in memory on qb:55657 (size: 11.1 MB, free: 1743.5 MB)
2021-12-08 10:36:27,152 [Executor task launch worker for task 127] INFO [org.apache.spark.storage.memory.MemoryStore] - Block rdd_37_11 stored as values in memory (estimated size 11.1 MB, free 1731.6 MB)
2021-12-08 10:36:27,153 [dispatcher-event-loop-4] INFO [org.apache.spark.storage.BlockManagerInfo] - Added rdd_37_11 in memory on qb:55657 (size: 11.1 MB, free: 1732.4 MB)
2021-12-08 10:36:27,229 [Executor task launch worker for task 125] INFO [org.apache.spark.storage.memory.MemoryStore] - Block rdd_37_9 stored as values in memory (estimated size 11.1 MB, free 1720.5 MB)
2021-12-08 10:36:27,230 [dispatcher-event-loop-10] INFO [org.apache.spark.storage.BlockManagerInfo] - Added rdd_37_9 in memory on qb:55657 (size: 11.1 MB, free: 1721.3 MB)
2021-12-08 10:36:27,244 [Executor task launch worker for task 118] INFO [org.apache.spark.executor.Executor] - Finished task 2.0 in stage 23.0 (TID 118). 166054 bytes result sent to driver
2021-12-08 10:36:27,266 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 2.0 in stage 23.0 (TID 118) in 38386 ms on localhost (executor driver) (1/12)
2021-12-08 10:36:27,357 [Executor task launch worker for task 123] INFO [org.apache.spark.storage.memory.MemoryStore] - Block rdd_37_7 stored as values in memory (estimated size 11.1 MB, free 1709.4 MB)
2021-12-08 10:36:27,357 [dispatcher-event-loop-1] INFO [org.apache.spark.storage.BlockManagerInfo] - Added rdd_37_7 in memory on qb:55657 (size: 11.1 MB, free: 1710.1 MB)
2021-12-08 10:36:27,481 [Executor task launch worker for task 127] INFO [org.apache.spark.executor.Executor] - Finished task 11.0 in stage 23.0 (TID 127). 166054 bytes result sent to driver
2021-12-08 10:36:27,483 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 11.0 in stage 23.0 (TID 127) in 38602 ms on localhost (executor driver) (2/12)
2021-12-08 10:36:27,561 [Executor task launch worker for task 125] INFO [org.apache.spark.executor.Executor] - Finished task 9.0 in stage 23.0 (TID 125). 166097 bytes result sent to driver
2021-12-08 10:36:27,563 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 9.0 in stage 23.0 (TID 125) in 38682 ms on localhost (executor driver) (3/12)
2021-12-08 10:36:27,684 [Executor task launch worker for task 123] INFO [org.apache.spark.executor.Executor] - Finished task 7.0 in stage 23.0 (TID 123). 166054 bytes result sent to driver
2021-12-08 10:36:27,685 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 7.0 in stage 23.0 (TID 123) in 38804 ms on localhost (executor driver) (4/12)
2021-12-08 10:36:28,000 [Executor task launch worker for task 117] INFO [org.apache.spark.storage.memory.MemoryStore] - Block rdd_37_1 stored as values in memory (estimated size 11.1 MB, free 1698.3 MB)
2021-12-08 10:36:28,000 [dispatcher-event-loop-5] INFO [org.apache.spark.storage.BlockManagerInfo] - Added rdd_37_1 in memory on qb:55657 (size: 11.1 MB, free: 1699.0 MB)
2021-12-08 10:36:28,050 [Executor task launch worker for task 122] INFO [org.apache.spark.storage.memory.MemoryStore] - Block rdd_37_6 stored as values in memory (estimated size 11.1 MB, free 1687.2 MB)
2021-12-08 10:36:28,050 [dispatcher-event-loop-3] INFO [org.apache.spark.storage.BlockManagerInfo] - Added rdd_37_6 in memory on qb:55657 (size: 11.1 MB, free: 1687.9 MB)
2021-12-08 10:36:28,151 [Executor task launch worker for task 120] INFO [org.apache.spark.storage.memory.MemoryStore] - Block rdd_37_4 stored as values in memory (estimated size 11.1 MB, free 1676.0 MB)
2021-12-08 10:36:28,151 [dispatcher-event-loop-0] INFO [org.apache.spark.storage.BlockManagerInfo] - Added rdd_37_4 in memory on qb:55657 (size: 11.1 MB, free: 1676.8 MB)
2021-12-08 10:36:28,284 [Executor task launch worker for task 117] INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 23.0 (TID 117). 166054 bytes result sent to driver
2021-12-08 10:36:28,285 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 23.0 (TID 117) in 39405 ms on localhost (executor driver) (5/12)
2021-12-08 10:36:28,340 [Executor task launch worker for task 122] INFO [org.apache.spark.executor.Executor] - Finished task 6.0 in stage 23.0 (TID 122). 166054 bytes result sent to driver
2021-12-08 10:36:28,340 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 6.0 in stage 23.0 (TID 122) in 39459 ms on localhost (executor driver) (6/12)
2021-12-08 10:36:28,407 [Executor task launch worker for task 120] INFO [org.apache.spark.executor.Executor] - Finished task 4.0 in stage 23.0 (TID 120). 166054 bytes result sent to driver
2021-12-08 10:36:28,408 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 4.0 in stage 23.0 (TID 120) in 39527 ms on localhost (executor driver) (7/12)
2021-12-08 10:36:29,600 [Executor task launch worker for task 116] INFO [org.apache.spark.storage.memory.MemoryStore] - Block rdd_37_0 stored as values in memory (estimated size 11.1 MB, free 1664.9 MB)
2021-12-08 10:36:29,600 [dispatcher-event-loop-1] INFO [org.apache.spark.storage.BlockManagerInfo] - Added rdd_37_0 in memory on qb:55657 (size: 11.1 MB, free: 1665.7 MB)
2021-12-08 10:36:29,808 [Executor task launch worker for task 116] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 23.0 (TID 116). 166054 bytes result sent to driver
2021-12-08 10:36:29,809 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 23.0 (TID 116) in 40928 ms on localhost (executor driver) (8/12)
2021-12-08 10:36:29,989 [Executor task launch worker for task 126] INFO [org.apache.spark.storage.memory.MemoryStore] - Block rdd_37_10 stored as values in memory (estimated size 11.1 MB, free 1653.8 MB)
2021-12-08 10:36:29,990 [dispatcher-event-loop-9] INFO [org.apache.spark.storage.BlockManagerInfo] - Added rdd_37_10 in memory on qb:55657 (size: 11.1 MB, free: 1654.6 MB)
2021-12-08 10:36:30,059 [Executor task launch worker for task 124] INFO [org.apache.spark.storage.memory.MemoryStore] - Block rdd_37_8 stored as values in memory (estimated size 11.1 MB, free 1642.7 MB)
2021-12-08 10:36:30,060 [dispatcher-event-loop-6] INFO [org.apache.spark.storage.BlockManagerInfo] - Added rdd_37_8 in memory on qb:55657 (size: 11.1 MB, free: 1643.5 MB)
2021-12-08 10:36:30,095 [Executor task launch worker for task 121] INFO [org.apache.spark.storage.memory.MemoryStore] - Block rdd_37_5 stored as values in memory (estimated size 11.1 MB, free 1631.6 MB)
2021-12-08 10:36:30,096 [dispatcher-event-loop-5] INFO [org.apache.spark.storage.BlockManagerInfo] - Added rdd_37_5 in memory on qb:55657 (size: 11.1 MB, free: 1632.4 MB)
2021-12-08 10:36:30,167 [Executor task launch worker for task 126] INFO [org.apache.spark.executor.Executor] - Finished task 10.0 in stage 23.0 (TID 126). 166054 bytes result sent to driver
2021-12-08 10:36:30,167 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 10.0 in stage 23.0 (TID 126) in 41286 ms on localhost (executor driver) (9/12)
2021-12-08 10:36:30,250 [Executor task launch worker for task 124] INFO [org.apache.spark.executor.Executor] - Finished task 8.0 in stage 23.0 (TID 124). 166054 bytes result sent to driver
2021-12-08 10:36:30,250 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 8.0 in stage 23.0 (TID 124) in 41369 ms on localhost (executor driver) (10/12)
2021-12-08 10:36:30,276 [Executor task launch worker for task 121] INFO [org.apache.spark.executor.Executor] - Finished task 5.0 in stage 23.0 (TID 121). 166054 bytes result sent to driver
2021-12-08 10:36:30,276 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 5.0 in stage 23.0 (TID 121) in 41395 ms on localhost (executor driver) (11/12)
2021-12-08 10:36:30,372 [Executor task launch worker for task 119] INFO [org.apache.spark.storage.memory.MemoryStore] - Block rdd_37_3 stored as values in memory (estimated size 11.1 MB, free 1620.5 MB)
2021-12-08 10:36:30,373 [dispatcher-event-loop-11] INFO [org.apache.spark.storage.BlockManagerInfo] - Added rdd_37_3 in memory on qb:55657 (size: 11.1 MB, free: 1621.3 MB)
2021-12-08 10:36:30,544 [Executor task launch worker for task 119] INFO [org.apache.spark.executor.Executor] - Finished task 3.0 in stage 23.0 (TID 119). 166054 bytes result sent to driver
2021-12-08 10:36:30,545 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 3.0 in stage 23.0 (TID 119) in 41665 ms on localhost (executor driver) (12/12)
2021-12-08 10:36:30,545 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 23.0, whose tasks have all completed, from pool 
2021-12-08 10:36:30,545 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 23 (aggregate at ALS.scala:1711) finished in 41.669 s
2021-12-08 10:36:30,545 [main] INFO [org.apache.spark.scheduler.DAGScheduler] - Job 6 finished: aggregate at ALS.scala:1711, took 42.407670 s
2021-12-08 10:36:30,562 [main] INFO [org.apache.spark.rdd.MapPartitionsRDD] - Removing RDD 27 from persistence list
2021-12-08 10:36:30,562 [block-manager-slave-async-thread-pool-0] INFO [org.apache.spark.storage.BlockManager] - Removing RDD 27
2021-12-08 10:36:30,570 [main] INFO [org.apache.spark.SparkContext] - Starting job: aggregate at ALS.scala:1711
2021-12-08 10:36:30,570 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 42 (flatMap at ALS.scala:1653)
2021-12-08 10:36:30,571 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 7 (aggregate at ALS.scala:1711) with 12 output partitions
2021-12-08 10:36:30,571 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 31 (aggregate at ALS.scala:1711)
2021-12-08 10:36:30,571 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 30, ShuffleMapStage 28)
2021-12-08 10:36:30,571 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List(ShuffleMapStage 30)
2021-12-08 10:36:30,571 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ShuffleMapStage 30 (MapPartitionsRDD[42] at flatMap at ALS.scala:1653), which has no missing parents
2021-12-08 10:36:30,573 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_14 stored as values in memory (estimated size 333.0 KB, free 1668.1 MB)
2021-12-08 10:36:30,575 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_14_piece0 stored as bytes in memory (estimated size 320.6 KB, free 1667.7 MB)
2021-12-08 10:36:30,575 [dispatcher-event-loop-5] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_14_piece0 in memory on qb:55657 (size: 320.6 KB, free: 1668.9 MB)
2021-12-08 10:36:30,575 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 14 from broadcast at DAGScheduler.scala:1039
2021-12-08 10:36:30,576 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 12 missing tasks from ShuffleMapStage 30 (MapPartitionsRDD[42] at flatMap at ALS.scala:1653) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11))
2021-12-08 10:36:30,576 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 30.0 with 12 tasks
2021-12-08 10:36:30,576 [dispatcher-event-loop-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 30.0 (TID 128, localhost, executor driver, partition 0, PROCESS_LOCAL, 7928 bytes)
2021-12-08 10:36:30,576 [dispatcher-event-loop-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 30.0 (TID 129, localhost, executor driver, partition 1, PROCESS_LOCAL, 7928 bytes)
2021-12-08 10:36:30,576 [dispatcher-event-loop-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 2.0 in stage 30.0 (TID 130, localhost, executor driver, partition 2, PROCESS_LOCAL, 7928 bytes)
2021-12-08 10:36:30,576 [dispatcher-event-loop-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 3.0 in stage 30.0 (TID 131, localhost, executor driver, partition 3, PROCESS_LOCAL, 7928 bytes)
2021-12-08 10:36:30,577 [dispatcher-event-loop-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 4.0 in stage 30.0 (TID 132, localhost, executor driver, partition 4, PROCESS_LOCAL, 7928 bytes)
2021-12-08 10:36:30,577 [dispatcher-event-loop-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 5.0 in stage 30.0 (TID 133, localhost, executor driver, partition 5, PROCESS_LOCAL, 7928 bytes)
2021-12-08 10:36:30,577 [dispatcher-event-loop-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 6.0 in stage 30.0 (TID 134, localhost, executor driver, partition 6, PROCESS_LOCAL, 7928 bytes)
2021-12-08 10:36:30,577 [dispatcher-event-loop-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 7.0 in stage 30.0 (TID 135, localhost, executor driver, partition 7, PROCESS_LOCAL, 7928 bytes)
2021-12-08 10:36:30,577 [dispatcher-event-loop-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 8.0 in stage 30.0 (TID 136, localhost, executor driver, partition 8, PROCESS_LOCAL, 7928 bytes)
2021-12-08 10:36:30,577 [dispatcher-event-loop-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 9.0 in stage 30.0 (TID 137, localhost, executor driver, partition 9, PROCESS_LOCAL, 7928 bytes)
2021-12-08 10:36:30,577 [dispatcher-event-loop-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 10.0 in stage 30.0 (TID 138, localhost, executor driver, partition 10, PROCESS_LOCAL, 7928 bytes)
2021-12-08 10:36:30,577 [dispatcher-event-loop-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 11.0 in stage 30.0 (TID 139, localhost, executor driver, partition 11, PROCESS_LOCAL, 7928 bytes)
2021-12-08 10:36:30,577 [Executor task launch worker for task 129] INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 30.0 (TID 129)
2021-12-08 10:36:30,577 [Executor task launch worker for task 132] INFO [org.apache.spark.executor.Executor] - Running task 4.0 in stage 30.0 (TID 132)
2021-12-08 10:36:30,577 [Executor task launch worker for task 138] INFO [org.apache.spark.executor.Executor] - Running task 10.0 in stage 30.0 (TID 138)
2021-12-08 10:36:30,577 [Executor task launch worker for task 131] INFO [org.apache.spark.executor.Executor] - Running task 3.0 in stage 30.0 (TID 131)
2021-12-08 10:36:30,577 [Executor task launch worker for task 128] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 30.0 (TID 128)
2021-12-08 10:36:30,577 [Executor task launch worker for task 135] INFO [org.apache.spark.executor.Executor] - Running task 7.0 in stage 30.0 (TID 135)
2021-12-08 10:36:30,577 [Executor task launch worker for task 134] INFO [org.apache.spark.executor.Executor] - Running task 6.0 in stage 30.0 (TID 134)
2021-12-08 10:36:30,577 [Executor task launch worker for task 130] INFO [org.apache.spark.executor.Executor] - Running task 2.0 in stage 30.0 (TID 130)
2021-12-08 10:36:30,577 [Executor task launch worker for task 133] INFO [org.apache.spark.executor.Executor] - Running task 5.0 in stage 30.0 (TID 133)
2021-12-08 10:36:30,577 [Executor task launch worker for task 136] INFO [org.apache.spark.executor.Executor] - Running task 8.0 in stage 30.0 (TID 136)
2021-12-08 10:36:30,577 [Executor task launch worker for task 139] INFO [org.apache.spark.executor.Executor] - Running task 11.0 in stage 30.0 (TID 139)
2021-12-08 10:36:30,577 [Executor task launch worker for task 137] INFO [org.apache.spark.executor.Executor] - Running task 9.0 in stage 30.0 (TID 137)
2021-12-08 10:36:30,579 [Executor task launch worker for task 136] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_10_8 locally
2021-12-08 10:36:30,579 [Executor task launch worker for task 136] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_37_8 locally
2021-12-08 10:36:30,579 [Executor task launch worker for task 132] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_10_4 locally
2021-12-08 10:36:30,579 [Executor task launch worker for task 130] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_10_2 locally
2021-12-08 10:36:30,579 [Executor task launch worker for task 135] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_10_7 locally
2021-12-08 10:36:30,579 [Executor task launch worker for task 138] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_10_10 locally
2021-12-08 10:36:30,579 [Executor task launch worker for task 139] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_10_11 locally
2021-12-08 10:36:30,579 [Executor task launch worker for task 138] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_37_10 locally
2021-12-08 10:36:30,579 [Executor task launch worker for task 133] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_10_5 locally
2021-12-08 10:36:30,579 [Executor task launch worker for task 135] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_37_7 locally
2021-12-08 10:36:30,579 [Executor task launch worker for task 133] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_37_5 locally
2021-12-08 10:36:30,579 [Executor task launch worker for task 132] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_37_4 locally
2021-12-08 10:36:30,580 [Executor task launch worker for task 134] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_10_6 locally
2021-12-08 10:36:30,580 [Executor task launch worker for task 134] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_37_6 locally
2021-12-08 10:36:30,580 [Executor task launch worker for task 128] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_10_0 locally
2021-12-08 10:36:30,580 [Executor task launch worker for task 128] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_37_0 locally
2021-12-08 10:36:30,580 [Executor task launch worker for task 129] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_10_1 locally
2021-12-08 10:36:30,580 [Executor task launch worker for task 129] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_37_1 locally
2021-12-08 10:36:30,581 [Executor task launch worker for task 130] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_37_2 locally
2021-12-08 10:36:30,585 [Executor task launch worker for task 139] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_37_11 locally
2021-12-08 10:36:30,585 [Executor task launch worker for task 137] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_10_9 locally
2021-12-08 10:36:30,585 [Executor task launch worker for task 137] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_37_9 locally
2021-12-08 10:36:30,585 [Executor task launch worker for task 131] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_10_3 locally
2021-12-08 10:36:30,585 [Executor task launch worker for task 131] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_37_3 locally
2021-12-08 10:36:32,008 [Executor task launch worker for task 139] INFO [org.apache.spark.executor.Executor] - Finished task 11.0 in stage 30.0 (TID 139). 999 bytes result sent to driver
2021-12-08 10:36:32,008 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 11.0 in stage 30.0 (TID 139) in 1431 ms on localhost (executor driver) (1/12)
2021-12-08 10:36:32,106 [Executor task launch worker for task 135] INFO [org.apache.spark.executor.Executor] - Finished task 7.0 in stage 30.0 (TID 135). 999 bytes result sent to driver
2021-12-08 10:36:32,107 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 7.0 in stage 30.0 (TID 135) in 1530 ms on localhost (executor driver) (2/12)
2021-12-08 10:36:32,116 [Executor task launch worker for task 132] INFO [org.apache.spark.executor.Executor] - Finished task 4.0 in stage 30.0 (TID 132). 999 bytes result sent to driver
2021-12-08 10:36:32,116 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 4.0 in stage 30.0 (TID 132) in 1540 ms on localhost (executor driver) (3/12)
2021-12-08 10:36:32,140 [Executor task launch worker for task 129] INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 30.0 (TID 129). 999 bytes result sent to driver
2021-12-08 10:36:32,140 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 30.0 (TID 129) in 1564 ms on localhost (executor driver) (4/12)
2021-12-08 10:36:32,171 [Executor task launch worker for task 128] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 30.0 (TID 128). 999 bytes result sent to driver
2021-12-08 10:36:32,172 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 30.0 (TID 128) in 1596 ms on localhost (executor driver) (5/12)
2021-12-08 10:36:32,191 [Executor task launch worker for task 136] INFO [org.apache.spark.executor.Executor] - Finished task 8.0 in stage 30.0 (TID 136). 999 bytes result sent to driver
2021-12-08 10:36:32,192 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 8.0 in stage 30.0 (TID 136) in 1615 ms on localhost (executor driver) (6/12)
2021-12-08 10:36:32,197 [Executor task launch worker for task 138] INFO [org.apache.spark.executor.Executor] - Finished task 10.0 in stage 30.0 (TID 138). 999 bytes result sent to driver
2021-12-08 10:36:32,198 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 10.0 in stage 30.0 (TID 138) in 1621 ms on localhost (executor driver) (7/12)
2021-12-08 10:36:32,371 [Executor task launch worker for task 130] INFO [org.apache.spark.executor.Executor] - Finished task 2.0 in stage 30.0 (TID 130). 999 bytes result sent to driver
2021-12-08 10:36:32,372 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 2.0 in stage 30.0 (TID 130) in 1796 ms on localhost (executor driver) (8/12)
2021-12-08 10:36:32,397 [Executor task launch worker for task 137] INFO [org.apache.spark.executor.Executor] - Finished task 9.0 in stage 30.0 (TID 137). 999 bytes result sent to driver
2021-12-08 10:36:32,397 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 9.0 in stage 30.0 (TID 137) in 1820 ms on localhost (executor driver) (9/12)
2021-12-08 10:36:32,398 [Executor task launch worker for task 133] INFO [org.apache.spark.executor.Executor] - Finished task 5.0 in stage 30.0 (TID 133). 999 bytes result sent to driver
2021-12-08 10:36:32,398 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 5.0 in stage 30.0 (TID 133) in 1821 ms on localhost (executor driver) (10/12)
2021-12-08 10:36:32,436 [Executor task launch worker for task 131] INFO [org.apache.spark.executor.Executor] - Finished task 3.0 in stage 30.0 (TID 131). 999 bytes result sent to driver
2021-12-08 10:36:32,436 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 3.0 in stage 30.0 (TID 131) in 1860 ms on localhost (executor driver) (11/12)
2021-12-08 10:36:32,437 [Executor task launch worker for task 134] INFO [org.apache.spark.executor.Executor] - Finished task 6.0 in stage 30.0 (TID 134). 999 bytes result sent to driver
2021-12-08 10:36:32,437 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 6.0 in stage 30.0 (TID 134) in 1860 ms on localhost (executor driver) (12/12)
2021-12-08 10:36:32,437 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 30.0, whose tasks have all completed, from pool 
2021-12-08 10:36:32,437 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ShuffleMapStage 30 (flatMap at ALS.scala:1653) finished in 1.865 s
2021-12-08 10:36:32,440 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - looking for newly runnable stages
2021-12-08 10:36:32,440 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - running: Set()
2021-12-08 10:36:32,440 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - waiting: Set(ResultStage 31)
2021-12-08 10:36:32,440 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - failed: Set()
2021-12-08 10:36:32,440 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 31 (MapPartitionsRDD[48] at values at ALS.scala:1711), which has no missing parents
2021-12-08 10:36:32,442 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_15 stored as values in memory (estimated size 654.6 KB, free 1667.1 MB)
2021-12-08 10:36:32,444 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_15_piece0 stored as bytes in memory (estimated size 479.4 KB, free 1666.6 MB)
2021-12-08 10:36:32,444 [dispatcher-event-loop-0] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_15_piece0 in memory on qb:55657 (size: 479.4 KB, free: 1668.4 MB)
2021-12-08 10:36:32,444 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 15 from broadcast at DAGScheduler.scala:1039
2021-12-08 10:36:32,445 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 12 missing tasks from ResultStage 31 (MapPartitionsRDD[48] at values at ALS.scala:1711) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11))
2021-12-08 10:36:32,445 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 31.0 with 12 tasks
2021-12-08 10:36:32,445 [dispatcher-event-loop-4] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 31.0 (TID 140, localhost, executor driver, partition 0, PROCESS_LOCAL, 7888 bytes)
2021-12-08 10:36:32,445 [dispatcher-event-loop-4] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 31.0 (TID 141, localhost, executor driver, partition 1, PROCESS_LOCAL, 7888 bytes)
2021-12-08 10:36:32,445 [dispatcher-event-loop-4] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 2.0 in stage 31.0 (TID 142, localhost, executor driver, partition 2, PROCESS_LOCAL, 7888 bytes)
2021-12-08 10:36:32,445 [dispatcher-event-loop-4] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 3.0 in stage 31.0 (TID 143, localhost, executor driver, partition 3, PROCESS_LOCAL, 7888 bytes)
2021-12-08 10:36:32,445 [dispatcher-event-loop-4] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 4.0 in stage 31.0 (TID 144, localhost, executor driver, partition 4, PROCESS_LOCAL, 7888 bytes)
2021-12-08 10:36:32,446 [dispatcher-event-loop-4] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 5.0 in stage 31.0 (TID 145, localhost, executor driver, partition 5, PROCESS_LOCAL, 7888 bytes)
2021-12-08 10:36:32,446 [dispatcher-event-loop-4] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 6.0 in stage 31.0 (TID 146, localhost, executor driver, partition 6, PROCESS_LOCAL, 7888 bytes)
2021-12-08 10:36:32,446 [dispatcher-event-loop-4] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 7.0 in stage 31.0 (TID 147, localhost, executor driver, partition 7, PROCESS_LOCAL, 7888 bytes)
2021-12-08 10:36:32,446 [dispatcher-event-loop-4] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 8.0 in stage 31.0 (TID 148, localhost, executor driver, partition 8, PROCESS_LOCAL, 7888 bytes)
2021-12-08 10:36:32,446 [dispatcher-event-loop-4] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 9.0 in stage 31.0 (TID 149, localhost, executor driver, partition 9, PROCESS_LOCAL, 7888 bytes)
2021-12-08 10:36:32,446 [dispatcher-event-loop-4] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 10.0 in stage 31.0 (TID 150, localhost, executor driver, partition 10, PROCESS_LOCAL, 7888 bytes)
2021-12-08 10:36:32,446 [dispatcher-event-loop-4] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 11.0 in stage 31.0 (TID 151, localhost, executor driver, partition 11, PROCESS_LOCAL, 7888 bytes)
2021-12-08 10:36:32,446 [Executor task launch worker for task 140] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 31.0 (TID 140)
2021-12-08 10:36:32,446 [Executor task launch worker for task 142] INFO [org.apache.spark.executor.Executor] - Running task 2.0 in stage 31.0 (TID 142)
2021-12-08 10:36:32,446 [Executor task launch worker for task 148] INFO [org.apache.spark.executor.Executor] - Running task 8.0 in stage 31.0 (TID 148)
2021-12-08 10:36:32,446 [Executor task launch worker for task 147] INFO [org.apache.spark.executor.Executor] - Running task 7.0 in stage 31.0 (TID 147)
2021-12-08 10:36:32,446 [Executor task launch worker for task 141] INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 31.0 (TID 141)
2021-12-08 10:36:32,446 [Executor task launch worker for task 146] INFO [org.apache.spark.executor.Executor] - Running task 6.0 in stage 31.0 (TID 146)
2021-12-08 10:36:32,446 [Executor task launch worker for task 144] INFO [org.apache.spark.executor.Executor] - Running task 4.0 in stage 31.0 (TID 144)
2021-12-08 10:36:32,446 [Executor task launch worker for task 145] INFO [org.apache.spark.executor.Executor] - Running task 5.0 in stage 31.0 (TID 145)
2021-12-08 10:36:32,446 [Executor task launch worker for task 143] INFO [org.apache.spark.executor.Executor] - Running task 3.0 in stage 31.0 (TID 143)
2021-12-08 10:36:32,446 [Executor task launch worker for task 150] INFO [org.apache.spark.executor.Executor] - Running task 10.0 in stage 31.0 (TID 150)
2021-12-08 10:36:32,446 [Executor task launch worker for task 149] INFO [org.apache.spark.executor.Executor] - Running task 9.0 in stage 31.0 (TID 149)
2021-12-08 10:36:32,446 [Executor task launch worker for task 151] INFO [org.apache.spark.executor.Executor] - Running task 11.0 in stage 31.0 (TID 151)
2021-12-08 10:36:32,449 [Executor task launch worker for task 144] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_14_4 locally
2021-12-08 10:36:32,449 [Executor task launch worker for task 146] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_14_6 locally
2021-12-08 10:36:32,449 [Executor task launch worker for task 150] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_14_10 locally
2021-12-08 10:36:32,449 [Executor task launch worker for task 149] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_14_9 locally
2021-12-08 10:36:32,449 [Executor task launch worker for task 147] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_14_7 locally
2021-12-08 10:36:32,449 [Executor task launch worker for task 143] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_14_3 locally
2021-12-08 10:36:32,449 [Executor task launch worker for task 151] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_14_11 locally
2021-12-08 10:36:32,449 [Executor task launch worker for task 145] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_14_5 locally
2021-12-08 10:36:32,449 [Executor task launch worker for task 140] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_14_0 locally
2021-12-08 10:36:32,449 [Executor task launch worker for task 142] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_14_2 locally
2021-12-08 10:36:32,449 [Executor task launch worker for task 143] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 12 non-empty blocks out of 12 blocks
2021-12-08 10:36:32,449 [Executor task launch worker for task 144] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 12 non-empty blocks out of 12 blocks
2021-12-08 10:36:32,449 [Executor task launch worker for task 146] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 12 non-empty blocks out of 12 blocks
2021-12-08 10:36:32,449 [Executor task launch worker for task 146] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-08 10:36:32,449 [Executor task launch worker for task 142] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 12 non-empty blocks out of 12 blocks
2021-12-08 10:36:32,449 [Executor task launch worker for task 145] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 12 non-empty blocks out of 12 blocks
2021-12-08 10:36:32,449 [Executor task launch worker for task 144] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-08 10:36:32,449 [Executor task launch worker for task 150] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 12 non-empty blocks out of 12 blocks
2021-12-08 10:36:32,449 [Executor task launch worker for task 150] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-08 10:36:32,449 [Executor task launch worker for task 143] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-08 10:36:32,449 [Executor task launch worker for task 149] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 12 non-empty blocks out of 12 blocks
2021-12-08 10:36:32,449 [Executor task launch worker for task 140] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 12 non-empty blocks out of 12 blocks
2021-12-08 10:36:32,449 [Executor task launch worker for task 145] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-08 10:36:32,449 [Executor task launch worker for task 142] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-08 10:36:32,449 [Executor task launch worker for task 147] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 12 non-empty blocks out of 12 blocks
2021-12-08 10:36:32,449 [Executor task launch worker for task 151] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 12 non-empty blocks out of 12 blocks
2021-12-08 10:36:32,449 [Executor task launch worker for task 140] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-08 10:36:32,449 [Executor task launch worker for task 149] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-08 10:36:32,449 [Executor task launch worker for task 151] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-08 10:36:32,449 [Executor task launch worker for task 147] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-08 10:36:32,450 [Executor task launch worker for task 148] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_14_8 locally
2021-12-08 10:36:32,450 [Executor task launch worker for task 141] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_14_1 locally
2021-12-08 10:36:32,450 [Executor task launch worker for task 148] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 12 non-empty blocks out of 12 blocks
2021-12-08 10:36:32,450 [Executor task launch worker for task 148] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-08 10:36:32,450 [Executor task launch worker for task 141] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 12 non-empty blocks out of 12 blocks
2021-12-08 10:36:32,450 [Executor task launch worker for task 141] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-08 10:36:32,539 [dispatcher-event-loop-8] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_14_piece0 on qb:55657 in memory (size: 320.6 KB, free: 1668.7 MB)
2021-12-08 10:36:32,829 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 301
2021-12-08 10:36:32,829 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 289
2021-12-08 10:36:32,829 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 303
2021-12-08 10:36:32,829 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 285
2021-12-08 10:36:32,829 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 311
2021-12-08 10:36:32,829 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 286
2021-12-08 10:36:32,829 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 319
2021-12-08 10:36:32,829 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 278
2021-12-08 10:36:32,831 [dispatcher-event-loop-5] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_13_piece0 on qb:55657 in memory (size: 321.7 KB, free: 1669.0 MB)
2021-12-08 10:36:32,832 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 302
2021-12-08 10:36:32,832 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 318
2021-12-08 10:36:32,832 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 297
2021-12-08 10:36:32,833 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 306
2021-12-08 10:36:32,833 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 277
2021-12-08 10:36:32,833 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 295
2021-12-08 10:36:32,833 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 290
2021-12-08 10:36:32,833 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 275
2021-12-08 10:36:32,833 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 304
2021-12-08 10:36:32,833 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 291
2021-12-08 10:36:32,833 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 299
2021-12-08 10:36:32,833 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 279
2021-12-08 10:36:32,833 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 280
2021-12-08 10:36:32,833 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 316
2021-12-08 10:36:32,833 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 296
2021-12-08 10:36:32,833 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 283
2021-12-08 10:36:32,833 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 276
2021-12-08 10:36:32,833 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 281
2021-12-08 10:36:32,833 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 310
2021-12-08 10:36:32,833 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 305
2021-12-08 10:36:32,833 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 307
2021-12-08 10:36:32,833 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 300
2021-12-08 10:36:32,833 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 314
2021-12-08 10:36:32,833 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 294
2021-12-08 10:36:32,833 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 312
2021-12-08 10:36:32,833 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 315
2021-12-08 10:36:32,833 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 293
2021-12-08 10:36:32,833 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 298
2021-12-08 10:36:32,833 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 282
2021-12-08 10:36:32,833 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 308
2021-12-08 10:36:32,833 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 288
2021-12-08 10:36:32,833 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 323
2021-12-08 10:36:32,833 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 309
2021-12-08 10:36:32,833 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 287
2021-12-08 10:36:32,833 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 313
2021-12-08 10:36:32,833 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 322
2021-12-08 10:36:32,833 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 321
2021-12-08 10:36:32,833 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 317
2021-12-08 10:36:32,833 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 324
2021-12-08 10:36:32,833 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 320
2021-12-08 10:36:32,833 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 292
2021-12-08 10:36:32,833 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 284
2021-12-08 10:36:55,201 [Executor task launch worker for task 145] INFO [org.apache.spark.storage.memory.MemoryStore] - Block rdd_47_5 stored as values in memory (estimated size 4.0 MB, free 1664.1 MB)
2021-12-08 10:36:55,202 [dispatcher-event-loop-4] INFO [org.apache.spark.storage.BlockManagerInfo] - Added rdd_47_5 in memory on qb:55657 (size: 4.0 MB, free: 1665.0 MB)
2021-12-08 10:36:55,327 [Executor task launch worker for task 145] INFO [org.apache.spark.executor.Executor] - Finished task 5.0 in stage 31.0 (TID 145). 166054 bytes result sent to driver
2021-12-08 10:36:55,328 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 5.0 in stage 31.0 (TID 145) in 22883 ms on localhost (executor driver) (1/12)
2021-12-08 10:36:56,132 [Executor task launch worker for task 151] INFO [org.apache.spark.storage.memory.MemoryStore] - Block rdd_47_11 stored as values in memory (estimated size 4.0 MB, free 1660.1 MB)
2021-12-08 10:36:56,133 [dispatcher-event-loop-2] INFO [org.apache.spark.storage.BlockManagerInfo] - Added rdd_47_11 in memory on qb:55657 (size: 4.0 MB, free: 1661.0 MB)
2021-12-08 10:36:56,172 [Executor task launch worker for task 140] INFO [org.apache.spark.storage.memory.MemoryStore] - Block rdd_47_0 stored as values in memory (estimated size 4.0 MB, free 1656.1 MB)
2021-12-08 10:36:56,172 [dispatcher-event-loop-1] INFO [org.apache.spark.storage.BlockManagerInfo] - Added rdd_47_0 in memory on qb:55657 (size: 4.0 MB, free: 1657.1 MB)
2021-12-08 10:36:56,254 [Executor task launch worker for task 151] INFO [org.apache.spark.executor.Executor] - Finished task 11.0 in stage 31.0 (TID 151). 166097 bytes result sent to driver
2021-12-08 10:36:56,263 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 11.0 in stage 31.0 (TID 151) in 23817 ms on localhost (executor driver) (2/12)
2021-12-08 10:36:56,304 [Executor task launch worker for task 140] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 31.0 (TID 140). 166097 bytes result sent to driver
2021-12-08 10:36:56,305 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 31.0 (TID 140) in 23860 ms on localhost (executor driver) (3/12)
2021-12-08 10:36:56,725 [Executor task launch worker for task 150] INFO [org.apache.spark.storage.memory.MemoryStore] - Block rdd_47_10 stored as values in memory (estimated size 4.0 MB, free 1652.1 MB)
2021-12-08 10:36:56,726 [dispatcher-event-loop-9] INFO [org.apache.spark.storage.BlockManagerInfo] - Added rdd_47_10 in memory on qb:55657 (size: 4.0 MB, free: 1653.1 MB)
2021-12-08 10:36:56,854 [Executor task launch worker for task 150] INFO [org.apache.spark.executor.Executor] - Finished task 10.0 in stage 31.0 (TID 150). 166097 bytes result sent to driver
2021-12-08 10:36:56,855 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 10.0 in stage 31.0 (TID 150) in 24409 ms on localhost (executor driver) (4/12)
2021-12-08 10:36:57,157 [Executor task launch worker for task 141] INFO [org.apache.spark.storage.memory.MemoryStore] - Block rdd_47_1 stored as values in memory (estimated size 4.0 MB, free 1648.1 MB)
2021-12-08 10:36:57,157 [dispatcher-event-loop-3] INFO [org.apache.spark.storage.BlockManagerInfo] - Added rdd_47_1 in memory on qb:55657 (size: 4.0 MB, free: 1649.1 MB)
2021-12-08 10:36:57,270 [Executor task launch worker for task 141] INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 31.0 (TID 141). 166097 bytes result sent to driver
2021-12-08 10:36:57,271 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 31.0 (TID 141) in 24826 ms on localhost (executor driver) (5/12)
2021-12-08 10:36:57,683 [Executor task launch worker for task 144] INFO [org.apache.spark.storage.memory.MemoryStore] - Block rdd_47_4 stored as values in memory (estimated size 4.0 MB, free 1644.1 MB)
2021-12-08 10:36:57,683 [dispatcher-event-loop-11] INFO [org.apache.spark.storage.BlockManagerInfo] - Added rdd_47_4 in memory on qb:55657 (size: 4.0 MB, free: 1645.1 MB)
2021-12-08 10:36:57,785 [Executor task launch worker for task 144] INFO [org.apache.spark.executor.Executor] - Finished task 4.0 in stage 31.0 (TID 144). 166097 bytes result sent to driver
2021-12-08 10:36:57,786 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 4.0 in stage 31.0 (TID 144) in 25341 ms on localhost (executor driver) (6/12)
2021-12-08 10:36:57,806 [Executor task launch worker for task 143] INFO [org.apache.spark.storage.memory.MemoryStore] - Block rdd_47_3 stored as values in memory (estimated size 4.0 MB, free 1640.2 MB)
2021-12-08 10:36:57,806 [dispatcher-event-loop-4] INFO [org.apache.spark.storage.BlockManagerInfo] - Added rdd_47_3 in memory on qb:55657 (size: 4.0 MB, free: 1641.1 MB)
2021-12-08 10:36:57,903 [Executor task launch worker for task 143] INFO [org.apache.spark.executor.Executor] - Finished task 3.0 in stage 31.0 (TID 143). 166097 bytes result sent to driver
2021-12-08 10:36:57,904 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 3.0 in stage 31.0 (TID 143) in 25459 ms on localhost (executor driver) (7/12)
2021-12-08 10:36:58,113 [Executor task launch worker for task 146] INFO [org.apache.spark.storage.memory.MemoryStore] - Block rdd_47_6 stored as values in memory (estimated size 4.0 MB, free 1636.2 MB)
2021-12-08 10:36:58,113 [dispatcher-event-loop-2] INFO [org.apache.spark.storage.BlockManagerInfo] - Added rdd_47_6 in memory on qb:55657 (size: 4.0 MB, free: 1637.1 MB)
2021-12-08 10:36:58,210 [Executor task launch worker for task 146] INFO [org.apache.spark.executor.Executor] - Finished task 6.0 in stage 31.0 (TID 146). 166054 bytes result sent to driver
2021-12-08 10:36:58,211 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 6.0 in stage 31.0 (TID 146) in 25765 ms on localhost (executor driver) (8/12)
2021-12-08 10:36:58,424 [Executor task launch worker for task 148] INFO [org.apache.spark.storage.memory.MemoryStore] - Block rdd_47_8 stored as values in memory (estimated size 4.0 MB, free 1632.2 MB)
2021-12-08 10:36:58,425 [dispatcher-event-loop-8] INFO [org.apache.spark.storage.BlockManagerInfo] - Added rdd_47_8 in memory on qb:55657 (size: 4.0 MB, free: 1633.1 MB)
2021-12-08 10:36:58,471 [Executor task launch worker for task 142] INFO [org.apache.spark.storage.memory.MemoryStore] - Block rdd_47_2 stored as values in memory (estimated size 4.0 MB, free 1628.2 MB)
2021-12-08 10:36:58,472 [dispatcher-event-loop-6] INFO [org.apache.spark.storage.BlockManagerInfo] - Added rdd_47_2 in memory on qb:55657 (size: 4.0 MB, free: 1629.1 MB)
2021-12-08 10:36:58,475 [Executor task launch worker for task 147] INFO [org.apache.spark.storage.memory.MemoryStore] - Block rdd_47_7 stored as values in memory (estimated size 4.0 MB, free 1624.2 MB)
2021-12-08 10:36:58,475 [dispatcher-event-loop-9] INFO [org.apache.spark.storage.BlockManagerInfo] - Added rdd_47_7 in memory on qb:55657 (size: 4.0 MB, free: 1625.1 MB)
2021-12-08 10:36:58,531 [Executor task launch worker for task 148] INFO [org.apache.spark.executor.Executor] - Finished task 8.0 in stage 31.0 (TID 148). 166054 bytes result sent to driver
2021-12-08 10:36:58,532 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 8.0 in stage 31.0 (TID 148) in 26086 ms on localhost (executor driver) (9/12)
2021-12-08 10:36:58,558 [Executor task launch worker for task 147] INFO [org.apache.spark.executor.Executor] - Finished task 7.0 in stage 31.0 (TID 147). 166054 bytes result sent to driver
2021-12-08 10:36:58,559 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 7.0 in stage 31.0 (TID 147) in 26113 ms on localhost (executor driver) (10/12)
2021-12-08 10:36:58,566 [Executor task launch worker for task 142] INFO [org.apache.spark.executor.Executor] - Finished task 2.0 in stage 31.0 (TID 142). 166097 bytes result sent to driver
2021-12-08 10:36:58,567 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 2.0 in stage 31.0 (TID 142) in 26122 ms on localhost (executor driver) (11/12)
2021-12-08 10:36:59,088 [Executor task launch worker for task 149] INFO [org.apache.spark.storage.memory.MemoryStore] - Block rdd_47_9 stored as values in memory (estimated size 4.0 MB, free 1620.2 MB)
2021-12-08 10:36:59,088 [dispatcher-event-loop-4] INFO [org.apache.spark.storage.BlockManagerInfo] - Added rdd_47_9 in memory on qb:55657 (size: 4.0 MB, free: 1621.2 MB)
2021-12-08 10:36:59,153 [Executor task launch worker for task 149] INFO [org.apache.spark.executor.Executor] - Finished task 9.0 in stage 31.0 (TID 149). 166097 bytes result sent to driver
2021-12-08 10:36:59,153 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 9.0 in stage 31.0 (TID 149) in 26707 ms on localhost (executor driver) (12/12)
2021-12-08 10:36:59,153 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 31.0, whose tasks have all completed, from pool 
2021-12-08 10:36:59,153 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 31 (aggregate at ALS.scala:1711) finished in 26.712 s
2021-12-08 10:36:59,154 [main] INFO [org.apache.spark.scheduler.DAGScheduler] - Job 7 finished: aggregate at ALS.scala:1711, took 28.584167 s
2021-12-08 10:36:59,172 [main] INFO [org.apache.spark.rdd.MapPartitionsRDD] - Removing RDD 37 from persistence list
2021-12-08 10:36:59,173 [block-manager-slave-async-thread-pool-2] INFO [org.apache.spark.storage.BlockManager] - Removing RDD 37
2021-12-08 10:36:59,180 [main] INFO [org.apache.spark.SparkContext] - Starting job: aggregate at ALS.scala:1711
2021-12-08 10:36:59,181 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 52 (flatMap at ALS.scala:1653)
2021-12-08 10:36:59,181 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 8 (aggregate at ALS.scala:1711) with 12 output partitions
2021-12-08 10:36:59,181 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 40 (aggregate at ALS.scala:1711)
2021-12-08 10:36:59,181 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 33, ShuffleMapStage 39)
2021-12-08 10:36:59,182 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List(ShuffleMapStage 39)
2021-12-08 10:36:59,182 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ShuffleMapStage 39 (MapPartitionsRDD[52] at flatMap at ALS.scala:1653), which has no missing parents
2021-12-08 10:36:59,184 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_16 stored as values in memory (estimated size 494.1 KB, free 1753.0 MB)
2021-12-08 10:36:59,186 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_16_piece0 stored as bytes in memory (estimated size 478.4 KB, free 1752.5 MB)
2021-12-08 10:36:59,186 [dispatcher-event-loop-3] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_16_piece0 in memory on qb:55657 (size: 478.4 KB, free: 1753.9 MB)
2021-12-08 10:36:59,187 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 16 from broadcast at DAGScheduler.scala:1039
2021-12-08 10:36:59,188 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 12 missing tasks from ShuffleMapStage 39 (MapPartitionsRDD[52] at flatMap at ALS.scala:1653) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11))
2021-12-08 10:36:59,188 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 39.0 with 12 tasks
2021-12-08 10:36:59,188 [dispatcher-event-loop-7] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 39.0 (TID 152, localhost, executor driver, partition 0, PROCESS_LOCAL, 7928 bytes)
2021-12-08 10:36:59,188 [dispatcher-event-loop-7] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 39.0 (TID 153, localhost, executor driver, partition 1, PROCESS_LOCAL, 7928 bytes)
2021-12-08 10:36:59,189 [dispatcher-event-loop-7] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 2.0 in stage 39.0 (TID 154, localhost, executor driver, partition 2, PROCESS_LOCAL, 7928 bytes)
2021-12-08 10:36:59,189 [dispatcher-event-loop-7] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 3.0 in stage 39.0 (TID 155, localhost, executor driver, partition 3, PROCESS_LOCAL, 7928 bytes)
2021-12-08 10:36:59,189 [dispatcher-event-loop-7] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 4.0 in stage 39.0 (TID 156, localhost, executor driver, partition 4, PROCESS_LOCAL, 7928 bytes)
2021-12-08 10:36:59,189 [dispatcher-event-loop-7] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 5.0 in stage 39.0 (TID 157, localhost, executor driver, partition 5, PROCESS_LOCAL, 7928 bytes)
2021-12-08 10:36:59,189 [dispatcher-event-loop-7] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 6.0 in stage 39.0 (TID 158, localhost, executor driver, partition 6, PROCESS_LOCAL, 7928 bytes)
2021-12-08 10:36:59,189 [dispatcher-event-loop-7] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 7.0 in stage 39.0 (TID 159, localhost, executor driver, partition 7, PROCESS_LOCAL, 7928 bytes)
2021-12-08 10:36:59,189 [dispatcher-event-loop-7] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 8.0 in stage 39.0 (TID 160, localhost, executor driver, partition 8, PROCESS_LOCAL, 7928 bytes)
2021-12-08 10:36:59,189 [dispatcher-event-loop-7] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 9.0 in stage 39.0 (TID 161, localhost, executor driver, partition 9, PROCESS_LOCAL, 7928 bytes)
2021-12-08 10:36:59,189 [dispatcher-event-loop-7] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 10.0 in stage 39.0 (TID 162, localhost, executor driver, partition 10, PROCESS_LOCAL, 7928 bytes)
2021-12-08 10:36:59,189 [dispatcher-event-loop-7] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 11.0 in stage 39.0 (TID 163, localhost, executor driver, partition 11, PROCESS_LOCAL, 7928 bytes)
2021-12-08 10:36:59,189 [Executor task launch worker for task 153] INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 39.0 (TID 153)
2021-12-08 10:36:59,189 [Executor task launch worker for task 154] INFO [org.apache.spark.executor.Executor] - Running task 2.0 in stage 39.0 (TID 154)
2021-12-08 10:36:59,189 [Executor task launch worker for task 162] INFO [org.apache.spark.executor.Executor] - Running task 10.0 in stage 39.0 (TID 162)
2021-12-08 10:36:59,189 [Executor task launch worker for task 161] INFO [org.apache.spark.executor.Executor] - Running task 9.0 in stage 39.0 (TID 161)
2021-12-08 10:36:59,189 [Executor task launch worker for task 155] INFO [org.apache.spark.executor.Executor] - Running task 3.0 in stage 39.0 (TID 155)
2021-12-08 10:36:59,189 [Executor task launch worker for task 157] INFO [org.apache.spark.executor.Executor] - Running task 5.0 in stage 39.0 (TID 157)
2021-12-08 10:36:59,189 [Executor task launch worker for task 152] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 39.0 (TID 152)
2021-12-08 10:36:59,189 [Executor task launch worker for task 156] INFO [org.apache.spark.executor.Executor] - Running task 4.0 in stage 39.0 (TID 156)
2021-12-08 10:36:59,189 [Executor task launch worker for task 159] INFO [org.apache.spark.executor.Executor] - Running task 7.0 in stage 39.0 (TID 159)
2021-12-08 10:36:59,189 [Executor task launch worker for task 158] INFO [org.apache.spark.executor.Executor] - Running task 6.0 in stage 39.0 (TID 158)
2021-12-08 10:36:59,189 [Executor task launch worker for task 163] INFO [org.apache.spark.executor.Executor] - Running task 11.0 in stage 39.0 (TID 163)
2021-12-08 10:36:59,189 [Executor task launch worker for task 160] INFO [org.apache.spark.executor.Executor] - Running task 8.0 in stage 39.0 (TID 160)
2021-12-08 10:36:59,191 [Executor task launch worker for task 153] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_15_1 locally
2021-12-08 10:36:59,191 [Executor task launch worker for task 154] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_15_2 locally
2021-12-08 10:36:59,191 [Executor task launch worker for task 163] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_15_11 locally
2021-12-08 10:36:59,191 [Executor task launch worker for task 158] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_15_6 locally
2021-12-08 10:36:59,191 [Executor task launch worker for task 159] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_15_7 locally
2021-12-08 10:36:59,191 [Executor task launch worker for task 162] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_15_10 locally
2021-12-08 10:36:59,191 [Executor task launch worker for task 159] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_47_7 locally
2021-12-08 10:36:59,192 [Executor task launch worker for task 158] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_47_6 locally
2021-12-08 10:36:59,192 [Executor task launch worker for task 156] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_15_4 locally
2021-12-08 10:36:59,192 [Executor task launch worker for task 156] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_47_4 locally
2021-12-08 10:36:59,192 [Executor task launch worker for task 152] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_15_0 locally
2021-12-08 10:36:59,191 [Executor task launch worker for task 163] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_47_11 locally
2021-12-08 10:36:59,192 [Executor task launch worker for task 154] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_47_2 locally
2021-12-08 10:36:59,192 [Executor task launch worker for task 160] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_15_8 locally
2021-12-08 10:36:59,191 [Executor task launch worker for task 153] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_47_1 locally
2021-12-08 10:36:59,192 [Executor task launch worker for task 160] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_47_8 locally
2021-12-08 10:36:59,193 [Executor task launch worker for task 157] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_15_5 locally
2021-12-08 10:36:59,193 [Executor task launch worker for task 157] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_47_5 locally
2021-12-08 10:36:59,192 [Executor task launch worker for task 155] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_15_3 locally
2021-12-08 10:36:59,197 [Executor task launch worker for task 155] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_47_3 locally
2021-12-08 10:36:59,191 [Executor task launch worker for task 162] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_47_10 locally
2021-12-08 10:36:59,192 [Executor task launch worker for task 161] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_15_9 locally
2021-12-08 10:36:59,198 [Executor task launch worker for task 161] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_47_9 locally
2021-12-08 10:36:59,198 [Executor task launch worker for task 152] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_47_0 locally
2021-12-08 10:36:59,470 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 339
2021-12-08 10:36:59,470 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 326
2021-12-08 10:36:59,470 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 344
2021-12-08 10:36:59,470 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 330
2021-12-08 10:36:59,470 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 361
2021-12-08 10:36:59,470 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 372
2021-12-08 10:36:59,470 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 352
2021-12-08 10:36:59,470 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 328
2021-12-08 10:36:59,470 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 341
2021-12-08 10:36:59,470 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 350
2021-12-08 10:36:59,470 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 369
2021-12-08 10:36:59,470 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 359
2021-12-08 10:36:59,470 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 364
2021-12-08 10:36:59,470 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 325
2021-12-08 10:36:59,470 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 366
2021-12-08 10:36:59,470 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 362
2021-12-08 10:36:59,470 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 358
2021-12-08 10:36:59,470 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 373
2021-12-08 10:36:59,470 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 346
2021-12-08 10:36:59,470 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 337
2021-12-08 10:36:59,471 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 348
2021-12-08 10:36:59,471 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 370
2021-12-08 10:36:59,471 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 349
2021-12-08 10:36:59,471 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 336
2021-12-08 10:36:59,471 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 363
2021-12-08 10:36:59,471 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 365
2021-12-08 10:36:59,471 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 329
2021-12-08 10:36:59,471 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 354
2021-12-08 10:36:59,471 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 342
2021-12-08 10:36:59,471 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 374
2021-12-08 10:36:59,471 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 332
2021-12-08 10:36:59,472 [dispatcher-event-loop-11] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_15_piece0 on qb:55657 in memory (size: 479.4 KB, free: 1754.4 MB)
2021-12-08 10:36:59,473 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 345
2021-12-08 10:36:59,473 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 347
2021-12-08 10:36:59,473 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 351
2021-12-08 10:36:59,473 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 335
2021-12-08 10:36:59,473 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 371
2021-12-08 10:36:59,473 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 353
2021-12-08 10:36:59,473 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 343
2021-12-08 10:36:59,473 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 334
2021-12-08 10:36:59,473 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 357
2021-12-08 10:36:59,473 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 340
2021-12-08 10:36:59,473 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 360
2021-12-08 10:36:59,473 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 356
2021-12-08 10:36:59,473 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 355
2021-12-08 10:36:59,473 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 333
2021-12-08 10:36:59,473 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 338
2021-12-08 10:36:59,473 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 327
2021-12-08 10:36:59,473 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 368
2021-12-08 10:36:59,473 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 367
2021-12-08 10:36:59,473 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 331
2021-12-08 10:36:59,986 [Executor task launch worker for task 160] INFO [org.apache.spark.executor.Executor] - Finished task 8.0 in stage 39.0 (TID 160). 1085 bytes result sent to driver
2021-12-08 10:36:59,986 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 8.0 in stage 39.0 (TID 160) in 797 ms on localhost (executor driver) (1/12)
2021-12-08 10:36:59,987 [Executor task launch worker for task 162] INFO [org.apache.spark.executor.Executor] - Finished task 10.0 in stage 39.0 (TID 162). 1042 bytes result sent to driver
2021-12-08 10:36:59,988 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 10.0 in stage 39.0 (TID 162) in 799 ms on localhost (executor driver) (2/12)
2021-12-08 10:36:59,989 [Executor task launch worker for task 154] INFO [org.apache.spark.executor.Executor] - Finished task 2.0 in stage 39.0 (TID 154). 1042 bytes result sent to driver
2021-12-08 10:36:59,990 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 2.0 in stage 39.0 (TID 154) in 802 ms on localhost (executor driver) (3/12)
2021-12-08 10:36:59,991 [Executor task launch worker for task 153] INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 39.0 (TID 153). 1085 bytes result sent to driver
2021-12-08 10:36:59,991 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 39.0 (TID 153) in 803 ms on localhost (executor driver) (4/12)
2021-12-08 10:36:59,998 [Executor task launch worker for task 155] INFO [org.apache.spark.executor.Executor] - Finished task 3.0 in stage 39.0 (TID 155). 1042 bytes result sent to driver
2021-12-08 10:36:59,999 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 3.0 in stage 39.0 (TID 155) in 810 ms on localhost (executor driver) (5/12)
2021-12-08 10:37:00,000 [Executor task launch worker for task 152] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 39.0 (TID 152). 1042 bytes result sent to driver
2021-12-08 10:37:00,001 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 39.0 (TID 152) in 813 ms on localhost (executor driver) (6/12)
2021-12-08 10:37:00,002 [Executor task launch worker for task 158] INFO [org.apache.spark.executor.Executor] - Finished task 6.0 in stage 39.0 (TID 158). 1042 bytes result sent to driver
2021-12-08 10:37:00,003 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 6.0 in stage 39.0 (TID 158) in 814 ms on localhost (executor driver) (7/12)
2021-12-08 10:37:00,025 [Executor task launch worker for task 161] INFO [org.apache.spark.executor.Executor] - Finished task 9.0 in stage 39.0 (TID 161). 1042 bytes result sent to driver
2021-12-08 10:37:00,026 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 9.0 in stage 39.0 (TID 161) in 837 ms on localhost (executor driver) (8/12)
2021-12-08 10:37:00,036 [Executor task launch worker for task 159] INFO [org.apache.spark.executor.Executor] - Finished task 7.0 in stage 39.0 (TID 159). 1042 bytes result sent to driver
2021-12-08 10:37:00,036 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 7.0 in stage 39.0 (TID 159) in 847 ms on localhost (executor driver) (9/12)
2021-12-08 10:37:00,104 [Executor task launch worker for task 156] INFO [org.apache.spark.executor.Executor] - Finished task 4.0 in stage 39.0 (TID 156). 1042 bytes result sent to driver
2021-12-08 10:37:00,105 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 4.0 in stage 39.0 (TID 156) in 916 ms on localhost (executor driver) (10/12)
2021-12-08 10:37:00,128 [Executor task launch worker for task 163] INFO [org.apache.spark.executor.Executor] - Finished task 11.0 in stage 39.0 (TID 163). 1042 bytes result sent to driver
2021-12-08 10:37:00,128 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 11.0 in stage 39.0 (TID 163) in 939 ms on localhost (executor driver) (11/12)
2021-12-08 10:37:00,136 [Executor task launch worker for task 157] INFO [org.apache.spark.executor.Executor] - Finished task 5.0 in stage 39.0 (TID 157). 1042 bytes result sent to driver
2021-12-08 10:37:00,137 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 5.0 in stage 39.0 (TID 157) in 948 ms on localhost (executor driver) (12/12)
2021-12-08 10:37:00,137 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 39.0, whose tasks have all completed, from pool 
2021-12-08 10:37:00,137 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ShuffleMapStage 39 (flatMap at ALS.scala:1653) finished in 0.954 s
2021-12-08 10:37:00,137 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - looking for newly runnable stages
2021-12-08 10:37:00,137 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - running: Set()
2021-12-08 10:37:00,137 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - waiting: Set(ResultStage 40)
2021-12-08 10:37:00,137 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - failed: Set()
2021-12-08 10:37:00,137 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 40 (MapPartitionsRDD[58] at values at ALS.scala:1711), which has no missing parents
2021-12-08 10:37:00,139 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_17 stored as values in memory (estimated size 815.7 KB, free 1752.8 MB)
2021-12-08 10:37:00,141 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_17_piece0 stored as bytes in memory (estimated size 637.1 KB, free 1752.2 MB)
2021-12-08 10:37:00,141 [dispatcher-event-loop-2] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_17_piece0 in memory on qb:55657 (size: 637.1 KB, free: 1753.8 MB)
2021-12-08 10:37:00,142 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 17 from broadcast at DAGScheduler.scala:1039
2021-12-08 10:37:00,142 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 12 missing tasks from ResultStage 40 (MapPartitionsRDD[58] at values at ALS.scala:1711) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11))
2021-12-08 10:37:00,142 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 40.0 with 12 tasks
2021-12-08 10:37:00,142 [dispatcher-event-loop-8] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 40.0 (TID 164, localhost, executor driver, partition 0, PROCESS_LOCAL, 7888 bytes)
2021-12-08 10:37:00,142 [dispatcher-event-loop-8] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 40.0 (TID 165, localhost, executor driver, partition 1, PROCESS_LOCAL, 7888 bytes)
2021-12-08 10:37:00,142 [dispatcher-event-loop-8] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 2.0 in stage 40.0 (TID 166, localhost, executor driver, partition 2, PROCESS_LOCAL, 7888 bytes)
2021-12-08 10:37:00,142 [dispatcher-event-loop-8] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 3.0 in stage 40.0 (TID 167, localhost, executor driver, partition 3, PROCESS_LOCAL, 7888 bytes)
2021-12-08 10:37:00,143 [dispatcher-event-loop-8] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 4.0 in stage 40.0 (TID 168, localhost, executor driver, partition 4, PROCESS_LOCAL, 7888 bytes)
2021-12-08 10:37:00,143 [dispatcher-event-loop-8] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 5.0 in stage 40.0 (TID 169, localhost, executor driver, partition 5, PROCESS_LOCAL, 7888 bytes)
2021-12-08 10:37:00,143 [dispatcher-event-loop-8] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 6.0 in stage 40.0 (TID 170, localhost, executor driver, partition 6, PROCESS_LOCAL, 7888 bytes)
2021-12-08 10:37:00,143 [dispatcher-event-loop-8] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 7.0 in stage 40.0 (TID 171, localhost, executor driver, partition 7, PROCESS_LOCAL, 7888 bytes)
2021-12-08 10:37:00,143 [dispatcher-event-loop-8] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 8.0 in stage 40.0 (TID 172, localhost, executor driver, partition 8, PROCESS_LOCAL, 7888 bytes)
2021-12-08 10:37:00,143 [dispatcher-event-loop-8] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 9.0 in stage 40.0 (TID 173, localhost, executor driver, partition 9, PROCESS_LOCAL, 7888 bytes)
2021-12-08 10:37:00,143 [dispatcher-event-loop-8] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 10.0 in stage 40.0 (TID 174, localhost, executor driver, partition 10, PROCESS_LOCAL, 7888 bytes)
2021-12-08 10:37:00,143 [dispatcher-event-loop-8] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 11.0 in stage 40.0 (TID 175, localhost, executor driver, partition 11, PROCESS_LOCAL, 7888 bytes)
2021-12-08 10:37:00,143 [Executor task launch worker for task 166] INFO [org.apache.spark.executor.Executor] - Running task 2.0 in stage 40.0 (TID 166)
2021-12-08 10:37:00,143 [Executor task launch worker for task 167] INFO [org.apache.spark.executor.Executor] - Running task 3.0 in stage 40.0 (TID 167)
2021-12-08 10:37:00,143 [Executor task launch worker for task 175] INFO [org.apache.spark.executor.Executor] - Running task 11.0 in stage 40.0 (TID 175)
2021-12-08 10:37:00,143 [Executor task launch worker for task 173] INFO [org.apache.spark.executor.Executor] - Running task 9.0 in stage 40.0 (TID 173)
2021-12-08 10:37:00,143 [Executor task launch worker for task 171] INFO [org.apache.spark.executor.Executor] - Running task 7.0 in stage 40.0 (TID 171)
2021-12-08 10:37:00,143 [Executor task launch worker for task 164] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 40.0 (TID 164)
2021-12-08 10:37:00,143 [Executor task launch worker for task 169] INFO [org.apache.spark.executor.Executor] - Running task 5.0 in stage 40.0 (TID 169)
2021-12-08 10:37:00,143 [Executor task launch worker for task 165] INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 40.0 (TID 165)
2021-12-08 10:37:00,143 [Executor task launch worker for task 168] INFO [org.apache.spark.executor.Executor] - Running task 4.0 in stage 40.0 (TID 168)
2021-12-08 10:37:00,143 [Executor task launch worker for task 172] INFO [org.apache.spark.executor.Executor] - Running task 8.0 in stage 40.0 (TID 172)
2021-12-08 10:37:00,143 [Executor task launch worker for task 170] INFO [org.apache.spark.executor.Executor] - Running task 6.0 in stage 40.0 (TID 170)
2021-12-08 10:37:00,143 [Executor task launch worker for task 174] INFO [org.apache.spark.executor.Executor] - Running task 10.0 in stage 40.0 (TID 174)
2021-12-08 10:37:00,146 [Executor task launch worker for task 173] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_9_9 locally
2021-12-08 10:37:00,147 [Executor task launch worker for task 171] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_9_7 locally
2021-12-08 10:37:00,147 [Executor task launch worker for task 167] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_9_3 locally
2021-12-08 10:37:00,147 [Executor task launch worker for task 170] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_9_6 locally
2021-12-08 10:37:00,147 [Executor task launch worker for task 170] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 12 non-empty blocks out of 12 blocks
2021-12-08 10:37:00,147 [Executor task launch worker for task 167] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 12 non-empty blocks out of 12 blocks
2021-12-08 10:37:00,147 [Executor task launch worker for task 171] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 12 non-empty blocks out of 12 blocks
2021-12-08 10:37:00,147 [Executor task launch worker for task 173] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 12 non-empty blocks out of 12 blocks
2021-12-08 10:37:00,148 [Executor task launch worker for task 171] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 1 ms
2021-12-08 10:37:00,147 [Executor task launch worker for task 167] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-08 10:37:00,148 [Executor task launch worker for task 169] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_9_5 locally
2021-12-08 10:37:00,147 [Executor task launch worker for task 170] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-08 10:37:00,147 [Executor task launch worker for task 174] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_9_10 locally
2021-12-08 10:37:00,147 [Executor task launch worker for task 175] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_9_11 locally
2021-12-08 10:37:00,148 [Executor task launch worker for task 168] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_9_4 locally
2021-12-08 10:37:00,148 [Executor task launch worker for task 164] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_9_0 locally
2021-12-08 10:37:00,148 [Executor task launch worker for task 173] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 1 ms
2021-12-08 10:37:00,148 [Executor task launch worker for task 175] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 12 non-empty blocks out of 12 blocks
2021-12-08 10:37:00,148 [Executor task launch worker for task 175] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-08 10:37:00,148 [Executor task launch worker for task 165] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_9_1 locally
2021-12-08 10:37:00,148 [Executor task launch worker for task 169] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 12 non-empty blocks out of 12 blocks
2021-12-08 10:37:00,148 [Executor task launch worker for task 174] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 12 non-empty blocks out of 12 blocks
2021-12-08 10:37:00,148 [Executor task launch worker for task 169] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-08 10:37:00,148 [Executor task launch worker for task 168] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 12 non-empty blocks out of 12 blocks
2021-12-08 10:37:00,148 [Executor task launch worker for task 165] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 12 non-empty blocks out of 12 blocks
2021-12-08 10:37:00,148 [Executor task launch worker for task 164] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 12 non-empty blocks out of 12 blocks
2021-12-08 10:37:00,148 [Executor task launch worker for task 174] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-08 10:37:00,148 [Executor task launch worker for task 164] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-08 10:37:00,148 [Executor task launch worker for task 165] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-08 10:37:00,148 [Executor task launch worker for task 168] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-08 10:37:00,148 [Executor task launch worker for task 166] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_9_2 locally
2021-12-08 10:37:00,148 [Executor task launch worker for task 172] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_9_8 locally
2021-12-08 10:37:00,148 [Executor task launch worker for task 166] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 12 non-empty blocks out of 12 blocks
2021-12-08 10:37:00,148 [Executor task launch worker for task 166] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-08 10:37:00,148 [Executor task launch worker for task 172] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 12 non-empty blocks out of 12 blocks
2021-12-08 10:37:00,148 [Executor task launch worker for task 172] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-08 10:37:37,130 [Executor task launch worker for task 166] INFO [org.apache.spark.storage.memory.MemoryStore] - Block rdd_57_2 stored as values in memory (estimated size 11.1 MB, free 1741.1 MB)
2021-12-08 10:37:37,131 [dispatcher-event-loop-10] INFO [org.apache.spark.storage.BlockManagerInfo] - Added rdd_57_2 in memory on qb:55657 (size: 11.1 MB, free: 1742.7 MB)
2021-12-08 10:37:37,467 [Executor task launch worker for task 166] INFO [org.apache.spark.executor.Executor] - Finished task 2.0 in stage 40.0 (TID 166). 166054 bytes result sent to driver
2021-12-08 10:37:37,469 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 2.0 in stage 40.0 (TID 166) in 37327 ms on localhost (executor driver) (1/12)
2021-12-08 10:37:37,498 [Executor task launch worker for task 164] INFO [org.apache.spark.storage.memory.MemoryStore] - Block rdd_57_0 stored as values in memory (estimated size 11.1 MB, free 1730.0 MB)
2021-12-08 10:37:37,498 [dispatcher-event-loop-1] INFO [org.apache.spark.storage.BlockManagerInfo] - Added rdd_57_0 in memory on qb:55657 (size: 11.1 MB, free: 1731.6 MB)
2021-12-08 10:37:37,510 [Executor task launch worker for task 174] INFO [org.apache.spark.storage.memory.MemoryStore] - Block rdd_57_10 stored as values in memory (estimated size 11.1 MB, free 1718.9 MB)
2021-12-08 10:37:37,510 [dispatcher-event-loop-2] INFO [org.apache.spark.storage.BlockManagerInfo] - Added rdd_57_10 in memory on qb:55657 (size: 11.1 MB, free: 1720.5 MB)
2021-12-08 10:37:37,829 [Executor task launch worker for task 164] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 40.0 (TID 164). 166054 bytes result sent to driver
2021-12-08 10:37:37,830 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 40.0 (TID 164) in 37688 ms on localhost (executor driver) (2/12)
2021-12-08 10:37:37,840 [Executor task launch worker for task 174] INFO [org.apache.spark.executor.Executor] - Finished task 10.0 in stage 40.0 (TID 174). 166097 bytes result sent to driver
2021-12-08 10:37:37,841 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 10.0 in stage 40.0 (TID 174) in 37698 ms on localhost (executor driver) (3/12)
2021-12-08 10:37:37,868 [Executor task launch worker for task 165] INFO [org.apache.spark.storage.memory.MemoryStore] - Block rdd_57_1 stored as values in memory (estimated size 11.1 MB, free 1707.8 MB)
2021-12-08 10:37:37,869 [dispatcher-event-loop-6] INFO [org.apache.spark.storage.BlockManagerInfo] - Added rdd_57_1 in memory on qb:55657 (size: 11.1 MB, free: 1709.4 MB)
2021-12-08 10:37:38,191 [Executor task launch worker for task 165] INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 40.0 (TID 165). 166054 bytes result sent to driver
2021-12-08 10:37:38,191 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 40.0 (TID 165) in 38049 ms on localhost (executor driver) (4/12)
2021-12-08 10:37:38,716 [Executor task launch worker for task 172] INFO [org.apache.spark.storage.memory.MemoryStore] - Block rdd_57_8 stored as values in memory (estimated size 11.1 MB, free 1696.7 MB)
2021-12-08 10:37:38,716 [dispatcher-event-loop-4] INFO [org.apache.spark.storage.BlockManagerInfo] - Added rdd_57_8 in memory on qb:55657 (size: 11.1 MB, free: 1698.3 MB)
2021-12-08 10:37:38,823 [Executor task launch worker for task 175] INFO [org.apache.spark.storage.memory.MemoryStore] - Block rdd_57_11 stored as values in memory (estimated size 11.1 MB, free 1685.6 MB)
2021-12-08 10:37:38,824 [dispatcher-event-loop-11] INFO [org.apache.spark.storage.BlockManagerInfo] - Added rdd_57_11 in memory on qb:55657 (size: 11.1 MB, free: 1687.2 MB)
2021-12-08 10:37:38,947 [Executor task launch worker for task 168] INFO [org.apache.spark.storage.memory.MemoryStore] - Block rdd_57_4 stored as values in memory (estimated size 11.1 MB, free 1674.5 MB)
2021-12-08 10:37:38,947 [dispatcher-event-loop-10] INFO [org.apache.spark.storage.BlockManagerInfo] - Added rdd_57_4 in memory on qb:55657 (size: 11.1 MB, free: 1676.1 MB)
2021-12-08 10:37:38,993 [Executor task launch worker for task 172] INFO [org.apache.spark.executor.Executor] - Finished task 8.0 in stage 40.0 (TID 172). 166097 bytes result sent to driver
2021-12-08 10:37:38,994 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 8.0 in stage 40.0 (TID 172) in 38851 ms on localhost (executor driver) (5/12)
2021-12-08 10:37:39,090 [Executor task launch worker for task 175] INFO [org.apache.spark.executor.Executor] - Finished task 11.0 in stage 40.0 (TID 175). 166097 bytes result sent to driver
2021-12-08 10:37:39,091 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 11.0 in stage 40.0 (TID 175) in 38948 ms on localhost (executor driver) (6/12)
2021-12-08 10:37:39,206 [Executor task launch worker for task 168] INFO [org.apache.spark.executor.Executor] - Finished task 4.0 in stage 40.0 (TID 168). 166054 bytes result sent to driver
2021-12-08 10:37:39,207 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 4.0 in stage 40.0 (TID 168) in 39064 ms on localhost (executor driver) (7/12)
2021-12-08 10:37:40,002 [Executor task launch worker for task 173] INFO [org.apache.spark.storage.memory.MemoryStore] - Block rdd_57_9 stored as values in memory (estimated size 11.1 MB, free 1663.4 MB)
2021-12-08 10:37:40,003 [dispatcher-event-loop-8] INFO [org.apache.spark.storage.BlockManagerInfo] - Added rdd_57_9 in memory on qb:55657 (size: 11.1 MB, free: 1665.0 MB)
2021-12-08 10:37:40,215 [Executor task launch worker for task 173] INFO [org.apache.spark.executor.Executor] - Finished task 9.0 in stage 40.0 (TID 173). 166054 bytes result sent to driver
2021-12-08 10:37:40,215 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 9.0 in stage 40.0 (TID 173) in 40072 ms on localhost (executor driver) (8/12)
2021-12-08 10:37:40,396 [Executor task launch worker for task 170] INFO [org.apache.spark.storage.memory.MemoryStore] - Block rdd_57_6 stored as values in memory (estimated size 11.1 MB, free 1652.3 MB)
2021-12-08 10:37:40,396 [dispatcher-event-loop-6] INFO [org.apache.spark.storage.BlockManagerInfo] - Added rdd_57_6 in memory on qb:55657 (size: 11.1 MB, free: 1653.8 MB)
2021-12-08 10:37:40,447 [Executor task launch worker for task 167] INFO [org.apache.spark.storage.memory.MemoryStore] - Block rdd_57_3 stored as values in memory (estimated size 11.1 MB, free 1641.2 MB)
2021-12-08 10:37:40,447 [dispatcher-event-loop-3] INFO [org.apache.spark.storage.BlockManagerInfo] - Added rdd_57_3 in memory on qb:55657 (size: 11.1 MB, free: 1642.7 MB)
2021-12-08 10:37:40,518 [Executor task launch worker for task 171] INFO [org.apache.spark.storage.memory.MemoryStore] - Block rdd_57_7 stored as values in memory (estimated size 11.1 MB, free 1630.1 MB)
2021-12-08 10:37:40,518 [dispatcher-event-loop-9] INFO [org.apache.spark.storage.BlockManagerInfo] - Added rdd_57_7 in memory on qb:55657 (size: 11.1 MB, free: 1631.6 MB)
2021-12-08 10:37:40,528 [Executor task launch worker for task 169] INFO [org.apache.spark.storage.memory.MemoryStore] - Block rdd_57_5 stored as values in memory (estimated size 11.1 MB, free 1618.9 MB)
2021-12-08 10:37:40,528 [dispatcher-event-loop-7] INFO [org.apache.spark.storage.BlockManagerInfo] - Added rdd_57_5 in memory on qb:55657 (size: 11.1 MB, free: 1620.5 MB)
2021-12-08 10:37:40,578 [Executor task launch worker for task 170] INFO [org.apache.spark.executor.Executor] - Finished task 6.0 in stage 40.0 (TID 170). 166054 bytes result sent to driver
2021-12-08 10:37:40,579 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 6.0 in stage 40.0 (TID 170) in 40436 ms on localhost (executor driver) (9/12)
2021-12-08 10:37:40,660 [Executor task launch worker for task 167] INFO [org.apache.spark.executor.Executor] - Finished task 3.0 in stage 40.0 (TID 167). 166097 bytes result sent to driver
2021-12-08 10:37:40,660 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 3.0 in stage 40.0 (TID 167) in 40518 ms on localhost (executor driver) (10/12)
2021-12-08 10:37:40,720 [Executor task launch worker for task 171] INFO [org.apache.spark.executor.Executor] - Finished task 7.0 in stage 40.0 (TID 171). 166054 bytes result sent to driver
2021-12-08 10:37:40,720 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 7.0 in stage 40.0 (TID 171) in 40577 ms on localhost (executor driver) (11/12)
2021-12-08 10:37:40,726 [Executor task launch worker for task 169] INFO [org.apache.spark.executor.Executor] - Finished task 5.0 in stage 40.0 (TID 169). 166054 bytes result sent to driver
2021-12-08 10:37:40,726 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 5.0 in stage 40.0 (TID 169) in 40583 ms on localhost (executor driver) (12/12)
2021-12-08 10:37:40,727 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 40.0, whose tasks have all completed, from pool 
2021-12-08 10:37:40,727 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 40 (aggregate at ALS.scala:1711) finished in 40.589 s
2021-12-08 10:37:40,727 [main] INFO [org.apache.spark.scheduler.DAGScheduler] - Job 8 finished: aggregate at ALS.scala:1711, took 41.547107 s
2021-12-08 10:37:40,743 [main] INFO [org.apache.spark.rdd.MapPartitionsRDD] - Removing RDD 47 from persistence list
2021-12-08 10:37:40,743 [block-manager-slave-async-thread-pool-1] INFO [org.apache.spark.storage.BlockManager] - Removing RDD 47
2021-12-08 10:37:40,750 [main] INFO [org.apache.spark.SparkContext] - Starting job: aggregate at ALS.scala:1711
2021-12-08 10:37:40,750 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 62 (flatMap at ALS.scala:1653)
2021-12-08 10:37:40,751 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 9 (aggregate at ALS.scala:1711) with 12 output partitions
2021-12-08 10:37:40,751 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 50 (aggregate at ALS.scala:1711)
2021-12-08 10:37:40,751 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 49, ShuffleMapStage 42)
2021-12-08 10:37:40,751 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List(ShuffleMapStage 49)
2021-12-08 10:37:40,751 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ShuffleMapStage 49 (MapPartitionsRDD[62] at flatMap at ALS.scala:1653), which has no missing parents
2021-12-08 10:37:40,753 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_18 stored as values in memory (estimated size 655.3 KB, free 1666.2 MB)
2021-12-08 10:37:40,754 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_18_piece0 stored as bytes in memory (estimated size 636.1 KB, free 1665.6 MB)
2021-12-08 10:37:40,754 [dispatcher-event-loop-9] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_18_piece0 in memory on qb:55657 (size: 636.1 KB, free: 1667.8 MB)
2021-12-08 10:37:40,755 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 18 from broadcast at DAGScheduler.scala:1039
2021-12-08 10:37:40,755 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 12 missing tasks from ShuffleMapStage 49 (MapPartitionsRDD[62] at flatMap at ALS.scala:1653) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11))
2021-12-08 10:37:40,755 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 49.0 with 12 tasks
2021-12-08 10:37:40,755 [dispatcher-event-loop-7] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 49.0 (TID 176, localhost, executor driver, partition 0, PROCESS_LOCAL, 7928 bytes)
2021-12-08 10:37:40,755 [dispatcher-event-loop-7] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 49.0 (TID 177, localhost, executor driver, partition 1, PROCESS_LOCAL, 7928 bytes)
2021-12-08 10:37:40,755 [dispatcher-event-loop-7] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 2.0 in stage 49.0 (TID 178, localhost, executor driver, partition 2, PROCESS_LOCAL, 7928 bytes)
2021-12-08 10:37:40,755 [dispatcher-event-loop-7] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 3.0 in stage 49.0 (TID 179, localhost, executor driver, partition 3, PROCESS_LOCAL, 7928 bytes)
2021-12-08 10:37:40,755 [dispatcher-event-loop-7] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 4.0 in stage 49.0 (TID 180, localhost, executor driver, partition 4, PROCESS_LOCAL, 7928 bytes)
2021-12-08 10:37:40,756 [dispatcher-event-loop-7] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 5.0 in stage 49.0 (TID 181, localhost, executor driver, partition 5, PROCESS_LOCAL, 7928 bytes)
2021-12-08 10:37:40,756 [dispatcher-event-loop-7] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 6.0 in stage 49.0 (TID 182, localhost, executor driver, partition 6, PROCESS_LOCAL, 7928 bytes)
2021-12-08 10:37:40,756 [dispatcher-event-loop-7] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 7.0 in stage 49.0 (TID 183, localhost, executor driver, partition 7, PROCESS_LOCAL, 7928 bytes)
2021-12-08 10:37:40,756 [dispatcher-event-loop-7] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 8.0 in stage 49.0 (TID 184, localhost, executor driver, partition 8, PROCESS_LOCAL, 7928 bytes)
2021-12-08 10:37:40,756 [dispatcher-event-loop-7] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 9.0 in stage 49.0 (TID 185, localhost, executor driver, partition 9, PROCESS_LOCAL, 7928 bytes)
2021-12-08 10:37:40,756 [dispatcher-event-loop-7] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 10.0 in stage 49.0 (TID 186, localhost, executor driver, partition 10, PROCESS_LOCAL, 7928 bytes)
2021-12-08 10:37:40,756 [dispatcher-event-loop-7] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 11.0 in stage 49.0 (TID 187, localhost, executor driver, partition 11, PROCESS_LOCAL, 7928 bytes)
2021-12-08 10:37:40,756 [Executor task launch worker for task 177] INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 49.0 (TID 177)
2021-12-08 10:37:40,756 [Executor task launch worker for task 176] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 49.0 (TID 176)
2021-12-08 10:37:40,756 [Executor task launch worker for task 182] INFO [org.apache.spark.executor.Executor] - Running task 6.0 in stage 49.0 (TID 182)
2021-12-08 10:37:40,756 [Executor task launch worker for task 185] INFO [org.apache.spark.executor.Executor] - Running task 9.0 in stage 49.0 (TID 185)
2021-12-08 10:37:40,756 [Executor task launch worker for task 183] INFO [org.apache.spark.executor.Executor] - Running task 7.0 in stage 49.0 (TID 183)
2021-12-08 10:37:40,756 [Executor task launch worker for task 181] INFO [org.apache.spark.executor.Executor] - Running task 5.0 in stage 49.0 (TID 181)
2021-12-08 10:37:40,756 [Executor task launch worker for task 186] INFO [org.apache.spark.executor.Executor] - Running task 10.0 in stage 49.0 (TID 186)
2021-12-08 10:37:40,756 [Executor task launch worker for task 187] INFO [org.apache.spark.executor.Executor] - Running task 11.0 in stage 49.0 (TID 187)
2021-12-08 10:37:40,756 [Executor task launch worker for task 184] INFO [org.apache.spark.executor.Executor] - Running task 8.0 in stage 49.0 (TID 184)
2021-12-08 10:37:40,756 [Executor task launch worker for task 179] INFO [org.apache.spark.executor.Executor] - Running task 3.0 in stage 49.0 (TID 179)
2021-12-08 10:37:40,756 [Executor task launch worker for task 180] INFO [org.apache.spark.executor.Executor] - Running task 4.0 in stage 49.0 (TID 180)
2021-12-08 10:37:40,756 [Executor task launch worker for task 178] INFO [org.apache.spark.executor.Executor] - Running task 2.0 in stage 49.0 (TID 178)
2021-12-08 10:37:40,758 [Executor task launch worker for task 177] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_10_1 locally
2021-12-08 10:37:40,758 [Executor task launch worker for task 180] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_10_4 locally
2021-12-08 10:37:40,758 [Executor task launch worker for task 185] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_10_9 locally
2021-12-08 10:37:40,758 [Executor task launch worker for task 179] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_10_3 locally
2021-12-08 10:37:40,759 [Executor task launch worker for task 186] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_10_10 locally
2021-12-08 10:37:40,759 [Executor task launch worker for task 185] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_57_9 locally
2021-12-08 10:37:40,758 [Executor task launch worker for task 187] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_10_11 locally
2021-12-08 10:37:40,759 [Executor task launch worker for task 181] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_10_5 locally
2021-12-08 10:37:40,759 [Executor task launch worker for task 176] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_10_0 locally
2021-12-08 10:37:40,759 [Executor task launch worker for task 181] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_57_5 locally
2021-12-08 10:37:40,759 [Executor task launch worker for task 178] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_10_2 locally
2021-12-08 10:37:40,759 [Executor task launch worker for task 180] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_57_4 locally
2021-12-08 10:37:40,759 [Executor task launch worker for task 187] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_57_11 locally
2021-12-08 10:37:40,759 [Executor task launch worker for task 186] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_57_10 locally
2021-12-08 10:37:40,759 [Executor task launch worker for task 178] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_57_2 locally
2021-12-08 10:37:40,759 [Executor task launch worker for task 176] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_57_0 locally
2021-12-08 10:37:40,759 [Executor task launch worker for task 177] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_57_1 locally
2021-12-08 10:37:40,759 [Executor task launch worker for task 183] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_10_7 locally
2021-12-08 10:37:40,759 [Executor task launch worker for task 179] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_57_3 locally
2021-12-08 10:37:40,759 [Executor task launch worker for task 184] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_10_8 locally
2021-12-08 10:37:40,759 [Executor task launch worker for task 184] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_57_8 locally
2021-12-08 10:37:40,759 [Executor task launch worker for task 183] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_57_7 locally
2021-12-08 10:37:40,760 [Executor task launch worker for task 182] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_10_6 locally
2021-12-08 10:37:40,760 [Executor task launch worker for task 182] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_57_6 locally
2021-12-08 10:37:42,620 [Executor task launch worker for task 176] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 49.0 (TID 176). 999 bytes result sent to driver
2021-12-08 10:37:42,621 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 49.0 (TID 176) in 1866 ms on localhost (executor driver) (1/12)
2021-12-08 10:37:42,634 [Executor task launch worker for task 182] INFO [org.apache.spark.executor.Executor] - Finished task 6.0 in stage 49.0 (TID 182). 999 bytes result sent to driver
2021-12-08 10:37:42,634 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 6.0 in stage 49.0 (TID 182) in 1878 ms on localhost (executor driver) (2/12)
2021-12-08 10:37:42,715 [Executor task launch worker for task 180] INFO [org.apache.spark.executor.Executor] - Finished task 4.0 in stage 49.0 (TID 180). 999 bytes result sent to driver
2021-12-08 10:37:42,715 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 4.0 in stage 49.0 (TID 180) in 1960 ms on localhost (executor driver) (3/12)
2021-12-08 10:37:42,729 [Executor task launch worker for task 178] INFO [org.apache.spark.executor.Executor] - Finished task 2.0 in stage 49.0 (TID 178). 999 bytes result sent to driver
2021-12-08 10:37:42,729 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 2.0 in stage 49.0 (TID 178) in 1974 ms on localhost (executor driver) (4/12)
2021-12-08 10:37:42,730 [Executor task launch worker for task 183] INFO [org.apache.spark.executor.Executor] - Finished task 7.0 in stage 49.0 (TID 183). 999 bytes result sent to driver
2021-12-08 10:37:42,731 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 7.0 in stage 49.0 (TID 183) in 1975 ms on localhost (executor driver) (5/12)
2021-12-08 10:37:42,749 [Executor task launch worker for task 179] INFO [org.apache.spark.executor.Executor] - Finished task 3.0 in stage 49.0 (TID 179). 999 bytes result sent to driver
2021-12-08 10:37:42,750 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 3.0 in stage 49.0 (TID 179) in 1995 ms on localhost (executor driver) (6/12)
2021-12-08 10:37:42,751 [Executor task launch worker for task 181] INFO [org.apache.spark.executor.Executor] - Finished task 5.0 in stage 49.0 (TID 181). 999 bytes result sent to driver
2021-12-08 10:37:42,751 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 5.0 in stage 49.0 (TID 181) in 1995 ms on localhost (executor driver) (7/12)
2021-12-08 10:37:42,896 [Executor task launch worker for task 187] INFO [org.apache.spark.executor.Executor] - Finished task 11.0 in stage 49.0 (TID 187). 999 bytes result sent to driver
2021-12-08 10:37:42,896 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 11.0 in stage 49.0 (TID 187) in 2140 ms on localhost (executor driver) (8/12)
2021-12-08 10:37:43,034 [Executor task launch worker for task 186] INFO [org.apache.spark.executor.Executor] - Finished task 10.0 in stage 49.0 (TID 186). 999 bytes result sent to driver
2021-12-08 10:37:43,035 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 10.0 in stage 49.0 (TID 186) in 2279 ms on localhost (executor driver) (9/12)
2021-12-08 10:37:43,036 [Executor task launch worker for task 177] INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 49.0 (TID 177). 999 bytes result sent to driver
2021-12-08 10:37:43,036 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 49.0 (TID 177) in 2281 ms on localhost (executor driver) (10/12)
2021-12-08 10:37:43,037 [Executor task launch worker for task 185] INFO [org.apache.spark.executor.Executor] - Finished task 9.0 in stage 49.0 (TID 185). 999 bytes result sent to driver
2021-12-08 10:37:43,037 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 9.0 in stage 49.0 (TID 185) in 2281 ms on localhost (executor driver) (11/12)
2021-12-08 10:37:43,038 [Executor task launch worker for task 184] INFO [org.apache.spark.executor.Executor] - Finished task 8.0 in stage 49.0 (TID 184). 999 bytes result sent to driver
2021-12-08 10:37:43,038 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 8.0 in stage 49.0 (TID 184) in 2282 ms on localhost (executor driver) (12/12)
2021-12-08 10:37:43,038 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 49.0, whose tasks have all completed, from pool 
2021-12-08 10:37:43,039 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ShuffleMapStage 49 (flatMap at ALS.scala:1653) finished in 2.287 s
2021-12-08 10:37:43,039 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - looking for newly runnable stages
2021-12-08 10:37:43,039 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - running: Set()
2021-12-08 10:37:43,039 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - waiting: Set(ResultStage 50)
2021-12-08 10:37:43,039 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - failed: Set()
2021-12-08 10:37:43,039 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 50 (MapPartitionsRDD[68] at values at ALS.scala:1711), which has no missing parents
2021-12-08 10:37:43,041 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_19 stored as values in memory (estimated size 976.9 KB, free 1664.6 MB)
2021-12-08 10:37:43,043 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_19_piece0 stored as bytes in memory (estimated size 794.8 KB, free 1663.8 MB)
2021-12-08 10:37:43,043 [dispatcher-event-loop-10] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_19_piece0 in memory on qb:55657 (size: 794.8 KB, free: 1667.0 MB)
2021-12-08 10:37:43,043 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 19 from broadcast at DAGScheduler.scala:1039
2021-12-08 10:37:43,043 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 12 missing tasks from ResultStage 50 (MapPartitionsRDD[68] at values at ALS.scala:1711) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11))
2021-12-08 10:37:43,043 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 50.0 with 12 tasks
2021-12-08 10:37:43,044 [dispatcher-event-loop-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 50.0 (TID 188, localhost, executor driver, partition 0, PROCESS_LOCAL, 7888 bytes)
2021-12-08 10:37:43,044 [dispatcher-event-loop-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 50.0 (TID 189, localhost, executor driver, partition 1, PROCESS_LOCAL, 7888 bytes)
2021-12-08 10:37:43,044 [dispatcher-event-loop-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 2.0 in stage 50.0 (TID 190, localhost, executor driver, partition 2, PROCESS_LOCAL, 7888 bytes)
2021-12-08 10:37:43,044 [dispatcher-event-loop-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 3.0 in stage 50.0 (TID 191, localhost, executor driver, partition 3, PROCESS_LOCAL, 7888 bytes)
2021-12-08 10:37:43,044 [dispatcher-event-loop-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 4.0 in stage 50.0 (TID 192, localhost, executor driver, partition 4, PROCESS_LOCAL, 7888 bytes)
2021-12-08 10:37:43,044 [dispatcher-event-loop-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 5.0 in stage 50.0 (TID 193, localhost, executor driver, partition 5, PROCESS_LOCAL, 7888 bytes)
2021-12-08 10:37:43,044 [dispatcher-event-loop-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 6.0 in stage 50.0 (TID 194, localhost, executor driver, partition 6, PROCESS_LOCAL, 7888 bytes)
2021-12-08 10:37:43,044 [dispatcher-event-loop-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 7.0 in stage 50.0 (TID 195, localhost, executor driver, partition 7, PROCESS_LOCAL, 7888 bytes)
2021-12-08 10:37:43,044 [dispatcher-event-loop-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 8.0 in stage 50.0 (TID 196, localhost, executor driver, partition 8, PROCESS_LOCAL, 7888 bytes)
2021-12-08 10:37:43,044 [dispatcher-event-loop-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 9.0 in stage 50.0 (TID 197, localhost, executor driver, partition 9, PROCESS_LOCAL, 7888 bytes)
2021-12-08 10:37:43,044 [dispatcher-event-loop-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 10.0 in stage 50.0 (TID 198, localhost, executor driver, partition 10, PROCESS_LOCAL, 7888 bytes)
2021-12-08 10:37:43,044 [dispatcher-event-loop-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 11.0 in stage 50.0 (TID 199, localhost, executor driver, partition 11, PROCESS_LOCAL, 7888 bytes)
2021-12-08 10:37:43,045 [Executor task launch worker for task 190] INFO [org.apache.spark.executor.Executor] - Running task 2.0 in stage 50.0 (TID 190)
2021-12-08 10:37:43,045 [Executor task launch worker for task 188] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 50.0 (TID 188)
2021-12-08 10:37:43,045 [Executor task launch worker for task 196] INFO [org.apache.spark.executor.Executor] - Running task 8.0 in stage 50.0 (TID 196)
2021-12-08 10:37:43,045 [Executor task launch worker for task 191] INFO [org.apache.spark.executor.Executor] - Running task 3.0 in stage 50.0 (TID 191)
2021-12-08 10:37:43,045 [Executor task launch worker for task 194] INFO [org.apache.spark.executor.Executor] - Running task 6.0 in stage 50.0 (TID 194)
2021-12-08 10:37:43,045 [Executor task launch worker for task 192] INFO [org.apache.spark.executor.Executor] - Running task 4.0 in stage 50.0 (TID 192)
2021-12-08 10:37:43,045 [Executor task launch worker for task 193] INFO [org.apache.spark.executor.Executor] - Running task 5.0 in stage 50.0 (TID 193)
2021-12-08 10:37:43,045 [Executor task launch worker for task 189] INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 50.0 (TID 189)
2021-12-08 10:37:43,045 [Executor task launch worker for task 195] INFO [org.apache.spark.executor.Executor] - Running task 7.0 in stage 50.0 (TID 195)
2021-12-08 10:37:43,045 [Executor task launch worker for task 199] INFO [org.apache.spark.executor.Executor] - Running task 11.0 in stage 50.0 (TID 199)
2021-12-08 10:37:43,045 [Executor task launch worker for task 198] INFO [org.apache.spark.executor.Executor] - Running task 10.0 in stage 50.0 (TID 198)
2021-12-08 10:37:43,045 [Executor task launch worker for task 197] INFO [org.apache.spark.executor.Executor] - Running task 9.0 in stage 50.0 (TID 197)
2021-12-08 10:37:43,047 [Executor task launch worker for task 199] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_14_11 locally
2021-12-08 10:37:43,048 [Executor task launch worker for task 196] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_14_8 locally
2021-12-08 10:37:43,048 [Executor task launch worker for task 197] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_14_9 locally
2021-12-08 10:37:43,047 [Executor task launch worker for task 191] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_14_3 locally
2021-12-08 10:37:43,047 [Executor task launch worker for task 189] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_14_1 locally
2021-12-08 10:37:43,048 [Executor task launch worker for task 190] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_14_2 locally
2021-12-08 10:37:43,048 [Executor task launch worker for task 193] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_14_5 locally
2021-12-08 10:37:43,048 [Executor task launch worker for task 194] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_14_6 locally
2021-12-08 10:37:43,048 [Executor task launch worker for task 198] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_14_10 locally
2021-12-08 10:37:43,048 [Executor task launch worker for task 192] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_14_4 locally
2021-12-08 10:37:43,048 [Executor task launch worker for task 190] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 12 non-empty blocks out of 12 blocks
2021-12-08 10:37:43,048 [Executor task launch worker for task 199] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 12 non-empty blocks out of 12 blocks
2021-12-08 10:37:43,048 [Executor task launch worker for task 196] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 12 non-empty blocks out of 12 blocks
2021-12-08 10:37:43,048 [Executor task launch worker for task 199] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-08 10:37:43,048 [Executor task launch worker for task 196] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-08 10:37:43,048 [Executor task launch worker for task 188] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_14_0 locally
2021-12-08 10:37:43,048 [Executor task launch worker for task 194] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 12 non-empty blocks out of 12 blocks
2021-12-08 10:37:43,048 [Executor task launch worker for task 190] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-08 10:37:43,048 [Executor task launch worker for task 189] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 12 non-empty blocks out of 12 blocks
2021-12-08 10:37:43,048 [Executor task launch worker for task 197] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 12 non-empty blocks out of 12 blocks
2021-12-08 10:37:43,048 [Executor task launch worker for task 193] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 12 non-empty blocks out of 12 blocks
2021-12-08 10:37:43,048 [Executor task launch worker for task 189] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-08 10:37:43,048 [Executor task launch worker for task 191] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 12 non-empty blocks out of 12 blocks
2021-12-08 10:37:43,048 [Executor task launch worker for task 194] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-08 10:37:43,048 [Executor task launch worker for task 191] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-08 10:37:43,048 [Executor task launch worker for task 198] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 12 non-empty blocks out of 12 blocks
2021-12-08 10:37:43,048 [Executor task launch worker for task 193] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-08 10:37:43,048 [Executor task launch worker for task 197] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-08 10:37:43,048 [Executor task launch worker for task 192] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 12 non-empty blocks out of 12 blocks
2021-12-08 10:37:43,048 [Executor task launch worker for task 198] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-08 10:37:43,048 [Executor task launch worker for task 188] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 12 non-empty blocks out of 12 blocks
2021-12-08 10:37:43,048 [Executor task launch worker for task 192] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-08 10:37:43,049 [Executor task launch worker for task 188] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 1 ms
2021-12-08 10:37:43,049 [Executor task launch worker for task 195] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_14_7 locally
2021-12-08 10:37:43,049 [Executor task launch worker for task 195] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 12 non-empty blocks out of 12 blocks
2021-12-08 10:37:43,049 [Executor task launch worker for task 195] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-08 10:37:43,367 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 422
2021-12-08 10:37:43,370 [dispatcher-event-loop-8] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_18_piece0 on qb:55657 in memory (size: 636.1 KB, free: 1667.6 MB)
2021-12-08 10:37:43,371 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 382
2021-12-08 10:37:43,371 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 381
2021-12-08 10:37:43,371 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 424
2021-12-08 10:37:43,371 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 376
2021-12-08 10:37:43,371 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 393
2021-12-08 10:37:43,371 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 384
2021-12-08 10:37:43,371 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 375
2021-12-08 10:37:43,371 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 399
2021-12-08 10:37:43,371 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 406
2021-12-08 10:37:43,371 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 377
2021-12-08 10:37:43,371 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 417
2021-12-08 10:37:43,371 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 418
2021-12-08 10:37:43,371 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 395
2021-12-08 10:37:43,371 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 383
2021-12-08 10:37:43,371 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 410
2021-12-08 10:37:43,371 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 390
2021-12-08 10:37:43,371 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 392
2021-12-08 10:37:43,371 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 407
2021-12-08 10:37:43,371 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 386
2021-12-08 10:37:43,371 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 379
2021-12-08 10:37:43,371 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 396
2021-12-08 10:37:43,372 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 405
2021-12-08 10:37:43,372 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 408
2021-12-08 10:37:43,372 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 387
2021-12-08 10:37:43,372 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 400
2021-12-08 10:37:43,372 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 409
2021-12-08 10:37:43,372 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 397
2021-12-08 10:37:43,372 [dispatcher-event-loop-9] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_17_piece0 on qb:55657 in memory (size: 637.1 KB, free: 1668.2 MB)
2021-12-08 10:37:43,373 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 389
2021-12-08 10:37:43,373 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 421
2021-12-08 10:37:43,373 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 402
2021-12-08 10:37:43,373 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 394
2021-12-08 10:37:43,373 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 413
2021-12-08 10:37:43,373 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 419
2021-12-08 10:37:43,373 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 391
2021-12-08 10:37:43,373 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 415
2021-12-08 10:37:43,373 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 411
2021-12-08 10:37:43,373 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 398
2021-12-08 10:37:43,373 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 378
2021-12-08 10:37:43,373 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 416
2021-12-08 10:37:43,373 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 385
2021-12-08 10:37:43,373 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 412
2021-12-08 10:37:43,373 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 403
2021-12-08 10:37:43,373 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 423
2021-12-08 10:37:43,373 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 380
2021-12-08 10:37:43,373 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 414
2021-12-08 10:37:43,373 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 401
2021-12-08 10:37:43,373 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 404
2021-12-08 10:37:43,373 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 420
2021-12-08 10:37:43,374 [dispatcher-event-loop-4] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_16_piece0 on qb:55657 in memory (size: 478.4 KB, free: 1668.7 MB)
2021-12-08 10:37:43,374 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 388
2021-12-08 10:38:04,922 [Executor task launch worker for task 189] INFO [org.apache.spark.storage.memory.MemoryStore] - Block rdd_67_1 stored as values in memory (estimated size 4.0 MB, free 1663.5 MB)
2021-12-08 10:38:04,922 [dispatcher-event-loop-8] INFO [org.apache.spark.storage.BlockManagerInfo] - Added rdd_67_1 in memory on qb:55657 (size: 4.0 MB, free: 1664.7 MB)
2021-12-08 10:38:05,042 [Executor task launch worker for task 189] INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 50.0 (TID 189). 166054 bytes result sent to driver
2021-12-08 10:38:05,043 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 50.0 (TID 189) in 21999 ms on localhost (executor driver) (1/12)
2021-12-08 10:38:05,608 [Executor task launch worker for task 188] INFO [org.apache.spark.storage.memory.MemoryStore] - Block rdd_67_0 stored as values in memory (estimated size 4.0 MB, free 1659.5 MB)
2021-12-08 10:38:05,609 [dispatcher-event-loop-3] INFO [org.apache.spark.storage.BlockManagerInfo] - Added rdd_67_0 in memory on qb:55657 (size: 4.0 MB, free: 1660.7 MB)
2021-12-08 10:38:05,724 [Executor task launch worker for task 188] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 50.0 (TID 188). 166054 bytes result sent to driver
2021-12-08 10:38:05,724 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 50.0 (TID 188) in 22680 ms on localhost (executor driver) (2/12)
2021-12-08 10:38:05,741 [Executor task launch worker for task 192] INFO [org.apache.spark.storage.memory.MemoryStore] - Block rdd_67_4 stored as values in memory (estimated size 4.0 MB, free 1655.5 MB)
2021-12-08 10:38:05,741 [dispatcher-event-loop-11] INFO [org.apache.spark.storage.BlockManagerInfo] - Added rdd_67_4 in memory on qb:55657 (size: 4.0 MB, free: 1656.7 MB)
2021-12-08 10:38:05,859 [Executor task launch worker for task 192] INFO [org.apache.spark.executor.Executor] - Finished task 4.0 in stage 50.0 (TID 192). 166054 bytes result sent to driver
2021-12-08 10:38:05,860 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 4.0 in stage 50.0 (TID 192) in 22816 ms on localhost (executor driver) (3/12)
2021-12-08 10:38:06,290 [Executor task launch worker for task 193] INFO [org.apache.spark.storage.memory.MemoryStore] - Block rdd_67_5 stored as values in memory (estimated size 4.0 MB, free 1651.5 MB)
2021-12-08 10:38:06,290 [dispatcher-event-loop-4] INFO [org.apache.spark.storage.BlockManagerInfo] - Added rdd_67_5 in memory on qb:55657 (size: 4.0 MB, free: 1652.8 MB)
2021-12-08 10:38:06,398 [Executor task launch worker for task 193] INFO [org.apache.spark.executor.Executor] - Finished task 5.0 in stage 50.0 (TID 193). 166054 bytes result sent to driver
2021-12-08 10:38:06,401 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 5.0 in stage 50.0 (TID 193) in 23357 ms on localhost (executor driver) (4/12)
2021-12-08 10:38:07,520 [Executor task launch worker for task 199] INFO [org.apache.spark.storage.memory.MemoryStore] - Block rdd_67_11 stored as values in memory (estimated size 4.0 MB, free 1647.5 MB)
2021-12-08 10:38:07,520 [dispatcher-event-loop-10] INFO [org.apache.spark.storage.BlockManagerInfo] - Added rdd_67_11 in memory on qb:55657 (size: 4.0 MB, free: 1648.8 MB)
2021-12-08 10:38:07,639 [Executor task launch worker for task 199] INFO [org.apache.spark.executor.Executor] - Finished task 11.0 in stage 50.0 (TID 199). 166054 bytes result sent to driver
2021-12-08 10:38:07,639 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 11.0 in stage 50.0 (TID 199) in 24595 ms on localhost (executor driver) (5/12)
2021-12-08 10:38:07,652 [Executor task launch worker for task 191] INFO [org.apache.spark.storage.memory.MemoryStore] - Block rdd_67_3 stored as values in memory (estimated size 4.0 MB, free 1643.5 MB)
2021-12-08 10:38:07,652 [dispatcher-event-loop-2] INFO [org.apache.spark.storage.BlockManagerInfo] - Added rdd_67_3 in memory on qb:55657 (size: 4.0 MB, free: 1644.8 MB)
2021-12-08 10:38:07,727 [Executor task launch worker for task 198] INFO [org.apache.spark.storage.memory.MemoryStore] - Block rdd_67_10 stored as values in memory (estimated size 4.0 MB, free 1639.5 MB)
2021-12-08 10:38:07,727 [dispatcher-event-loop-5] INFO [org.apache.spark.storage.BlockManagerInfo] - Added rdd_67_10 in memory on qb:55657 (size: 4.0 MB, free: 1640.8 MB)
2021-12-08 10:38:07,757 [Executor task launch worker for task 196] INFO [org.apache.spark.storage.memory.MemoryStore] - Block rdd_67_8 stored as values in memory (estimated size 4.0 MB, free 1635.5 MB)
2021-12-08 10:38:07,757 [dispatcher-event-loop-8] INFO [org.apache.spark.storage.BlockManagerInfo] - Added rdd_67_8 in memory on qb:55657 (size: 4.0 MB, free: 1636.8 MB)
2021-12-08 10:38:07,766 [Executor task launch worker for task 191] INFO [org.apache.spark.executor.Executor] - Finished task 3.0 in stage 50.0 (TID 191). 166054 bytes result sent to driver
2021-12-08 10:38:07,768 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 3.0 in stage 50.0 (TID 191) in 24724 ms on localhost (executor driver) (6/12)
2021-12-08 10:38:07,841 [Executor task launch worker for task 198] INFO [org.apache.spark.executor.Executor] - Finished task 10.0 in stage 50.0 (TID 198). 166054 bytes result sent to driver
2021-12-08 10:38:07,841 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 10.0 in stage 50.0 (TID 198) in 24797 ms on localhost (executor driver) (7/12)
2021-12-08 10:38:07,850 [Executor task launch worker for task 196] INFO [org.apache.spark.executor.Executor] - Finished task 8.0 in stage 50.0 (TID 196). 166054 bytes result sent to driver
2021-12-08 10:38:07,851 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 8.0 in stage 50.0 (TID 196) in 24807 ms on localhost (executor driver) (8/12)
2021-12-08 10:38:08,126 [Executor task launch worker for task 195] INFO [org.apache.spark.storage.memory.MemoryStore] - Block rdd_67_7 stored as values in memory (estimated size 4.0 MB, free 1631.6 MB)
2021-12-08 10:38:08,126 [dispatcher-event-loop-11] INFO [org.apache.spark.storage.BlockManagerInfo] - Added rdd_67_7 in memory on qb:55657 (size: 4.0 MB, free: 1632.8 MB)
2021-12-08 10:38:08,230 [Executor task launch worker for task 195] INFO [org.apache.spark.executor.Executor] - Finished task 7.0 in stage 50.0 (TID 195). 166054 bytes result sent to driver
2021-12-08 10:38:08,230 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 7.0 in stage 50.0 (TID 195) in 25186 ms on localhost (executor driver) (9/12)
2021-12-08 10:38:08,559 [Executor task launch worker for task 197] INFO [org.apache.spark.storage.memory.MemoryStore] - Block rdd_67_9 stored as values in memory (estimated size 4.0 MB, free 1627.6 MB)
2021-12-08 10:38:08,559 [dispatcher-event-loop-4] INFO [org.apache.spark.storage.BlockManagerInfo] - Added rdd_67_9 in memory on qb:55657 (size: 4.0 MB, free: 1628.8 MB)
2021-12-08 10:38:08,627 [Executor task launch worker for task 197] INFO [org.apache.spark.executor.Executor] - Finished task 9.0 in stage 50.0 (TID 197). 166097 bytes result sent to driver
2021-12-08 10:38:08,627 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 9.0 in stage 50.0 (TID 197) in 25583 ms on localhost (executor driver) (10/12)
2021-12-08 10:38:09,047 [Executor task launch worker for task 194] INFO [org.apache.spark.storage.memory.MemoryStore] - Block rdd_67_6 stored as values in memory (estimated size 4.0 MB, free 1623.6 MB)
2021-12-08 10:38:09,047 [dispatcher-event-loop-2] INFO [org.apache.spark.storage.BlockManagerInfo] - Added rdd_67_6 in memory on qb:55657 (size: 4.0 MB, free: 1624.8 MB)
2021-12-08 10:38:09,125 [Executor task launch worker for task 194] INFO [org.apache.spark.executor.Executor] - Finished task 6.0 in stage 50.0 (TID 194). 166054 bytes result sent to driver
2021-12-08 10:38:09,126 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 6.0 in stage 50.0 (TID 194) in 26082 ms on localhost (executor driver) (11/12)
2021-12-08 10:38:09,579 [Executor task launch worker for task 190] INFO [org.apache.spark.storage.memory.MemoryStore] - Block rdd_67_2 stored as values in memory (estimated size 4.0 MB, free 1619.6 MB)
2021-12-08 10:38:09,579 [dispatcher-event-loop-8] INFO [org.apache.spark.storage.BlockManagerInfo] - Added rdd_67_2 in memory on qb:55657 (size: 4.0 MB, free: 1620.8 MB)
2021-12-08 10:38:09,643 [Executor task launch worker for task 190] INFO [org.apache.spark.executor.Executor] - Finished task 2.0 in stage 50.0 (TID 190). 166054 bytes result sent to driver
2021-12-08 10:38:09,643 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 2.0 in stage 50.0 (TID 190) in 26599 ms on localhost (executor driver) (12/12)
2021-12-08 10:38:09,643 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 50.0, whose tasks have all completed, from pool 
2021-12-08 10:38:09,643 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 50 (aggregate at ALS.scala:1711) finished in 26.604 s
2021-12-08 10:38:09,644 [main] INFO [org.apache.spark.scheduler.DAGScheduler] - Job 9 finished: aggregate at ALS.scala:1711, took 28.893844 s
2021-12-08 10:38:09,660 [main] INFO [org.apache.spark.rdd.MapPartitionsRDD] - Removing RDD 57 from persistence list
2021-12-08 10:38:09,661 [block-manager-slave-async-thread-pool-2] INFO [org.apache.spark.storage.BlockManager] - Removing RDD 57
2021-12-08 10:38:09,667 [main] INFO [org.apache.spark.SparkContext] - Starting job: aggregate at ALS.scala:1711
2021-12-08 10:38:09,668 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 72 (flatMap at ALS.scala:1653)
2021-12-08 10:38:09,668 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 10 (aggregate at ALS.scala:1711) with 12 output partitions
2021-12-08 10:38:09,668 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 61 (aggregate at ALS.scala:1711)
2021-12-08 10:38:09,668 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 60, ShuffleMapStage 52)
2021-12-08 10:38:09,668 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List(ShuffleMapStage 60)
2021-12-08 10:38:09,669 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ShuffleMapStage 60 (MapPartitionsRDD[72] at flatMap at ALS.scala:1653), which has no missing parents
2021-12-08 10:38:09,672 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_20 stored as values in memory (estimated size 816.4 KB, free 1752.0 MB)
2021-12-08 10:38:09,675 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_20_piece0 stored as bytes in memory (estimated size 793.8 KB, free 1751.3 MB)
2021-12-08 10:38:09,675 [dispatcher-event-loop-10] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_20_piece0 in memory on qb:55657 (size: 793.8 KB, free: 1753.3 MB)
2021-12-08 10:38:09,675 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 20 from broadcast at DAGScheduler.scala:1039
2021-12-08 10:38:09,675 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 12 missing tasks from ShuffleMapStage 60 (MapPartitionsRDD[72] at flatMap at ALS.scala:1653) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11))
2021-12-08 10:38:09,675 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 60.0 with 12 tasks
2021-12-08 10:38:09,675 [dispatcher-event-loop-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 60.0 (TID 200, localhost, executor driver, partition 0, PROCESS_LOCAL, 7928 bytes)
2021-12-08 10:38:09,675 [dispatcher-event-loop-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 60.0 (TID 201, localhost, executor driver, partition 1, PROCESS_LOCAL, 7928 bytes)
2021-12-08 10:38:09,675 [dispatcher-event-loop-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 2.0 in stage 60.0 (TID 202, localhost, executor driver, partition 2, PROCESS_LOCAL, 7928 bytes)
2021-12-08 10:38:09,675 [dispatcher-event-loop-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 3.0 in stage 60.0 (TID 203, localhost, executor driver, partition 3, PROCESS_LOCAL, 7928 bytes)
2021-12-08 10:38:09,675 [dispatcher-event-loop-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 4.0 in stage 60.0 (TID 204, localhost, executor driver, partition 4, PROCESS_LOCAL, 7928 bytes)
2021-12-08 10:38:09,676 [dispatcher-event-loop-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 5.0 in stage 60.0 (TID 205, localhost, executor driver, partition 5, PROCESS_LOCAL, 7928 bytes)
2021-12-08 10:38:09,676 [dispatcher-event-loop-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 6.0 in stage 60.0 (TID 206, localhost, executor driver, partition 6, PROCESS_LOCAL, 7928 bytes)
2021-12-08 10:38:09,676 [dispatcher-event-loop-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 7.0 in stage 60.0 (TID 207, localhost, executor driver, partition 7, PROCESS_LOCAL, 7928 bytes)
2021-12-08 10:38:09,676 [dispatcher-event-loop-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 8.0 in stage 60.0 (TID 208, localhost, executor driver, partition 8, PROCESS_LOCAL, 7928 bytes)
2021-12-08 10:38:09,676 [dispatcher-event-loop-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 9.0 in stage 60.0 (TID 209, localhost, executor driver, partition 9, PROCESS_LOCAL, 7928 bytes)
2021-12-08 10:38:09,676 [dispatcher-event-loop-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 10.0 in stage 60.0 (TID 210, localhost, executor driver, partition 10, PROCESS_LOCAL, 7928 bytes)
2021-12-08 10:38:09,676 [dispatcher-event-loop-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 11.0 in stage 60.0 (TID 211, localhost, executor driver, partition 11, PROCESS_LOCAL, 7928 bytes)
2021-12-08 10:38:09,676 [Executor task launch worker for task 205] INFO [org.apache.spark.executor.Executor] - Running task 5.0 in stage 60.0 (TID 205)
2021-12-08 10:38:09,676 [Executor task launch worker for task 207] INFO [org.apache.spark.executor.Executor] - Running task 7.0 in stage 60.0 (TID 207)
2021-12-08 10:38:09,676 [Executor task launch worker for task 210] INFO [org.apache.spark.executor.Executor] - Running task 10.0 in stage 60.0 (TID 210)
2021-12-08 10:38:09,676 [Executor task launch worker for task 200] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 60.0 (TID 200)
2021-12-08 10:38:09,676 [Executor task launch worker for task 201] INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 60.0 (TID 201)
2021-12-08 10:38:09,676 [Executor task launch worker for task 206] INFO [org.apache.spark.executor.Executor] - Running task 6.0 in stage 60.0 (TID 206)
2021-12-08 10:38:09,676 [Executor task launch worker for task 208] INFO [org.apache.spark.executor.Executor] - Running task 8.0 in stage 60.0 (TID 208)
2021-12-08 10:38:09,676 [Executor task launch worker for task 203] INFO [org.apache.spark.executor.Executor] - Running task 3.0 in stage 60.0 (TID 203)
2021-12-08 10:38:09,676 [Executor task launch worker for task 202] INFO [org.apache.spark.executor.Executor] - Running task 2.0 in stage 60.0 (TID 202)
2021-12-08 10:38:09,676 [Executor task launch worker for task 209] INFO [org.apache.spark.executor.Executor] - Running task 9.0 in stage 60.0 (TID 209)
2021-12-08 10:38:09,676 [Executor task launch worker for task 204] INFO [org.apache.spark.executor.Executor] - Running task 4.0 in stage 60.0 (TID 204)
2021-12-08 10:38:09,676 [Executor task launch worker for task 211] INFO [org.apache.spark.executor.Executor] - Running task 11.0 in stage 60.0 (TID 211)
2021-12-08 10:38:09,678 [Executor task launch worker for task 200] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_15_0 locally
2021-12-08 10:38:09,678 [Executor task launch worker for task 204] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_15_4 locally
2021-12-08 10:38:09,678 [Executor task launch worker for task 206] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_15_6 locally
2021-12-08 10:38:09,678 [Executor task launch worker for task 202] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_15_2 locally
2021-12-08 10:38:09,678 [Executor task launch worker for task 207] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_15_7 locally
2021-12-08 10:38:09,678 [Executor task launch worker for task 204] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_67_4 locally
2021-12-08 10:38:09,678 [Executor task launch worker for task 207] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_67_7 locally
2021-12-08 10:38:09,678 [Executor task launch worker for task 210] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_15_10 locally
2021-12-08 10:38:09,678 [Executor task launch worker for task 210] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_67_10 locally
2021-12-08 10:38:09,679 [Executor task launch worker for task 208] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_15_8 locally
2021-12-08 10:38:09,679 [Executor task launch worker for task 208] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_67_8 locally
2021-12-08 10:38:09,678 [Executor task launch worker for task 211] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_15_11 locally
2021-12-08 10:38:09,679 [Executor task launch worker for task 205] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_15_5 locally
2021-12-08 10:38:09,678 [Executor task launch worker for task 206] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_67_6 locally
2021-12-08 10:38:09,679 [Executor task launch worker for task 202] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_67_2 locally
2021-12-08 10:38:09,679 [Executor task launch worker for task 209] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_15_9 locally
2021-12-08 10:38:09,679 [Executor task launch worker for task 209] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_67_9 locally
2021-12-08 10:38:09,679 [Executor task launch worker for task 201] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_15_1 locally
2021-12-08 10:38:09,679 [Executor task launch worker for task 201] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_67_1 locally
2021-12-08 10:38:09,679 [Executor task launch worker for task 200] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_67_0 locally
2021-12-08 10:38:09,680 [Executor task launch worker for task 211] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_67_11 locally
2021-12-08 10:38:09,683 [Executor task launch worker for task 203] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_15_3 locally
2021-12-08 10:38:09,683 [Executor task launch worker for task 203] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_67_3 locally
2021-12-08 10:38:09,683 [Executor task launch worker for task 205] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_67_5 locally
2021-12-08 10:38:10,235 [Executor task launch worker for task 205] INFO [org.apache.spark.executor.Executor] - Finished task 5.0 in stage 60.0 (TID 205). 999 bytes result sent to driver
2021-12-08 10:38:10,236 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 5.0 in stage 60.0 (TID 205) in 561 ms on localhost (executor driver) (1/12)
2021-12-08 10:38:10,240 [Executor task launch worker for task 211] INFO [org.apache.spark.executor.Executor] - Finished task 11.0 in stage 60.0 (TID 211). 1042 bytes result sent to driver
2021-12-08 10:38:10,240 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 11.0 in stage 60.0 (TID 211) in 564 ms on localhost (executor driver) (2/12)
2021-12-08 10:38:10,248 [Executor task launch worker for task 206] INFO [org.apache.spark.executor.Executor] - Finished task 6.0 in stage 60.0 (TID 206). 1042 bytes result sent to driver
2021-12-08 10:38:10,248 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 6.0 in stage 60.0 (TID 206) in 572 ms on localhost (executor driver) (3/12)
2021-12-08 10:38:10,272 [Executor task launch worker for task 210] INFO [org.apache.spark.executor.Executor] - Finished task 10.0 in stage 60.0 (TID 210). 1042 bytes result sent to driver
2021-12-08 10:38:10,272 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 10.0 in stage 60.0 (TID 210) in 596 ms on localhost (executor driver) (4/12)
2021-12-08 10:38:10,273 [Executor task launch worker for task 209] INFO [org.apache.spark.executor.Executor] - Finished task 9.0 in stage 60.0 (TID 209). 1042 bytes result sent to driver
2021-12-08 10:38:10,274 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 9.0 in stage 60.0 (TID 209) in 598 ms on localhost (executor driver) (5/12)
2021-12-08 10:38:10,274 [Executor task launch worker for task 208] INFO [org.apache.spark.executor.Executor] - Finished task 8.0 in stage 60.0 (TID 208). 999 bytes result sent to driver
2021-12-08 10:38:10,275 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 8.0 in stage 60.0 (TID 208) in 599 ms on localhost (executor driver) (6/12)
2021-12-08 10:38:10,278 [Executor task launch worker for task 207] INFO [org.apache.spark.executor.Executor] - Finished task 7.0 in stage 60.0 (TID 207). 1042 bytes result sent to driver
2021-12-08 10:38:10,279 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 7.0 in stage 60.0 (TID 207) in 603 ms on localhost (executor driver) (7/12)
2021-12-08 10:38:10,282 [Executor task launch worker for task 204] INFO [org.apache.spark.executor.Executor] - Finished task 4.0 in stage 60.0 (TID 204). 1042 bytes result sent to driver
2021-12-08 10:38:10,283 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 4.0 in stage 60.0 (TID 204) in 608 ms on localhost (executor driver) (8/12)
2021-12-08 10:38:10,310 [Executor task launch worker for task 203] INFO [org.apache.spark.executor.Executor] - Finished task 3.0 in stage 60.0 (TID 203). 999 bytes result sent to driver
2021-12-08 10:38:10,310 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 3.0 in stage 60.0 (TID 203) in 635 ms on localhost (executor driver) (9/12)
2021-12-08 10:38:10,311 [Executor task launch worker for task 200] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 60.0 (TID 200). 1042 bytes result sent to driver
2021-12-08 10:38:10,312 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 60.0 (TID 200) in 637 ms on localhost (executor driver) (10/12)
2021-12-08 10:38:10,313 [Executor task launch worker for task 202] INFO [org.apache.spark.executor.Executor] - Finished task 2.0 in stage 60.0 (TID 202). 1042 bytes result sent to driver
2021-12-08 10:38:10,313 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 2.0 in stage 60.0 (TID 202) in 638 ms on localhost (executor driver) (11/12)
2021-12-08 10:38:10,314 [Executor task launch worker for task 201] INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 60.0 (TID 201). 999 bytes result sent to driver
2021-12-08 10:38:10,315 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 60.0 (TID 201) in 640 ms on localhost (executor driver) (12/12)
2021-12-08 10:38:10,315 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 60.0, whose tasks have all completed, from pool 
2021-12-08 10:38:10,315 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ShuffleMapStage 60 (flatMap at ALS.scala:1653) finished in 0.646 s
2021-12-08 10:38:10,315 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - looking for newly runnable stages
2021-12-08 10:38:10,315 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - running: Set()
2021-12-08 10:38:10,315 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - waiting: Set(ResultStage 61)
2021-12-08 10:38:10,315 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - failed: Set()
2021-12-08 10:38:10,315 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 61 (MapPartitionsRDD[78] at values at ALS.scala:1711), which has no missing parents
2021-12-08 10:38:10,317 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_21 stored as values in memory (estimated size 1138.0 KB, free 1750.2 MB)
2021-12-08 10:38:10,320 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_21_piece0 stored as bytes in memory (estimated size 952.5 KB, free 1749.2 MB)
2021-12-08 10:38:10,320 [dispatcher-event-loop-8] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_21_piece0 in memory on qb:55657 (size: 952.5 KB, free: 1752.4 MB)
2021-12-08 10:38:10,320 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 21 from broadcast at DAGScheduler.scala:1039
2021-12-08 10:38:10,320 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 12 missing tasks from ResultStage 61 (MapPartitionsRDD[78] at values at ALS.scala:1711) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11))
2021-12-08 10:38:10,320 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 61.0 with 12 tasks
2021-12-08 10:38:10,321 [dispatcher-event-loop-6] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 61.0 (TID 212, localhost, executor driver, partition 0, PROCESS_LOCAL, 7888 bytes)
2021-12-08 10:38:10,321 [dispatcher-event-loop-6] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 61.0 (TID 213, localhost, executor driver, partition 1, PROCESS_LOCAL, 7888 bytes)
2021-12-08 10:38:10,321 [dispatcher-event-loop-6] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 2.0 in stage 61.0 (TID 214, localhost, executor driver, partition 2, PROCESS_LOCAL, 7888 bytes)
2021-12-08 10:38:10,321 [dispatcher-event-loop-6] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 3.0 in stage 61.0 (TID 215, localhost, executor driver, partition 3, PROCESS_LOCAL, 7888 bytes)
2021-12-08 10:38:10,321 [dispatcher-event-loop-6] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 4.0 in stage 61.0 (TID 216, localhost, executor driver, partition 4, PROCESS_LOCAL, 7888 bytes)
2021-12-08 10:38:10,321 [dispatcher-event-loop-6] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 5.0 in stage 61.0 (TID 217, localhost, executor driver, partition 5, PROCESS_LOCAL, 7888 bytes)
2021-12-08 10:38:10,321 [dispatcher-event-loop-6] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 6.0 in stage 61.0 (TID 218, localhost, executor driver, partition 6, PROCESS_LOCAL, 7888 bytes)
2021-12-08 10:38:10,321 [dispatcher-event-loop-6] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 7.0 in stage 61.0 (TID 219, localhost, executor driver, partition 7, PROCESS_LOCAL, 7888 bytes)
2021-12-08 10:38:10,321 [dispatcher-event-loop-6] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 8.0 in stage 61.0 (TID 220, localhost, executor driver, partition 8, PROCESS_LOCAL, 7888 bytes)
2021-12-08 10:38:10,321 [dispatcher-event-loop-6] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 9.0 in stage 61.0 (TID 221, localhost, executor driver, partition 9, PROCESS_LOCAL, 7888 bytes)
2021-12-08 10:38:10,321 [dispatcher-event-loop-6] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 10.0 in stage 61.0 (TID 222, localhost, executor driver, partition 10, PROCESS_LOCAL, 7888 bytes)
2021-12-08 10:38:10,321 [dispatcher-event-loop-6] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 11.0 in stage 61.0 (TID 223, localhost, executor driver, partition 11, PROCESS_LOCAL, 7888 bytes)
2021-12-08 10:38:10,321 [Executor task launch worker for task 215] INFO [org.apache.spark.executor.Executor] - Running task 3.0 in stage 61.0 (TID 215)
2021-12-08 10:38:10,322 [Executor task launch worker for task 222] INFO [org.apache.spark.executor.Executor] - Running task 10.0 in stage 61.0 (TID 222)
2021-12-08 10:38:10,321 [Executor task launch worker for task 220] INFO [org.apache.spark.executor.Executor] - Running task 8.0 in stage 61.0 (TID 220)
2021-12-08 10:38:10,321 [Executor task launch worker for task 219] INFO [org.apache.spark.executor.Executor] - Running task 7.0 in stage 61.0 (TID 219)
2021-12-08 10:38:10,321 [Executor task launch worker for task 212] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 61.0 (TID 212)
2021-12-08 10:38:10,321 [Executor task launch worker for task 221] INFO [org.apache.spark.executor.Executor] - Running task 9.0 in stage 61.0 (TID 221)
2021-12-08 10:38:10,321 [Executor task launch worker for task 214] INFO [org.apache.spark.executor.Executor] - Running task 2.0 in stage 61.0 (TID 214)
2021-12-08 10:38:10,321 [Executor task launch worker for task 218] INFO [org.apache.spark.executor.Executor] - Running task 6.0 in stage 61.0 (TID 218)
2021-12-08 10:38:10,321 [Executor task launch worker for task 217] INFO [org.apache.spark.executor.Executor] - Running task 5.0 in stage 61.0 (TID 217)
2021-12-08 10:38:10,321 [Executor task launch worker for task 216] INFO [org.apache.spark.executor.Executor] - Running task 4.0 in stage 61.0 (TID 216)
2021-12-08 10:38:10,321 [Executor task launch worker for task 213] INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 61.0 (TID 213)
2021-12-08 10:38:10,322 [Executor task launch worker for task 223] INFO [org.apache.spark.executor.Executor] - Running task 11.0 in stage 61.0 (TID 223)
2021-12-08 10:38:10,324 [Executor task launch worker for task 214] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_9_2 locally
2021-12-08 10:38:10,325 [Executor task launch worker for task 217] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_9_5 locally
2021-12-08 10:38:10,325 [Executor task launch worker for task 218] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_9_6 locally
2021-12-08 10:38:10,324 [Executor task launch worker for task 219] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_9_7 locally
2021-12-08 10:38:10,325 [Executor task launch worker for task 214] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 12 non-empty blocks out of 12 blocks
2021-12-08 10:38:10,325 [Executor task launch worker for task 221] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_9_9 locally
2021-12-08 10:38:10,325 [Executor task launch worker for task 214] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-08 10:38:10,325 [Executor task launch worker for task 220] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_9_8 locally
2021-12-08 10:38:10,325 [Executor task launch worker for task 222] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_9_10 locally
2021-12-08 10:38:10,325 [Executor task launch worker for task 223] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_9_11 locally
2021-12-08 10:38:10,325 [Executor task launch worker for task 213] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_9_1 locally
2021-12-08 10:38:10,325 [Executor task launch worker for task 219] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 12 non-empty blocks out of 12 blocks
2021-12-08 10:38:10,325 [Executor task launch worker for task 217] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 12 non-empty blocks out of 12 blocks
2021-12-08 10:38:10,325 [Executor task launch worker for task 219] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-08 10:38:10,325 [Executor task launch worker for task 217] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-08 10:38:10,325 [Executor task launch worker for task 216] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_9_4 locally
2021-12-08 10:38:10,325 [Executor task launch worker for task 218] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 12 non-empty blocks out of 12 blocks
2021-12-08 10:38:10,325 [Executor task launch worker for task 223] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 12 non-empty blocks out of 12 blocks
2021-12-08 10:38:10,325 [Executor task launch worker for task 223] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-08 10:38:10,325 [Executor task launch worker for task 221] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 12 non-empty blocks out of 12 blocks
2021-12-08 10:38:10,325 [Executor task launch worker for task 221] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-08 10:38:10,325 [Executor task launch worker for task 218] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-08 10:38:10,325 [Executor task launch worker for task 220] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 12 non-empty blocks out of 12 blocks
2021-12-08 10:38:10,325 [Executor task launch worker for task 216] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 12 non-empty blocks out of 12 blocks
2021-12-08 10:38:10,325 [Executor task launch worker for task 222] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 12 non-empty blocks out of 12 blocks
2021-12-08 10:38:10,325 [Executor task launch worker for task 213] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 12 non-empty blocks out of 12 blocks
2021-12-08 10:38:10,325 [Executor task launch worker for task 222] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-08 10:38:10,325 [Executor task launch worker for task 216] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-08 10:38:10,325 [Executor task launch worker for task 220] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-08 10:38:10,325 [Executor task launch worker for task 213] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-08 10:38:10,325 [Executor task launch worker for task 212] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_9_0 locally
2021-12-08 10:38:10,325 [Executor task launch worker for task 215] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_9_3 locally
2021-12-08 10:38:10,326 [Executor task launch worker for task 212] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 12 non-empty blocks out of 12 blocks
2021-12-08 10:38:10,326 [Executor task launch worker for task 215] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 12 non-empty blocks out of 12 blocks
2021-12-08 10:38:10,326 [Executor task launch worker for task 212] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-08 10:38:10,326 [Executor task launch worker for task 215] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-08 10:38:10,631 [dispatcher-event-loop-7] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_20_piece0 on qb:55657 in memory (size: 793.8 KB, free: 1753.2 MB)
2021-12-08 10:38:47,689 [Executor task launch worker for task 221] INFO [org.apache.spark.storage.memory.MemoryStore] - Block rdd_77_9 stored as values in memory (estimated size 11.1 MB, free 1739.7 MB)
2021-12-08 10:38:47,689 [dispatcher-event-loop-2] INFO [org.apache.spark.storage.BlockManagerInfo] - Added rdd_77_9 in memory on qb:55657 (size: 11.1 MB, free: 1742.1 MB)
2021-12-08 10:38:47,829 [Executor task launch worker for task 220] INFO [org.apache.spark.storage.memory.MemoryStore] - Block rdd_77_8 stored as values in memory (estimated size 11.1 MB, free 1728.6 MB)
2021-12-08 10:38:47,829 [dispatcher-event-loop-6] INFO [org.apache.spark.storage.BlockManagerInfo] - Added rdd_77_8 in memory on qb:55657 (size: 11.1 MB, free: 1731.0 MB)
2021-12-08 10:38:47,967 [Executor task launch worker for task 222] INFO [org.apache.spark.storage.memory.MemoryStore] - Block rdd_77_10 stored as values in memory (estimated size 11.1 MB, free 1717.5 MB)
2021-12-08 10:38:47,967 [dispatcher-event-loop-8] INFO [org.apache.spark.storage.BlockManagerInfo] - Added rdd_77_10 in memory on qb:55657 (size: 11.1 MB, free: 1719.9 MB)
2021-12-08 10:38:48,026 [Executor task launch worker for task 221] INFO [org.apache.spark.executor.Executor] - Finished task 9.0 in stage 61.0 (TID 221). 166054 bytes result sent to driver
2021-12-08 10:38:48,032 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 9.0 in stage 61.0 (TID 221) in 37711 ms on localhost (executor driver) (1/12)
2021-12-08 10:38:48,055 [Executor task launch worker for task 219] INFO [org.apache.spark.storage.memory.MemoryStore] - Block rdd_77_7 stored as values in memory (estimated size 11.1 MB, free 1706.4 MB)
2021-12-08 10:38:48,055 [dispatcher-event-loop-9] INFO [org.apache.spark.storage.BlockManagerInfo] - Added rdd_77_7 in memory on qb:55657 (size: 11.1 MB, free: 1708.8 MB)
2021-12-08 10:38:48,161 [Executor task launch worker for task 220] INFO [org.apache.spark.executor.Executor] - Finished task 8.0 in stage 61.0 (TID 220). 166054 bytes result sent to driver
2021-12-08 10:38:48,165 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 8.0 in stage 61.0 (TID 220) in 37844 ms on localhost (executor driver) (2/12)
2021-12-08 10:38:48,308 [Executor task launch worker for task 222] INFO [org.apache.spark.executor.Executor] - Finished task 10.0 in stage 61.0 (TID 222). 166054 bytes result sent to driver
2021-12-08 10:38:48,309 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 10.0 in stage 61.0 (TID 222) in 37988 ms on localhost (executor driver) (3/12)
2021-12-08 10:38:48,395 [Executor task launch worker for task 219] INFO [org.apache.spark.executor.Executor] - Finished task 7.0 in stage 61.0 (TID 219). 166097 bytes result sent to driver
2021-12-08 10:38:48,396 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 7.0 in stage 61.0 (TID 219) in 38075 ms on localhost (executor driver) (4/12)
2021-12-08 10:38:49,441 [Executor task launch worker for task 223] INFO [org.apache.spark.storage.memory.MemoryStore] - Block rdd_77_11 stored as values in memory (estimated size 11.1 MB, free 1695.3 MB)
2021-12-08 10:38:49,442 [dispatcher-event-loop-5] INFO [org.apache.spark.storage.BlockManagerInfo] - Added rdd_77_11 in memory on qb:55657 (size: 11.1 MB, free: 1697.7 MB)
2021-12-08 10:38:49,602 [Executor task launch worker for task 218] INFO [org.apache.spark.storage.memory.MemoryStore] - Block rdd_77_6 stored as values in memory (estimated size 11.1 MB, free 1684.2 MB)
2021-12-08 10:38:49,602 [dispatcher-event-loop-3] INFO [org.apache.spark.storage.BlockManagerInfo] - Added rdd_77_6 in memory on qb:55657 (size: 11.1 MB, free: 1686.5 MB)
2021-12-08 10:38:49,762 [Executor task launch worker for task 215] INFO [org.apache.spark.storage.memory.MemoryStore] - Block rdd_77_3 stored as values in memory (estimated size 11.1 MB, free 1673.1 MB)
2021-12-08 10:38:49,762 [dispatcher-event-loop-2] INFO [org.apache.spark.storage.BlockManagerInfo] - Added rdd_77_3 in memory on qb:55657 (size: 11.1 MB, free: 1675.4 MB)
2021-12-08 10:38:49,763 [Executor task launch worker for task 223] INFO [org.apache.spark.executor.Executor] - Finished task 11.0 in stage 61.0 (TID 223). 166054 bytes result sent to driver
2021-12-08 10:38:49,763 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 11.0 in stage 61.0 (TID 223) in 39442 ms on localhost (executor driver) (5/12)
2021-12-08 10:38:49,897 [Executor task launch worker for task 218] INFO [org.apache.spark.executor.Executor] - Finished task 6.0 in stage 61.0 (TID 218). 166054 bytes result sent to driver
2021-12-08 10:38:49,897 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 6.0 in stage 61.0 (TID 218) in 39576 ms on localhost (executor driver) (6/12)
2021-12-08 10:38:50,072 [Executor task launch worker for task 215] INFO [org.apache.spark.executor.Executor] - Finished task 3.0 in stage 61.0 (TID 215). 166097 bytes result sent to driver
2021-12-08 10:38:50,072 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 3.0 in stage 61.0 (TID 215) in 39751 ms on localhost (executor driver) (7/12)
2021-12-08 10:38:50,895 [Executor task launch worker for task 216] INFO [org.apache.spark.storage.memory.MemoryStore] - Block rdd_77_4 stored as values in memory (estimated size 11.1 MB, free 1662.0 MB)
2021-12-08 10:38:50,895 [dispatcher-event-loop-9] INFO [org.apache.spark.storage.BlockManagerInfo] - Added rdd_77_4 in memory on qb:55657 (size: 11.1 MB, free: 1664.3 MB)
2021-12-08 10:38:50,904 [Executor task launch worker for task 214] INFO [org.apache.spark.storage.memory.MemoryStore] - Block rdd_77_2 stored as values in memory (estimated size 11.1 MB, free 1650.9 MB)
2021-12-08 10:38:50,904 [dispatcher-event-loop-7] INFO [org.apache.spark.storage.BlockManagerInfo] - Added rdd_77_2 in memory on qb:55657 (size: 11.1 MB, free: 1653.2 MB)
2021-12-08 10:38:51,041 [Executor task launch worker for task 213] INFO [org.apache.spark.storage.memory.MemoryStore] - Block rdd_77_1 stored as values in memory (estimated size 11.1 MB, free 1639.8 MB)
2021-12-08 10:38:51,041 [dispatcher-event-loop-4] INFO [org.apache.spark.storage.BlockManagerInfo] - Added rdd_77_1 in memory on qb:55657 (size: 11.1 MB, free: 1642.1 MB)
2021-12-08 10:38:51,118 [Executor task launch worker for task 216] INFO [org.apache.spark.executor.Executor] - Finished task 4.0 in stage 61.0 (TID 216). 166097 bytes result sent to driver
2021-12-08 10:38:51,118 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 4.0 in stage 61.0 (TID 216) in 40797 ms on localhost (executor driver) (8/12)
2021-12-08 10:38:51,120 [Executor task launch worker for task 214] INFO [org.apache.spark.executor.Executor] - Finished task 2.0 in stage 61.0 (TID 214). 166054 bytes result sent to driver
2021-12-08 10:38:51,120 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 2.0 in stage 61.0 (TID 214) in 40799 ms on localhost (executor driver) (9/12)
2021-12-08 10:38:51,128 [Executor task launch worker for task 217] INFO [org.apache.spark.storage.memory.MemoryStore] - Block rdd_77_5 stored as values in memory (estimated size 11.1 MB, free 1628.7 MB)
2021-12-08 10:38:51,128 [dispatcher-event-loop-0] INFO [org.apache.spark.storage.BlockManagerInfo] - Added rdd_77_5 in memory on qb:55657 (size: 11.1 MB, free: 1631.0 MB)
2021-12-08 10:38:51,230 [Executor task launch worker for task 213] INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 61.0 (TID 213). 166097 bytes result sent to driver
2021-12-08 10:38:51,231 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 61.0 (TID 213) in 40910 ms on localhost (executor driver) (10/12)
2021-12-08 10:38:51,273 [Executor task launch worker for task 212] INFO [org.apache.spark.storage.memory.MemoryStore] - Block rdd_77_0 stored as values in memory (estimated size 11.1 MB, free 1617.5 MB)
2021-12-08 10:38:51,273 [dispatcher-event-loop-3] INFO [org.apache.spark.storage.BlockManagerInfo] - Added rdd_77_0 in memory on qb:55657 (size: 11.1 MB, free: 1619.9 MB)
2021-12-08 10:38:51,328 [Executor task launch worker for task 217] INFO [org.apache.spark.executor.Executor] - Finished task 5.0 in stage 61.0 (TID 217). 166054 bytes result sent to driver
2021-12-08 10:38:51,329 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 5.0 in stage 61.0 (TID 217) in 41008 ms on localhost (executor driver) (11/12)
2021-12-08 10:38:51,457 [Executor task launch worker for task 212] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 61.0 (TID 212). 166054 bytes result sent to driver
2021-12-08 10:38:51,458 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 61.0 (TID 212) in 41137 ms on localhost (executor driver) (12/12)
2021-12-08 10:38:51,458 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 61.0, whose tasks have all completed, from pool 
2021-12-08 10:38:51,458 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 61 (aggregate at ALS.scala:1711) finished in 41.143 s
2021-12-08 10:38:51,458 [main] INFO [org.apache.spark.scheduler.DAGScheduler] - Job 10 finished: aggregate at ALS.scala:1711, took 41.791275 s
2021-12-08 10:38:51,474 [main] INFO [org.apache.spark.rdd.MapPartitionsRDD] - Removing RDD 67 from persistence list
2021-12-08 10:38:51,474 [block-manager-slave-async-thread-pool-2] INFO [org.apache.spark.storage.BlockManager] - Removing RDD 67
2021-12-08 10:38:51,481 [main] INFO [org.apache.spark.SparkContext] - Starting job: aggregate at ALS.scala:1711
2021-12-08 10:38:51,482 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 82 (flatMap at ALS.scala:1653)
2021-12-08 10:38:51,482 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 11 (aggregate at ALS.scala:1711) with 12 output partitions
2021-12-08 10:38:51,482 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 73 (aggregate at ALS.scala:1711)
2021-12-08 10:38:51,482 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 63, ShuffleMapStage 72)
2021-12-08 10:38:51,482 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List(ShuffleMapStage 72)
2021-12-08 10:38:51,482 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ShuffleMapStage 72 (MapPartitionsRDD[82] at flatMap at ALS.scala:1653), which has no missing parents
2021-12-08 10:38:51,484 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_22 stored as values in memory (estimated size 977.5 KB, free 1664.5 MB)
2021-12-08 10:38:51,486 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_22_piece0 stored as bytes in memory (estimated size 951.5 KB, free 1663.5 MB)
2021-12-08 10:38:51,486 [dispatcher-event-loop-10] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_22_piece0 in memory on qb:55657 (size: 951.5 KB, free: 1666.9 MB)
2021-12-08 10:38:51,487 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 22 from broadcast at DAGScheduler.scala:1039
2021-12-08 10:38:51,487 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 12 missing tasks from ShuffleMapStage 72 (MapPartitionsRDD[82] at flatMap at ALS.scala:1653) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11))
2021-12-08 10:38:51,487 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 72.0 with 12 tasks
2021-12-08 10:38:51,487 [dispatcher-event-loop-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 72.0 (TID 224, localhost, executor driver, partition 0, PROCESS_LOCAL, 7928 bytes)
2021-12-08 10:38:51,487 [dispatcher-event-loop-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 72.0 (TID 225, localhost, executor driver, partition 1, PROCESS_LOCAL, 7928 bytes)
2021-12-08 10:38:51,487 [dispatcher-event-loop-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 2.0 in stage 72.0 (TID 226, localhost, executor driver, partition 2, PROCESS_LOCAL, 7928 bytes)
2021-12-08 10:38:51,487 [dispatcher-event-loop-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 3.0 in stage 72.0 (TID 227, localhost, executor driver, partition 3, PROCESS_LOCAL, 7928 bytes)
2021-12-08 10:38:51,488 [dispatcher-event-loop-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 4.0 in stage 72.0 (TID 228, localhost, executor driver, partition 4, PROCESS_LOCAL, 7928 bytes)
2021-12-08 10:38:51,488 [dispatcher-event-loop-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 5.0 in stage 72.0 (TID 229, localhost, executor driver, partition 5, PROCESS_LOCAL, 7928 bytes)
2021-12-08 10:38:51,488 [dispatcher-event-loop-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 6.0 in stage 72.0 (TID 230, localhost, executor driver, partition 6, PROCESS_LOCAL, 7928 bytes)
2021-12-08 10:38:51,488 [dispatcher-event-loop-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 7.0 in stage 72.0 (TID 231, localhost, executor driver, partition 7, PROCESS_LOCAL, 7928 bytes)
2021-12-08 10:38:51,488 [dispatcher-event-loop-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 8.0 in stage 72.0 (TID 232, localhost, executor driver, partition 8, PROCESS_LOCAL, 7928 bytes)
2021-12-08 10:38:51,488 [dispatcher-event-loop-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 9.0 in stage 72.0 (TID 233, localhost, executor driver, partition 9, PROCESS_LOCAL, 7928 bytes)
2021-12-08 10:38:51,488 [dispatcher-event-loop-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 10.0 in stage 72.0 (TID 234, localhost, executor driver, partition 10, PROCESS_LOCAL, 7928 bytes)
2021-12-08 10:38:51,488 [dispatcher-event-loop-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 11.0 in stage 72.0 (TID 235, localhost, executor driver, partition 11, PROCESS_LOCAL, 7928 bytes)
2021-12-08 10:38:51,488 [Executor task launch worker for task 224] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 72.0 (TID 224)
2021-12-08 10:38:51,488 [Executor task launch worker for task 226] INFO [org.apache.spark.executor.Executor] - Running task 2.0 in stage 72.0 (TID 226)
2021-12-08 10:38:51,488 [Executor task launch worker for task 232] INFO [org.apache.spark.executor.Executor] - Running task 8.0 in stage 72.0 (TID 232)
2021-12-08 10:38:51,488 [Executor task launch worker for task 231] INFO [org.apache.spark.executor.Executor] - Running task 7.0 in stage 72.0 (TID 231)
2021-12-08 10:38:51,488 [Executor task launch worker for task 230] INFO [org.apache.spark.executor.Executor] - Running task 6.0 in stage 72.0 (TID 230)
2021-12-08 10:38:51,488 [Executor task launch worker for task 228] INFO [org.apache.spark.executor.Executor] - Running task 4.0 in stage 72.0 (TID 228)
2021-12-08 10:38:51,488 [Executor task launch worker for task 227] INFO [org.apache.spark.executor.Executor] - Running task 3.0 in stage 72.0 (TID 227)
2021-12-08 10:38:51,488 [Executor task launch worker for task 229] INFO [org.apache.spark.executor.Executor] - Running task 5.0 in stage 72.0 (TID 229)
2021-12-08 10:38:51,488 [Executor task launch worker for task 225] INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 72.0 (TID 225)
2021-12-08 10:38:51,488 [Executor task launch worker for task 233] INFO [org.apache.spark.executor.Executor] - Running task 9.0 in stage 72.0 (TID 233)
2021-12-08 10:38:51,488 [Executor task launch worker for task 235] INFO [org.apache.spark.executor.Executor] - Running task 11.0 in stage 72.0 (TID 235)
2021-12-08 10:38:51,488 [Executor task launch worker for task 234] INFO [org.apache.spark.executor.Executor] - Running task 10.0 in stage 72.0 (TID 234)
2021-12-08 10:38:51,491 [Executor task launch worker for task 233] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_10_9 locally
2021-12-08 10:38:51,491 [Executor task launch worker for task 235] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_10_11 locally
2021-12-08 10:38:51,491 [Executor task launch worker for task 235] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_77_11 locally
2021-12-08 10:38:51,491 [Executor task launch worker for task 232] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_10_8 locally
2021-12-08 10:38:51,491 [Executor task launch worker for task 234] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_10_10 locally
2021-12-08 10:38:51,491 [Executor task launch worker for task 234] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_77_10 locally
2021-12-08 10:38:51,491 [Executor task launch worker for task 232] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_77_8 locally
2021-12-08 10:38:51,491 [Executor task launch worker for task 225] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_10_1 locally
2021-12-08 10:38:51,491 [Executor task launch worker for task 225] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_77_1 locally
2021-12-08 10:38:51,492 [Executor task launch worker for task 229] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_10_5 locally
2021-12-08 10:38:51,492 [Executor task launch worker for task 229] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_77_5 locally
2021-12-08 10:38:51,492 [Executor task launch worker for task 231] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_10_7 locally
2021-12-08 10:38:51,492 [Executor task launch worker for task 231] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_77_7 locally
2021-12-08 10:38:51,491 [Executor task launch worker for task 230] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_10_6 locally
2021-12-08 10:38:51,492 [Executor task launch worker for task 233] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_77_9 locally
2021-12-08 10:38:51,492 [Executor task launch worker for task 226] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_10_2 locally
2021-12-08 10:38:51,492 [Executor task launch worker for task 226] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_77_2 locally
2021-12-08 10:38:51,492 [Executor task launch worker for task 228] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_10_4 locally
2021-12-08 10:38:51,492 [Executor task launch worker for task 228] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_77_4 locally
2021-12-08 10:38:51,492 [Executor task launch worker for task 230] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_77_6 locally
2021-12-08 10:38:51,492 [Executor task launch worker for task 227] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_10_3 locally
2021-12-08 10:38:51,496 [Executor task launch worker for task 227] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_77_3 locally
2021-12-08 10:38:51,492 [Executor task launch worker for task 224] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_10_0 locally
2021-12-08 10:38:51,496 [Executor task launch worker for task 224] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_77_0 locally
2021-12-08 10:38:53,504 [Executor task launch worker for task 226] INFO [org.apache.spark.executor.Executor] - Finished task 2.0 in stage 72.0 (TID 226). 999 bytes result sent to driver
2021-12-08 10:38:53,504 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 2.0 in stage 72.0 (TID 226) in 2017 ms on localhost (executor driver) (1/12)
2021-12-08 10:38:53,541 [Executor task launch worker for task 232] INFO [org.apache.spark.executor.Executor] - Finished task 8.0 in stage 72.0 (TID 232). 1042 bytes result sent to driver
2021-12-08 10:38:53,541 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 8.0 in stage 72.0 (TID 232) in 2053 ms on localhost (executor driver) (2/12)
2021-12-08 10:38:53,637 [Executor task launch worker for task 224] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 72.0 (TID 224). 999 bytes result sent to driver
2021-12-08 10:38:53,637 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 72.0 (TID 224) in 2150 ms on localhost (executor driver) (3/12)
2021-12-08 10:38:53,653 [Executor task launch worker for task 229] INFO [org.apache.spark.executor.Executor] - Finished task 5.0 in stage 72.0 (TID 229). 1042 bytes result sent to driver
2021-12-08 10:38:53,653 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 5.0 in stage 72.0 (TID 229) in 2165 ms on localhost (executor driver) (4/12)
2021-12-08 10:38:53,660 [Executor task launch worker for task 235] INFO [org.apache.spark.executor.Executor] - Finished task 11.0 in stage 72.0 (TID 235). 999 bytes result sent to driver
2021-12-08 10:38:53,660 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 11.0 in stage 72.0 (TID 235) in 2172 ms on localhost (executor driver) (5/12)
2021-12-08 10:38:53,664 [Executor task launch worker for task 228] INFO [org.apache.spark.executor.Executor] - Finished task 4.0 in stage 72.0 (TID 228). 999 bytes result sent to driver
2021-12-08 10:38:53,664 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 4.0 in stage 72.0 (TID 228) in 2177 ms on localhost (executor driver) (6/12)
2021-12-08 10:38:53,675 [Executor task launch worker for task 231] INFO [org.apache.spark.executor.Executor] - Finished task 7.0 in stage 72.0 (TID 231). 999 bytes result sent to driver
2021-12-08 10:38:53,675 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 7.0 in stage 72.0 (TID 231) in 2187 ms on localhost (executor driver) (7/12)
2021-12-08 10:38:53,791 [Executor task launch worker for task 234] INFO [org.apache.spark.executor.Executor] - Finished task 10.0 in stage 72.0 (TID 234). 1042 bytes result sent to driver
2021-12-08 10:38:53,791 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 10.0 in stage 72.0 (TID 234) in 2303 ms on localhost (executor driver) (8/12)
2021-12-08 10:38:53,939 [Executor task launch worker for task 230] INFO [org.apache.spark.executor.Executor] - Finished task 6.0 in stage 72.0 (TID 230). 1042 bytes result sent to driver
2021-12-08 10:38:53,939 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 6.0 in stage 72.0 (TID 230) in 2451 ms on localhost (executor driver) (9/12)
2021-12-08 10:38:53,940 [Executor task launch worker for task 233] INFO [org.apache.spark.executor.Executor] - Finished task 9.0 in stage 72.0 (TID 233). 1042 bytes result sent to driver
2021-12-08 10:38:53,940 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 9.0 in stage 72.0 (TID 233) in 2452 ms on localhost (executor driver) (10/12)
2021-12-08 10:38:54,095 [Executor task launch worker for task 225] INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 72.0 (TID 225). 999 bytes result sent to driver
2021-12-08 10:38:54,095 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 72.0 (TID 225) in 2608 ms on localhost (executor driver) (11/12)
2021-12-08 10:38:54,096 [Executor task launch worker for task 227] INFO [org.apache.spark.executor.Executor] - Finished task 3.0 in stage 72.0 (TID 227). 1042 bytes result sent to driver
2021-12-08 10:38:54,096 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 3.0 in stage 72.0 (TID 227) in 2609 ms on localhost (executor driver) (12/12)
2021-12-08 10:38:54,096 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 72.0, whose tasks have all completed, from pool 
2021-12-08 10:38:54,097 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ShuffleMapStage 72 (flatMap at ALS.scala:1653) finished in 2.614 s
2021-12-08 10:38:54,097 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - looking for newly runnable stages
2021-12-08 10:38:54,097 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - running: Set()
2021-12-08 10:38:54,097 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - waiting: Set(ResultStage 73)
2021-12-08 10:38:54,097 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - failed: Set()
2021-12-08 10:38:54,097 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 73 (MapPartitionsRDD[88] at values at ALS.scala:1711), which has no missing parents
2021-12-08 10:38:54,099 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_23 stored as values in memory (estimated size 1299.1 KB, free 1662.3 MB)
2021-12-08 10:38:54,102 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_23_piece0 stored as bytes in memory (estimated size 1110.2 KB, free 1661.2 MB)
2021-12-08 10:38:54,102 [dispatcher-event-loop-2] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_23_piece0 in memory on qb:55657 (size: 1110.2 KB, free: 1665.8 MB)
2021-12-08 10:38:54,102 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 23 from broadcast at DAGScheduler.scala:1039
2021-12-08 10:38:54,103 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 12 missing tasks from ResultStage 73 (MapPartitionsRDD[88] at values at ALS.scala:1711) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11))
2021-12-08 10:38:54,103 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 73.0 with 12 tasks
2021-12-08 10:38:54,103 [dispatcher-event-loop-6] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 73.0 (TID 236, localhost, executor driver, partition 0, PROCESS_LOCAL, 7888 bytes)
2021-12-08 10:38:54,103 [dispatcher-event-loop-6] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 73.0 (TID 237, localhost, executor driver, partition 1, PROCESS_LOCAL, 7888 bytes)
2021-12-08 10:38:54,103 [dispatcher-event-loop-6] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 2.0 in stage 73.0 (TID 238, localhost, executor driver, partition 2, PROCESS_LOCAL, 7888 bytes)
2021-12-08 10:38:54,103 [dispatcher-event-loop-6] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 3.0 in stage 73.0 (TID 239, localhost, executor driver, partition 3, PROCESS_LOCAL, 7888 bytes)
2021-12-08 10:38:54,103 [dispatcher-event-loop-6] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 4.0 in stage 73.0 (TID 240, localhost, executor driver, partition 4, PROCESS_LOCAL, 7888 bytes)
2021-12-08 10:38:54,103 [dispatcher-event-loop-6] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 5.0 in stage 73.0 (TID 241, localhost, executor driver, partition 5, PROCESS_LOCAL, 7888 bytes)
2021-12-08 10:38:54,103 [dispatcher-event-loop-6] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 6.0 in stage 73.0 (TID 242, localhost, executor driver, partition 6, PROCESS_LOCAL, 7888 bytes)
2021-12-08 10:38:54,103 [dispatcher-event-loop-6] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 7.0 in stage 73.0 (TID 243, localhost, executor driver, partition 7, PROCESS_LOCAL, 7888 bytes)
2021-12-08 10:38:54,104 [dispatcher-event-loop-6] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 8.0 in stage 73.0 (TID 244, localhost, executor driver, partition 8, PROCESS_LOCAL, 7888 bytes)
2021-12-08 10:38:54,104 [dispatcher-event-loop-6] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 9.0 in stage 73.0 (TID 245, localhost, executor driver, partition 9, PROCESS_LOCAL, 7888 bytes)
2021-12-08 10:38:54,104 [dispatcher-event-loop-6] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 10.0 in stage 73.0 (TID 246, localhost, executor driver, partition 10, PROCESS_LOCAL, 7888 bytes)
2021-12-08 10:38:54,104 [dispatcher-event-loop-6] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 11.0 in stage 73.0 (TID 247, localhost, executor driver, partition 11, PROCESS_LOCAL, 7888 bytes)
2021-12-08 10:38:54,104 [Executor task launch worker for task 237] INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 73.0 (TID 237)
2021-12-08 10:38:54,104 [Executor task launch worker for task 241] INFO [org.apache.spark.executor.Executor] - Running task 5.0 in stage 73.0 (TID 241)
2021-12-08 10:38:54,104 [Executor task launch worker for task 247] INFO [org.apache.spark.executor.Executor] - Running task 11.0 in stage 73.0 (TID 247)
2021-12-08 10:38:54,104 [Executor task launch worker for task 245] INFO [org.apache.spark.executor.Executor] - Running task 9.0 in stage 73.0 (TID 245)
2021-12-08 10:38:54,104 [Executor task launch worker for task 243] INFO [org.apache.spark.executor.Executor] - Running task 7.0 in stage 73.0 (TID 243)
2021-12-08 10:38:54,104 [Executor task launch worker for task 244] INFO [org.apache.spark.executor.Executor] - Running task 8.0 in stage 73.0 (TID 244)
2021-12-08 10:38:54,104 [Executor task launch worker for task 240] INFO [org.apache.spark.executor.Executor] - Running task 4.0 in stage 73.0 (TID 240)
2021-12-08 10:38:54,104 [Executor task launch worker for task 236] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 73.0 (TID 236)
2021-12-08 10:38:54,104 [Executor task launch worker for task 242] INFO [org.apache.spark.executor.Executor] - Running task 6.0 in stage 73.0 (TID 242)
2021-12-08 10:38:54,104 [Executor task launch worker for task 239] INFO [org.apache.spark.executor.Executor] - Running task 3.0 in stage 73.0 (TID 239)
2021-12-08 10:38:54,104 [Executor task launch worker for task 238] INFO [org.apache.spark.executor.Executor] - Running task 2.0 in stage 73.0 (TID 238)
2021-12-08 10:38:54,104 [Executor task launch worker for task 246] INFO [org.apache.spark.executor.Executor] - Running task 10.0 in stage 73.0 (TID 246)
2021-12-08 10:38:54,106 [Executor task launch worker for task 244] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_14_8 locally
2021-12-08 10:38:54,107 [Executor task launch worker for task 236] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_14_0 locally
2021-12-08 10:38:54,106 [Executor task launch worker for task 240] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_14_4 locally
2021-12-08 10:38:54,106 [Executor task launch worker for task 246] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_14_10 locally
2021-12-08 10:38:54,106 [Executor task launch worker for task 245] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_14_9 locally
2021-12-08 10:38:54,107 [Executor task launch worker for task 236] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 12 non-empty blocks out of 12 blocks
2021-12-08 10:38:54,107 [Executor task launch worker for task 246] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 12 non-empty blocks out of 12 blocks
2021-12-08 10:38:54,107 [Executor task launch worker for task 246] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-08 10:38:54,107 [Executor task launch worker for task 243] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_14_7 locally
2021-12-08 10:38:54,107 [Executor task launch worker for task 245] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 12 non-empty blocks out of 12 blocks
2021-12-08 10:38:54,107 [Executor task launch worker for task 244] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 12 non-empty blocks out of 12 blocks
2021-12-08 10:38:54,107 [Executor task launch worker for task 244] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-08 10:38:54,107 [Executor task launch worker for task 240] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 12 non-empty blocks out of 12 blocks
2021-12-08 10:38:54,107 [Executor task launch worker for task 236] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-08 10:38:54,108 [Executor task launch worker for task 240] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 1 ms
2021-12-08 10:38:54,107 [Executor task launch worker for task 237] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_14_1 locally
2021-12-08 10:38:54,108 [Executor task launch worker for task 237] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 12 non-empty blocks out of 12 blocks
2021-12-08 10:38:54,108 [Executor task launch worker for task 237] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-08 10:38:54,108 [Executor task launch worker for task 243] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 12 non-empty blocks out of 12 blocks
2021-12-08 10:38:54,107 [Executor task launch worker for task 245] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-08 10:38:54,108 [Executor task launch worker for task 243] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 1 ms
2021-12-08 10:38:54,108 [Executor task launch worker for task 239] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_14_3 locally
2021-12-08 10:38:54,108 [Executor task launch worker for task 239] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 12 non-empty blocks out of 12 blocks
2021-12-08 10:38:54,108 [Executor task launch worker for task 239] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-08 10:38:54,108 [Executor task launch worker for task 238] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_14_2 locally
2021-12-08 10:38:54,108 [Executor task launch worker for task 238] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 12 non-empty blocks out of 12 blocks
2021-12-08 10:38:54,108 [Executor task launch worker for task 238] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-08 10:38:54,108 [Executor task launch worker for task 241] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_14_5 locally
2021-12-08 10:38:54,108 [Executor task launch worker for task 242] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_14_6 locally
2021-12-08 10:38:54,108 [Executor task launch worker for task 247] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_14_11 locally
2021-12-08 10:38:54,109 [Executor task launch worker for task 242] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 12 non-empty blocks out of 12 blocks
2021-12-08 10:38:54,109 [Executor task launch worker for task 241] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 12 non-empty blocks out of 12 blocks
2021-12-08 10:38:54,109 [Executor task launch worker for task 247] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 12 non-empty blocks out of 12 blocks
2021-12-08 10:38:54,109 [Executor task launch worker for task 241] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-08 10:38:54,109 [Executor task launch worker for task 242] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-08 10:38:54,109 [Executor task launch worker for task 247] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-08 10:38:54,328 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 471
2021-12-08 10:38:54,329 [dispatcher-event-loop-4] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_22_piece0 on qb:55657 in memory (size: 951.5 KB, free: 1666.7 MB)
2021-12-08 10:38:54,330 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 522
2021-12-08 10:38:54,330 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 516
2021-12-08 10:38:54,330 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 505
2021-12-08 10:38:54,330 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 515
2021-12-08 10:38:54,330 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 484
2021-12-08 10:38:54,330 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 445
2021-12-08 10:38:54,330 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 450
2021-12-08 10:38:54,330 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 462
2021-12-08 10:38:54,330 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 453
2021-12-08 10:38:54,330 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 509
2021-12-08 10:38:54,330 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 485
2021-12-08 10:38:54,330 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 481
2021-12-08 10:38:54,330 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 492
2021-12-08 10:38:54,330 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 451
2021-12-08 10:38:54,330 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 464
2021-12-08 10:38:54,330 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 431
2021-12-08 10:38:54,330 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 512
2021-12-08 10:38:54,330 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 425
2021-12-08 10:38:54,330 [dispatcher-event-loop-10] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_21_piece0 on qb:55657 in memory (size: 952.5 KB, free: 1667.6 MB)
2021-12-08 10:38:54,331 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 455
2021-12-08 10:38:54,331 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 489
2021-12-08 10:38:54,331 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 427
2021-12-08 10:38:54,332 [dispatcher-event-loop-0] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_19_piece0 on qb:55657 in memory (size: 794.8 KB, free: 1668.4 MB)
2021-12-08 10:38:54,332 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 439
2021-12-08 10:38:54,332 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 521
2021-12-08 10:38:54,332 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 498
2021-12-08 10:38:54,332 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 507
2021-12-08 10:38:54,333 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 470
2021-12-08 10:38:54,333 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 500
2021-12-08 10:38:54,333 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 520
2021-12-08 10:38:54,333 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 436
2021-12-08 10:38:54,333 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 454
2021-12-08 10:38:54,333 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 494
2021-12-08 10:38:54,333 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 446
2021-12-08 10:38:54,333 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 463
2021-12-08 10:38:54,333 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 493
2021-12-08 10:38:54,333 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 475
2021-12-08 10:38:54,333 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 480
2021-12-08 10:38:54,333 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 506
2021-12-08 10:38:54,333 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 478
2021-12-08 10:38:54,333 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 469
2021-12-08 10:38:54,333 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 440
2021-12-08 10:38:54,333 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 452
2021-12-08 10:38:54,333 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 502
2021-12-08 10:38:54,333 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 511
2021-12-08 10:38:54,333 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 514
2021-12-08 10:38:54,333 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 496
2021-12-08 10:38:54,333 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 460
2021-12-08 10:38:54,333 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 428
2021-12-08 10:38:54,333 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 429
2021-12-08 10:38:54,333 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 491
2021-12-08 10:38:54,333 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 459
2021-12-08 10:38:54,333 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 474
2021-12-08 10:38:54,333 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 465
2021-12-08 10:38:54,333 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 456
2021-12-08 10:38:54,333 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 438
2021-12-08 10:38:54,333 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 468
2021-12-08 10:38:54,333 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 467
2021-12-08 10:38:54,333 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 482
2021-12-08 10:38:54,333 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 477
2021-12-08 10:38:54,333 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 487
2021-12-08 10:38:54,333 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 519
2021-12-08 10:38:54,333 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 476
2021-12-08 10:38:54,333 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 473
2021-12-08 10:38:54,333 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 513
2021-12-08 10:38:54,333 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 495
2021-12-08 10:38:54,333 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 449
2021-12-08 10:38:54,333 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 503
2021-12-08 10:38:54,333 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 435
2021-12-08 10:38:54,333 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 517
2021-12-08 10:38:54,333 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 430
2021-12-08 10:38:54,333 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 524
2021-12-08 10:38:54,333 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 488
2021-12-08 10:38:54,333 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 448
2021-12-08 10:38:54,333 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 499
2021-12-08 10:38:54,333 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 479
2021-12-08 10:38:54,333 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 490
2021-12-08 10:38:54,333 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 447
2021-12-08 10:38:54,333 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 434
2021-12-08 10:38:54,334 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 472
2021-12-08 10:38:54,334 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 486
2021-12-08 10:38:54,334 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 458
2021-12-08 10:38:54,334 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 501
2021-12-08 10:38:54,334 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 433
2021-12-08 10:38:54,334 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 457
2021-12-08 10:38:54,334 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 466
2021-12-08 10:38:54,334 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 497
2021-12-08 10:38:54,334 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 441
2021-12-08 10:38:54,334 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 432
2021-12-08 10:38:54,334 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 518
2021-12-08 10:38:54,334 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 442
2021-12-08 10:38:54,334 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 483
2021-12-08 10:38:54,334 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 443
2021-12-08 10:38:54,334 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 510
2021-12-08 10:38:54,334 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 504
2021-12-08 10:38:54,334 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 437
2021-12-08 10:38:54,334 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 523
2021-12-08 10:38:54,334 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 444
2021-12-08 10:38:54,334 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 508
2021-12-08 10:38:54,334 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 426
2021-12-08 10:38:54,334 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 461
2021-12-08 10:39:16,356 [Executor task launch worker for task 240] INFO [org.apache.spark.storage.memory.MemoryStore] - Block rdd_87_4 stored as values in memory (estimated size 4.0 MB, free 1662.8 MB)
2021-12-08 10:39:16,357 [dispatcher-event-loop-4] INFO [org.apache.spark.storage.BlockManagerInfo] - Added rdd_87_4 in memory on qb:55657 (size: 4.0 MB, free: 1664.4 MB)
2021-12-08 10:39:16,477 [Executor task launch worker for task 240] INFO [org.apache.spark.executor.Executor] - Finished task 4.0 in stage 73.0 (TID 240). 166054 bytes result sent to driver
2021-12-08 10:39:16,489 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 4.0 in stage 73.0 (TID 240) in 22386 ms on localhost (executor driver) (1/12)
2021-12-08 10:39:17,056 [Executor task launch worker for task 246] INFO [org.apache.spark.storage.memory.MemoryStore] - Block rdd_87_10 stored as values in memory (estimated size 4.0 MB, free 1658.9 MB)
2021-12-08 10:39:17,056 [dispatcher-event-loop-7] INFO [org.apache.spark.storage.BlockManagerInfo] - Added rdd_87_10 in memory on qb:55657 (size: 4.0 MB, free: 1660.4 MB)
2021-12-08 10:39:17,179 [Executor task launch worker for task 241] INFO [org.apache.spark.storage.memory.MemoryStore] - Block rdd_87_5 stored as values in memory (estimated size 4.0 MB, free 1654.9 MB)
2021-12-08 10:39:17,179 [dispatcher-event-loop-10] INFO [org.apache.spark.storage.BlockManagerInfo] - Added rdd_87_5 in memory on qb:55657 (size: 4.0 MB, free: 1656.4 MB)
2021-12-08 10:39:17,181 [Executor task launch worker for task 246] INFO [org.apache.spark.executor.Executor] - Finished task 10.0 in stage 73.0 (TID 246). 166054 bytes result sent to driver
2021-12-08 10:39:17,181 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 10.0 in stage 73.0 (TID 246) in 23077 ms on localhost (executor driver) (2/12)
2021-12-08 10:39:17,289 [Executor task launch worker for task 241] INFO [org.apache.spark.executor.Executor] - Finished task 5.0 in stage 73.0 (TID 241). 166054 bytes result sent to driver
2021-12-08 10:39:17,290 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 5.0 in stage 73.0 (TID 241) in 23187 ms on localhost (executor driver) (3/12)
2021-12-08 10:39:17,464 [Executor task launch worker for task 243] INFO [org.apache.spark.storage.memory.MemoryStore] - Block rdd_87_7 stored as values in memory (estimated size 4.0 MB, free 1650.9 MB)
2021-12-08 10:39:17,464 [dispatcher-event-loop-0] INFO [org.apache.spark.storage.BlockManagerInfo] - Added rdd_87_7 in memory on qb:55657 (size: 4.0 MB, free: 1652.4 MB)
2021-12-08 10:39:17,564 [Executor task launch worker for task 243] INFO [org.apache.spark.executor.Executor] - Finished task 7.0 in stage 73.0 (TID 243). 166054 bytes result sent to driver
2021-12-08 10:39:17,564 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 7.0 in stage 73.0 (TID 243) in 23461 ms on localhost (executor driver) (4/12)
2021-12-08 10:39:18,109 [Executor task launch worker for task 237] INFO [org.apache.spark.storage.memory.MemoryStore] - Block rdd_87_1 stored as values in memory (estimated size 4.0 MB, free 1646.9 MB)
2021-12-08 10:39:18,109 [dispatcher-event-loop-6] INFO [org.apache.spark.storage.BlockManagerInfo] - Added rdd_87_1 in memory on qb:55657 (size: 4.0 MB, free: 1648.5 MB)
2021-12-08 10:39:18,209 [Executor task launch worker for task 244] INFO [org.apache.spark.storage.memory.MemoryStore] - Block rdd_87_8 stored as values in memory (estimated size 4.0 MB, free 1642.9 MB)
2021-12-08 10:39:18,209 [dispatcher-event-loop-3] INFO [org.apache.spark.storage.BlockManagerInfo] - Added rdd_87_8 in memory on qb:55657 (size: 4.0 MB, free: 1644.5 MB)
2021-12-08 10:39:18,213 [Executor task launch worker for task 237] INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 73.0 (TID 237). 166054 bytes result sent to driver
2021-12-08 10:39:18,213 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 73.0 (TID 237) in 24110 ms on localhost (executor driver) (5/12)
2021-12-08 10:39:18,305 [Executor task launch worker for task 244] INFO [org.apache.spark.executor.Executor] - Finished task 8.0 in stage 73.0 (TID 244). 166054 bytes result sent to driver
2021-12-08 10:39:18,305 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 8.0 in stage 73.0 (TID 244) in 24202 ms on localhost (executor driver) (6/12)
2021-12-08 10:39:18,609 [Executor task launch worker for task 238] INFO [org.apache.spark.storage.memory.MemoryStore] - Block rdd_87_2 stored as values in memory (estimated size 4.0 MB, free 1638.9 MB)
2021-12-08 10:39:18,609 [dispatcher-event-loop-4] INFO [org.apache.spark.storage.BlockManagerInfo] - Added rdd_87_2 in memory on qb:55657 (size: 4.0 MB, free: 1640.5 MB)
2021-12-08 10:39:18,632 [Executor task launch worker for task 236] INFO [org.apache.spark.storage.memory.MemoryStore] - Block rdd_87_0 stored as values in memory (estimated size 4.0 MB, free 1634.9 MB)
2021-12-08 10:39:18,633 [dispatcher-event-loop-1] INFO [org.apache.spark.storage.BlockManagerInfo] - Added rdd_87_0 in memory on qb:55657 (size: 4.0 MB, free: 1636.5 MB)
2021-12-08 10:39:18,681 [Executor task launch worker for task 238] INFO [org.apache.spark.executor.Executor] - Finished task 2.0 in stage 73.0 (TID 238). 166097 bytes result sent to driver
2021-12-08 10:39:18,681 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 2.0 in stage 73.0 (TID 238) in 24578 ms on localhost (executor driver) (7/12)
2021-12-08 10:39:18,704 [Executor task launch worker for task 236] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 73.0 (TID 236). 166097 bytes result sent to driver
2021-12-08 10:39:18,704 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 73.0 (TID 236) in 24601 ms on localhost (executor driver) (8/12)
2021-12-08 10:39:18,861 [Executor task launch worker for task 247] INFO [org.apache.spark.storage.memory.MemoryStore] - Block rdd_87_11 stored as values in memory (estimated size 4.0 MB, free 1630.9 MB)
2021-12-08 10:39:18,861 [dispatcher-event-loop-0] INFO [org.apache.spark.storage.BlockManagerInfo] - Added rdd_87_11 in memory on qb:55657 (size: 4.0 MB, free: 1632.5 MB)
2021-12-08 10:39:18,932 [Executor task launch worker for task 247] INFO [org.apache.spark.executor.Executor] - Finished task 11.0 in stage 73.0 (TID 247). 166054 bytes result sent to driver
2021-12-08 10:39:18,932 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 11.0 in stage 73.0 (TID 247) in 24828 ms on localhost (executor driver) (9/12)
2021-12-08 10:39:19,317 [Executor task launch worker for task 239] INFO [org.apache.spark.storage.memory.MemoryStore] - Block rdd_87_3 stored as values in memory (estimated size 4.0 MB, free 1626.9 MB)
2021-12-08 10:39:19,317 [dispatcher-event-loop-6] INFO [org.apache.spark.storage.BlockManagerInfo] - Added rdd_87_3 in memory on qb:55657 (size: 4.0 MB, free: 1628.5 MB)
2021-12-08 10:39:19,379 [Executor task launch worker for task 239] INFO [org.apache.spark.executor.Executor] - Finished task 3.0 in stage 73.0 (TID 239). 166054 bytes result sent to driver
2021-12-08 10:39:19,379 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 3.0 in stage 73.0 (TID 239) in 25276 ms on localhost (executor driver) (10/12)
2021-12-08 10:39:19,888 [Executor task launch worker for task 245] INFO [org.apache.spark.storage.memory.MemoryStore] - Block rdd_87_9 stored as values in memory (estimated size 4.0 MB, free 1623.0 MB)
2021-12-08 10:39:19,889 [dispatcher-event-loop-9] INFO [org.apache.spark.storage.BlockManagerInfo] - Added rdd_87_9 in memory on qb:55657 (size: 4.0 MB, free: 1624.5 MB)
2021-12-08 10:39:19,952 [Executor task launch worker for task 245] INFO [org.apache.spark.executor.Executor] - Finished task 9.0 in stage 73.0 (TID 245). 166054 bytes result sent to driver
2021-12-08 10:39:19,952 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 9.0 in stage 73.0 (TID 245) in 25848 ms on localhost (executor driver) (11/12)
2021-12-08 10:39:20,184 [Executor task launch worker for task 242] INFO [org.apache.spark.storage.memory.MemoryStore] - Block rdd_87_6 stored as values in memory (estimated size 4.0 MB, free 1619.0 MB)
2021-12-08 10:39:20,185 [dispatcher-event-loop-4] INFO [org.apache.spark.storage.BlockManagerInfo] - Added rdd_87_6 in memory on qb:55657 (size: 4.0 MB, free: 1620.5 MB)
2021-12-08 10:39:20,247 [Executor task launch worker for task 242] INFO [org.apache.spark.executor.Executor] - Finished task 6.0 in stage 73.0 (TID 242). 166054 bytes result sent to driver
2021-12-08 10:39:20,248 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 6.0 in stage 73.0 (TID 242) in 26145 ms on localhost (executor driver) (12/12)
2021-12-08 10:39:20,248 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 73.0, whose tasks have all completed, from pool 
2021-12-08 10:39:20,248 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 73 (aggregate at ALS.scala:1711) finished in 26.150 s
2021-12-08 10:39:20,248 [main] INFO [org.apache.spark.scheduler.DAGScheduler] - Job 11 finished: aggregate at ALS.scala:1711, took 28.767016 s
2021-12-08 10:39:20,263 [main] INFO [org.apache.spark.rdd.MapPartitionsRDD] - Removing RDD 77 from persistence list
2021-12-08 10:39:20,264 [block-manager-slave-async-thread-pool-2] INFO [org.apache.spark.storage.BlockManager] - Removing RDD 77
2021-12-08 10:39:20,269 [main] INFO [org.apache.spark.SparkContext] - Starting job: aggregate at ALS.scala:1711
2021-12-08 10:39:20,271 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 92 (flatMap at ALS.scala:1653)
2021-12-08 10:39:20,271 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 12 (aggregate at ALS.scala:1711) with 12 output partitions
2021-12-08 10:39:20,271 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 86 (aggregate at ALS.scala:1711)
2021-12-08 10:39:20,271 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 85, ShuffleMapStage 75)
2021-12-08 10:39:20,271 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List(ShuffleMapStage 85)
2021-12-08 10:39:20,272 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ShuffleMapStage 85 (MapPartitionsRDD[92] at flatMap at ALS.scala:1653), which has no missing parents
2021-12-08 10:39:20,275 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_24 stored as values in memory (estimated size 1138.6 KB, free 1751.1 MB)
2021-12-08 10:39:20,277 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_24_piece0 stored as bytes in memory (estimated size 1109.2 KB, free 1750.0 MB)
2021-12-08 10:39:20,278 [dispatcher-event-loop-6] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_24_piece0 in memory on qb:55657 (size: 1109.2 KB, free: 1752.7 MB)
2021-12-08 10:39:20,278 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 24 from broadcast at DAGScheduler.scala:1039
2021-12-08 10:39:20,278 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 12 missing tasks from ShuffleMapStage 85 (MapPartitionsRDD[92] at flatMap at ALS.scala:1653) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11))
2021-12-08 10:39:20,278 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 85.0 with 12 tasks
2021-12-08 10:39:20,278 [dispatcher-event-loop-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 85.0 (TID 248, localhost, executor driver, partition 0, PROCESS_LOCAL, 7928 bytes)
2021-12-08 10:39:20,279 [dispatcher-event-loop-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 85.0 (TID 249, localhost, executor driver, partition 1, PROCESS_LOCAL, 7928 bytes)
2021-12-08 10:39:20,279 [dispatcher-event-loop-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 2.0 in stage 85.0 (TID 250, localhost, executor driver, partition 2, PROCESS_LOCAL, 7928 bytes)
2021-12-08 10:39:20,279 [dispatcher-event-loop-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 3.0 in stage 85.0 (TID 251, localhost, executor driver, partition 3, PROCESS_LOCAL, 7928 bytes)
2021-12-08 10:39:20,279 [dispatcher-event-loop-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 4.0 in stage 85.0 (TID 252, localhost, executor driver, partition 4, PROCESS_LOCAL, 7928 bytes)
2021-12-08 10:39:20,279 [dispatcher-event-loop-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 5.0 in stage 85.0 (TID 253, localhost, executor driver, partition 5, PROCESS_LOCAL, 7928 bytes)
2021-12-08 10:39:20,279 [dispatcher-event-loop-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 6.0 in stage 85.0 (TID 254, localhost, executor driver, partition 6, PROCESS_LOCAL, 7928 bytes)
2021-12-08 10:39:20,279 [dispatcher-event-loop-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 7.0 in stage 85.0 (TID 255, localhost, executor driver, partition 7, PROCESS_LOCAL, 7928 bytes)
2021-12-08 10:39:20,279 [dispatcher-event-loop-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 8.0 in stage 85.0 (TID 256, localhost, executor driver, partition 8, PROCESS_LOCAL, 7928 bytes)
2021-12-08 10:39:20,279 [dispatcher-event-loop-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 9.0 in stage 85.0 (TID 257, localhost, executor driver, partition 9, PROCESS_LOCAL, 7928 bytes)
2021-12-08 10:39:20,279 [dispatcher-event-loop-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 10.0 in stage 85.0 (TID 258, localhost, executor driver, partition 10, PROCESS_LOCAL, 7928 bytes)
2021-12-08 10:39:20,279 [dispatcher-event-loop-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 11.0 in stage 85.0 (TID 259, localhost, executor driver, partition 11, PROCESS_LOCAL, 7928 bytes)
2021-12-08 10:39:20,279 [Executor task launch worker for task 249] INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 85.0 (TID 249)
2021-12-08 10:39:20,279 [Executor task launch worker for task 252] INFO [org.apache.spark.executor.Executor] - Running task 4.0 in stage 85.0 (TID 252)
2021-12-08 10:39:20,279 [Executor task launch worker for task 256] INFO [org.apache.spark.executor.Executor] - Running task 8.0 in stage 85.0 (TID 256)
2021-12-08 10:39:20,279 [Executor task launch worker for task 248] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 85.0 (TID 248)
2021-12-08 10:39:20,279 [Executor task launch worker for task 254] INFO [org.apache.spark.executor.Executor] - Running task 6.0 in stage 85.0 (TID 254)
2021-12-08 10:39:20,279 [Executor task launch worker for task 253] INFO [org.apache.spark.executor.Executor] - Running task 5.0 in stage 85.0 (TID 253)
2021-12-08 10:39:20,279 [Executor task launch worker for task 250] INFO [org.apache.spark.executor.Executor] - Running task 2.0 in stage 85.0 (TID 250)
2021-12-08 10:39:20,279 [Executor task launch worker for task 251] INFO [org.apache.spark.executor.Executor] - Running task 3.0 in stage 85.0 (TID 251)
2021-12-08 10:39:20,279 [Executor task launch worker for task 255] INFO [org.apache.spark.executor.Executor] - Running task 7.0 in stage 85.0 (TID 255)
2021-12-08 10:39:20,279 [Executor task launch worker for task 258] INFO [org.apache.spark.executor.Executor] - Running task 10.0 in stage 85.0 (TID 258)
2021-12-08 10:39:20,279 [Executor task launch worker for task 257] INFO [org.apache.spark.executor.Executor] - Running task 9.0 in stage 85.0 (TID 257)
2021-12-08 10:39:20,279 [Executor task launch worker for task 259] INFO [org.apache.spark.executor.Executor] - Running task 11.0 in stage 85.0 (TID 259)
2021-12-08 10:39:20,282 [Executor task launch worker for task 253] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_15_5 locally
2021-12-08 10:39:20,282 [Executor task launch worker for task 258] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_15_10 locally
2021-12-08 10:39:20,282 [Executor task launch worker for task 258] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_87_10 locally
2021-12-08 10:39:20,282 [Executor task launch worker for task 259] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_15_11 locally
2021-12-08 10:39:20,282 [Executor task launch worker for task 259] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_87_11 locally
2021-12-08 10:39:20,282 [Executor task launch worker for task 257] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_15_9 locally
2021-12-08 10:39:20,282 [Executor task launch worker for task 249] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_15_1 locally
2021-12-08 10:39:20,282 [Executor task launch worker for task 249] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_87_1 locally
2021-12-08 10:39:20,282 [Executor task launch worker for task 250] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_15_2 locally
2021-12-08 10:39:20,282 [Executor task launch worker for task 255] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_15_7 locally
2021-12-08 10:39:20,282 [Executor task launch worker for task 254] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_15_6 locally
2021-12-08 10:39:20,282 [Executor task launch worker for task 251] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_15_3 locally
2021-12-08 10:39:20,282 [Executor task launch worker for task 252] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_15_4 locally
2021-12-08 10:39:20,282 [Executor task launch worker for task 252] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_87_4 locally
2021-12-08 10:39:20,282 [Executor task launch worker for task 257] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_87_9 locally
2021-12-08 10:39:20,282 [Executor task launch worker for task 250] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_87_2 locally
2021-12-08 10:39:20,282 [Executor task launch worker for task 255] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_87_7 locally
2021-12-08 10:39:20,282 [Executor task launch worker for task 254] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_87_6 locally
2021-12-08 10:39:20,283 [Executor task launch worker for task 248] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_15_0 locally
2021-12-08 10:39:20,283 [Executor task launch worker for task 248] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_87_0 locally
2021-12-08 10:39:20,282 [Executor task launch worker for task 253] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_87_5 locally
2021-12-08 10:39:20,282 [Executor task launch worker for task 251] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_87_3 locally
2021-12-08 10:39:20,283 [Executor task launch worker for task 256] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_15_8 locally
2021-12-08 10:39:20,283 [Executor task launch worker for task 256] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_87_8 locally
2021-12-08 10:39:20,457 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 557
2021-12-08 10:39:20,457 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 526
2021-12-08 10:39:20,457 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 530
2021-12-08 10:39:20,457 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 529
2021-12-08 10:39:20,457 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 535
2021-12-08 10:39:20,457 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 533
2021-12-08 10:39:20,457 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 534
2021-12-08 10:39:20,457 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 570
2021-12-08 10:39:20,457 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 550
2021-12-08 10:39:20,458 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 537
2021-12-08 10:39:20,458 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 561
2021-12-08 10:39:20,458 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 548
2021-12-08 10:39:20,458 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 547
2021-12-08 10:39:20,458 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 525
2021-12-08 10:39:20,458 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 555
2021-12-08 10:39:20,458 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 527
2021-12-08 10:39:20,458 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 563
2021-12-08 10:39:20,458 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 573
2021-12-08 10:39:20,458 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 540
2021-12-08 10:39:20,458 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 569
2021-12-08 10:39:20,458 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 551
2021-12-08 10:39:20,458 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 572
2021-12-08 10:39:20,458 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 574
2021-12-08 10:39:20,458 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 564
2021-12-08 10:39:20,458 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 559
2021-12-08 10:39:20,458 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 566
2021-12-08 10:39:20,458 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 560
2021-12-08 10:39:20,458 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 531
2021-12-08 10:39:20,458 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 536
2021-12-08 10:39:20,458 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 549
2021-12-08 10:39:20,458 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 571
2021-12-08 10:39:20,460 [dispatcher-event-loop-9] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_23_piece0 on qb:55657 in memory (size: 1110.2 KB, free: 1753.8 MB)
2021-12-08 10:39:20,462 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 539
2021-12-08 10:39:20,462 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 528
2021-12-08 10:39:20,462 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 562
2021-12-08 10:39:20,462 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 541
2021-12-08 10:39:20,462 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 542
2021-12-08 10:39:20,462 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 568
2021-12-08 10:39:20,462 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 553
2021-12-08 10:39:20,462 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 544
2021-12-08 10:39:20,462 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 554
2021-12-08 10:39:20,462 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 532
2021-12-08 10:39:20,462 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 565
2021-12-08 10:39:20,462 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 552
2021-12-08 10:39:20,462 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 558
2021-12-08 10:39:20,462 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 546
2021-12-08 10:39:20,462 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 556
2021-12-08 10:39:20,462 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 545
2021-12-08 10:39:20,462 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 538
2021-12-08 10:39:20,462 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 567
2021-12-08 10:39:20,462 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 543
2021-12-08 10:39:20,881 [Executor task launch worker for task 254] INFO [org.apache.spark.executor.Executor] - Finished task 6.0 in stage 85.0 (TID 254). 1042 bytes result sent to driver
2021-12-08 10:39:20,882 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 6.0 in stage 85.0 (TID 254) in 603 ms on localhost (executor driver) (1/12)
2021-12-08 10:39:20,912 [Executor task launch worker for task 251] INFO [org.apache.spark.executor.Executor] - Finished task 3.0 in stage 85.0 (TID 251). 1042 bytes result sent to driver
2021-12-08 10:39:20,912 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 3.0 in stage 85.0 (TID 251) in 633 ms on localhost (executor driver) (2/12)
2021-12-08 10:39:20,998 [Executor task launch worker for task 258] INFO [org.apache.spark.executor.Executor] - Finished task 10.0 in stage 85.0 (TID 258). 1042 bytes result sent to driver
2021-12-08 10:39:20,998 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 10.0 in stage 85.0 (TID 258) in 719 ms on localhost (executor driver) (3/12)
2021-12-08 10:39:21,014 [Executor task launch worker for task 259] INFO [org.apache.spark.executor.Executor] - Finished task 11.0 in stage 85.0 (TID 259). 1042 bytes result sent to driver
2021-12-08 10:39:21,014 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 11.0 in stage 85.0 (TID 259) in 735 ms on localhost (executor driver) (4/12)
2021-12-08 10:39:21,016 [Executor task launch worker for task 248] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 85.0 (TID 248). 1042 bytes result sent to driver
2021-12-08 10:39:21,016 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 85.0 (TID 248) in 738 ms on localhost (executor driver) (5/12)
2021-12-08 10:39:21,027 [Executor task launch worker for task 249] INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 85.0 (TID 249). 1042 bytes result sent to driver
2021-12-08 10:39:21,028 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 85.0 (TID 249) in 750 ms on localhost (executor driver) (6/12)
2021-12-08 10:39:21,029 [Executor task launch worker for task 256] INFO [org.apache.spark.executor.Executor] - Finished task 8.0 in stage 85.0 (TID 256). 1085 bytes result sent to driver
2021-12-08 10:39:21,029 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 8.0 in stage 85.0 (TID 256) in 750 ms on localhost (executor driver) (7/12)
2021-12-08 10:39:21,048 [Executor task launch worker for task 253] INFO [org.apache.spark.executor.Executor] - Finished task 5.0 in stage 85.0 (TID 253). 1042 bytes result sent to driver
2021-12-08 10:39:21,048 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 5.0 in stage 85.0 (TID 253) in 769 ms on localhost (executor driver) (8/12)
2021-12-08 10:39:21,077 [Executor task launch worker for task 255] INFO [org.apache.spark.executor.Executor] - Finished task 7.0 in stage 85.0 (TID 255). 1042 bytes result sent to driver
2021-12-08 10:39:21,077 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 7.0 in stage 85.0 (TID 255) in 798 ms on localhost (executor driver) (9/12)
2021-12-08 10:39:21,128 [Executor task launch worker for task 252] INFO [org.apache.spark.executor.Executor] - Finished task 4.0 in stage 85.0 (TID 252). 1042 bytes result sent to driver
2021-12-08 10:39:21,129 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 4.0 in stage 85.0 (TID 252) in 849 ms on localhost (executor driver) (10/12)
2021-12-08 10:39:21,130 [Executor task launch worker for task 250] INFO [org.apache.spark.executor.Executor] - Finished task 2.0 in stage 85.0 (TID 250). 1042 bytes result sent to driver
2021-12-08 10:39:21,130 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 2.0 in stage 85.0 (TID 250) in 851 ms on localhost (executor driver) (11/12)
2021-12-08 10:39:21,139 [Executor task launch worker for task 257] INFO [org.apache.spark.executor.Executor] - Finished task 9.0 in stage 85.0 (TID 257). 1042 bytes result sent to driver
2021-12-08 10:39:21,139 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 9.0 in stage 85.0 (TID 257) in 860 ms on localhost (executor driver) (12/12)
2021-12-08 10:39:21,139 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 85.0, whose tasks have all completed, from pool 
2021-12-08 10:39:21,139 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ShuffleMapStage 85 (flatMap at ALS.scala:1653) finished in 0.867 s
2021-12-08 10:39:21,139 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - looking for newly runnable stages
2021-12-08 10:39:21,139 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - running: Set()
2021-12-08 10:39:21,140 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - waiting: Set(ResultStage 86)
2021-12-08 10:39:21,140 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - failed: Set()
2021-12-08 10:39:21,140 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 86 (MapPartitionsRDD[98] at values at ALS.scala:1711), which has no missing parents
2021-12-08 10:39:21,144 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_25 stored as values in memory (estimated size 1460.2 KB, free 1751.0 MB)
2021-12-08 10:39:21,148 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_25_piece0 stored as bytes in memory (estimated size 1268.0 KB, free 1749.7 MB)
2021-12-08 10:39:21,148 [dispatcher-event-loop-10] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_25_piece0 in memory on qb:55657 (size: 1268.0 KB, free: 1752.6 MB)
2021-12-08 10:39:21,149 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 25 from broadcast at DAGScheduler.scala:1039
2021-12-08 10:39:21,149 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 12 missing tasks from ResultStage 86 (MapPartitionsRDD[98] at values at ALS.scala:1711) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11))
2021-12-08 10:39:21,149 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 86.0 with 12 tasks
2021-12-08 10:39:21,150 [dispatcher-event-loop-5] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 86.0 (TID 260, localhost, executor driver, partition 0, PROCESS_LOCAL, 7888 bytes)
2021-12-08 10:39:21,150 [dispatcher-event-loop-5] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 86.0 (TID 261, localhost, executor driver, partition 1, PROCESS_LOCAL, 7888 bytes)
2021-12-08 10:39:21,150 [dispatcher-event-loop-5] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 2.0 in stage 86.0 (TID 262, localhost, executor driver, partition 2, PROCESS_LOCAL, 7888 bytes)
2021-12-08 10:39:21,150 [dispatcher-event-loop-5] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 3.0 in stage 86.0 (TID 263, localhost, executor driver, partition 3, PROCESS_LOCAL, 7888 bytes)
2021-12-08 10:39:21,150 [dispatcher-event-loop-5] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 4.0 in stage 86.0 (TID 264, localhost, executor driver, partition 4, PROCESS_LOCAL, 7888 bytes)
2021-12-08 10:39:21,150 [dispatcher-event-loop-5] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 5.0 in stage 86.0 (TID 265, localhost, executor driver, partition 5, PROCESS_LOCAL, 7888 bytes)
2021-12-08 10:39:21,150 [dispatcher-event-loop-5] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 6.0 in stage 86.0 (TID 266, localhost, executor driver, partition 6, PROCESS_LOCAL, 7888 bytes)
2021-12-08 10:39:21,150 [dispatcher-event-loop-5] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 7.0 in stage 86.0 (TID 267, localhost, executor driver, partition 7, PROCESS_LOCAL, 7888 bytes)
2021-12-08 10:39:21,151 [dispatcher-event-loop-5] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 8.0 in stage 86.0 (TID 268, localhost, executor driver, partition 8, PROCESS_LOCAL, 7888 bytes)
2021-12-08 10:39:21,151 [dispatcher-event-loop-5] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 9.0 in stage 86.0 (TID 269, localhost, executor driver, partition 9, PROCESS_LOCAL, 7888 bytes)
2021-12-08 10:39:21,151 [dispatcher-event-loop-5] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 10.0 in stage 86.0 (TID 270, localhost, executor driver, partition 10, PROCESS_LOCAL, 7888 bytes)
2021-12-08 10:39:21,151 [dispatcher-event-loop-5] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 11.0 in stage 86.0 (TID 271, localhost, executor driver, partition 11, PROCESS_LOCAL, 7888 bytes)
2021-12-08 10:39:21,151 [Executor task launch worker for task 265] INFO [org.apache.spark.executor.Executor] - Running task 5.0 in stage 86.0 (TID 265)
2021-12-08 10:39:21,151 [Executor task launch worker for task 260] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 86.0 (TID 260)
2021-12-08 10:39:21,151 [Executor task launch worker for task 266] INFO [org.apache.spark.executor.Executor] - Running task 6.0 in stage 86.0 (TID 266)
2021-12-08 10:39:21,151 [Executor task launch worker for task 264] INFO [org.apache.spark.executor.Executor] - Running task 4.0 in stage 86.0 (TID 264)
2021-12-08 10:39:21,151 [Executor task launch worker for task 261] INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 86.0 (TID 261)
2021-12-08 10:39:21,151 [Executor task launch worker for task 268] INFO [org.apache.spark.executor.Executor] - Running task 8.0 in stage 86.0 (TID 268)
2021-12-08 10:39:21,151 [Executor task launch worker for task 267] INFO [org.apache.spark.executor.Executor] - Running task 7.0 in stage 86.0 (TID 267)
2021-12-08 10:39:21,151 [Executor task launch worker for task 262] INFO [org.apache.spark.executor.Executor] - Running task 2.0 in stage 86.0 (TID 262)
2021-12-08 10:39:21,151 [Executor task launch worker for task 263] INFO [org.apache.spark.executor.Executor] - Running task 3.0 in stage 86.0 (TID 263)
2021-12-08 10:39:21,151 [Executor task launch worker for task 269] INFO [org.apache.spark.executor.Executor] - Running task 9.0 in stage 86.0 (TID 269)
2021-12-08 10:39:21,151 [Executor task launch worker for task 270] INFO [org.apache.spark.executor.Executor] - Running task 10.0 in stage 86.0 (TID 270)
2021-12-08 10:39:21,151 [Executor task launch worker for task 271] INFO [org.apache.spark.executor.Executor] - Running task 11.0 in stage 86.0 (TID 271)
2021-12-08 10:39:21,154 [Executor task launch worker for task 267] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_9_7 locally
2021-12-08 10:39:21,155 [Executor task launch worker for task 263] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_9_3 locally
2021-12-08 10:39:21,155 [Executor task launch worker for task 260] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_9_0 locally
2021-12-08 10:39:21,154 [Executor task launch worker for task 262] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_9_2 locally
2021-12-08 10:39:21,154 [Executor task launch worker for task 268] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_9_8 locally
2021-12-08 10:39:21,154 [Executor task launch worker for task 270] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_9_10 locally
2021-12-08 10:39:21,155 [Executor task launch worker for task 261] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_9_1 locally
2021-12-08 10:39:21,155 [Executor task launch worker for task 265] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_9_5 locally
2021-12-08 10:39:21,155 [Executor task launch worker for task 267] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 12 non-empty blocks out of 12 blocks
2021-12-08 10:39:21,155 [Executor task launch worker for task 263] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 12 non-empty blocks out of 12 blocks
2021-12-08 10:39:21,155 [Executor task launch worker for task 267] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-08 10:39:21,155 [Executor task launch worker for task 260] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 12 non-empty blocks out of 12 blocks
2021-12-08 10:39:21,155 [Executor task launch worker for task 260] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-08 10:39:21,155 [Executor task launch worker for task 270] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 12 non-empty blocks out of 12 blocks
2021-12-08 10:39:21,155 [Executor task launch worker for task 261] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 12 non-empty blocks out of 12 blocks
2021-12-08 10:39:21,155 [Executor task launch worker for task 271] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_9_11 locally
2021-12-08 10:39:21,155 [Executor task launch worker for task 261] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-08 10:39:21,155 [Executor task launch worker for task 270] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-08 10:39:21,155 [Executor task launch worker for task 269] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_9_9 locally
2021-12-08 10:39:21,155 [Executor task launch worker for task 263] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-08 10:39:21,155 [Executor task launch worker for task 268] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 12 non-empty blocks out of 12 blocks
2021-12-08 10:39:21,155 [Executor task launch worker for task 265] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 12 non-empty blocks out of 12 blocks
2021-12-08 10:39:21,156 [Executor task launch worker for task 268] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 1 ms
2021-12-08 10:39:21,156 [Executor task launch worker for task 262] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 12 non-empty blocks out of 12 blocks
2021-12-08 10:39:21,156 [Executor task launch worker for task 262] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 1 ms
2021-12-08 10:39:21,156 [Executor task launch worker for task 266] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_9_6 locally
2021-12-08 10:39:21,156 [Executor task launch worker for task 265] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 1 ms
2021-12-08 10:39:21,156 [Executor task launch worker for task 269] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 12 non-empty blocks out of 12 blocks
2021-12-08 10:39:21,156 [Executor task launch worker for task 271] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 12 non-empty blocks out of 12 blocks
2021-12-08 10:39:21,156 [Executor task launch worker for task 269] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-08 10:39:21,156 [Executor task launch worker for task 271] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-08 10:39:21,156 [Executor task launch worker for task 266] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 12 non-empty blocks out of 12 blocks
2021-12-08 10:39:21,156 [Executor task launch worker for task 266] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-08 10:39:21,156 [Executor task launch worker for task 264] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_9_4 locally
2021-12-08 10:39:21,156 [Executor task launch worker for task 264] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 12 non-empty blocks out of 12 blocks
2021-12-08 10:39:21,156 [Executor task launch worker for task 264] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-08 10:39:58,586 [Executor task launch worker for task 265] INFO [org.apache.spark.storage.memory.MemoryStore] - Block rdd_97_5 stored as values in memory (estimated size 11.1 MB, free 1738.6 MB)
2021-12-08 10:39:58,587 [dispatcher-event-loop-9] INFO [org.apache.spark.storage.BlockManagerInfo] - Added rdd_97_5 in memory on qb:55657 (size: 11.1 MB, free: 1741.5 MB)
2021-12-08 10:39:58,626 [Executor task launch worker for task 268] INFO [org.apache.spark.storage.memory.MemoryStore] - Block rdd_97_8 stored as values in memory (estimated size 11.1 MB, free 1727.5 MB)
2021-12-08 10:39:58,626 [dispatcher-event-loop-7] INFO [org.apache.spark.storage.BlockManagerInfo] - Added rdd_97_8 in memory on qb:55657 (size: 11.1 MB, free: 1730.3 MB)
2021-12-08 10:39:58,715 [Executor task launch worker for task 269] INFO [org.apache.spark.storage.memory.MemoryStore] - Block rdd_97_9 stored as values in memory (estimated size 11.1 MB, free 1716.4 MB)
2021-12-08 10:39:58,716 [dispatcher-event-loop-1] INFO [org.apache.spark.storage.BlockManagerInfo] - Added rdd_97_9 in memory on qb:55657 (size: 11.1 MB, free: 1719.2 MB)
2021-12-08 10:39:58,881 [Executor task launch worker for task 264] INFO [org.apache.spark.storage.memory.MemoryStore] - Block rdd_97_4 stored as values in memory (estimated size 11.1 MB, free 1705.3 MB)
2021-12-08 10:39:58,881 [dispatcher-event-loop-5] INFO [org.apache.spark.storage.BlockManagerInfo] - Added rdd_97_4 in memory on qb:55657 (size: 11.1 MB, free: 1708.1 MB)
2021-12-08 10:39:58,951 [Executor task launch worker for task 265] INFO [org.apache.spark.executor.Executor] - Finished task 5.0 in stage 86.0 (TID 265). 166054 bytes result sent to driver
2021-12-08 10:39:58,958 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 5.0 in stage 86.0 (TID 265) in 37808 ms on localhost (executor driver) (1/12)
2021-12-08 10:39:58,969 [Executor task launch worker for task 268] INFO [org.apache.spark.executor.Executor] - Finished task 8.0 in stage 86.0 (TID 268). 166054 bytes result sent to driver
2021-12-08 10:39:58,970 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 8.0 in stage 86.0 (TID 268) in 37820 ms on localhost (executor driver) (2/12)
2021-12-08 10:39:58,994 [Executor task launch worker for task 271] INFO [org.apache.spark.storage.memory.MemoryStore] - Block rdd_97_11 stored as values in memory (estimated size 11.1 MB, free 1694.2 MB)
2021-12-08 10:39:58,994 [dispatcher-event-loop-6] INFO [org.apache.spark.storage.BlockManagerInfo] - Added rdd_97_11 in memory on qb:55657 (size: 11.1 MB, free: 1697.0 MB)
2021-12-08 10:39:59,018 [Executor task launch worker for task 261] INFO [org.apache.spark.storage.memory.MemoryStore] - Block rdd_97_1 stored as values in memory (estimated size 11.1 MB, free 1683.1 MB)
2021-12-08 10:39:59,018 [dispatcher-event-loop-3] INFO [org.apache.spark.storage.BlockManagerInfo] - Added rdd_97_1 in memory on qb:55657 (size: 11.1 MB, free: 1685.9 MB)
2021-12-08 10:39:59,076 [Executor task launch worker for task 269] INFO [org.apache.spark.executor.Executor] - Finished task 9.0 in stage 86.0 (TID 269). 166054 bytes result sent to driver
2021-12-08 10:39:59,077 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 9.0 in stage 86.0 (TID 269) in 37926 ms on localhost (executor driver) (3/12)
2021-12-08 10:39:59,139 [Executor task launch worker for task 260] INFO [org.apache.spark.storage.memory.MemoryStore] - Block rdd_97_0 stored as values in memory (estimated size 11.1 MB, free 1672.0 MB)
2021-12-08 10:39:59,139 [dispatcher-event-loop-11] INFO [org.apache.spark.storage.BlockManagerInfo] - Added rdd_97_0 in memory on qb:55657 (size: 11.1 MB, free: 1674.8 MB)
2021-12-08 10:39:59,217 [Executor task launch worker for task 264] INFO [org.apache.spark.executor.Executor] - Finished task 4.0 in stage 86.0 (TID 264). 166054 bytes result sent to driver
2021-12-08 10:39:59,218 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 4.0 in stage 86.0 (TID 264) in 38068 ms on localhost (executor driver) (4/12)
2021-12-08 10:39:59,308 [Executor task launch worker for task 271] INFO [org.apache.spark.executor.Executor] - Finished task 11.0 in stage 86.0 (TID 271). 166097 bytes result sent to driver
2021-12-08 10:39:59,308 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 11.0 in stage 86.0 (TID 271) in 38157 ms on localhost (executor driver) (5/12)
2021-12-08 10:39:59,324 [Executor task launch worker for task 261] INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 86.0 (TID 261). 166054 bytes result sent to driver
2021-12-08 10:39:59,324 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 86.0 (TID 261) in 38174 ms on localhost (executor driver) (6/12)
2021-12-08 10:39:59,404 [Executor task launch worker for task 260] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 86.0 (TID 260). 166054 bytes result sent to driver
2021-12-08 10:39:59,404 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 86.0 (TID 260) in 38254 ms on localhost (executor driver) (7/12)
2021-12-08 10:40:01,160 [Executor task launch worker for task 262] INFO [org.apache.spark.storage.memory.MemoryStore] - Block rdd_97_2 stored as values in memory (estimated size 11.1 MB, free 1660.9 MB)
2021-12-08 10:40:01,160 [dispatcher-event-loop-1] INFO [org.apache.spark.storage.BlockManagerInfo] - Added rdd_97_2 in memory on qb:55657 (size: 11.1 MB, free: 1663.7 MB)
2021-12-08 10:40:01,230 [Executor task launch worker for task 270] INFO [org.apache.spark.storage.memory.MemoryStore] - Block rdd_97_10 stored as values in memory (estimated size 11.1 MB, free 1649.8 MB)
2021-12-08 10:40:01,230 [dispatcher-event-loop-5] INFO [org.apache.spark.storage.BlockManagerInfo] - Added rdd_97_10 in memory on qb:55657 (size: 11.1 MB, free: 1652.6 MB)
2021-12-08 10:40:01,288 [Executor task launch worker for task 267] INFO [org.apache.spark.storage.memory.MemoryStore] - Block rdd_97_7 stored as values in memory (estimated size 11.1 MB, free 1638.7 MB)
2021-12-08 10:40:01,289 [dispatcher-event-loop-2] INFO [org.apache.spark.storage.BlockManagerInfo] - Added rdd_97_7 in memory on qb:55657 (size: 11.1 MB, free: 1641.5 MB)
2021-12-08 10:40:01,405 [Executor task launch worker for task 262] INFO [org.apache.spark.executor.Executor] - Finished task 2.0 in stage 86.0 (TID 262). 166054 bytes result sent to driver
2021-12-08 10:40:01,405 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 2.0 in stage 86.0 (TID 262) in 40255 ms on localhost (executor driver) (8/12)
2021-12-08 10:40:01,406 [Executor task launch worker for task 263] INFO [org.apache.spark.storage.memory.MemoryStore] - Block rdd_97_3 stored as values in memory (estimated size 11.1 MB, free 1627.6 MB)
2021-12-08 10:40:01,406 [dispatcher-event-loop-6] INFO [org.apache.spark.storage.BlockManagerInfo] - Added rdd_97_3 in memory on qb:55657 (size: 11.1 MB, free: 1630.4 MB)
2021-12-08 10:40:01,428 [Executor task launch worker for task 270] INFO [org.apache.spark.executor.Executor] - Finished task 10.0 in stage 86.0 (TID 270). 166054 bytes result sent to driver
2021-12-08 10:40:01,428 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 10.0 in stage 86.0 (TID 270) in 40277 ms on localhost (executor driver) (9/12)
2021-12-08 10:40:01,478 [Executor task launch worker for task 267] INFO [org.apache.spark.executor.Executor] - Finished task 7.0 in stage 86.0 (TID 267). 166054 bytes result sent to driver
2021-12-08 10:40:01,478 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 7.0 in stage 86.0 (TID 267) in 40328 ms on localhost (executor driver) (10/12)
2021-12-08 10:40:01,577 [Executor task launch worker for task 263] INFO [org.apache.spark.executor.Executor] - Finished task 3.0 in stage 86.0 (TID 263). 166054 bytes result sent to driver
2021-12-08 10:40:01,577 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 3.0 in stage 86.0 (TID 263) in 40427 ms on localhost (executor driver) (11/12)
2021-12-08 10:40:01,593 [Executor task launch worker for task 266] INFO [org.apache.spark.storage.memory.MemoryStore] - Block rdd_97_6 stored as values in memory (estimated size 11.1 MB, free 1616.5 MB)
2021-12-08 10:40:01,594 [dispatcher-event-loop-9] INFO [org.apache.spark.storage.BlockManagerInfo] - Added rdd_97_6 in memory on qb:55657 (size: 11.1 MB, free: 1619.3 MB)
2021-12-08 10:40:01,764 [Executor task launch worker for task 266] INFO [org.apache.spark.executor.Executor] - Finished task 6.0 in stage 86.0 (TID 266). 166054 bytes result sent to driver
2021-12-08 10:40:01,765 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 6.0 in stage 86.0 (TID 266) in 40615 ms on localhost (executor driver) (12/12)
2021-12-08 10:40:01,765 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 86.0, whose tasks have all completed, from pool 
2021-12-08 10:40:01,765 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 86 (aggregate at ALS.scala:1711) finished in 40.624 s
2021-12-08 10:40:01,765 [main] INFO [org.apache.spark.scheduler.DAGScheduler] - Job 12 finished: aggregate at ALS.scala:1711, took 41.495394 s
2021-12-08 10:40:01,780 [main] INFO [org.apache.spark.rdd.MapPartitionsRDD] - Removing RDD 87 from persistence list
2021-12-08 10:40:01,780 [block-manager-slave-async-thread-pool-2] INFO [org.apache.spark.storage.BlockManager] - Removing RDD 87
2021-12-08 10:40:01,787 [main] INFO [org.apache.spark.SparkContext] - Starting job: aggregate at ALS.scala:1711
2021-12-08 10:40:01,788 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 102 (flatMap at ALS.scala:1653)
2021-12-08 10:40:01,788 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 13 (aggregate at ALS.scala:1711) with 12 output partitions
2021-12-08 10:40:01,788 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 100 (aggregate at ALS.scala:1711)
2021-12-08 10:40:01,788 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 99, ShuffleMapStage 88)
2021-12-08 10:40:01,788 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List(ShuffleMapStage 99)
2021-12-08 10:40:01,788 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ShuffleMapStage 99 (MapPartitionsRDD[102] at flatMap at ALS.scala:1653), which has no missing parents
2021-12-08 10:40:01,791 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_26 stored as values in memory (estimated size 1299.8 KB, free 1663.1 MB)
2021-12-08 10:40:01,794 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_26_piece0 stored as bytes in memory (estimated size 1266.9 KB, free 1661.8 MB)
2021-12-08 10:40:01,794 [dispatcher-event-loop-6] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_26_piece0 in memory on qb:55657 (size: 1266.9 KB, free: 1665.9 MB)
2021-12-08 10:40:01,794 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 26 from broadcast at DAGScheduler.scala:1039
2021-12-08 10:40:01,794 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 12 missing tasks from ShuffleMapStage 99 (MapPartitionsRDD[102] at flatMap at ALS.scala:1653) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11))
2021-12-08 10:40:01,794 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 99.0 with 12 tasks
2021-12-08 10:40:01,795 [dispatcher-event-loop-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 99.0 (TID 272, localhost, executor driver, partition 0, PROCESS_LOCAL, 7928 bytes)
2021-12-08 10:40:01,795 [dispatcher-event-loop-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 99.0 (TID 273, localhost, executor driver, partition 1, PROCESS_LOCAL, 7928 bytes)
2021-12-08 10:40:01,795 [dispatcher-event-loop-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 2.0 in stage 99.0 (TID 274, localhost, executor driver, partition 2, PROCESS_LOCAL, 7928 bytes)
2021-12-08 10:40:01,795 [dispatcher-event-loop-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 3.0 in stage 99.0 (TID 275, localhost, executor driver, partition 3, PROCESS_LOCAL, 7928 bytes)
2021-12-08 10:40:01,795 [dispatcher-event-loop-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 4.0 in stage 99.0 (TID 276, localhost, executor driver, partition 4, PROCESS_LOCAL, 7928 bytes)
2021-12-08 10:40:01,795 [dispatcher-event-loop-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 5.0 in stage 99.0 (TID 277, localhost, executor driver, partition 5, PROCESS_LOCAL, 7928 bytes)
2021-12-08 10:40:01,795 [dispatcher-event-loop-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 6.0 in stage 99.0 (TID 278, localhost, executor driver, partition 6, PROCESS_LOCAL, 7928 bytes)
2021-12-08 10:40:01,795 [dispatcher-event-loop-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 7.0 in stage 99.0 (TID 279, localhost, executor driver, partition 7, PROCESS_LOCAL, 7928 bytes)
2021-12-08 10:40:01,795 [dispatcher-event-loop-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 8.0 in stage 99.0 (TID 280, localhost, executor driver, partition 8, PROCESS_LOCAL, 7928 bytes)
2021-12-08 10:40:01,795 [dispatcher-event-loop-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 9.0 in stage 99.0 (TID 281, localhost, executor driver, partition 9, PROCESS_LOCAL, 7928 bytes)
2021-12-08 10:40:01,795 [dispatcher-event-loop-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 10.0 in stage 99.0 (TID 282, localhost, executor driver, partition 10, PROCESS_LOCAL, 7928 bytes)
2021-12-08 10:40:01,795 [dispatcher-event-loop-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 11.0 in stage 99.0 (TID 283, localhost, executor driver, partition 11, PROCESS_LOCAL, 7928 bytes)
2021-12-08 10:40:01,795 [Executor task launch worker for task 275] INFO [org.apache.spark.executor.Executor] - Running task 3.0 in stage 99.0 (TID 275)
2021-12-08 10:40:01,795 [Executor task launch worker for task 279] INFO [org.apache.spark.executor.Executor] - Running task 7.0 in stage 99.0 (TID 279)
2021-12-08 10:40:01,795 [Executor task launch worker for task 273] INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 99.0 (TID 273)
2021-12-08 10:40:01,795 [Executor task launch worker for task 283] INFO [org.apache.spark.executor.Executor] - Running task 11.0 in stage 99.0 (TID 283)
2021-12-08 10:40:01,795 [Executor task launch worker for task 272] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 99.0 (TID 272)
2021-12-08 10:40:01,795 [Executor task launch worker for task 282] INFO [org.apache.spark.executor.Executor] - Running task 10.0 in stage 99.0 (TID 282)
2021-12-08 10:40:01,795 [Executor task launch worker for task 274] INFO [org.apache.spark.executor.Executor] - Running task 2.0 in stage 99.0 (TID 274)
2021-12-08 10:40:01,795 [Executor task launch worker for task 277] INFO [org.apache.spark.executor.Executor] - Running task 5.0 in stage 99.0 (TID 277)
2021-12-08 10:40:01,795 [Executor task launch worker for task 280] INFO [org.apache.spark.executor.Executor] - Running task 8.0 in stage 99.0 (TID 280)
2021-12-08 10:40:01,795 [Executor task launch worker for task 281] INFO [org.apache.spark.executor.Executor] - Running task 9.0 in stage 99.0 (TID 281)
2021-12-08 10:40:01,795 [Executor task launch worker for task 278] INFO [org.apache.spark.executor.Executor] - Running task 6.0 in stage 99.0 (TID 278)
2021-12-08 10:40:01,795 [Executor task launch worker for task 276] INFO [org.apache.spark.executor.Executor] - Running task 4.0 in stage 99.0 (TID 276)
2021-12-08 10:40:01,798 [Executor task launch worker for task 278] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_10_6 locally
2021-12-08 10:40:01,798 [Executor task launch worker for task 280] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_10_8 locally
2021-12-08 10:40:01,798 [Executor task launch worker for task 273] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_10_1 locally
2021-12-08 10:40:01,798 [Executor task launch worker for task 283] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_10_11 locally
2021-12-08 10:40:01,798 [Executor task launch worker for task 279] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_10_7 locally
2021-12-08 10:40:01,798 [Executor task launch worker for task 281] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_10_9 locally
2021-12-08 10:40:01,798 [Executor task launch worker for task 277] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_10_5 locally
2021-12-08 10:40:01,798 [Executor task launch worker for task 276] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_10_4 locally
2021-12-08 10:40:01,798 [Executor task launch worker for task 273] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_97_1 locally
2021-12-08 10:40:01,799 [Executor task launch worker for task 272] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_10_0 locally
2021-12-08 10:40:01,799 [Executor task launch worker for task 274] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_10_2 locally
2021-12-08 10:40:01,799 [Executor task launch worker for task 276] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_97_4 locally
2021-12-08 10:40:01,798 [Executor task launch worker for task 275] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_10_3 locally
2021-12-08 10:40:01,799 [Executor task launch worker for task 280] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_97_8 locally
2021-12-08 10:40:01,798 [Executor task launch worker for task 277] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_97_5 locally
2021-12-08 10:40:01,798 [Executor task launch worker for task 283] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_97_11 locally
2021-12-08 10:40:01,798 [Executor task launch worker for task 281] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_97_9 locally
2021-12-08 10:40:01,799 [Executor task launch worker for task 279] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_97_7 locally
2021-12-08 10:40:01,799 [Executor task launch worker for task 274] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_97_2 locally
2021-12-08 10:40:01,799 [Executor task launch worker for task 282] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_10_10 locally
2021-12-08 10:40:01,799 [Executor task launch worker for task 272] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_97_0 locally
2021-12-08 10:40:01,799 [Executor task launch worker for task 275] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_97_3 locally
2021-12-08 10:40:01,799 [Executor task launch worker for task 282] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_97_10 locally
2021-12-08 10:40:01,799 [Executor task launch worker for task 278] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_97_6 locally
2021-12-08 10:40:03,825 [Executor task launch worker for task 283] INFO [org.apache.spark.executor.Executor] - Finished task 11.0 in stage 99.0 (TID 283). 1042 bytes result sent to driver
2021-12-08 10:40:03,825 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 11.0 in stage 99.0 (TID 283) in 2030 ms on localhost (executor driver) (1/12)
2021-12-08 10:40:03,826 [Executor task launch worker for task 275] INFO [org.apache.spark.executor.Executor] - Finished task 3.0 in stage 99.0 (TID 275). 1042 bytes result sent to driver
2021-12-08 10:40:03,826 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 3.0 in stage 99.0 (TID 275) in 2031 ms on localhost (executor driver) (2/12)
2021-12-08 10:40:03,885 [Executor task launch worker for task 277] INFO [org.apache.spark.executor.Executor] - Finished task 5.0 in stage 99.0 (TID 277). 1042 bytes result sent to driver
2021-12-08 10:40:03,885 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 5.0 in stage 99.0 (TID 277) in 2090 ms on localhost (executor driver) (3/12)
2021-12-08 10:40:03,886 [Executor task launch worker for task 274] INFO [org.apache.spark.executor.Executor] - Finished task 2.0 in stage 99.0 (TID 274). 1042 bytes result sent to driver
2021-12-08 10:40:03,887 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 2.0 in stage 99.0 (TID 274) in 2092 ms on localhost (executor driver) (4/12)
2021-12-08 10:40:03,932 [Executor task launch worker for task 273] INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 99.0 (TID 273). 1042 bytes result sent to driver
2021-12-08 10:40:03,933 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 99.0 (TID 273) in 2138 ms on localhost (executor driver) (5/12)
2021-12-08 10:40:03,955 [Executor task launch worker for task 276] INFO [org.apache.spark.executor.Executor] - Finished task 4.0 in stage 99.0 (TID 276). 1042 bytes result sent to driver
2021-12-08 10:40:03,955 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 4.0 in stage 99.0 (TID 276) in 2160 ms on localhost (executor driver) (6/12)
2021-12-08 10:40:03,970 [Executor task launch worker for task 272] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 99.0 (TID 272). 1042 bytes result sent to driver
2021-12-08 10:40:03,971 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 99.0 (TID 272) in 2177 ms on localhost (executor driver) (7/12)
2021-12-08 10:40:04,206 [Executor task launch worker for task 278] INFO [org.apache.spark.executor.Executor] - Finished task 6.0 in stage 99.0 (TID 278). 1042 bytes result sent to driver
2021-12-08 10:40:04,206 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 6.0 in stage 99.0 (TID 278) in 2411 ms on localhost (executor driver) (8/12)
2021-12-08 10:40:04,290 [Executor task launch worker for task 282] INFO [org.apache.spark.executor.Executor] - Finished task 10.0 in stage 99.0 (TID 282). 1042 bytes result sent to driver
2021-12-08 10:40:04,291 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 10.0 in stage 99.0 (TID 282) in 2496 ms on localhost (executor driver) (9/12)
2021-12-08 10:40:04,417 [Executor task launch worker for task 281] INFO [org.apache.spark.executor.Executor] - Finished task 9.0 in stage 99.0 (TID 281). 1042 bytes result sent to driver
2021-12-08 10:40:04,417 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 9.0 in stage 99.0 (TID 281) in 2622 ms on localhost (executor driver) (10/12)
2021-12-08 10:40:04,418 [Executor task launch worker for task 280] INFO [org.apache.spark.executor.Executor] - Finished task 8.0 in stage 99.0 (TID 280). 1042 bytes result sent to driver
2021-12-08 10:40:04,419 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 8.0 in stage 99.0 (TID 280) in 2624 ms on localhost (executor driver) (11/12)
2021-12-08 10:40:04,420 [Executor task launch worker for task 279] INFO [org.apache.spark.executor.Executor] - Finished task 7.0 in stage 99.0 (TID 279). 1042 bytes result sent to driver
2021-12-08 10:40:04,421 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 7.0 in stage 99.0 (TID 279) in 2626 ms on localhost (executor driver) (12/12)
2021-12-08 10:40:04,421 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 99.0, whose tasks have all completed, from pool 
2021-12-08 10:40:04,421 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ShuffleMapStage 99 (flatMap at ALS.scala:1653) finished in 2.633 s
2021-12-08 10:40:04,421 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - looking for newly runnable stages
2021-12-08 10:40:04,421 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - running: Set()
2021-12-08 10:40:04,421 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - waiting: Set(ResultStage 100)
2021-12-08 10:40:04,421 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - failed: Set()
2021-12-08 10:40:04,421 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 100 (MapPartitionsRDD[108] at values at ALS.scala:1711), which has no missing parents
2021-12-08 10:40:04,424 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_27 stored as values in memory (estimated size 1621.3 KB, free 1660.2 MB)
2021-12-08 10:40:04,426 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_27_piece0 stored as bytes in memory (estimated size 1425.7 KB, free 1658.8 MB)
2021-12-08 10:40:04,426 [dispatcher-event-loop-7] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_27_piece0 in memory on qb:55657 (size: 1425.7 KB, free: 1664.5 MB)
2021-12-08 10:40:04,426 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 27 from broadcast at DAGScheduler.scala:1039
2021-12-08 10:40:04,426 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 12 missing tasks from ResultStage 100 (MapPartitionsRDD[108] at values at ALS.scala:1711) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11))
2021-12-08 10:40:04,426 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 100.0 with 12 tasks
2021-12-08 10:40:04,427 [dispatcher-event-loop-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 100.0 (TID 284, localhost, executor driver, partition 0, PROCESS_LOCAL, 7888 bytes)
2021-12-08 10:40:04,427 [dispatcher-event-loop-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 100.0 (TID 285, localhost, executor driver, partition 1, PROCESS_LOCAL, 7888 bytes)
2021-12-08 10:40:04,427 [dispatcher-event-loop-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 2.0 in stage 100.0 (TID 286, localhost, executor driver, partition 2, PROCESS_LOCAL, 7888 bytes)
2021-12-08 10:40:04,427 [dispatcher-event-loop-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 3.0 in stage 100.0 (TID 287, localhost, executor driver, partition 3, PROCESS_LOCAL, 7888 bytes)
2021-12-08 10:40:04,427 [dispatcher-event-loop-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 4.0 in stage 100.0 (TID 288, localhost, executor driver, partition 4, PROCESS_LOCAL, 7888 bytes)
2021-12-08 10:40:04,427 [dispatcher-event-loop-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 5.0 in stage 100.0 (TID 289, localhost, executor driver, partition 5, PROCESS_LOCAL, 7888 bytes)
2021-12-08 10:40:04,427 [dispatcher-event-loop-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 6.0 in stage 100.0 (TID 290, localhost, executor driver, partition 6, PROCESS_LOCAL, 7888 bytes)
2021-12-08 10:40:04,427 [dispatcher-event-loop-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 7.0 in stage 100.0 (TID 291, localhost, executor driver, partition 7, PROCESS_LOCAL, 7888 bytes)
2021-12-08 10:40:04,427 [dispatcher-event-loop-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 8.0 in stage 100.0 (TID 292, localhost, executor driver, partition 8, PROCESS_LOCAL, 7888 bytes)
2021-12-08 10:40:04,427 [dispatcher-event-loop-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 9.0 in stage 100.0 (TID 293, localhost, executor driver, partition 9, PROCESS_LOCAL, 7888 bytes)
2021-12-08 10:40:04,427 [dispatcher-event-loop-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 10.0 in stage 100.0 (TID 294, localhost, executor driver, partition 10, PROCESS_LOCAL, 7888 bytes)
2021-12-08 10:40:04,427 [dispatcher-event-loop-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 11.0 in stage 100.0 (TID 295, localhost, executor driver, partition 11, PROCESS_LOCAL, 7888 bytes)
2021-12-08 10:40:04,427 [Executor task launch worker for task 288] INFO [org.apache.spark.executor.Executor] - Running task 4.0 in stage 100.0 (TID 288)
2021-12-08 10:40:04,427 [Executor task launch worker for task 293] INFO [org.apache.spark.executor.Executor] - Running task 9.0 in stage 100.0 (TID 293)
2021-12-08 10:40:04,427 [Executor task launch worker for task 294] INFO [org.apache.spark.executor.Executor] - Running task 10.0 in stage 100.0 (TID 294)
2021-12-08 10:40:04,427 [Executor task launch worker for task 295] INFO [org.apache.spark.executor.Executor] - Running task 11.0 in stage 100.0 (TID 295)
2021-12-08 10:40:04,427 [Executor task launch worker for task 284] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 100.0 (TID 284)
2021-12-08 10:40:04,427 [Executor task launch worker for task 292] INFO [org.apache.spark.executor.Executor] - Running task 8.0 in stage 100.0 (TID 292)
2021-12-08 10:40:04,427 [Executor task launch worker for task 287] INFO [org.apache.spark.executor.Executor] - Running task 3.0 in stage 100.0 (TID 287)
2021-12-08 10:40:04,427 [Executor task launch worker for task 285] INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 100.0 (TID 285)
2021-12-08 10:40:04,427 [Executor task launch worker for task 286] INFO [org.apache.spark.executor.Executor] - Running task 2.0 in stage 100.0 (TID 286)
2021-12-08 10:40:04,427 [Executor task launch worker for task 291] INFO [org.apache.spark.executor.Executor] - Running task 7.0 in stage 100.0 (TID 291)
2021-12-08 10:40:04,427 [Executor task launch worker for task 289] INFO [org.apache.spark.executor.Executor] - Running task 5.0 in stage 100.0 (TID 289)
2021-12-08 10:40:04,427 [Executor task launch worker for task 290] INFO [org.apache.spark.executor.Executor] - Running task 6.0 in stage 100.0 (TID 290)
2021-12-08 10:40:04,431 [Executor task launch worker for task 289] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_14_5 locally
2021-12-08 10:40:04,432 [Executor task launch worker for task 292] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_14_8 locally
2021-12-08 10:40:04,431 [Executor task launch worker for task 291] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_14_7 locally
2021-12-08 10:40:04,431 [Executor task launch worker for task 284] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_14_0 locally
2021-12-08 10:40:04,431 [Executor task launch worker for task 290] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_14_6 locally
2021-12-08 10:40:04,431 [Executor task launch worker for task 288] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_14_4 locally
2021-12-08 10:40:04,431 [Executor task launch worker for task 293] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_14_9 locally
2021-12-08 10:40:04,432 [Executor task launch worker for task 295] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_14_11 locally
2021-12-08 10:40:04,432 [Executor task launch worker for task 286] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_14_2 locally
2021-12-08 10:40:04,432 [Executor task launch worker for task 295] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 12 non-empty blocks out of 12 blocks
2021-12-08 10:40:04,432 [Executor task launch worker for task 295] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-08 10:40:04,432 [Executor task launch worker for task 285] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_14_1 locally
2021-12-08 10:40:04,432 [Executor task launch worker for task 291] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 12 non-empty blocks out of 12 blocks
2021-12-08 10:40:04,432 [Executor task launch worker for task 291] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-08 10:40:04,432 [Executor task launch worker for task 293] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 12 non-empty blocks out of 12 blocks
2021-12-08 10:40:04,432 [Executor task launch worker for task 290] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 12 non-empty blocks out of 12 blocks
2021-12-08 10:40:04,432 [Executor task launch worker for task 290] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-08 10:40:04,432 [Executor task launch worker for task 293] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-08 10:40:04,432 [Executor task launch worker for task 288] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 12 non-empty blocks out of 12 blocks
2021-12-08 10:40:04,432 [Executor task launch worker for task 284] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 12 non-empty blocks out of 12 blocks
2021-12-08 10:40:04,432 [Executor task launch worker for task 285] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 12 non-empty blocks out of 12 blocks
2021-12-08 10:40:04,432 [Executor task launch worker for task 284] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-08 10:40:04,432 [Executor task launch worker for task 285] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-08 10:40:04,432 [Executor task launch worker for task 292] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 12 non-empty blocks out of 12 blocks
2021-12-08 10:40:04,432 [Executor task launch worker for task 286] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 12 non-empty blocks out of 12 blocks
2021-12-08 10:40:04,432 [Executor task launch worker for task 294] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_14_10 locally
2021-12-08 10:40:04,432 [Executor task launch worker for task 286] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-08 10:40:04,432 [Executor task launch worker for task 292] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-08 10:40:04,432 [Executor task launch worker for task 288] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-08 10:40:04,433 [Executor task launch worker for task 289] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 12 non-empty blocks out of 12 blocks
2021-12-08 10:40:04,433 [Executor task launch worker for task 289] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 1 ms
2021-12-08 10:40:04,433 [Executor task launch worker for task 294] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 12 non-empty blocks out of 12 blocks
2021-12-08 10:40:04,433 [Executor task launch worker for task 294] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-08 10:40:04,433 [Executor task launch worker for task 287] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_14_3 locally
2021-12-08 10:40:04,433 [Executor task launch worker for task 287] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 12 non-empty blocks out of 12 blocks
2021-12-08 10:40:04,433 [Executor task launch worker for task 287] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-08 10:40:05,156 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 612
2021-12-08 10:40:05,156 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 622
2021-12-08 10:40:05,156 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 580
2021-12-08 10:40:05,156 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 604
2021-12-08 10:40:05,156 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 596
2021-12-08 10:40:05,156 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 615
2021-12-08 10:40:05,156 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 623
2021-12-08 10:40:05,157 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 586
2021-12-08 10:40:05,157 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 575
2021-12-08 10:40:05,157 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 617
2021-12-08 10:40:05,157 [dispatcher-event-loop-6] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_24_piece0 on qb:55657 in memory (size: 1109.2 KB, free: 1665.6 MB)
2021-12-08 10:40:05,158 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 599
2021-12-08 10:40:05,158 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 593
2021-12-08 10:40:05,158 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 600
2021-12-08 10:40:05,158 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 577
2021-12-08 10:40:05,158 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 587
2021-12-08 10:40:05,158 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 589
2021-12-08 10:40:05,158 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 609
2021-12-08 10:40:05,158 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 603
2021-12-08 10:40:05,158 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 607
2021-12-08 10:40:05,158 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 613
2021-12-08 10:40:05,158 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 616
2021-12-08 10:40:05,159 [dispatcher-event-loop-3] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_25_piece0 on qb:55657 in memory (size: 1268.0 KB, free: 1666.9 MB)
2021-12-08 10:40:05,159 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 611
2021-12-08 10:40:05,159 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 621
2021-12-08 10:40:05,159 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 606
2021-12-08 10:40:05,159 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 602
2021-12-08 10:40:05,159 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 591
2021-12-08 10:40:05,159 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 583
2021-12-08 10:40:05,159 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 619
2021-12-08 10:40:05,159 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 610
2021-12-08 10:40:05,159 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 594
2021-12-08 10:40:05,159 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 588
2021-12-08 10:40:05,159 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 620
2021-12-08 10:40:05,159 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 624
2021-12-08 10:40:05,159 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 578
2021-12-08 10:40:05,159 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 592
2021-12-08 10:40:05,159 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 582
2021-12-08 10:40:05,159 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 598
2021-12-08 10:40:05,159 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 584
2021-12-08 10:40:05,159 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 585
2021-12-08 10:40:05,159 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 605
2021-12-08 10:40:05,159 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 579
2021-12-08 10:40:05,159 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 601
2021-12-08 10:40:05,159 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 595
2021-12-08 10:40:05,159 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 614
2021-12-08 10:40:05,159 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 608
2021-12-08 10:40:05,161 [dispatcher-event-loop-11] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_26_piece0 on qb:55657 in memory (size: 1266.9 KB, free: 1668.1 MB)
2021-12-08 10:40:05,161 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 597
2021-12-08 10:40:05,161 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 618
2021-12-08 10:40:05,161 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 581
2021-12-08 10:40:05,161 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 590
2021-12-08 10:40:05,161 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 576
2021-12-08 10:40:25,899 [Executor task launch worker for task 285] INFO [org.apache.spark.storage.memory.MemoryStore] - Block rdd_107_1 stored as values in memory (estimated size 4.0 MB, free 1662.2 MB)
2021-12-08 10:40:25,900 [dispatcher-event-loop-2] INFO [org.apache.spark.storage.BlockManagerInfo] - Added rdd_107_1 in memory on qb:55657 (size: 4.0 MB, free: 1664.1 MB)
2021-12-08 10:40:26,023 [Executor task launch worker for task 285] INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 100.0 (TID 285). 166097 bytes result sent to driver
2021-12-08 10:40:26,024 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 100.0 (TID 285) in 21597 ms on localhost (executor driver) (1/12)
2021-12-08 10:40:26,558 [Executor task launch worker for task 284] INFO [org.apache.spark.storage.memory.MemoryStore] - Block rdd_107_0 stored as values in memory (estimated size 4.0 MB, free 1658.2 MB)
2021-12-08 10:40:26,559 [dispatcher-event-loop-5] INFO [org.apache.spark.storage.BlockManagerInfo] - Added rdd_107_0 in memory on qb:55657 (size: 4.0 MB, free: 1660.1 MB)
2021-12-08 10:40:26,580 [Executor task launch worker for task 288] INFO [org.apache.spark.storage.memory.MemoryStore] - Block rdd_107_4 stored as values in memory (estimated size 4.0 MB, free 1654.2 MB)
2021-12-08 10:40:26,581 [dispatcher-event-loop-8] INFO [org.apache.spark.storage.BlockManagerInfo] - Added rdd_107_4 in memory on qb:55657 (size: 4.0 MB, free: 1656.1 MB)
2021-12-08 10:40:26,594 [Executor task launch worker for task 295] INFO [org.apache.spark.storage.memory.MemoryStore] - Block rdd_107_11 stored as values in memory (estimated size 4.0 MB, free 1650.3 MB)
2021-12-08 10:40:26,594 [dispatcher-event-loop-3] INFO [org.apache.spark.storage.BlockManagerInfo] - Added rdd_107_11 in memory on qb:55657 (size: 4.0 MB, free: 1652.1 MB)
2021-12-08 10:40:26,666 [Executor task launch worker for task 289] INFO [org.apache.spark.storage.memory.MemoryStore] - Block rdd_107_5 stored as values in memory (estimated size 4.0 MB, free 1646.3 MB)
2021-12-08 10:40:26,666 [dispatcher-event-loop-4] INFO [org.apache.spark.storage.BlockManagerInfo] - Added rdd_107_5 in memory on qb:55657 (size: 4.0 MB, free: 1648.2 MB)
2021-12-08 10:40:26,684 [Executor task launch worker for task 284] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 100.0 (TID 284). 166097 bytes result sent to driver
2021-12-08 10:40:26,684 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 100.0 (TID 284) in 22257 ms on localhost (executor driver) (2/12)
2021-12-08 10:40:26,705 [Executor task launch worker for task 288] INFO [org.apache.spark.executor.Executor] - Finished task 4.0 in stage 100.0 (TID 288). 166097 bytes result sent to driver
2021-12-08 10:40:26,705 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 4.0 in stage 100.0 (TID 288) in 22278 ms on localhost (executor driver) (3/12)
2021-12-08 10:40:26,711 [Executor task launch worker for task 295] INFO [org.apache.spark.executor.Executor] - Finished task 11.0 in stage 100.0 (TID 295). 166097 bytes result sent to driver
2021-12-08 10:40:26,712 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 11.0 in stage 100.0 (TID 295) in 22285 ms on localhost (executor driver) (4/12)
2021-12-08 10:40:26,770 [Executor task launch worker for task 289] INFO [org.apache.spark.executor.Executor] - Finished task 5.0 in stage 100.0 (TID 289). 166054 bytes result sent to driver
2021-12-08 10:40:26,771 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 5.0 in stage 100.0 (TID 289) in 22344 ms on localhost (executor driver) (5/12)
2021-12-08 10:40:27,893 [Executor task launch worker for task 294] INFO [org.apache.spark.storage.memory.MemoryStore] - Block rdd_107_10 stored as values in memory (estimated size 4.0 MB, free 1642.3 MB)
2021-12-08 10:40:27,893 [dispatcher-event-loop-0] INFO [org.apache.spark.storage.BlockManagerInfo] - Added rdd_107_10 in memory on qb:55657 (size: 4.0 MB, free: 1644.2 MB)
2021-12-08 10:40:27,926 [Executor task launch worker for task 292] INFO [org.apache.spark.storage.memory.MemoryStore] - Block rdd_107_8 stored as values in memory (estimated size 4.0 MB, free 1638.3 MB)
2021-12-08 10:40:27,926 [dispatcher-event-loop-1] INFO [org.apache.spark.storage.BlockManagerInfo] - Added rdd_107_8 in memory on qb:55657 (size: 4.0 MB, free: 1640.2 MB)
2021-12-08 10:40:27,939 [Executor task launch worker for task 293] INFO [org.apache.spark.storage.memory.MemoryStore] - Block rdd_107_9 stored as values in memory (estimated size 4.0 MB, free 1634.3 MB)
2021-12-08 10:40:27,940 [dispatcher-event-loop-2] INFO [org.apache.spark.storage.BlockManagerInfo] - Added rdd_107_9 in memory on qb:55657 (size: 4.0 MB, free: 1636.2 MB)
2021-12-08 10:40:27,952 [Executor task launch worker for task 291] INFO [org.apache.spark.storage.memory.MemoryStore] - Block rdd_107_7 stored as values in memory (estimated size 4.0 MB, free 1630.3 MB)
2021-12-08 10:40:27,952 [dispatcher-event-loop-6] INFO [org.apache.spark.storage.BlockManagerInfo] - Added rdd_107_7 in memory on qb:55657 (size: 4.0 MB, free: 1632.2 MB)
2021-12-08 10:40:27,969 [Executor task launch worker for task 294] INFO [org.apache.spark.executor.Executor] - Finished task 10.0 in stage 100.0 (TID 294). 166097 bytes result sent to driver
2021-12-08 10:40:27,969 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 10.0 in stage 100.0 (TID 294) in 23542 ms on localhost (executor driver) (6/12)
2021-12-08 10:40:28,004 [Executor task launch worker for task 287] INFO [org.apache.spark.storage.memory.MemoryStore] - Block rdd_107_3 stored as values in memory (estimated size 4.0 MB, free 1626.3 MB)
2021-12-08 10:40:28,005 [dispatcher-event-loop-8] INFO [org.apache.spark.storage.BlockManagerInfo] - Added rdd_107_3 in memory on qb:55657 (size: 4.0 MB, free: 1628.2 MB)
2021-12-08 10:40:28,021 [Executor task launch worker for task 292] INFO [org.apache.spark.executor.Executor] - Finished task 8.0 in stage 100.0 (TID 292). 166054 bytes result sent to driver
2021-12-08 10:40:28,021 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 8.0 in stage 100.0 (TID 292) in 23594 ms on localhost (executor driver) (7/12)
2021-12-08 10:40:28,029 [Executor task launch worker for task 293] INFO [org.apache.spark.executor.Executor] - Finished task 9.0 in stage 100.0 (TID 293). 166097 bytes result sent to driver
2021-12-08 10:40:28,029 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 9.0 in stage 100.0 (TID 293) in 23602 ms on localhost (executor driver) (8/12)
2021-12-08 10:40:28,032 [Executor task launch worker for task 291] INFO [org.apache.spark.executor.Executor] - Finished task 7.0 in stage 100.0 (TID 291). 166054 bytes result sent to driver
2021-12-08 10:40:28,032 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 7.0 in stage 100.0 (TID 291) in 23605 ms on localhost (executor driver) (9/12)
2021-12-08 10:40:28,081 [Executor task launch worker for task 287] INFO [org.apache.spark.executor.Executor] - Finished task 3.0 in stage 100.0 (TID 287). 166054 bytes result sent to driver
2021-12-08 10:40:28,082 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 3.0 in stage 100.0 (TID 287) in 23655 ms on localhost (executor driver) (10/12)
2021-12-08 10:40:28,459 [Executor task launch worker for task 286] INFO [org.apache.spark.storage.memory.MemoryStore] - Block rdd_107_2 stored as values in memory (estimated size 4.0 MB, free 1622.3 MB)
2021-12-08 10:40:28,459 [dispatcher-event-loop-7] INFO [org.apache.spark.storage.BlockManagerInfo] - Added rdd_107_2 in memory on qb:55657 (size: 4.0 MB, free: 1624.2 MB)
2021-12-08 10:40:28,523 [Executor task launch worker for task 286] INFO [org.apache.spark.executor.Executor] - Finished task 2.0 in stage 100.0 (TID 286). 166054 bytes result sent to driver
2021-12-08 10:40:28,523 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 2.0 in stage 100.0 (TID 286) in 24096 ms on localhost (executor driver) (11/12)
2021-12-08 10:40:29,092 [Executor task launch worker for task 290] INFO [org.apache.spark.storage.memory.MemoryStore] - Block rdd_107_6 stored as values in memory (estimated size 4.0 MB, free 1618.3 MB)
2021-12-08 10:40:29,092 [dispatcher-event-loop-2] INFO [org.apache.spark.storage.BlockManagerInfo] - Added rdd_107_6 in memory on qb:55657 (size: 4.0 MB, free: 1620.2 MB)
2021-12-08 10:40:29,155 [Executor task launch worker for task 290] INFO [org.apache.spark.executor.Executor] - Finished task 6.0 in stage 100.0 (TID 290). 166054 bytes result sent to driver
2021-12-08 10:40:29,155 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 6.0 in stage 100.0 (TID 290) in 24728 ms on localhost (executor driver) (12/12)
2021-12-08 10:40:29,155 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 100.0, whose tasks have all completed, from pool 
2021-12-08 10:40:29,156 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 100 (aggregate at ALS.scala:1711) finished in 24.735 s
2021-12-08 10:40:29,156 [main] INFO [org.apache.spark.scheduler.DAGScheduler] - Job 13 finished: aggregate at ALS.scala:1711, took 27.369469 s
2021-12-08 10:40:29,171 [main] INFO [org.apache.spark.rdd.MapPartitionsRDD] - Removing RDD 97 from persistence list
2021-12-08 10:40:29,172 [block-manager-slave-async-thread-pool-1] INFO [org.apache.spark.storage.BlockManager] - Removing RDD 97
2021-12-08 10:40:29,178 [main] INFO [org.apache.spark.SparkContext] - Starting job: aggregate at ALS.scala:1711
2021-12-08 10:40:29,179 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 112 (flatMap at ALS.scala:1653)
2021-12-08 10:40:29,179 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 14 (aggregate at ALS.scala:1711) with 12 output partitions
2021-12-08 10:40:29,179 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 115 (aggregate at ALS.scala:1711)
2021-12-08 10:40:29,179 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 102, ShuffleMapStage 114)
2021-12-08 10:40:29,179 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List(ShuffleMapStage 114)
2021-12-08 10:40:29,180 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ShuffleMapStage 114 (MapPartitionsRDD[112] at flatMap at ALS.scala:1653), which has no missing parents
2021-12-08 10:40:29,182 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_28 stored as values in memory (estimated size 1460.9 KB, free 1750.2 MB)
2021-12-08 10:40:29,184 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_28_piece0 stored as bytes in memory (estimated size 1424.7 KB, free 1748.8 MB)
2021-12-08 10:40:29,185 [dispatcher-event-loop-7] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_28_piece0 in memory on qb:55657 (size: 1424.7 KB, free: 1752.1 MB)
2021-12-08 10:40:29,185 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 28 from broadcast at DAGScheduler.scala:1039
2021-12-08 10:40:29,185 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 12 missing tasks from ShuffleMapStage 114 (MapPartitionsRDD[112] at flatMap at ALS.scala:1653) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11))
2021-12-08 10:40:29,185 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 114.0 with 12 tasks
2021-12-08 10:40:29,185 [dispatcher-event-loop-10] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 114.0 (TID 296, localhost, executor driver, partition 0, PROCESS_LOCAL, 7928 bytes)
2021-12-08 10:40:29,185 [dispatcher-event-loop-10] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 114.0 (TID 297, localhost, executor driver, partition 1, PROCESS_LOCAL, 7928 bytes)
2021-12-08 10:40:29,185 [dispatcher-event-loop-10] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 2.0 in stage 114.0 (TID 298, localhost, executor driver, partition 2, PROCESS_LOCAL, 7928 bytes)
2021-12-08 10:40:29,186 [dispatcher-event-loop-10] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 3.0 in stage 114.0 (TID 299, localhost, executor driver, partition 3, PROCESS_LOCAL, 7928 bytes)
2021-12-08 10:40:29,186 [dispatcher-event-loop-10] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 4.0 in stage 114.0 (TID 300, localhost, executor driver, partition 4, PROCESS_LOCAL, 7928 bytes)
2021-12-08 10:40:29,186 [dispatcher-event-loop-10] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 5.0 in stage 114.0 (TID 301, localhost, executor driver, partition 5, PROCESS_LOCAL, 7928 bytes)
2021-12-08 10:40:29,186 [dispatcher-event-loop-10] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 6.0 in stage 114.0 (TID 302, localhost, executor driver, partition 6, PROCESS_LOCAL, 7928 bytes)
2021-12-08 10:40:29,186 [dispatcher-event-loop-10] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 7.0 in stage 114.0 (TID 303, localhost, executor driver, partition 7, PROCESS_LOCAL, 7928 bytes)
2021-12-08 10:40:29,186 [dispatcher-event-loop-10] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 8.0 in stage 114.0 (TID 304, localhost, executor driver, partition 8, PROCESS_LOCAL, 7928 bytes)
2021-12-08 10:40:29,186 [dispatcher-event-loop-10] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 9.0 in stage 114.0 (TID 305, localhost, executor driver, partition 9, PROCESS_LOCAL, 7928 bytes)
2021-12-08 10:40:29,186 [dispatcher-event-loop-10] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 10.0 in stage 114.0 (TID 306, localhost, executor driver, partition 10, PROCESS_LOCAL, 7928 bytes)
2021-12-08 10:40:29,186 [dispatcher-event-loop-10] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 11.0 in stage 114.0 (TID 307, localhost, executor driver, partition 11, PROCESS_LOCAL, 7928 bytes)
2021-12-08 10:40:29,186 [Executor task launch worker for task 297] INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 114.0 (TID 297)
2021-12-08 10:40:29,186 [Executor task launch worker for task 300] INFO [org.apache.spark.executor.Executor] - Running task 4.0 in stage 114.0 (TID 300)
2021-12-08 10:40:29,186 [Executor task launch worker for task 306] INFO [org.apache.spark.executor.Executor] - Running task 10.0 in stage 114.0 (TID 306)
2021-12-08 10:40:29,186 [Executor task launch worker for task 307] INFO [org.apache.spark.executor.Executor] - Running task 11.0 in stage 114.0 (TID 307)
2021-12-08 10:40:29,186 [Executor task launch worker for task 304] INFO [org.apache.spark.executor.Executor] - Running task 8.0 in stage 114.0 (TID 304)
2021-12-08 10:40:29,186 [Executor task launch worker for task 296] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 114.0 (TID 296)
2021-12-08 10:40:29,186 [Executor task launch worker for task 302] INFO [org.apache.spark.executor.Executor] - Running task 6.0 in stage 114.0 (TID 302)
2021-12-08 10:40:29,186 [Executor task launch worker for task 305] INFO [org.apache.spark.executor.Executor] - Running task 9.0 in stage 114.0 (TID 305)
2021-12-08 10:40:29,186 [Executor task launch worker for task 303] INFO [org.apache.spark.executor.Executor] - Running task 7.0 in stage 114.0 (TID 303)
2021-12-08 10:40:29,186 [Executor task launch worker for task 301] INFO [org.apache.spark.executor.Executor] - Running task 5.0 in stage 114.0 (TID 301)
2021-12-08 10:40:29,186 [Executor task launch worker for task 299] INFO [org.apache.spark.executor.Executor] - Running task 3.0 in stage 114.0 (TID 299)
2021-12-08 10:40:29,186 [Executor task launch worker for task 298] INFO [org.apache.spark.executor.Executor] - Running task 2.0 in stage 114.0 (TID 298)
2021-12-08 10:40:29,189 [Executor task launch worker for task 302] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_15_6 locally
2021-12-08 10:40:29,189 [Executor task launch worker for task 300] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_15_4 locally
2021-12-08 10:40:29,189 [Executor task launch worker for task 306] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_15_10 locally
2021-12-08 10:40:29,189 [Executor task launch worker for task 298] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_15_2 locally
2021-12-08 10:40:29,189 [Executor task launch worker for task 304] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_15_8 locally
2021-12-08 10:40:29,189 [Executor task launch worker for task 306] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_107_10 locally
2021-12-08 10:40:29,189 [Executor task launch worker for task 296] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_15_0 locally
2021-12-08 10:40:29,189 [Executor task launch worker for task 305] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_15_9 locally
2021-12-08 10:40:29,189 [Executor task launch worker for task 299] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_15_3 locally
2021-12-08 10:40:29,189 [Executor task launch worker for task 296] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_107_0 locally
2021-12-08 10:40:29,189 [Executor task launch worker for task 300] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_107_4 locally
2021-12-08 10:40:29,189 [Executor task launch worker for task 307] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_15_11 locally
2021-12-08 10:40:29,189 [Executor task launch worker for task 297] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_15_1 locally
2021-12-08 10:40:29,189 [Executor task launch worker for task 298] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_107_2 locally
2021-12-08 10:40:29,189 [Executor task launch worker for task 305] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_107_9 locally
2021-12-08 10:40:29,189 [Executor task launch worker for task 302] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_107_6 locally
2021-12-08 10:40:29,189 [Executor task launch worker for task 307] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_107_11 locally
2021-12-08 10:40:29,189 [Executor task launch worker for task 304] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_107_8 locally
2021-12-08 10:40:29,189 [Executor task launch worker for task 299] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_107_3 locally
2021-12-08 10:40:29,190 [Executor task launch worker for task 301] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_15_5 locally
2021-12-08 10:40:29,190 [Executor task launch worker for task 301] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_107_5 locally
2021-12-08 10:40:29,189 [Executor task launch worker for task 297] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_107_1 locally
2021-12-08 10:40:29,190 [Executor task launch worker for task 303] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_15_7 locally
2021-12-08 10:40:29,190 [Executor task launch worker for task 303] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_107_7 locally
2021-12-08 10:40:30,321 [Executor task launch worker for task 301] INFO [org.apache.spark.executor.Executor] - Finished task 5.0 in stage 114.0 (TID 301). 999 bytes result sent to driver
2021-12-08 10:40:30,321 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 5.0 in stage 114.0 (TID 301) in 1135 ms on localhost (executor driver) (1/12)
2021-12-08 10:40:30,323 [Executor task launch worker for task 304] INFO [org.apache.spark.executor.Executor] - Finished task 8.0 in stage 114.0 (TID 304). 999 bytes result sent to driver
2021-12-08 10:40:30,323 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 8.0 in stage 114.0 (TID 304) in 1137 ms on localhost (executor driver) (2/12)
2021-12-08 10:40:30,325 [Executor task launch worker for task 300] INFO [org.apache.spark.executor.Executor] - Finished task 4.0 in stage 114.0 (TID 300). 999 bytes result sent to driver
2021-12-08 10:40:30,326 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 4.0 in stage 114.0 (TID 300) in 1140 ms on localhost (executor driver) (3/12)
2021-12-08 10:40:30,327 [Executor task launch worker for task 302] INFO [org.apache.spark.executor.Executor] - Finished task 6.0 in stage 114.0 (TID 302). 999 bytes result sent to driver
2021-12-08 10:40:30,327 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 6.0 in stage 114.0 (TID 302) in 1141 ms on localhost (executor driver) (4/12)
2021-12-08 10:40:30,489 [Executor task launch worker for task 298] INFO [org.apache.spark.executor.Executor] - Finished task 2.0 in stage 114.0 (TID 298). 999 bytes result sent to driver
2021-12-08 10:40:30,489 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 2.0 in stage 114.0 (TID 298) in 1304 ms on localhost (executor driver) (5/12)
2021-12-08 10:40:30,491 [Executor task launch worker for task 307] INFO [org.apache.spark.executor.Executor] - Finished task 11.0 in stage 114.0 (TID 307). 999 bytes result sent to driver
2021-12-08 10:40:30,492 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 11.0 in stage 114.0 (TID 307) in 1306 ms on localhost (executor driver) (6/12)
2021-12-08 10:40:30,493 [Executor task launch worker for task 296] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 114.0 (TID 296). 999 bytes result sent to driver
2021-12-08 10:40:30,493 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 114.0 (TID 296) in 1308 ms on localhost (executor driver) (7/12)
2021-12-08 10:40:30,573 [Executor task launch worker for task 297] INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 114.0 (TID 297). 999 bytes result sent to driver
2021-12-08 10:40:30,573 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 114.0 (TID 297) in 1388 ms on localhost (executor driver) (8/12)
2021-12-08 10:40:30,574 [Executor task launch worker for task 303] INFO [org.apache.spark.executor.Executor] - Finished task 7.0 in stage 114.0 (TID 303). 999 bytes result sent to driver
2021-12-08 10:40:30,574 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 7.0 in stage 114.0 (TID 303) in 1388 ms on localhost (executor driver) (9/12)
2021-12-08 10:40:30,575 [Executor task launch worker for task 305] INFO [org.apache.spark.executor.Executor] - Finished task 9.0 in stage 114.0 (TID 305). 999 bytes result sent to driver
2021-12-08 10:40:30,575 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 9.0 in stage 114.0 (TID 305) in 1389 ms on localhost (executor driver) (10/12)
2021-12-08 10:40:30,576 [Executor task launch worker for task 299] INFO [org.apache.spark.executor.Executor] - Finished task 3.0 in stage 114.0 (TID 299). 999 bytes result sent to driver
2021-12-08 10:40:30,576 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 3.0 in stage 114.0 (TID 299) in 1391 ms on localhost (executor driver) (11/12)
2021-12-08 10:40:30,578 [Executor task launch worker for task 306] INFO [org.apache.spark.executor.Executor] - Finished task 10.0 in stage 114.0 (TID 306). 999 bytes result sent to driver
2021-12-08 10:40:30,578 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 10.0 in stage 114.0 (TID 306) in 1392 ms on localhost (executor driver) (12/12)
2021-12-08 10:40:30,578 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 114.0, whose tasks have all completed, from pool 
2021-12-08 10:40:30,578 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ShuffleMapStage 114 (flatMap at ALS.scala:1653) finished in 1.398 s
2021-12-08 10:40:30,578 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - looking for newly runnable stages
2021-12-08 10:40:30,578 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - running: Set()
2021-12-08 10:40:30,578 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - waiting: Set(ResultStage 115)
2021-12-08 10:40:30,578 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - failed: Set()
2021-12-08 10:40:30,578 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 115 (MapPartitionsRDD[118] at values at ALS.scala:1711), which has no missing parents
2021-12-08 10:40:30,581 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_29 stored as values in memory (estimated size 1782.5 KB, free 1747.0 MB)
2021-12-08 10:40:30,584 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_29_piece0 stored as bytes in memory (estimated size 1583.4 KB, free 1745.5 MB)
2021-12-08 10:40:30,585 [dispatcher-event-loop-2] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_29_piece0 in memory on qb:55657 (size: 1583.4 KB, free: 1750.6 MB)
2021-12-08 10:40:30,585 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 29 from broadcast at DAGScheduler.scala:1039
2021-12-08 10:40:30,585 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 12 missing tasks from ResultStage 115 (MapPartitionsRDD[118] at values at ALS.scala:1711) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11))
2021-12-08 10:40:30,585 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 115.0 with 12 tasks
2021-12-08 10:40:30,585 [dispatcher-event-loop-6] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 115.0 (TID 308, localhost, executor driver, partition 0, PROCESS_LOCAL, 7888 bytes)
2021-12-08 10:40:30,586 [dispatcher-event-loop-6] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 115.0 (TID 309, localhost, executor driver, partition 1, PROCESS_LOCAL, 7888 bytes)
2021-12-08 10:40:30,586 [dispatcher-event-loop-6] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 2.0 in stage 115.0 (TID 310, localhost, executor driver, partition 2, PROCESS_LOCAL, 7888 bytes)
2021-12-08 10:40:30,586 [dispatcher-event-loop-6] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 3.0 in stage 115.0 (TID 311, localhost, executor driver, partition 3, PROCESS_LOCAL, 7888 bytes)
2021-12-08 10:40:30,586 [dispatcher-event-loop-6] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 4.0 in stage 115.0 (TID 312, localhost, executor driver, partition 4, PROCESS_LOCAL, 7888 bytes)
2021-12-08 10:40:30,586 [dispatcher-event-loop-6] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 5.0 in stage 115.0 (TID 313, localhost, executor driver, partition 5, PROCESS_LOCAL, 7888 bytes)
2021-12-08 10:40:30,586 [dispatcher-event-loop-6] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 6.0 in stage 115.0 (TID 314, localhost, executor driver, partition 6, PROCESS_LOCAL, 7888 bytes)
2021-12-08 10:40:30,586 [dispatcher-event-loop-6] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 7.0 in stage 115.0 (TID 315, localhost, executor driver, partition 7, PROCESS_LOCAL, 7888 bytes)
2021-12-08 10:40:30,586 [dispatcher-event-loop-6] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 8.0 in stage 115.0 (TID 316, localhost, executor driver, partition 8, PROCESS_LOCAL, 7888 bytes)
2021-12-08 10:40:30,586 [dispatcher-event-loop-6] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 9.0 in stage 115.0 (TID 317, localhost, executor driver, partition 9, PROCESS_LOCAL, 7888 bytes)
2021-12-08 10:40:30,586 [dispatcher-event-loop-6] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 10.0 in stage 115.0 (TID 318, localhost, executor driver, partition 10, PROCESS_LOCAL, 7888 bytes)
2021-12-08 10:40:30,586 [dispatcher-event-loop-6] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 11.0 in stage 115.0 (TID 319, localhost, executor driver, partition 11, PROCESS_LOCAL, 7888 bytes)
2021-12-08 10:40:30,586 [Executor task launch worker for task 309] INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 115.0 (TID 309)
2021-12-08 10:40:30,586 [Executor task launch worker for task 312] INFO [org.apache.spark.executor.Executor] - Running task 4.0 in stage 115.0 (TID 312)
2021-12-08 10:40:30,586 [Executor task launch worker for task 317] INFO [org.apache.spark.executor.Executor] - Running task 9.0 in stage 115.0 (TID 317)
2021-12-08 10:40:30,586 [Executor task launch worker for task 311] INFO [org.apache.spark.executor.Executor] - Running task 3.0 in stage 115.0 (TID 311)
2021-12-08 10:40:30,586 [Executor task launch worker for task 315] INFO [org.apache.spark.executor.Executor] - Running task 7.0 in stage 115.0 (TID 315)
2021-12-08 10:40:30,586 [Executor task launch worker for task 308] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 115.0 (TID 308)
2021-12-08 10:40:30,586 [Executor task launch worker for task 316] INFO [org.apache.spark.executor.Executor] - Running task 8.0 in stage 115.0 (TID 316)
2021-12-08 10:40:30,586 [Executor task launch worker for task 310] INFO [org.apache.spark.executor.Executor] - Running task 2.0 in stage 115.0 (TID 310)
2021-12-08 10:40:30,586 [Executor task launch worker for task 314] INFO [org.apache.spark.executor.Executor] - Running task 6.0 in stage 115.0 (TID 314)
2021-12-08 10:40:30,586 [Executor task launch worker for task 313] INFO [org.apache.spark.executor.Executor] - Running task 5.0 in stage 115.0 (TID 313)
2021-12-08 10:40:30,586 [Executor task launch worker for task 318] INFO [org.apache.spark.executor.Executor] - Running task 10.0 in stage 115.0 (TID 318)
2021-12-08 10:40:30,586 [Executor task launch worker for task 319] INFO [org.apache.spark.executor.Executor] - Running task 11.0 in stage 115.0 (TID 319)
2021-12-08 10:40:30,590 [Executor task launch worker for task 319] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_9_11 locally
2021-12-08 10:40:30,590 [Executor task launch worker for task 308] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_9_0 locally
2021-12-08 10:40:30,590 [Executor task launch worker for task 309] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_9_1 locally
2021-12-08 10:40:30,590 [Executor task launch worker for task 317] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_9_9 locally
2021-12-08 10:40:30,590 [Executor task launch worker for task 315] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_9_7 locally
2021-12-08 10:40:30,591 [Executor task launch worker for task 311] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_9_3 locally
2021-12-08 10:40:30,591 [Executor task launch worker for task 310] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_9_2 locally
2021-12-08 10:40:30,591 [Executor task launch worker for task 309] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 12 non-empty blocks out of 12 blocks
2021-12-08 10:40:30,591 [Executor task launch worker for task 308] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 12 non-empty blocks out of 12 blocks
2021-12-08 10:40:30,591 [Executor task launch worker for task 311] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 12 non-empty blocks out of 12 blocks
2021-12-08 10:40:30,591 [Executor task launch worker for task 317] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 12 non-empty blocks out of 12 blocks
2021-12-08 10:40:30,591 [Executor task launch worker for task 311] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-08 10:40:30,591 [Executor task launch worker for task 317] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-08 10:40:30,591 [Executor task launch worker for task 308] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-08 10:40:30,591 [Executor task launch worker for task 309] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-08 10:40:30,591 [Executor task launch worker for task 319] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 12 non-empty blocks out of 12 blocks
2021-12-08 10:40:30,591 [Executor task launch worker for task 314] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_9_6 locally
2021-12-08 10:40:30,591 [Executor task launch worker for task 319] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-08 10:40:30,591 [Executor task launch worker for task 310] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 12 non-empty blocks out of 12 blocks
2021-12-08 10:40:30,591 [Executor task launch worker for task 310] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-08 10:40:30,591 [Executor task launch worker for task 315] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 12 non-empty blocks out of 12 blocks
2021-12-08 10:40:30,591 [Executor task launch worker for task 315] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-08 10:40:30,591 [Executor task launch worker for task 314] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 12 non-empty blocks out of 12 blocks
2021-12-08 10:40:30,591 [Executor task launch worker for task 314] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-08 10:40:30,592 [Executor task launch worker for task 316] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_9_8 locally
2021-12-08 10:40:30,592 [Executor task launch worker for task 316] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 12 non-empty blocks out of 12 blocks
2021-12-08 10:40:30,592 [Executor task launch worker for task 316] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-08 10:40:30,592 [Executor task launch worker for task 313] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_9_5 locally
2021-12-08 10:40:30,592 [Executor task launch worker for task 313] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 12 non-empty blocks out of 12 blocks
2021-12-08 10:40:30,592 [Executor task launch worker for task 313] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-08 10:40:30,592 [Executor task launch worker for task 312] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_9_4 locally
2021-12-08 10:40:30,592 [Executor task launch worker for task 312] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 12 non-empty blocks out of 12 blocks
2021-12-08 10:40:30,592 [Executor task launch worker for task 312] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-08 10:40:30,592 [Executor task launch worker for task 318] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_9_10 locally
2021-12-08 10:40:30,592 [Executor task launch worker for task 318] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 12 non-empty blocks out of 12 blocks
2021-12-08 10:40:30,592 [Executor task launch worker for task 318] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-08 10:40:30,709 [dispatcher-event-loop-4] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_28_piece0 on qb:55657 in memory (size: 1424.7 KB, free: 1751.9 MB)
2021-12-08 10:41:08,374 [Executor task launch worker for task 312] INFO [org.apache.spark.storage.memory.MemoryStore] - Block rdd_117_4 stored as values in memory (estimated size 11.1 MB, free 1737.2 MB)
2021-12-08 10:41:08,374 [dispatcher-event-loop-2] INFO [org.apache.spark.storage.BlockManagerInfo] - Added rdd_117_4 in memory on qb:55657 (size: 11.1 MB, free: 1740.8 MB)
2021-12-08 10:41:08,543 [Executor task launch worker for task 315] INFO [org.apache.spark.storage.memory.MemoryStore] - Block rdd_117_7 stored as values in memory (estimated size 11.1 MB, free 1726.1 MB)
2021-12-08 10:41:08,543 [dispatcher-event-loop-6] INFO [org.apache.spark.storage.BlockManagerInfo] - Added rdd_117_7 in memory on qb:55657 (size: 11.1 MB, free: 1729.7 MB)
2021-12-08 10:41:08,629 [Executor task launch worker for task 314] INFO [org.apache.spark.storage.memory.MemoryStore] - Block rdd_117_6 stored as values in memory (estimated size 11.1 MB, free 1715.0 MB)
2021-12-08 10:41:08,629 [dispatcher-event-loop-3] INFO [org.apache.spark.storage.BlockManagerInfo] - Added rdd_117_6 in memory on qb:55657 (size: 11.1 MB, free: 1718.6 MB)
2021-12-08 10:41:08,711 [Executor task launch worker for task 312] INFO [org.apache.spark.executor.Executor] - Finished task 4.0 in stage 115.0 (TID 312). 166054 bytes result sent to driver
2021-12-08 10:41:08,711 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 4.0 in stage 115.0 (TID 312) in 38125 ms on localhost (executor driver) (1/12)
2021-12-08 10:41:08,725 [Executor task launch worker for task 310] INFO [org.apache.spark.storage.memory.MemoryStore] - Block rdd_117_2 stored as values in memory (estimated size 11.1 MB, free 1703.9 MB)
2021-12-08 10:41:08,725 [dispatcher-event-loop-11] INFO [org.apache.spark.storage.BlockManagerInfo] - Added rdd_117_2 in memory on qb:55657 (size: 11.1 MB, free: 1707.5 MB)
2021-12-08 10:41:08,821 [Executor task launch worker for task 317] INFO [org.apache.spark.storage.memory.MemoryStore] - Block rdd_117_9 stored as values in memory (estimated size 11.1 MB, free 1692.8 MB)
2021-12-08 10:41:08,821 [dispatcher-event-loop-7] INFO [org.apache.spark.storage.BlockManagerInfo] - Added rdd_117_9 in memory on qb:55657 (size: 11.1 MB, free: 1696.4 MB)
2021-12-08 10:41:08,866 [Executor task launch worker for task 315] INFO [org.apache.spark.executor.Executor] - Finished task 7.0 in stage 115.0 (TID 315). 166097 bytes result sent to driver
2021-12-08 10:41:08,867 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 7.0 in stage 115.0 (TID 315) in 38281 ms on localhost (executor driver) (2/12)
2021-12-08 10:41:08,910 [Executor task launch worker for task 318] INFO [org.apache.spark.storage.memory.MemoryStore] - Block rdd_117_10 stored as values in memory (estimated size 11.1 MB, free 1681.7 MB)
2021-12-08 10:41:08,910 [dispatcher-event-loop-8] INFO [org.apache.spark.storage.BlockManagerInfo] - Added rdd_117_10 in memory on qb:55657 (size: 11.1 MB, free: 1685.3 MB)
2021-12-08 10:41:08,910 [Executor task launch worker for task 308] INFO [org.apache.spark.storage.memory.MemoryStore] - Block rdd_117_0 stored as values in memory (estimated size 11.1 MB, free 1670.6 MB)
2021-12-08 10:41:08,911 [dispatcher-event-loop-0] INFO [org.apache.spark.storage.BlockManagerInfo] - Added rdd_117_0 in memory on qb:55657 (size: 11.1 MB, free: 1674.2 MB)
2021-12-08 10:41:08,956 [Executor task launch worker for task 314] INFO [org.apache.spark.executor.Executor] - Finished task 6.0 in stage 115.0 (TID 314). 166054 bytes result sent to driver
2021-12-08 10:41:08,956 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 6.0 in stage 115.0 (TID 314) in 38370 ms on localhost (executor driver) (3/12)
2021-12-08 10:41:09,067 [Executor task launch worker for task 310] INFO [org.apache.spark.executor.Executor] - Finished task 2.0 in stage 115.0 (TID 310). 166097 bytes result sent to driver
2021-12-08 10:41:09,068 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 2.0 in stage 115.0 (TID 310) in 38482 ms on localhost (executor driver) (4/12)
2021-12-08 10:41:09,162 [Executor task launch worker for task 317] INFO [org.apache.spark.executor.Executor] - Finished task 9.0 in stage 115.0 (TID 317). 166054 bytes result sent to driver
2021-12-08 10:41:09,162 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 9.0 in stage 115.0 (TID 317) in 38576 ms on localhost (executor driver) (5/12)
2021-12-08 10:41:09,217 [Executor task launch worker for task 308] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 115.0 (TID 308). 166054 bytes result sent to driver
2021-12-08 10:41:09,218 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 115.0 (TID 308) in 38633 ms on localhost (executor driver) (6/12)
2021-12-08 10:41:09,229 [Executor task launch worker for task 318] INFO [org.apache.spark.executor.Executor] - Finished task 10.0 in stage 115.0 (TID 318). 166054 bytes result sent to driver
2021-12-08 10:41:09,230 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 10.0 in stage 115.0 (TID 318) in 38644 ms on localhost (executor driver) (7/12)
2021-12-08 10:41:10,416 [Executor task launch worker for task 313] INFO [org.apache.spark.storage.memory.MemoryStore] - Block rdd_117_5 stored as values in memory (estimated size 11.1 MB, free 1659.5 MB)
2021-12-08 10:41:10,416 [dispatcher-event-loop-4] INFO [org.apache.spark.storage.BlockManagerInfo] - Added rdd_117_5 in memory on qb:55657 (size: 11.1 MB, free: 1663.1 MB)
2021-12-08 10:41:10,451 [Executor task launch worker for task 316] INFO [org.apache.spark.storage.memory.MemoryStore] - Block rdd_117_8 stored as values in memory (estimated size 11.1 MB, free 1648.4 MB)
2021-12-08 10:41:10,451 [dispatcher-event-loop-9] INFO [org.apache.spark.storage.BlockManagerInfo] - Added rdd_117_8 in memory on qb:55657 (size: 11.1 MB, free: 1652.0 MB)
2021-12-08 10:41:10,508 [Executor task launch worker for task 319] INFO [org.apache.spark.storage.memory.MemoryStore] - Block rdd_117_11 stored as values in memory (estimated size 11.1 MB, free 1637.3 MB)
2021-12-08 10:41:10,508 [dispatcher-event-loop-11] INFO [org.apache.spark.storage.BlockManagerInfo] - Added rdd_117_11 in memory on qb:55657 (size: 11.1 MB, free: 1640.9 MB)
2021-12-08 10:41:10,629 [Executor task launch worker for task 309] INFO [org.apache.spark.storage.memory.MemoryStore] - Block rdd_117_1 stored as values in memory (estimated size 11.1 MB, free 1626.2 MB)
2021-12-08 10:41:10,630 [dispatcher-event-loop-7] INFO [org.apache.spark.storage.BlockManagerInfo] - Added rdd_117_1 in memory on qb:55657 (size: 11.1 MB, free: 1629.8 MB)
2021-12-08 10:41:10,634 [Executor task launch worker for task 313] INFO [org.apache.spark.executor.Executor] - Finished task 5.0 in stage 115.0 (TID 313). 166097 bytes result sent to driver
2021-12-08 10:41:10,634 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 5.0 in stage 115.0 (TID 313) in 40048 ms on localhost (executor driver) (8/12)
2021-12-08 10:41:10,661 [Executor task launch worker for task 316] INFO [org.apache.spark.executor.Executor] - Finished task 8.0 in stage 115.0 (TID 316). 166054 bytes result sent to driver
2021-12-08 10:41:10,661 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 8.0 in stage 115.0 (TID 316) in 40075 ms on localhost (executor driver) (9/12)
2021-12-08 10:41:10,709 [Executor task launch worker for task 319] INFO [org.apache.spark.executor.Executor] - Finished task 11.0 in stage 115.0 (TID 319). 166054 bytes result sent to driver
2021-12-08 10:41:10,709 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 11.0 in stage 115.0 (TID 319) in 40123 ms on localhost (executor driver) (10/12)
2021-12-08 10:41:10,788 [Executor task launch worker for task 311] INFO [org.apache.spark.storage.memory.MemoryStore] - Block rdd_117_3 stored as values in memory (estimated size 11.1 MB, free 1615.1 MB)
2021-12-08 10:41:10,788 [dispatcher-event-loop-1] INFO [org.apache.spark.storage.BlockManagerInfo] - Added rdd_117_3 in memory on qb:55657 (size: 11.1 MB, free: 1618.7 MB)
2021-12-08 10:41:10,813 [Executor task launch worker for task 309] INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 115.0 (TID 309). 166054 bytes result sent to driver
2021-12-08 10:41:10,813 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 115.0 (TID 309) in 40228 ms on localhost (executor driver) (11/12)
2021-12-08 10:41:10,959 [Executor task launch worker for task 311] INFO [org.apache.spark.executor.Executor] - Finished task 3.0 in stage 115.0 (TID 311). 166054 bytes result sent to driver
2021-12-08 10:41:10,960 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 3.0 in stage 115.0 (TID 311) in 40374 ms on localhost (executor driver) (12/12)
2021-12-08 10:41:10,960 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 115.0, whose tasks have all completed, from pool 
2021-12-08 10:41:10,960 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 115 (aggregate at ALS.scala:1711) finished in 40.381 s
2021-12-08 10:41:10,960 [main] INFO [org.apache.spark.scheduler.DAGScheduler] - Job 14 finished: aggregate at ALS.scala:1711, took 41.782421 s
2021-12-08 10:41:10,974 [main] INFO [org.apache.spark.rdd.MapPartitionsRDD] - Removing RDD 107 from persistence list
2021-12-08 10:41:10,975 [block-manager-slave-async-thread-pool-1] INFO [org.apache.spark.storage.BlockManager] - Removing RDD 107
2021-12-08 10:41:10,981 [main] INFO [org.apache.spark.SparkContext] - Starting job: aggregate at ALS.scala:1711
2021-12-08 10:41:10,982 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 122 (flatMap at ALS.scala:1653)
2021-12-08 10:41:10,982 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 15 (aggregate at ALS.scala:1711) with 12 output partitions
2021-12-08 10:41:10,982 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 131 (aggregate at ALS.scala:1711)
2021-12-08 10:41:10,982 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 117, ShuffleMapStage 130)
2021-12-08 10:41:10,982 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List(ShuffleMapStage 130)
2021-12-08 10:41:10,982 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ShuffleMapStage 130 (MapPartitionsRDD[122] at flatMap at ALS.scala:1653), which has no missing parents
2021-12-08 10:41:10,986 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_30 stored as values in memory (estimated size 1622.0 KB, free 1661.3 MB)
2021-12-08 10:41:10,989 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_30_piece0 stored as bytes in memory (estimated size 1582.4 KB, free 1659.8 MB)
2021-12-08 10:41:10,989 [dispatcher-event-loop-10] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_30_piece0 in memory on qb:55657 (size: 1582.4 KB, free: 1665.0 MB)
2021-12-08 10:41:10,990 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 30 from broadcast at DAGScheduler.scala:1039
2021-12-08 10:41:10,990 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 12 missing tasks from ShuffleMapStage 130 (MapPartitionsRDD[122] at flatMap at ALS.scala:1653) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11))
2021-12-08 10:41:10,990 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 130.0 with 12 tasks
2021-12-08 10:41:10,990 [dispatcher-event-loop-8] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 130.0 (TID 320, localhost, executor driver, partition 0, PROCESS_LOCAL, 7928 bytes)
2021-12-08 10:41:10,990 [dispatcher-event-loop-8] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 130.0 (TID 321, localhost, executor driver, partition 1, PROCESS_LOCAL, 7928 bytes)
2021-12-08 10:41:10,990 [dispatcher-event-loop-8] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 2.0 in stage 130.0 (TID 322, localhost, executor driver, partition 2, PROCESS_LOCAL, 7928 bytes)
2021-12-08 10:41:10,990 [dispatcher-event-loop-8] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 3.0 in stage 130.0 (TID 323, localhost, executor driver, partition 3, PROCESS_LOCAL, 7928 bytes)
2021-12-08 10:41:10,990 [dispatcher-event-loop-8] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 4.0 in stage 130.0 (TID 324, localhost, executor driver, partition 4, PROCESS_LOCAL, 7928 bytes)
2021-12-08 10:41:10,990 [dispatcher-event-loop-8] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 5.0 in stage 130.0 (TID 325, localhost, executor driver, partition 5, PROCESS_LOCAL, 7928 bytes)
2021-12-08 10:41:10,990 [dispatcher-event-loop-8] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 6.0 in stage 130.0 (TID 326, localhost, executor driver, partition 6, PROCESS_LOCAL, 7928 bytes)
2021-12-08 10:41:10,991 [dispatcher-event-loop-8] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 7.0 in stage 130.0 (TID 327, localhost, executor driver, partition 7, PROCESS_LOCAL, 7928 bytes)
2021-12-08 10:41:10,991 [dispatcher-event-loop-8] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 8.0 in stage 130.0 (TID 328, localhost, executor driver, partition 8, PROCESS_LOCAL, 7928 bytes)
2021-12-08 10:41:10,991 [dispatcher-event-loop-8] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 9.0 in stage 130.0 (TID 329, localhost, executor driver, partition 9, PROCESS_LOCAL, 7928 bytes)
2021-12-08 10:41:10,991 [dispatcher-event-loop-8] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 10.0 in stage 130.0 (TID 330, localhost, executor driver, partition 10, PROCESS_LOCAL, 7928 bytes)
2021-12-08 10:41:10,991 [dispatcher-event-loop-8] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 11.0 in stage 130.0 (TID 331, localhost, executor driver, partition 11, PROCESS_LOCAL, 7928 bytes)
2021-12-08 10:41:10,991 [Executor task launch worker for task 320] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 130.0 (TID 320)
2021-12-08 10:41:10,991 [Executor task launch worker for task 322] INFO [org.apache.spark.executor.Executor] - Running task 2.0 in stage 130.0 (TID 322)
2021-12-08 10:41:10,991 [Executor task launch worker for task 329] INFO [org.apache.spark.executor.Executor] - Running task 9.0 in stage 130.0 (TID 329)
2021-12-08 10:41:10,991 [Executor task launch worker for task 328] INFO [org.apache.spark.executor.Executor] - Running task 8.0 in stage 130.0 (TID 328)
2021-12-08 10:41:10,991 [Executor task launch worker for task 330] INFO [org.apache.spark.executor.Executor] - Running task 10.0 in stage 130.0 (TID 330)
2021-12-08 10:41:10,991 [Executor task launch worker for task 325] INFO [org.apache.spark.executor.Executor] - Running task 5.0 in stage 130.0 (TID 325)
2021-12-08 10:41:10,991 [Executor task launch worker for task 323] INFO [org.apache.spark.executor.Executor] - Running task 3.0 in stage 130.0 (TID 323)
2021-12-08 10:41:10,991 [Executor task launch worker for task 321] INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 130.0 (TID 321)
2021-12-08 10:41:10,991 [Executor task launch worker for task 324] INFO [org.apache.spark.executor.Executor] - Running task 4.0 in stage 130.0 (TID 324)
2021-12-08 10:41:10,991 [Executor task launch worker for task 327] INFO [org.apache.spark.executor.Executor] - Running task 7.0 in stage 130.0 (TID 327)
2021-12-08 10:41:10,991 [Executor task launch worker for task 326] INFO [org.apache.spark.executor.Executor] - Running task 6.0 in stage 130.0 (TID 326)
2021-12-08 10:41:10,991 [Executor task launch worker for task 331] INFO [org.apache.spark.executor.Executor] - Running task 11.0 in stage 130.0 (TID 331)
2021-12-08 10:41:10,994 [Executor task launch worker for task 324] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_10_4 locally
2021-12-08 10:41:10,994 [Executor task launch worker for task 324] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_117_4 locally
2021-12-08 10:41:10,994 [Executor task launch worker for task 330] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_10_10 locally
2021-12-08 10:41:10,994 [Executor task launch worker for task 326] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_10_6 locally
2021-12-08 10:41:10,994 [Executor task launch worker for task 327] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_10_7 locally
2021-12-08 10:41:10,994 [Executor task launch worker for task 321] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_10_1 locally
2021-12-08 10:41:10,994 [Executor task launch worker for task 327] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_117_7 locally
2021-12-08 10:41:10,994 [Executor task launch worker for task 325] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_10_5 locally
2021-12-08 10:41:10,994 [Executor task launch worker for task 321] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_117_1 locally
2021-12-08 10:41:10,994 [Executor task launch worker for task 331] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_10_11 locally
2021-12-08 10:41:10,994 [Executor task launch worker for task 331] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_117_11 locally
2021-12-08 10:41:10,995 [Executor task launch worker for task 328] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_10_8 locally
2021-12-08 10:41:10,995 [Executor task launch worker for task 328] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_117_8 locally
2021-12-08 10:41:10,994 [Executor task launch worker for task 326] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_117_6 locally
2021-12-08 10:41:10,995 [Executor task launch worker for task 325] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_117_5 locally
2021-12-08 10:41:10,996 [Executor task launch worker for task 320] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_10_0 locally
2021-12-08 10:41:10,996 [Executor task launch worker for task 320] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_117_0 locally
2021-12-08 10:41:10,996 [Executor task launch worker for task 322] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_10_2 locally
2021-12-08 10:41:10,996 [Executor task launch worker for task 322] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_117_2 locally
2021-12-08 10:41:10,999 [Executor task launch worker for task 330] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_117_10 locally
2021-12-08 10:41:10,999 [Executor task launch worker for task 323] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_10_3 locally
2021-12-08 10:41:11,000 [Executor task launch worker for task 323] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_117_3 locally
2021-12-08 10:41:11,006 [Executor task launch worker for task 329] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_10_9 locally
2021-12-08 10:41:11,007 [Executor task launch worker for task 329] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_117_9 locally
2021-12-08 10:41:13,642 [Executor task launch worker for task 322] INFO [org.apache.spark.executor.Executor] - Finished task 2.0 in stage 130.0 (TID 322). 999 bytes result sent to driver
2021-12-08 10:41:13,642 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 2.0 in stage 130.0 (TID 322) in 2652 ms on localhost (executor driver) (1/12)
2021-12-08 10:41:13,643 [Executor task launch worker for task 331] INFO [org.apache.spark.executor.Executor] - Finished task 11.0 in stage 130.0 (TID 331). 999 bytes result sent to driver
2021-12-08 10:41:13,644 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 11.0 in stage 130.0 (TID 331) in 2653 ms on localhost (executor driver) (2/12)
2021-12-08 10:41:13,719 [Executor task launch worker for task 330] INFO [org.apache.spark.executor.Executor] - Finished task 10.0 in stage 130.0 (TID 330). 999 bytes result sent to driver
2021-12-08 10:41:13,719 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 10.0 in stage 130.0 (TID 330) in 2728 ms on localhost (executor driver) (3/12)
2021-12-08 10:41:13,736 [Executor task launch worker for task 325] INFO [org.apache.spark.executor.Executor] - Finished task 5.0 in stage 130.0 (TID 325). 999 bytes result sent to driver
2021-12-08 10:41:13,736 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 5.0 in stage 130.0 (TID 325) in 2746 ms on localhost (executor driver) (4/12)
2021-12-08 10:41:13,748 [Executor task launch worker for task 323] INFO [org.apache.spark.executor.Executor] - Finished task 3.0 in stage 130.0 (TID 323). 999 bytes result sent to driver
2021-12-08 10:41:13,748 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 3.0 in stage 130.0 (TID 323) in 2758 ms on localhost (executor driver) (5/12)
2021-12-08 10:41:13,756 [Executor task launch worker for task 327] INFO [org.apache.spark.executor.Executor] - Finished task 7.0 in stage 130.0 (TID 327). 999 bytes result sent to driver
2021-12-08 10:41:13,756 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 7.0 in stage 130.0 (TID 327) in 2766 ms on localhost (executor driver) (6/12)
2021-12-08 10:41:13,843 [Executor task launch worker for task 320] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 130.0 (TID 320). 999 bytes result sent to driver
2021-12-08 10:41:13,843 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 130.0 (TID 320) in 2853 ms on localhost (executor driver) (7/12)
2021-12-08 10:41:13,870 [Executor task launch worker for task 321] INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 130.0 (TID 321). 999 bytes result sent to driver
2021-12-08 10:41:13,871 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 130.0 (TID 321) in 2880 ms on localhost (executor driver) (8/12)
2021-12-08 10:41:13,872 [Executor task launch worker for task 328] INFO [org.apache.spark.executor.Executor] - Finished task 8.0 in stage 130.0 (TID 328). 999 bytes result sent to driver
2021-12-08 10:41:13,872 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 8.0 in stage 130.0 (TID 328) in 2881 ms on localhost (executor driver) (9/12)
2021-12-08 10:41:13,873 [Executor task launch worker for task 324] INFO [org.apache.spark.executor.Executor] - Finished task 4.0 in stage 130.0 (TID 324). 999 bytes result sent to driver
2021-12-08 10:41:13,873 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 4.0 in stage 130.0 (TID 324) in 2883 ms on localhost (executor driver) (10/12)
2021-12-08 10:41:13,875 [Executor task launch worker for task 329] INFO [org.apache.spark.executor.Executor] - Finished task 9.0 in stage 130.0 (TID 329). 1042 bytes result sent to driver
2021-12-08 10:41:13,875 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 9.0 in stage 130.0 (TID 329) in 2884 ms on localhost (executor driver) (11/12)
2021-12-08 10:41:14,418 [Executor task launch worker for task 326] INFO [org.apache.spark.executor.Executor] - Finished task 6.0 in stage 130.0 (TID 326). 999 bytes result sent to driver
2021-12-08 10:41:14,418 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 6.0 in stage 130.0 (TID 326) in 3428 ms on localhost (executor driver) (12/12)
2021-12-08 10:41:14,418 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 130.0, whose tasks have all completed, from pool 
2021-12-08 10:41:14,418 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ShuffleMapStage 130 (flatMap at ALS.scala:1653) finished in 3.435 s
2021-12-08 10:41:14,419 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - looking for newly runnable stages
2021-12-08 10:41:14,419 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - running: Set()
2021-12-08 10:41:14,419 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - waiting: Set(ResultStage 131)
2021-12-08 10:41:14,419 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - failed: Set()
2021-12-08 10:41:14,419 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 131 (MapPartitionsRDD[128] at values at ALS.scala:1711), which has no missing parents
2021-12-08 10:41:14,422 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_31 stored as values in memory (estimated size 1943.6 KB, free 1657.9 MB)
2021-12-08 10:41:14,424 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_31_piece0 stored as bytes in memory (estimated size 1741.1 KB, free 1656.2 MB)
2021-12-08 10:41:14,425 [dispatcher-event-loop-2] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_31_piece0 in memory on qb:55657 (size: 1741.1 KB, free: 1663.3 MB)
2021-12-08 10:41:14,425 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 31 from broadcast at DAGScheduler.scala:1039
2021-12-08 10:41:14,425 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 12 missing tasks from ResultStage 131 (MapPartitionsRDD[128] at values at ALS.scala:1711) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11))
2021-12-08 10:41:14,425 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 131.0 with 12 tasks
2021-12-08 10:41:14,425 [dispatcher-event-loop-6] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 131.0 (TID 332, localhost, executor driver, partition 0, PROCESS_LOCAL, 7888 bytes)
2021-12-08 10:41:14,425 [dispatcher-event-loop-6] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 131.0 (TID 333, localhost, executor driver, partition 1, PROCESS_LOCAL, 7888 bytes)
2021-12-08 10:41:14,425 [dispatcher-event-loop-6] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 2.0 in stage 131.0 (TID 334, localhost, executor driver, partition 2, PROCESS_LOCAL, 7888 bytes)
2021-12-08 10:41:14,426 [dispatcher-event-loop-6] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 3.0 in stage 131.0 (TID 335, localhost, executor driver, partition 3, PROCESS_LOCAL, 7888 bytes)
2021-12-08 10:41:14,426 [dispatcher-event-loop-6] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 4.0 in stage 131.0 (TID 336, localhost, executor driver, partition 4, PROCESS_LOCAL, 7888 bytes)
2021-12-08 10:41:14,426 [dispatcher-event-loop-6] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 5.0 in stage 131.0 (TID 337, localhost, executor driver, partition 5, PROCESS_LOCAL, 7888 bytes)
2021-12-08 10:41:14,426 [dispatcher-event-loop-6] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 6.0 in stage 131.0 (TID 338, localhost, executor driver, partition 6, PROCESS_LOCAL, 7888 bytes)
2021-12-08 10:41:14,426 [dispatcher-event-loop-6] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 7.0 in stage 131.0 (TID 339, localhost, executor driver, partition 7, PROCESS_LOCAL, 7888 bytes)
2021-12-08 10:41:14,426 [dispatcher-event-loop-6] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 8.0 in stage 131.0 (TID 340, localhost, executor driver, partition 8, PROCESS_LOCAL, 7888 bytes)
2021-12-08 10:41:14,426 [dispatcher-event-loop-6] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 9.0 in stage 131.0 (TID 341, localhost, executor driver, partition 9, PROCESS_LOCAL, 7888 bytes)
2021-12-08 10:41:14,426 [dispatcher-event-loop-6] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 10.0 in stage 131.0 (TID 342, localhost, executor driver, partition 10, PROCESS_LOCAL, 7888 bytes)
2021-12-08 10:41:14,426 [dispatcher-event-loop-6] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 11.0 in stage 131.0 (TID 343, localhost, executor driver, partition 11, PROCESS_LOCAL, 7888 bytes)
2021-12-08 10:41:14,426 [Executor task launch worker for task 333] INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 131.0 (TID 333)
2021-12-08 10:41:14,426 [Executor task launch worker for task 337] INFO [org.apache.spark.executor.Executor] - Running task 5.0 in stage 131.0 (TID 337)
2021-12-08 10:41:14,426 [Executor task launch worker for task 343] INFO [org.apache.spark.executor.Executor] - Running task 11.0 in stage 131.0 (TID 343)
2021-12-08 10:41:14,426 [Executor task launch worker for task 342] INFO [org.apache.spark.executor.Executor] - Running task 10.0 in stage 131.0 (TID 342)
2021-12-08 10:41:14,426 [Executor task launch worker for task 341] INFO [org.apache.spark.executor.Executor] - Running task 9.0 in stage 131.0 (TID 341)
2021-12-08 10:41:14,426 [Executor task launch worker for task 340] INFO [org.apache.spark.executor.Executor] - Running task 8.0 in stage 131.0 (TID 340)
2021-12-08 10:41:14,426 [Executor task launch worker for task 332] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 131.0 (TID 332)
2021-12-08 10:41:14,426 [Executor task launch worker for task 339] INFO [org.apache.spark.executor.Executor] - Running task 7.0 in stage 131.0 (TID 339)
2021-12-08 10:41:14,426 [Executor task launch worker for task 335] INFO [org.apache.spark.executor.Executor] - Running task 3.0 in stage 131.0 (TID 335)
2021-12-08 10:41:14,426 [Executor task launch worker for task 336] INFO [org.apache.spark.executor.Executor] - Running task 4.0 in stage 131.0 (TID 336)
2021-12-08 10:41:14,426 [Executor task launch worker for task 338] INFO [org.apache.spark.executor.Executor] - Running task 6.0 in stage 131.0 (TID 338)
2021-12-08 10:41:14,426 [Executor task launch worker for task 334] INFO [org.apache.spark.executor.Executor] - Running task 2.0 in stage 131.0 (TID 334)
2021-12-08 10:41:14,430 [Executor task launch worker for task 336] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_14_4 locally
2021-12-08 10:41:14,430 [Executor task launch worker for task 341] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_14_9 locally
2021-12-08 10:41:14,430 [Executor task launch worker for task 343] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_14_11 locally
2021-12-08 10:41:14,430 [Executor task launch worker for task 337] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_14_5 locally
2021-12-08 10:41:14,431 [Executor task launch worker for task 339] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_14_7 locally
2021-12-08 10:41:14,431 [Executor task launch worker for task 337] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 12 non-empty blocks out of 12 blocks
2021-12-08 10:41:14,431 [Executor task launch worker for task 333] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_14_1 locally
2021-12-08 10:41:14,430 [Executor task launch worker for task 336] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 12 non-empty blocks out of 12 blocks
2021-12-08 10:41:14,431 [Executor task launch worker for task 336] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 1 ms
2021-12-08 10:41:14,431 [Executor task launch worker for task 335] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_14_3 locally
2021-12-08 10:41:14,431 [Executor task launch worker for task 337] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-08 10:41:14,431 [Executor task launch worker for task 334] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_14_2 locally
2021-12-08 10:41:14,431 [Executor task launch worker for task 341] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 12 non-empty blocks out of 12 blocks
2021-12-08 10:41:14,431 [Executor task launch worker for task 343] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 12 non-empty blocks out of 12 blocks
2021-12-08 10:41:14,431 [Executor task launch worker for task 339] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 12 non-empty blocks out of 12 blocks
2021-12-08 10:41:14,431 [Executor task launch worker for task 343] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-08 10:41:14,431 [Executor task launch worker for task 334] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 12 non-empty blocks out of 12 blocks
2021-12-08 10:41:14,431 [Executor task launch worker for task 341] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-08 10:41:14,431 [Executor task launch worker for task 332] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_14_0 locally
2021-12-08 10:41:14,431 [Executor task launch worker for task 334] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-08 10:41:14,431 [Executor task launch worker for task 333] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 12 non-empty blocks out of 12 blocks
2021-12-08 10:41:14,431 [Executor task launch worker for task 339] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-08 10:41:14,431 [Executor task launch worker for task 333] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-08 10:41:14,431 [Executor task launch worker for task 335] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 12 non-empty blocks out of 12 blocks
2021-12-08 10:41:14,431 [Executor task launch worker for task 335] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-08 10:41:14,431 [Executor task launch worker for task 332] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 12 non-empty blocks out of 12 blocks
2021-12-08 10:41:14,431 [Executor task launch worker for task 332] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-08 10:41:14,432 [Executor task launch worker for task 338] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_14_6 locally
2021-12-08 10:41:14,432 [Executor task launch worker for task 340] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_14_8 locally
2021-12-08 10:41:14,432 [Executor task launch worker for task 338] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 12 non-empty blocks out of 12 blocks
2021-12-08 10:41:14,432 [Executor task launch worker for task 338] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-08 10:41:14,432 [Executor task launch worker for task 340] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 12 non-empty blocks out of 12 blocks
2021-12-08 10:41:14,432 [Executor task launch worker for task 340] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-08 10:41:14,432 [Executor task launch worker for task 342] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_14_10 locally
2021-12-08 10:41:14,432 [Executor task launch worker for task 342] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 12 non-empty blocks out of 12 blocks
2021-12-08 10:41:14,432 [Executor task launch worker for task 342] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-08 10:41:14,661 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 635
2021-12-08 10:41:14,662 [dispatcher-event-loop-4] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_30_piece0 on qb:55657 in memory (size: 1582.4 KB, free: 1664.8 MB)
2021-12-08 10:41:14,663 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 639
2021-12-08 10:41:14,663 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 680
2021-12-08 10:41:14,663 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 715
2021-12-08 10:41:14,663 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 708
2021-12-08 10:41:14,663 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 720
2021-12-08 10:41:14,663 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 657
2021-12-08 10:41:14,663 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 667
2021-12-08 10:41:14,663 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 654
2021-12-08 10:41:14,663 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 710
2021-12-08 10:41:14,663 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 690
2021-12-08 10:41:14,663 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 660
2021-12-08 10:41:14,663 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 699
2021-12-08 10:41:14,663 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 634
2021-12-08 10:41:14,663 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 640
2021-12-08 10:41:14,663 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 689
2021-12-08 10:41:14,663 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 684
2021-12-08 10:41:14,663 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 663
2021-12-08 10:41:14,663 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 674
2021-12-08 10:41:14,663 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 679
2021-12-08 10:41:14,663 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 681
2021-12-08 10:41:14,663 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 709
2021-12-08 10:41:14,663 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 691
2021-12-08 10:41:14,663 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 676
2021-12-08 10:41:14,663 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 704
2021-12-08 10:41:14,663 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 673
2021-12-08 10:41:14,663 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 701
2021-12-08 10:41:14,663 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 630
2021-12-08 10:41:14,663 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 632
2021-12-08 10:41:14,663 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 724
2021-12-08 10:41:14,663 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 655
2021-12-08 10:41:14,663 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 675
2021-12-08 10:41:14,663 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 648
2021-12-08 10:41:14,663 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 661
2021-12-08 10:41:14,663 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 653
2021-12-08 10:41:14,663 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 677
2021-12-08 10:41:14,663 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 682
2021-12-08 10:41:14,663 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 662
2021-12-08 10:41:14,663 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 658
2021-12-08 10:41:14,663 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 638
2021-12-08 10:41:14,663 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 686
2021-12-08 10:41:14,663 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 703
2021-12-08 10:41:14,663 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 647
2021-12-08 10:41:14,663 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 637
2021-12-08 10:41:14,663 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 641
2021-12-08 10:41:14,663 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 718
2021-12-08 10:41:14,663 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 666
2021-12-08 10:41:14,663 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 717
2021-12-08 10:41:14,663 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 665
2021-12-08 10:41:14,663 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 698
2021-12-08 10:41:14,663 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 670
2021-12-08 10:41:14,663 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 649
2021-12-08 10:41:14,663 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 642
2021-12-08 10:41:14,663 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 687
2021-12-08 10:41:14,664 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 697
2021-12-08 10:41:14,664 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 626
2021-12-08 10:41:14,664 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 643
2021-12-08 10:41:14,664 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 636
2021-12-08 10:41:14,664 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 700
2021-12-08 10:41:14,664 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 633
2021-12-08 10:41:14,664 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 671
2021-12-08 10:41:14,664 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 651
2021-12-08 10:41:14,664 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 716
2021-12-08 10:41:14,664 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 656
2021-12-08 10:41:14,664 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 707
2021-12-08 10:41:14,664 [dispatcher-event-loop-7] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_29_piece0 on qb:55657 in memory (size: 1583.4 KB, free: 1666.4 MB)
2021-12-08 10:41:14,665 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 650
2021-12-08 10:41:14,665 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 669
2021-12-08 10:41:14,665 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 629
2021-12-08 10:41:14,665 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 644
2021-12-08 10:41:14,665 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 685
2021-12-08 10:41:14,665 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 722
2021-12-08 10:41:14,665 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 628
2021-12-08 10:41:14,665 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 692
2021-12-08 10:41:14,665 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 695
2021-12-08 10:41:14,665 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 672
2021-12-08 10:41:14,665 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 678
2021-12-08 10:41:14,666 [dispatcher-event-loop-0] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_27_piece0 on qb:55657 in memory (size: 1425.7 KB, free: 1667.8 MB)
2021-12-08 10:41:14,666 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 645
2021-12-08 10:41:14,666 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 702
2021-12-08 10:41:14,666 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 712
2021-12-08 10:41:14,666 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 659
2021-12-08 10:41:14,666 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 693
2021-12-08 10:41:14,666 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 721
2021-12-08 10:41:14,666 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 705
2021-12-08 10:41:14,666 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 627
2021-12-08 10:41:14,666 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 719
2021-12-08 10:41:14,666 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 713
2021-12-08 10:41:14,666 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 723
2021-12-08 10:41:14,666 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 668
2021-12-08 10:41:14,666 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 694
2021-12-08 10:41:14,666 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 652
2021-12-08 10:41:14,666 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 664
2021-12-08 10:41:14,666 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 706
2021-12-08 10:41:14,666 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 683
2021-12-08 10:41:14,666 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 646
2021-12-08 10:41:14,666 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 696
2021-12-08 10:41:14,666 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 631
2021-12-08 10:41:14,666 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 714
2021-12-08 10:41:14,666 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 625
2021-12-08 10:41:14,666 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 711
2021-12-08 10:41:14,666 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 688
2021-12-08 10:41:35,651 [Executor task launch worker for task 333] INFO [org.apache.spark.storage.memory.MemoryStore] - Block rdd_127_1 stored as values in memory (estimated size 4.0 MB, free 1661.6 MB)
2021-12-08 10:41:35,651 [dispatcher-event-loop-3] INFO [org.apache.spark.storage.BlockManagerInfo] - Added rdd_127_1 in memory on qb:55657 (size: 4.0 MB, free: 1663.8 MB)
2021-12-08 10:41:35,774 [Executor task launch worker for task 333] INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 131.0 (TID 333). 166097 bytes result sent to driver
2021-12-08 10:41:35,775 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 131.0 (TID 333) in 21350 ms on localhost (executor driver) (1/12)
2021-12-08 10:41:36,639 [Executor task launch worker for task 332] INFO [org.apache.spark.storage.memory.MemoryStore] - Block rdd_127_0 stored as values in memory (estimated size 4.0 MB, free 1657.6 MB)
2021-12-08 10:41:36,639 [dispatcher-event-loop-11] INFO [org.apache.spark.storage.BlockManagerInfo] - Added rdd_127_0 in memory on qb:55657 (size: 4.0 MB, free: 1659.8 MB)
2021-12-08 10:41:36,765 [Executor task launch worker for task 332] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 131.0 (TID 332). 166097 bytes result sent to driver
2021-12-08 10:41:36,765 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 131.0 (TID 332) in 22340 ms on localhost (executor driver) (2/12)
2021-12-08 10:41:36,842 [Executor task launch worker for task 340] INFO [org.apache.spark.storage.memory.MemoryStore] - Block rdd_127_8 stored as values in memory (estimated size 4.0 MB, free 1653.6 MB)
2021-12-08 10:41:36,843 [dispatcher-event-loop-7] INFO [org.apache.spark.storage.BlockManagerInfo] - Added rdd_127_8 in memory on qb:55657 (size: 4.0 MB, free: 1655.8 MB)
2021-12-08 10:41:36,889 [Executor task launch worker for task 342] INFO [org.apache.spark.storage.memory.MemoryStore] - Block rdd_127_10 stored as values in memory (estimated size 4.0 MB, free 1649.6 MB)
2021-12-08 10:41:36,890 [dispatcher-event-loop-8] INFO [org.apache.spark.storage.BlockManagerInfo] - Added rdd_127_10 in memory on qb:55657 (size: 4.0 MB, free: 1651.8 MB)
2021-12-08 10:41:36,961 [Executor task launch worker for task 340] INFO [org.apache.spark.executor.Executor] - Finished task 8.0 in stage 131.0 (TID 340). 166097 bytes result sent to driver
2021-12-08 10:41:36,962 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 8.0 in stage 131.0 (TID 340) in 22536 ms on localhost (executor driver) (3/12)
2021-12-08 10:41:37,009 [Executor task launch worker for task 342] INFO [org.apache.spark.executor.Executor] - Finished task 10.0 in stage 131.0 (TID 342). 166054 bytes result sent to driver
2021-12-08 10:41:37,010 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 10.0 in stage 131.0 (TID 342) in 22584 ms on localhost (executor driver) (4/12)
2021-12-08 10:41:37,519 [Executor task launch worker for task 337] INFO [org.apache.spark.storage.memory.MemoryStore] - Block rdd_127_5 stored as values in memory (estimated size 4.0 MB, free 1645.6 MB)
2021-12-08 10:41:37,519 [dispatcher-event-loop-2] INFO [org.apache.spark.storage.BlockManagerInfo] - Added rdd_127_5 in memory on qb:55657 (size: 4.0 MB, free: 1647.8 MB)
2021-12-08 10:41:37,607 [Executor task launch worker for task 337] INFO [org.apache.spark.executor.Executor] - Finished task 5.0 in stage 131.0 (TID 337). 166097 bytes result sent to driver
2021-12-08 10:41:37,608 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 5.0 in stage 131.0 (TID 337) in 23182 ms on localhost (executor driver) (5/12)
2021-12-08 10:41:37,887 [Executor task launch worker for task 341] INFO [org.apache.spark.storage.memory.MemoryStore] - Block rdd_127_9 stored as values in memory (estimated size 4.0 MB, free 1641.7 MB)
2021-12-08 10:41:37,888 [dispatcher-event-loop-6] INFO [org.apache.spark.storage.BlockManagerInfo] - Added rdd_127_9 in memory on qb:55657 (size: 4.0 MB, free: 1643.9 MB)
2021-12-08 10:41:37,962 [Executor task launch worker for task 341] INFO [org.apache.spark.executor.Executor] - Finished task 9.0 in stage 131.0 (TID 341). 166097 bytes result sent to driver
2021-12-08 10:41:37,962 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 9.0 in stage 131.0 (TID 341) in 23536 ms on localhost (executor driver) (6/12)
2021-12-08 10:41:37,979 [Executor task launch worker for task 336] INFO [org.apache.spark.storage.memory.MemoryStore] - Block rdd_127_4 stored as values in memory (estimated size 4.0 MB, free 1637.7 MB)
2021-12-08 10:41:37,979 [dispatcher-event-loop-3] INFO [org.apache.spark.storage.BlockManagerInfo] - Added rdd_127_4 in memory on qb:55657 (size: 4.0 MB, free: 1639.9 MB)
2021-12-08 10:41:38,065 [Executor task launch worker for task 336] INFO [org.apache.spark.executor.Executor] - Finished task 4.0 in stage 131.0 (TID 336). 166097 bytes result sent to driver
2021-12-08 10:41:38,065 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 4.0 in stage 131.0 (TID 336) in 23639 ms on localhost (executor driver) (7/12)
2021-12-08 10:41:38,245 [Executor task launch worker for task 343] INFO [org.apache.spark.storage.memory.MemoryStore] - Block rdd_127_11 stored as values in memory (estimated size 4.0 MB, free 1633.7 MB)
2021-12-08 10:41:38,245 [dispatcher-event-loop-11] INFO [org.apache.spark.storage.BlockManagerInfo] - Added rdd_127_11 in memory on qb:55657 (size: 4.0 MB, free: 1635.9 MB)
2021-12-08 10:41:38,308 [Executor task launch worker for task 343] INFO [org.apache.spark.executor.Executor] - Finished task 11.0 in stage 131.0 (TID 343). 166097 bytes result sent to driver
2021-12-08 10:41:38,309 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 11.0 in stage 131.0 (TID 343) in 23883 ms on localhost (executor driver) (8/12)
2021-12-08 10:41:38,311 [Executor task launch worker for task 335] INFO [org.apache.spark.storage.memory.MemoryStore] - Block rdd_127_3 stored as values in memory (estimated size 4.0 MB, free 1629.7 MB)
2021-12-08 10:41:38,311 [dispatcher-event-loop-7] INFO [org.apache.spark.storage.BlockManagerInfo] - Added rdd_127_3 in memory on qb:55657 (size: 4.0 MB, free: 1631.9 MB)
2021-12-08 10:41:38,387 [Executor task launch worker for task 335] INFO [org.apache.spark.executor.Executor] - Finished task 3.0 in stage 131.0 (TID 335). 166097 bytes result sent to driver
2021-12-08 10:41:38,387 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 3.0 in stage 131.0 (TID 335) in 23962 ms on localhost (executor driver) (9/12)
2021-12-08 10:41:38,545 [Executor task launch worker for task 339] INFO [org.apache.spark.storage.memory.MemoryStore] - Block rdd_127_7 stored as values in memory (estimated size 4.0 MB, free 1625.7 MB)
2021-12-08 10:41:38,546 [dispatcher-event-loop-10] INFO [org.apache.spark.storage.BlockManagerInfo] - Added rdd_127_7 in memory on qb:55657 (size: 4.0 MB, free: 1627.9 MB)
2021-12-08 10:41:38,608 [Executor task launch worker for task 339] INFO [org.apache.spark.executor.Executor] - Finished task 7.0 in stage 131.0 (TID 339). 166097 bytes result sent to driver
2021-12-08 10:41:38,608 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 7.0 in stage 131.0 (TID 339) in 24182 ms on localhost (executor driver) (10/12)
2021-12-08 10:41:38,617 [Executor task launch worker for task 338] INFO [org.apache.spark.storage.memory.MemoryStore] - Block rdd_127_6 stored as values in memory (estimated size 4.0 MB, free 1621.7 MB)
2021-12-08 10:41:38,618 [dispatcher-event-loop-2] INFO [org.apache.spark.storage.BlockManagerInfo] - Added rdd_127_6 in memory on qb:55657 (size: 4.0 MB, free: 1623.9 MB)
2021-12-08 10:41:38,687 [Executor task launch worker for task 338] INFO [org.apache.spark.executor.Executor] - Finished task 6.0 in stage 131.0 (TID 338). 166097 bytes result sent to driver
2021-12-08 10:41:38,688 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 6.0 in stage 131.0 (TID 338) in 24262 ms on localhost (executor driver) (11/12)
2021-12-08 10:41:39,843 [Executor task launch worker for task 334] INFO [org.apache.spark.storage.memory.MemoryStore] - Block rdd_127_2 stored as values in memory (estimated size 4.0 MB, free 1617.7 MB)
2021-12-08 10:41:39,844 [dispatcher-event-loop-3] INFO [org.apache.spark.storage.BlockManagerInfo] - Added rdd_127_2 in memory on qb:55657 (size: 4.0 MB, free: 1619.9 MB)
2021-12-08 10:41:39,913 [Executor task launch worker for task 334] INFO [org.apache.spark.executor.Executor] - Finished task 2.0 in stage 131.0 (TID 334). 166097 bytes result sent to driver
2021-12-08 10:41:39,914 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 2.0 in stage 131.0 (TID 334) in 25489 ms on localhost (executor driver) (12/12)
2021-12-08 10:41:39,914 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 131.0, whose tasks have all completed, from pool 
2021-12-08 10:41:39,914 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 131 (aggregate at ALS.scala:1711) finished in 25.495 s
2021-12-08 10:41:39,914 [main] INFO [org.apache.spark.scheduler.DAGScheduler] - Job 15 finished: aggregate at ALS.scala:1711, took 28.933189 s
2021-12-08 10:41:39,928 [main] INFO [org.apache.spark.rdd.MapPartitionsRDD] - Removing RDD 117 from persistence list
2021-12-08 10:41:39,929 [block-manager-slave-async-thread-pool-1] INFO [org.apache.spark.storage.BlockManager] - Removing RDD 117
2021-12-08 10:41:39,935 [main] INFO [org.apache.spark.SparkContext] - Starting job: aggregate at ALS.scala:1711
2021-12-08 10:41:39,936 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 132 (flatMap at ALS.scala:1653)
2021-12-08 10:41:39,936 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 16 (aggregate at ALS.scala:1711) with 12 output partitions
2021-12-08 10:41:39,936 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 148 (aggregate at ALS.scala:1711)
2021-12-08 10:41:39,936 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 147, ShuffleMapStage 133)
2021-12-08 10:41:39,936 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List(ShuffleMapStage 147)
2021-12-08 10:41:39,937 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ShuffleMapStage 147 (MapPartitionsRDD[132] at flatMap at ALS.scala:1653), which has no missing parents
2021-12-08 10:41:39,939 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_32 stored as values in memory (estimated size 1783.1 KB, free 1749.2 MB)
2021-12-08 10:41:39,942 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_32_piece0 stored as bytes in memory (estimated size 1740.1 KB, free 1747.5 MB)
2021-12-08 10:41:39,942 [dispatcher-event-loop-2] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_32_piece0 in memory on qb:55657 (size: 1740.1 KB, free: 1751.5 MB)
2021-12-08 10:41:39,942 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 32 from broadcast at DAGScheduler.scala:1039
2021-12-08 10:41:39,942 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 12 missing tasks from ShuffleMapStage 147 (MapPartitionsRDD[132] at flatMap at ALS.scala:1653) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11))
2021-12-08 10:41:39,942 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 147.0 with 12 tasks
2021-12-08 10:41:39,943 [dispatcher-event-loop-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 147.0 (TID 344, localhost, executor driver, partition 0, PROCESS_LOCAL, 7928 bytes)
2021-12-08 10:41:39,943 [dispatcher-event-loop-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 147.0 (TID 345, localhost, executor driver, partition 1, PROCESS_LOCAL, 7928 bytes)
2021-12-08 10:41:39,943 [dispatcher-event-loop-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 2.0 in stage 147.0 (TID 346, localhost, executor driver, partition 2, PROCESS_LOCAL, 7928 bytes)
2021-12-08 10:41:39,943 [dispatcher-event-loop-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 3.0 in stage 147.0 (TID 347, localhost, executor driver, partition 3, PROCESS_LOCAL, 7928 bytes)
2021-12-08 10:41:39,943 [dispatcher-event-loop-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 4.0 in stage 147.0 (TID 348, localhost, executor driver, partition 4, PROCESS_LOCAL, 7928 bytes)
2021-12-08 10:41:39,943 [dispatcher-event-loop-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 5.0 in stage 147.0 (TID 349, localhost, executor driver, partition 5, PROCESS_LOCAL, 7928 bytes)
2021-12-08 10:41:39,943 [dispatcher-event-loop-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 6.0 in stage 147.0 (TID 350, localhost, executor driver, partition 6, PROCESS_LOCAL, 7928 bytes)
2021-12-08 10:41:39,943 [dispatcher-event-loop-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 7.0 in stage 147.0 (TID 351, localhost, executor driver, partition 7, PROCESS_LOCAL, 7928 bytes)
2021-12-08 10:41:39,943 [dispatcher-event-loop-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 8.0 in stage 147.0 (TID 352, localhost, executor driver, partition 8, PROCESS_LOCAL, 7928 bytes)
2021-12-08 10:41:39,943 [dispatcher-event-loop-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 9.0 in stage 147.0 (TID 353, localhost, executor driver, partition 9, PROCESS_LOCAL, 7928 bytes)
2021-12-08 10:41:39,943 [dispatcher-event-loop-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 10.0 in stage 147.0 (TID 354, localhost, executor driver, partition 10, PROCESS_LOCAL, 7928 bytes)
2021-12-08 10:41:39,943 [dispatcher-event-loop-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 11.0 in stage 147.0 (TID 355, localhost, executor driver, partition 11, PROCESS_LOCAL, 7928 bytes)
2021-12-08 10:41:39,943 [Executor task launch worker for task 348] INFO [org.apache.spark.executor.Executor] - Running task 4.0 in stage 147.0 (TID 348)
2021-12-08 10:41:39,943 [Executor task launch worker for task 352] INFO [org.apache.spark.executor.Executor] - Running task 8.0 in stage 147.0 (TID 352)
2021-12-08 10:41:39,943 [Executor task launch worker for task 346] INFO [org.apache.spark.executor.Executor] - Running task 2.0 in stage 147.0 (TID 346)
2021-12-08 10:41:39,943 [Executor task launch worker for task 349] INFO [org.apache.spark.executor.Executor] - Running task 5.0 in stage 147.0 (TID 349)
2021-12-08 10:41:39,943 [Executor task launch worker for task 355] INFO [org.apache.spark.executor.Executor] - Running task 11.0 in stage 147.0 (TID 355)
2021-12-08 10:41:39,943 [Executor task launch worker for task 353] INFO [org.apache.spark.executor.Executor] - Running task 9.0 in stage 147.0 (TID 353)
2021-12-08 10:41:39,943 [Executor task launch worker for task 350] INFO [org.apache.spark.executor.Executor] - Running task 6.0 in stage 147.0 (TID 350)
2021-12-08 10:41:39,943 [Executor task launch worker for task 351] INFO [org.apache.spark.executor.Executor] - Running task 7.0 in stage 147.0 (TID 351)
2021-12-08 10:41:39,943 [Executor task launch worker for task 347] INFO [org.apache.spark.executor.Executor] - Running task 3.0 in stage 147.0 (TID 347)
2021-12-08 10:41:39,943 [Executor task launch worker for task 354] INFO [org.apache.spark.executor.Executor] - Running task 10.0 in stage 147.0 (TID 354)
2021-12-08 10:41:39,943 [Executor task launch worker for task 345] INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 147.0 (TID 345)
2021-12-08 10:41:39,943 [Executor task launch worker for task 344] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 147.0 (TID 344)
2021-12-08 10:41:39,947 [Executor task launch worker for task 349] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_15_5 locally
2021-12-08 10:41:39,947 [Executor task launch worker for task 349] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_127_5 locally
2021-12-08 10:41:39,947 [Executor task launch worker for task 345] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_15_1 locally
2021-12-08 10:41:39,947 [Executor task launch worker for task 345] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_127_1 locally
2021-12-08 10:41:39,947 [Executor task launch worker for task 346] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_15_2 locally
2021-12-08 10:41:39,947 [Executor task launch worker for task 352] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_15_8 locally
2021-12-08 10:41:39,947 [Executor task launch worker for task 351] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_15_7 locally
2021-12-08 10:41:39,947 [Executor task launch worker for task 344] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_15_0 locally
2021-12-08 10:41:39,947 [Executor task launch worker for task 344] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_127_0 locally
2021-12-08 10:41:39,947 [Executor task launch worker for task 347] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_15_3 locally
2021-12-08 10:41:39,947 [Executor task launch worker for task 353] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_15_9 locally
2021-12-08 10:41:39,947 [Executor task launch worker for task 346] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_127_2 locally
2021-12-08 10:41:39,947 [Executor task launch worker for task 348] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_15_4 locally
2021-12-08 10:41:39,947 [Executor task launch worker for task 350] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_15_6 locally
2021-12-08 10:41:39,948 [Executor task launch worker for task 354] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_15_10 locally
2021-12-08 10:41:39,948 [Executor task launch worker for task 354] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_127_10 locally
2021-12-08 10:41:39,948 [Executor task launch worker for task 347] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_127_3 locally
2021-12-08 10:41:39,948 [Executor task launch worker for task 351] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_127_7 locally
2021-12-08 10:41:39,948 [Executor task launch worker for task 353] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_127_9 locally
2021-12-08 10:41:39,948 [Executor task launch worker for task 350] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_127_6 locally
2021-12-08 10:41:39,948 [Executor task launch worker for task 348] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_127_4 locally
2021-12-08 10:41:39,948 [Executor task launch worker for task 352] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_127_8 locally
2021-12-08 10:41:39,950 [Executor task launch worker for task 355] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_15_11 locally
2021-12-08 10:41:39,950 [Executor task launch worker for task 355] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_127_11 locally
2021-12-08 10:41:40,155 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 768
2021-12-08 10:41:40,155 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 728
2021-12-08 10:41:40,155 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 774
2021-12-08 10:41:40,155 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 773
2021-12-08 10:41:40,155 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 732
2021-12-08 10:41:40,155 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 756
2021-12-08 10:41:40,155 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 767
2021-12-08 10:41:40,155 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 737
2021-12-08 10:41:40,155 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 754
2021-12-08 10:41:40,157 [dispatcher-event-loop-5] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_31_piece0 on qb:55657 in memory (size: 1741.1 KB, free: 1753.2 MB)
2021-12-08 10:41:40,157 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 761
2021-12-08 10:41:40,157 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 763
2021-12-08 10:41:40,157 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 751
2021-12-08 10:41:40,157 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 739
2021-12-08 10:41:40,157 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 772
2021-12-08 10:41:40,157 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 734
2021-12-08 10:41:40,157 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 740
2021-12-08 10:41:40,157 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 759
2021-12-08 10:41:40,157 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 743
2021-12-08 10:41:40,157 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 741
2021-12-08 10:41:40,157 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 744
2021-12-08 10:41:40,157 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 760
2021-12-08 10:41:40,157 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 746
2021-12-08 10:41:40,157 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 771
2021-12-08 10:41:40,157 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 766
2021-12-08 10:41:40,157 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 729
2021-12-08 10:41:40,157 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 731
2021-12-08 10:41:40,157 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 750
2021-12-08 10:41:40,157 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 757
2021-12-08 10:41:40,157 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 755
2021-12-08 10:41:40,157 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 730
2021-12-08 10:41:40,157 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 748
2021-12-08 10:41:40,157 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 736
2021-12-08 10:41:40,157 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 769
2021-12-08 10:41:40,157 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 762
2021-12-08 10:41:40,157 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 727
2021-12-08 10:41:40,157 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 765
2021-12-08 10:41:40,157 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 733
2021-12-08 10:41:40,157 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 735
2021-12-08 10:41:40,157 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 725
2021-12-08 10:41:40,157 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 747
2021-12-08 10:41:40,157 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 770
2021-12-08 10:41:40,157 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 738
2021-12-08 10:41:40,157 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 764
2021-12-08 10:41:40,157 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 752
2021-12-08 10:41:40,157 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 726
2021-12-08 10:41:40,157 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 745
2021-12-08 10:41:40,157 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 742
2021-12-08 10:41:40,157 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 749
2021-12-08 10:41:40,158 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 753
2021-12-08 10:41:40,158 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 758
2021-12-08 10:41:41,042 [Executor task launch worker for task 349] INFO [org.apache.spark.executor.Executor] - Finished task 5.0 in stage 147.0 (TID 349). 1042 bytes result sent to driver
2021-12-08 10:41:41,042 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 5.0 in stage 147.0 (TID 349) in 1099 ms on localhost (executor driver) (1/12)
2021-12-08 10:41:41,047 [Executor task launch worker for task 351] INFO [org.apache.spark.executor.Executor] - Finished task 7.0 in stage 147.0 (TID 351). 1085 bytes result sent to driver
2021-12-08 10:41:41,047 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 7.0 in stage 147.0 (TID 351) in 1104 ms on localhost (executor driver) (2/12)
2021-12-08 10:41:41,049 [Executor task launch worker for task 346] INFO [org.apache.spark.executor.Executor] - Finished task 2.0 in stage 147.0 (TID 346). 1042 bytes result sent to driver
2021-12-08 10:41:41,049 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 2.0 in stage 147.0 (TID 346) in 1106 ms on localhost (executor driver) (3/12)
2021-12-08 10:41:41,055 [Executor task launch worker for task 353] INFO [org.apache.spark.executor.Executor] - Finished task 9.0 in stage 147.0 (TID 353). 1085 bytes result sent to driver
2021-12-08 10:41:41,056 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 9.0 in stage 147.0 (TID 353) in 1113 ms on localhost (executor driver) (4/12)
2021-12-08 10:41:41,057 [Executor task launch worker for task 347] INFO [org.apache.spark.executor.Executor] - Finished task 3.0 in stage 147.0 (TID 347). 1085 bytes result sent to driver
2021-12-08 10:41:41,057 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 3.0 in stage 147.0 (TID 347) in 1114 ms on localhost (executor driver) (5/12)
2021-12-08 10:41:41,064 [Executor task launch worker for task 352] INFO [org.apache.spark.executor.Executor] - Finished task 8.0 in stage 147.0 (TID 352). 1042 bytes result sent to driver
2021-12-08 10:41:41,064 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 8.0 in stage 147.0 (TID 352) in 1121 ms on localhost (executor driver) (6/12)
2021-12-08 10:41:41,072 [Executor task launch worker for task 345] INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 147.0 (TID 345). 1042 bytes result sent to driver
2021-12-08 10:41:41,073 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 147.0 (TID 345) in 1130 ms on localhost (executor driver) (7/12)
2021-12-08 10:41:41,075 [Executor task launch worker for task 355] INFO [org.apache.spark.executor.Executor] - Finished task 11.0 in stage 147.0 (TID 355). 1085 bytes result sent to driver
2021-12-08 10:41:41,075 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 11.0 in stage 147.0 (TID 355) in 1132 ms on localhost (executor driver) (8/12)
2021-12-08 10:41:41,090 [Executor task launch worker for task 350] INFO [org.apache.spark.executor.Executor] - Finished task 6.0 in stage 147.0 (TID 350). 1085 bytes result sent to driver
2021-12-08 10:41:41,090 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 6.0 in stage 147.0 (TID 350) in 1147 ms on localhost (executor driver) (9/12)
2021-12-08 10:41:41,107 [Executor task launch worker for task 344] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 147.0 (TID 344). 1042 bytes result sent to driver
2021-12-08 10:41:41,107 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 147.0 (TID 344) in 1164 ms on localhost (executor driver) (10/12)
2021-12-08 10:41:41,109 [Executor task launch worker for task 354] INFO [org.apache.spark.executor.Executor] - Finished task 10.0 in stage 147.0 (TID 354). 1042 bytes result sent to driver
2021-12-08 10:41:41,109 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 10.0 in stage 147.0 (TID 354) in 1166 ms on localhost (executor driver) (11/12)
2021-12-08 10:41:41,149 [Executor task launch worker for task 348] INFO [org.apache.spark.executor.Executor] - Finished task 4.0 in stage 147.0 (TID 348). 1042 bytes result sent to driver
2021-12-08 10:41:41,149 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 4.0 in stage 147.0 (TID 348) in 1206 ms on localhost (executor driver) (12/12)
2021-12-08 10:41:41,149 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 147.0, whose tasks have all completed, from pool 
2021-12-08 10:41:41,149 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ShuffleMapStage 147 (flatMap at ALS.scala:1653) finished in 1.212 s
2021-12-08 10:41:41,149 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - looking for newly runnable stages
2021-12-08 10:41:41,149 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - running: Set()
2021-12-08 10:41:41,149 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - waiting: Set(ResultStage 148)
2021-12-08 10:41:41,149 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - failed: Set()
2021-12-08 10:41:41,149 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 148 (MapPartitionsRDD[138] at values at ALS.scala:1711), which has no missing parents
2021-12-08 10:41:41,152 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_33 stored as values in memory (estimated size 2.1 MB, free 1749.1 MB)
2021-12-08 10:41:41,155 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_33_piece0 stored as bytes in memory (estimated size 1898.9 KB, free 1747.2 MB)
2021-12-08 10:41:41,156 [dispatcher-event-loop-9] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_33_piece0 in memory on qb:55657 (size: 1898.9 KB, free: 1751.3 MB)
2021-12-08 10:41:41,156 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 33 from broadcast at DAGScheduler.scala:1039
2021-12-08 10:41:41,156 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 12 missing tasks from ResultStage 148 (MapPartitionsRDD[138] at values at ALS.scala:1711) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11))
2021-12-08 10:41:41,156 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 148.0 with 12 tasks
2021-12-08 10:41:41,156 [dispatcher-event-loop-7] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 148.0 (TID 356, localhost, executor driver, partition 0, PROCESS_LOCAL, 7888 bytes)
2021-12-08 10:41:41,157 [dispatcher-event-loop-7] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 148.0 (TID 357, localhost, executor driver, partition 1, PROCESS_LOCAL, 7888 bytes)
2021-12-08 10:41:41,157 [dispatcher-event-loop-7] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 2.0 in stage 148.0 (TID 358, localhost, executor driver, partition 2, PROCESS_LOCAL, 7888 bytes)
2021-12-08 10:41:41,157 [dispatcher-event-loop-7] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 3.0 in stage 148.0 (TID 359, localhost, executor driver, partition 3, PROCESS_LOCAL, 7888 bytes)
2021-12-08 10:41:41,157 [dispatcher-event-loop-7] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 4.0 in stage 148.0 (TID 360, localhost, executor driver, partition 4, PROCESS_LOCAL, 7888 bytes)
2021-12-08 10:41:41,157 [dispatcher-event-loop-7] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 5.0 in stage 148.0 (TID 361, localhost, executor driver, partition 5, PROCESS_LOCAL, 7888 bytes)
2021-12-08 10:41:41,157 [dispatcher-event-loop-7] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 6.0 in stage 148.0 (TID 362, localhost, executor driver, partition 6, PROCESS_LOCAL, 7888 bytes)
2021-12-08 10:41:41,157 [dispatcher-event-loop-7] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 7.0 in stage 148.0 (TID 363, localhost, executor driver, partition 7, PROCESS_LOCAL, 7888 bytes)
2021-12-08 10:41:41,157 [dispatcher-event-loop-7] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 8.0 in stage 148.0 (TID 364, localhost, executor driver, partition 8, PROCESS_LOCAL, 7888 bytes)
2021-12-08 10:41:41,157 [dispatcher-event-loop-7] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 9.0 in stage 148.0 (TID 365, localhost, executor driver, partition 9, PROCESS_LOCAL, 7888 bytes)
2021-12-08 10:41:41,157 [dispatcher-event-loop-7] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 10.0 in stage 148.0 (TID 366, localhost, executor driver, partition 10, PROCESS_LOCAL, 7888 bytes)
2021-12-08 10:41:41,157 [dispatcher-event-loop-7] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 11.0 in stage 148.0 (TID 367, localhost, executor driver, partition 11, PROCESS_LOCAL, 7888 bytes)
2021-12-08 10:41:41,157 [Executor task launch worker for task 356] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 148.0 (TID 356)
2021-12-08 10:41:41,157 [Executor task launch worker for task 363] INFO [org.apache.spark.executor.Executor] - Running task 7.0 in stage 148.0 (TID 363)
2021-12-08 10:41:41,157 [Executor task launch worker for task 366] INFO [org.apache.spark.executor.Executor] - Running task 10.0 in stage 148.0 (TID 366)
2021-12-08 10:41:41,157 [Executor task launch worker for task 364] INFO [org.apache.spark.executor.Executor] - Running task 8.0 in stage 148.0 (TID 364)
2021-12-08 10:41:41,157 [Executor task launch worker for task 365] INFO [org.apache.spark.executor.Executor] - Running task 9.0 in stage 148.0 (TID 365)
2021-12-08 10:41:41,157 [Executor task launch worker for task 362] INFO [org.apache.spark.executor.Executor] - Running task 6.0 in stage 148.0 (TID 362)
2021-12-08 10:41:41,157 [Executor task launch worker for task 358] INFO [org.apache.spark.executor.Executor] - Running task 2.0 in stage 148.0 (TID 358)
2021-12-08 10:41:41,157 [Executor task launch worker for task 361] INFO [org.apache.spark.executor.Executor] - Running task 5.0 in stage 148.0 (TID 361)
2021-12-08 10:41:41,157 [Executor task launch worker for task 357] INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 148.0 (TID 357)
2021-12-08 10:41:41,157 [Executor task launch worker for task 360] INFO [org.apache.spark.executor.Executor] - Running task 4.0 in stage 148.0 (TID 360)
2021-12-08 10:41:41,157 [Executor task launch worker for task 359] INFO [org.apache.spark.executor.Executor] - Running task 3.0 in stage 148.0 (TID 359)
2021-12-08 10:41:41,157 [Executor task launch worker for task 367] INFO [org.apache.spark.executor.Executor] - Running task 11.0 in stage 148.0 (TID 367)
2021-12-08 10:41:41,161 [Executor task launch worker for task 358] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_9_2 locally
2021-12-08 10:41:41,161 [Executor task launch worker for task 356] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_9_0 locally
2021-12-08 10:41:41,161 [Executor task launch worker for task 360] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_9_4 locally
2021-12-08 10:41:41,161 [Executor task launch worker for task 361] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_9_5 locally
2021-12-08 10:41:41,161 [Executor task launch worker for task 362] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_9_6 locally
2021-12-08 10:41:41,161 [Executor task launch worker for task 359] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_9_3 locally
2021-12-08 10:41:41,161 [Executor task launch worker for task 365] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_9_9 locally
2021-12-08 10:41:41,162 [Executor task launch worker for task 364] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_9_8 locally
2021-12-08 10:41:41,162 [Executor task launch worker for task 359] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 12 non-empty blocks out of 12 blocks
2021-12-08 10:41:41,163 [Executor task launch worker for task 357] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_9_1 locally
2021-12-08 10:41:41,162 [Executor task launch worker for task 365] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 12 non-empty blocks out of 12 blocks
2021-12-08 10:41:41,162 [Executor task launch worker for task 356] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 12 non-empty blocks out of 12 blocks
2021-12-08 10:41:41,162 [Executor task launch worker for task 358] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 12 non-empty blocks out of 12 blocks
2021-12-08 10:41:41,162 [Executor task launch worker for task 362] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 12 non-empty blocks out of 12 blocks
2021-12-08 10:41:41,162 [Executor task launch worker for task 363] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_9_7 locally
2021-12-08 10:41:41,163 [Executor task launch worker for task 362] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 1 ms
2021-12-08 10:41:41,163 [Executor task launch worker for task 358] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 1 ms
2021-12-08 10:41:41,163 [Executor task launch worker for task 356] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 1 ms
2021-12-08 10:41:41,163 [Executor task launch worker for task 365] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 1 ms
2021-12-08 10:41:41,163 [Executor task launch worker for task 364] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 12 non-empty blocks out of 12 blocks
2021-12-08 10:41:41,163 [Executor task launch worker for task 364] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-08 10:41:41,163 [Executor task launch worker for task 357] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 12 non-empty blocks out of 12 blocks
2021-12-08 10:41:41,163 [Executor task launch worker for task 359] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 1 ms
2021-12-08 10:41:41,163 [Executor task launch worker for task 361] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 12 non-empty blocks out of 12 blocks
2021-12-08 10:41:41,163 [Executor task launch worker for task 357] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-08 10:41:41,163 [Executor task launch worker for task 360] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 12 non-empty blocks out of 12 blocks
2021-12-08 10:41:41,163 [Executor task launch worker for task 361] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-08 10:41:41,163 [Executor task launch worker for task 366] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_9_10 locally
2021-12-08 10:41:41,163 [Executor task launch worker for task 360] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-08 10:41:41,163 [Executor task launch worker for task 363] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 12 non-empty blocks out of 12 blocks
2021-12-08 10:41:41,163 [Executor task launch worker for task 363] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-08 10:41:41,163 [Executor task launch worker for task 366] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 12 non-empty blocks out of 12 blocks
2021-12-08 10:41:41,163 [Executor task launch worker for task 366] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-08 10:41:41,163 [Executor task launch worker for task 367] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_9_11 locally
2021-12-08 10:41:41,164 [Executor task launch worker for task 367] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 12 non-empty blocks out of 12 blocks
2021-12-08 10:41:41,164 [Executor task launch worker for task 367] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-08 10:42:18,721 [Executor task launch worker for task 364] INFO [org.apache.spark.storage.memory.MemoryStore] - Block rdd_137_8 stored as values in memory (estimated size 11.1 MB, free 1736.1 MB)
2021-12-08 10:42:18,722 [dispatcher-event-loop-9] INFO [org.apache.spark.storage.BlockManagerInfo] - Added rdd_137_8 in memory on qb:55657 (size: 11.1 MB, free: 1740.2 MB)
2021-12-08 10:42:18,738 [Executor task launch worker for task 359] INFO [org.apache.spark.storage.memory.MemoryStore] - Block rdd_137_3 stored as values in memory (estimated size 11.1 MB, free 1725.0 MB)
2021-12-08 10:42:18,738 [dispatcher-event-loop-10] INFO [org.apache.spark.storage.BlockManagerInfo] - Added rdd_137_3 in memory on qb:55657 (size: 11.1 MB, free: 1729.1 MB)
2021-12-08 10:42:18,755 [Executor task launch worker for task 360] INFO [org.apache.spark.storage.memory.MemoryStore] - Block rdd_137_4 stored as values in memory (estimated size 11.1 MB, free 1713.9 MB)
2021-12-08 10:42:18,756 [dispatcher-event-loop-7] INFO [org.apache.spark.storage.BlockManagerInfo] - Added rdd_137_4 in memory on qb:55657 (size: 11.1 MB, free: 1718.0 MB)
2021-12-08 10:42:19,062 [Executor task launch worker for task 364] INFO [org.apache.spark.executor.Executor] - Finished task 8.0 in stage 148.0 (TID 364). 166054 bytes result sent to driver
2021-12-08 10:42:19,066 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 8.0 in stage 148.0 (TID 364) in 37909 ms on localhost (executor driver) (1/12)
2021-12-08 10:42:19,077 [Executor task launch worker for task 359] INFO [org.apache.spark.executor.Executor] - Finished task 3.0 in stage 148.0 (TID 359). 166054 bytes result sent to driver
2021-12-08 10:42:19,077 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 3.0 in stage 148.0 (TID 359) in 37920 ms on localhost (executor driver) (2/12)
2021-12-08 10:42:19,095 [Executor task launch worker for task 360] INFO [org.apache.spark.executor.Executor] - Finished task 4.0 in stage 148.0 (TID 360). 166054 bytes result sent to driver
2021-12-08 10:42:19,097 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 4.0 in stage 148.0 (TID 360) in 37940 ms on localhost (executor driver) (3/12)
2021-12-08 10:42:19,178 [Executor task launch worker for task 362] INFO [org.apache.spark.storage.memory.MemoryStore] - Block rdd_137_6 stored as values in memory (estimated size 11.1 MB, free 1702.8 MB)
2021-12-08 10:42:19,178 [dispatcher-event-loop-1] INFO [org.apache.spark.storage.BlockManagerInfo] - Added rdd_137_6 in memory on qb:55657 (size: 11.1 MB, free: 1706.9 MB)
2021-12-08 10:42:19,309 [Executor task launch worker for task 361] INFO [org.apache.spark.storage.memory.MemoryStore] - Block rdd_137_5 stored as values in memory (estimated size 11.1 MB, free 1691.7 MB)
2021-12-08 10:42:19,310 [dispatcher-event-loop-6] INFO [org.apache.spark.storage.BlockManagerInfo] - Added rdd_137_5 in memory on qb:55657 (size: 11.1 MB, free: 1695.8 MB)
2021-12-08 10:42:19,387 [Executor task launch worker for task 363] INFO [org.apache.spark.storage.memory.MemoryStore] - Block rdd_137_7 stored as values in memory (estimated size 11.1 MB, free 1680.6 MB)
2021-12-08 10:42:19,388 [dispatcher-event-loop-3] INFO [org.apache.spark.storage.BlockManagerInfo] - Added rdd_137_7 in memory on qb:55657 (size: 11.1 MB, free: 1684.7 MB)
2021-12-08 10:42:19,427 [Executor task launch worker for task 357] INFO [org.apache.spark.storage.memory.MemoryStore] - Block rdd_137_1 stored as values in memory (estimated size 11.1 MB, free 1669.5 MB)
2021-12-08 10:42:19,427 [dispatcher-event-loop-5] INFO [org.apache.spark.storage.BlockManagerInfo] - Added rdd_137_1 in memory on qb:55657 (size: 11.1 MB, free: 1673.6 MB)
2021-12-08 10:42:19,489 [Executor task launch worker for task 362] INFO [org.apache.spark.executor.Executor] - Finished task 6.0 in stage 148.0 (TID 362). 166054 bytes result sent to driver
2021-12-08 10:42:19,490 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 6.0 in stage 148.0 (TID 362) in 38333 ms on localhost (executor driver) (4/12)
2021-12-08 10:42:19,619 [Executor task launch worker for task 361] INFO [org.apache.spark.executor.Executor] - Finished task 5.0 in stage 148.0 (TID 361). 166097 bytes result sent to driver
2021-12-08 10:42:19,619 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 5.0 in stage 148.0 (TID 361) in 38462 ms on localhost (executor driver) (5/12)
2021-12-08 10:42:19,669 [Executor task launch worker for task 363] INFO [org.apache.spark.executor.Executor] - Finished task 7.0 in stage 148.0 (TID 363). 166054 bytes result sent to driver
2021-12-08 10:42:19,669 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 7.0 in stage 148.0 (TID 363) in 38512 ms on localhost (executor driver) (6/12)
2021-12-08 10:42:19,711 [Executor task launch worker for task 357] INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 148.0 (TID 357). 166054 bytes result sent to driver
2021-12-08 10:42:19,711 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 148.0 (TID 357) in 38555 ms on localhost (executor driver) (7/12)
2021-12-08 10:42:21,140 [Executor task launch worker for task 356] INFO [org.apache.spark.storage.memory.MemoryStore] - Block rdd_137_0 stored as values in memory (estimated size 11.1 MB, free 1658.4 MB)
2021-12-08 10:42:21,140 [dispatcher-event-loop-7] INFO [org.apache.spark.storage.BlockManagerInfo] - Added rdd_137_0 in memory on qb:55657 (size: 11.1 MB, free: 1662.5 MB)
2021-12-08 10:42:21,154 [Executor task launch worker for task 367] INFO [org.apache.spark.storage.memory.MemoryStore] - Block rdd_137_11 stored as values in memory (estimated size 11.1 MB, free 1647.3 MB)
2021-12-08 10:42:21,155 [dispatcher-event-loop-8] INFO [org.apache.spark.storage.BlockManagerInfo] - Added rdd_137_11 in memory on qb:55657 (size: 11.1 MB, free: 1651.4 MB)
2021-12-08 10:42:21,224 [Executor task launch worker for task 365] INFO [org.apache.spark.storage.memory.MemoryStore] - Block rdd_137_9 stored as values in memory (estimated size 11.1 MB, free 1636.2 MB)
2021-12-08 10:42:21,225 [dispatcher-event-loop-0] INFO [org.apache.spark.storage.BlockManagerInfo] - Added rdd_137_9 in memory on qb:55657 (size: 11.1 MB, free: 1640.3 MB)
2021-12-08 10:42:21,251 [Executor task launch worker for task 366] INFO [org.apache.spark.storage.memory.MemoryStore] - Block rdd_137_10 stored as values in memory (estimated size 11.1 MB, free 1625.1 MB)
2021-12-08 10:42:21,251 [dispatcher-event-loop-2] INFO [org.apache.spark.storage.BlockManagerInfo] - Added rdd_137_10 in memory on qb:55657 (size: 11.1 MB, free: 1629.2 MB)
2021-12-08 10:42:21,343 [Executor task launch worker for task 358] INFO [org.apache.spark.storage.memory.MemoryStore] - Block rdd_137_2 stored as values in memory (estimated size 11.1 MB, free 1614.0 MB)
2021-12-08 10:42:21,344 [dispatcher-event-loop-1] INFO [org.apache.spark.storage.BlockManagerInfo] - Added rdd_137_2 in memory on qb:55657 (size: 11.1 MB, free: 1618.1 MB)
2021-12-08 10:42:21,355 [Executor task launch worker for task 356] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 148.0 (TID 356). 166054 bytes result sent to driver
2021-12-08 10:42:21,355 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 148.0 (TID 356) in 40199 ms on localhost (executor driver) (8/12)
2021-12-08 10:42:21,383 [Executor task launch worker for task 367] INFO [org.apache.spark.executor.Executor] - Finished task 11.0 in stage 148.0 (TID 367). 166097 bytes result sent to driver
2021-12-08 10:42:21,383 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 11.0 in stage 148.0 (TID 367) in 40226 ms on localhost (executor driver) (9/12)
2021-12-08 10:42:21,441 [Executor task launch worker for task 365] INFO [org.apache.spark.executor.Executor] - Finished task 9.0 in stage 148.0 (TID 365). 166054 bytes result sent to driver
2021-12-08 10:42:21,442 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 9.0 in stage 148.0 (TID 365) in 40284 ms on localhost (executor driver) (10/12)
2021-12-08 10:42:21,442 [Executor task launch worker for task 366] INFO [org.apache.spark.executor.Executor] - Finished task 10.0 in stage 148.0 (TID 366). 166054 bytes result sent to driver
2021-12-08 10:42:21,442 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 10.0 in stage 148.0 (TID 366) in 40285 ms on localhost (executor driver) (11/12)
2021-12-08 10:42:21,535 [Executor task launch worker for task 358] INFO [org.apache.spark.executor.Executor] - Finished task 2.0 in stage 148.0 (TID 358). 166054 bytes result sent to driver
2021-12-08 10:42:21,535 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 2.0 in stage 148.0 (TID 358) in 40378 ms on localhost (executor driver) (12/12)
2021-12-08 10:42:21,535 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 148.0, whose tasks have all completed, from pool 
2021-12-08 10:42:21,535 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 148 (aggregate at ALS.scala:1711) finished in 40.385 s
2021-12-08 10:42:21,536 [main] INFO [org.apache.spark.scheduler.DAGScheduler] - Job 16 finished: aggregate at ALS.scala:1711, took 41.600748 s
2021-12-08 10:42:21,551 [main] INFO [org.apache.spark.rdd.MapPartitionsRDD] - Removing RDD 127 from persistence list
2021-12-08 10:42:21,551 [block-manager-slave-async-thread-pool-1] INFO [org.apache.spark.storage.BlockManager] - Removing RDD 127
2021-12-08 10:42:21,558 [main] INFO [org.apache.spark.SparkContext] - Starting job: aggregate at ALS.scala:1711
2021-12-08 10:42:21,559 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 142 (flatMap at ALS.scala:1653)
2021-12-08 10:42:21,559 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 17 (aggregate at ALS.scala:1711) with 12 output partitions
2021-12-08 10:42:21,559 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 166 (aggregate at ALS.scala:1711)
2021-12-08 10:42:21,559 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 153, ShuffleMapStage 165)
2021-12-08 10:42:21,559 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List(ShuffleMapStage 165)
2021-12-08 10:42:21,559 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ShuffleMapStage 165 (MapPartitionsRDD[142] at flatMap at ALS.scala:1653), which has no missing parents
2021-12-08 10:42:21,563 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_34 stored as values in memory (estimated size 1944.2 KB, free 1659.9 MB)
2021-12-08 10:42:21,566 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_34_piece0 stored as bytes in memory (estimated size 1897.8 KB, free 1658.1 MB)
2021-12-08 10:42:21,567 [dispatcher-event-loop-1] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_34_piece0 in memory on qb:55657 (size: 1897.8 KB, free: 1664.1 MB)
2021-12-08 10:42:21,567 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 34 from broadcast at DAGScheduler.scala:1039
2021-12-08 10:42:21,567 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 12 missing tasks from ShuffleMapStage 165 (MapPartitionsRDD[142] at flatMap at ALS.scala:1653) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11))
2021-12-08 10:42:21,567 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 165.0 with 12 tasks
2021-12-08 10:42:21,568 [dispatcher-event-loop-6] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 165.0 (TID 368, localhost, executor driver, partition 0, PROCESS_LOCAL, 7928 bytes)
2021-12-08 10:42:21,568 [dispatcher-event-loop-6] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 165.0 (TID 369, localhost, executor driver, partition 1, PROCESS_LOCAL, 7928 bytes)
2021-12-08 10:42:21,568 [dispatcher-event-loop-6] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 2.0 in stage 165.0 (TID 370, localhost, executor driver, partition 2, PROCESS_LOCAL, 7928 bytes)
2021-12-08 10:42:21,568 [dispatcher-event-loop-6] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 3.0 in stage 165.0 (TID 371, localhost, executor driver, partition 3, PROCESS_LOCAL, 7928 bytes)
2021-12-08 10:42:21,568 [dispatcher-event-loop-6] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 4.0 in stage 165.0 (TID 372, localhost, executor driver, partition 4, PROCESS_LOCAL, 7928 bytes)
2021-12-08 10:42:21,568 [dispatcher-event-loop-6] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 5.0 in stage 165.0 (TID 373, localhost, executor driver, partition 5, PROCESS_LOCAL, 7928 bytes)
2021-12-08 10:42:21,568 [dispatcher-event-loop-6] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 6.0 in stage 165.0 (TID 374, localhost, executor driver, partition 6, PROCESS_LOCAL, 7928 bytes)
2021-12-08 10:42:21,568 [dispatcher-event-loop-6] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 7.0 in stage 165.0 (TID 375, localhost, executor driver, partition 7, PROCESS_LOCAL, 7928 bytes)
2021-12-08 10:42:21,568 [dispatcher-event-loop-6] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 8.0 in stage 165.0 (TID 376, localhost, executor driver, partition 8, PROCESS_LOCAL, 7928 bytes)
2021-12-08 10:42:21,568 [dispatcher-event-loop-6] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 9.0 in stage 165.0 (TID 377, localhost, executor driver, partition 9, PROCESS_LOCAL, 7928 bytes)
2021-12-08 10:42:21,568 [dispatcher-event-loop-6] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 10.0 in stage 165.0 (TID 378, localhost, executor driver, partition 10, PROCESS_LOCAL, 7928 bytes)
2021-12-08 10:42:21,568 [dispatcher-event-loop-6] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 11.0 in stage 165.0 (TID 379, localhost, executor driver, partition 11, PROCESS_LOCAL, 7928 bytes)
2021-12-08 10:42:21,568 [Executor task launch worker for task 368] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 165.0 (TID 368)
2021-12-08 10:42:21,568 [Executor task launch worker for task 372] INFO [org.apache.spark.executor.Executor] - Running task 4.0 in stage 165.0 (TID 372)
2021-12-08 10:42:21,568 [Executor task launch worker for task 377] INFO [org.apache.spark.executor.Executor] - Running task 9.0 in stage 165.0 (TID 377)
2021-12-08 10:42:21,568 [Executor task launch worker for task 374] INFO [org.apache.spark.executor.Executor] - Running task 6.0 in stage 165.0 (TID 374)
2021-12-08 10:42:21,568 [Executor task launch worker for task 376] INFO [org.apache.spark.executor.Executor] - Running task 8.0 in stage 165.0 (TID 376)
2021-12-08 10:42:21,568 [Executor task launch worker for task 369] INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 165.0 (TID 369)
2021-12-08 10:42:21,568 [Executor task launch worker for task 375] INFO [org.apache.spark.executor.Executor] - Running task 7.0 in stage 165.0 (TID 375)
2021-12-08 10:42:21,568 [Executor task launch worker for task 370] INFO [org.apache.spark.executor.Executor] - Running task 2.0 in stage 165.0 (TID 370)
2021-12-08 10:42:21,568 [Executor task launch worker for task 371] INFO [org.apache.spark.executor.Executor] - Running task 3.0 in stage 165.0 (TID 371)
2021-12-08 10:42:21,568 [Executor task launch worker for task 373] INFO [org.apache.spark.executor.Executor] - Running task 5.0 in stage 165.0 (TID 373)
2021-12-08 10:42:21,568 [Executor task launch worker for task 379] INFO [org.apache.spark.executor.Executor] - Running task 11.0 in stage 165.0 (TID 379)
2021-12-08 10:42:21,568 [Executor task launch worker for task 378] INFO [org.apache.spark.executor.Executor] - Running task 10.0 in stage 165.0 (TID 378)
2021-12-08 10:42:21,572 [Executor task launch worker for task 379] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_10_11 locally
2021-12-08 10:42:21,573 [Executor task launch worker for task 379] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_137_11 locally
2021-12-08 10:42:21,572 [Executor task launch worker for task 377] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_10_9 locally
2021-12-08 10:42:21,572 [Executor task launch worker for task 371] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_10_3 locally
2021-12-08 10:42:21,573 [Executor task launch worker for task 377] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_137_9 locally
2021-12-08 10:42:21,573 [Executor task launch worker for task 371] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_137_3 locally
2021-12-08 10:42:21,573 [Executor task launch worker for task 374] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_10_6 locally
2021-12-08 10:42:21,573 [Executor task launch worker for task 374] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_137_6 locally
2021-12-08 10:42:21,573 [Executor task launch worker for task 375] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_10_7 locally
2021-12-08 10:42:21,573 [Executor task launch worker for task 375] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_137_7 locally
2021-12-08 10:42:21,573 [Executor task launch worker for task 369] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_10_1 locally
2021-12-08 10:42:21,573 [Executor task launch worker for task 369] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_137_1 locally
2021-12-08 10:42:21,573 [Executor task launch worker for task 368] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_10_0 locally
2021-12-08 10:42:21,573 [Executor task launch worker for task 368] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_137_0 locally
2021-12-08 10:42:21,574 [Executor task launch worker for task 376] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_10_8 locally
2021-12-08 10:42:21,574 [Executor task launch worker for task 376] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_137_8 locally
2021-12-08 10:42:21,574 [Executor task launch worker for task 370] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_10_2 locally
2021-12-08 10:42:21,574 [Executor task launch worker for task 370] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_137_2 locally
2021-12-08 10:42:21,575 [Executor task launch worker for task 378] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_10_10 locally
2021-12-08 10:42:21,575 [Executor task launch worker for task 378] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_137_10 locally
2021-12-08 10:42:21,580 [Executor task launch worker for task 373] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_10_5 locally
2021-12-08 10:42:21,580 [Executor task launch worker for task 373] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_137_5 locally
2021-12-08 10:42:21,580 [Executor task launch worker for task 372] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_10_4 locally
2021-12-08 10:42:21,580 [Executor task launch worker for task 372] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_137_4 locally
2021-12-08 10:42:23,287 [Executor task launch worker for task 370] INFO [org.apache.spark.executor.Executor] - Finished task 2.0 in stage 165.0 (TID 370). 999 bytes result sent to driver
2021-12-08 10:42:23,287 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 2.0 in stage 165.0 (TID 370) in 1719 ms on localhost (executor driver) (1/12)
2021-12-08 10:42:23,288 [Executor task launch worker for task 369] INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 165.0 (TID 369). 999 bytes result sent to driver
2021-12-08 10:42:23,289 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 165.0 (TID 369) in 1721 ms on localhost (executor driver) (2/12)
2021-12-08 10:42:23,290 [Executor task launch worker for task 371] INFO [org.apache.spark.executor.Executor] - Finished task 3.0 in stage 165.0 (TID 371). 999 bytes result sent to driver
2021-12-08 10:42:23,290 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 3.0 in stage 165.0 (TID 371) in 1722 ms on localhost (executor driver) (3/12)
2021-12-08 10:42:23,291 [Executor task launch worker for task 368] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 165.0 (TID 368). 1042 bytes result sent to driver
2021-12-08 10:42:23,292 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 165.0 (TID 368) in 1725 ms on localhost (executor driver) (4/12)
2021-12-08 10:42:23,307 [Executor task launch worker for task 375] INFO [org.apache.spark.executor.Executor] - Finished task 7.0 in stage 165.0 (TID 375). 999 bytes result sent to driver
2021-12-08 10:42:23,308 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 7.0 in stage 165.0 (TID 375) in 1740 ms on localhost (executor driver) (5/12)
2021-12-08 10:42:23,341 [Executor task launch worker for task 379] INFO [org.apache.spark.executor.Executor] - Finished task 11.0 in stage 165.0 (TID 379). 999 bytes result sent to driver
2021-12-08 10:42:23,341 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 11.0 in stage 165.0 (TID 379) in 1773 ms on localhost (executor driver) (6/12)
2021-12-08 10:42:23,343 [Executor task launch worker for task 374] INFO [org.apache.spark.executor.Executor] - Finished task 6.0 in stage 165.0 (TID 374). 999 bytes result sent to driver
2021-12-08 10:42:23,343 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 6.0 in stage 165.0 (TID 374) in 1775 ms on localhost (executor driver) (7/12)
2021-12-08 10:42:23,344 [Executor task launch worker for task 377] INFO [org.apache.spark.executor.Executor] - Finished task 9.0 in stage 165.0 (TID 377). 1042 bytes result sent to driver
2021-12-08 10:42:23,344 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 9.0 in stage 165.0 (TID 377) in 1776 ms on localhost (executor driver) (8/12)
2021-12-08 10:42:23,616 [Executor task launch worker for task 376] INFO [org.apache.spark.executor.Executor] - Finished task 8.0 in stage 165.0 (TID 376). 999 bytes result sent to driver
2021-12-08 10:42:23,616 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 8.0 in stage 165.0 (TID 376) in 2048 ms on localhost (executor driver) (9/12)
2021-12-08 10:42:23,692 [Executor task launch worker for task 378] INFO [org.apache.spark.executor.Executor] - Finished task 10.0 in stage 165.0 (TID 378). 999 bytes result sent to driver
2021-12-08 10:42:23,692 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 10.0 in stage 165.0 (TID 378) in 2124 ms on localhost (executor driver) (10/12)
2021-12-08 10:42:23,693 [Executor task launch worker for task 373] INFO [org.apache.spark.executor.Executor] - Finished task 5.0 in stage 165.0 (TID 373). 999 bytes result sent to driver
2021-12-08 10:42:23,693 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 5.0 in stage 165.0 (TID 373) in 2125 ms on localhost (executor driver) (11/12)
2021-12-08 10:42:23,694 [Executor task launch worker for task 372] INFO [org.apache.spark.executor.Executor] - Finished task 4.0 in stage 165.0 (TID 372). 1042 bytes result sent to driver
2021-12-08 10:42:23,695 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 4.0 in stage 165.0 (TID 372) in 2127 ms on localhost (executor driver) (12/12)
2021-12-08 10:42:23,695 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 165.0, whose tasks have all completed, from pool 
2021-12-08 10:42:23,695 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ShuffleMapStage 165 (flatMap at ALS.scala:1653) finished in 2.135 s
2021-12-08 10:42:23,695 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - looking for newly runnable stages
2021-12-08 10:42:23,695 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - running: Set()
2021-12-08 10:42:23,695 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - waiting: Set(ResultStage 166)
2021-12-08 10:42:23,695 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - failed: Set()
2021-12-08 10:42:23,696 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 166 (MapPartitionsRDD[148] at values at ALS.scala:1711), which has no missing parents
2021-12-08 10:42:23,699 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_35 stored as values in memory (estimated size 2.2 MB, free 1655.9 MB)
2021-12-08 10:42:23,702 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_35_piece0 stored as bytes in memory (estimated size 2.0 MB, free 1653.9 MB)
2021-12-08 10:42:23,702 [dispatcher-event-loop-4] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_35_piece0 in memory on qb:55657 (size: 2.0 MB, free: 1662.1 MB)
2021-12-08 10:42:23,702 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 35 from broadcast at DAGScheduler.scala:1039
2021-12-08 10:42:23,702 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 12 missing tasks from ResultStage 166 (MapPartitionsRDD[148] at values at ALS.scala:1711) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11))
2021-12-08 10:42:23,702 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 166.0 with 12 tasks
2021-12-08 10:42:23,703 [dispatcher-event-loop-11] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 166.0 (TID 380, localhost, executor driver, partition 0, PROCESS_LOCAL, 7888 bytes)
2021-12-08 10:42:23,703 [dispatcher-event-loop-11] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 166.0 (TID 381, localhost, executor driver, partition 1, PROCESS_LOCAL, 7888 bytes)
2021-12-08 10:42:23,703 [dispatcher-event-loop-11] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 2.0 in stage 166.0 (TID 382, localhost, executor driver, partition 2, PROCESS_LOCAL, 7888 bytes)
2021-12-08 10:42:23,703 [dispatcher-event-loop-11] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 3.0 in stage 166.0 (TID 383, localhost, executor driver, partition 3, PROCESS_LOCAL, 7888 bytes)
2021-12-08 10:42:23,703 [dispatcher-event-loop-11] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 4.0 in stage 166.0 (TID 384, localhost, executor driver, partition 4, PROCESS_LOCAL, 7888 bytes)
2021-12-08 10:42:23,703 [dispatcher-event-loop-11] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 5.0 in stage 166.0 (TID 385, localhost, executor driver, partition 5, PROCESS_LOCAL, 7888 bytes)
2021-12-08 10:42:23,703 [dispatcher-event-loop-11] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 6.0 in stage 166.0 (TID 386, localhost, executor driver, partition 6, PROCESS_LOCAL, 7888 bytes)
2021-12-08 10:42:23,703 [dispatcher-event-loop-11] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 7.0 in stage 166.0 (TID 387, localhost, executor driver, partition 7, PROCESS_LOCAL, 7888 bytes)
2021-12-08 10:42:23,703 [dispatcher-event-loop-11] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 8.0 in stage 166.0 (TID 388, localhost, executor driver, partition 8, PROCESS_LOCAL, 7888 bytes)
2021-12-08 10:42:23,703 [dispatcher-event-loop-11] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 9.0 in stage 166.0 (TID 389, localhost, executor driver, partition 9, PROCESS_LOCAL, 7888 bytes)
2021-12-08 10:42:23,703 [dispatcher-event-loop-11] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 10.0 in stage 166.0 (TID 390, localhost, executor driver, partition 10, PROCESS_LOCAL, 7888 bytes)
2021-12-08 10:42:23,703 [dispatcher-event-loop-11] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 11.0 in stage 166.0 (TID 391, localhost, executor driver, partition 11, PROCESS_LOCAL, 7888 bytes)
2021-12-08 10:42:23,703 [Executor task launch worker for task 380] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 166.0 (TID 380)
2021-12-08 10:42:23,703 [Executor task launch worker for task 384] INFO [org.apache.spark.executor.Executor] - Running task 4.0 in stage 166.0 (TID 384)
2021-12-08 10:42:23,703 [Executor task launch worker for task 388] INFO [org.apache.spark.executor.Executor] - Running task 8.0 in stage 166.0 (TID 388)
2021-12-08 10:42:23,703 [Executor task launch worker for task 386] INFO [org.apache.spark.executor.Executor] - Running task 6.0 in stage 166.0 (TID 386)
2021-12-08 10:42:23,703 [Executor task launch worker for task 387] INFO [org.apache.spark.executor.Executor] - Running task 7.0 in stage 166.0 (TID 387)
2021-12-08 10:42:23,703 [Executor task launch worker for task 385] INFO [org.apache.spark.executor.Executor] - Running task 5.0 in stage 166.0 (TID 385)
2021-12-08 10:42:23,703 [Executor task launch worker for task 382] INFO [org.apache.spark.executor.Executor] - Running task 2.0 in stage 166.0 (TID 382)
2021-12-08 10:42:23,703 [Executor task launch worker for task 383] INFO [org.apache.spark.executor.Executor] - Running task 3.0 in stage 166.0 (TID 383)
2021-12-08 10:42:23,703 [Executor task launch worker for task 381] INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 166.0 (TID 381)
2021-12-08 10:42:23,703 [Executor task launch worker for task 389] INFO [org.apache.spark.executor.Executor] - Running task 9.0 in stage 166.0 (TID 389)
2021-12-08 10:42:23,703 [Executor task launch worker for task 390] INFO [org.apache.spark.executor.Executor] - Running task 10.0 in stage 166.0 (TID 390)
2021-12-08 10:42:23,703 [Executor task launch worker for task 391] INFO [org.apache.spark.executor.Executor] - Running task 11.0 in stage 166.0 (TID 391)
2021-12-08 10:42:23,741 [dispatcher-event-loop-7] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_34_piece0 on qb:55657 in memory (size: 1897.8 KB, free: 1663.9 MB)
2021-12-08 10:42:23,744 [Executor task launch worker for task 387] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_14_7 locally
2021-12-08 10:42:23,744 [Executor task launch worker for task 390] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_14_10 locally
2021-12-08 10:42:23,744 [Executor task launch worker for task 389] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_14_9 locally
2021-12-08 10:42:23,745 [Executor task launch worker for task 390] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 12 non-empty blocks out of 12 blocks
2021-12-08 10:42:23,745 [Executor task launch worker for task 390] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-08 10:42:23,744 [Executor task launch worker for task 380] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_14_0 locally
2021-12-08 10:42:23,746 [Executor task launch worker for task 380] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 12 non-empty blocks out of 12 blocks
2021-12-08 10:42:23,746 [Executor task launch worker for task 380] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-08 10:42:23,746 [Executor task launch worker for task 381] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_14_1 locally
2021-12-08 10:42:23,746 [Executor task launch worker for task 381] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 12 non-empty blocks out of 12 blocks
2021-12-08 10:42:23,745 [Executor task launch worker for task 389] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 12 non-empty blocks out of 12 blocks
2021-12-08 10:42:23,745 [Executor task launch worker for task 387] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 12 non-empty blocks out of 12 blocks
2021-12-08 10:42:23,746 [Executor task launch worker for task 387] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 1 ms
2021-12-08 10:42:23,746 [Executor task launch worker for task 391] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_14_11 locally
2021-12-08 10:42:23,746 [Executor task launch worker for task 389] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 1 ms
2021-12-08 10:42:23,746 [Executor task launch worker for task 381] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-08 10:42:23,746 [Executor task launch worker for task 384] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_14_4 locally
2021-12-08 10:42:23,746 [Executor task launch worker for task 383] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_14_3 locally
2021-12-08 10:42:23,746 [Executor task launch worker for task 383] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 12 non-empty blocks out of 12 blocks
2021-12-08 10:42:23,747 [Executor task launch worker for task 383] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 1 ms
2021-12-08 10:42:23,747 [Executor task launch worker for task 384] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 12 non-empty blocks out of 12 blocks
2021-12-08 10:42:23,747 [Executor task launch worker for task 384] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 1 ms
2021-12-08 10:42:23,746 [Executor task launch worker for task 391] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 12 non-empty blocks out of 12 blocks
2021-12-08 10:42:23,747 [Executor task launch worker for task 391] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 1 ms
2021-12-08 10:42:23,747 [Executor task launch worker for task 388] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_14_8 locally
2021-12-08 10:42:23,747 [Executor task launch worker for task 388] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 12 non-empty blocks out of 12 blocks
2021-12-08 10:42:23,747 [Executor task launch worker for task 388] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-08 10:42:23,748 [Executor task launch worker for task 382] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_14_2 locally
2021-12-08 10:42:23,748 [Executor task launch worker for task 385] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_14_5 locally
2021-12-08 10:42:23,748 [Executor task launch worker for task 386] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_14_6 locally
2021-12-08 10:42:23,748 [Executor task launch worker for task 385] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 12 non-empty blocks out of 12 blocks
2021-12-08 10:42:23,748 [Executor task launch worker for task 385] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-08 10:42:23,748 [Executor task launch worker for task 382] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 12 non-empty blocks out of 12 blocks
2021-12-08 10:42:23,749 [Executor task launch worker for task 382] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 1 ms
2021-12-08 10:42:23,749 [Executor task launch worker for task 386] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 12 non-empty blocks out of 12 blocks
2021-12-08 10:42:23,749 [Executor task launch worker for task 386] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 1 ms
2021-12-08 10:42:24,029 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 790
2021-12-08 10:42:24,029 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 807
2021-12-08 10:42:24,029 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 815
2021-12-08 10:42:24,029 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 812
2021-12-08 10:42:24,029 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 788
2021-12-08 10:42:24,029 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 800
2021-12-08 10:42:24,029 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 820
2021-12-08 10:42:24,029 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 810
2021-12-08 10:42:24,029 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 821
2021-12-08 10:42:24,029 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 797
2021-12-08 10:42:24,029 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 813
2021-12-08 10:42:24,029 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 811
2021-12-08 10:42:24,029 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 795
2021-12-08 10:42:24,029 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 809
2021-12-08 10:42:24,029 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 822
2021-12-08 10:42:24,029 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 817
2021-12-08 10:42:24,029 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 785
2021-12-08 10:42:24,029 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 802
2021-12-08 10:42:24,029 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 778
2021-12-08 10:42:24,029 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 789
2021-12-08 10:42:24,029 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 804
2021-12-08 10:42:24,029 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 776
2021-12-08 10:42:24,029 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 805
2021-12-08 10:42:24,029 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 783
2021-12-08 10:42:24,029 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 794
2021-12-08 10:42:24,029 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 784
2021-12-08 10:42:24,029 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 798
2021-12-08 10:42:24,029 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 806
2021-12-08 10:42:24,029 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 803
2021-12-08 10:42:24,029 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 782
2021-12-08 10:42:24,029 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 824
2021-12-08 10:42:24,029 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 792
2021-12-08 10:42:24,029 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 777
2021-12-08 10:42:24,029 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 793
2021-12-08 10:42:24,029 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 787
2021-12-08 10:42:24,029 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 791
2021-12-08 10:42:24,036 [dispatcher-event-loop-1] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_33_piece0 on qb:55657 in memory (size: 1898.9 KB, free: 1665.8 MB)
2021-12-08 10:42:24,037 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 808
2021-12-08 10:42:24,037 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 823
2021-12-08 10:42:24,037 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 780
2021-12-08 10:42:24,037 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 779
2021-12-08 10:42:24,037 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 796
2021-12-08 10:42:24,037 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 786
2021-12-08 10:42:24,037 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 775
2021-12-08 10:42:24,037 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 814
2021-12-08 10:42:24,037 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 819
2021-12-08 10:42:24,037 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 799
2021-12-08 10:42:24,037 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 801
2021-12-08 10:42:24,037 [dispatcher-event-loop-5] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_32_piece0 on qb:55657 in memory (size: 1740.1 KB, free: 1667.5 MB)
2021-12-08 10:42:24,037 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 781
2021-12-08 10:42:24,037 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 816
2021-12-08 10:42:24,037 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 818
2021-12-08 10:42:45,682 [Executor task launch worker for task 381] INFO [org.apache.spark.storage.memory.MemoryStore] - Block rdd_147_1 stored as values in memory (estimated size 4.0 MB, free 1661.0 MB)
2021-12-08 10:42:45,683 [dispatcher-event-loop-7] INFO [org.apache.spark.storage.BlockManagerInfo] - Added rdd_147_1 in memory on qb:55657 (size: 4.0 MB, free: 1663.5 MB)
2021-12-08 10:42:45,722 [Executor task launch worker for task 385] INFO [org.apache.spark.storage.memory.MemoryStore] - Block rdd_147_5 stored as values in memory (estimated size 4.0 MB, free 1657.0 MB)
2021-12-08 10:42:45,723 [dispatcher-event-loop-9] INFO [org.apache.spark.storage.BlockManagerInfo] - Added rdd_147_5 in memory on qb:55657 (size: 4.0 MB, free: 1659.5 MB)
2021-12-08 10:42:45,805 [Executor task launch worker for task 381] INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 166.0 (TID 381). 166140 bytes result sent to driver
2021-12-08 10:42:45,837 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 166.0 (TID 381) in 22134 ms on localhost (executor driver) (1/12)
2021-12-08 10:42:45,847 [Executor task launch worker for task 385] INFO [org.apache.spark.executor.Executor] - Finished task 5.0 in stage 166.0 (TID 385). 166054 bytes result sent to driver
2021-12-08 10:42:45,848 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 5.0 in stage 166.0 (TID 385) in 22145 ms on localhost (executor driver) (2/12)
2021-12-08 10:42:46,089 [Executor task launch worker for task 384] INFO [org.apache.spark.storage.memory.MemoryStore] - Block rdd_147_4 stored as values in memory (estimated size 4.0 MB, free 1653.0 MB)
2021-12-08 10:42:46,090 [dispatcher-event-loop-1] INFO [org.apache.spark.storage.BlockManagerInfo] - Added rdd_147_4 in memory on qb:55657 (size: 4.0 MB, free: 1655.5 MB)
2021-12-08 10:42:46,211 [Executor task launch worker for task 384] INFO [org.apache.spark.executor.Executor] - Finished task 4.0 in stage 166.0 (TID 384). 166054 bytes result sent to driver
2021-12-08 10:42:46,211 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 4.0 in stage 166.0 (TID 384) in 22508 ms on localhost (executor driver) (3/12)
2021-12-08 10:42:47,315 [Executor task launch worker for task 387] INFO [org.apache.spark.storage.memory.MemoryStore] - Block rdd_147_7 stored as values in memory (estimated size 4.0 MB, free 1649.0 MB)
2021-12-08 10:42:47,315 [dispatcher-event-loop-6] INFO [org.apache.spark.storage.BlockManagerInfo] - Added rdd_147_7 in memory on qb:55657 (size: 4.0 MB, free: 1651.5 MB)
2021-12-08 10:42:47,420 [Executor task launch worker for task 387] INFO [org.apache.spark.executor.Executor] - Finished task 7.0 in stage 166.0 (TID 387). 166054 bytes result sent to driver
2021-12-08 10:42:47,421 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 7.0 in stage 166.0 (TID 387) in 23718 ms on localhost (executor driver) (4/12)
2021-12-08 10:42:47,590 [Executor task launch worker for task 391] INFO [org.apache.spark.storage.memory.MemoryStore] - Block rdd_147_11 stored as values in memory (estimated size 4.0 MB, free 1645.0 MB)
2021-12-08 10:42:47,591 [dispatcher-event-loop-3] INFO [org.apache.spark.storage.BlockManagerInfo] - Added rdd_147_11 in memory on qb:55657 (size: 4.0 MB, free: 1647.5 MB)
2021-12-08 10:42:47,665 [Executor task launch worker for task 380] INFO [org.apache.spark.storage.memory.MemoryStore] - Block rdd_147_0 stored as values in memory (estimated size 4.0 MB, free 1641.0 MB)
2021-12-08 10:42:47,665 [dispatcher-event-loop-4] INFO [org.apache.spark.storage.BlockManagerInfo] - Added rdd_147_0 in memory on qb:55657 (size: 4.0 MB, free: 1643.5 MB)
2021-12-08 10:42:47,682 [Executor task launch worker for task 391] INFO [org.apache.spark.executor.Executor] - Finished task 11.0 in stage 166.0 (TID 391). 166054 bytes result sent to driver
2021-12-08 10:42:47,683 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 11.0 in stage 166.0 (TID 391) in 23980 ms on localhost (executor driver) (5/12)
2021-12-08 10:42:47,768 [Executor task launch worker for task 380] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 166.0 (TID 380). 166054 bytes result sent to driver
2021-12-08 10:42:47,769 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 166.0 (TID 380) in 24066 ms on localhost (executor driver) (6/12)
2021-12-08 10:42:47,785 [Executor task launch worker for task 383] INFO [org.apache.spark.storage.memory.MemoryStore] - Block rdd_147_3 stored as values in memory (estimated size 4.0 MB, free 1637.0 MB)
2021-12-08 10:42:47,786 [dispatcher-event-loop-7] INFO [org.apache.spark.storage.BlockManagerInfo] - Added rdd_147_3 in memory on qb:55657 (size: 4.0 MB, free: 1639.6 MB)
2021-12-08 10:42:47,826 [Executor task launch worker for task 388] INFO [org.apache.spark.storage.memory.MemoryStore] - Block rdd_147_8 stored as values in memory (estimated size 4.0 MB, free 1633.1 MB)
2021-12-08 10:42:47,826 [dispatcher-event-loop-9] INFO [org.apache.spark.storage.BlockManagerInfo] - Added rdd_147_8 in memory on qb:55657 (size: 4.0 MB, free: 1635.6 MB)
2021-12-08 10:42:47,861 [Executor task launch worker for task 383] INFO [org.apache.spark.executor.Executor] - Finished task 3.0 in stage 166.0 (TID 383). 166097 bytes result sent to driver
2021-12-08 10:42:47,861 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 3.0 in stage 166.0 (TID 383) in 24158 ms on localhost (executor driver) (7/12)
2021-12-08 10:42:47,912 [Executor task launch worker for task 388] INFO [org.apache.spark.executor.Executor] - Finished task 8.0 in stage 166.0 (TID 388). 166054 bytes result sent to driver
2021-12-08 10:42:47,912 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 8.0 in stage 166.0 (TID 388) in 24209 ms on localhost (executor driver) (8/12)
2021-12-08 10:42:47,943 [Executor task launch worker for task 390] INFO [org.apache.spark.storage.memory.MemoryStore] - Block rdd_147_10 stored as values in memory (estimated size 4.0 MB, free 1629.1 MB)
2021-12-08 10:42:47,943 [dispatcher-event-loop-1] INFO [org.apache.spark.storage.BlockManagerInfo] - Added rdd_147_10 in memory on qb:55657 (size: 4.0 MB, free: 1631.6 MB)
2021-12-08 10:42:48,016 [Executor task launch worker for task 390] INFO [org.apache.spark.executor.Executor] - Finished task 10.0 in stage 166.0 (TID 390). 166054 bytes result sent to driver
2021-12-08 10:42:48,017 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 10.0 in stage 166.0 (TID 390) in 24314 ms on localhost (executor driver) (9/12)
2021-12-08 10:42:48,203 [Executor task launch worker for task 386] INFO [org.apache.spark.storage.memory.MemoryStore] - Block rdd_147_6 stored as values in memory (estimated size 4.0 MB, free 1625.1 MB)
2021-12-08 10:42:48,203 [dispatcher-event-loop-6] INFO [org.apache.spark.storage.BlockManagerInfo] - Added rdd_147_6 in memory on qb:55657 (size: 4.0 MB, free: 1627.6 MB)
2021-12-08 10:42:48,274 [Executor task launch worker for task 386] INFO [org.apache.spark.executor.Executor] - Finished task 6.0 in stage 166.0 (TID 386). 166054 bytes result sent to driver
2021-12-08 10:42:48,274 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 6.0 in stage 166.0 (TID 386) in 24571 ms on localhost (executor driver) (10/12)
2021-12-08 10:42:48,358 [Executor task launch worker for task 382] INFO [org.apache.spark.storage.memory.MemoryStore] - Block rdd_147_2 stored as values in memory (estimated size 4.0 MB, free 1621.1 MB)
2021-12-08 10:42:48,359 [dispatcher-event-loop-3] INFO [org.apache.spark.storage.BlockManagerInfo] - Added rdd_147_2 in memory on qb:55657 (size: 4.0 MB, free: 1623.6 MB)
2021-12-08 10:42:48,422 [Executor task launch worker for task 382] INFO [org.apache.spark.executor.Executor] - Finished task 2.0 in stage 166.0 (TID 382). 166054 bytes result sent to driver
2021-12-08 10:42:48,422 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 2.0 in stage 166.0 (TID 382) in 24719 ms on localhost (executor driver) (11/12)
2021-12-08 10:42:48,547 [Executor task launch worker for task 389] INFO [org.apache.spark.storage.memory.MemoryStore] - Block rdd_147_9 stored as values in memory (estimated size 4.0 MB, free 1617.1 MB)
2021-12-08 10:42:48,548 [dispatcher-event-loop-11] INFO [org.apache.spark.storage.BlockManagerInfo] - Added rdd_147_9 in memory on qb:55657 (size: 4.0 MB, free: 1619.6 MB)
2021-12-08 10:42:48,611 [Executor task launch worker for task 389] INFO [org.apache.spark.executor.Executor] - Finished task 9.0 in stage 166.0 (TID 389). 166097 bytes result sent to driver
2021-12-08 10:42:48,611 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 9.0 in stage 166.0 (TID 389) in 24908 ms on localhost (executor driver) (12/12)
2021-12-08 10:42:48,611 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 166.0, whose tasks have all completed, from pool 
2021-12-08 10:42:48,612 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 166 (aggregate at ALS.scala:1711) finished in 24.915 s
2021-12-08 10:42:48,612 [main] INFO [org.apache.spark.scheduler.DAGScheduler] - Job 17 finished: aggregate at ALS.scala:1711, took 27.054017 s
2021-12-08 10:42:48,625 [main] INFO [org.apache.spark.rdd.MapPartitionsRDD] - Removing RDD 137 from persistence list
2021-12-08 10:42:48,626 [block-manager-slave-async-thread-pool-1] INFO [org.apache.spark.storage.BlockManager] - Removing RDD 137
2021-12-08 10:42:48,632 [main] INFO [org.apache.spark.SparkContext] - Starting job: aggregate at ALS.scala:1711
2021-12-08 10:42:48,633 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 152 (flatMap at ALS.scala:1653)
2021-12-08 10:42:48,633 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 18 (aggregate at ALS.scala:1711) with 12 output partitions
2021-12-08 10:42:48,633 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 185 (aggregate at ALS.scala:1711)
2021-12-08 10:42:48,633 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 168, ShuffleMapStage 184)
2021-12-08 10:42:48,633 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List(ShuffleMapStage 184)
2021-12-08 10:42:48,634 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ShuffleMapStage 184 (MapPartitionsRDD[152] at flatMap at ALS.scala:1653), which has no missing parents
2021-12-08 10:42:48,637 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_36 stored as values in memory (estimated size 2.1 MB, free 1748.3 MB)
2021-12-08 10:42:48,640 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_36_piece0 stored as bytes in memory (estimated size 2.0 MB, free 1746.3 MB)
2021-12-08 10:42:48,640 [dispatcher-event-loop-6] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_36_piece0 in memory on qb:55657 (size: 2.0 MB, free: 1750.9 MB)
2021-12-08 10:42:48,640 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 36 from broadcast at DAGScheduler.scala:1039
2021-12-08 10:42:48,640 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 12 missing tasks from ShuffleMapStage 184 (MapPartitionsRDD[152] at flatMap at ALS.scala:1653) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11))
2021-12-08 10:42:48,640 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 184.0 with 12 tasks
2021-12-08 10:42:48,641 [dispatcher-event-loop-5] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 184.0 (TID 392, localhost, executor driver, partition 0, PROCESS_LOCAL, 7928 bytes)
2021-12-08 10:42:48,641 [dispatcher-event-loop-5] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 184.0 (TID 393, localhost, executor driver, partition 1, PROCESS_LOCAL, 7928 bytes)
2021-12-08 10:42:48,641 [dispatcher-event-loop-5] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 2.0 in stage 184.0 (TID 394, localhost, executor driver, partition 2, PROCESS_LOCAL, 7928 bytes)
2021-12-08 10:42:48,641 [dispatcher-event-loop-5] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 3.0 in stage 184.0 (TID 395, localhost, executor driver, partition 3, PROCESS_LOCAL, 7928 bytes)
2021-12-08 10:42:48,641 [dispatcher-event-loop-5] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 4.0 in stage 184.0 (TID 396, localhost, executor driver, partition 4, PROCESS_LOCAL, 7928 bytes)
2021-12-08 10:42:48,641 [dispatcher-event-loop-5] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 5.0 in stage 184.0 (TID 397, localhost, executor driver, partition 5, PROCESS_LOCAL, 7928 bytes)
2021-12-08 10:42:48,641 [dispatcher-event-loop-5] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 6.0 in stage 184.0 (TID 398, localhost, executor driver, partition 6, PROCESS_LOCAL, 7928 bytes)
2021-12-08 10:42:48,641 [dispatcher-event-loop-5] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 7.0 in stage 184.0 (TID 399, localhost, executor driver, partition 7, PROCESS_LOCAL, 7928 bytes)
2021-12-08 10:42:48,641 [dispatcher-event-loop-5] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 8.0 in stage 184.0 (TID 400, localhost, executor driver, partition 8, PROCESS_LOCAL, 7928 bytes)
2021-12-08 10:42:48,641 [dispatcher-event-loop-5] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 9.0 in stage 184.0 (TID 401, localhost, executor driver, partition 9, PROCESS_LOCAL, 7928 bytes)
2021-12-08 10:42:48,641 [dispatcher-event-loop-5] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 10.0 in stage 184.0 (TID 402, localhost, executor driver, partition 10, PROCESS_LOCAL, 7928 bytes)
2021-12-08 10:42:48,641 [dispatcher-event-loop-5] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 11.0 in stage 184.0 (TID 403, localhost, executor driver, partition 11, PROCESS_LOCAL, 7928 bytes)
2021-12-08 10:42:48,641 [Executor task launch worker for task 392] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 184.0 (TID 392)
2021-12-08 10:42:48,641 [Executor task launch worker for task 398] INFO [org.apache.spark.executor.Executor] - Running task 6.0 in stage 184.0 (TID 398)
2021-12-08 10:42:48,641 [Executor task launch worker for task 402] INFO [org.apache.spark.executor.Executor] - Running task 10.0 in stage 184.0 (TID 402)
2021-12-08 10:42:48,641 [Executor task launch worker for task 401] INFO [org.apache.spark.executor.Executor] - Running task 9.0 in stage 184.0 (TID 401)
2021-12-08 10:42:48,641 [Executor task launch worker for task 396] INFO [org.apache.spark.executor.Executor] - Running task 4.0 in stage 184.0 (TID 396)
2021-12-08 10:42:48,641 [Executor task launch worker for task 400] INFO [org.apache.spark.executor.Executor] - Running task 8.0 in stage 184.0 (TID 400)
2021-12-08 10:42:48,641 [Executor task launch worker for task 395] INFO [org.apache.spark.executor.Executor] - Running task 3.0 in stage 184.0 (TID 395)
2021-12-08 10:42:48,641 [Executor task launch worker for task 393] INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 184.0 (TID 393)
2021-12-08 10:42:48,641 [Executor task launch worker for task 403] INFO [org.apache.spark.executor.Executor] - Running task 11.0 in stage 184.0 (TID 403)
2021-12-08 10:42:48,641 [Executor task launch worker for task 399] INFO [org.apache.spark.executor.Executor] - Running task 7.0 in stage 184.0 (TID 399)
2021-12-08 10:42:48,641 [Executor task launch worker for task 394] INFO [org.apache.spark.executor.Executor] - Running task 2.0 in stage 184.0 (TID 394)
2021-12-08 10:42:48,641 [Executor task launch worker for task 397] INFO [org.apache.spark.executor.Executor] - Running task 5.0 in stage 184.0 (TID 397)
2021-12-08 10:42:48,645 [Executor task launch worker for task 392] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_15_0 locally
2021-12-08 10:42:48,645 [Executor task launch worker for task 394] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_15_2 locally
2021-12-08 10:42:48,645 [Executor task launch worker for task 392] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_147_0 locally
2021-12-08 10:42:48,645 [Executor task launch worker for task 394] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_147_2 locally
2021-12-08 10:42:48,645 [Executor task launch worker for task 398] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_15_6 locally
2021-12-08 10:42:48,645 [Executor task launch worker for task 399] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_15_7 locally
2021-12-08 10:42:48,646 [Executor task launch worker for task 399] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_147_7 locally
2021-12-08 10:42:48,645 [Executor task launch worker for task 398] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_147_6 locally
2021-12-08 10:42:48,646 [Executor task launch worker for task 395] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_15_3 locally
2021-12-08 10:42:48,646 [Executor task launch worker for task 395] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_147_3 locally
2021-12-08 10:42:48,646 [Executor task launch worker for task 403] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_15_11 locally
2021-12-08 10:42:48,646 [Executor task launch worker for task 403] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_147_11 locally
2021-12-08 10:42:48,646 [Executor task launch worker for task 402] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_15_10 locally
2021-12-08 10:42:48,646 [Executor task launch worker for task 402] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_147_10 locally
2021-12-08 10:42:48,646 [Executor task launch worker for task 396] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_15_4 locally
2021-12-08 10:42:48,647 [Executor task launch worker for task 396] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_147_4 locally
2021-12-08 10:42:48,647 [Executor task launch worker for task 393] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_15_1 locally
2021-12-08 10:42:48,647 [Executor task launch worker for task 393] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_147_1 locally
2021-12-08 10:42:48,648 [Executor task launch worker for task 401] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_15_9 locally
2021-12-08 10:42:48,648 [Executor task launch worker for task 401] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_147_9 locally
2021-12-08 10:42:48,648 [Executor task launch worker for task 400] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_15_8 locally
2021-12-08 10:42:48,648 [Executor task launch worker for task 400] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_147_8 locally
2021-12-08 10:42:48,653 [Executor task launch worker for task 397] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_15_5 locally
2021-12-08 10:42:48,653 [Executor task launch worker for task 397] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_147_5 locally
2021-12-08 10:42:49,554 [Executor task launch worker for task 392] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 184.0 (TID 392). 999 bytes result sent to driver
2021-12-08 10:42:49,554 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 184.0 (TID 392) in 914 ms on localhost (executor driver) (1/12)
2021-12-08 10:42:49,556 [Executor task launch worker for task 395] INFO [org.apache.spark.executor.Executor] - Finished task 3.0 in stage 184.0 (TID 395). 999 bytes result sent to driver
2021-12-08 10:42:49,557 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 3.0 in stage 184.0 (TID 395) in 915 ms on localhost (executor driver) (2/12)
2021-12-08 10:42:49,602 [Executor task launch worker for task 403] INFO [org.apache.spark.executor.Executor] - Finished task 11.0 in stage 184.0 (TID 403). 999 bytes result sent to driver
2021-12-08 10:42:49,602 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 11.0 in stage 184.0 (TID 403) in 961 ms on localhost (executor driver) (3/12)
2021-12-08 10:42:49,627 [Executor task launch worker for task 399] INFO [org.apache.spark.executor.Executor] - Finished task 7.0 in stage 184.0 (TID 399). 999 bytes result sent to driver
2021-12-08 10:42:49,627 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 7.0 in stage 184.0 (TID 399) in 986 ms on localhost (executor driver) (4/12)
2021-12-08 10:42:49,630 [Executor task launch worker for task 397] INFO [org.apache.spark.executor.Executor] - Finished task 5.0 in stage 184.0 (TID 397). 1042 bytes result sent to driver
2021-12-08 10:42:49,630 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 5.0 in stage 184.0 (TID 397) in 989 ms on localhost (executor driver) (5/12)
2021-12-08 10:42:49,648 [Executor task launch worker for task 402] INFO [org.apache.spark.executor.Executor] - Finished task 10.0 in stage 184.0 (TID 402). 999 bytes result sent to driver
2021-12-08 10:42:49,648 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 10.0 in stage 184.0 (TID 402) in 1007 ms on localhost (executor driver) (6/12)
2021-12-08 10:42:49,652 [Executor task launch worker for task 394] INFO [org.apache.spark.executor.Executor] - Finished task 2.0 in stage 184.0 (TID 394). 999 bytes result sent to driver
2021-12-08 10:42:49,652 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 2.0 in stage 184.0 (TID 394) in 1011 ms on localhost (executor driver) (7/12)
2021-12-08 10:42:49,676 [Executor task launch worker for task 396] INFO [org.apache.spark.executor.Executor] - Finished task 4.0 in stage 184.0 (TID 396). 999 bytes result sent to driver
2021-12-08 10:42:49,676 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 4.0 in stage 184.0 (TID 396) in 1035 ms on localhost (executor driver) (8/12)
2021-12-08 10:42:49,679 [Executor task launch worker for task 400] INFO [org.apache.spark.executor.Executor] - Finished task 8.0 in stage 184.0 (TID 400). 1042 bytes result sent to driver
2021-12-08 10:42:49,679 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 8.0 in stage 184.0 (TID 400) in 1038 ms on localhost (executor driver) (9/12)
2021-12-08 10:42:49,911 [Executor task launch worker for task 398] INFO [org.apache.spark.executor.Executor] - Finished task 6.0 in stage 184.0 (TID 398). 999 bytes result sent to driver
2021-12-08 10:42:49,911 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 6.0 in stage 184.0 (TID 398) in 1270 ms on localhost (executor driver) (10/12)
2021-12-08 10:42:49,912 [Executor task launch worker for task 401] INFO [org.apache.spark.executor.Executor] - Finished task 9.0 in stage 184.0 (TID 401). 1042 bytes result sent to driver
2021-12-08 10:42:49,912 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 9.0 in stage 184.0 (TID 401) in 1271 ms on localhost (executor driver) (11/12)
2021-12-08 10:42:49,914 [Executor task launch worker for task 393] INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 184.0 (TID 393). 1085 bytes result sent to driver
2021-12-08 10:42:49,914 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 184.0 (TID 393) in 1273 ms on localhost (executor driver) (12/12)
2021-12-08 10:42:49,914 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 184.0, whose tasks have all completed, from pool 
2021-12-08 10:42:49,914 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ShuffleMapStage 184 (flatMap at ALS.scala:1653) finished in 1.280 s
2021-12-08 10:42:49,914 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - looking for newly runnable stages
2021-12-08 10:42:49,914 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - running: Set()
2021-12-08 10:42:49,914 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - waiting: Set(ResultStage 185)
2021-12-08 10:42:49,914 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - failed: Set()
2021-12-08 10:42:49,914 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 185 (MapPartitionsRDD[158] at values at ALS.scala:1711), which has no missing parents
2021-12-08 10:42:49,918 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_37 stored as values in memory (estimated size 2.4 MB, free 1743.9 MB)
2021-12-08 10:42:49,921 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_37_piece0 stored as bytes in memory (estimated size 2.2 MB, free 1741.8 MB)
2021-12-08 10:42:49,921 [dispatcher-event-loop-7] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_37_piece0 in memory on qb:55657 (size: 2.2 MB, free: 1748.7 MB)
2021-12-08 10:42:49,922 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 37 from broadcast at DAGScheduler.scala:1039
2021-12-08 10:42:49,922 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 12 missing tasks from ResultStage 185 (MapPartitionsRDD[158] at values at ALS.scala:1711) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11))
2021-12-08 10:42:49,922 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 185.0 with 12 tasks
2021-12-08 10:42:49,922 [dispatcher-event-loop-9] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 185.0 (TID 404, localhost, executor driver, partition 0, PROCESS_LOCAL, 7888 bytes)
2021-12-08 10:42:49,922 [dispatcher-event-loop-9] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 185.0 (TID 405, localhost, executor driver, partition 1, PROCESS_LOCAL, 7888 bytes)
2021-12-08 10:42:49,922 [dispatcher-event-loop-9] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 2.0 in stage 185.0 (TID 406, localhost, executor driver, partition 2, PROCESS_LOCAL, 7888 bytes)
2021-12-08 10:42:49,922 [dispatcher-event-loop-9] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 3.0 in stage 185.0 (TID 407, localhost, executor driver, partition 3, PROCESS_LOCAL, 7888 bytes)
2021-12-08 10:42:49,922 [dispatcher-event-loop-9] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 4.0 in stage 185.0 (TID 408, localhost, executor driver, partition 4, PROCESS_LOCAL, 7888 bytes)
2021-12-08 10:42:49,922 [dispatcher-event-loop-9] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 5.0 in stage 185.0 (TID 409, localhost, executor driver, partition 5, PROCESS_LOCAL, 7888 bytes)
2021-12-08 10:42:49,922 [dispatcher-event-loop-9] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 6.0 in stage 185.0 (TID 410, localhost, executor driver, partition 6, PROCESS_LOCAL, 7888 bytes)
2021-12-08 10:42:49,923 [dispatcher-event-loop-9] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 7.0 in stage 185.0 (TID 411, localhost, executor driver, partition 7, PROCESS_LOCAL, 7888 bytes)
2021-12-08 10:42:49,923 [dispatcher-event-loop-9] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 8.0 in stage 185.0 (TID 412, localhost, executor driver, partition 8, PROCESS_LOCAL, 7888 bytes)
2021-12-08 10:42:49,923 [dispatcher-event-loop-9] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 9.0 in stage 185.0 (TID 413, localhost, executor driver, partition 9, PROCESS_LOCAL, 7888 bytes)
2021-12-08 10:42:49,923 [dispatcher-event-loop-9] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 10.0 in stage 185.0 (TID 414, localhost, executor driver, partition 10, PROCESS_LOCAL, 7888 bytes)
2021-12-08 10:42:49,923 [dispatcher-event-loop-9] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 11.0 in stage 185.0 (TID 415, localhost, executor driver, partition 11, PROCESS_LOCAL, 7888 bytes)
2021-12-08 10:42:49,923 [Executor task launch worker for task 404] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 185.0 (TID 404)
2021-12-08 10:42:49,923 [Executor task launch worker for task 409] INFO [org.apache.spark.executor.Executor] - Running task 5.0 in stage 185.0 (TID 409)
2021-12-08 10:42:49,923 [Executor task launch worker for task 414] INFO [org.apache.spark.executor.Executor] - Running task 10.0 in stage 185.0 (TID 414)
2021-12-08 10:42:49,923 [Executor task launch worker for task 411] INFO [org.apache.spark.executor.Executor] - Running task 7.0 in stage 185.0 (TID 411)
2021-12-08 10:42:49,923 [Executor task launch worker for task 408] INFO [org.apache.spark.executor.Executor] - Running task 4.0 in stage 185.0 (TID 408)
2021-12-08 10:42:49,923 [Executor task launch worker for task 407] INFO [org.apache.spark.executor.Executor] - Running task 3.0 in stage 185.0 (TID 407)
2021-12-08 10:42:49,923 [Executor task launch worker for task 406] INFO [org.apache.spark.executor.Executor] - Running task 2.0 in stage 185.0 (TID 406)
2021-12-08 10:42:49,923 [Executor task launch worker for task 412] INFO [org.apache.spark.executor.Executor] - Running task 8.0 in stage 185.0 (TID 412)
2021-12-08 10:42:49,923 [Executor task launch worker for task 405] INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 185.0 (TID 405)
2021-12-08 10:42:49,923 [Executor task launch worker for task 413] INFO [org.apache.spark.executor.Executor] - Running task 9.0 in stage 185.0 (TID 413)
2021-12-08 10:42:49,923 [Executor task launch worker for task 410] INFO [org.apache.spark.executor.Executor] - Running task 6.0 in stage 185.0 (TID 410)
2021-12-08 10:42:49,923 [Executor task launch worker for task 415] INFO [org.apache.spark.executor.Executor] - Running task 11.0 in stage 185.0 (TID 415)
2021-12-08 10:42:49,927 [Executor task launch worker for task 409] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_9_5 locally
2021-12-08 10:42:49,927 [Executor task launch worker for task 413] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_9_9 locally
2021-12-08 10:42:49,927 [Executor task launch worker for task 415] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_9_11 locally
2021-12-08 10:42:49,927 [Executor task launch worker for task 411] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_9_7 locally
2021-12-08 10:42:49,927 [Executor task launch worker for task 405] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_9_1 locally
2021-12-08 10:42:49,928 [Executor task launch worker for task 410] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_9_6 locally
2021-12-08 10:42:49,928 [Executor task launch worker for task 412] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_9_8 locally
2021-12-08 10:42:49,928 [Executor task launch worker for task 407] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_9_3 locally
2021-12-08 10:42:49,928 [Executor task launch worker for task 412] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 12 non-empty blocks out of 12 blocks
2021-12-08 10:42:49,928 [Executor task launch worker for task 413] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 12 non-empty blocks out of 12 blocks
2021-12-08 10:42:49,928 [Executor task launch worker for task 413] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-08 10:42:49,928 [Executor task launch worker for task 412] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-08 10:42:49,928 [Executor task launch worker for task 410] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 12 non-empty blocks out of 12 blocks
2021-12-08 10:42:49,928 [Executor task launch worker for task 411] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 12 non-empty blocks out of 12 blocks
2021-12-08 10:42:49,928 [Executor task launch worker for task 405] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 12 non-empty blocks out of 12 blocks
2021-12-08 10:42:49,928 [Executor task launch worker for task 415] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 12 non-empty blocks out of 12 blocks
2021-12-08 10:42:49,928 [Executor task launch worker for task 405] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-08 10:42:49,928 [Executor task launch worker for task 411] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-08 10:42:49,928 [Executor task launch worker for task 410] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-08 10:42:49,928 [Executor task launch worker for task 407] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 12 non-empty blocks out of 12 blocks
2021-12-08 10:42:49,928 [Executor task launch worker for task 409] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 12 non-empty blocks out of 12 blocks
2021-12-08 10:42:49,929 [Executor task launch worker for task 407] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 1 ms
2021-12-08 10:42:49,929 [Executor task launch worker for task 408] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_9_4 locally
2021-12-08 10:42:49,928 [Executor task launch worker for task 415] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-08 10:42:49,929 [Executor task launch worker for task 409] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 1 ms
2021-12-08 10:42:49,929 [Executor task launch worker for task 408] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 12 non-empty blocks out of 12 blocks
2021-12-08 10:42:49,929 [Executor task launch worker for task 408] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-08 10:42:49,930 [Executor task launch worker for task 414] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_9_10 locally
2021-12-08 10:42:49,930 [Executor task launch worker for task 406] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_9_2 locally
2021-12-08 10:42:49,930 [Executor task launch worker for task 404] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_9_0 locally
2021-12-08 10:42:49,930 [Executor task launch worker for task 406] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 12 non-empty blocks out of 12 blocks
2021-12-08 10:42:49,930 [Executor task launch worker for task 414] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 12 non-empty blocks out of 12 blocks
2021-12-08 10:42:49,930 [Executor task launch worker for task 406] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-08 10:42:49,930 [Executor task launch worker for task 404] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 12 non-empty blocks out of 12 blocks
2021-12-08 10:42:49,930 [Executor task launch worker for task 414] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-08 10:42:49,930 [Executor task launch worker for task 404] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-08 10:42:50,251 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 854
2021-12-08 10:42:50,254 [dispatcher-event-loop-0] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_36_piece0 on qb:55657 in memory (size: 2.0 MB, free: 1750.7 MB)
2021-12-08 10:42:50,254 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 855
2021-12-08 10:42:50,254 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 856
2021-12-08 10:42:50,254 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 837
2021-12-08 10:42:50,254 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 829
2021-12-08 10:42:50,254 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 861
2021-12-08 10:42:50,254 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 863
2021-12-08 10:42:50,254 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 832
2021-12-08 10:42:50,254 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 866
2021-12-08 10:42:50,254 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 840
2021-12-08 10:42:50,255 [dispatcher-event-loop-8] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_35_piece0 on qb:55657 in memory (size: 2.0 MB, free: 1752.7 MB)
2021-12-08 10:42:50,255 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 841
2021-12-08 10:42:50,255 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 850
2021-12-08 10:42:50,255 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 868
2021-12-08 10:42:50,255 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 860
2021-12-08 10:42:50,255 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 847
2021-12-08 10:42:50,255 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 845
2021-12-08 10:42:50,255 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 851
2021-12-08 10:42:50,255 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 853
2021-12-08 10:42:50,255 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 843
2021-12-08 10:42:50,255 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 870
2021-12-08 10:42:50,255 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 834
2021-12-08 10:42:50,255 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 857
2021-12-08 10:42:50,255 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 833
2021-12-08 10:42:50,255 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 825
2021-12-08 10:42:50,255 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 864
2021-12-08 10:42:50,255 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 839
2021-12-08 10:42:50,255 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 831
2021-12-08 10:42:50,255 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 846
2021-12-08 10:42:50,255 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 836
2021-12-08 10:42:50,255 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 826
2021-12-08 10:42:50,255 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 872
2021-12-08 10:42:50,255 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 862
2021-12-08 10:42:50,255 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 848
2021-12-08 10:42:50,255 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 849
2021-12-08 10:42:50,255 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 873
2021-12-08 10:42:50,255 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 828
2021-12-08 10:42:50,255 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 865
2021-12-08 10:42:50,255 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 827
2021-12-08 10:42:50,255 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 830
2021-12-08 10:42:50,255 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 838
2021-12-08 10:42:50,255 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 869
2021-12-08 10:42:50,255 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 871
2021-12-08 10:42:50,255 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 867
2021-12-08 10:42:50,255 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 844
2021-12-08 10:42:50,255 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 842
2021-12-08 10:42:50,255 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 858
2021-12-08 10:42:50,255 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 859
2021-12-08 10:42:50,255 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 835
2021-12-08 10:42:50,255 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 852
2021-12-08 10:42:50,255 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 874
2021-12-08 10:43:27,627 [Executor task launch worker for task 405] INFO [org.apache.spark.storage.memory.MemoryStore] - Block rdd_157_1 stored as values in memory (estimated size 11.1 MB, free 1738.9 MB)
2021-12-08 10:43:27,627 [dispatcher-event-loop-1] INFO [org.apache.spark.storage.BlockManagerInfo] - Added rdd_157_1 in memory on qb:55657 (size: 11.1 MB, free: 1741.6 MB)
2021-12-08 10:43:27,637 [Executor task launch worker for task 404] INFO [org.apache.spark.storage.memory.MemoryStore] - Block rdd_157_0 stored as values in memory (estimated size 11.1 MB, free 1727.8 MB)
2021-12-08 10:43:27,637 [dispatcher-event-loop-0] INFO [org.apache.spark.storage.BlockManagerInfo] - Added rdd_157_0 in memory on qb:55657 (size: 11.1 MB, free: 1730.5 MB)
2021-12-08 10:43:27,671 [Executor task launch worker for task 409] INFO [org.apache.spark.storage.memory.MemoryStore] - Block rdd_157_5 stored as values in memory (estimated size 11.1 MB, free 1716.7 MB)
2021-12-08 10:43:27,671 [dispatcher-event-loop-5] INFO [org.apache.spark.storage.BlockManagerInfo] - Added rdd_157_5 in memory on qb:55657 (size: 11.1 MB, free: 1719.4 MB)
2021-12-08 10:43:27,760 [Executor task launch worker for task 411] INFO [org.apache.spark.storage.memory.MemoryStore] - Block rdd_157_7 stored as values in memory (estimated size 11.1 MB, free 1705.6 MB)
2021-12-08 10:43:27,760 [dispatcher-event-loop-6] INFO [org.apache.spark.storage.BlockManagerInfo] - Added rdd_157_7 in memory on qb:55657 (size: 11.1 MB, free: 1708.3 MB)
2021-12-08 10:43:27,992 [Executor task launch worker for task 405] INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 185.0 (TID 405). 166097 bytes result sent to driver
2021-12-08 10:43:27,996 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 185.0 (TID 405) in 38074 ms on localhost (executor driver) (1/12)
2021-12-08 10:43:28,001 [Executor task launch worker for task 404] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 185.0 (TID 404). 166097 bytes result sent to driver
2021-12-08 10:43:28,002 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 185.0 (TID 404) in 38080 ms on localhost (executor driver) (2/12)
2021-12-08 10:43:28,013 [Executor task launch worker for task 409] INFO [org.apache.spark.executor.Executor] - Finished task 5.0 in stage 185.0 (TID 409). 166054 bytes result sent to driver
2021-12-08 10:43:28,014 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 5.0 in stage 185.0 (TID 409) in 38092 ms on localhost (executor driver) (3/12)
2021-12-08 10:43:28,093 [Executor task launch worker for task 411] INFO [org.apache.spark.executor.Executor] - Finished task 7.0 in stage 185.0 (TID 411). 166097 bytes result sent to driver
2021-12-08 10:43:28,094 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 7.0 in stage 185.0 (TID 411) in 38172 ms on localhost (executor driver) (4/12)
2021-12-08 10:43:28,418 [Executor task launch worker for task 410] INFO [org.apache.spark.storage.memory.MemoryStore] - Block rdd_157_6 stored as values in memory (estimated size 11.1 MB, free 1694.5 MB)
2021-12-08 10:43:28,418 [dispatcher-event-loop-7] INFO [org.apache.spark.storage.BlockManagerInfo] - Added rdd_157_6 in memory on qb:55657 (size: 11.1 MB, free: 1697.2 MB)
2021-12-08 10:43:28,569 [Executor task launch worker for task 413] INFO [org.apache.spark.storage.memory.MemoryStore] - Block rdd_157_9 stored as values in memory (estimated size 11.1 MB, free 1683.4 MB)
2021-12-08 10:43:28,570 [dispatcher-event-loop-3] INFO [org.apache.spark.storage.BlockManagerInfo] - Added rdd_157_9 in memory on qb:55657 (size: 11.1 MB, free: 1686.1 MB)
2021-12-08 10:43:28,663 [Executor task launch worker for task 407] INFO [org.apache.spark.storage.memory.MemoryStore] - Block rdd_157_3 stored as values in memory (estimated size 11.1 MB, free 1672.3 MB)
2021-12-08 10:43:28,663 [dispatcher-event-loop-9] INFO [org.apache.spark.storage.BlockManagerInfo] - Added rdd_157_3 in memory on qb:55657 (size: 11.1 MB, free: 1675.0 MB)
2021-12-08 10:43:28,716 [Executor task launch worker for task 410] INFO [org.apache.spark.executor.Executor] - Finished task 6.0 in stage 185.0 (TID 410). 166097 bytes result sent to driver
2021-12-08 10:43:28,716 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 6.0 in stage 185.0 (TID 410) in 38794 ms on localhost (executor driver) (5/12)
2021-12-08 10:43:28,844 [Executor task launch worker for task 413] INFO [org.apache.spark.executor.Executor] - Finished task 9.0 in stage 185.0 (TID 413). 166054 bytes result sent to driver
2021-12-08 10:43:28,844 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 9.0 in stage 185.0 (TID 413) in 38921 ms on localhost (executor driver) (6/12)
2021-12-08 10:43:28,926 [Executor task launch worker for task 407] INFO [org.apache.spark.executor.Executor] - Finished task 3.0 in stage 185.0 (TID 407). 166054 bytes result sent to driver
2021-12-08 10:43:28,927 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 3.0 in stage 185.0 (TID 407) in 39005 ms on localhost (executor driver) (7/12)
2021-12-08 10:43:29,741 [Executor task launch worker for task 412] INFO [org.apache.spark.storage.memory.MemoryStore] - Block rdd_157_8 stored as values in memory (estimated size 11.1 MB, free 1661.2 MB)
2021-12-08 10:43:29,741 [dispatcher-event-loop-8] INFO [org.apache.spark.storage.BlockManagerInfo] - Added rdd_157_8 in memory on qb:55657 (size: 11.1 MB, free: 1663.9 MB)
2021-12-08 10:43:29,773 [Executor task launch worker for task 406] INFO [org.apache.spark.storage.memory.MemoryStore] - Block rdd_157_2 stored as values in memory (estimated size 11.1 MB, free 1650.1 MB)
2021-12-08 10:43:29,773 [dispatcher-event-loop-4] INFO [org.apache.spark.storage.BlockManagerInfo] - Added rdd_157_2 in memory on qb:55657 (size: 11.1 MB, free: 1652.8 MB)
2021-12-08 10:43:29,823 [Executor task launch worker for task 415] INFO [org.apache.spark.storage.memory.MemoryStore] - Block rdd_157_11 stored as values in memory (estimated size 11.1 MB, free 1639.0 MB)
2021-12-08 10:43:29,823 [dispatcher-event-loop-11] INFO [org.apache.spark.storage.BlockManagerInfo] - Added rdd_157_11 in memory on qb:55657 (size: 11.1 MB, free: 1641.7 MB)
2021-12-08 10:43:29,896 [Executor task launch worker for task 408] INFO [org.apache.spark.storage.memory.MemoryStore] - Block rdd_157_4 stored as values in memory (estimated size 11.1 MB, free 1627.9 MB)
2021-12-08 10:43:29,897 [dispatcher-event-loop-10] INFO [org.apache.spark.storage.BlockManagerInfo] - Added rdd_157_4 in memory on qb:55657 (size: 11.1 MB, free: 1630.6 MB)
2021-12-08 10:43:29,984 [Executor task launch worker for task 412] INFO [org.apache.spark.executor.Executor] - Finished task 8.0 in stage 185.0 (TID 412). 166054 bytes result sent to driver
2021-12-08 10:43:29,984 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 8.0 in stage 185.0 (TID 412) in 40061 ms on localhost (executor driver) (8/12)
2021-12-08 10:43:29,995 [Executor task launch worker for task 406] INFO [org.apache.spark.executor.Executor] - Finished task 2.0 in stage 185.0 (TID 406). 166097 bytes result sent to driver
2021-12-08 10:43:29,995 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 2.0 in stage 185.0 (TID 406) in 40073 ms on localhost (executor driver) (9/12)
2021-12-08 10:43:30,040 [Executor task launch worker for task 415] INFO [org.apache.spark.executor.Executor] - Finished task 11.0 in stage 185.0 (TID 415). 166054 bytes result sent to driver
2021-12-08 10:43:30,041 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 11.0 in stage 185.0 (TID 415) in 40118 ms on localhost (executor driver) (10/12)
2021-12-08 10:43:30,080 [Executor task launch worker for task 408] INFO [org.apache.spark.executor.Executor] - Finished task 4.0 in stage 185.0 (TID 408). 166054 bytes result sent to driver
2021-12-08 10:43:30,081 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 4.0 in stage 185.0 (TID 408) in 40159 ms on localhost (executor driver) (11/12)
2021-12-08 10:43:30,102 [Executor task launch worker for task 414] INFO [org.apache.spark.storage.memory.MemoryStore] - Block rdd_157_10 stored as values in memory (estimated size 11.1 MB, free 1616.8 MB)
2021-12-08 10:43:30,103 [dispatcher-event-loop-1] INFO [org.apache.spark.storage.BlockManagerInfo] - Added rdd_157_10 in memory on qb:55657 (size: 11.1 MB, free: 1619.5 MB)
2021-12-08 10:43:30,273 [Executor task launch worker for task 414] INFO [org.apache.spark.executor.Executor] - Finished task 10.0 in stage 185.0 (TID 414). 166097 bytes result sent to driver
2021-12-08 10:43:30,273 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 10.0 in stage 185.0 (TID 414) in 40350 ms on localhost (executor driver) (12/12)
2021-12-08 10:43:30,273 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 185.0, whose tasks have all completed, from pool 
2021-12-08 10:43:30,273 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 185 (aggregate at ALS.scala:1711) finished in 40.359 s
2021-12-08 10:43:30,274 [main] INFO [org.apache.spark.scheduler.DAGScheduler] - Job 18 finished: aggregate at ALS.scala:1711, took 41.641521 s
2021-12-08 10:43:30,289 [main] INFO [org.apache.spark.rdd.MapPartitionsRDD] - Removing RDD 147 from persistence list
2021-12-08 10:43:30,290 [block-manager-slave-async-thread-pool-2] INFO [org.apache.spark.storage.BlockManager] - Removing RDD 147
2021-12-08 10:43:30,297 [main] INFO [org.apache.spark.SparkContext] - Starting job: aggregate at ALS.scala:1711
2021-12-08 10:43:30,298 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 162 (flatMap at ALS.scala:1653)
2021-12-08 10:43:30,298 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 19 (aggregate at ALS.scala:1711) with 12 output partitions
2021-12-08 10:43:30,298 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 205 (aggregate at ALS.scala:1711)
2021-12-08 10:43:30,298 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 204, ShuffleMapStage 190)
2021-12-08 10:43:30,298 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List(ShuffleMapStage 204)
2021-12-08 10:43:30,299 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ShuffleMapStage 204 (MapPartitionsRDD[162] at flatMap at ALS.scala:1653), which has no missing parents
2021-12-08 10:43:30,303 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_38 stored as values in memory (estimated size 2.2 MB, free 1662.4 MB)
2021-12-08 10:43:30,306 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_38_piece0 stored as bytes in memory (estimated size 2.2 MB, free 1660.3 MB)
2021-12-08 10:43:30,306 [dispatcher-event-loop-7] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_38_piece0 in memory on qb:55657 (size: 2.2 MB, free: 1665.2 MB)
2021-12-08 10:43:30,307 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 38 from broadcast at DAGScheduler.scala:1039
2021-12-08 10:43:30,307 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 12 missing tasks from ShuffleMapStage 204 (MapPartitionsRDD[162] at flatMap at ALS.scala:1653) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11))
2021-12-08 10:43:30,307 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 204.0 with 12 tasks
2021-12-08 10:43:30,307 [dispatcher-event-loop-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 204.0 (TID 416, localhost, executor driver, partition 0, PROCESS_LOCAL, 7928 bytes)
2021-12-08 10:43:30,307 [dispatcher-event-loop-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 204.0 (TID 417, localhost, executor driver, partition 1, PROCESS_LOCAL, 7928 bytes)
2021-12-08 10:43:30,308 [dispatcher-event-loop-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 2.0 in stage 204.0 (TID 418, localhost, executor driver, partition 2, PROCESS_LOCAL, 7928 bytes)
2021-12-08 10:43:30,308 [dispatcher-event-loop-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 3.0 in stage 204.0 (TID 419, localhost, executor driver, partition 3, PROCESS_LOCAL, 7928 bytes)
2021-12-08 10:43:30,308 [dispatcher-event-loop-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 4.0 in stage 204.0 (TID 420, localhost, executor driver, partition 4, PROCESS_LOCAL, 7928 bytes)
2021-12-08 10:43:30,308 [dispatcher-event-loop-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 5.0 in stage 204.0 (TID 421, localhost, executor driver, partition 5, PROCESS_LOCAL, 7928 bytes)
2021-12-08 10:43:30,308 [dispatcher-event-loop-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 6.0 in stage 204.0 (TID 422, localhost, executor driver, partition 6, PROCESS_LOCAL, 7928 bytes)
2021-12-08 10:43:30,308 [dispatcher-event-loop-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 7.0 in stage 204.0 (TID 423, localhost, executor driver, partition 7, PROCESS_LOCAL, 7928 bytes)
2021-12-08 10:43:30,308 [dispatcher-event-loop-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 8.0 in stage 204.0 (TID 424, localhost, executor driver, partition 8, PROCESS_LOCAL, 7928 bytes)
2021-12-08 10:43:30,308 [dispatcher-event-loop-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 9.0 in stage 204.0 (TID 425, localhost, executor driver, partition 9, PROCESS_LOCAL, 7928 bytes)
2021-12-08 10:43:30,308 [dispatcher-event-loop-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 10.0 in stage 204.0 (TID 426, localhost, executor driver, partition 10, PROCESS_LOCAL, 7928 bytes)
2021-12-08 10:43:30,308 [dispatcher-event-loop-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 11.0 in stage 204.0 (TID 427, localhost, executor driver, partition 11, PROCESS_LOCAL, 7928 bytes)
2021-12-08 10:43:30,308 [Executor task launch worker for task 417] INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 204.0 (TID 417)
2021-12-08 10:43:30,308 [Executor task launch worker for task 424] INFO [org.apache.spark.executor.Executor] - Running task 8.0 in stage 204.0 (TID 424)
2021-12-08 10:43:30,308 [Executor task launch worker for task 416] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 204.0 (TID 416)
2021-12-08 10:43:30,308 [Executor task launch worker for task 421] INFO [org.apache.spark.executor.Executor] - Running task 5.0 in stage 204.0 (TID 421)
2021-12-08 10:43:30,308 [Executor task launch worker for task 427] INFO [org.apache.spark.executor.Executor] - Running task 11.0 in stage 204.0 (TID 427)
2021-12-08 10:43:30,308 [Executor task launch worker for task 420] INFO [org.apache.spark.executor.Executor] - Running task 4.0 in stage 204.0 (TID 420)
2021-12-08 10:43:30,308 [Executor task launch worker for task 418] INFO [org.apache.spark.executor.Executor] - Running task 2.0 in stage 204.0 (TID 418)
2021-12-08 10:43:30,308 [Executor task launch worker for task 425] INFO [org.apache.spark.executor.Executor] - Running task 9.0 in stage 204.0 (TID 425)
2021-12-08 10:43:30,308 [Executor task launch worker for task 419] INFO [org.apache.spark.executor.Executor] - Running task 3.0 in stage 204.0 (TID 419)
2021-12-08 10:43:30,308 [Executor task launch worker for task 426] INFO [org.apache.spark.executor.Executor] - Running task 10.0 in stage 204.0 (TID 426)
2021-12-08 10:43:30,308 [Executor task launch worker for task 423] INFO [org.apache.spark.executor.Executor] - Running task 7.0 in stage 204.0 (TID 423)
2021-12-08 10:43:30,308 [Executor task launch worker for task 422] INFO [org.apache.spark.executor.Executor] - Running task 6.0 in stage 204.0 (TID 422)
2021-12-08 10:43:30,312 [Executor task launch worker for task 417] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_10_1 locally
2021-12-08 10:43:30,312 [Executor task launch worker for task 420] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_10_4 locally
2021-12-08 10:43:30,312 [Executor task launch worker for task 425] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_10_9 locally
2021-12-08 10:43:30,312 [Executor task launch worker for task 427] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_10_11 locally
2021-12-08 10:43:30,313 [Executor task launch worker for task 422] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_10_6 locally
2021-12-08 10:43:30,312 [Executor task launch worker for task 423] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_10_7 locally
2021-12-08 10:43:30,313 [Executor task launch worker for task 425] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_157_9 locally
2021-12-08 10:43:30,313 [Executor task launch worker for task 420] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_157_4 locally
2021-12-08 10:43:30,312 [Executor task launch worker for task 418] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_10_2 locally
2021-12-08 10:43:30,313 [Executor task launch worker for task 417] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_157_1 locally
2021-12-08 10:43:30,313 [Executor task launch worker for task 422] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_157_6 locally
2021-12-08 10:43:30,313 [Executor task launch worker for task 419] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_10_3 locally
2021-12-08 10:43:30,313 [Executor task launch worker for task 426] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_10_10 locally
2021-12-08 10:43:30,313 [Executor task launch worker for task 423] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_157_7 locally
2021-12-08 10:43:30,313 [Executor task launch worker for task 427] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_157_11 locally
2021-12-08 10:43:30,313 [Executor task launch worker for task 424] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_10_8 locally
2021-12-08 10:43:30,313 [Executor task launch worker for task 424] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_157_8 locally
2021-12-08 10:43:30,313 [Executor task launch worker for task 416] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_10_0 locally
2021-12-08 10:43:30,313 [Executor task launch worker for task 416] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_157_0 locally
2021-12-08 10:43:30,313 [Executor task launch worker for task 418] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_157_2 locally
2021-12-08 10:43:30,314 [Executor task launch worker for task 419] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_157_3 locally
2021-12-08 10:43:30,314 [Executor task launch worker for task 426] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_157_10 locally
2021-12-08 10:43:30,315 [Executor task launch worker for task 421] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_10_5 locally
2021-12-08 10:43:30,315 [Executor task launch worker for task 421] INFO [org.apache.spark.storage.BlockManager] - Found block rdd_157_5 locally
2021-12-08 10:43:31,809 [Executor task launch worker for task 416] ERROR [org.apache.spark.executor.Executor] - Exception in task 0.0 in stage 204.0 (TID 416)
com.esotericsoftware.kryo.KryoException: java.io.IOException: 磁盘空间不足。
	at com.esotericsoftware.kryo.io.Output.flush(Output.java:183)
	at com.esotericsoftware.kryo.io.Output.require(Output.java:160)
	at com.esotericsoftware.kryo.io.Output.writeInt(Output.java:254)
	at com.esotericsoftware.kryo.io.Output.writeFloat(Output.java:496)
	at com.esotericsoftware.kryo.io.Output.writeFloats(Output.java:711)
	at com.esotericsoftware.kryo.serializers.DefaultArraySerializers$FloatArraySerializer.write(DefaultArraySerializers.java:108)
	at com.esotericsoftware.kryo.serializers.DefaultArraySerializers$FloatArraySerializer.write(DefaultArraySerializers.java:97)
	at com.esotericsoftware.kryo.Kryo.writeObjectOrNull(Kryo.java:606)
	at com.esotericsoftware.kryo.serializers.DefaultArraySerializers$ObjectArraySerializer.write(DefaultArraySerializers.java:338)
	at com.esotericsoftware.kryo.serializers.DefaultArraySerializers$ObjectArraySerializer.write(DefaultArraySerializers.java:307)
	at com.esotericsoftware.kryo.Kryo.writeClassAndObject(Kryo.java:628)
	at com.twitter.chill.Tuple2Serializer.write(TupleSerializers.scala:37)
	at com.twitter.chill.Tuple2Serializer.write(TupleSerializers.scala:33)
	at com.esotericsoftware.kryo.Kryo.writeClassAndObject(Kryo.java:628)
	at org.apache.spark.serializer.KryoSerializationStream.writeObject(KryoSerializer.scala:241)
	at org.apache.spark.serializer.SerializationStream.writeValue(Serializer.scala:134)
	at org.apache.spark.storage.DiskBlockObjectWriter.write(DiskBlockObjectWriter.scala:241)
	at org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.write(BypassMergeSortShuffleWriter.java:151)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53)
	at org.apache.spark.scheduler.Task.run(Task.scala:109)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:345)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.io.IOException: 磁盘空间不足。
	at java.io.FileOutputStream.writeBytes(Native Method)
	at java.io.FileOutputStream.write(FileOutputStream.java:326)
	at org.apache.spark.storage.TimeTrackingOutputStream.write(TimeTrackingOutputStream.java:58)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at net.jpountz.lz4.LZ4BlockOutputStream.flushBufferedData(LZ4BlockOutputStream.java:220)
	at net.jpountz.lz4.LZ4BlockOutputStream.write(LZ4BlockOutputStream.java:173)
	at com.esotericsoftware.kryo.io.Output.flush(Output.java:181)
	... 24 more
2021-12-08 10:43:31,813 [Executor task launch worker for task 425] ERROR [org.apache.spark.executor.Executor] - Exception in task 9.0 in stage 204.0 (TID 425)
com.esotericsoftware.kryo.KryoException: java.io.IOException: 磁盘空间不足。
	at com.esotericsoftware.kryo.io.Output.flush(Output.java:183)
	at com.esotericsoftware.kryo.io.Output.require(Output.java:160)
	at com.esotericsoftware.kryo.io.Output.writeInt(Output.java:254)
	at com.esotericsoftware.kryo.io.Output.writeFloat(Output.java:496)
	at com.esotericsoftware.kryo.io.Output.writeFloats(Output.java:711)
	at com.esotericsoftware.kryo.serializers.DefaultArraySerializers$FloatArraySerializer.write(DefaultArraySerializers.java:108)
	at com.esotericsoftware.kryo.serializers.DefaultArraySerializers$FloatArraySerializer.write(DefaultArraySerializers.java:97)
	at com.esotericsoftware.kryo.Kryo.writeObjectOrNull(Kryo.java:606)
	at com.esotericsoftware.kryo.serializers.DefaultArraySerializers$ObjectArraySerializer.write(DefaultArraySerializers.java:338)
	at com.esotericsoftware.kryo.serializers.DefaultArraySerializers$ObjectArraySerializer.write(DefaultArraySerializers.java:307)
	at com.esotericsoftware.kryo.Kryo.writeClassAndObject(Kryo.java:628)
	at com.twitter.chill.Tuple2Serializer.write(TupleSerializers.scala:37)
	at com.twitter.chill.Tuple2Serializer.write(TupleSerializers.scala:33)
	at com.esotericsoftware.kryo.Kryo.writeClassAndObject(Kryo.java:628)
	at org.apache.spark.serializer.KryoSerializationStream.writeObject(KryoSerializer.scala:241)
	at org.apache.spark.serializer.SerializationStream.writeValue(Serializer.scala:134)
	at org.apache.spark.storage.DiskBlockObjectWriter.write(DiskBlockObjectWriter.scala:241)
	at org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.write(BypassMergeSortShuffleWriter.java:151)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53)
	at org.apache.spark.scheduler.Task.run(Task.scala:109)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:345)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.io.IOException: 磁盘空间不足。
	at java.io.FileOutputStream.writeBytes(Native Method)
	at java.io.FileOutputStream.write(FileOutputStream.java:326)
	at org.apache.spark.storage.TimeTrackingOutputStream.write(TimeTrackingOutputStream.java:58)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at net.jpountz.lz4.LZ4BlockOutputStream.flushBufferedData(LZ4BlockOutputStream.java:220)
	at net.jpountz.lz4.LZ4BlockOutputStream.write(LZ4BlockOutputStream.java:173)
	at com.esotericsoftware.kryo.io.Output.flush(Output.java:181)
	... 24 more
2021-12-08 10:43:31,809 [Executor task launch worker for task 417] ERROR [org.apache.spark.executor.Executor] - Exception in task 1.0 in stage 204.0 (TID 417)
com.esotericsoftware.kryo.KryoException: java.io.IOException: 磁盘空间不足。
	at com.esotericsoftware.kryo.io.Output.flush(Output.java:183)
	at com.esotericsoftware.kryo.io.Output.require(Output.java:160)
	at com.esotericsoftware.kryo.io.Output.writeInt(Output.java:254)
	at com.esotericsoftware.kryo.io.Output.writeFloat(Output.java:496)
	at com.esotericsoftware.kryo.io.Output.writeFloats(Output.java:711)
	at com.esotericsoftware.kryo.serializers.DefaultArraySerializers$FloatArraySerializer.write(DefaultArraySerializers.java:108)
	at com.esotericsoftware.kryo.serializers.DefaultArraySerializers$FloatArraySerializer.write(DefaultArraySerializers.java:97)
	at com.esotericsoftware.kryo.Kryo.writeObjectOrNull(Kryo.java:606)
	at com.esotericsoftware.kryo.serializers.DefaultArraySerializers$ObjectArraySerializer.write(DefaultArraySerializers.java:338)
	at com.esotericsoftware.kryo.serializers.DefaultArraySerializers$ObjectArraySerializer.write(DefaultArraySerializers.java:307)
	at com.esotericsoftware.kryo.Kryo.writeClassAndObject(Kryo.java:628)
	at com.twitter.chill.Tuple2Serializer.write(TupleSerializers.scala:37)
	at com.twitter.chill.Tuple2Serializer.write(TupleSerializers.scala:33)
	at com.esotericsoftware.kryo.Kryo.writeClassAndObject(Kryo.java:628)
	at org.apache.spark.serializer.KryoSerializationStream.writeObject(KryoSerializer.scala:241)
	at org.apache.spark.serializer.SerializationStream.writeValue(Serializer.scala:134)
	at org.apache.spark.storage.DiskBlockObjectWriter.write(DiskBlockObjectWriter.scala:241)
	at org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.write(BypassMergeSortShuffleWriter.java:151)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53)
	at org.apache.spark.scheduler.Task.run(Task.scala:109)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:345)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.io.IOException: 磁盘空间不足。
	at java.io.FileOutputStream.writeBytes(Native Method)
	at java.io.FileOutputStream.write(FileOutputStream.java:326)
	at org.apache.spark.storage.TimeTrackingOutputStream.write(TimeTrackingOutputStream.java:58)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at net.jpountz.lz4.LZ4BlockOutputStream.flushBufferedData(LZ4BlockOutputStream.java:220)
	at net.jpountz.lz4.LZ4BlockOutputStream.write(LZ4BlockOutputStream.java:173)
	at com.esotericsoftware.kryo.io.Output.flush(Output.java:181)
	... 24 more
2021-12-08 10:43:31,809 [Executor task launch worker for task 421] ERROR [org.apache.spark.executor.Executor] - Exception in task 5.0 in stage 204.0 (TID 421)
com.esotericsoftware.kryo.KryoException: java.io.IOException: 磁盘空间不足。
	at com.esotericsoftware.kryo.io.Output.flush(Output.java:183)
	at com.esotericsoftware.kryo.io.Output.require(Output.java:160)
	at com.esotericsoftware.kryo.io.Output.writeInt(Output.java:254)
	at com.esotericsoftware.kryo.io.Output.writeFloat(Output.java:496)
	at com.esotericsoftware.kryo.io.Output.writeFloats(Output.java:711)
	at com.esotericsoftware.kryo.serializers.DefaultArraySerializers$FloatArraySerializer.write(DefaultArraySerializers.java:108)
	at com.esotericsoftware.kryo.serializers.DefaultArraySerializers$FloatArraySerializer.write(DefaultArraySerializers.java:97)
	at com.esotericsoftware.kryo.Kryo.writeObjectOrNull(Kryo.java:606)
	at com.esotericsoftware.kryo.serializers.DefaultArraySerializers$ObjectArraySerializer.write(DefaultArraySerializers.java:338)
	at com.esotericsoftware.kryo.serializers.DefaultArraySerializers$ObjectArraySerializer.write(DefaultArraySerializers.java:307)
	at com.esotericsoftware.kryo.Kryo.writeClassAndObject(Kryo.java:628)
	at com.twitter.chill.Tuple2Serializer.write(TupleSerializers.scala:37)
	at com.twitter.chill.Tuple2Serializer.write(TupleSerializers.scala:33)
	at com.esotericsoftware.kryo.Kryo.writeClassAndObject(Kryo.java:628)
	at org.apache.spark.serializer.KryoSerializationStream.writeObject(KryoSerializer.scala:241)
	at org.apache.spark.serializer.SerializationStream.writeValue(Serializer.scala:134)
	at org.apache.spark.storage.DiskBlockObjectWriter.write(DiskBlockObjectWriter.scala:241)
	at org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.write(BypassMergeSortShuffleWriter.java:151)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53)
	at org.apache.spark.scheduler.Task.run(Task.scala:109)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:345)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.io.IOException: 磁盘空间不足。
	at java.io.FileOutputStream.writeBytes(Native Method)
	at java.io.FileOutputStream.write(FileOutputStream.java:326)
	at org.apache.spark.storage.TimeTrackingOutputStream.write(TimeTrackingOutputStream.java:58)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:121)
	at net.jpountz.lz4.LZ4BlockOutputStream.flushBufferedData(LZ4BlockOutputStream.java:220)
	at net.jpountz.lz4.LZ4BlockOutputStream.write(LZ4BlockOutputStream.java:173)
	at com.esotericsoftware.kryo.io.Output.flush(Output.java:181)
	... 24 more
2021-12-08 10:43:31,809 [Executor task launch worker for task 427] ERROR [org.apache.spark.executor.Executor] - Exception in task 11.0 in stage 204.0 (TID 427)
com.esotericsoftware.kryo.KryoException: java.io.IOException: 磁盘空间不足。
	at com.esotericsoftware.kryo.io.Output.flush(Output.java:183)
	at com.esotericsoftware.kryo.io.Output.require(Output.java:160)
	at com.esotericsoftware.kryo.io.Output.writeInt(Output.java:254)
	at com.esotericsoftware.kryo.io.Output.writeFloat(Output.java:496)
	at com.esotericsoftware.kryo.io.Output.writeFloats(Output.java:711)
	at com.esotericsoftware.kryo.serializers.DefaultArraySerializers$FloatArraySerializer.write(DefaultArraySerializers.java:108)
	at com.esotericsoftware.kryo.serializers.DefaultArraySerializers$FloatArraySerializer.write(DefaultArraySerializers.java:97)
	at com.esotericsoftware.kryo.Kryo.writeObjectOrNull(Kryo.java:606)
	at com.esotericsoftware.kryo.serializers.DefaultArraySerializers$ObjectArraySerializer.write(DefaultArraySerializers.java:338)
	at com.esotericsoftware.kryo.serializers.DefaultArraySerializers$ObjectArraySerializer.write(DefaultArraySerializers.java:307)
	at com.esotericsoftware.kryo.Kryo.writeClassAndObject(Kryo.java:628)
	at com.twitter.chill.Tuple2Serializer.write(TupleSerializers.scala:37)
	at com.twitter.chill.Tuple2Serializer.write(TupleSerializers.scala:33)
	at com.esotericsoftware.kryo.Kryo.writeClassAndObject(Kryo.java:628)
	at org.apache.spark.serializer.KryoSerializationStream.writeObject(KryoSerializer.scala:241)
	at org.apache.spark.serializer.SerializationStream.writeValue(Serializer.scala:134)
	at org.apache.spark.storage.DiskBlockObjectWriter.write(DiskBlockObjectWriter.scala:241)
	at org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.write(BypassMergeSortShuffleWriter.java:151)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53)
	at org.apache.spark.scheduler.Task.run(Task.scala:109)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:345)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.io.IOException: 磁盘空间不足。
	at java.io.FileOutputStream.writeBytes(Native Method)
	at java.io.FileOutputStream.write(FileOutputStream.java:326)
	at org.apache.spark.storage.TimeTrackingOutputStream.write(TimeTrackingOutputStream.java:58)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at net.jpountz.lz4.LZ4BlockOutputStream.flushBufferedData(LZ4BlockOutputStream.java:220)
	at net.jpountz.lz4.LZ4BlockOutputStream.write(LZ4BlockOutputStream.java:173)
	at com.esotericsoftware.kryo.io.Output.flush(Output.java:181)
	... 24 more
2021-12-08 10:43:31,809 [Executor task launch worker for task 424] ERROR [org.apache.spark.executor.Executor] - Exception in task 8.0 in stage 204.0 (TID 424)
com.esotericsoftware.kryo.KryoException: java.io.IOException: 磁盘空间不足。
	at com.esotericsoftware.kryo.io.Output.flush(Output.java:183)
	at com.esotericsoftware.kryo.io.Output.require(Output.java:160)
	at com.esotericsoftware.kryo.io.Output.writeInt(Output.java:254)
	at com.esotericsoftware.kryo.io.Output.writeFloat(Output.java:496)
	at com.esotericsoftware.kryo.io.Output.writeFloats(Output.java:711)
	at com.esotericsoftware.kryo.serializers.DefaultArraySerializers$FloatArraySerializer.write(DefaultArraySerializers.java:108)
	at com.esotericsoftware.kryo.serializers.DefaultArraySerializers$FloatArraySerializer.write(DefaultArraySerializers.java:97)
	at com.esotericsoftware.kryo.Kryo.writeObjectOrNull(Kryo.java:606)
	at com.esotericsoftware.kryo.serializers.DefaultArraySerializers$ObjectArraySerializer.write(DefaultArraySerializers.java:338)
	at com.esotericsoftware.kryo.serializers.DefaultArraySerializers$ObjectArraySerializer.write(DefaultArraySerializers.java:307)
	at com.esotericsoftware.kryo.Kryo.writeClassAndObject(Kryo.java:628)
	at com.twitter.chill.Tuple2Serializer.write(TupleSerializers.scala:37)
	at com.twitter.chill.Tuple2Serializer.write(TupleSerializers.scala:33)
	at com.esotericsoftware.kryo.Kryo.writeClassAndObject(Kryo.java:628)
	at org.apache.spark.serializer.KryoSerializationStream.writeObject(KryoSerializer.scala:241)
	at org.apache.spark.serializer.SerializationStream.writeValue(Serializer.scala:134)
	at org.apache.spark.storage.DiskBlockObjectWriter.write(DiskBlockObjectWriter.scala:241)
	at org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.write(BypassMergeSortShuffleWriter.java:151)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53)
	at org.apache.spark.scheduler.Task.run(Task.scala:109)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:345)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.io.IOException: 磁盘空间不足。
	at java.io.FileOutputStream.writeBytes(Native Method)
	at java.io.FileOutputStream.write(FileOutputStream.java:326)
	at org.apache.spark.storage.TimeTrackingOutputStream.write(TimeTrackingOutputStream.java:58)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at net.jpountz.lz4.LZ4BlockOutputStream.flushBufferedData(LZ4BlockOutputStream.java:220)
	at net.jpountz.lz4.LZ4BlockOutputStream.write(LZ4BlockOutputStream.java:173)
	at com.esotericsoftware.kryo.io.Output.flush(Output.java:181)
	... 24 more
2021-12-08 10:43:31,809 [Executor task launch worker for task 422] ERROR [org.apache.spark.executor.Executor] - Exception in task 6.0 in stage 204.0 (TID 422)
com.esotericsoftware.kryo.KryoException: java.io.IOException: 磁盘空间不足。
	at com.esotericsoftware.kryo.io.Output.flush(Output.java:183)
	at com.esotericsoftware.kryo.io.Output.require(Output.java:160)
	at com.esotericsoftware.kryo.io.Output.writeInt(Output.java:254)
	at com.esotericsoftware.kryo.io.Output.writeFloat(Output.java:496)
	at com.esotericsoftware.kryo.io.Output.writeFloats(Output.java:711)
	at com.esotericsoftware.kryo.serializers.DefaultArraySerializers$FloatArraySerializer.write(DefaultArraySerializers.java:108)
	at com.esotericsoftware.kryo.serializers.DefaultArraySerializers$FloatArraySerializer.write(DefaultArraySerializers.java:97)
	at com.esotericsoftware.kryo.Kryo.writeObjectOrNull(Kryo.java:606)
	at com.esotericsoftware.kryo.serializers.DefaultArraySerializers$ObjectArraySerializer.write(DefaultArraySerializers.java:338)
	at com.esotericsoftware.kryo.serializers.DefaultArraySerializers$ObjectArraySerializer.write(DefaultArraySerializers.java:307)
	at com.esotericsoftware.kryo.Kryo.writeClassAndObject(Kryo.java:628)
	at com.twitter.chill.Tuple2Serializer.write(TupleSerializers.scala:37)
	at com.twitter.chill.Tuple2Serializer.write(TupleSerializers.scala:33)
	at com.esotericsoftware.kryo.Kryo.writeClassAndObject(Kryo.java:628)
	at org.apache.spark.serializer.KryoSerializationStream.writeObject(KryoSerializer.scala:241)
	at org.apache.spark.serializer.SerializationStream.writeValue(Serializer.scala:134)
	at org.apache.spark.storage.DiskBlockObjectWriter.write(DiskBlockObjectWriter.scala:241)
	at org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.write(BypassMergeSortShuffleWriter.java:151)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53)
	at org.apache.spark.scheduler.Task.run(Task.scala:109)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:345)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.io.IOException: 磁盘空间不足。
	at java.io.FileOutputStream.writeBytes(Native Method)
	at java.io.FileOutputStream.write(FileOutputStream.java:326)
	at org.apache.spark.storage.TimeTrackingOutputStream.write(TimeTrackingOutputStream.java:58)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at net.jpountz.lz4.LZ4BlockOutputStream.flushBufferedData(LZ4BlockOutputStream.java:220)
	at net.jpountz.lz4.LZ4BlockOutputStream.write(LZ4BlockOutputStream.java:173)
	at com.esotericsoftware.kryo.io.Output.flush(Output.java:181)
	... 24 more
2021-12-08 10:43:31,809 [Executor task launch worker for task 418] ERROR [org.apache.spark.executor.Executor] - Exception in task 2.0 in stage 204.0 (TID 418)
com.esotericsoftware.kryo.KryoException: java.io.IOException: 磁盘空间不足。
	at com.esotericsoftware.kryo.io.Output.flush(Output.java:183)
	at com.esotericsoftware.kryo.io.Output.require(Output.java:160)
	at com.esotericsoftware.kryo.io.Output.writeInt(Output.java:254)
	at com.esotericsoftware.kryo.io.Output.writeFloat(Output.java:496)
	at com.esotericsoftware.kryo.io.Output.writeFloats(Output.java:711)
	at com.esotericsoftware.kryo.serializers.DefaultArraySerializers$FloatArraySerializer.write(DefaultArraySerializers.java:108)
	at com.esotericsoftware.kryo.serializers.DefaultArraySerializers$FloatArraySerializer.write(DefaultArraySerializers.java:97)
	at com.esotericsoftware.kryo.Kryo.writeObjectOrNull(Kryo.java:606)
	at com.esotericsoftware.kryo.serializers.DefaultArraySerializers$ObjectArraySerializer.write(DefaultArraySerializers.java:338)
	at com.esotericsoftware.kryo.serializers.DefaultArraySerializers$ObjectArraySerializer.write(DefaultArraySerializers.java:307)
	at com.esotericsoftware.kryo.Kryo.writeClassAndObject(Kryo.java:628)
	at com.twitter.chill.Tuple2Serializer.write(TupleSerializers.scala:37)
	at com.twitter.chill.Tuple2Serializer.write(TupleSerializers.scala:33)
	at com.esotericsoftware.kryo.Kryo.writeClassAndObject(Kryo.java:628)
	at org.apache.spark.serializer.KryoSerializationStream.writeObject(KryoSerializer.scala:241)
	at org.apache.spark.serializer.SerializationStream.writeValue(Serializer.scala:134)
	at org.apache.spark.storage.DiskBlockObjectWriter.write(DiskBlockObjectWriter.scala:241)
	at org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.write(BypassMergeSortShuffleWriter.java:151)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53)
	at org.apache.spark.scheduler.Task.run(Task.scala:109)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:345)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.io.IOException: 磁盘空间不足。
	at java.io.FileOutputStream.writeBytes(Native Method)
	at java.io.FileOutputStream.write(FileOutputStream.java:326)
	at org.apache.spark.storage.TimeTrackingOutputStream.write(TimeTrackingOutputStream.java:58)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at net.jpountz.lz4.LZ4BlockOutputStream.flushBufferedData(LZ4BlockOutputStream.java:220)
	at net.jpountz.lz4.LZ4BlockOutputStream.write(LZ4BlockOutputStream.java:173)
	at com.esotericsoftware.kryo.io.Output.flush(Output.java:181)
	... 24 more
2021-12-08 10:43:31,809 [Executor task launch worker for task 426] ERROR [org.apache.spark.executor.Executor] - Exception in task 10.0 in stage 204.0 (TID 426)
java.io.FileNotFoundException: C:\Users\ACER\AppData\Local\Temp\blockmgr-dfed5075-df19-4290-95ed-bfc4d93c7407\36\temp_shuffle_644dafe1-33b2-4514-af66-df79d84bed0b (磁盘空间不足。)
	at java.io.FileOutputStream.open0(Native Method)
	at java.io.FileOutputStream.open(FileOutputStream.java:270)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:213)
	at org.apache.spark.storage.DiskBlockObjectWriter.initialize(DiskBlockObjectWriter.scala:103)
	at org.apache.spark.storage.DiskBlockObjectWriter.open(DiskBlockObjectWriter.scala:116)
	at org.apache.spark.storage.DiskBlockObjectWriter.write(DiskBlockObjectWriter.scala:237)
	at org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.write(BypassMergeSortShuffleWriter.java:151)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53)
	at org.apache.spark.scheduler.Task.run(Task.scala:109)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:345)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
2021-12-08 10:43:31,809 [Executor task launch worker for task 420] ERROR [org.apache.spark.executor.Executor] - Exception in task 4.0 in stage 204.0 (TID 420)
com.esotericsoftware.kryo.KryoException: java.io.IOException: 磁盘空间不足。
	at com.esotericsoftware.kryo.io.Output.flush(Output.java:183)
	at com.esotericsoftware.kryo.io.Output.require(Output.java:160)
	at com.esotericsoftware.kryo.io.Output.writeInt(Output.java:254)
	at com.esotericsoftware.kryo.io.Output.writeFloat(Output.java:496)
	at com.esotericsoftware.kryo.io.Output.writeFloats(Output.java:711)
	at com.esotericsoftware.kryo.serializers.DefaultArraySerializers$FloatArraySerializer.write(DefaultArraySerializers.java:108)
	at com.esotericsoftware.kryo.serializers.DefaultArraySerializers$FloatArraySerializer.write(DefaultArraySerializers.java:97)
	at com.esotericsoftware.kryo.Kryo.writeObjectOrNull(Kryo.java:606)
	at com.esotericsoftware.kryo.serializers.DefaultArraySerializers$ObjectArraySerializer.write(DefaultArraySerializers.java:338)
	at com.esotericsoftware.kryo.serializers.DefaultArraySerializers$ObjectArraySerializer.write(DefaultArraySerializers.java:307)
	at com.esotericsoftware.kryo.Kryo.writeClassAndObject(Kryo.java:628)
	at com.twitter.chill.Tuple2Serializer.write(TupleSerializers.scala:37)
	at com.twitter.chill.Tuple2Serializer.write(TupleSerializers.scala:33)
	at com.esotericsoftware.kryo.Kryo.writeClassAndObject(Kryo.java:628)
	at org.apache.spark.serializer.KryoSerializationStream.writeObject(KryoSerializer.scala:241)
	at org.apache.spark.serializer.SerializationStream.writeValue(Serializer.scala:134)
	at org.apache.spark.storage.DiskBlockObjectWriter.write(DiskBlockObjectWriter.scala:241)
	at org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.write(BypassMergeSortShuffleWriter.java:151)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53)
	at org.apache.spark.scheduler.Task.run(Task.scala:109)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:345)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.io.IOException: 磁盘空间不足。
	at java.io.FileOutputStream.writeBytes(Native Method)
	at java.io.FileOutputStream.write(FileOutputStream.java:326)
	at org.apache.spark.storage.TimeTrackingOutputStream.write(TimeTrackingOutputStream.java:58)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)
	at net.jpountz.lz4.LZ4BlockOutputStream.flushBufferedData(LZ4BlockOutputStream.java:220)
	at net.jpountz.lz4.LZ4BlockOutputStream.write(LZ4BlockOutputStream.java:173)
	at com.esotericsoftware.kryo.io.Output.flush(Output.java:181)
	... 24 more
2021-12-08 10:43:31,809 [Executor task launch worker for task 419] ERROR [org.apache.spark.executor.Executor] - Exception in task 3.0 in stage 204.0 (TID 419)
com.esotericsoftware.kryo.KryoException: java.io.IOException: 磁盘空间不足。
	at com.esotericsoftware.kryo.io.Output.flush(Output.java:183)
	at com.esotericsoftware.kryo.io.Output.require(Output.java:160)
	at com.esotericsoftware.kryo.io.Output.writeInt(Output.java:254)
	at com.esotericsoftware.kryo.io.Output.writeFloat(Output.java:496)
	at com.esotericsoftware.kryo.io.Output.writeFloats(Output.java:711)
	at com.esotericsoftware.kryo.serializers.DefaultArraySerializers$FloatArraySerializer.write(DefaultArraySerializers.java:108)
	at com.esotericsoftware.kryo.serializers.DefaultArraySerializers$FloatArraySerializer.write(DefaultArraySerializers.java:97)
	at com.esotericsoftware.kryo.Kryo.writeObjectOrNull(Kryo.java:606)
	at com.esotericsoftware.kryo.serializers.DefaultArraySerializers$ObjectArraySerializer.write(DefaultArraySerializers.java:338)
	at com.esotericsoftware.kryo.serializers.DefaultArraySerializers$ObjectArraySerializer.write(DefaultArraySerializers.java:307)
	at com.esotericsoftware.kryo.Kryo.writeClassAndObject(Kryo.java:628)
	at com.twitter.chill.Tuple2Serializer.write(TupleSerializers.scala:37)
	at com.twitter.chill.Tuple2Serializer.write(TupleSerializers.scala:33)
	at com.esotericsoftware.kryo.Kryo.writeClassAndObject(Kryo.java:628)
	at org.apache.spark.serializer.KryoSerializationStream.writeObject(KryoSerializer.scala:241)
	at org.apache.spark.serializer.SerializationStream.writeValue(Serializer.scala:134)
	at org.apache.spark.storage.DiskBlockObjectWriter.write(DiskBlockObjectWriter.scala:241)
	at org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.write(BypassMergeSortShuffleWriter.java:151)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53)
	at org.apache.spark.scheduler.Task.run(Task.scala:109)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:345)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.io.IOException: 磁盘空间不足。
	at java.io.FileOutputStream.writeBytes(Native Method)
	at java.io.FileOutputStream.write(FileOutputStream.java:326)
	at org.apache.spark.storage.TimeTrackingOutputStream.write(TimeTrackingOutputStream.java:58)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:121)
	at net.jpountz.lz4.LZ4BlockOutputStream.flushBufferedData(LZ4BlockOutputStream.java:220)
	at net.jpountz.lz4.LZ4BlockOutputStream.write(LZ4BlockOutputStream.java:173)
	at com.esotericsoftware.kryo.io.Output.flush(Output.java:181)
	... 24 more
2021-12-08 10:43:31,809 [Executor task launch worker for task 423] ERROR [org.apache.spark.executor.Executor] - Exception in task 7.0 in stage 204.0 (TID 423)
com.esotericsoftware.kryo.KryoException: java.io.IOException: 磁盘空间不足。
	at com.esotericsoftware.kryo.io.Output.flush(Output.java:183)
	at com.esotericsoftware.kryo.io.Output.require(Output.java:160)
	at com.esotericsoftware.kryo.io.Output.writeInt(Output.java:254)
	at com.esotericsoftware.kryo.io.Output.writeFloat(Output.java:496)
	at com.esotericsoftware.kryo.io.Output.writeFloats(Output.java:711)
	at com.esotericsoftware.kryo.serializers.DefaultArraySerializers$FloatArraySerializer.write(DefaultArraySerializers.java:108)
	at com.esotericsoftware.kryo.serializers.DefaultArraySerializers$FloatArraySerializer.write(DefaultArraySerializers.java:97)
	at com.esotericsoftware.kryo.Kryo.writeObjectOrNull(Kryo.java:606)
	at com.esotericsoftware.kryo.serializers.DefaultArraySerializers$ObjectArraySerializer.write(DefaultArraySerializers.java:338)
	at com.esotericsoftware.kryo.serializers.DefaultArraySerializers$ObjectArraySerializer.write(DefaultArraySerializers.java:307)
	at com.esotericsoftware.kryo.Kryo.writeClassAndObject(Kryo.java:628)
	at com.twitter.chill.Tuple2Serializer.write(TupleSerializers.scala:37)
	at com.twitter.chill.Tuple2Serializer.write(TupleSerializers.scala:33)
	at com.esotericsoftware.kryo.Kryo.writeClassAndObject(Kryo.java:628)
	at org.apache.spark.serializer.KryoSerializationStream.writeObject(KryoSerializer.scala:241)
	at org.apache.spark.serializer.SerializationStream.writeValue(Serializer.scala:134)
	at org.apache.spark.storage.DiskBlockObjectWriter.write(DiskBlockObjectWriter.scala:241)
	at org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.write(BypassMergeSortShuffleWriter.java:151)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53)
	at org.apache.spark.scheduler.Task.run(Task.scala:109)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:345)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.io.IOException: 磁盘空间不足。
	at java.io.FileOutputStream.writeBytes(Native Method)
	at java.io.FileOutputStream.write(FileOutputStream.java:326)
	at org.apache.spark.storage.TimeTrackingOutputStream.write(TimeTrackingOutputStream.java:58)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:121)
	at net.jpountz.lz4.LZ4BlockOutputStream.flushBufferedData(LZ4BlockOutputStream.java:220)
	at net.jpountz.lz4.LZ4BlockOutputStream.write(LZ4BlockOutputStream.java:173)
	at com.esotericsoftware.kryo.io.Output.flush(Output.java:181)
	... 24 more
2021-12-08 10:43:31,838 [task-result-getter-2] WARN [org.apache.spark.scheduler.TaskSetManager] - Lost task 10.0 in stage 204.0 (TID 426, localhost, executor driver): java.io.FileNotFoundException: C:\Users\ACER\AppData\Local\Temp\blockmgr-dfed5075-df19-4290-95ed-bfc4d93c7407\36\temp_shuffle_644dafe1-33b2-4514-af66-df79d84bed0b (磁盘空间不足。)
	at java.io.FileOutputStream.open0(Native Method)
	at java.io.FileOutputStream.open(FileOutputStream.java:270)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:213)
	at org.apache.spark.storage.DiskBlockObjectWriter.initialize(DiskBlockObjectWriter.scala:103)
	at org.apache.spark.storage.DiskBlockObjectWriter.open(DiskBlockObjectWriter.scala:116)
	at org.apache.spark.storage.DiskBlockObjectWriter.write(DiskBlockObjectWriter.scala:237)
	at org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.write(BypassMergeSortShuffleWriter.java:151)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53)
	at org.apache.spark.scheduler.Task.run(Task.scala:109)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:345)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)

2021-12-08 10:43:31,839 [task-result-getter-2] ERROR [org.apache.spark.scheduler.TaskSetManager] - Task 10 in stage 204.0 failed 1 times; aborting job
2021-12-08 10:43:31,840 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 204.0, whose tasks have all completed, from pool 
2021-12-08 10:43:31,840 [task-result-getter-1] WARN [org.apache.spark.scheduler.TaskSetManager] - Lost task 6.0 in stage 204.0 (TID 422, localhost, executor driver): com.esotericsoftware.kryo.KryoException: java.io.IOException: 磁盘空间不足。
	at com.esotericsoftware.kryo.io.Output.flush(Output.java:183)
	at com.esotericsoftware.kryo.io.Output.require(Output.java:160)
	at com.esotericsoftware.kryo.io.Output.writeInt(Output.java:254)
	at com.esotericsoftware.kryo.io.Output.writeFloat(Output.java:496)
	at com.esotericsoftware.kryo.io.Output.writeFloats(Output.java:711)
	at com.esotericsoftware.kryo.serializers.DefaultArraySerializers$FloatArraySerializer.write(DefaultArraySerializers.java:108)
	at com.esotericsoftware.kryo.serializers.DefaultArraySerializers$FloatArraySerializer.write(DefaultArraySerializers.java:97)
	at com.esotericsoftware.kryo.Kryo.writeObjectOrNull(Kryo.java:606)
	at com.esotericsoftware.kryo.serializers.DefaultArraySerializers$ObjectArraySerializer.write(DefaultArraySerializers.java:338)
	at com.esotericsoftware.kryo.serializers.DefaultArraySerializers$ObjectArraySerializer.write(DefaultArraySerializers.java:307)
	at com.esotericsoftware.kryo.Kryo.writeClassAndObject(Kryo.java:628)
	at com.twitter.chill.Tuple2Serializer.write(TupleSerializers.scala:37)
	at com.twitter.chill.Tuple2Serializer.write(TupleSerializers.scala:33)
	at com.esotericsoftware.kryo.Kryo.writeClassAndObject(Kryo.java:628)
	at org.apache.spark.serializer.KryoSerializationStream.writeObject(KryoSerializer.scala:241)
	at org.apache.spark.serializer.SerializationStream.writeValue(Serializer.scala:134)
	at org.apache.spark.storage.DiskBlockObjectWriter.write(DiskBlockObjectWriter.scala:241)
	at org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.write(BypassMergeSortShuffleWriter.java:151)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53)
	at org.apache.spark.scheduler.Task.run(Task.scala:109)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:345)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.io.IOException: 磁盘空间不足。
	at java.io.FileOutputStream.writeBytes(Native Method)
	at java.io.FileOutputStream.write(FileOutputStream.java:326)
	at org.apache.spark.storage.TimeTrackingOutputStream.write(TimeTrackingOutputStream.java:58)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at net.jpountz.lz4.LZ4BlockOutputStream.flushBufferedData(LZ4BlockOutputStream.java:220)
	at net.jpountz.lz4.LZ4BlockOutputStream.write(LZ4BlockOutputStream.java:173)
	at com.esotericsoftware.kryo.io.Output.flush(Output.java:181)
	... 24 more

2021-12-08 10:43:31,840 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 204.0, whose tasks have all completed, from pool 
2021-12-08 10:43:31,841 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Lost task 5.0 in stage 204.0 (TID 421) on localhost, executor driver: com.esotericsoftware.kryo.KryoException (java.io.IOException: 磁盘空间不足。) [duplicate 1]
2021-12-08 10:43:31,841 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 204.0, whose tasks have all completed, from pool 
2021-12-08 10:43:31,841 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Lost task 1.0 in stage 204.0 (TID 417) on localhost, executor driver: com.esotericsoftware.kryo.KryoException (java.io.IOException: 磁盘空间不足。) [duplicate 2]
2021-12-08 10:43:31,841 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 204.0, whose tasks have all completed, from pool 
2021-12-08 10:43:31,841 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Lost task 8.0 in stage 204.0 (TID 424) on localhost, executor driver: com.esotericsoftware.kryo.KryoException (java.io.IOException: 磁盘空间不足。) [duplicate 3]
2021-12-08 10:43:31,841 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 204.0, whose tasks have all completed, from pool 
2021-12-08 10:43:31,842 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Lost task 3.0 in stage 204.0 (TID 419) on localhost, executor driver: com.esotericsoftware.kryo.KryoException (java.io.IOException: 磁盘空间不足。) [duplicate 4]
2021-12-08 10:43:31,842 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 204.0, whose tasks have all completed, from pool 
2021-12-08 10:43:31,842 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Lost task 4.0 in stage 204.0 (TID 420) on localhost, executor driver: com.esotericsoftware.kryo.KryoException (java.io.IOException: 磁盘空间不足。) [duplicate 5]
2021-12-08 10:43:31,842 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 204.0, whose tasks have all completed, from pool 
2021-12-08 10:43:31,842 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Lost task 2.0 in stage 204.0 (TID 418) on localhost, executor driver: com.esotericsoftware.kryo.KryoException (java.io.IOException: 磁盘空间不足。) [duplicate 6]
2021-12-08 10:43:31,842 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 204.0, whose tasks have all completed, from pool 
2021-12-08 10:43:31,842 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Lost task 0.0 in stage 204.0 (TID 416) on localhost, executor driver: com.esotericsoftware.kryo.KryoException (java.io.IOException: 磁盘空间不足。) [duplicate 7]
2021-12-08 10:43:31,843 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 204.0, whose tasks have all completed, from pool 
2021-12-08 10:43:31,843 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Lost task 9.0 in stage 204.0 (TID 425) on localhost, executor driver: com.esotericsoftware.kryo.KryoException (java.io.IOException: 磁盘空间不足。) [duplicate 8]
2021-12-08 10:43:31,843 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 204.0, whose tasks have all completed, from pool 
2021-12-08 10:43:31,843 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Lost task 7.0 in stage 204.0 (TID 423) on localhost, executor driver: com.esotericsoftware.kryo.KryoException (java.io.IOException: 磁盘空间不足。) [duplicate 9]
2021-12-08 10:43:31,843 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 204.0, whose tasks have all completed, from pool 
2021-12-08 10:43:31,843 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Lost task 11.0 in stage 204.0 (TID 427) on localhost, executor driver: com.esotericsoftware.kryo.KryoException (java.io.IOException: 磁盘空间不足。) [duplicate 10]
2021-12-08 10:43:31,843 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 204.0, whose tasks have all completed, from pool 
2021-12-08 10:43:31,845 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Cancelling stage 204
2021-12-08 10:43:31,846 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ShuffleMapStage 204 (flatMap at ALS.scala:1653) failed in 1.546 s due to Job aborted due to stage failure: Task 10 in stage 204.0 failed 1 times, most recent failure: Lost task 10.0 in stage 204.0 (TID 426, localhost, executor driver): java.io.FileNotFoundException: C:\Users\ACER\AppData\Local\Temp\blockmgr-dfed5075-df19-4290-95ed-bfc4d93c7407\36\temp_shuffle_644dafe1-33b2-4514-af66-df79d84bed0b (磁盘空间不足。)
	at java.io.FileOutputStream.open0(Native Method)
	at java.io.FileOutputStream.open(FileOutputStream.java:270)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:213)
	at org.apache.spark.storage.DiskBlockObjectWriter.initialize(DiskBlockObjectWriter.scala:103)
	at org.apache.spark.storage.DiskBlockObjectWriter.open(DiskBlockObjectWriter.scala:116)
	at org.apache.spark.storage.DiskBlockObjectWriter.write(DiskBlockObjectWriter.scala:237)
	at org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.write(BypassMergeSortShuffleWriter.java:151)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53)
	at org.apache.spark.scheduler.Task.run(Task.scala:109)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:345)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)

Driver stacktrace:
2021-12-08 10:43:31,848 [main] INFO [org.apache.spark.scheduler.DAGScheduler] - Job 19 failed: aggregate at ALS.scala:1711, took 1.550513 s
2021-12-08 10:43:31,853 [Thread-1] INFO [org.apache.spark.SparkContext] - Invoking stop() from shutdown hook
2021-12-08 10:43:31,860 [Thread-1] INFO [org.spark_project.jetty.server.AbstractConnector] - Stopped Spark@5b800468{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2021-12-08 10:43:31,862 [Thread-1] INFO [org.apache.spark.ui.SparkUI] - Stopped Spark web UI at http://qb:4040
2021-12-08 10:43:31,875 [dispatcher-event-loop-5] INFO [org.apache.spark.MapOutputTrackerMasterEndpoint] - MapOutputTrackerMasterEndpoint stopped!
2021-12-08 10:43:32,302 [Thread-1] ERROR [org.apache.spark.storage.DiskBlockManager] - Exception while deleting local spark dir: C:\Users\ACER\AppData\Local\Temp\blockmgr-dfed5075-df19-4290-95ed-bfc4d93c7407
java.io.IOException: Failed to delete: C:\Users\ACER\AppData\Local\Temp\blockmgr-dfed5075-df19-4290-95ed-bfc4d93c7407
	at org.apache.spark.util.Utils$.deleteRecursively(Utils.scala:1070)
	at org.apache.spark.storage.DiskBlockManager$$anonfun$org$apache$spark$storage$DiskBlockManager$$doStop$1.apply(DiskBlockManager.scala:178)
	at org.apache.spark.storage.DiskBlockManager$$anonfun$org$apache$spark$storage$DiskBlockManager$$doStop$1.apply(DiskBlockManager.scala:174)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:186)
	at org.apache.spark.storage.DiskBlockManager.org$apache$spark$storage$DiskBlockManager$$doStop(DiskBlockManager.scala:174)
	at org.apache.spark.storage.DiskBlockManager.stop(DiskBlockManager.scala:169)
	at org.apache.spark.storage.BlockManager.stop(BlockManager.scala:1544)
	at org.apache.spark.SparkEnv.stop(SparkEnv.scala:90)
	at org.apache.spark.SparkContext$$anonfun$stop$11.apply$mcV$sp(SparkContext.scala:1940)
	at org.apache.spark.util.Utils$.tryLogNonFatalError(Utils.scala:1357)
	at org.apache.spark.SparkContext.stop(SparkContext.scala:1939)
	at org.apache.spark.SparkContext$$anonfun$2.apply$mcV$sp(SparkContext.scala:572)
	at org.apache.spark.util.SparkShutdownHook.run(ShutdownHookManager.scala:216)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply$mcV$sp(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1988)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply$mcV$sp(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply(ShutdownHookManager.scala:188)
	at scala.util.Try$.apply(Try.scala:192)
	at org.apache.spark.util.SparkShutdownHookManager.runAll(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anon$2.run(ShutdownHookManager.scala:178)
	at org.apache.hadoop.util.ShutdownHookManager$1.run(ShutdownHookManager.java:54)
2021-12-08 10:43:32,304 [Thread-1] INFO [org.apache.spark.storage.memory.MemoryStore] - MemoryStore cleared
2021-12-08 10:43:32,304 [Thread-1] INFO [org.apache.spark.storage.BlockManager] - BlockManager stopped
2021-12-08 10:43:32,305 [Thread-1] INFO [org.apache.spark.storage.BlockManagerMaster] - BlockManagerMaster stopped
2021-12-08 10:43:32,308 [dispatcher-event-loop-11] INFO [org.apache.spark.scheduler.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint] - OutputCommitCoordinator stopped!
2021-12-08 10:43:32,312 [Thread-1] INFO [org.apache.spark.SparkContext] - Successfully stopped SparkContext
2021-12-08 10:43:32,312 [Thread-1] INFO [org.apache.spark.util.ShutdownHookManager] - Shutdown hook called
2021-12-08 10:43:32,313 [Thread-1] INFO [org.apache.spark.util.ShutdownHookManager] - Deleting directory C:\Users\ACER\AppData\Local\Temp\spark-e97d81bc-a577-4c1a-a02f-bcab48dcf5ea
2021-12-08 14:37:49,594 [main] INFO [org.apache.spark.SparkContext] - Running Spark version 2.3.0
2021-12-08 14:37:49,894 [main] INFO [org.apache.spark.SparkContext] - Submitted application: PaidPromotionAdjustParameter
2021-12-08 14:37:49,944 [main] INFO [org.apache.spark.SecurityManager] - Changing view acls to: ACER,root
2021-12-08 14:37:49,945 [main] INFO [org.apache.spark.SecurityManager] - Changing modify acls to: ACER,root
2021-12-08 14:37:49,945 [main] INFO [org.apache.spark.SecurityManager] - Changing view acls groups to: 
2021-12-08 14:37:49,945 [main] INFO [org.apache.spark.SecurityManager] - Changing modify acls groups to: 
2021-12-08 14:37:49,946 [main] INFO [org.apache.spark.SecurityManager] - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(ACER, root); groups with view permissions: Set(); users  with modify permissions: Set(ACER, root); groups with modify permissions: Set()
2021-12-08 14:37:50,525 [main] INFO [org.apache.spark.util.Utils] - Successfully started service 'sparkDriver' on port 62173.
2021-12-08 14:37:50,541 [main] INFO [org.apache.spark.SparkEnv] - Registering MapOutputTracker
2021-12-08 14:37:50,555 [main] INFO [org.apache.spark.SparkEnv] - Registering BlockManagerMaster
2021-12-08 14:37:50,557 [main] INFO [org.apache.spark.storage.BlockManagerMasterEndpoint] - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2021-12-08 14:37:50,558 [main] INFO [org.apache.spark.storage.BlockManagerMasterEndpoint] - BlockManagerMasterEndpoint up
2021-12-08 14:37:50,564 [main] INFO [org.apache.spark.storage.DiskBlockManager] - Created local directory at C:\Users\ACER\AppData\Local\Temp\blockmgr-410d5f4d-56df-4e3b-bf14-3880bd3441ca
2021-12-08 14:37:50,580 [main] INFO [org.apache.spark.storage.memory.MemoryStore] - MemoryStore started with capacity 1990.8 MB
2021-12-08 14:37:50,589 [main] INFO [org.apache.spark.SparkEnv] - Registering OutputCommitCoordinator
2021-12-08 14:37:50,640 [main] INFO [org.spark_project.jetty.util.log] - Logging initialized @1891ms
2021-12-08 14:37:50,689 [main] INFO [org.spark_project.jetty.server.Server] - jetty-9.3.z-SNAPSHOT
2021-12-08 14:37:50,700 [main] INFO [org.spark_project.jetty.server.Server] - Started @1952ms
2021-12-08 14:37:50,726 [main] INFO [org.spark_project.jetty.server.AbstractConnector] - Started ServerConnector@5f7f2382{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2021-12-08 14:37:50,726 [main] INFO [org.apache.spark.util.Utils] - Successfully started service 'SparkUI' on port 4040.
2021-12-08 14:37:50,746 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@3af17be2{/jobs,null,AVAILABLE,@Spark}
2021-12-08 14:37:50,747 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@6a1d204a{/jobs/json,null,AVAILABLE,@Spark}
2021-12-08 14:37:50,748 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@72ccd81a{/jobs/job,null,AVAILABLE,@Spark}
2021-12-08 14:37:50,749 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@5d25e6bb{/jobs/job/json,null,AVAILABLE,@Spark}
2021-12-08 14:37:50,751 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@7859e786{/stages,null,AVAILABLE,@Spark}
2021-12-08 14:37:50,752 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@5118388b{/stages/json,null,AVAILABLE,@Spark}
2021-12-08 14:37:50,753 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@71104a4{/stages/stage,null,AVAILABLE,@Spark}
2021-12-08 14:37:50,754 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@332a7fce{/stages/stage/json,null,AVAILABLE,@Spark}
2021-12-08 14:37:50,755 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@37ebc9d8{/stages/pool,null,AVAILABLE,@Spark}
2021-12-08 14:37:50,756 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@6e9319f{/stages/pool/json,null,AVAILABLE,@Spark}
2021-12-08 14:37:50,757 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@2c177f9e{/storage,null,AVAILABLE,@Spark}
2021-12-08 14:37:50,758 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@f9b7332{/storage/json,null,AVAILABLE,@Spark}
2021-12-08 14:37:50,759 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@192f2f27{/storage/rdd,null,AVAILABLE,@Spark}
2021-12-08 14:37:50,760 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@b672aa8{/storage/rdd/json,null,AVAILABLE,@Spark}
2021-12-08 14:37:50,761 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@7997b197{/environment,null,AVAILABLE,@Spark}
2021-12-08 14:37:50,762 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@11acdc30{/environment/json,null,AVAILABLE,@Spark}
2021-12-08 14:37:50,764 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@611f8234{/executors,null,AVAILABLE,@Spark}
2021-12-08 14:37:50,766 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@62923ee6{/executors/json,null,AVAILABLE,@Spark}
2021-12-08 14:37:50,767 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@4b6166aa{/executors/threadDump,null,AVAILABLE,@Spark}
2021-12-08 14:37:50,768 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@a1217f9{/executors/threadDump/json,null,AVAILABLE,@Spark}
2021-12-08 14:37:50,773 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@791cbf87{/static,null,AVAILABLE,@Spark}
2021-12-08 14:37:50,774 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@cf65451{/,null,AVAILABLE,@Spark}
2021-12-08 14:37:50,776 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@46074492{/api,null,AVAILABLE,@Spark}
2021-12-08 14:37:50,777 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@5ae76500{/jobs/job/kill,null,AVAILABLE,@Spark}
2021-12-08 14:37:50,778 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@24f360b2{/stages/stage/kill,null,AVAILABLE,@Spark}
2021-12-08 14:37:50,780 [main] INFO [org.apache.spark.ui.SparkUI] - Bound SparkUI to 0.0.0.0, and started at http://qb:4040
2021-12-08 14:37:50,855 [main] INFO [org.apache.spark.executor.Executor] - Starting executor ID driver on host localhost
2021-12-08 14:37:50,900 [main] INFO [org.apache.spark.util.Utils] - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 62214.
2021-12-08 14:37:50,900 [main] INFO [org.apache.spark.network.netty.NettyBlockTransferService] - Server created on qb:62214
2021-12-08 14:37:50,901 [main] INFO [org.apache.spark.storage.BlockManager] - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2021-12-08 14:37:50,902 [main] INFO [org.apache.spark.storage.BlockManagerMaster] - Registering BlockManager BlockManagerId(driver, qb, 62214, None)
2021-12-08 14:37:50,904 [dispatcher-event-loop-10] INFO [org.apache.spark.storage.BlockManagerMasterEndpoint] - Registering block manager qb:62214 with 1990.8 MB RAM, BlockManagerId(driver, qb, 62214, None)
2021-12-08 14:37:50,906 [main] INFO [org.apache.spark.storage.BlockManagerMaster] - Registered BlockManager BlockManagerId(driver, qb, 62214, None)
2021-12-08 14:37:50,906 [main] INFO [org.apache.spark.storage.BlockManager] - Initialized BlockManager: BlockManagerId(driver, qb, 62214, None)
2021-12-08 14:37:51,019 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@7c9b78e3{/metrics/json,null,AVAILABLE,@Spark}
2021-12-08 14:37:51,459 [main] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_0 stored as values in memory (estimated size 312.7 KB, free 1990.5 MB)
2021-12-08 14:37:51,645 [main] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_0_piece0 stored as bytes in memory (estimated size 27.3 KB, free 1990.5 MB)
2021-12-08 14:37:51,646 [dispatcher-event-loop-0] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_0_piece0 in memory on qb:62214 (size: 27.3 KB, free: 1990.8 MB)
2021-12-08 14:37:51,649 [main] INFO [org.apache.spark.SparkContext] - Created broadcast 0 from textFile at PaidPromotionAdjustParameter.scala:50
2021-12-08 14:37:51,954 [main] WARN [org.apache.hadoop.hdfs.shortcircuit.DomainSocketFactory] - The short-circuit local reads feature cannot be used because UNIX Domain sockets are not available on Windows.
2021-12-08 14:37:52,089 [main] INFO [org.apache.hadoop.mapred.FileInputFormat] - Total input paths to process : 1
2021-12-08 14:37:52,126 [main] INFO [org.apache.spark.SparkContext] - Starting job: count at PaidPromotionAdjustParameter.scala:52
2021-12-08 14:37:52,135 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 0 (count at PaidPromotionAdjustParameter.scala:52) with 20 output partitions
2021-12-08 14:37:52,135 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 0 (count at PaidPromotionAdjustParameter.scala:52)
2021-12-08 14:37:52,135 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List()
2021-12-08 14:37:52,136 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2021-12-08 14:37:52,141 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 0 (/sk/chongqing/data/behavior_data.bcp MapPartitionsRDD[1] at textFile at PaidPromotionAdjustParameter.scala:50), which has no missing parents
2021-12-08 14:37:52,171 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_1 stored as values in memory (estimated size 3.1 KB, free 1990.5 MB)
2021-12-08 14:37:52,176 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_1_piece0 stored as bytes in memory (estimated size 1903.0 B, free 1990.5 MB)
2021-12-08 14:37:52,177 [dispatcher-event-loop-1] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_1_piece0 in memory on qb:62214 (size: 1903.0 B, free: 1990.8 MB)
2021-12-08 14:37:52,177 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 1 from broadcast at DAGScheduler.scala:1039
2021-12-08 14:37:52,186 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 20 missing tasks from ResultStage 0 (/sk/chongqing/data/behavior_data.bcp MapPartitionsRDD[1] at textFile at PaidPromotionAdjustParameter.scala:50) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14))
2021-12-08 14:37:52,187 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 0.0 with 20 tasks
2021-12-08 14:37:52,221 [dispatcher-event-loop-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 0.0 (TID 0, localhost, executor driver, partition 0, ANY, 7899 bytes)
2021-12-08 14:37:52,223 [dispatcher-event-loop-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 0.0 (TID 1, localhost, executor driver, partition 1, ANY, 7899 bytes)
2021-12-08 14:37:52,223 [dispatcher-event-loop-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 2.0 in stage 0.0 (TID 2, localhost, executor driver, partition 2, ANY, 7899 bytes)
2021-12-08 14:37:52,223 [dispatcher-event-loop-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 3.0 in stage 0.0 (TID 3, localhost, executor driver, partition 3, ANY, 7899 bytes)
2021-12-08 14:37:52,224 [dispatcher-event-loop-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 4.0 in stage 0.0 (TID 4, localhost, executor driver, partition 4, ANY, 7899 bytes)
2021-12-08 14:37:52,224 [dispatcher-event-loop-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 5.0 in stage 0.0 (TID 5, localhost, executor driver, partition 5, ANY, 7899 bytes)
2021-12-08 14:37:52,224 [dispatcher-event-loop-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 6.0 in stage 0.0 (TID 6, localhost, executor driver, partition 6, ANY, 7899 bytes)
2021-12-08 14:37:52,224 [dispatcher-event-loop-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 7.0 in stage 0.0 (TID 7, localhost, executor driver, partition 7, ANY, 7899 bytes)
2021-12-08 14:37:52,225 [dispatcher-event-loop-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 8.0 in stage 0.0 (TID 8, localhost, executor driver, partition 8, ANY, 7899 bytes)
2021-12-08 14:37:52,225 [dispatcher-event-loop-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 9.0 in stage 0.0 (TID 9, localhost, executor driver, partition 9, ANY, 7899 bytes)
2021-12-08 14:37:52,225 [dispatcher-event-loop-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 10.0 in stage 0.0 (TID 10, localhost, executor driver, partition 10, ANY, 7899 bytes)
2021-12-08 14:37:52,225 [dispatcher-event-loop-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 11.0 in stage 0.0 (TID 11, localhost, executor driver, partition 11, ANY, 7899 bytes)
2021-12-08 14:37:52,230 [Executor task launch worker for task 6] INFO [org.apache.spark.executor.Executor] - Running task 6.0 in stage 0.0 (TID 6)
2021-12-08 14:37:52,230 [Executor task launch worker for task 11] INFO [org.apache.spark.executor.Executor] - Running task 11.0 in stage 0.0 (TID 11)
2021-12-08 14:37:52,230 [Executor task launch worker for task 8] INFO [org.apache.spark.executor.Executor] - Running task 8.0 in stage 0.0 (TID 8)
2021-12-08 14:37:52,230 [Executor task launch worker for task 9] INFO [org.apache.spark.executor.Executor] - Running task 9.0 in stage 0.0 (TID 9)
2021-12-08 14:37:52,230 [Executor task launch worker for task 2] INFO [org.apache.spark.executor.Executor] - Running task 2.0 in stage 0.0 (TID 2)
2021-12-08 14:37:52,230 [Executor task launch worker for task 7] INFO [org.apache.spark.executor.Executor] - Running task 7.0 in stage 0.0 (TID 7)
2021-12-08 14:37:52,230 [Executor task launch worker for task 4] INFO [org.apache.spark.executor.Executor] - Running task 4.0 in stage 0.0 (TID 4)
2021-12-08 14:37:52,230 [Executor task launch worker for task 5] INFO [org.apache.spark.executor.Executor] - Running task 5.0 in stage 0.0 (TID 5)
2021-12-08 14:37:52,230 [Executor task launch worker for task 0] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 0.0 (TID 0)
2021-12-08 14:37:52,230 [Executor task launch worker for task 3] INFO [org.apache.spark.executor.Executor] - Running task 3.0 in stage 0.0 (TID 3)
2021-12-08 14:37:52,230 [Executor task launch worker for task 10] INFO [org.apache.spark.executor.Executor] - Running task 10.0 in stage 0.0 (TID 10)
2021-12-08 14:37:52,230 [Executor task launch worker for task 1] INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 0.0 (TID 1)
2021-12-08 14:37:52,270 [Executor task launch worker for task 0] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:0+134217728
2021-12-08 14:37:52,270 [Executor task launch worker for task 1] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:134217728+134217728
2021-12-08 14:37:52,270 [Executor task launch worker for task 3] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:402653184+134217728
2021-12-08 14:37:52,270 [Executor task launch worker for task 10] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:1342177280+134217728
2021-12-08 14:37:52,270 [Executor task launch worker for task 9] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:1207959552+134217728
2021-12-08 14:37:52,270 [Executor task launch worker for task 6] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:805306368+134217728
2021-12-08 14:37:52,270 [Executor task launch worker for task 5] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:671088640+134217728
2021-12-08 14:37:52,270 [Executor task launch worker for task 2] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:268435456+134217728
2021-12-08 14:37:52,270 [Executor task launch worker for task 7] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:939524096+134217728
2021-12-08 14:37:52,270 [Executor task launch worker for task 11] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:1476395008+134217728
2021-12-08 14:37:52,270 [Executor task launch worker for task 8] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:1073741824+134217728
2021-12-08 14:37:52,270 [Executor task launch worker for task 4] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:536870912+134217728
2021-12-08 14:39:43,911 [Executor task launch worker for task 8] INFO [org.apache.spark.executor.Executor] - Finished task 8.0 in stage 0.0 (TID 8). 755 bytes result sent to driver
2021-12-08 14:39:43,912 [dispatcher-event-loop-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 12.0 in stage 0.0 (TID 12, localhost, executor driver, partition 12, ANY, 7899 bytes)
2021-12-08 14:39:43,913 [Executor task launch worker for task 12] INFO [org.apache.spark.executor.Executor] - Running task 12.0 in stage 0.0 (TID 12)
2021-12-08 14:39:43,914 [Executor task launch worker for task 12] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:1610612736+134217728
2021-12-08 14:39:43,920 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 8.0 in stage 0.0 (TID 8) in 111695 ms on localhost (executor driver) (1/20)
2021-12-08 14:40:22,610 [Executor task launch worker for task 2] INFO [org.apache.spark.executor.Executor] - Finished task 2.0 in stage 0.0 (TID 2). 755 bytes result sent to driver
2021-12-08 14:40:22,610 [dispatcher-event-loop-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 13.0 in stage 0.0 (TID 13, localhost, executor driver, partition 13, ANY, 7899 bytes)
2021-12-08 14:40:22,611 [Executor task launch worker for task 13] INFO [org.apache.spark.executor.Executor] - Running task 13.0 in stage 0.0 (TID 13)
2021-12-08 14:40:22,612 [Executor task launch worker for task 13] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:1744830464+134217728
2021-12-08 14:40:22,613 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 2.0 in stage 0.0 (TID 2) in 150390 ms on localhost (executor driver) (2/20)
2021-12-08 14:40:28,772 [Executor task launch worker for task 3] INFO [org.apache.spark.executor.Executor] - Finished task 3.0 in stage 0.0 (TID 3). 755 bytes result sent to driver
2021-12-08 14:40:28,772 [dispatcher-event-loop-4] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 14.0 in stage 0.0 (TID 14, localhost, executor driver, partition 14, ANY, 7899 bytes)
2021-12-08 14:40:28,773 [Executor task launch worker for task 14] INFO [org.apache.spark.executor.Executor] - Running task 14.0 in stage 0.0 (TID 14)
2021-12-08 14:40:28,774 [Executor task launch worker for task 14] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:1879048192+134217728
2021-12-08 14:40:28,775 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 3.0 in stage 0.0 (TID 3) in 156552 ms on localhost (executor driver) (3/20)
2021-12-08 14:40:29,499 [Executor task launch worker for task 6] INFO [org.apache.spark.executor.Executor] - Finished task 6.0 in stage 0.0 (TID 6). 755 bytes result sent to driver
2021-12-08 14:40:29,500 [dispatcher-event-loop-6] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 15.0 in stage 0.0 (TID 15, localhost, executor driver, partition 15, ANY, 7899 bytes)
2021-12-08 14:40:29,500 [Executor task launch worker for task 15] INFO [org.apache.spark.executor.Executor] - Running task 15.0 in stage 0.0 (TID 15)
2021-12-08 14:40:29,501 [Executor task launch worker for task 15] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:2013265920+134217728
2021-12-08 14:40:29,502 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 6.0 in stage 0.0 (TID 6) in 157278 ms on localhost (executor driver) (4/20)
2021-12-08 14:40:30,570 [Executor task launch worker for task 9] INFO [org.apache.spark.executor.Executor] - Finished task 9.0 in stage 0.0 (TID 9). 755 bytes result sent to driver
2021-12-08 14:40:30,571 [dispatcher-event-loop-9] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 16.0 in stage 0.0 (TID 16, localhost, executor driver, partition 16, ANY, 7899 bytes)
2021-12-08 14:40:30,571 [Executor task launch worker for task 16] INFO [org.apache.spark.executor.Executor] - Running task 16.0 in stage 0.0 (TID 16)
2021-12-08 14:40:30,571 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 9.0 in stage 0.0 (TID 9) in 158346 ms on localhost (executor driver) (5/20)
2021-12-08 14:40:30,572 [Executor task launch worker for task 16] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:2147483648+134217728
2021-12-08 14:40:36,385 [Executor task launch worker for task 11] INFO [org.apache.spark.executor.Executor] - Finished task 11.0 in stage 0.0 (TID 11). 755 bytes result sent to driver
2021-12-08 14:40:36,385 [dispatcher-event-loop-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 17.0 in stage 0.0 (TID 17, localhost, executor driver, partition 17, ANY, 7899 bytes)
2021-12-08 14:40:36,385 [Executor task launch worker for task 17] INFO [org.apache.spark.executor.Executor] - Running task 17.0 in stage 0.0 (TID 17)
2021-12-08 14:40:36,385 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 11.0 in stage 0.0 (TID 11) in 164160 ms on localhost (executor driver) (6/20)
2021-12-08 14:40:36,386 [Executor task launch worker for task 17] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:2281701376+134217728
2021-12-08 14:40:39,826 [Executor task launch worker for task 0] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 0.0 (TID 0). 755 bytes result sent to driver
2021-12-08 14:40:39,827 [dispatcher-event-loop-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 18.0 in stage 0.0 (TID 18, localhost, executor driver, partition 18, ANY, 7899 bytes)
2021-12-08 14:40:39,827 [Executor task launch worker for task 18] INFO [org.apache.spark.executor.Executor] - Running task 18.0 in stage 0.0 (TID 18)
2021-12-08 14:40:39,827 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 0.0 (TID 0) in 167616 ms on localhost (executor driver) (7/20)
2021-12-08 14:40:39,828 [Executor task launch worker for task 18] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:2415919104+134217728
2021-12-08 14:40:40,117 [Executor task launch worker for task 10] INFO [org.apache.spark.executor.Executor] - Finished task 10.0 in stage 0.0 (TID 10). 755 bytes result sent to driver
2021-12-08 14:40:40,117 [dispatcher-event-loop-4] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 19.0 in stage 0.0 (TID 19, localhost, executor driver, partition 19, ANY, 7899 bytes)
2021-12-08 14:40:40,117 [Executor task launch worker for task 19] INFO [org.apache.spark.executor.Executor] - Running task 19.0 in stage 0.0 (TID 19)
2021-12-08 14:40:40,117 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 10.0 in stage 0.0 (TID 10) in 167892 ms on localhost (executor driver) (8/20)
2021-12-08 14:40:40,118 [Executor task launch worker for task 19] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:2550136832+85027535
2021-12-08 14:40:40,332 [Executor task launch worker for task 7] INFO [org.apache.spark.executor.Executor] - Finished task 7.0 in stage 0.0 (TID 7). 755 bytes result sent to driver
2021-12-08 14:40:40,334 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 7.0 in stage 0.0 (TID 7) in 168110 ms on localhost (executor driver) (9/20)
2021-12-08 14:40:41,834 [Executor task launch worker for task 1] INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 0.0 (TID 1). 755 bytes result sent to driver
2021-12-08 14:40:41,834 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 0.0 (TID 1) in 169612 ms on localhost (executor driver) (10/20)
2021-12-08 14:40:43,489 [Executor task launch worker for task 5] INFO [org.apache.spark.executor.Executor] - Finished task 5.0 in stage 0.0 (TID 5). 755 bytes result sent to driver
2021-12-08 14:40:43,489 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 5.0 in stage 0.0 (TID 5) in 171265 ms on localhost (executor driver) (11/20)
2021-12-08 14:40:52,794 [Executor task launch worker for task 4] INFO [org.apache.spark.executor.Executor] - Finished task 4.0 in stage 0.0 (TID 4). 755 bytes result sent to driver
2021-12-08 14:40:52,795 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 4.0 in stage 0.0 (TID 4) in 180572 ms on localhost (executor driver) (12/20)
2021-12-08 14:41:31,867 [Executor task launch worker for task 19] INFO [org.apache.spark.executor.Executor] - Finished task 19.0 in stage 0.0 (TID 19). 755 bytes result sent to driver
2021-12-08 14:41:31,868 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 19.0 in stage 0.0 (TID 19) in 51751 ms on localhost (executor driver) (13/20)
2021-12-08 14:41:52,335 [Executor task launch worker for task 13] INFO [org.apache.spark.executor.Executor] - Finished task 13.0 in stage 0.0 (TID 13). 755 bytes result sent to driver
2021-12-08 14:41:52,335 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 13.0 in stage 0.0 (TID 13) in 89725 ms on localhost (executor driver) (14/20)
2021-12-08 14:41:54,010 [Executor task launch worker for task 15] INFO [org.apache.spark.executor.Executor] - Finished task 15.0 in stage 0.0 (TID 15). 712 bytes result sent to driver
2021-12-08 14:41:54,010 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 15.0 in stage 0.0 (TID 15) in 84511 ms on localhost (executor driver) (15/20)
2021-12-08 14:41:55,756 [Executor task launch worker for task 18] INFO [org.apache.spark.executor.Executor] - Finished task 18.0 in stage 0.0 (TID 18). 755 bytes result sent to driver
2021-12-08 14:41:55,756 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 18.0 in stage 0.0 (TID 18) in 75929 ms on localhost (executor driver) (16/20)
2021-12-08 14:42:03,435 [Executor task launch worker for task 12] INFO [org.apache.spark.executor.Executor] - Finished task 12.0 in stage 0.0 (TID 12). 712 bytes result sent to driver
2021-12-08 14:42:03,436 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 12.0 in stage 0.0 (TID 12) in 139524 ms on localhost (executor driver) (17/20)
2021-12-08 14:42:06,081 [Executor task launch worker for task 16] INFO [org.apache.spark.executor.Executor] - Finished task 16.0 in stage 0.0 (TID 16). 755 bytes result sent to driver
2021-12-08 14:42:06,081 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 16.0 in stage 0.0 (TID 16) in 95511 ms on localhost (executor driver) (18/20)
2021-12-08 14:42:09,493 [Executor task launch worker for task 14] INFO [org.apache.spark.executor.Executor] - Finished task 14.0 in stage 0.0 (TID 14). 712 bytes result sent to driver
2021-12-08 14:42:09,493 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 14.0 in stage 0.0 (TID 14) in 100721 ms on localhost (executor driver) (19/20)
2021-12-08 14:42:11,395 [Executor task launch worker for task 17] INFO [org.apache.spark.executor.Executor] - Finished task 17.0 in stage 0.0 (TID 17). 755 bytes result sent to driver
2021-12-08 14:42:11,395 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 17.0 in stage 0.0 (TID 17) in 95010 ms on localhost (executor driver) (20/20)
2021-12-08 14:42:11,396 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 0.0, whose tasks have all completed, from pool 
2021-12-08 14:42:11,396 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 0 (count at PaidPromotionAdjustParameter.scala:52) finished in 259.241 s
2021-12-08 14:42:11,400 [main] INFO [org.apache.spark.scheduler.DAGScheduler] - Job 0 finished: count at PaidPromotionAdjustParameter.scala:52, took 259.273761 s
2021-12-08 14:42:11,401 [main] INFO [PaidPromotionAdjustParameter$] - 收视总数60870678
2021-12-08 14:42:11,419 [main] INFO [org.apache.spark.SparkContext] - Starting job: count at PaidPromotionAdjustParameter.scala:61
2021-12-08 14:42:11,426 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 3 (map at PaidPromotionAdjustParameter.scala:60)
2021-12-08 14:42:11,427 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 1 (count at PaidPromotionAdjustParameter.scala:61) with 20 output partitions
2021-12-08 14:42:11,427 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 2 (count at PaidPromotionAdjustParameter.scala:61)
2021-12-08 14:42:11,427 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 1)
2021-12-08 14:42:11,427 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List(ShuffleMapStage 1)
2021-12-08 14:42:11,428 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ShuffleMapStage 1 (MapPartitionsRDD[3] at map at PaidPromotionAdjustParameter.scala:60), which has no missing parents
2021-12-08 14:42:11,436 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_2 stored as values in memory (estimated size 4.7 KB, free 1990.5 MB)
2021-12-08 14:42:11,439 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_2_piece0 stored as bytes in memory (estimated size 2.7 KB, free 1990.5 MB)
2021-12-08 14:42:11,440 [dispatcher-event-loop-2] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_2_piece0 in memory on qb:62214 (size: 2.7 KB, free: 1990.8 MB)
2021-12-08 14:42:11,441 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 2 from broadcast at DAGScheduler.scala:1039
2021-12-08 14:42:11,444 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 20 missing tasks from ShuffleMapStage 1 (MapPartitionsRDD[3] at map at PaidPromotionAdjustParameter.scala:60) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14))
2021-12-08 14:42:11,444 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 1.0 with 20 tasks
2021-12-08 14:42:11,445 [dispatcher-event-loop-8] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 1.0 (TID 20, localhost, executor driver, partition 0, ANY, 7888 bytes)
2021-12-08 14:42:11,445 [dispatcher-event-loop-8] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 1.0 (TID 21, localhost, executor driver, partition 1, ANY, 7888 bytes)
2021-12-08 14:42:11,446 [dispatcher-event-loop-8] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 2.0 in stage 1.0 (TID 22, localhost, executor driver, partition 2, ANY, 7888 bytes)
2021-12-08 14:42:11,446 [dispatcher-event-loop-8] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 3.0 in stage 1.0 (TID 23, localhost, executor driver, partition 3, ANY, 7888 bytes)
2021-12-08 14:42:11,446 [dispatcher-event-loop-8] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 4.0 in stage 1.0 (TID 24, localhost, executor driver, partition 4, ANY, 7888 bytes)
2021-12-08 14:42:11,446 [dispatcher-event-loop-8] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 5.0 in stage 1.0 (TID 25, localhost, executor driver, partition 5, ANY, 7888 bytes)
2021-12-08 14:42:11,446 [dispatcher-event-loop-8] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 6.0 in stage 1.0 (TID 26, localhost, executor driver, partition 6, ANY, 7888 bytes)
2021-12-08 14:42:11,447 [dispatcher-event-loop-8] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 7.0 in stage 1.0 (TID 27, localhost, executor driver, partition 7, ANY, 7888 bytes)
2021-12-08 14:42:11,447 [dispatcher-event-loop-8] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 8.0 in stage 1.0 (TID 28, localhost, executor driver, partition 8, ANY, 7888 bytes)
2021-12-08 14:42:11,447 [dispatcher-event-loop-8] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 9.0 in stage 1.0 (TID 29, localhost, executor driver, partition 9, ANY, 7888 bytes)
2021-12-08 14:42:11,447 [dispatcher-event-loop-8] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 10.0 in stage 1.0 (TID 30, localhost, executor driver, partition 10, ANY, 7888 bytes)
2021-12-08 14:42:11,447 [dispatcher-event-loop-8] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 11.0 in stage 1.0 (TID 31, localhost, executor driver, partition 11, ANY, 7888 bytes)
2021-12-08 14:42:11,448 [Executor task launch worker for task 22] INFO [org.apache.spark.executor.Executor] - Running task 2.0 in stage 1.0 (TID 22)
2021-12-08 14:42:11,448 [Executor task launch worker for task 25] INFO [org.apache.spark.executor.Executor] - Running task 5.0 in stage 1.0 (TID 25)
2021-12-08 14:42:11,448 [Executor task launch worker for task 27] INFO [org.apache.spark.executor.Executor] - Running task 7.0 in stage 1.0 (TID 27)
2021-12-08 14:42:11,448 [Executor task launch worker for task 26] INFO [org.apache.spark.executor.Executor] - Running task 6.0 in stage 1.0 (TID 26)
2021-12-08 14:42:11,448 [Executor task launch worker for task 23] INFO [org.apache.spark.executor.Executor] - Running task 3.0 in stage 1.0 (TID 23)
2021-12-08 14:42:11,448 [Executor task launch worker for task 24] INFO [org.apache.spark.executor.Executor] - Running task 4.0 in stage 1.0 (TID 24)
2021-12-08 14:42:11,448 [Executor task launch worker for task 21] INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 1.0 (TID 21)
2021-12-08 14:42:11,448 [Executor task launch worker for task 20] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 1.0 (TID 20)
2021-12-08 14:42:11,450 [Executor task launch worker for task 28] INFO [org.apache.spark.executor.Executor] - Running task 8.0 in stage 1.0 (TID 28)
2021-12-08 14:42:11,451 [Executor task launch worker for task 29] INFO [org.apache.spark.executor.Executor] - Running task 9.0 in stage 1.0 (TID 29)
2021-12-08 14:42:11,451 [Executor task launch worker for task 31] INFO [org.apache.spark.executor.Executor] - Running task 11.0 in stage 1.0 (TID 31)
2021-12-08 14:42:11,451 [Executor task launch worker for task 30] INFO [org.apache.spark.executor.Executor] - Running task 10.0 in stage 1.0 (TID 30)
2021-12-08 14:42:11,455 [Executor task launch worker for task 30] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:1342177280+134217728
2021-12-08 14:42:11,455 [Executor task launch worker for task 27] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:939524096+134217728
2021-12-08 14:42:11,455 [Executor task launch worker for task 20] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:0+134217728
2021-12-08 14:42:11,455 [Executor task launch worker for task 24] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:536870912+134217728
2021-12-08 14:42:11,455 [Executor task launch worker for task 22] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:268435456+134217728
2021-12-08 14:42:11,455 [Executor task launch worker for task 26] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:805306368+134217728
2021-12-08 14:42:11,455 [Executor task launch worker for task 31] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:1476395008+134217728
2021-12-08 14:42:11,455 [Executor task launch worker for task 28] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:1073741824+134217728
2021-12-08 14:42:11,455 [Executor task launch worker for task 21] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:134217728+134217728
2021-12-08 14:42:11,455 [Executor task launch worker for task 23] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:402653184+134217728
2021-12-08 14:42:11,455 [Executor task launch worker for task 29] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:1207959552+134217728
2021-12-08 14:42:11,455 [Executor task launch worker for task 25] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:671088640+134217728
2021-12-08 14:44:16,116 [Executor task launch worker for task 25] INFO [org.apache.spark.executor.Executor] - Finished task 5.0 in stage 1.0 (TID 25). 1050 bytes result sent to driver
2021-12-08 14:44:16,117 [dispatcher-event-loop-7] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 12.0 in stage 1.0 (TID 32, localhost, executor driver, partition 12, ANY, 7888 bytes)
2021-12-08 14:44:16,117 [Executor task launch worker for task 32] INFO [org.apache.spark.executor.Executor] - Running task 12.0 in stage 1.0 (TID 32)
2021-12-08 14:44:16,118 [Executor task launch worker for task 32] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:1610612736+134217728
2021-12-08 14:44:16,132 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 5.0 in stage 1.0 (TID 25) in 124686 ms on localhost (executor driver) (1/20)
2021-12-08 14:44:41,258 [Executor task launch worker for task 23] INFO [org.apache.spark.executor.Executor] - Finished task 3.0 in stage 1.0 (TID 23). 1050 bytes result sent to driver
2021-12-08 14:44:41,259 [dispatcher-event-loop-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 13.0 in stage 1.0 (TID 33, localhost, executor driver, partition 13, ANY, 7888 bytes)
2021-12-08 14:44:41,259 [Executor task launch worker for task 33] INFO [org.apache.spark.executor.Executor] - Running task 13.0 in stage 1.0 (TID 33)
2021-12-08 14:44:41,259 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 3.0 in stage 1.0 (TID 23) in 149813 ms on localhost (executor driver) (2/20)
2021-12-08 14:44:41,260 [Executor task launch worker for task 33] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:1744830464+134217728
2021-12-08 14:44:42,310 [Executor task launch worker for task 21] INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 1.0 (TID 21). 1050 bytes result sent to driver
2021-12-08 14:44:42,310 [dispatcher-event-loop-5] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 14.0 in stage 1.0 (TID 34, localhost, executor driver, partition 14, ANY, 7888 bytes)
2021-12-08 14:44:42,310 [Executor task launch worker for task 34] INFO [org.apache.spark.executor.Executor] - Running task 14.0 in stage 1.0 (TID 34)
2021-12-08 14:44:42,311 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 1.0 (TID 21) in 150866 ms on localhost (executor driver) (3/20)
2021-12-08 14:44:42,311 [Executor task launch worker for task 34] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:1879048192+134217728
2021-12-08 14:44:42,755 [Executor task launch worker for task 29] INFO [org.apache.spark.executor.Executor] - Finished task 9.0 in stage 1.0 (TID 29). 1050 bytes result sent to driver
2021-12-08 14:44:42,756 [dispatcher-event-loop-7] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 15.0 in stage 1.0 (TID 35, localhost, executor driver, partition 15, ANY, 7888 bytes)
2021-12-08 14:44:42,756 [Executor task launch worker for task 35] INFO [org.apache.spark.executor.Executor] - Running task 15.0 in stage 1.0 (TID 35)
2021-12-08 14:44:42,756 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 9.0 in stage 1.0 (TID 29) in 151309 ms on localhost (executor driver) (4/20)
2021-12-08 14:44:42,757 [Executor task launch worker for task 35] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:2013265920+134217728
2021-12-08 14:44:42,954 [Executor task launch worker for task 24] INFO [org.apache.spark.executor.Executor] - Finished task 4.0 in stage 1.0 (TID 24). 1050 bytes result sent to driver
2021-12-08 14:44:42,954 [dispatcher-event-loop-10] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 16.0 in stage 1.0 (TID 36, localhost, executor driver, partition 16, ANY, 7888 bytes)
2021-12-08 14:44:42,955 [Executor task launch worker for task 36] INFO [org.apache.spark.executor.Executor] - Running task 16.0 in stage 1.0 (TID 36)
2021-12-08 14:44:42,955 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 4.0 in stage 1.0 (TID 24) in 151509 ms on localhost (executor driver) (5/20)
2021-12-08 14:44:42,955 [Executor task launch worker for task 36] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:2147483648+134217728
2021-12-08 14:44:46,076 [Executor task launch worker for task 22] INFO [org.apache.spark.executor.Executor] - Finished task 2.0 in stage 1.0 (TID 22). 1050 bytes result sent to driver
2021-12-08 14:44:46,077 [dispatcher-event-loop-11] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 17.0 in stage 1.0 (TID 37, localhost, executor driver, partition 17, ANY, 7888 bytes)
2021-12-08 14:44:46,077 [Executor task launch worker for task 37] INFO [org.apache.spark.executor.Executor] - Running task 17.0 in stage 1.0 (TID 37)
2021-12-08 14:44:46,077 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 2.0 in stage 1.0 (TID 22) in 154632 ms on localhost (executor driver) (6/20)
2021-12-08 14:44:46,078 [Executor task launch worker for task 37] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:2281701376+134217728
2021-12-08 14:44:48,791 [Executor task launch worker for task 27] INFO [org.apache.spark.executor.Executor] - Finished task 7.0 in stage 1.0 (TID 27). 1050 bytes result sent to driver
2021-12-08 14:44:48,791 [dispatcher-event-loop-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 18.0 in stage 1.0 (TID 38, localhost, executor driver, partition 18, ANY, 7888 bytes)
2021-12-08 14:44:48,791 [Executor task launch worker for task 38] INFO [org.apache.spark.executor.Executor] - Running task 18.0 in stage 1.0 (TID 38)
2021-12-08 14:44:48,791 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 7.0 in stage 1.0 (TID 27) in 157345 ms on localhost (executor driver) (7/20)
2021-12-08 14:44:48,792 [Executor task launch worker for task 38] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:2415919104+134217728
2021-12-08 14:44:49,846 [Executor task launch worker for task 26] INFO [org.apache.spark.executor.Executor] - Finished task 6.0 in stage 1.0 (TID 26). 1050 bytes result sent to driver
2021-12-08 14:44:49,847 [dispatcher-event-loop-5] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 19.0 in stage 1.0 (TID 39, localhost, executor driver, partition 19, ANY, 7888 bytes)
2021-12-08 14:44:49,847 [Executor task launch worker for task 39] INFO [org.apache.spark.executor.Executor] - Running task 19.0 in stage 1.0 (TID 39)
2021-12-08 14:44:49,847 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 6.0 in stage 1.0 (TID 26) in 158401 ms on localhost (executor driver) (8/20)
2021-12-08 14:44:49,848 [Executor task launch worker for task 39] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:2550136832+85027535
2021-12-08 14:44:51,961 [Executor task launch worker for task 31] INFO [org.apache.spark.executor.Executor] - Finished task 11.0 in stage 1.0 (TID 31). 1050 bytes result sent to driver
2021-12-08 14:44:51,962 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 11.0 in stage 1.0 (TID 31) in 160515 ms on localhost (executor driver) (9/20)
2021-12-08 14:44:52,944 [Executor task launch worker for task 28] INFO [org.apache.spark.executor.Executor] - Finished task 8.0 in stage 1.0 (TID 28). 1050 bytes result sent to driver
2021-12-08 14:44:52,945 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 8.0 in stage 1.0 (TID 28) in 161497 ms on localhost (executor driver) (10/20)
2021-12-08 14:44:53,692 [Executor task launch worker for task 20] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 1.0 (TID 20). 1050 bytes result sent to driver
2021-12-08 14:44:53,692 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 1.0 (TID 20) in 162248 ms on localhost (executor driver) (11/20)
2021-12-08 14:45:11,866 [Executor task launch worker for task 30] INFO [org.apache.spark.executor.Executor] - Finished task 10.0 in stage 1.0 (TID 30). 1050 bytes result sent to driver
2021-12-08 14:45:11,867 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 10.0 in stage 1.0 (TID 30) in 180420 ms on localhost (executor driver) (12/20)
2021-12-08 14:45:56,166 [Executor task launch worker for task 39] INFO [org.apache.spark.executor.Executor] - Finished task 19.0 in stage 1.0 (TID 39). 1050 bytes result sent to driver
2021-12-08 14:45:56,167 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 19.0 in stage 1.0 (TID 39) in 66320 ms on localhost (executor driver) (13/20)
2021-12-08 14:46:13,092 [Executor task launch worker for task 32] INFO [org.apache.spark.executor.Executor] - Finished task 12.0 in stage 1.0 (TID 32). 1050 bytes result sent to driver
2021-12-08 14:46:13,092 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 12.0 in stage 1.0 (TID 32) in 116975 ms on localhost (executor driver) (14/20)
2021-12-08 14:46:21,955 [Executor task launch worker for task 38] INFO [org.apache.spark.executor.Executor] - Finished task 18.0 in stage 1.0 (TID 38). 1093 bytes result sent to driver
2021-12-08 14:46:21,955 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 18.0 in stage 1.0 (TID 38) in 93164 ms on localhost (executor driver) (15/20)
2021-12-08 14:46:45,192 [Executor task launch worker for task 36] INFO [org.apache.spark.executor.Executor] - Finished task 16.0 in stage 1.0 (TID 36). 1007 bytes result sent to driver
2021-12-08 14:46:45,193 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 16.0 in stage 1.0 (TID 36) in 122239 ms on localhost (executor driver) (16/20)
2021-12-08 14:46:45,678 [Executor task launch worker for task 33] INFO [org.apache.spark.executor.Executor] - Finished task 13.0 in stage 1.0 (TID 33). 1007 bytes result sent to driver
2021-12-08 14:46:45,678 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 13.0 in stage 1.0 (TID 33) in 124419 ms on localhost (executor driver) (17/20)
2021-12-08 14:46:46,724 [Executor task launch worker for task 37] INFO [org.apache.spark.executor.Executor] - Finished task 17.0 in stage 1.0 (TID 37). 1050 bytes result sent to driver
2021-12-08 14:46:46,724 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 17.0 in stage 1.0 (TID 37) in 120647 ms on localhost (executor driver) (18/20)
2021-12-08 14:46:46,792 [Executor task launch worker for task 34] INFO [org.apache.spark.executor.Executor] - Finished task 14.0 in stage 1.0 (TID 34). 1050 bytes result sent to driver
2021-12-08 14:46:46,792 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 14.0 in stage 1.0 (TID 34) in 124482 ms on localhost (executor driver) (19/20)
2021-12-08 14:46:47,706 [Executor task launch worker for task 35] INFO [org.apache.spark.executor.Executor] - Finished task 15.0 in stage 1.0 (TID 35). 1050 bytes result sent to driver
2021-12-08 14:46:47,707 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 15.0 in stage 1.0 (TID 35) in 124952 ms on localhost (executor driver) (20/20)
2021-12-08 14:46:47,707 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 1.0, whose tasks have all completed, from pool 
2021-12-08 14:46:47,707 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ShuffleMapStage 1 (map at PaidPromotionAdjustParameter.scala:60) finished in 276.276 s
2021-12-08 14:46:47,708 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - looking for newly runnable stages
2021-12-08 14:46:47,708 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - running: Set()
2021-12-08 14:46:47,708 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - waiting: Set(ResultStage 2)
2021-12-08 14:46:47,708 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - failed: Set()
2021-12-08 14:46:47,711 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 2 (ShuffledRDD[4] at reduceByKey at PaidPromotionAdjustParameter.scala:60), which has no missing parents
2021-12-08 14:46:47,716 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_3 stored as values in memory (estimated size 3.0 KB, free 1990.5 MB)
2021-12-08 14:46:47,718 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_3_piece0 stored as bytes in memory (estimated size 1907.0 B, free 1990.5 MB)
2021-12-08 14:46:47,718 [dispatcher-event-loop-10] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_3_piece0 in memory on qb:62214 (size: 1907.0 B, free: 1990.8 MB)
2021-12-08 14:46:47,719 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 3 from broadcast at DAGScheduler.scala:1039
2021-12-08 14:46:47,719 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 20 missing tasks from ResultStage 2 (ShuffledRDD[4] at reduceByKey at PaidPromotionAdjustParameter.scala:60) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14))
2021-12-08 14:46:47,719 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 2.0 with 20 tasks
2021-12-08 14:46:47,720 [dispatcher-event-loop-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 2.0 (TID 40, localhost, executor driver, partition 0, ANY, 7649 bytes)
2021-12-08 14:46:47,720 [dispatcher-event-loop-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 2.0 (TID 41, localhost, executor driver, partition 1, ANY, 7649 bytes)
2021-12-08 14:46:47,720 [dispatcher-event-loop-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 2.0 in stage 2.0 (TID 42, localhost, executor driver, partition 2, ANY, 7649 bytes)
2021-12-08 14:46:47,720 [dispatcher-event-loop-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 3.0 in stage 2.0 (TID 43, localhost, executor driver, partition 3, ANY, 7649 bytes)
2021-12-08 14:46:47,720 [dispatcher-event-loop-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 4.0 in stage 2.0 (TID 44, localhost, executor driver, partition 4, ANY, 7649 bytes)
2021-12-08 14:46:47,721 [dispatcher-event-loop-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 5.0 in stage 2.0 (TID 45, localhost, executor driver, partition 5, ANY, 7649 bytes)
2021-12-08 14:46:47,721 [dispatcher-event-loop-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 6.0 in stage 2.0 (TID 46, localhost, executor driver, partition 6, ANY, 7649 bytes)
2021-12-08 14:46:47,721 [dispatcher-event-loop-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 7.0 in stage 2.0 (TID 47, localhost, executor driver, partition 7, ANY, 7649 bytes)
2021-12-08 14:46:47,721 [dispatcher-event-loop-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 8.0 in stage 2.0 (TID 48, localhost, executor driver, partition 8, ANY, 7649 bytes)
2021-12-08 14:46:47,721 [dispatcher-event-loop-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 9.0 in stage 2.0 (TID 49, localhost, executor driver, partition 9, ANY, 7649 bytes)
2021-12-08 14:46:47,721 [dispatcher-event-loop-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 10.0 in stage 2.0 (TID 50, localhost, executor driver, partition 10, ANY, 7649 bytes)
2021-12-08 14:46:47,721 [dispatcher-event-loop-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 11.0 in stage 2.0 (TID 51, localhost, executor driver, partition 11, ANY, 7649 bytes)
2021-12-08 14:46:47,721 [Executor task launch worker for task 41] INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 2.0 (TID 41)
2021-12-08 14:46:47,721 [Executor task launch worker for task 45] INFO [org.apache.spark.executor.Executor] - Running task 5.0 in stage 2.0 (TID 45)
2021-12-08 14:46:47,721 [Executor task launch worker for task 47] INFO [org.apache.spark.executor.Executor] - Running task 7.0 in stage 2.0 (TID 47)
2021-12-08 14:46:47,721 [Executor task launch worker for task 46] INFO [org.apache.spark.executor.Executor] - Running task 6.0 in stage 2.0 (TID 46)
2021-12-08 14:46:47,721 [Executor task launch worker for task 44] INFO [org.apache.spark.executor.Executor] - Running task 4.0 in stage 2.0 (TID 44)
2021-12-08 14:46:47,721 [Executor task launch worker for task 43] INFO [org.apache.spark.executor.Executor] - Running task 3.0 in stage 2.0 (TID 43)
2021-12-08 14:46:47,721 [Executor task launch worker for task 42] INFO [org.apache.spark.executor.Executor] - Running task 2.0 in stage 2.0 (TID 42)
2021-12-08 14:46:47,723 [Executor task launch worker for task 51] INFO [org.apache.spark.executor.Executor] - Running task 11.0 in stage 2.0 (TID 51)
2021-12-08 14:46:47,721 [Executor task launch worker for task 40] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 2.0 (TID 40)
2021-12-08 14:46:47,723 [Executor task launch worker for task 49] INFO [org.apache.spark.executor.Executor] - Running task 9.0 in stage 2.0 (TID 49)
2021-12-08 14:46:47,723 [Executor task launch worker for task 50] INFO [org.apache.spark.executor.Executor] - Running task 10.0 in stage 2.0 (TID 50)
2021-12-08 14:46:47,722 [Executor task launch worker for task 48] INFO [org.apache.spark.executor.Executor] - Running task 8.0 in stage 2.0 (TID 48)
2021-12-08 14:46:47,735 [Executor task launch worker for task 40] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 20 non-empty blocks out of 20 blocks
2021-12-08 14:46:47,735 [Executor task launch worker for task 45] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 20 non-empty blocks out of 20 blocks
2021-12-08 14:46:47,735 [Executor task launch worker for task 46] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 20 non-empty blocks out of 20 blocks
2021-12-08 14:46:47,735 [Executor task launch worker for task 42] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 20 non-empty blocks out of 20 blocks
2021-12-08 14:46:47,735 [Executor task launch worker for task 44] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 20 non-empty blocks out of 20 blocks
2021-12-08 14:46:47,735 [Executor task launch worker for task 48] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 20 non-empty blocks out of 20 blocks
2021-12-08 14:46:47,735 [Executor task launch worker for task 49] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 20 non-empty blocks out of 20 blocks
2021-12-08 14:46:47,735 [Executor task launch worker for task 43] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 20 non-empty blocks out of 20 blocks
2021-12-08 14:46:47,735 [Executor task launch worker for task 47] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 20 non-empty blocks out of 20 blocks
2021-12-08 14:46:47,735 [Executor task launch worker for task 41] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 20 non-empty blocks out of 20 blocks
2021-12-08 14:46:47,735 [Executor task launch worker for task 50] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 20 non-empty blocks out of 20 blocks
2021-12-08 14:46:47,735 [Executor task launch worker for task 51] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 20 non-empty blocks out of 20 blocks
2021-12-08 14:46:47,737 [Executor task launch worker for task 50] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 6 ms
2021-12-08 14:46:47,737 [Executor task launch worker for task 40] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 6 ms
2021-12-08 14:46:47,737 [Executor task launch worker for task 45] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 6 ms
2021-12-08 14:46:47,737 [Executor task launch worker for task 49] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 6 ms
2021-12-08 14:46:47,737 [Executor task launch worker for task 47] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 6 ms
2021-12-08 14:46:47,737 [Executor task launch worker for task 43] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 6 ms
2021-12-08 14:46:47,737 [Executor task launch worker for task 44] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 6 ms
2021-12-08 14:46:47,737 [Executor task launch worker for task 46] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 6 ms
2021-12-08 14:46:47,737 [Executor task launch worker for task 42] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 6 ms
2021-12-08 14:46:47,737 [Executor task launch worker for task 48] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 6 ms
2021-12-08 14:46:47,737 [Executor task launch worker for task 41] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 6 ms
2021-12-08 14:46:47,737 [Executor task launch worker for task 51] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 6 ms
2021-12-08 14:46:47,903 [dispatcher-event-loop-1] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_2_piece0 on qb:62214 in memory (size: 2.7 KB, free: 1990.8 MB)
2021-12-08 14:46:47,920 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 13
2021-12-08 14:46:47,921 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 21
2021-12-08 14:46:47,921 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 9
2021-12-08 14:46:47,921 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 3
2021-12-08 14:46:47,921 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 10
2021-12-08 14:46:47,921 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 17
2021-12-08 14:46:47,921 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 18
2021-12-08 14:46:47,921 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 0
2021-12-08 14:46:47,921 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 15
2021-12-08 14:46:47,921 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 16
2021-12-08 14:46:47,921 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 4
2021-12-08 14:46:47,921 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 7
2021-12-08 14:46:47,921 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 11
2021-12-08 14:46:47,921 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 20
2021-12-08 14:46:47,932 [dispatcher-event-loop-4] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_1_piece0 on qb:62214 in memory (size: 1903.0 B, free: 1990.8 MB)
2021-12-08 14:46:47,933 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1
2021-12-08 14:46:47,933 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 5
2021-12-08 14:46:47,933 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 12
2021-12-08 14:46:47,933 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 2
2021-12-08 14:46:47,933 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 23
2021-12-08 14:46:47,933 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 22
2021-12-08 14:46:47,933 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 8
2021-12-08 14:46:47,933 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 6
2021-12-08 14:46:47,933 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 24
2021-12-08 14:46:47,933 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 14
2021-12-08 14:46:47,933 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 19
2021-12-08 14:46:48,263 [Executor task launch worker for task 44] INFO [org.apache.spark.executor.Executor] - Finished task 4.0 in stage 2.0 (TID 44). 1098 bytes result sent to driver
2021-12-08 14:46:48,264 [dispatcher-event-loop-5] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 12.0 in stage 2.0 (TID 52, localhost, executor driver, partition 12, ANY, 7649 bytes)
2021-12-08 14:46:48,264 [Executor task launch worker for task 52] INFO [org.apache.spark.executor.Executor] - Running task 12.0 in stage 2.0 (TID 52)
2021-12-08 14:46:48,265 [Executor task launch worker for task 52] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 20 non-empty blocks out of 20 blocks
2021-12-08 14:46:48,265 [Executor task launch worker for task 52] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-08 14:46:48,270 [Executor task launch worker for task 48] INFO [org.apache.spark.executor.Executor] - Finished task 8.0 in stage 2.0 (TID 48). 1098 bytes result sent to driver
2021-12-08 14:46:48,270 [Executor task launch worker for task 40] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 2.0 (TID 40). 1098 bytes result sent to driver
2021-12-08 14:46:48,271 [Executor task launch worker for task 51] INFO [org.apache.spark.executor.Executor] - Finished task 11.0 in stage 2.0 (TID 51). 1055 bytes result sent to driver
2021-12-08 14:46:48,271 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 4.0 in stage 2.0 (TID 44) in 551 ms on localhost (executor driver) (1/20)
2021-12-08 14:46:48,271 [dispatcher-event-loop-7] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 13.0 in stage 2.0 (TID 53, localhost, executor driver, partition 13, ANY, 7649 bytes)
2021-12-08 14:46:48,271 [Executor task launch worker for task 53] INFO [org.apache.spark.executor.Executor] - Running task 13.0 in stage 2.0 (TID 53)
2021-12-08 14:46:48,271 [dispatcher-event-loop-7] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 14.0 in stage 2.0 (TID 54, localhost, executor driver, partition 14, ANY, 7649 bytes)
2021-12-08 14:46:48,272 [dispatcher-event-loop-7] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 15.0 in stage 2.0 (TID 55, localhost, executor driver, partition 15, ANY, 7649 bytes)
2021-12-08 14:46:48,273 [Executor task launch worker for task 53] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 20 non-empty blocks out of 20 blocks
2021-12-08 14:46:48,273 [Executor task launch worker for task 53] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 1 ms
2021-12-08 14:46:48,275 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 8.0 in stage 2.0 (TID 48) in 554 ms on localhost (executor driver) (2/20)
2021-12-08 14:46:48,275 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 2.0 (TID 40) in 555 ms on localhost (executor driver) (3/20)
2021-12-08 14:46:48,275 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 11.0 in stage 2.0 (TID 51) in 554 ms on localhost (executor driver) (4/20)
2021-12-08 14:46:48,276 [Executor task launch worker for task 45] INFO [org.apache.spark.executor.Executor] - Finished task 5.0 in stage 2.0 (TID 45). 1098 bytes result sent to driver
2021-12-08 14:46:48,276 [Executor task launch worker for task 54] INFO [org.apache.spark.executor.Executor] - Running task 14.0 in stage 2.0 (TID 54)
2021-12-08 14:46:48,277 [Executor task launch worker for task 55] INFO [org.apache.spark.executor.Executor] - Running task 15.0 in stage 2.0 (TID 55)
2021-12-08 14:46:48,277 [Executor task launch worker for task 54] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 20 non-empty blocks out of 20 blocks
2021-12-08 14:46:48,277 [Executor task launch worker for task 54] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-08 14:46:48,277 [Executor task launch worker for task 46] INFO [org.apache.spark.executor.Executor] - Finished task 6.0 in stage 2.0 (TID 46). 1098 bytes result sent to driver
2021-12-08 14:46:48,277 [dispatcher-event-loop-10] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 16.0 in stage 2.0 (TID 56, localhost, executor driver, partition 16, ANY, 7649 bytes)
2021-12-08 14:46:48,278 [Executor task launch worker for task 55] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 20 non-empty blocks out of 20 blocks
2021-12-08 14:46:48,278 [Executor task launch worker for task 55] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-08 14:46:48,278 [dispatcher-event-loop-10] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 17.0 in stage 2.0 (TID 57, localhost, executor driver, partition 17, ANY, 7649 bytes)
2021-12-08 14:46:48,278 [Executor task launch worker for task 56] INFO [org.apache.spark.executor.Executor] - Running task 16.0 in stage 2.0 (TID 56)
2021-12-08 14:46:48,278 [Executor task launch worker for task 57] INFO [org.apache.spark.executor.Executor] - Running task 17.0 in stage 2.0 (TID 57)
2021-12-08 14:46:48,278 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 5.0 in stage 2.0 (TID 45) in 558 ms on localhost (executor driver) (5/20)
2021-12-08 14:46:48,278 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 6.0 in stage 2.0 (TID 46) in 557 ms on localhost (executor driver) (6/20)
2021-12-08 14:46:48,279 [Executor task launch worker for task 56] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 20 non-empty blocks out of 20 blocks
2021-12-08 14:46:48,279 [Executor task launch worker for task 56] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-08 14:46:48,280 [Executor task launch worker for task 57] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 20 non-empty blocks out of 20 blocks
2021-12-08 14:46:48,280 [Executor task launch worker for task 57] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-08 14:46:48,280 [Executor task launch worker for task 43] INFO [org.apache.spark.executor.Executor] - Finished task 3.0 in stage 2.0 (TID 43). 1098 bytes result sent to driver
2021-12-08 14:46:48,281 [Executor task launch worker for task 42] INFO [org.apache.spark.executor.Executor] - Finished task 2.0 in stage 2.0 (TID 42). 1098 bytes result sent to driver
2021-12-08 14:46:48,280 [Executor task launch worker for task 49] INFO [org.apache.spark.executor.Executor] - Finished task 9.0 in stage 2.0 (TID 49). 1098 bytes result sent to driver
2021-12-08 14:46:48,281 [dispatcher-event-loop-5] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 18.0 in stage 2.0 (TID 58, localhost, executor driver, partition 18, ANY, 7649 bytes)
2021-12-08 14:46:48,281 [Executor task launch worker for task 47] INFO [org.apache.spark.executor.Executor] - Finished task 7.0 in stage 2.0 (TID 47). 1098 bytes result sent to driver
2021-12-08 14:46:48,281 [Executor task launch worker for task 58] INFO [org.apache.spark.executor.Executor] - Running task 18.0 in stage 2.0 (TID 58)
2021-12-08 14:46:48,281 [dispatcher-event-loop-5] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 19.0 in stage 2.0 (TID 59, localhost, executor driver, partition 19, ANY, 7649 bytes)
2021-12-08 14:46:48,281 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 3.0 in stage 2.0 (TID 43) in 561 ms on localhost (executor driver) (7/20)
2021-12-08 14:46:48,281 [Executor task launch worker for task 59] INFO [org.apache.spark.executor.Executor] - Running task 19.0 in stage 2.0 (TID 59)
2021-12-08 14:46:48,282 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 2.0 in stage 2.0 (TID 42) in 561 ms on localhost (executor driver) (8/20)
2021-12-08 14:46:48,282 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 9.0 in stage 2.0 (TID 49) in 561 ms on localhost (executor driver) (9/20)
2021-12-08 14:46:48,282 [Executor task launch worker for task 58] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 20 non-empty blocks out of 20 blocks
2021-12-08 14:46:48,282 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 7.0 in stage 2.0 (TID 47) in 561 ms on localhost (executor driver) (10/20)
2021-12-08 14:46:48,282 [Executor task launch worker for task 58] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-08 14:46:48,283 [Executor task launch worker for task 59] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 20 non-empty blocks out of 20 blocks
2021-12-08 14:46:48,283 [Executor task launch worker for task 59] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 1 ms
2021-12-08 14:46:48,286 [Executor task launch worker for task 41] INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 2.0 (TID 41). 1098 bytes result sent to driver
2021-12-08 14:46:48,286 [Executor task launch worker for task 50] INFO [org.apache.spark.executor.Executor] - Finished task 10.0 in stage 2.0 (TID 50). 1098 bytes result sent to driver
2021-12-08 14:46:48,287 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 10.0 in stage 2.0 (TID 50) in 566 ms on localhost (executor driver) (11/20)
2021-12-08 14:46:48,288 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 2.0 (TID 41) in 567 ms on localhost (executor driver) (12/20)
2021-12-08 14:46:48,375 [Executor task launch worker for task 52] INFO [org.apache.spark.executor.Executor] - Finished task 12.0 in stage 2.0 (TID 52). 1098 bytes result sent to driver
2021-12-08 14:46:48,375 [Executor task launch worker for task 56] INFO [org.apache.spark.executor.Executor] - Finished task 16.0 in stage 2.0 (TID 56). 1098 bytes result sent to driver
2021-12-08 14:46:48,375 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 12.0 in stage 2.0 (TID 52) in 112 ms on localhost (executor driver) (13/20)
2021-12-08 14:46:48,375 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 16.0 in stage 2.0 (TID 56) in 98 ms on localhost (executor driver) (14/20)
2021-12-08 14:46:48,376 [Executor task launch worker for task 53] INFO [org.apache.spark.executor.Executor] - Finished task 13.0 in stage 2.0 (TID 53). 1055 bytes result sent to driver
2021-12-08 14:46:48,376 [Executor task launch worker for task 55] INFO [org.apache.spark.executor.Executor] - Finished task 15.0 in stage 2.0 (TID 55). 1055 bytes result sent to driver
2021-12-08 14:46:48,377 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 13.0 in stage 2.0 (TID 53) in 106 ms on localhost (executor driver) (15/20)
2021-12-08 14:46:48,377 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 15.0 in stage 2.0 (TID 55) in 105 ms on localhost (executor driver) (16/20)
2021-12-08 14:46:48,378 [Executor task launch worker for task 57] INFO [org.apache.spark.executor.Executor] - Finished task 17.0 in stage 2.0 (TID 57). 1055 bytes result sent to driver
2021-12-08 14:46:48,378 [Executor task launch worker for task 54] INFO [org.apache.spark.executor.Executor] - Finished task 14.0 in stage 2.0 (TID 54). 1098 bytes result sent to driver
2021-12-08 14:46:48,378 [Executor task launch worker for task 59] INFO [org.apache.spark.executor.Executor] - Finished task 19.0 in stage 2.0 (TID 59). 1098 bytes result sent to driver
2021-12-08 14:46:48,378 [Executor task launch worker for task 58] INFO [org.apache.spark.executor.Executor] - Finished task 18.0 in stage 2.0 (TID 58). 1055 bytes result sent to driver
2021-12-08 14:46:48,378 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 17.0 in stage 2.0 (TID 57) in 100 ms on localhost (executor driver) (17/20)
2021-12-08 14:46:48,378 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 14.0 in stage 2.0 (TID 54) in 107 ms on localhost (executor driver) (18/20)
2021-12-08 14:46:48,378 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 19.0 in stage 2.0 (TID 59) in 97 ms on localhost (executor driver) (19/20)
2021-12-08 14:46:48,378 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 18.0 in stage 2.0 (TID 58) in 97 ms on localhost (executor driver) (20/20)
2021-12-08 14:46:48,378 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 2.0, whose tasks have all completed, from pool 
2021-12-08 14:46:48,379 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 2 (count at PaidPromotionAdjustParameter.scala:61) finished in 0.665 s
2021-12-08 14:46:48,379 [main] INFO [org.apache.spark.scheduler.DAGScheduler] - Job 1 finished: count at PaidPromotionAdjustParameter.scala:61, took 276.959908 s
2021-12-08 14:46:48,379 [main] INFO [PaidPromotionAdjustParameter$] - 用户总数627740
2021-12-08 14:46:48,399 [main] INFO [org.apache.spark.SparkContext] - Starting job: sortByKey at PaidPromotionAdjustParameter.scala:67
2021-12-08 14:46:48,399 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 2 (sortByKey at PaidPromotionAdjustParameter.scala:67) with 20 output partitions
2021-12-08 14:46:48,399 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 4 (sortByKey at PaidPromotionAdjustParameter.scala:67)
2021-12-08 14:46:48,399 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 3)
2021-12-08 14:46:48,399 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2021-12-08 14:46:48,400 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 4 (MapPartitionsRDD[7] at sortByKey at PaidPromotionAdjustParameter.scala:67), which has no missing parents
2021-12-08 14:46:48,403 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_4 stored as values in memory (estimated size 4.1 KB, free 1990.5 MB)
2021-12-08 14:46:48,404 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_4_piece0 stored as bytes in memory (estimated size 2.4 KB, free 1990.5 MB)
2021-12-08 14:46:48,405 [dispatcher-event-loop-5] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_4_piece0 in memory on qb:62214 (size: 2.4 KB, free: 1990.8 MB)
2021-12-08 14:46:48,405 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 4 from broadcast at DAGScheduler.scala:1039
2021-12-08 14:46:48,405 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 20 missing tasks from ResultStage 4 (MapPartitionsRDD[7] at sortByKey at PaidPromotionAdjustParameter.scala:67) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14))
2021-12-08 14:46:48,405 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 4.0 with 20 tasks
2021-12-08 14:46:48,406 [dispatcher-event-loop-8] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 4.0 (TID 60, localhost, executor driver, partition 0, ANY, 7649 bytes)
2021-12-08 14:46:48,406 [dispatcher-event-loop-8] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 4.0 (TID 61, localhost, executor driver, partition 1, ANY, 7649 bytes)
2021-12-08 14:46:48,406 [dispatcher-event-loop-8] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 2.0 in stage 4.0 (TID 62, localhost, executor driver, partition 2, ANY, 7649 bytes)
2021-12-08 14:46:48,406 [dispatcher-event-loop-8] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 3.0 in stage 4.0 (TID 63, localhost, executor driver, partition 3, ANY, 7649 bytes)
2021-12-08 14:46:48,406 [dispatcher-event-loop-8] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 4.0 in stage 4.0 (TID 64, localhost, executor driver, partition 4, ANY, 7649 bytes)
2021-12-08 14:46:48,406 [dispatcher-event-loop-8] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 5.0 in stage 4.0 (TID 65, localhost, executor driver, partition 5, ANY, 7649 bytes)
2021-12-08 14:46:48,406 [dispatcher-event-loop-8] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 6.0 in stage 4.0 (TID 66, localhost, executor driver, partition 6, ANY, 7649 bytes)
2021-12-08 14:46:48,406 [dispatcher-event-loop-8] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 7.0 in stage 4.0 (TID 67, localhost, executor driver, partition 7, ANY, 7649 bytes)
2021-12-08 14:46:48,407 [dispatcher-event-loop-8] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 8.0 in stage 4.0 (TID 68, localhost, executor driver, partition 8, ANY, 7649 bytes)
2021-12-08 14:46:48,407 [dispatcher-event-loop-8] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 9.0 in stage 4.0 (TID 69, localhost, executor driver, partition 9, ANY, 7649 bytes)
2021-12-08 14:46:48,407 [dispatcher-event-loop-8] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 10.0 in stage 4.0 (TID 70, localhost, executor driver, partition 10, ANY, 7649 bytes)
2021-12-08 14:46:48,407 [dispatcher-event-loop-8] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 11.0 in stage 4.0 (TID 71, localhost, executor driver, partition 11, ANY, 7649 bytes)
2021-12-08 14:46:48,407 [Executor task launch worker for task 60] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 4.0 (TID 60)
2021-12-08 14:46:48,407 [Executor task launch worker for task 61] INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 4.0 (TID 61)
2021-12-08 14:46:48,407 [Executor task launch worker for task 69] INFO [org.apache.spark.executor.Executor] - Running task 9.0 in stage 4.0 (TID 69)
2021-12-08 14:46:48,407 [Executor task launch worker for task 66] INFO [org.apache.spark.executor.Executor] - Running task 6.0 in stage 4.0 (TID 66)
2021-12-08 14:46:48,407 [Executor task launch worker for task 64] INFO [org.apache.spark.executor.Executor] - Running task 4.0 in stage 4.0 (TID 64)
2021-12-08 14:46:48,407 [Executor task launch worker for task 65] INFO [org.apache.spark.executor.Executor] - Running task 5.0 in stage 4.0 (TID 65)
2021-12-08 14:46:48,407 [Executor task launch worker for task 63] INFO [org.apache.spark.executor.Executor] - Running task 3.0 in stage 4.0 (TID 63)
2021-12-08 14:46:48,407 [Executor task launch worker for task 62] INFO [org.apache.spark.executor.Executor] - Running task 2.0 in stage 4.0 (TID 62)
2021-12-08 14:46:48,407 [Executor task launch worker for task 71] INFO [org.apache.spark.executor.Executor] - Running task 11.0 in stage 4.0 (TID 71)
2021-12-08 14:46:48,407 [Executor task launch worker for task 67] INFO [org.apache.spark.executor.Executor] - Running task 7.0 in stage 4.0 (TID 67)
2021-12-08 14:46:48,407 [Executor task launch worker for task 68] INFO [org.apache.spark.executor.Executor] - Running task 8.0 in stage 4.0 (TID 68)
2021-12-08 14:46:48,407 [Executor task launch worker for task 70] INFO [org.apache.spark.executor.Executor] - Running task 10.0 in stage 4.0 (TID 70)
2021-12-08 14:46:48,409 [Executor task launch worker for task 65] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 20 non-empty blocks out of 20 blocks
2021-12-08 14:46:48,409 [Executor task launch worker for task 65] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-08 14:46:48,409 [Executor task launch worker for task 70] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 20 non-empty blocks out of 20 blocks
2021-12-08 14:46:48,409 [Executor task launch worker for task 60] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 20 non-empty blocks out of 20 blocks
2021-12-08 14:46:48,409 [Executor task launch worker for task 70] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-08 14:46:48,409 [Executor task launch worker for task 63] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 20 non-empty blocks out of 20 blocks
2021-12-08 14:46:48,409 [Executor task launch worker for task 60] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-08 14:46:48,409 [Executor task launch worker for task 63] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-08 14:46:48,409 [Executor task launch worker for task 62] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 20 non-empty blocks out of 20 blocks
2021-12-08 14:46:48,409 [Executor task launch worker for task 62] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-08 14:46:48,409 [Executor task launch worker for task 64] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 20 non-empty blocks out of 20 blocks
2021-12-08 14:46:48,409 [Executor task launch worker for task 69] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 20 non-empty blocks out of 20 blocks
2021-12-08 14:46:48,409 [Executor task launch worker for task 64] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-08 14:46:48,409 [Executor task launch worker for task 69] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-08 14:46:48,409 [Executor task launch worker for task 66] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 20 non-empty blocks out of 20 blocks
2021-12-08 14:46:48,409 [Executor task launch worker for task 66] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-08 14:46:48,409 [Executor task launch worker for task 61] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 20 non-empty blocks out of 20 blocks
2021-12-08 14:46:48,409 [Executor task launch worker for task 68] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 20 non-empty blocks out of 20 blocks
2021-12-08 14:46:48,409 [Executor task launch worker for task 61] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-08 14:46:48,409 [Executor task launch worker for task 68] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-08 14:46:48,409 [Executor task launch worker for task 67] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 20 non-empty blocks out of 20 blocks
2021-12-08 14:46:48,409 [Executor task launch worker for task 67] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-08 14:46:48,409 [Executor task launch worker for task 71] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 20 non-empty blocks out of 20 blocks
2021-12-08 14:46:48,409 [Executor task launch worker for task 71] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-08 14:46:48,521 [Executor task launch worker for task 66] INFO [org.apache.spark.executor.Executor] - Finished task 6.0 in stage 4.0 (TID 66). 1201 bytes result sent to driver
2021-12-08 14:46:48,521 [Executor task launch worker for task 64] INFO [org.apache.spark.executor.Executor] - Finished task 4.0 in stage 4.0 (TID 64). 1201 bytes result sent to driver
2021-12-08 14:46:48,521 [Executor task launch worker for task 67] INFO [org.apache.spark.executor.Executor] - Finished task 7.0 in stage 4.0 (TID 67). 1196 bytes result sent to driver
2021-12-08 14:46:48,521 [Executor task launch worker for task 71] INFO [org.apache.spark.executor.Executor] - Finished task 11.0 in stage 4.0 (TID 71). 1203 bytes result sent to driver
2021-12-08 14:46:48,522 [dispatcher-event-loop-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 12.0 in stage 4.0 (TID 72, localhost, executor driver, partition 12, ANY, 7649 bytes)
2021-12-08 14:46:48,522 [dispatcher-event-loop-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 13.0 in stage 4.0 (TID 73, localhost, executor driver, partition 13, ANY, 7649 bytes)
2021-12-08 14:46:48,522 [Executor task launch worker for task 73] INFO [org.apache.spark.executor.Executor] - Running task 13.0 in stage 4.0 (TID 73)
2021-12-08 14:46:48,523 [dispatcher-event-loop-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 14.0 in stage 4.0 (TID 74, localhost, executor driver, partition 14, ANY, 7649 bytes)
2021-12-08 14:46:48,523 [dispatcher-event-loop-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 15.0 in stage 4.0 (TID 75, localhost, executor driver, partition 15, ANY, 7649 bytes)
2021-12-08 14:46:48,523 [Executor task launch worker for task 74] INFO [org.apache.spark.executor.Executor] - Running task 14.0 in stage 4.0 (TID 74)
2021-12-08 14:46:48,524 [Executor task launch worker for task 72] INFO [org.apache.spark.executor.Executor] - Running task 12.0 in stage 4.0 (TID 72)
2021-12-08 14:46:48,524 [Executor task launch worker for task 74] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 20 non-empty blocks out of 20 blocks
2021-12-08 14:46:48,524 [Executor task launch worker for task 73] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 20 non-empty blocks out of 20 blocks
2021-12-08 14:46:48,524 [Executor task launch worker for task 74] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-08 14:46:48,524 [Executor task launch worker for task 73] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-08 14:46:48,524 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 4.0 in stage 4.0 (TID 64) in 118 ms on localhost (executor driver) (1/20)
2021-12-08 14:46:48,524 [Executor task launch worker for task 72] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 20 non-empty blocks out of 20 blocks
2021-12-08 14:46:48,524 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 6.0 in stage 4.0 (TID 66) in 118 ms on localhost (executor driver) (2/20)
2021-12-08 14:46:48,525 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 11.0 in stage 4.0 (TID 71) in 118 ms on localhost (executor driver) (3/20)
2021-12-08 14:46:48,524 [Executor task launch worker for task 72] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-08 14:46:48,526 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 7.0 in stage 4.0 (TID 67) in 120 ms on localhost (executor driver) (4/20)
2021-12-08 14:46:48,525 [Executor task launch worker for task 65] INFO [org.apache.spark.executor.Executor] - Finished task 5.0 in stage 4.0 (TID 65). 1204 bytes result sent to driver
2021-12-08 14:46:48,527 [dispatcher-event-loop-6] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 16.0 in stage 4.0 (TID 76, localhost, executor driver, partition 16, ANY, 7649 bytes)
2021-12-08 14:46:48,528 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 5.0 in stage 4.0 (TID 65) in 122 ms on localhost (executor driver) (5/20)
2021-12-08 14:46:48,531 [Executor task launch worker for task 75] INFO [org.apache.spark.executor.Executor] - Running task 15.0 in stage 4.0 (TID 75)
2021-12-08 14:46:48,534 [Executor task launch worker for task 76] INFO [org.apache.spark.executor.Executor] - Running task 16.0 in stage 4.0 (TID 76)
2021-12-08 14:46:48,534 [Executor task launch worker for task 75] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 20 non-empty blocks out of 20 blocks
2021-12-08 14:46:48,534 [Executor task launch worker for task 75] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-08 14:46:48,535 [Executor task launch worker for task 76] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 20 non-empty blocks out of 20 blocks
2021-12-08 14:46:48,535 [Executor task launch worker for task 76] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-08 14:46:48,536 [Executor task launch worker for task 68] INFO [org.apache.spark.executor.Executor] - Finished task 8.0 in stage 4.0 (TID 68). 1244 bytes result sent to driver
2021-12-08 14:46:48,537 [Executor task launch worker for task 70] INFO [org.apache.spark.executor.Executor] - Finished task 10.0 in stage 4.0 (TID 70). 1193 bytes result sent to driver
2021-12-08 14:46:48,537 [Executor task launch worker for task 63] INFO [org.apache.spark.executor.Executor] - Finished task 3.0 in stage 4.0 (TID 63). 1207 bytes result sent to driver
2021-12-08 14:46:48,538 [dispatcher-event-loop-5] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 17.0 in stage 4.0 (TID 77, localhost, executor driver, partition 17, ANY, 7649 bytes)
2021-12-08 14:46:48,538 [Executor task launch worker for task 77] INFO [org.apache.spark.executor.Executor] - Running task 17.0 in stage 4.0 (TID 77)
2021-12-08 14:46:48,538 [dispatcher-event-loop-5] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 18.0 in stage 4.0 (TID 78, localhost, executor driver, partition 18, ANY, 7649 bytes)
2021-12-08 14:46:48,538 [dispatcher-event-loop-5] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 19.0 in stage 4.0 (TID 79, localhost, executor driver, partition 19, ANY, 7649 bytes)
2021-12-08 14:46:48,538 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 8.0 in stage 4.0 (TID 68) in 132 ms on localhost (executor driver) (6/20)
2021-12-08 14:46:48,539 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 10.0 in stage 4.0 (TID 70) in 132 ms on localhost (executor driver) (7/20)
2021-12-08 14:46:48,539 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 3.0 in stage 4.0 (TID 63) in 133 ms on localhost (executor driver) (8/20)
2021-12-08 14:46:48,539 [Executor task launch worker for task 78] INFO [org.apache.spark.executor.Executor] - Running task 18.0 in stage 4.0 (TID 78)
2021-12-08 14:46:48,540 [Executor task launch worker for task 77] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 20 non-empty blocks out of 20 blocks
2021-12-08 14:46:48,540 [Executor task launch worker for task 77] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 1 ms
2021-12-08 14:46:48,540 [Executor task launch worker for task 79] INFO [org.apache.spark.executor.Executor] - Running task 19.0 in stage 4.0 (TID 79)
2021-12-08 14:46:48,541 [Executor task launch worker for task 79] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 20 non-empty blocks out of 20 blocks
2021-12-08 14:46:48,541 [Executor task launch worker for task 79] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-08 14:46:48,541 [Executor task launch worker for task 78] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 20 non-empty blocks out of 20 blocks
2021-12-08 14:46:48,541 [Executor task launch worker for task 78] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-08 14:46:48,542 [Executor task launch worker for task 60] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 4.0 (TID 60). 1201 bytes result sent to driver
2021-12-08 14:46:48,543 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 4.0 (TID 60) in 137 ms on localhost (executor driver) (9/20)
2021-12-08 14:46:48,544 [Executor task launch worker for task 62] INFO [org.apache.spark.executor.Executor] - Finished task 2.0 in stage 4.0 (TID 62). 1196 bytes result sent to driver
2021-12-08 14:46:48,545 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 2.0 in stage 4.0 (TID 62) in 139 ms on localhost (executor driver) (10/20)
2021-12-08 14:46:48,545 [Executor task launch worker for task 69] INFO [org.apache.spark.executor.Executor] - Finished task 9.0 in stage 4.0 (TID 69). 1203 bytes result sent to driver
2021-12-08 14:46:48,546 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 9.0 in stage 4.0 (TID 69) in 139 ms on localhost (executor driver) (11/20)
2021-12-08 14:46:48,548 [Executor task launch worker for task 61] INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 4.0 (TID 61). 1205 bytes result sent to driver
2021-12-08 14:46:48,549 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 4.0 (TID 61) in 143 ms on localhost (executor driver) (12/20)
2021-12-08 14:46:48,599 [Executor task launch worker for task 74] INFO [org.apache.spark.executor.Executor] - Finished task 14.0 in stage 4.0 (TID 74). 1205 bytes result sent to driver
2021-12-08 14:46:48,599 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 14.0 in stage 4.0 (TID 74) in 77 ms on localhost (executor driver) (13/20)
2021-12-08 14:46:48,603 [Executor task launch worker for task 73] INFO [org.apache.spark.executor.Executor] - Finished task 13.0 in stage 4.0 (TID 73). 1200 bytes result sent to driver
2021-12-08 14:46:48,604 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 13.0 in stage 4.0 (TID 73) in 82 ms on localhost (executor driver) (14/20)
2021-12-08 14:46:48,604 [Executor task launch worker for task 76] INFO [org.apache.spark.executor.Executor] - Finished task 16.0 in stage 4.0 (TID 76). 1198 bytes result sent to driver
2021-12-08 14:46:48,604 [Executor task launch worker for task 72] INFO [org.apache.spark.executor.Executor] - Finished task 12.0 in stage 4.0 (TID 72). 1200 bytes result sent to driver
2021-12-08 14:46:48,605 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 16.0 in stage 4.0 (TID 76) in 77 ms on localhost (executor driver) (15/20)
2021-12-08 14:46:48,605 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 12.0 in stage 4.0 (TID 72) in 83 ms on localhost (executor driver) (16/20)
2021-12-08 14:46:48,606 [Executor task launch worker for task 77] INFO [org.apache.spark.executor.Executor] - Finished task 17.0 in stage 4.0 (TID 77). 1205 bytes result sent to driver
2021-12-08 14:46:48,606 [Executor task launch worker for task 75] INFO [org.apache.spark.executor.Executor] - Finished task 15.0 in stage 4.0 (TID 75). 1202 bytes result sent to driver
2021-12-08 14:46:48,606 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 17.0 in stage 4.0 (TID 77) in 69 ms on localhost (executor driver) (17/20)
2021-12-08 14:46:48,606 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 15.0 in stage 4.0 (TID 75) in 83 ms on localhost (executor driver) (18/20)
2021-12-08 14:46:48,607 [Executor task launch worker for task 78] INFO [org.apache.spark.executor.Executor] - Finished task 18.0 in stage 4.0 (TID 78). 1203 bytes result sent to driver
2021-12-08 14:46:48,607 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 18.0 in stage 4.0 (TID 78) in 69 ms on localhost (executor driver) (19/20)
2021-12-08 14:46:48,608 [Executor task launch worker for task 79] INFO [org.apache.spark.executor.Executor] - Finished task 19.0 in stage 4.0 (TID 79). 1200 bytes result sent to driver
2021-12-08 14:46:48,608 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 19.0 in stage 4.0 (TID 79) in 70 ms on localhost (executor driver) (20/20)
2021-12-08 14:46:48,608 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 4.0, whose tasks have all completed, from pool 
2021-12-08 14:46:48,608 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 4 (sortByKey at PaidPromotionAdjustParameter.scala:67) finished in 0.206 s
2021-12-08 14:46:48,608 [main] INFO [org.apache.spark.scheduler.DAGScheduler] - Job 2 finished: sortByKey at PaidPromotionAdjustParameter.scala:67, took 0.209389 s
2021-12-08 14:46:48,625 [main] INFO [org.apache.spark.SparkContext] - Starting job: zipWithIndex at PaidPromotionAdjustParameter.scala:68
2021-12-08 14:46:48,625 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 5 (map at PaidPromotionAdjustParameter.scala:66)
2021-12-08 14:46:48,625 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 3 (zipWithIndex at PaidPromotionAdjustParameter.scala:68) with 19 output partitions
2021-12-08 14:46:48,626 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 7 (zipWithIndex at PaidPromotionAdjustParameter.scala:68)
2021-12-08 14:46:48,626 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 6)
2021-12-08 14:46:48,626 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List(ShuffleMapStage 6)
2021-12-08 14:46:48,626 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ShuffleMapStage 6 (MapPartitionsRDD[5] at map at PaidPromotionAdjustParameter.scala:66), which has no missing parents
2021-12-08 14:46:48,634 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_5 stored as values in memory (estimated size 4.1 KB, free 1990.5 MB)
2021-12-08 14:46:48,638 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_5_piece0 stored as bytes in memory (estimated size 2.4 KB, free 1990.5 MB)
2021-12-08 14:46:48,638 [dispatcher-event-loop-2] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_5_piece0 in memory on qb:62214 (size: 2.4 KB, free: 1990.8 MB)
2021-12-08 14:46:48,639 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 5 from broadcast at DAGScheduler.scala:1039
2021-12-08 14:46:48,639 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 20 missing tasks from ShuffleMapStage 6 (MapPartitionsRDD[5] at map at PaidPromotionAdjustParameter.scala:66) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14))
2021-12-08 14:46:48,639 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 6.0 with 20 tasks
2021-12-08 14:46:48,639 [dispatcher-event-loop-4] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 6.0 (TID 80, localhost, executor driver, partition 0, ANY, 7638 bytes)
2021-12-08 14:46:48,640 [dispatcher-event-loop-4] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 6.0 (TID 81, localhost, executor driver, partition 1, ANY, 7638 bytes)
2021-12-08 14:46:48,640 [dispatcher-event-loop-4] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 2.0 in stage 6.0 (TID 82, localhost, executor driver, partition 2, ANY, 7638 bytes)
2021-12-08 14:46:48,640 [dispatcher-event-loop-4] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 3.0 in stage 6.0 (TID 83, localhost, executor driver, partition 3, ANY, 7638 bytes)
2021-12-08 14:46:48,640 [dispatcher-event-loop-4] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 4.0 in stage 6.0 (TID 84, localhost, executor driver, partition 4, ANY, 7638 bytes)
2021-12-08 14:46:48,640 [dispatcher-event-loop-4] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 5.0 in stage 6.0 (TID 85, localhost, executor driver, partition 5, ANY, 7638 bytes)
2021-12-08 14:46:48,640 [dispatcher-event-loop-4] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 6.0 in stage 6.0 (TID 86, localhost, executor driver, partition 6, ANY, 7638 bytes)
2021-12-08 14:46:48,640 [dispatcher-event-loop-4] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 7.0 in stage 6.0 (TID 87, localhost, executor driver, partition 7, ANY, 7638 bytes)
2021-12-08 14:46:48,640 [dispatcher-event-loop-4] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 8.0 in stage 6.0 (TID 88, localhost, executor driver, partition 8, ANY, 7638 bytes)
2021-12-08 14:46:48,640 [dispatcher-event-loop-4] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 9.0 in stage 6.0 (TID 89, localhost, executor driver, partition 9, ANY, 7638 bytes)
2021-12-08 14:46:48,640 [dispatcher-event-loop-4] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 10.0 in stage 6.0 (TID 90, localhost, executor driver, partition 10, ANY, 7638 bytes)
2021-12-08 14:46:48,641 [dispatcher-event-loop-4] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 11.0 in stage 6.0 (TID 91, localhost, executor driver, partition 11, ANY, 7638 bytes)
2021-12-08 14:46:48,641 [Executor task launch worker for task 80] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 6.0 (TID 80)
2021-12-08 14:46:48,641 [Executor task launch worker for task 83] INFO [org.apache.spark.executor.Executor] - Running task 3.0 in stage 6.0 (TID 83)
2021-12-08 14:46:48,641 [Executor task launch worker for task 86] INFO [org.apache.spark.executor.Executor] - Running task 6.0 in stage 6.0 (TID 86)
2021-12-08 14:46:48,641 [Executor task launch worker for task 89] INFO [org.apache.spark.executor.Executor] - Running task 9.0 in stage 6.0 (TID 89)
2021-12-08 14:46:48,641 [Executor task launch worker for task 85] INFO [org.apache.spark.executor.Executor] - Running task 5.0 in stage 6.0 (TID 85)
2021-12-08 14:46:48,641 [Executor task launch worker for task 81] INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 6.0 (TID 81)
2021-12-08 14:46:48,641 [Executor task launch worker for task 82] INFO [org.apache.spark.executor.Executor] - Running task 2.0 in stage 6.0 (TID 82)
2021-12-08 14:46:48,641 [Executor task launch worker for task 84] INFO [org.apache.spark.executor.Executor] - Running task 4.0 in stage 6.0 (TID 84)
2021-12-08 14:46:48,641 [Executor task launch worker for task 91] INFO [org.apache.spark.executor.Executor] - Running task 11.0 in stage 6.0 (TID 91)
2021-12-08 14:46:48,641 [Executor task launch worker for task 87] INFO [org.apache.spark.executor.Executor] - Running task 7.0 in stage 6.0 (TID 87)
2021-12-08 14:46:48,641 [Executor task launch worker for task 88] INFO [org.apache.spark.executor.Executor] - Running task 8.0 in stage 6.0 (TID 88)
2021-12-08 14:46:48,641 [Executor task launch worker for task 90] INFO [org.apache.spark.executor.Executor] - Running task 10.0 in stage 6.0 (TID 90)
2021-12-08 14:46:48,650 [Executor task launch worker for task 88] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 20 non-empty blocks out of 20 blocks
2021-12-08 14:46:48,650 [Executor task launch worker for task 81] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 20 non-empty blocks out of 20 blocks
2021-12-08 14:46:48,650 [Executor task launch worker for task 91] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 20 non-empty blocks out of 20 blocks
2021-12-08 14:46:48,650 [Executor task launch worker for task 88] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-08 14:46:48,650 [Executor task launch worker for task 91] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-08 14:46:48,650 [Executor task launch worker for task 89] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 20 non-empty blocks out of 20 blocks
2021-12-08 14:46:48,650 [Executor task launch worker for task 81] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-08 14:46:48,650 [Executor task launch worker for task 89] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-08 14:46:48,650 [Executor task launch worker for task 85] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 20 non-empty blocks out of 20 blocks
2021-12-08 14:46:48,650 [Executor task launch worker for task 85] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-08 14:46:48,650 [Executor task launch worker for task 87] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 20 non-empty blocks out of 20 blocks
2021-12-08 14:46:48,650 [Executor task launch worker for task 83] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 20 non-empty blocks out of 20 blocks
2021-12-08 14:46:48,650 [Executor task launch worker for task 80] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 20 non-empty blocks out of 20 blocks
2021-12-08 14:46:48,650 [Executor task launch worker for task 83] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-08 14:46:48,650 [Executor task launch worker for task 86] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 20 non-empty blocks out of 20 blocks
2021-12-08 14:46:48,650 [Executor task launch worker for task 87] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-08 14:46:48,650 [Executor task launch worker for task 86] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-08 14:46:48,650 [Executor task launch worker for task 82] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 20 non-empty blocks out of 20 blocks
2021-12-08 14:46:48,650 [Executor task launch worker for task 90] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 20 non-empty blocks out of 20 blocks
2021-12-08 14:46:48,650 [Executor task launch worker for task 84] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 20 non-empty blocks out of 20 blocks
2021-12-08 14:46:48,650 [Executor task launch worker for task 90] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-08 14:46:48,650 [Executor task launch worker for task 84] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-08 14:46:48,650 [Executor task launch worker for task 80] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-08 14:46:48,650 [Executor task launch worker for task 82] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-08 14:46:49,154 [Executor task launch worker for task 87] INFO [org.apache.spark.executor.Executor] - Finished task 7.0 in stage 6.0 (TID 87). 1308 bytes result sent to driver
2021-12-08 14:46:49,155 [dispatcher-event-loop-6] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 12.0 in stage 6.0 (TID 92, localhost, executor driver, partition 12, ANY, 7638 bytes)
2021-12-08 14:46:49,155 [Executor task launch worker for task 92] INFO [org.apache.spark.executor.Executor] - Running task 12.0 in stage 6.0 (TID 92)
2021-12-08 14:46:49,157 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 7.0 in stage 6.0 (TID 87) in 517 ms on localhost (executor driver) (1/20)
2021-12-08 14:46:49,159 [Executor task launch worker for task 92] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 20 non-empty blocks out of 20 blocks
2021-12-08 14:46:49,159 [Executor task launch worker for task 92] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-08 14:46:49,163 [Executor task launch worker for task 83] INFO [org.apache.spark.executor.Executor] - Finished task 3.0 in stage 6.0 (TID 83). 1265 bytes result sent to driver
2021-12-08 14:46:49,164 [dispatcher-event-loop-9] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 13.0 in stage 6.0 (TID 93, localhost, executor driver, partition 13, ANY, 7638 bytes)
2021-12-08 14:46:49,164 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 3.0 in stage 6.0 (TID 83) in 524 ms on localhost (executor driver) (2/20)
2021-12-08 14:46:49,164 [Executor task launch worker for task 93] INFO [org.apache.spark.executor.Executor] - Running task 13.0 in stage 6.0 (TID 93)
2021-12-08 14:46:49,168 [Executor task launch worker for task 86] INFO [org.apache.spark.executor.Executor] - Finished task 6.0 in stage 6.0 (TID 86). 1265 bytes result sent to driver
2021-12-08 14:46:49,168 [Executor task launch worker for task 93] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 20 non-empty blocks out of 20 blocks
2021-12-08 14:46:49,168 [Executor task launch worker for task 93] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-08 14:46:49,170 [dispatcher-event-loop-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 14.0 in stage 6.0 (TID 94, localhost, executor driver, partition 14, ANY, 7638 bytes)
2021-12-08 14:46:49,170 [Executor task launch worker for task 94] INFO [org.apache.spark.executor.Executor] - Running task 14.0 in stage 6.0 (TID 94)
2021-12-08 14:46:49,170 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 6.0 in stage 6.0 (TID 86) in 530 ms on localhost (executor driver) (3/20)
2021-12-08 14:46:49,173 [Executor task launch worker for task 94] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 20 non-empty blocks out of 20 blocks
2021-12-08 14:46:49,173 [Executor task launch worker for task 94] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-08 14:46:49,190 [Executor task launch worker for task 90] INFO [org.apache.spark.executor.Executor] - Finished task 10.0 in stage 6.0 (TID 90). 1265 bytes result sent to driver
2021-12-08 14:46:49,191 [dispatcher-event-loop-8] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 15.0 in stage 6.0 (TID 95, localhost, executor driver, partition 15, ANY, 7638 bytes)
2021-12-08 14:46:49,192 [Executor task launch worker for task 95] INFO [org.apache.spark.executor.Executor] - Running task 15.0 in stage 6.0 (TID 95)
2021-12-08 14:46:49,192 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 10.0 in stage 6.0 (TID 90) in 552 ms on localhost (executor driver) (4/20)
2021-12-08 14:46:49,196 [Executor task launch worker for task 95] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 20 non-empty blocks out of 20 blocks
2021-12-08 14:46:49,196 [Executor task launch worker for task 95] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-08 14:46:49,218 [Executor task launch worker for task 85] INFO [org.apache.spark.executor.Executor] - Finished task 5.0 in stage 6.0 (TID 85). 1308 bytes result sent to driver
2021-12-08 14:46:49,219 [dispatcher-event-loop-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 16.0 in stage 6.0 (TID 96, localhost, executor driver, partition 16, ANY, 7638 bytes)
2021-12-08 14:46:49,219 [Executor task launch worker for task 96] INFO [org.apache.spark.executor.Executor] - Running task 16.0 in stage 6.0 (TID 96)
2021-12-08 14:46:49,220 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 5.0 in stage 6.0 (TID 85) in 580 ms on localhost (executor driver) (5/20)
2021-12-08 14:46:49,223 [Executor task launch worker for task 96] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 20 non-empty blocks out of 20 blocks
2021-12-08 14:46:49,223 [Executor task launch worker for task 96] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-08 14:46:49,307 [Executor task launch worker for task 80] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 6.0 (TID 80). 1308 bytes result sent to driver
2021-12-08 14:46:49,307 [dispatcher-event-loop-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 17.0 in stage 6.0 (TID 97, localhost, executor driver, partition 17, ANY, 7638 bytes)
2021-12-08 14:46:49,307 [Executor task launch worker for task 97] INFO [org.apache.spark.executor.Executor] - Running task 17.0 in stage 6.0 (TID 97)
2021-12-08 14:46:49,307 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 6.0 (TID 80) in 668 ms on localhost (executor driver) (6/20)
2021-12-08 14:46:49,310 [Executor task launch worker for task 97] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 20 non-empty blocks out of 20 blocks
2021-12-08 14:46:49,310 [Executor task launch worker for task 97] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-08 14:46:49,333 [Executor task launch worker for task 89] INFO [org.apache.spark.executor.Executor] - Finished task 9.0 in stage 6.0 (TID 89). 1308 bytes result sent to driver
2021-12-08 14:46:49,334 [dispatcher-event-loop-6] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 18.0 in stage 6.0 (TID 98, localhost, executor driver, partition 18, ANY, 7638 bytes)
2021-12-08 14:46:49,334 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 9.0 in stage 6.0 (TID 89) in 694 ms on localhost (executor driver) (7/20)
2021-12-08 14:46:49,334 [Executor task launch worker for task 98] INFO [org.apache.spark.executor.Executor] - Running task 18.0 in stage 6.0 (TID 98)
2021-12-08 14:46:49,338 [Executor task launch worker for task 98] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 20 non-empty blocks out of 20 blocks
2021-12-08 14:46:49,338 [Executor task launch worker for task 98] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-08 14:46:49,355 [Executor task launch worker for task 91] INFO [org.apache.spark.executor.Executor] - Finished task 11.0 in stage 6.0 (TID 91). 1265 bytes result sent to driver
2021-12-08 14:46:49,356 [dispatcher-event-loop-9] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 19.0 in stage 6.0 (TID 99, localhost, executor driver, partition 19, ANY, 7638 bytes)
2021-12-08 14:46:49,356 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 11.0 in stage 6.0 (TID 91) in 716 ms on localhost (executor driver) (8/20)
2021-12-08 14:46:49,357 [Executor task launch worker for task 99] INFO [org.apache.spark.executor.Executor] - Running task 19.0 in stage 6.0 (TID 99)
2021-12-08 14:46:49,360 [Executor task launch worker for task 99] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 20 non-empty blocks out of 20 blocks
2021-12-08 14:46:49,360 [Executor task launch worker for task 99] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-08 14:46:49,445 [Executor task launch worker for task 84] INFO [org.apache.spark.executor.Executor] - Finished task 4.0 in stage 6.0 (TID 84). 1265 bytes result sent to driver
2021-12-08 14:46:49,446 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 4.0 in stage 6.0 (TID 84) in 806 ms on localhost (executor driver) (9/20)
2021-12-08 14:46:49,459 [Executor task launch worker for task 88] INFO [org.apache.spark.executor.Executor] - Finished task 8.0 in stage 6.0 (TID 88). 1265 bytes result sent to driver
2021-12-08 14:46:49,459 [Executor task launch worker for task 81] INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 6.0 (TID 81). 1265 bytes result sent to driver
2021-12-08 14:46:49,460 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 8.0 in stage 6.0 (TID 88) in 820 ms on localhost (executor driver) (10/20)
2021-12-08 14:46:49,460 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 6.0 (TID 81) in 820 ms on localhost (executor driver) (11/20)
2021-12-08 14:46:49,489 [Executor task launch worker for task 82] INFO [org.apache.spark.executor.Executor] - Finished task 2.0 in stage 6.0 (TID 82). 1265 bytes result sent to driver
2021-12-08 14:46:49,489 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 2.0 in stage 6.0 (TID 82) in 849 ms on localhost (executor driver) (12/20)
2021-12-08 14:46:49,524 [Executor task launch worker for task 93] INFO [org.apache.spark.executor.Executor] - Finished task 13.0 in stage 6.0 (TID 93). 1265 bytes result sent to driver
2021-12-08 14:46:49,526 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 13.0 in stage 6.0 (TID 93) in 362 ms on localhost (executor driver) (13/20)
2021-12-08 14:46:49,541 [Executor task launch worker for task 95] INFO [org.apache.spark.executor.Executor] - Finished task 15.0 in stage 6.0 (TID 95). 1308 bytes result sent to driver
2021-12-08 14:46:49,543 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 15.0 in stage 6.0 (TID 95) in 352 ms on localhost (executor driver) (14/20)
2021-12-08 14:46:49,547 [Executor task launch worker for task 94] INFO [org.apache.spark.executor.Executor] - Finished task 14.0 in stage 6.0 (TID 94). 1265 bytes result sent to driver
2021-12-08 14:46:49,548 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 14.0 in stage 6.0 (TID 94) in 379 ms on localhost (executor driver) (15/20)
2021-12-08 14:46:49,565 [Executor task launch worker for task 92] INFO [org.apache.spark.executor.Executor] - Finished task 12.0 in stage 6.0 (TID 92). 1265 bytes result sent to driver
2021-12-08 14:46:49,565 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 12.0 in stage 6.0 (TID 92) in 410 ms on localhost (executor driver) (16/20)
2021-12-08 14:46:49,601 [Executor task launch worker for task 96] INFO [org.apache.spark.executor.Executor] - Finished task 16.0 in stage 6.0 (TID 96). 1265 bytes result sent to driver
2021-12-08 14:46:49,601 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 16.0 in stage 6.0 (TID 96) in 382 ms on localhost (executor driver) (17/20)
2021-12-08 14:46:49,676 [Executor task launch worker for task 97] INFO [org.apache.spark.executor.Executor] - Finished task 17.0 in stage 6.0 (TID 97). 1265 bytes result sent to driver
2021-12-08 14:46:49,677 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 17.0 in stage 6.0 (TID 97) in 370 ms on localhost (executor driver) (18/20)
2021-12-08 14:46:49,677 [Executor task launch worker for task 98] INFO [org.apache.spark.executor.Executor] - Finished task 18.0 in stage 6.0 (TID 98). 1265 bytes result sent to driver
2021-12-08 14:46:49,678 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 18.0 in stage 6.0 (TID 98) in 343 ms on localhost (executor driver) (19/20)
2021-12-08 14:46:49,686 [Executor task launch worker for task 99] INFO [org.apache.spark.executor.Executor] - Finished task 19.0 in stage 6.0 (TID 99). 1265 bytes result sent to driver
2021-12-08 14:46:49,686 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 19.0 in stage 6.0 (TID 99) in 331 ms on localhost (executor driver) (20/20)
2021-12-08 14:46:49,687 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 6.0, whose tasks have all completed, from pool 
2021-12-08 14:46:49,687 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ShuffleMapStage 6 (map at PaidPromotionAdjustParameter.scala:66) finished in 1.059 s
2021-12-08 14:46:49,687 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - looking for newly runnable stages
2021-12-08 14:46:49,687 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - running: Set()
2021-12-08 14:46:49,687 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - waiting: Set(ResultStage 7)
2021-12-08 14:46:49,687 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - failed: Set()
2021-12-08 14:46:49,687 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 7 (ShuffledRDD[8] at sortByKey at PaidPromotionAdjustParameter.scala:67), which has no missing parents
2021-12-08 14:46:49,690 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_6 stored as values in memory (estimated size 3.4 KB, free 1990.4 MB)
2021-12-08 14:46:49,691 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_6_piece0 stored as bytes in memory (estimated size 2.0 KB, free 1990.4 MB)
2021-12-08 14:46:49,691 [dispatcher-event-loop-1] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_6_piece0 in memory on qb:62214 (size: 2.0 KB, free: 1990.8 MB)
2021-12-08 14:46:49,692 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 6 from broadcast at DAGScheduler.scala:1039
2021-12-08 14:46:49,692 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 19 missing tasks from ResultStage 7 (ShuffledRDD[8] at sortByKey at PaidPromotionAdjustParameter.scala:67) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14))
2021-12-08 14:46:49,692 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 7.0 with 19 tasks
2021-12-08 14:46:49,693 [dispatcher-event-loop-8] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 7.0 (TID 100, localhost, executor driver, partition 0, ANY, 7649 bytes)
2021-12-08 14:46:49,693 [dispatcher-event-loop-8] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 7.0 (TID 101, localhost, executor driver, partition 1, ANY, 7649 bytes)
2021-12-08 14:46:49,693 [dispatcher-event-loop-8] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 2.0 in stage 7.0 (TID 102, localhost, executor driver, partition 2, ANY, 7649 bytes)
2021-12-08 14:46:49,693 [dispatcher-event-loop-8] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 3.0 in stage 7.0 (TID 103, localhost, executor driver, partition 3, ANY, 7649 bytes)
2021-12-08 14:46:49,693 [dispatcher-event-loop-8] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 4.0 in stage 7.0 (TID 104, localhost, executor driver, partition 4, ANY, 7649 bytes)
2021-12-08 14:46:49,693 [dispatcher-event-loop-8] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 5.0 in stage 7.0 (TID 105, localhost, executor driver, partition 5, ANY, 7649 bytes)
2021-12-08 14:46:49,693 [dispatcher-event-loop-8] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 6.0 in stage 7.0 (TID 106, localhost, executor driver, partition 6, ANY, 7649 bytes)
2021-12-08 14:46:49,693 [dispatcher-event-loop-8] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 7.0 in stage 7.0 (TID 107, localhost, executor driver, partition 7, ANY, 7649 bytes)
2021-12-08 14:46:49,694 [dispatcher-event-loop-8] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 8.0 in stage 7.0 (TID 108, localhost, executor driver, partition 8, ANY, 7649 bytes)
2021-12-08 14:46:49,694 [dispatcher-event-loop-8] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 9.0 in stage 7.0 (TID 109, localhost, executor driver, partition 9, ANY, 7649 bytes)
2021-12-08 14:46:49,694 [dispatcher-event-loop-8] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 10.0 in stage 7.0 (TID 110, localhost, executor driver, partition 10, ANY, 7649 bytes)
2021-12-08 14:46:49,694 [dispatcher-event-loop-8] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 11.0 in stage 7.0 (TID 111, localhost, executor driver, partition 11, ANY, 7649 bytes)
2021-12-08 14:46:49,694 [Executor task launch worker for task 103] INFO [org.apache.spark.executor.Executor] - Running task 3.0 in stage 7.0 (TID 103)
2021-12-08 14:46:49,694 [Executor task launch worker for task 106] INFO [org.apache.spark.executor.Executor] - Running task 6.0 in stage 7.0 (TID 106)
2021-12-08 14:46:49,694 [Executor task launch worker for task 105] INFO [org.apache.spark.executor.Executor] - Running task 5.0 in stage 7.0 (TID 105)
2021-12-08 14:46:49,694 [Executor task launch worker for task 100] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 7.0 (TID 100)
2021-12-08 14:46:49,694 [Executor task launch worker for task 101] INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 7.0 (TID 101)
2021-12-08 14:46:49,694 [Executor task launch worker for task 104] INFO [org.apache.spark.executor.Executor] - Running task 4.0 in stage 7.0 (TID 104)
2021-12-08 14:46:49,694 [Executor task launch worker for task 102] INFO [org.apache.spark.executor.Executor] - Running task 2.0 in stage 7.0 (TID 102)
2021-12-08 14:46:49,694 [Executor task launch worker for task 107] INFO [org.apache.spark.executor.Executor] - Running task 7.0 in stage 7.0 (TID 107)
2021-12-08 14:46:49,694 [Executor task launch worker for task 111] INFO [org.apache.spark.executor.Executor] - Running task 11.0 in stage 7.0 (TID 111)
2021-12-08 14:46:49,694 [Executor task launch worker for task 108] INFO [org.apache.spark.executor.Executor] - Running task 8.0 in stage 7.0 (TID 108)
2021-12-08 14:46:49,694 [Executor task launch worker for task 109] INFO [org.apache.spark.executor.Executor] - Running task 9.0 in stage 7.0 (TID 109)
2021-12-08 14:46:49,694 [Executor task launch worker for task 110] INFO [org.apache.spark.executor.Executor] - Running task 10.0 in stage 7.0 (TID 110)
2021-12-08 14:46:49,698 [Executor task launch worker for task 109] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 20 non-empty blocks out of 20 blocks
2021-12-08 14:46:49,698 [Executor task launch worker for task 109] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-08 14:46:49,698 [Executor task launch worker for task 100] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 20 non-empty blocks out of 20 blocks
2021-12-08 14:46:49,698 [Executor task launch worker for task 111] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 20 non-empty blocks out of 20 blocks
2021-12-08 14:46:49,698 [Executor task launch worker for task 111] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-08 14:46:49,698 [Executor task launch worker for task 100] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-08 14:46:49,699 [Executor task launch worker for task 101] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 20 non-empty blocks out of 20 blocks
2021-12-08 14:46:49,699 [Executor task launch worker for task 101] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-08 14:46:49,699 [Executor task launch worker for task 110] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 20 non-empty blocks out of 20 blocks
2021-12-08 14:46:49,699 [Executor task launch worker for task 110] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-08 14:46:49,699 [Executor task launch worker for task 102] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 20 non-empty blocks out of 20 blocks
2021-12-08 14:46:49,699 [Executor task launch worker for task 102] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-08 14:46:49,699 [Executor task launch worker for task 108] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 20 non-empty blocks out of 20 blocks
2021-12-08 14:46:49,699 [Executor task launch worker for task 108] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-08 14:46:49,700 [Executor task launch worker for task 104] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 20 non-empty blocks out of 20 blocks
2021-12-08 14:46:49,700 [Executor task launch worker for task 104] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-08 14:46:49,700 [Executor task launch worker for task 106] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 20 non-empty blocks out of 20 blocks
2021-12-08 14:46:49,700 [Executor task launch worker for task 106] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-08 14:46:49,702 [Executor task launch worker for task 107] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 20 non-empty blocks out of 20 blocks
2021-12-08 14:46:49,702 [Executor task launch worker for task 107] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 1 ms
2021-12-08 14:46:49,702 [Executor task launch worker for task 103] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 20 non-empty blocks out of 20 blocks
2021-12-08 14:46:49,702 [Executor task launch worker for task 103] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-08 14:46:49,702 [Executor task launch worker for task 105] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 20 non-empty blocks out of 20 blocks
2021-12-08 14:46:49,702 [Executor task launch worker for task 105] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-08 14:46:50,004 [Executor task launch worker for task 105] INFO [org.apache.spark.executor.Executor] - Finished task 5.0 in stage 7.0 (TID 105). 1098 bytes result sent to driver
2021-12-08 14:46:50,008 [dispatcher-event-loop-8] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 12.0 in stage 7.0 (TID 112, localhost, executor driver, partition 12, ANY, 7649 bytes)
2021-12-08 14:46:50,008 [Executor task launch worker for task 112] INFO [org.apache.spark.executor.Executor] - Running task 12.0 in stage 7.0 (TID 112)
2021-12-08 14:46:50,008 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 5.0 in stage 7.0 (TID 105) in 315 ms on localhost (executor driver) (1/19)
2021-12-08 14:46:50,010 [Executor task launch worker for task 112] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 20 non-empty blocks out of 20 blocks
2021-12-08 14:46:50,011 [Executor task launch worker for task 112] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 1 ms
2021-12-08 14:46:50,016 [Executor task launch worker for task 104] INFO [org.apache.spark.executor.Executor] - Finished task 4.0 in stage 7.0 (TID 104). 1098 bytes result sent to driver
2021-12-08 14:46:50,017 [dispatcher-event-loop-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 13.0 in stage 7.0 (TID 113, localhost, executor driver, partition 13, ANY, 7649 bytes)
2021-12-08 14:46:50,017 [Executor task launch worker for task 113] INFO [org.apache.spark.executor.Executor] - Running task 13.0 in stage 7.0 (TID 113)
2021-12-08 14:46:50,017 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 4.0 in stage 7.0 (TID 104) in 324 ms on localhost (executor driver) (2/19)
2021-12-08 14:46:50,020 [Executor task launch worker for task 113] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 20 non-empty blocks out of 20 blocks
2021-12-08 14:46:50,020 [Executor task launch worker for task 113] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-08 14:46:50,020 [Executor task launch worker for task 106] INFO [org.apache.spark.executor.Executor] - Finished task 6.0 in stage 7.0 (TID 106). 1098 bytes result sent to driver
2021-12-08 14:46:50,021 [Executor task launch worker for task 109] INFO [org.apache.spark.executor.Executor] - Finished task 9.0 in stage 7.0 (TID 109). 1098 bytes result sent to driver
2021-12-08 14:46:50,021 [dispatcher-event-loop-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 14.0 in stage 7.0 (TID 114, localhost, executor driver, partition 14, ANY, 7649 bytes)
2021-12-08 14:46:50,021 [Executor task launch worker for task 114] INFO [org.apache.spark.executor.Executor] - Running task 14.0 in stage 7.0 (TID 114)
2021-12-08 14:46:50,021 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 6.0 in stage 7.0 (TID 106) in 328 ms on localhost (executor driver) (3/19)
2021-12-08 14:46:50,022 [dispatcher-event-loop-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 15.0 in stage 7.0 (TID 115, localhost, executor driver, partition 15, ANY, 7649 bytes)
2021-12-08 14:46:50,022 [Executor task launch worker for task 115] INFO [org.apache.spark.executor.Executor] - Running task 15.0 in stage 7.0 (TID 115)
2021-12-08 14:46:50,023 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 9.0 in stage 7.0 (TID 109) in 329 ms on localhost (executor driver) (4/19)
2021-12-08 14:46:50,024 [Executor task launch worker for task 115] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 20 non-empty blocks out of 20 blocks
2021-12-08 14:46:50,025 [Executor task launch worker for task 115] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 1 ms
2021-12-08 14:46:50,025 [Executor task launch worker for task 111] INFO [org.apache.spark.executor.Executor] - Finished task 11.0 in stage 7.0 (TID 111). 1098 bytes result sent to driver
2021-12-08 14:46:50,026 [dispatcher-event-loop-9] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 16.0 in stage 7.0 (TID 116, localhost, executor driver, partition 16, ANY, 7649 bytes)
2021-12-08 14:46:50,028 [Executor task launch worker for task 107] INFO [org.apache.spark.executor.Executor] - Finished task 7.0 in stage 7.0 (TID 107). 1098 bytes result sent to driver
2021-12-08 14:46:50,028 [Executor task launch worker for task 100] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 7.0 (TID 100). 1098 bytes result sent to driver
2021-12-08 14:46:50,029 [Executor task launch worker for task 103] INFO [org.apache.spark.executor.Executor] - Finished task 3.0 in stage 7.0 (TID 103). 1098 bytes result sent to driver
2021-12-08 14:46:50,029 [Executor task launch worker for task 110] INFO [org.apache.spark.executor.Executor] - Finished task 10.0 in stage 7.0 (TID 110). 1098 bytes result sent to driver
2021-12-08 14:46:50,031 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 11.0 in stage 7.0 (TID 111) in 337 ms on localhost (executor driver) (5/19)
2021-12-08 14:46:50,031 [Executor task launch worker for task 116] INFO [org.apache.spark.executor.Executor] - Running task 16.0 in stage 7.0 (TID 116)
2021-12-08 14:46:50,031 [dispatcher-event-loop-7] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 17.0 in stage 7.0 (TID 117, localhost, executor driver, partition 17, ANY, 7649 bytes)
2021-12-08 14:46:50,031 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 7.0 in stage 7.0 (TID 107) in 338 ms on localhost (executor driver) (6/19)
2021-12-08 14:46:50,032 [Executor task launch worker for task 114] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 20 non-empty blocks out of 20 blocks
2021-12-08 14:46:50,032 [Executor task launch worker for task 114] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-08 14:46:50,032 [Executor task launch worker for task 117] INFO [org.apache.spark.executor.Executor] - Running task 17.0 in stage 7.0 (TID 117)
2021-12-08 14:46:50,032 [Executor task launch worker for task 108] INFO [org.apache.spark.executor.Executor] - Finished task 8.0 in stage 7.0 (TID 108). 1098 bytes result sent to driver
2021-12-08 14:46:50,033 [Executor task launch worker for task 102] INFO [org.apache.spark.executor.Executor] - Finished task 2.0 in stage 7.0 (TID 102). 1098 bytes result sent to driver
2021-12-08 14:46:50,033 [Executor task launch worker for task 101] INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 7.0 (TID 101). 1098 bytes result sent to driver
2021-12-08 14:46:50,033 [dispatcher-event-loop-7] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 18.0 in stage 7.0 (TID 118, localhost, executor driver, partition 18, ANY, 7649 bytes)
2021-12-08 14:46:50,034 [Executor task launch worker for task 116] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 20 non-empty blocks out of 20 blocks
2021-12-08 14:46:50,034 [Executor task launch worker for task 116] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-08 14:46:50,034 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 10.0 in stage 7.0 (TID 110) in 340 ms on localhost (executor driver) (7/19)
2021-12-08 14:46:50,034 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 2.0 in stage 7.0 (TID 102) in 341 ms on localhost (executor driver) (8/19)
2021-12-08 14:46:50,035 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 7.0 (TID 101) in 342 ms on localhost (executor driver) (9/19)
2021-12-08 14:46:50,035 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 8.0 in stage 7.0 (TID 108) in 342 ms on localhost (executor driver) (10/19)
2021-12-08 14:46:50,034 [Executor task launch worker for task 118] INFO [org.apache.spark.executor.Executor] - Running task 18.0 in stage 7.0 (TID 118)
2021-12-08 14:46:50,035 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 3.0 in stage 7.0 (TID 103) in 342 ms on localhost (executor driver) (11/19)
2021-12-08 14:46:50,035 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 7.0 (TID 100) in 343 ms on localhost (executor driver) (12/19)
2021-12-08 14:46:50,035 [Executor task launch worker for task 117] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 20 non-empty blocks out of 20 blocks
2021-12-08 14:46:50,035 [Executor task launch worker for task 117] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-08 14:46:50,037 [Executor task launch worker for task 118] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 20 non-empty blocks out of 20 blocks
2021-12-08 14:46:50,037 [Executor task launch worker for task 118] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-08 14:46:50,091 [Executor task launch worker for task 112] INFO [org.apache.spark.executor.Executor] - Finished task 12.0 in stage 7.0 (TID 112). 1098 bytes result sent to driver
2021-12-08 14:46:50,091 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 12.0 in stage 7.0 (TID 112) in 83 ms on localhost (executor driver) (13/19)
2021-12-08 14:46:50,104 [Executor task launch worker for task 113] INFO [org.apache.spark.executor.Executor] - Finished task 13.0 in stage 7.0 (TID 113). 1098 bytes result sent to driver
2021-12-08 14:46:50,105 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 13.0 in stage 7.0 (TID 113) in 88 ms on localhost (executor driver) (14/19)
2021-12-08 14:46:50,107 [Executor task launch worker for task 115] INFO [org.apache.spark.executor.Executor] - Finished task 15.0 in stage 7.0 (TID 115). 1098 bytes result sent to driver
2021-12-08 14:46:50,108 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 15.0 in stage 7.0 (TID 115) in 86 ms on localhost (executor driver) (15/19)
2021-12-08 14:46:50,109 [Executor task launch worker for task 114] INFO [org.apache.spark.executor.Executor] - Finished task 14.0 in stage 7.0 (TID 114). 1141 bytes result sent to driver
2021-12-08 14:46:50,110 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 14.0 in stage 7.0 (TID 114) in 89 ms on localhost (executor driver) (16/19)
2021-12-08 14:46:50,113 [Executor task launch worker for task 117] INFO [org.apache.spark.executor.Executor] - Finished task 17.0 in stage 7.0 (TID 117). 1098 bytes result sent to driver
2021-12-08 14:46:50,114 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 17.0 in stage 7.0 (TID 117) in 83 ms on localhost (executor driver) (17/19)
2021-12-08 14:46:50,119 [Executor task launch worker for task 118] INFO [org.apache.spark.executor.Executor] - Finished task 18.0 in stage 7.0 (TID 118). 1098 bytes result sent to driver
2021-12-08 14:46:50,119 [Executor task launch worker for task 116] INFO [org.apache.spark.executor.Executor] - Finished task 16.0 in stage 7.0 (TID 116). 1098 bytes result sent to driver
2021-12-08 14:46:50,119 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 18.0 in stage 7.0 (TID 118) in 87 ms on localhost (executor driver) (18/19)
2021-12-08 14:46:50,119 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 16.0 in stage 7.0 (TID 116) in 94 ms on localhost (executor driver) (19/19)
2021-12-08 14:46:50,119 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 7.0, whose tasks have all completed, from pool 
2021-12-08 14:46:50,120 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 7 (zipWithIndex at PaidPromotionAdjustParameter.scala:68) finished in 0.431 s
2021-12-08 14:46:50,120 [main] INFO [org.apache.spark.scheduler.DAGScheduler] - Job 3 finished: zipWithIndex at PaidPromotionAdjustParameter.scala:68, took 1.495201 s
2021-12-08 14:46:50,133 [main] INFO [org.apache.spark.SparkContext] - Starting job: takeSample at PaidPromotionAdjustParameter.scala:71
2021-12-08 14:46:50,134 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 4 (takeSample at PaidPromotionAdjustParameter.scala:71) with 20 output partitions
2021-12-08 14:46:50,134 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 10 (takeSample at PaidPromotionAdjustParameter.scala:71)
2021-12-08 14:46:50,134 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 9)
2021-12-08 14:46:50,134 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2021-12-08 14:46:50,134 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 10 (MapPartitionsRDD[11] at map at PaidPromotionAdjustParameter.scala:70), which has no missing parents
2021-12-08 14:46:50,138 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_7 stored as values in memory (estimated size 4.2 KB, free 1990.4 MB)
2021-12-08 14:46:50,139 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_7_piece0 stored as bytes in memory (estimated size 2.4 KB, free 1990.4 MB)
2021-12-08 14:46:50,140 [dispatcher-event-loop-10] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_7_piece0 in memory on qb:62214 (size: 2.4 KB, free: 1990.8 MB)
2021-12-08 14:46:50,140 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 7 from broadcast at DAGScheduler.scala:1039
2021-12-08 14:46:50,140 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 20 missing tasks from ResultStage 10 (MapPartitionsRDD[11] at map at PaidPromotionAdjustParameter.scala:70) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14))
2021-12-08 14:46:50,140 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 10.0 with 20 tasks
2021-12-08 14:46:50,141 [dispatcher-event-loop-4] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 10.0 (TID 119, localhost, executor driver, partition 0, ANY, 7759 bytes)
2021-12-08 14:46:50,141 [dispatcher-event-loop-4] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 10.0 (TID 120, localhost, executor driver, partition 1, ANY, 7759 bytes)
2021-12-08 14:46:50,141 [dispatcher-event-loop-4] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 2.0 in stage 10.0 (TID 121, localhost, executor driver, partition 2, ANY, 7759 bytes)
2021-12-08 14:46:50,142 [dispatcher-event-loop-4] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 3.0 in stage 10.0 (TID 122, localhost, executor driver, partition 3, ANY, 7759 bytes)
2021-12-08 14:46:50,142 [dispatcher-event-loop-4] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 4.0 in stage 10.0 (TID 123, localhost, executor driver, partition 4, ANY, 7759 bytes)
2021-12-08 14:46:50,142 [dispatcher-event-loop-4] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 5.0 in stage 10.0 (TID 124, localhost, executor driver, partition 5, ANY, 7759 bytes)
2021-12-08 14:46:50,142 [dispatcher-event-loop-4] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 6.0 in stage 10.0 (TID 125, localhost, executor driver, partition 6, ANY, 7759 bytes)
2021-12-08 14:46:50,142 [dispatcher-event-loop-4] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 7.0 in stage 10.0 (TID 126, localhost, executor driver, partition 7, ANY, 7759 bytes)
2021-12-08 14:46:50,142 [dispatcher-event-loop-4] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 8.0 in stage 10.0 (TID 127, localhost, executor driver, partition 8, ANY, 7759 bytes)
2021-12-08 14:46:50,142 [dispatcher-event-loop-4] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 9.0 in stage 10.0 (TID 128, localhost, executor driver, partition 9, ANY, 7759 bytes)
2021-12-08 14:46:50,142 [dispatcher-event-loop-4] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 10.0 in stage 10.0 (TID 129, localhost, executor driver, partition 10, ANY, 7759 bytes)
2021-12-08 14:46:50,142 [dispatcher-event-loop-4] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 11.0 in stage 10.0 (TID 130, localhost, executor driver, partition 11, ANY, 7759 bytes)
2021-12-08 14:46:50,142 [Executor task launch worker for task 119] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 10.0 (TID 119)
2021-12-08 14:46:50,142 [Executor task launch worker for task 125] INFO [org.apache.spark.executor.Executor] - Running task 6.0 in stage 10.0 (TID 125)
2021-12-08 14:46:50,142 [Executor task launch worker for task 127] INFO [org.apache.spark.executor.Executor] - Running task 8.0 in stage 10.0 (TID 127)
2021-12-08 14:46:50,142 [Executor task launch worker for task 124] INFO [org.apache.spark.executor.Executor] - Running task 5.0 in stage 10.0 (TID 124)
2021-12-08 14:46:50,142 [Executor task launch worker for task 123] INFO [org.apache.spark.executor.Executor] - Running task 4.0 in stage 10.0 (TID 123)
2021-12-08 14:46:50,142 [Executor task launch worker for task 122] INFO [org.apache.spark.executor.Executor] - Running task 3.0 in stage 10.0 (TID 122)
2021-12-08 14:46:50,142 [Executor task launch worker for task 120] INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 10.0 (TID 120)
2021-12-08 14:46:50,142 [Executor task launch worker for task 121] INFO [org.apache.spark.executor.Executor] - Running task 2.0 in stage 10.0 (TID 121)
2021-12-08 14:46:50,142 [Executor task launch worker for task 130] INFO [org.apache.spark.executor.Executor] - Running task 11.0 in stage 10.0 (TID 130)
2021-12-08 14:46:50,142 [Executor task launch worker for task 129] INFO [org.apache.spark.executor.Executor] - Running task 10.0 in stage 10.0 (TID 129)
2021-12-08 14:46:50,142 [Executor task launch worker for task 128] INFO [org.apache.spark.executor.Executor] - Running task 9.0 in stage 10.0 (TID 128)
2021-12-08 14:46:50,142 [Executor task launch worker for task 126] INFO [org.apache.spark.executor.Executor] - Running task 7.0 in stage 10.0 (TID 126)
2021-12-08 14:46:50,145 [Executor task launch worker for task 129] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 20 non-empty blocks out of 20 blocks
2021-12-08 14:46:50,145 [Executor task launch worker for task 129] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-08 14:46:50,146 [Executor task launch worker for task 119] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 20 non-empty blocks out of 20 blocks
2021-12-08 14:46:50,146 [Executor task launch worker for task 125] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 20 non-empty blocks out of 20 blocks
2021-12-08 14:46:50,146 [Executor task launch worker for task 119] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-08 14:46:50,146 [Executor task launch worker for task 125] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-08 14:46:50,146 [Executor task launch worker for task 127] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 20 non-empty blocks out of 20 blocks
2021-12-08 14:46:50,146 [Executor task launch worker for task 127] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-08 14:46:50,147 [Executor task launch worker for task 121] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 20 non-empty blocks out of 20 blocks
2021-12-08 14:46:50,147 [Executor task launch worker for task 121] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-08 14:46:50,147 [Executor task launch worker for task 128] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 20 non-empty blocks out of 20 blocks
2021-12-08 14:46:50,147 [Executor task launch worker for task 128] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-08 14:46:50,148 [Executor task launch worker for task 122] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 20 non-empty blocks out of 20 blocks
2021-12-08 14:46:50,148 [Executor task launch worker for task 122] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-08 14:46:50,148 [Executor task launch worker for task 124] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 20 non-empty blocks out of 20 blocks
2021-12-08 14:46:50,148 [Executor task launch worker for task 124] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-08 14:46:50,148 [Executor task launch worker for task 120] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 20 non-empty blocks out of 20 blocks
2021-12-08 14:46:50,148 [Executor task launch worker for task 120] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-08 14:46:50,149 [Executor task launch worker for task 123] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 20 non-empty blocks out of 20 blocks
2021-12-08 14:46:50,149 [Executor task launch worker for task 123] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-08 14:46:50,149 [Executor task launch worker for task 130] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 20 non-empty blocks out of 20 blocks
2021-12-08 14:46:50,149 [Executor task launch worker for task 130] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-08 14:46:50,150 [Executor task launch worker for task 126] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 20 non-empty blocks out of 20 blocks
2021-12-08 14:46:50,150 [Executor task launch worker for task 126] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-08 14:46:50,259 [Executor task launch worker for task 124] INFO [org.apache.spark.executor.Executor] - Finished task 5.0 in stage 10.0 (TID 124). 1098 bytes result sent to driver
2021-12-08 14:46:50,260 [dispatcher-event-loop-11] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 12.0 in stage 10.0 (TID 131, localhost, executor driver, partition 12, ANY, 7759 bytes)
2021-12-08 14:46:50,260 [Executor task launch worker for task 131] INFO [org.apache.spark.executor.Executor] - Running task 12.0 in stage 10.0 (TID 131)
2021-12-08 14:46:50,266 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 5.0 in stage 10.0 (TID 124) in 124 ms on localhost (executor driver) (1/20)
2021-12-08 14:46:50,266 [Executor task launch worker for task 123] INFO [org.apache.spark.executor.Executor] - Finished task 4.0 in stage 10.0 (TID 123). 1098 bytes result sent to driver
2021-12-08 14:46:50,267 [dispatcher-event-loop-7] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 13.0 in stage 10.0 (TID 132, localhost, executor driver, partition 13, ANY, 7759 bytes)
2021-12-08 14:46:50,267 [Executor task launch worker for task 132] INFO [org.apache.spark.executor.Executor] - Running task 13.0 in stage 10.0 (TID 132)
2021-12-08 14:46:50,269 [Executor task launch worker for task 129] INFO [org.apache.spark.executor.Executor] - Finished task 10.0 in stage 10.0 (TID 129). 1098 bytes result sent to driver
2021-12-08 14:46:50,269 [Executor task launch worker for task 128] INFO [org.apache.spark.executor.Executor] - Finished task 9.0 in stage 10.0 (TID 128). 1141 bytes result sent to driver
2021-12-08 14:46:50,269 [Executor task launch worker for task 131] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 20 non-empty blocks out of 20 blocks
2021-12-08 14:46:50,269 [Executor task launch worker for task 131] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 2 ms
2021-12-08 14:46:50,269 [Executor task launch worker for task 130] INFO [org.apache.spark.executor.Executor] - Finished task 11.0 in stage 10.0 (TID 130). 1098 bytes result sent to driver
2021-12-08 14:46:50,269 [dispatcher-event-loop-6] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 14.0 in stage 10.0 (TID 133, localhost, executor driver, partition 14, ANY, 7759 bytes)
2021-12-08 14:46:50,269 [Executor task launch worker for task 133] INFO [org.apache.spark.executor.Executor] - Running task 14.0 in stage 10.0 (TID 133)
2021-12-08 14:46:50,269 [dispatcher-event-loop-6] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 15.0 in stage 10.0 (TID 134, localhost, executor driver, partition 15, ANY, 7759 bytes)
2021-12-08 14:46:50,269 [Executor task launch worker for task 134] INFO [org.apache.spark.executor.Executor] - Running task 15.0 in stage 10.0 (TID 134)
2021-12-08 14:46:50,270 [dispatcher-event-loop-6] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 16.0 in stage 10.0 (TID 135, localhost, executor driver, partition 16, ANY, 7759 bytes)
2021-12-08 14:46:50,270 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 10.0 in stage 10.0 (TID 129) in 128 ms on localhost (executor driver) (2/20)
2021-12-08 14:46:50,270 [Executor task launch worker for task 132] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 20 non-empty blocks out of 20 blocks
2021-12-08 14:46:50,270 [Executor task launch worker for task 132] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-08 14:46:50,270 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 9.0 in stage 10.0 (TID 128) in 128 ms on localhost (executor driver) (3/20)
2021-12-08 14:46:50,270 [Executor task launch worker for task 135] INFO [org.apache.spark.executor.Executor] - Running task 16.0 in stage 10.0 (TID 135)
2021-12-08 14:46:50,270 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 4.0 in stage 10.0 (TID 123) in 128 ms on localhost (executor driver) (4/20)
2021-12-08 14:46:50,270 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 11.0 in stage 10.0 (TID 130) in 128 ms on localhost (executor driver) (5/20)
2021-12-08 14:46:50,273 [Executor task launch worker for task 133] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 20 non-empty blocks out of 20 blocks
2021-12-08 14:46:50,273 [Executor task launch worker for task 133] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-08 14:46:50,273 [Executor task launch worker for task 135] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 20 non-empty blocks out of 20 blocks
2021-12-08 14:46:50,273 [Executor task launch worker for task 135] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-08 14:46:50,274 [Executor task launch worker for task 134] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 20 non-empty blocks out of 20 blocks
2021-12-08 14:46:50,274 [Executor task launch worker for task 134] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-08 14:46:50,277 [Executor task launch worker for task 122] INFO [org.apache.spark.executor.Executor] - Finished task 3.0 in stage 10.0 (TID 122). 1098 bytes result sent to driver
2021-12-08 14:46:50,278 [dispatcher-event-loop-10] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 17.0 in stage 10.0 (TID 136, localhost, executor driver, partition 17, ANY, 7759 bytes)
2021-12-08 14:46:50,278 [Executor task launch worker for task 136] INFO [org.apache.spark.executor.Executor] - Running task 17.0 in stage 10.0 (TID 136)
2021-12-08 14:46:50,278 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 3.0 in stage 10.0 (TID 122) in 137 ms on localhost (executor driver) (6/20)
2021-12-08 14:46:50,278 [Executor task launch worker for task 120] INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 10.0 (TID 120). 1096 bytes result sent to driver
2021-12-08 14:46:50,278 [dispatcher-event-loop-11] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 18.0 in stage 10.0 (TID 137, localhost, executor driver, partition 18, ANY, 7759 bytes)
2021-12-08 14:46:50,279 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 10.0 (TID 120) in 138 ms on localhost (executor driver) (7/20)
2021-12-08 14:46:50,279 [Executor task launch worker for task 137] INFO [org.apache.spark.executor.Executor] - Running task 18.0 in stage 10.0 (TID 137)
2021-12-08 14:46:50,282 [Executor task launch worker for task 136] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 20 non-empty blocks out of 20 blocks
2021-12-08 14:46:50,282 [Executor task launch worker for task 136] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 1 ms
2021-12-08 14:46:50,282 [Executor task launch worker for task 137] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 20 non-empty blocks out of 20 blocks
2021-12-08 14:46:50,283 [Executor task launch worker for task 137] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 1 ms
2021-12-08 14:46:50,283 [Executor task launch worker for task 121] INFO [org.apache.spark.executor.Executor] - Finished task 2.0 in stage 10.0 (TID 121). 1139 bytes result sent to driver
2021-12-08 14:46:50,283 [dispatcher-event-loop-7] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 19.0 in stage 10.0 (TID 138, localhost, executor driver, partition 19, ANY, 7759 bytes)
2021-12-08 14:46:50,283 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 2.0 in stage 10.0 (TID 121) in 142 ms on localhost (executor driver) (8/20)
2021-12-08 14:46:50,283 [Executor task launch worker for task 138] INFO [org.apache.spark.executor.Executor] - Running task 19.0 in stage 10.0 (TID 138)
2021-12-08 14:46:50,284 [Executor task launch worker for task 126] INFO [org.apache.spark.executor.Executor] - Finished task 7.0 in stage 10.0 (TID 126). 1098 bytes result sent to driver
2021-12-08 14:46:50,285 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 7.0 in stage 10.0 (TID 126) in 143 ms on localhost (executor driver) (9/20)
2021-12-08 14:46:50,287 [Executor task launch worker for task 138] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 20 non-empty blocks out of 20 blocks
2021-12-08 14:46:50,287 [Executor task launch worker for task 138] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 1 ms
2021-12-08 14:46:50,290 [Executor task launch worker for task 125] INFO [org.apache.spark.executor.Executor] - Finished task 6.0 in stage 10.0 (TID 125). 1098 bytes result sent to driver
2021-12-08 14:46:50,291 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 6.0 in stage 10.0 (TID 125) in 149 ms on localhost (executor driver) (10/20)
2021-12-08 14:46:50,291 [Executor task launch worker for task 127] INFO [org.apache.spark.executor.Executor] - Finished task 8.0 in stage 10.0 (TID 127). 1098 bytes result sent to driver
2021-12-08 14:46:50,291 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 8.0 in stage 10.0 (TID 127) in 149 ms on localhost (executor driver) (11/20)
2021-12-08 14:46:50,294 [Executor task launch worker for task 119] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 10.0 (TID 119). 1096 bytes result sent to driver
2021-12-08 14:46:50,294 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 10.0 (TID 119) in 153 ms on localhost (executor driver) (12/20)
2021-12-08 14:46:50,382 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 83
2021-12-08 14:46:50,382 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 57
2021-12-08 14:46:50,382 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 68
2021-12-08 14:46:50,382 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 34
2021-12-08 14:46:50,383 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 96
2021-12-08 14:46:50,383 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 78
2021-12-08 14:46:50,383 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 129
2021-12-08 14:46:50,383 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 91
2021-12-08 14:46:50,383 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 42
2021-12-08 14:46:50,383 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 142
2021-12-08 14:46:50,383 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 92
2021-12-08 14:46:50,383 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 118
2021-12-08 14:46:50,383 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 115
2021-12-08 14:46:50,383 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 122
2021-12-08 14:46:50,383 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 62
2021-12-08 14:46:50,383 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 125
2021-12-08 14:46:50,383 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 38
2021-12-08 14:46:50,383 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 116
2021-12-08 14:46:50,383 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 108
2021-12-08 14:46:50,383 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 60
2021-12-08 14:46:50,383 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 110
2021-12-08 14:46:50,383 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 76
2021-12-08 14:46:50,383 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 71
2021-12-08 14:46:50,383 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 89
2021-12-08 14:46:50,383 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 66
2021-12-08 14:46:50,383 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 145
2021-12-08 14:46:50,383 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 130
2021-12-08 14:46:50,383 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 84
2021-12-08 14:46:50,383 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 132
2021-12-08 14:46:50,383 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 143
2021-12-08 14:46:50,383 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 135
2021-12-08 14:46:50,383 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 79
2021-12-08 14:46:50,383 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 49
2021-12-08 14:46:50,384 [dispatcher-event-loop-10] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_4_piece0 on qb:62214 in memory (size: 2.4 KB, free: 1990.8 MB)
2021-12-08 14:46:50,384 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 109
2021-12-08 14:46:50,385 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 134
2021-12-08 14:46:50,385 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 111
2021-12-08 14:46:50,385 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 40
2021-12-08 14:46:50,385 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 29
2021-12-08 14:46:50,385 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 80
2021-12-08 14:46:50,385 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 98
2021-12-08 14:46:50,385 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 117
2021-12-08 14:46:50,385 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 48
2021-12-08 14:46:50,385 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 69
2021-12-08 14:46:50,385 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 144
2021-12-08 14:46:50,385 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 87
2021-12-08 14:46:50,385 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 52
2021-12-08 14:46:50,385 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 95
2021-12-08 14:46:50,385 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 126
2021-12-08 14:46:50,385 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 77
2021-12-08 14:46:50,385 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 124
2021-12-08 14:46:50,385 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 53
2021-12-08 14:46:50,385 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 141
2021-12-08 14:46:50,385 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 43
2021-12-08 14:46:50,385 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 82
2021-12-08 14:46:50,385 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 36
2021-12-08 14:46:50,385 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 113
2021-12-08 14:46:50,385 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 90
2021-12-08 14:46:50,385 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 33
2021-12-08 14:46:50,385 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 26
2021-12-08 14:46:50,386 [dispatcher-event-loop-2] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_3_piece0 on qb:62214 in memory (size: 1907.0 B, free: 1990.8 MB)
2021-12-08 14:46:50,386 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 101
2021-12-08 14:46:50,386 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 146
2021-12-08 14:46:50,386 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 28
2021-12-08 14:46:50,386 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 102
2021-12-08 14:46:50,386 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 67
2021-12-08 14:46:50,386 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 93
2021-12-08 14:46:50,386 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 39
2021-12-08 14:46:50,386 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 51
2021-12-08 14:46:50,386 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 72
2021-12-08 14:46:50,386 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 99
2021-12-08 14:46:50,386 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 63
2021-12-08 14:46:50,386 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 136
2021-12-08 14:46:50,386 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 85
2021-12-08 14:46:50,386 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 74
2021-12-08 14:46:50,386 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 70
2021-12-08 14:46:50,386 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 37
2021-12-08 14:46:50,386 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 128
2021-12-08 14:46:50,386 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 31
2021-12-08 14:46:50,386 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 88
2021-12-08 14:46:50,386 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 45
2021-12-08 14:46:50,386 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 127
2021-12-08 14:46:50,386 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 35
2021-12-08 14:46:50,386 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 139
2021-12-08 14:46:50,386 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 137
2021-12-08 14:46:50,386 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 65
2021-12-08 14:46:50,386 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 121
2021-12-08 14:46:50,386 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 73
2021-12-08 14:46:50,387 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 61
2021-12-08 14:46:50,387 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 119
2021-12-08 14:46:50,387 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 131
2021-12-08 14:46:50,387 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 100
2021-12-08 14:46:50,387 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 55
2021-12-08 14:46:50,387 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 41
2021-12-08 14:46:50,388 [dispatcher-event-loop-5] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_5_piece0 on qb:62214 in memory (size: 2.4 KB, free: 1990.8 MB)
2021-12-08 14:46:50,388 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 46
2021-12-08 14:46:50,388 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 58
2021-12-08 14:46:50,388 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 59
2021-12-08 14:46:50,388 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 56
2021-12-08 14:46:50,388 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 149
2021-12-08 14:46:50,388 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 81
2021-12-08 14:46:50,388 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 114
2021-12-08 14:46:50,388 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 97
2021-12-08 14:46:50,388 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 32
2021-12-08 14:46:50,388 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 64
2021-12-08 14:46:50,388 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 54
2021-12-08 14:46:50,388 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 30
2021-12-08 14:46:50,388 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 106
2021-12-08 14:46:50,388 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 140
2021-12-08 14:46:50,388 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 120
2021-12-08 14:46:50,389 [dispatcher-event-loop-8] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_6_piece0 on qb:62214 in memory (size: 2.0 KB, free: 1990.8 MB)
2021-12-08 14:46:50,390 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 112
2021-12-08 14:46:50,390 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 147
2021-12-08 14:46:50,390 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 148
2021-12-08 14:46:50,390 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 44
2021-12-08 14:46:50,390 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 47
2021-12-08 14:46:50,390 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 25
2021-12-08 14:46:50,390 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 75
2021-12-08 14:46:50,390 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 94
2021-12-08 14:46:50,390 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 138
2021-12-08 14:46:50,390 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 27
2021-12-08 14:46:50,390 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 50
2021-12-08 14:46:50,390 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 86
2021-12-08 14:46:50,390 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 133
2021-12-08 14:46:50,390 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 123
2021-12-08 14:46:50,390 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 104
2021-12-08 14:46:50,390 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 103
2021-12-08 14:46:50,390 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 105
2021-12-08 14:46:50,390 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 107
2021-12-08 14:46:50,393 [Executor task launch worker for task 131] INFO [org.apache.spark.executor.Executor] - Finished task 12.0 in stage 10.0 (TID 131). 1098 bytes result sent to driver
2021-12-08 14:46:50,393 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 12.0 in stage 10.0 (TID 131) in 133 ms on localhost (executor driver) (13/20)
2021-12-08 14:46:50,399 [Executor task launch worker for task 133] INFO [org.apache.spark.executor.Executor] - Finished task 14.0 in stage 10.0 (TID 133). 1139 bytes result sent to driver
2021-12-08 14:46:50,400 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 14.0 in stage 10.0 (TID 133) in 131 ms on localhost (executor driver) (14/20)
2021-12-08 14:46:50,408 [Executor task launch worker for task 132] INFO [org.apache.spark.executor.Executor] - Finished task 13.0 in stage 10.0 (TID 132). 1098 bytes result sent to driver
2021-12-08 14:46:50,408 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 13.0 in stage 10.0 (TID 132) in 141 ms on localhost (executor driver) (15/20)
2021-12-08 14:46:50,411 [Executor task launch worker for task 137] INFO [org.apache.spark.executor.Executor] - Finished task 18.0 in stage 10.0 (TID 137). 1096 bytes result sent to driver
2021-12-08 14:46:50,411 [Executor task launch worker for task 136] INFO [org.apache.spark.executor.Executor] - Finished task 17.0 in stage 10.0 (TID 136). 1096 bytes result sent to driver
2021-12-08 14:46:50,411 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 18.0 in stage 10.0 (TID 137) in 133 ms on localhost (executor driver) (16/20)
2021-12-08 14:46:50,412 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 17.0 in stage 10.0 (TID 136) in 134 ms on localhost (executor driver) (17/20)
2021-12-08 14:46:50,413 [Executor task launch worker for task 134] INFO [org.apache.spark.executor.Executor] - Finished task 15.0 in stage 10.0 (TID 134). 1139 bytes result sent to driver
2021-12-08 14:46:50,413 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 15.0 in stage 10.0 (TID 134) in 144 ms on localhost (executor driver) (18/20)
2021-12-08 14:46:50,413 [Executor task launch worker for task 135] INFO [org.apache.spark.executor.Executor] - Finished task 16.0 in stage 10.0 (TID 135). 1139 bytes result sent to driver
2021-12-08 14:46:50,413 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 16.0 in stage 10.0 (TID 135) in 144 ms on localhost (executor driver) (19/20)
2021-12-08 14:46:50,417 [Executor task launch worker for task 138] INFO [org.apache.spark.executor.Executor] - Finished task 19.0 in stage 10.0 (TID 138). 1096 bytes result sent to driver
2021-12-08 14:46:50,417 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 19.0 in stage 10.0 (TID 138) in 134 ms on localhost (executor driver) (20/20)
2021-12-08 14:46:50,417 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 10.0, whose tasks have all completed, from pool 
2021-12-08 14:46:50,417 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 10 (takeSample at PaidPromotionAdjustParameter.scala:71) finished in 0.281 s
2021-12-08 14:46:50,417 [main] INFO [org.apache.spark.scheduler.DAGScheduler] - Job 4 finished: takeSample at PaidPromotionAdjustParameter.scala:71, took 0.282812 s
2021-12-08 14:46:50,431 [main] INFO [org.apache.spark.SparkContext] - Starting job: takeSample at PaidPromotionAdjustParameter.scala:71
2021-12-08 14:46:50,432 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 5 (takeSample at PaidPromotionAdjustParameter.scala:71) with 20 output partitions
2021-12-08 14:46:50,432 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 13 (takeSample at PaidPromotionAdjustParameter.scala:71)
2021-12-08 14:46:50,432 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 12)
2021-12-08 14:46:50,432 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2021-12-08 14:46:50,432 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 13 (PartitionwiseSampledRDD[12] at takeSample at PaidPromotionAdjustParameter.scala:71), which has no missing parents
2021-12-08 14:46:50,435 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_8 stored as values in memory (estimated size 4.9 KB, free 1990.5 MB)
2021-12-08 14:46:50,436 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_8_piece0 stored as bytes in memory (estimated size 2.8 KB, free 1990.5 MB)
2021-12-08 14:46:50,437 [dispatcher-event-loop-5] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_8_piece0 in memory on qb:62214 (size: 2.8 KB, free: 1990.8 MB)
2021-12-08 14:46:50,437 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 8 from broadcast at DAGScheduler.scala:1039
2021-12-08 14:46:50,437 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 20 missing tasks from ResultStage 13 (PartitionwiseSampledRDD[12] at takeSample at PaidPromotionAdjustParameter.scala:71) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14))
2021-12-08 14:46:50,437 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 13.0 with 20 tasks
2021-12-08 14:46:50,438 [dispatcher-event-loop-6] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 13.0 (TID 139, localhost, executor driver, partition 0, ANY, 7868 bytes)
2021-12-08 14:46:50,438 [dispatcher-event-loop-6] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 13.0 (TID 140, localhost, executor driver, partition 1, ANY, 7868 bytes)
2021-12-08 14:46:50,438 [dispatcher-event-loop-6] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 2.0 in stage 13.0 (TID 141, localhost, executor driver, partition 2, ANY, 7868 bytes)
2021-12-08 14:46:50,438 [dispatcher-event-loop-6] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 3.0 in stage 13.0 (TID 142, localhost, executor driver, partition 3, ANY, 7868 bytes)
2021-12-08 14:46:50,438 [dispatcher-event-loop-6] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 4.0 in stage 13.0 (TID 143, localhost, executor driver, partition 4, ANY, 7868 bytes)
2021-12-08 14:46:50,438 [dispatcher-event-loop-6] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 5.0 in stage 13.0 (TID 144, localhost, executor driver, partition 5, ANY, 7868 bytes)
2021-12-08 14:46:50,438 [dispatcher-event-loop-6] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 6.0 in stage 13.0 (TID 145, localhost, executor driver, partition 6, ANY, 7868 bytes)
2021-12-08 14:46:50,439 [dispatcher-event-loop-6] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 7.0 in stage 13.0 (TID 146, localhost, executor driver, partition 7, ANY, 7868 bytes)
2021-12-08 14:46:50,439 [dispatcher-event-loop-6] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 8.0 in stage 13.0 (TID 147, localhost, executor driver, partition 8, ANY, 7868 bytes)
2021-12-08 14:46:50,439 [dispatcher-event-loop-6] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 9.0 in stage 13.0 (TID 148, localhost, executor driver, partition 9, ANY, 7868 bytes)
2021-12-08 14:46:50,439 [dispatcher-event-loop-6] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 10.0 in stage 13.0 (TID 149, localhost, executor driver, partition 10, ANY, 7868 bytes)
2021-12-08 14:46:50,439 [dispatcher-event-loop-6] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 11.0 in stage 13.0 (TID 150, localhost, executor driver, partition 11, ANY, 7868 bytes)
2021-12-08 14:46:50,439 [Executor task launch worker for task 139] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 13.0 (TID 139)
2021-12-08 14:46:50,439 [Executor task launch worker for task 141] INFO [org.apache.spark.executor.Executor] - Running task 2.0 in stage 13.0 (TID 141)
2021-12-08 14:46:50,439 [Executor task launch worker for task 147] INFO [org.apache.spark.executor.Executor] - Running task 8.0 in stage 13.0 (TID 147)
2021-12-08 14:46:50,439 [Executor task launch worker for task 148] INFO [org.apache.spark.executor.Executor] - Running task 9.0 in stage 13.0 (TID 148)
2021-12-08 14:46:50,439 [Executor task launch worker for task 144] INFO [org.apache.spark.executor.Executor] - Running task 5.0 in stage 13.0 (TID 144)
2021-12-08 14:46:50,439 [Executor task launch worker for task 143] INFO [org.apache.spark.executor.Executor] - Running task 4.0 in stage 13.0 (TID 143)
2021-12-08 14:46:50,439 [Executor task launch worker for task 142] INFO [org.apache.spark.executor.Executor] - Running task 3.0 in stage 13.0 (TID 142)
2021-12-08 14:46:50,439 [Executor task launch worker for task 140] INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 13.0 (TID 140)
2021-12-08 14:46:50,439 [Executor task launch worker for task 150] INFO [org.apache.spark.executor.Executor] - Running task 11.0 in stage 13.0 (TID 150)
2021-12-08 14:46:50,439 [Executor task launch worker for task 145] INFO [org.apache.spark.executor.Executor] - Running task 6.0 in stage 13.0 (TID 145)
2021-12-08 14:46:50,439 [Executor task launch worker for task 149] INFO [org.apache.spark.executor.Executor] - Running task 10.0 in stage 13.0 (TID 149)
2021-12-08 14:46:50,439 [Executor task launch worker for task 146] INFO [org.apache.spark.executor.Executor] - Running task 7.0 in stage 13.0 (TID 146)
2021-12-08 14:46:50,443 [Executor task launch worker for task 146] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 20 non-empty blocks out of 20 blocks
2021-12-08 14:46:50,443 [Executor task launch worker for task 149] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 20 non-empty blocks out of 20 blocks
2021-12-08 14:46:50,443 [Executor task launch worker for task 146] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-08 14:46:50,443 [Executor task launch worker for task 149] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-08 14:46:50,443 [Executor task launch worker for task 148] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 20 non-empty blocks out of 20 blocks
2021-12-08 14:46:50,443 [Executor task launch worker for task 148] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-08 14:46:50,444 [Executor task launch worker for task 145] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 20 non-empty blocks out of 20 blocks
2021-12-08 14:46:50,444 [Executor task launch worker for task 145] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 1 ms
2021-12-08 14:46:50,444 [Executor task launch worker for task 150] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 20 non-empty blocks out of 20 blocks
2021-12-08 14:46:50,444 [Executor task launch worker for task 150] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-08 14:46:50,444 [Executor task launch worker for task 139] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 20 non-empty blocks out of 20 blocks
2021-12-08 14:46:50,444 [Executor task launch worker for task 139] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-08 14:46:50,445 [Executor task launch worker for task 142] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 20 non-empty blocks out of 20 blocks
2021-12-08 14:46:50,445 [Executor task launch worker for task 142] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-08 14:46:50,445 [Executor task launch worker for task 140] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 20 non-empty blocks out of 20 blocks
2021-12-08 14:46:50,445 [Executor task launch worker for task 140] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-08 14:46:50,446 [Executor task launch worker for task 143] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 20 non-empty blocks out of 20 blocks
2021-12-08 14:46:50,446 [Executor task launch worker for task 143] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-08 14:46:50,446 [Executor task launch worker for task 147] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 20 non-empty blocks out of 20 blocks
2021-12-08 14:46:50,446 [Executor task launch worker for task 147] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-08 14:46:50,446 [Executor task launch worker for task 144] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 20 non-empty blocks out of 20 blocks
2021-12-08 14:46:50,446 [Executor task launch worker for task 144] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-08 14:46:50,446 [Executor task launch worker for task 141] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 20 non-empty blocks out of 20 blocks
2021-12-08 14:46:50,446 [Executor task launch worker for task 141] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-08 14:46:50,532 [Executor task launch worker for task 149] INFO [org.apache.spark.executor.Executor] - Finished task 10.0 in stage 13.0 (TID 149). 31649 bytes result sent to driver
2021-12-08 14:46:50,533 [dispatcher-event-loop-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 12.0 in stage 13.0 (TID 151, localhost, executor driver, partition 12, ANY, 7868 bytes)
2021-12-08 14:46:50,533 [Executor task launch worker for task 151] INFO [org.apache.spark.executor.Executor] - Running task 12.0 in stage 13.0 (TID 151)
2021-12-08 14:46:50,534 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 10.0 in stage 13.0 (TID 149) in 95 ms on localhost (executor driver) (1/20)
2021-12-08 14:46:50,536 [Executor task launch worker for task 151] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 20 non-empty blocks out of 20 blocks
2021-12-08 14:46:50,536 [Executor task launch worker for task 151] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-08 14:46:50,541 [Executor task launch worker for task 144] INFO [org.apache.spark.executor.Executor] - Finished task 5.0 in stage 13.0 (TID 144). 33639 bytes result sent to driver
2021-12-08 14:46:50,541 [dispatcher-event-loop-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 13.0 in stage 13.0 (TID 152, localhost, executor driver, partition 13, ANY, 7868 bytes)
2021-12-08 14:46:50,542 [Executor task launch worker for task 152] INFO [org.apache.spark.executor.Executor] - Running task 13.0 in stage 13.0 (TID 152)
2021-12-08 14:46:50,542 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 5.0 in stage 13.0 (TID 144) in 104 ms on localhost (executor driver) (2/20)
2021-12-08 14:46:50,544 [Executor task launch worker for task 146] INFO [org.apache.spark.executor.Executor] - Finished task 7.0 in stage 13.0 (TID 146). 39939 bytes result sent to driver
2021-12-08 14:46:50,544 [dispatcher-event-loop-10] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 14.0 in stage 13.0 (TID 153, localhost, executor driver, partition 14, ANY, 7868 bytes)
2021-12-08 14:46:50,544 [Executor task launch worker for task 153] INFO [org.apache.spark.executor.Executor] - Running task 14.0 in stage 13.0 (TID 153)
2021-12-08 14:46:50,544 [Executor task launch worker for task 152] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 20 non-empty blocks out of 20 blocks
2021-12-08 14:46:50,545 [Executor task launch worker for task 152] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 1 ms
2021-12-08 14:46:50,547 [Executor task launch worker for task 153] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 20 non-empty blocks out of 20 blocks
2021-12-08 14:46:50,547 [Executor task launch worker for task 153] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-08 14:46:50,549 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 7.0 in stage 13.0 (TID 146) in 111 ms on localhost (executor driver) (3/20)
2021-12-08 14:46:50,555 [Executor task launch worker for task 141] INFO [org.apache.spark.executor.Executor] - Finished task 2.0 in stage 13.0 (TID 141). 1097 bytes result sent to driver
2021-12-08 14:46:50,555 [Executor task launch worker for task 145] INFO [org.apache.spark.executor.Executor] - Finished task 6.0 in stage 13.0 (TID 145). 38380 bytes result sent to driver
2021-12-08 14:46:50,555 [dispatcher-event-loop-11] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 15.0 in stage 13.0 (TID 154, localhost, executor driver, partition 15, ANY, 7868 bytes)
2021-12-08 14:46:50,555 [Executor task launch worker for task 154] INFO [org.apache.spark.executor.Executor] - Running task 15.0 in stage 13.0 (TID 154)
2021-12-08 14:46:50,555 [dispatcher-event-loop-11] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 16.0 in stage 13.0 (TID 155, localhost, executor driver, partition 16, ANY, 7868 bytes)
2021-12-08 14:46:50,555 [Executor task launch worker for task 155] INFO [org.apache.spark.executor.Executor] - Running task 16.0 in stage 13.0 (TID 155)
2021-12-08 14:46:50,556 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 6.0 in stage 13.0 (TID 145) in 118 ms on localhost (executor driver) (4/20)
2021-12-08 14:46:50,556 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 2.0 in stage 13.0 (TID 141) in 118 ms on localhost (executor driver) (5/20)
2021-12-08 14:46:50,558 [Executor task launch worker for task 155] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 20 non-empty blocks out of 20 blocks
2021-12-08 14:46:50,558 [Executor task launch worker for task 154] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 20 non-empty blocks out of 20 blocks
2021-12-08 14:46:50,559 [Executor task launch worker for task 155] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 1 ms
2021-12-08 14:46:50,559 [Executor task launch worker for task 154] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 1 ms
2021-12-08 14:46:50,559 [Executor task launch worker for task 148] INFO [org.apache.spark.executor.Executor] - Finished task 9.0 in stage 13.0 (TID 148). 32941 bytes result sent to driver
2021-12-08 14:46:50,563 [Executor task launch worker for task 142] INFO [org.apache.spark.executor.Executor] - Finished task 3.0 in stage 13.0 (TID 142). 26773 bytes result sent to driver
2021-12-08 14:46:50,565 [dispatcher-event-loop-5] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 17.0 in stage 13.0 (TID 156, localhost, executor driver, partition 17, ANY, 7868 bytes)
2021-12-08 14:46:50,565 [Executor task launch worker for task 156] INFO [org.apache.spark.executor.Executor] - Running task 17.0 in stage 13.0 (TID 156)
2021-12-08 14:46:50,566 [dispatcher-event-loop-5] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 18.0 in stage 13.0 (TID 157, localhost, executor driver, partition 18, ANY, 7868 bytes)
2021-12-08 14:46:50,569 [Executor task launch worker for task 156] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 20 non-empty blocks out of 20 blocks
2021-12-08 14:46:50,569 [Executor task launch worker for task 156] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-08 14:46:50,569 [Executor task launch worker for task 157] INFO [org.apache.spark.executor.Executor] - Running task 18.0 in stage 13.0 (TID 157)
2021-12-08 14:46:50,571 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 3.0 in stage 13.0 (TID 142) in 133 ms on localhost (executor driver) (6/20)
2021-12-08 14:46:50,573 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 9.0 in stage 13.0 (TID 148) in 134 ms on localhost (executor driver) (7/20)
2021-12-08 14:46:50,575 [Executor task launch worker for task 150] INFO [org.apache.spark.executor.Executor] - Finished task 11.0 in stage 13.0 (TID 150). 33946 bytes result sent to driver
2021-12-08 14:46:50,576 [dispatcher-event-loop-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 19.0 in stage 13.0 (TID 158, localhost, executor driver, partition 19, ANY, 7868 bytes)
2021-12-08 14:46:50,590 [Executor task launch worker for task 158] INFO [org.apache.spark.executor.Executor] - Running task 19.0 in stage 13.0 (TID 158)
2021-12-08 14:46:50,594 [Executor task launch worker for task 158] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 20 non-empty blocks out of 20 blocks
2021-12-08 14:46:50,594 [Executor task launch worker for task 158] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-08 14:46:50,595 [Executor task launch worker for task 143] INFO [org.apache.spark.executor.Executor] - Finished task 4.0 in stage 13.0 (TID 143). 33761 bytes result sent to driver
2021-12-08 14:46:50,596 [Executor task launch worker for task 139] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 13.0 (TID 139). 1140 bytes result sent to driver
2021-12-08 14:46:50,596 [Executor task launch worker for task 140] INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 13.0 (TID 140). 1097 bytes result sent to driver
2021-12-08 14:46:50,597 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 11.0 in stage 13.0 (TID 150) in 158 ms on localhost (executor driver) (8/20)
2021-12-08 14:46:50,597 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 4.0 in stage 13.0 (TID 143) in 159 ms on localhost (executor driver) (9/20)
2021-12-08 14:46:50,597 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 13.0 (TID 139) in 159 ms on localhost (executor driver) (10/20)
2021-12-08 14:46:50,597 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 13.0 (TID 140) in 159 ms on localhost (executor driver) (11/20)
2021-12-08 14:46:50,597 [Executor task launch worker for task 157] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 20 non-empty blocks out of 20 blocks
2021-12-08 14:46:50,597 [Executor task launch worker for task 157] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-08 14:46:50,608 [Executor task launch worker for task 147] INFO [org.apache.spark.executor.Executor] - Finished task 8.0 in stage 13.0 (TID 147). 39708 bytes result sent to driver
2021-12-08 14:46:50,611 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 8.0 in stage 13.0 (TID 147) in 172 ms on localhost (executor driver) (12/20)
2021-12-08 14:46:50,620 [Executor task launch worker for task 151] INFO [org.apache.spark.executor.Executor] - Finished task 12.0 in stage 13.0 (TID 151). 30842 bytes result sent to driver
2021-12-08 14:46:50,620 [Executor task launch worker for task 153] INFO [org.apache.spark.executor.Executor] - Finished task 14.0 in stage 13.0 (TID 153). 1097 bytes result sent to driver
2021-12-08 14:46:50,621 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 14.0 in stage 13.0 (TID 153) in 77 ms on localhost (executor driver) (13/20)
2021-12-08 14:46:50,621 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 12.0 in stage 13.0 (TID 151) in 88 ms on localhost (executor driver) (14/20)
2021-12-08 14:46:50,632 [Executor task launch worker for task 152] INFO [org.apache.spark.executor.Executor] - Finished task 13.0 in stage 13.0 (TID 152). 19270 bytes result sent to driver
2021-12-08 14:46:50,633 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 13.0 in stage 13.0 (TID 152) in 92 ms on localhost (executor driver) (15/20)
2021-12-08 14:46:50,635 [Executor task launch worker for task 154] INFO [org.apache.spark.executor.Executor] - Finished task 15.0 in stage 13.0 (TID 154). 1097 bytes result sent to driver
2021-12-08 14:46:50,636 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 15.0 in stage 13.0 (TID 154) in 81 ms on localhost (executor driver) (16/20)
2021-12-08 14:46:50,641 [Executor task launch worker for task 155] INFO [org.apache.spark.executor.Executor] - Finished task 16.0 in stage 13.0 (TID 155). 1097 bytes result sent to driver
2021-12-08 14:46:50,641 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 16.0 in stage 13.0 (TID 155) in 86 ms on localhost (executor driver) (17/20)
2021-12-08 14:46:50,642 [Executor task launch worker for task 156] INFO [org.apache.spark.executor.Executor] - Finished task 17.0 in stage 13.0 (TID 156). 1140 bytes result sent to driver
2021-12-08 14:46:50,642 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 17.0 in stage 13.0 (TID 156) in 78 ms on localhost (executor driver) (18/20)
2021-12-08 14:46:50,656 [Executor task launch worker for task 157] INFO [org.apache.spark.executor.Executor] - Finished task 18.0 in stage 13.0 (TID 157). 1097 bytes result sent to driver
2021-12-08 14:46:50,656 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 18.0 in stage 13.0 (TID 157) in 90 ms on localhost (executor driver) (19/20)
2021-12-08 14:46:50,661 [Executor task launch worker for task 158] INFO [org.apache.spark.executor.Executor] - Finished task 19.0 in stage 13.0 (TID 158). 1054 bytes result sent to driver
2021-12-08 14:46:50,661 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 19.0 in stage 13.0 (TID 158) in 85 ms on localhost (executor driver) (20/20)
2021-12-08 14:46:50,661 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 13.0, whose tasks have all completed, from pool 
2021-12-08 14:46:50,661 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 13 (takeSample at PaidPromotionAdjustParameter.scala:71) finished in 0.227 s
2021-12-08 14:46:50,662 [main] INFO [org.apache.spark.scheduler.DAGScheduler] - Job 5 finished: takeSample at PaidPromotionAdjustParameter.scala:71, took 0.230507 s
2021-12-08 14:46:50,664 [main] INFO [PaidPromotionAdjustParameter$] - 小数据集个数：10000
2021-12-08 14:46:50,675 [main] INFO [org.apache.spark.SparkContext] - Starting job: count at PaidPromotionAdjustParameter.scala:80
2021-12-08 14:46:50,675 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 6 (count at PaidPromotionAdjustParameter.scala:80) with 20 output partitions
2021-12-08 14:46:50,676 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 14 (count at PaidPromotionAdjustParameter.scala:80)
2021-12-08 14:46:50,676 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List()
2021-12-08 14:46:50,676 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2021-12-08 14:46:50,676 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 14 (MapPartitionsRDD[14] at map at PaidPromotionAdjustParameter.scala:78), which has no missing parents
2021-12-08 14:46:50,679 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_9 stored as values in memory (estimated size 345.5 KB, free 1990.1 MB)
2021-12-08 14:46:50,681 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_9_piece0 stored as bytes in memory (estimated size 119.3 KB, free 1990.0 MB)
2021-12-08 14:46:50,682 [dispatcher-event-loop-10] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_9_piece0 in memory on qb:62214 (size: 119.3 KB, free: 1990.7 MB)
2021-12-08 14:46:50,682 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 9 from broadcast at DAGScheduler.scala:1039
2021-12-08 14:46:50,682 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 20 missing tasks from ResultStage 14 (MapPartitionsRDD[14] at map at PaidPromotionAdjustParameter.scala:78) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14))
2021-12-08 14:46:50,682 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 14.0 with 20 tasks
2021-12-08 14:46:50,683 [dispatcher-event-loop-4] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 14.0 (TID 159, localhost, executor driver, partition 0, ANY, 7899 bytes)
2021-12-08 14:46:50,683 [dispatcher-event-loop-4] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 14.0 (TID 160, localhost, executor driver, partition 1, ANY, 7899 bytes)
2021-12-08 14:46:50,683 [dispatcher-event-loop-4] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 2.0 in stage 14.0 (TID 161, localhost, executor driver, partition 2, ANY, 7899 bytes)
2021-12-08 14:46:50,683 [dispatcher-event-loop-4] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 3.0 in stage 14.0 (TID 162, localhost, executor driver, partition 3, ANY, 7899 bytes)
2021-12-08 14:46:50,683 [dispatcher-event-loop-4] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 4.0 in stage 14.0 (TID 163, localhost, executor driver, partition 4, ANY, 7899 bytes)
2021-12-08 14:46:50,683 [dispatcher-event-loop-4] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 5.0 in stage 14.0 (TID 164, localhost, executor driver, partition 5, ANY, 7899 bytes)
2021-12-08 14:46:50,683 [dispatcher-event-loop-4] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 6.0 in stage 14.0 (TID 165, localhost, executor driver, partition 6, ANY, 7899 bytes)
2021-12-08 14:46:50,683 [dispatcher-event-loop-4] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 7.0 in stage 14.0 (TID 166, localhost, executor driver, partition 7, ANY, 7899 bytes)
2021-12-08 14:46:50,684 [dispatcher-event-loop-4] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 8.0 in stage 14.0 (TID 167, localhost, executor driver, partition 8, ANY, 7899 bytes)
2021-12-08 14:46:50,684 [dispatcher-event-loop-4] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 9.0 in stage 14.0 (TID 168, localhost, executor driver, partition 9, ANY, 7899 bytes)
2021-12-08 14:46:50,684 [dispatcher-event-loop-4] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 10.0 in stage 14.0 (TID 169, localhost, executor driver, partition 10, ANY, 7899 bytes)
2021-12-08 14:46:50,684 [dispatcher-event-loop-4] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 11.0 in stage 14.0 (TID 170, localhost, executor driver, partition 11, ANY, 7899 bytes)
2021-12-08 14:46:50,684 [Executor task launch worker for task 159] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 14.0 (TID 159)
2021-12-08 14:46:50,684 [Executor task launch worker for task 162] INFO [org.apache.spark.executor.Executor] - Running task 3.0 in stage 14.0 (TID 162)
2021-12-08 14:46:50,684 [Executor task launch worker for task 166] INFO [org.apache.spark.executor.Executor] - Running task 7.0 in stage 14.0 (TID 166)
2021-12-08 14:46:50,684 [Executor task launch worker for task 168] INFO [org.apache.spark.executor.Executor] - Running task 9.0 in stage 14.0 (TID 168)
2021-12-08 14:46:50,684 [Executor task launch worker for task 169] INFO [org.apache.spark.executor.Executor] - Running task 10.0 in stage 14.0 (TID 169)
2021-12-08 14:46:50,684 [Executor task launch worker for task 170] INFO [org.apache.spark.executor.Executor] - Running task 11.0 in stage 14.0 (TID 170)
2021-12-08 14:46:50,684 [Executor task launch worker for task 167] INFO [org.apache.spark.executor.Executor] - Running task 8.0 in stage 14.0 (TID 167)
2021-12-08 14:46:50,684 [Executor task launch worker for task 165] INFO [org.apache.spark.executor.Executor] - Running task 6.0 in stage 14.0 (TID 165)
2021-12-08 14:46:50,684 [Executor task launch worker for task 160] INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 14.0 (TID 160)
2021-12-08 14:46:50,684 [Executor task launch worker for task 161] INFO [org.apache.spark.executor.Executor] - Running task 2.0 in stage 14.0 (TID 161)
2021-12-08 14:46:50,684 [Executor task launch worker for task 163] INFO [org.apache.spark.executor.Executor] - Running task 4.0 in stage 14.0 (TID 163)
2021-12-08 14:46:50,684 [Executor task launch worker for task 164] INFO [org.apache.spark.executor.Executor] - Running task 5.0 in stage 14.0 (TID 164)
2021-12-08 14:46:50,690 [Executor task launch worker for task 169] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:1342177280+134217728
2021-12-08 14:46:50,690 [Executor task launch worker for task 164] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:671088640+134217728
2021-12-08 14:46:50,690 [Executor task launch worker for task 161] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:268435456+134217728
2021-12-08 14:46:50,690 [Executor task launch worker for task 163] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:536870912+134217728
2021-12-08 14:46:50,690 [Executor task launch worker for task 159] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:0+134217728
2021-12-08 14:46:50,690 [Executor task launch worker for task 170] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:1476395008+134217728
2021-12-08 14:46:50,690 [Executor task launch worker for task 166] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:939524096+134217728
2021-12-08 14:46:50,690 [Executor task launch worker for task 160] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:134217728+134217728
2021-12-08 14:46:50,692 [Executor task launch worker for task 162] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:402653184+134217728
2021-12-08 14:46:50,695 [Executor task launch worker for task 167] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:1073741824+134217728
2021-12-08 14:46:50,696 [Executor task launch worker for task 165] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:805306368+134217728
2021-12-08 14:46:50,696 [Executor task launch worker for task 168] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:1207959552+134217728
2021-12-08 14:55:50,120 [Executor task launch worker for task 165] INFO [org.apache.spark.executor.Executor] - Finished task 6.0 in stage 14.0 (TID 165). 797 bytes result sent to driver
2021-12-08 14:55:50,121 [dispatcher-event-loop-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 12.0 in stage 14.0 (TID 171, localhost, executor driver, partition 12, ANY, 7899 bytes)
2021-12-08 14:55:50,121 [Executor task launch worker for task 171] INFO [org.apache.spark.executor.Executor] - Running task 12.0 in stage 14.0 (TID 171)
2021-12-08 14:55:50,121 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 6.0 in stage 14.0 (TID 165) in 539438 ms on localhost (executor driver) (1/20)
2021-12-08 14:55:50,126 [Executor task launch worker for task 171] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:1610612736+134217728
2021-12-08 14:55:55,545 [Executor task launch worker for task 163] INFO [org.apache.spark.executor.Executor] - Finished task 4.0 in stage 14.0 (TID 163). 754 bytes result sent to driver
2021-12-08 14:55:55,545 [dispatcher-event-loop-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 13.0 in stage 14.0 (TID 172, localhost, executor driver, partition 13, ANY, 7899 bytes)
2021-12-08 14:55:55,545 [Executor task launch worker for task 172] INFO [org.apache.spark.executor.Executor] - Running task 13.0 in stage 14.0 (TID 172)
2021-12-08 14:55:55,549 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 4.0 in stage 14.0 (TID 163) in 544866 ms on localhost (executor driver) (2/20)
2021-12-08 14:55:55,550 [Executor task launch worker for task 172] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:1744830464+134217728
2021-12-08 14:55:59,879 [Executor task launch worker for task 162] INFO [org.apache.spark.executor.Executor] - Finished task 3.0 in stage 14.0 (TID 162). 754 bytes result sent to driver
2021-12-08 14:55:59,884 [dispatcher-event-loop-6] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 14.0 in stage 14.0 (TID 173, localhost, executor driver, partition 14, ANY, 7899 bytes)
2021-12-08 14:55:59,884 [Executor task launch worker for task 173] INFO [org.apache.spark.executor.Executor] - Running task 14.0 in stage 14.0 (TID 173)
2021-12-08 14:55:59,884 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 3.0 in stage 14.0 (TID 162) in 549201 ms on localhost (executor driver) (3/20)
2021-12-08 14:55:59,889 [Executor task launch worker for task 173] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:1879048192+134217728
2021-12-08 14:56:30,148 [Executor task launch worker for task 168] INFO [org.apache.spark.executor.Executor] - Finished task 9.0 in stage 14.0 (TID 168). 797 bytes result sent to driver
2021-12-08 14:56:30,149 [dispatcher-event-loop-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 15.0 in stage 14.0 (TID 174, localhost, executor driver, partition 15, ANY, 7899 bytes)
2021-12-08 14:56:30,149 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 9.0 in stage 14.0 (TID 168) in 579465 ms on localhost (executor driver) (4/20)
2021-12-08 14:56:30,149 [Executor task launch worker for task 174] INFO [org.apache.spark.executor.Executor] - Running task 15.0 in stage 14.0 (TID 174)
2021-12-08 14:56:30,154 [Executor task launch worker for task 174] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:2013265920+134217728
2021-12-08 14:56:42,309 [Executor task launch worker for task 164] INFO [org.apache.spark.executor.Executor] - Finished task 5.0 in stage 14.0 (TID 164). 754 bytes result sent to driver
2021-12-08 14:56:42,312 [dispatcher-event-loop-6] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 16.0 in stage 14.0 (TID 175, localhost, executor driver, partition 16, ANY, 7899 bytes)
2021-12-08 14:56:42,312 [Executor task launch worker for task 175] INFO [org.apache.spark.executor.Executor] - Running task 16.0 in stage 14.0 (TID 175)
2021-12-08 14:56:42,316 [Executor task launch worker for task 175] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:2147483648+134217728
2021-12-08 14:56:42,318 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 5.0 in stage 14.0 (TID 164) in 591635 ms on localhost (executor driver) (5/20)
2021-12-08 14:56:42,343 [Executor task launch worker for task 170] INFO [org.apache.spark.executor.Executor] - Finished task 11.0 in stage 14.0 (TID 170). 754 bytes result sent to driver
2021-12-08 14:56:42,344 [dispatcher-event-loop-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 17.0 in stage 14.0 (TID 176, localhost, executor driver, partition 17, ANY, 7899 bytes)
2021-12-08 14:56:42,344 [Executor task launch worker for task 176] INFO [org.apache.spark.executor.Executor] - Running task 17.0 in stage 14.0 (TID 176)
2021-12-08 14:56:42,346 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 11.0 in stage 14.0 (TID 170) in 591662 ms on localhost (executor driver) (6/20)
2021-12-08 14:56:42,348 [Executor task launch worker for task 176] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:2281701376+134217728
2021-12-08 14:56:43,117 [Executor task launch worker for task 166] INFO [org.apache.spark.executor.Executor] - Finished task 7.0 in stage 14.0 (TID 166). 754 bytes result sent to driver
2021-12-08 14:56:43,117 [dispatcher-event-loop-8] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 18.0 in stage 14.0 (TID 177, localhost, executor driver, partition 18, ANY, 7899 bytes)
2021-12-08 14:56:43,117 [Executor task launch worker for task 177] INFO [org.apache.spark.executor.Executor] - Running task 18.0 in stage 14.0 (TID 177)
2021-12-08 14:56:43,117 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 7.0 in stage 14.0 (TID 166) in 592434 ms on localhost (executor driver) (7/20)
2021-12-08 14:56:43,122 [Executor task launch worker for task 177] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:2415919104+134217728
2021-12-08 14:57:20,471 [Executor task launch worker for task 169] INFO [org.apache.spark.executor.Executor] - Finished task 10.0 in stage 14.0 (TID 169). 754 bytes result sent to driver
2021-12-08 14:57:20,472 [dispatcher-event-loop-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 19.0 in stage 14.0 (TID 178, localhost, executor driver, partition 19, ANY, 7899 bytes)
2021-12-08 14:57:20,472 [Executor task launch worker for task 178] INFO [org.apache.spark.executor.Executor] - Running task 19.0 in stage 14.0 (TID 178)
2021-12-08 14:57:20,476 [Executor task launch worker for task 178] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:2550136832+85027535
2021-12-08 14:57:20,478 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 10.0 in stage 14.0 (TID 169) in 629793 ms on localhost (executor driver) (8/20)
2021-12-08 14:57:28,473 [Executor task launch worker for task 167] INFO [org.apache.spark.executor.Executor] - Finished task 8.0 in stage 14.0 (TID 167). 797 bytes result sent to driver
2021-12-08 14:57:28,476 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 8.0 in stage 14.0 (TID 167) in 637792 ms on localhost (executor driver) (9/20)
2021-12-08 14:57:32,148 [Executor task launch worker for task 160] INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 14.0 (TID 160). 754 bytes result sent to driver
2021-12-08 14:57:32,148 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 14.0 (TID 160) in 641465 ms on localhost (executor driver) (10/20)
2021-12-08 14:57:45,177 [Executor task launch worker for task 161] INFO [org.apache.spark.executor.Executor] - Finished task 2.0 in stage 14.0 (TID 161). 754 bytes result sent to driver
2021-12-08 14:57:45,177 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 2.0 in stage 14.0 (TID 161) in 654494 ms on localhost (executor driver) (11/20)
2021-12-08 14:57:55,149 [Executor task launch worker for task 159] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 14.0 (TID 159). 754 bytes result sent to driver
2021-12-08 14:57:55,150 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 14.0 (TID 159) in 664467 ms on localhost (executor driver) (12/20)
2021-12-08 15:00:46,106 [Executor task launch worker for task 178] INFO [org.apache.spark.executor.Executor] - Finished task 19.0 in stage 14.0 (TID 178). 797 bytes result sent to driver
2021-12-08 15:00:46,107 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 19.0 in stage 14.0 (TID 178) in 205635 ms on localhost (executor driver) (13/20)
2021-12-08 15:01:48,361 [Executor task launch worker for task 172] INFO [org.apache.spark.executor.Executor] - Finished task 13.0 in stage 14.0 (TID 172). 754 bytes result sent to driver
2021-12-08 15:01:48,361 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 13.0 in stage 14.0 (TID 172) in 352816 ms on localhost (executor driver) (14/20)
2021-12-08 15:01:48,777 [Executor task launch worker for task 173] INFO [org.apache.spark.executor.Executor] - Finished task 14.0 in stage 14.0 (TID 173). 754 bytes result sent to driver
2021-12-08 15:01:48,778 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 14.0 in stage 14.0 (TID 173) in 348894 ms on localhost (executor driver) (15/20)
2021-12-08 15:01:49,057 [Executor task launch worker for task 171] INFO [org.apache.spark.executor.Executor] - Finished task 12.0 in stage 14.0 (TID 171). 754 bytes result sent to driver
2021-12-08 15:01:49,058 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 12.0 in stage 14.0 (TID 171) in 358938 ms on localhost (executor driver) (16/20)
2021-12-08 15:02:04,472 [Executor task launch worker for task 174] INFO [org.apache.spark.executor.Executor] - Finished task 15.0 in stage 14.0 (TID 174). 754 bytes result sent to driver
2021-12-08 15:02:04,473 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 15.0 in stage 14.0 (TID 174) in 334325 ms on localhost (executor driver) (17/20)
2021-12-08 15:02:08,501 [Executor task launch worker for task 176] INFO [org.apache.spark.executor.Executor] - Finished task 17.0 in stage 14.0 (TID 176). 754 bytes result sent to driver
2021-12-08 15:02:08,501 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 17.0 in stage 14.0 (TID 176) in 326157 ms on localhost (executor driver) (18/20)
2021-12-08 15:02:11,084 [Executor task launch worker for task 175] INFO [org.apache.spark.executor.Executor] - Finished task 16.0 in stage 14.0 (TID 175). 754 bytes result sent to driver
2021-12-08 15:02:11,084 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 16.0 in stage 14.0 (TID 175) in 328773 ms on localhost (executor driver) (19/20)
2021-12-08 15:02:11,380 [Executor task launch worker for task 177] INFO [org.apache.spark.executor.Executor] - Finished task 18.0 in stage 14.0 (TID 177). 754 bytes result sent to driver
2021-12-08 15:02:11,381 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 18.0 in stage 14.0 (TID 177) in 328264 ms on localhost (executor driver) (20/20)
2021-12-08 15:02:11,381 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 14.0, whose tasks have all completed, from pool 
2021-12-08 15:02:11,381 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 14 (count at PaidPromotionAdjustParameter.scala:80) finished in 920.705 s
2021-12-08 15:02:11,381 [main] INFO [org.apache.spark.scheduler.DAGScheduler] - Job 6 finished: count at PaidPromotionAdjustParameter.scala:80, took 920.706271 s
2021-12-08 15:02:11,381 [main] INFO [PaidPromotionAdjustParameter$] - 抽样总数：869475
2021-12-08 15:02:11,384 [main] INFO [org.apache.spark.SparkContext] - Starting job: count at PaidPromotionAdjustParameter.scala:81
2021-12-08 15:02:11,384 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 7 (count at PaidPromotionAdjustParameter.scala:81) with 20 output partitions
2021-12-08 15:02:11,384 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 15 (count at PaidPromotionAdjustParameter.scala:81)
2021-12-08 15:02:11,384 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List()
2021-12-08 15:02:11,384 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2021-12-08 15:02:11,384 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 15 (MapPartitionsRDD[14] at map at PaidPromotionAdjustParameter.scala:78), which has no missing parents
2021-12-08 15:02:11,388 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_10 stored as values in memory (estimated size 345.5 KB, free 1989.7 MB)
2021-12-08 15:02:11,390 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_10_piece0 stored as bytes in memory (estimated size 119.3 KB, free 1989.5 MB)
2021-12-08 15:02:11,390 [dispatcher-event-loop-2] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_10_piece0 in memory on qb:62214 (size: 119.3 KB, free: 1990.5 MB)
2021-12-08 15:02:11,390 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 10 from broadcast at DAGScheduler.scala:1039
2021-12-08 15:02:11,391 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 20 missing tasks from ResultStage 15 (MapPartitionsRDD[14] at map at PaidPromotionAdjustParameter.scala:78) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14))
2021-12-08 15:02:11,391 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 15.0 with 20 tasks
2021-12-08 15:02:11,391 [dispatcher-event-loop-11] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 15.0 (TID 179, localhost, executor driver, partition 0, ANY, 7899 bytes)
2021-12-08 15:02:11,391 [dispatcher-event-loop-11] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 15.0 (TID 180, localhost, executor driver, partition 1, ANY, 7899 bytes)
2021-12-08 15:02:11,391 [dispatcher-event-loop-11] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 2.0 in stage 15.0 (TID 181, localhost, executor driver, partition 2, ANY, 7899 bytes)
2021-12-08 15:02:11,391 [dispatcher-event-loop-11] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 3.0 in stage 15.0 (TID 182, localhost, executor driver, partition 3, ANY, 7899 bytes)
2021-12-08 15:02:11,391 [dispatcher-event-loop-11] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 4.0 in stage 15.0 (TID 183, localhost, executor driver, partition 4, ANY, 7899 bytes)
2021-12-08 15:02:11,392 [dispatcher-event-loop-11] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 5.0 in stage 15.0 (TID 184, localhost, executor driver, partition 5, ANY, 7899 bytes)
2021-12-08 15:02:11,392 [dispatcher-event-loop-11] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 6.0 in stage 15.0 (TID 185, localhost, executor driver, partition 6, ANY, 7899 bytes)
2021-12-08 15:02:11,392 [dispatcher-event-loop-11] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 7.0 in stage 15.0 (TID 186, localhost, executor driver, partition 7, ANY, 7899 bytes)
2021-12-08 15:02:11,392 [dispatcher-event-loop-11] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 8.0 in stage 15.0 (TID 187, localhost, executor driver, partition 8, ANY, 7899 bytes)
2021-12-08 15:02:11,392 [dispatcher-event-loop-11] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 9.0 in stage 15.0 (TID 188, localhost, executor driver, partition 9, ANY, 7899 bytes)
2021-12-08 15:02:11,392 [dispatcher-event-loop-11] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 10.0 in stage 15.0 (TID 189, localhost, executor driver, partition 10, ANY, 7899 bytes)
2021-12-08 15:02:11,392 [dispatcher-event-loop-11] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 11.0 in stage 15.0 (TID 190, localhost, executor driver, partition 11, ANY, 7899 bytes)
2021-12-08 15:02:11,392 [Executor task launch worker for task 181] INFO [org.apache.spark.executor.Executor] - Running task 2.0 in stage 15.0 (TID 181)
2021-12-08 15:02:11,392 [Executor task launch worker for task 182] INFO [org.apache.spark.executor.Executor] - Running task 3.0 in stage 15.0 (TID 182)
2021-12-08 15:02:11,392 [Executor task launch worker for task 185] INFO [org.apache.spark.executor.Executor] - Running task 6.0 in stage 15.0 (TID 185)
2021-12-08 15:02:11,392 [Executor task launch worker for task 184] INFO [org.apache.spark.executor.Executor] - Running task 5.0 in stage 15.0 (TID 184)
2021-12-08 15:02:11,392 [Executor task launch worker for task 179] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 15.0 (TID 179)
2021-12-08 15:02:11,392 [Executor task launch worker for task 183] INFO [org.apache.spark.executor.Executor] - Running task 4.0 in stage 15.0 (TID 183)
2021-12-08 15:02:11,392 [Executor task launch worker for task 180] INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 15.0 (TID 180)
2021-12-08 15:02:11,393 [Executor task launch worker for task 186] INFO [org.apache.spark.executor.Executor] - Running task 7.0 in stage 15.0 (TID 186)
2021-12-08 15:02:11,393 [Executor task launch worker for task 188] INFO [org.apache.spark.executor.Executor] - Running task 9.0 in stage 15.0 (TID 188)
2021-12-08 15:02:11,393 [Executor task launch worker for task 189] INFO [org.apache.spark.executor.Executor] - Running task 10.0 in stage 15.0 (TID 189)
2021-12-08 15:02:11,393 [Executor task launch worker for task 187] INFO [org.apache.spark.executor.Executor] - Running task 8.0 in stage 15.0 (TID 187)
2021-12-08 15:02:11,394 [Executor task launch worker for task 190] INFO [org.apache.spark.executor.Executor] - Running task 11.0 in stage 15.0 (TID 190)
2021-12-08 15:02:11,397 [Executor task launch worker for task 186] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:939524096+134217728
2021-12-08 15:02:11,397 [Executor task launch worker for task 189] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:1342177280+134217728
2021-12-08 15:02:11,397 [Executor task launch worker for task 184] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:671088640+134217728
2021-12-08 15:02:11,398 [Executor task launch worker for task 180] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:134217728+134217728
2021-12-08 15:02:11,398 [Executor task launch worker for task 179] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:0+134217728
2021-12-08 15:02:11,398 [Executor task launch worker for task 182] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:402653184+134217728
2021-12-08 15:02:11,398 [Executor task launch worker for task 187] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:1073741824+134217728
2021-12-08 15:02:11,398 [Executor task launch worker for task 190] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:1476395008+134217728
2021-12-08 15:02:11,399 [Executor task launch worker for task 188] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:1207959552+134217728
2021-12-08 15:02:11,401 [Executor task launch worker for task 183] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:536870912+134217728
2021-12-08 15:02:11,402 [Executor task launch worker for task 181] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:268435456+134217728
2021-12-08 15:02:11,402 [Executor task launch worker for task 185] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:805306368+134217728
2021-12-08 15:07:51,137 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 197
2021-12-08 15:07:51,137 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 161
2021-12-08 15:07:51,137 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 198
2021-12-08 15:07:51,137 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 165
2021-12-08 15:07:51,137 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 187
2021-12-08 15:07:51,137 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 169
2021-12-08 15:07:51,137 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 159
2021-12-08 15:07:51,137 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 215
2021-12-08 15:07:51,137 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 212
2021-12-08 15:07:51,137 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 178
2021-12-08 15:07:51,137 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 188
2021-12-08 15:07:51,137 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 191
2021-12-08 15:07:51,137 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 208
2021-12-08 15:07:51,137 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 184
2021-12-08 15:07:51,137 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 183
2021-12-08 15:07:51,137 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 203
2021-12-08 15:07:51,137 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 173
2021-12-08 15:07:51,137 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 204
2021-12-08 15:07:51,137 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 206
2021-12-08 15:07:51,137 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 189
2021-12-08 15:07:51,137 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 222
2021-12-08 15:07:51,137 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 160
2021-12-08 15:07:51,137 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 162
2021-12-08 15:07:51,137 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 217
2021-12-08 15:07:51,137 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 210
2021-12-08 15:07:51,137 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 174
2021-12-08 15:07:51,137 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 152
2021-12-08 15:07:51,137 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 220
2021-12-08 15:07:51,137 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 190
2021-12-08 15:07:51,137 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 164
2021-12-08 15:07:51,137 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 193
2021-12-08 15:07:51,137 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 223
2021-12-08 15:07:51,137 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 166
2021-12-08 15:07:51,138 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 154
2021-12-08 15:07:51,238 [dispatcher-event-loop-0] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_9_piece0 on qb:62214 in memory (size: 119.3 KB, free: 1990.7 MB)
2021-12-08 15:07:51,271 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 202
2021-12-08 15:07:51,271 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 150
2021-12-08 15:07:51,271 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 209
2021-12-08 15:07:51,271 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 180
2021-12-08 15:07:51,271 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 157
2021-12-08 15:07:51,271 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 185
2021-12-08 15:07:51,271 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 151
2021-12-08 15:07:51,271 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 201
2021-12-08 15:07:51,271 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 163
2021-12-08 15:07:51,271 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 196
2021-12-08 15:07:51,271 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 205
2021-12-08 15:07:51,271 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 167
2021-12-08 15:07:51,271 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 171
2021-12-08 15:07:51,271 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 192
2021-12-08 15:07:51,272 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 213
2021-12-08 15:07:51,272 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 156
2021-12-08 15:07:51,272 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 153
2021-12-08 15:07:51,272 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 172
2021-12-08 15:07:51,272 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 182
2021-12-08 15:07:51,272 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 181
2021-12-08 15:07:51,272 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 170
2021-12-08 15:07:51,272 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 177
2021-12-08 15:07:51,272 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 224
2021-12-08 15:07:51,272 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 194
2021-12-08 15:07:51,272 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 179
2021-12-08 15:07:51,272 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 216
2021-12-08 15:07:51,273 [dispatcher-event-loop-11] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_7_piece0 on qb:62214 in memory (size: 2.4 KB, free: 1990.7 MB)
2021-12-08 15:07:51,273 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 218
2021-12-08 15:07:51,274 [dispatcher-event-loop-2] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_8_piece0 on qb:62214 in memory (size: 2.8 KB, free: 1990.7 MB)
2021-12-08 15:07:51,274 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 176
2021-12-08 15:07:51,274 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 175
2021-12-08 15:07:51,274 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 199
2021-12-08 15:07:51,274 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 214
2021-12-08 15:07:51,274 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 155
2021-12-08 15:07:51,274 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 186
2021-12-08 15:07:51,274 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 207
2021-12-08 15:07:51,274 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 211
2021-12-08 15:07:51,274 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 158
2021-12-08 15:07:51,274 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 195
2021-12-08 15:07:51,274 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 168
2021-12-08 15:07:51,274 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 221
2021-12-08 15:07:51,274 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 200
2021-12-08 15:07:51,274 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 219
2021-12-08 15:11:53,430 [Executor task launch worker for task 185] INFO [org.apache.spark.executor.Executor] - Finished task 6.0 in stage 15.0 (TID 185). 754 bytes result sent to driver
2021-12-08 15:11:53,431 [dispatcher-event-loop-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 12.0 in stage 15.0 (TID 191, localhost, executor driver, partition 12, ANY, 7899 bytes)
2021-12-08 15:11:53,431 [Executor task launch worker for task 191] INFO [org.apache.spark.executor.Executor] - Running task 12.0 in stage 15.0 (TID 191)
2021-12-08 15:11:53,431 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 6.0 in stage 15.0 (TID 185) in 582039 ms on localhost (executor driver) (1/20)
2021-12-08 15:11:53,435 [Executor task launch worker for task 191] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:1610612736+134217728
2021-12-08 15:11:56,004 [Executor task launch worker for task 182] INFO [org.apache.spark.executor.Executor] - Finished task 3.0 in stage 15.0 (TID 182). 797 bytes result sent to driver
2021-12-08 15:11:56,005 [dispatcher-event-loop-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 13.0 in stage 15.0 (TID 192, localhost, executor driver, partition 13, ANY, 7899 bytes)
2021-12-08 15:11:56,005 [Executor task launch worker for task 192] INFO [org.apache.spark.executor.Executor] - Running task 13.0 in stage 15.0 (TID 192)
2021-12-08 15:11:56,009 [Executor task launch worker for task 192] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:1744830464+134217728
2021-12-08 15:11:56,010 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 3.0 in stage 15.0 (TID 182) in 584619 ms on localhost (executor driver) (2/20)
2021-12-08 15:11:57,988 [Executor task launch worker for task 183] INFO [org.apache.spark.executor.Executor] - Finished task 4.0 in stage 15.0 (TID 183). 797 bytes result sent to driver
2021-12-08 15:11:57,996 [dispatcher-event-loop-10] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 14.0 in stage 15.0 (TID 193, localhost, executor driver, partition 14, ANY, 7899 bytes)
2021-12-08 15:11:57,997 [Executor task launch worker for task 193] INFO [org.apache.spark.executor.Executor] - Running task 14.0 in stage 15.0 (TID 193)
2021-12-08 15:11:58,001 [Executor task launch worker for task 193] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:1879048192+134217728
2021-12-08 15:11:58,002 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 4.0 in stage 15.0 (TID 183) in 586611 ms on localhost (executor driver) (3/20)
2021-12-08 15:12:00,393 [Executor task launch worker for task 187] INFO [org.apache.spark.executor.Executor] - Finished task 8.0 in stage 15.0 (TID 187). 797 bytes result sent to driver
2021-12-08 15:12:00,393 [dispatcher-event-loop-9] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 15.0 in stage 15.0 (TID 194, localhost, executor driver, partition 15, ANY, 7899 bytes)
2021-12-08 15:12:00,393 [Executor task launch worker for task 194] INFO [org.apache.spark.executor.Executor] - Running task 15.0 in stage 15.0 (TID 194)
2021-12-08 15:12:00,394 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 8.0 in stage 15.0 (TID 187) in 589002 ms on localhost (executor driver) (4/20)
2021-12-08 15:12:00,398 [Executor task launch worker for task 194] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:2013265920+134217728
2021-12-08 15:12:04,599 [Executor task launch worker for task 181] INFO [org.apache.spark.executor.Executor] - Finished task 2.0 in stage 15.0 (TID 181). 754 bytes result sent to driver
2021-12-08 15:12:04,599 [dispatcher-event-loop-6] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 16.0 in stage 15.0 (TID 195, localhost, executor driver, partition 16, ANY, 7899 bytes)
2021-12-08 15:12:04,599 [Executor task launch worker for task 195] INFO [org.apache.spark.executor.Executor] - Running task 16.0 in stage 15.0 (TID 195)
2021-12-08 15:12:04,600 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 2.0 in stage 15.0 (TID 181) in 593209 ms on localhost (executor driver) (5/20)
2021-12-08 15:12:04,603 [Executor task launch worker for task 195] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:2147483648+134217728
2021-12-08 15:12:08,998 [Executor task launch worker for task 189] INFO [org.apache.spark.executor.Executor] - Finished task 10.0 in stage 15.0 (TID 189). 797 bytes result sent to driver
2021-12-08 15:12:08,999 [dispatcher-event-loop-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 17.0 in stage 15.0 (TID 196, localhost, executor driver, partition 17, ANY, 7899 bytes)
2021-12-08 15:12:09,000 [Executor task launch worker for task 196] INFO [org.apache.spark.executor.Executor] - Running task 17.0 in stage 15.0 (TID 196)
2021-12-08 15:12:09,000 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 10.0 in stage 15.0 (TID 189) in 597608 ms on localhost (executor driver) (6/20)
2021-12-08 15:12:09,004 [Executor task launch worker for task 196] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:2281701376+134217728
2021-12-08 15:12:51,645 [Executor task launch worker for task 180] INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 15.0 (TID 180). 797 bytes result sent to driver
2021-12-08 15:12:51,645 [dispatcher-event-loop-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 18.0 in stage 15.0 (TID 197, localhost, executor driver, partition 18, ANY, 7899 bytes)
2021-12-08 15:12:51,645 [Executor task launch worker for task 197] INFO [org.apache.spark.executor.Executor] - Running task 18.0 in stage 15.0 (TID 197)
2021-12-08 15:12:51,649 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 15.0 (TID 180) in 640258 ms on localhost (executor driver) (7/20)
2021-12-08 15:12:51,650 [Executor task launch worker for task 197] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:2415919104+134217728
2021-12-08 15:12:57,141 [Executor task launch worker for task 188] INFO [org.apache.spark.executor.Executor] - Finished task 9.0 in stage 15.0 (TID 188). 797 bytes result sent to driver
2021-12-08 15:12:57,143 [dispatcher-event-loop-8] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 19.0 in stage 15.0 (TID 198, localhost, executor driver, partition 19, ANY, 7899 bytes)
2021-12-08 15:12:57,143 [Executor task launch worker for task 198] INFO [org.apache.spark.executor.Executor] - Running task 19.0 in stage 15.0 (TID 198)
2021-12-08 15:12:57,143 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 9.0 in stage 15.0 (TID 188) in 645751 ms on localhost (executor driver) (8/20)
2021-12-08 15:12:57,146 [Executor task launch worker for task 198] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:2550136832+85027535
2021-12-08 15:13:02,351 [Executor task launch worker for task 190] INFO [org.apache.spark.executor.Executor] - Finished task 11.0 in stage 15.0 (TID 190). 797 bytes result sent to driver
2021-12-08 15:13:02,363 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 11.0 in stage 15.0 (TID 190) in 650971 ms on localhost (executor driver) (9/20)
2021-12-08 15:13:18,454 [Executor task launch worker for task 179] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 15.0 (TID 179). 797 bytes result sent to driver
2021-12-08 15:13:18,454 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 15.0 (TID 179) in 667063 ms on localhost (executor driver) (10/20)
2021-12-08 15:13:24,542 [Executor task launch worker for task 184] INFO [org.apache.spark.executor.Executor] - Finished task 5.0 in stage 15.0 (TID 184). 840 bytes result sent to driver
2021-12-08 15:13:24,542 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 5.0 in stage 15.0 (TID 184) in 673151 ms on localhost (executor driver) (11/20)
2021-12-08 15:13:27,663 [Executor task launch worker for task 186] INFO [org.apache.spark.executor.Executor] - Finished task 7.0 in stage 15.0 (TID 186). 797 bytes result sent to driver
2021-12-08 15:13:27,663 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 7.0 in stage 15.0 (TID 186) in 676271 ms on localhost (executor driver) (12/20)
2021-12-08 15:16:25,065 [Executor task launch worker for task 198] INFO [org.apache.spark.executor.Executor] - Finished task 19.0 in stage 15.0 (TID 198). 797 bytes result sent to driver
2021-12-08 15:16:25,065 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 19.0 in stage 15.0 (TID 198) in 207922 ms on localhost (executor driver) (13/20)
2021-12-08 15:17:37,346 [Executor task launch worker for task 192] INFO [org.apache.spark.executor.Executor] - Finished task 13.0 in stage 15.0 (TID 192). 754 bytes result sent to driver
2021-12-08 15:17:37,346 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 13.0 in stage 15.0 (TID 192) in 341342 ms on localhost (executor driver) (14/20)
2021-12-08 15:17:37,410 [Executor task launch worker for task 193] INFO [org.apache.spark.executor.Executor] - Finished task 14.0 in stage 15.0 (TID 193). 754 bytes result sent to driver
2021-12-08 15:17:37,410 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 14.0 in stage 15.0 (TID 193) in 339414 ms on localhost (executor driver) (15/20)
2021-12-08 15:17:39,692 [Executor task launch worker for task 191] INFO [org.apache.spark.executor.Executor] - Finished task 12.0 in stage 15.0 (TID 191). 754 bytes result sent to driver
2021-12-08 15:17:39,692 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 12.0 in stage 15.0 (TID 191) in 346261 ms on localhost (executor driver) (16/20)
2021-12-08 15:17:42,164 [Executor task launch worker for task 195] INFO [org.apache.spark.executor.Executor] - Finished task 16.0 in stage 15.0 (TID 195). 797 bytes result sent to driver
2021-12-08 15:17:42,164 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 16.0 in stage 15.0 (TID 195) in 337565 ms on localhost (executor driver) (17/20)
2021-12-08 15:17:42,404 [Executor task launch worker for task 194] INFO [org.apache.spark.executor.Executor] - Finished task 15.0 in stage 15.0 (TID 194). 840 bytes result sent to driver
2021-12-08 15:17:42,404 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 15.0 in stage 15.0 (TID 194) in 342011 ms on localhost (executor driver) (18/20)
2021-12-08 15:17:43,127 [Executor task launch worker for task 196] INFO [org.apache.spark.executor.Executor] - Finished task 17.0 in stage 15.0 (TID 196). 754 bytes result sent to driver
2021-12-08 15:17:43,127 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 17.0 in stage 15.0 (TID 196) in 334128 ms on localhost (executor driver) (19/20)
2021-12-08 15:17:58,393 [Executor task launch worker for task 197] INFO [org.apache.spark.executor.Executor] - Finished task 18.0 in stage 15.0 (TID 197). 797 bytes result sent to driver
2021-12-08 15:17:58,393 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 18.0 in stage 15.0 (TID 197) in 306748 ms on localhost (executor driver) (20/20)
2021-12-08 15:17:58,393 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 15.0, whose tasks have all completed, from pool 
2021-12-08 15:17:58,393 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 15 (count at PaidPromotionAdjustParameter.scala:81) finished in 947.008 s
2021-12-08 15:17:58,394 [main] INFO [org.apache.spark.scheduler.DAGScheduler] - Job 7 finished: count at PaidPromotionAdjustParameter.scala:81, took 947.009426 s
2021-12-08 15:17:58,409 [main] INFO [org.apache.hadoop.conf.Configuration.deprecation] - mapred.output.dir is deprecated. Instead, use mapreduce.output.fileoutputformat.outputdir
2021-12-08 15:17:58,411 [main] INFO [org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter] - File Output Committer Algorithm version is 1
2021-12-08 15:17:58,461 [main] INFO [org.apache.spark.SparkContext] - Starting job: runJob at SparkHadoopWriter.scala:78
2021-12-08 15:17:58,461 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 8 (runJob at SparkHadoopWriter.scala:78) with 6 output partitions
2021-12-08 15:17:58,462 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 16 (runJob at SparkHadoopWriter.scala:78)
2021-12-08 15:17:58,462 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List()
2021-12-08 15:17:58,462 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2021-12-08 15:17:58,462 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 16 (MapPartitionsRDD[16] at saveAsTextFile at PaidPromotionAdjustParameter.scala:83), which has no missing parents
2021-12-08 15:17:58,474 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_11 stored as values in memory (estimated size 421.9 KB, free 1989.6 MB)
2021-12-08 15:17:58,476 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_11_piece0 stored as bytes in memory (estimated size 148.1 KB, free 1989.5 MB)
2021-12-08 15:17:58,476 [dispatcher-event-loop-1] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_11_piece0 in memory on qb:62214 (size: 148.1 KB, free: 1990.5 MB)
2021-12-08 15:17:58,477 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 11 from broadcast at DAGScheduler.scala:1039
2021-12-08 15:17:58,477 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 6 missing tasks from ResultStage 16 (MapPartitionsRDD[16] at saveAsTextFile at PaidPromotionAdjustParameter.scala:83) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5))
2021-12-08 15:17:58,477 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 16.0 with 6 tasks
2021-12-08 15:17:58,483 [dispatcher-event-loop-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 16.0 (TID 199, localhost, executor driver, partition 0, ANY, 8343 bytes)
2021-12-08 15:17:58,483 [dispatcher-event-loop-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 16.0 (TID 200, localhost, executor driver, partition 1, ANY, 8679 bytes)
2021-12-08 15:17:58,483 [dispatcher-event-loop-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 2.0 in stage 16.0 (TID 201, localhost, executor driver, partition 2, ANY, 8679 bytes)
2021-12-08 15:17:58,483 [dispatcher-event-loop-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 3.0 in stage 16.0 (TID 202, localhost, executor driver, partition 3, ANY, 8679 bytes)
2021-12-08 15:17:58,483 [dispatcher-event-loop-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 4.0 in stage 16.0 (TID 203, localhost, executor driver, partition 4, ANY, 8343 bytes)
2021-12-08 15:17:58,483 [dispatcher-event-loop-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 5.0 in stage 16.0 (TID 204, localhost, executor driver, partition 5, ANY, 8679 bytes)
2021-12-08 15:17:58,484 [Executor task launch worker for task 200] INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 16.0 (TID 200)
2021-12-08 15:17:58,484 [Executor task launch worker for task 202] INFO [org.apache.spark.executor.Executor] - Running task 3.0 in stage 16.0 (TID 202)
2021-12-08 15:17:58,484 [Executor task launch worker for task 201] INFO [org.apache.spark.executor.Executor] - Running task 2.0 in stage 16.0 (TID 201)
2021-12-08 15:17:58,484 [Executor task launch worker for task 203] INFO [org.apache.spark.executor.Executor] - Running task 4.0 in stage 16.0 (TID 203)
2021-12-08 15:17:58,484 [Executor task launch worker for task 204] INFO [org.apache.spark.executor.Executor] - Running task 5.0 in stage 16.0 (TID 204)
2021-12-08 15:17:58,484 [Executor task launch worker for task 199] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 16.0 (TID 199)
2021-12-08 15:17:58,502 [Executor task launch worker for task 202] INFO [org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter] - File Output Committer Algorithm version is 1
2021-12-08 15:17:58,502 [Executor task launch worker for task 200] INFO [org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter] - File Output Committer Algorithm version is 1
2021-12-08 15:17:58,502 [Executor task launch worker for task 199] INFO [org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter] - File Output Committer Algorithm version is 1
2021-12-08 15:17:58,502 [Executor task launch worker for task 201] INFO [org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter] - File Output Committer Algorithm version is 1
2021-12-08 15:17:58,502 [Executor task launch worker for task 203] INFO [org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter] - File Output Committer Algorithm version is 1
2021-12-08 15:17:58,502 [Executor task launch worker for task 204] INFO [org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter] - File Output Committer Algorithm version is 1
2021-12-08 15:17:58,539 [Executor task launch worker for task 204] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:536870912+134217728
2021-12-08 15:17:58,552 [Executor task launch worker for task 203] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:268435456+134217728
2021-12-08 15:17:58,552 [Executor task launch worker for task 202] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:1207959552+134217728
2021-12-08 15:17:58,553 [Executor task launch worker for task 201] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:402653184+134217728
2021-12-08 15:17:58,553 [Executor task launch worker for task 200] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:134217728+134217728
2021-12-08 15:17:58,553 [Executor task launch worker for task 199] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:0+134217728
2021-12-08 15:22:15,711 [Executor task launch worker for task 202] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:1342177280+134217728
2021-12-08 15:22:17,433 [Executor task launch worker for task 200] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:805306368+134217728
2021-12-08 15:22:19,274 [Executor task launch worker for task 201] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:671088640+134217728
2021-12-08 15:22:19,893 [Executor task launch worker for task 203] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:1744830464+134217728
2021-12-08 15:22:21,245 [Executor task launch worker for task 204] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:939524096+134217728
2021-12-08 15:22:22,185 [Executor task launch worker for task 199] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:1073741824+134217728
2021-12-08 15:26:27,426 [Executor task launch worker for task 202] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:1879048192+134217728
2021-12-08 15:26:30,679 [Executor task launch worker for task 200] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:1610612736+134217728
2021-12-08 15:26:34,203 [Executor task launch worker for task 201] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:1476395008+134217728
2021-12-08 15:26:34,888 [Executor task launch worker for task 203] INFO [org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter] - Saved output of task 'attempt_20211208151758_0016_m_000004_0' to hdfs://hdp1:8020/sk/chongqing/handle_data/device_video_data/_temporary/0/task_20211208151758_0016_m_000004
2021-12-08 15:26:34,888 [Executor task launch worker for task 203] INFO [org.apache.spark.mapred.SparkHadoopMapRedUtil] - attempt_20211208151758_0016_m_000004_0: Committed
2021-12-08 15:26:34,890 [Executor task launch worker for task 203] INFO [org.apache.spark.executor.Executor] - Finished task 4.0 in stage 16.0 (TID 203). 1041 bytes result sent to driver
2021-12-08 15:26:34,892 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 4.0 in stage 16.0 (TID 203) in 516409 ms on localhost (executor driver) (1/6)
2021-12-08 15:26:36,599 [Executor task launch worker for task 204] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:2013265920+134217728
2021-12-08 15:26:39,228 [Executor task launch worker for task 199] INFO [org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter] - Saved output of task 'attempt_20211208151758_0016_m_000000_0' to hdfs://hdp1:8020/sk/chongqing/handle_data/device_video_data/_temporary/0/task_20211208151758_0016_m_000000
2021-12-08 15:26:39,228 [Executor task launch worker for task 199] INFO [org.apache.spark.mapred.SparkHadoopMapRedUtil] - attempt_20211208151758_0016_m_000000_0: Committed
2021-12-08 15:26:39,230 [Executor task launch worker for task 199] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 16.0 (TID 199). 998 bytes result sent to driver
2021-12-08 15:26:39,231 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 16.0 (TID 199) in 520754 ms on localhost (executor driver) (2/6)
2021-12-08 15:30:07,338 [Executor task launch worker for task 202] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:2281701376+134217728
2021-12-08 15:30:11,681 [Executor task launch worker for task 200] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:2147483648+134217728
2021-12-08 15:30:18,157 [Executor task launch worker for task 201] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:2415919104+134217728
2021-12-08 15:30:19,071 [Executor task launch worker for task 204] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/behavior_data.bcp:2550136832+85027535
2021-12-08 15:32:41,309 [Executor task launch worker for task 204] INFO [org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter] - Saved output of task 'attempt_20211208151758_0016_m_000005_0' to hdfs://hdp1:8020/sk/chongqing/handle_data/device_video_data/_temporary/0/task_20211208151758_0016_m_000005
2021-12-08 15:32:41,309 [Executor task launch worker for task 204] INFO [org.apache.spark.mapred.SparkHadoopMapRedUtil] - attempt_20211208151758_0016_m_000005_0: Committed
2021-12-08 15:32:41,310 [Executor task launch worker for task 204] INFO [org.apache.spark.executor.Executor] - Finished task 5.0 in stage 16.0 (TID 204). 998 bytes result sent to driver
2021-12-08 15:32:41,312 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 5.0 in stage 16.0 (TID 204) in 882829 ms on localhost (executor driver) (3/6)
2021-12-08 15:33:43,827 [Executor task launch worker for task 202] INFO [org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter] - Saved output of task 'attempt_20211208151758_0016_m_000003_0' to hdfs://hdp1:8020/sk/chongqing/handle_data/device_video_data/_temporary/0/task_20211208151758_0016_m_000003
2021-12-08 15:33:43,827 [Executor task launch worker for task 202] INFO [org.apache.spark.mapred.SparkHadoopMapRedUtil] - attempt_20211208151758_0016_m_000003_0: Committed
2021-12-08 15:33:43,828 [Executor task launch worker for task 202] INFO [org.apache.spark.executor.Executor] - Finished task 3.0 in stage 16.0 (TID 202). 998 bytes result sent to driver
2021-12-08 15:33:43,829 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 3.0 in stage 16.0 (TID 202) in 945346 ms on localhost (executor driver) (4/6)
2021-12-08 15:33:48,210 [Executor task launch worker for task 200] INFO [org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter] - Saved output of task 'attempt_20211208151758_0016_m_000001_0' to hdfs://hdp1:8020/sk/chongqing/handle_data/device_video_data/_temporary/0/task_20211208151758_0016_m_000001
2021-12-08 15:33:48,210 [Executor task launch worker for task 200] INFO [org.apache.spark.mapred.SparkHadoopMapRedUtil] - attempt_20211208151758_0016_m_000001_0: Committed
2021-12-08 15:33:48,211 [Executor task launch worker for task 200] INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 16.0 (TID 200). 998 bytes result sent to driver
2021-12-08 15:33:48,211 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 16.0 (TID 200) in 949728 ms on localhost (executor driver) (5/6)
2021-12-08 15:33:56,260 [Executor task launch worker for task 201] INFO [org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter] - Saved output of task 'attempt_20211208151758_0016_m_000002_0' to hdfs://hdp1:8020/sk/chongqing/handle_data/device_video_data/_temporary/0/task_20211208151758_0016_m_000002
2021-12-08 15:33:56,260 [Executor task launch worker for task 201] INFO [org.apache.spark.mapred.SparkHadoopMapRedUtil] - attempt_20211208151758_0016_m_000002_0: Committed
2021-12-08 15:33:56,260 [Executor task launch worker for task 201] INFO [org.apache.spark.executor.Executor] - Finished task 2.0 in stage 16.0 (TID 201). 998 bytes result sent to driver
2021-12-08 15:33:56,261 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 2.0 in stage 16.0 (TID 201) in 957778 ms on localhost (executor driver) (6/6)
2021-12-08 15:33:56,261 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 16.0, whose tasks have all completed, from pool 
2021-12-08 15:33:56,261 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 16 (runJob at SparkHadoopWriter.scala:78) finished in 957.799 s
2021-12-08 15:33:56,261 [main] INFO [org.apache.spark.scheduler.DAGScheduler] - Job 8 finished: runJob at SparkHadoopWriter.scala:78, took 957.799671 s
2021-12-08 15:33:56,421 [main] INFO [org.apache.spark.internal.io.SparkHadoopWriter] - Job job_20211208151758_0016 committed.
2021-12-08 15:33:56,426 [main] INFO [org.spark_project.jetty.server.AbstractConnector] - Stopped Spark@5f7f2382{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2021-12-08 15:33:56,427 [main] INFO [org.apache.spark.ui.SparkUI] - Stopped Spark web UI at http://qb:4040
2021-12-08 15:33:56,434 [dispatcher-event-loop-1] INFO [org.apache.spark.MapOutputTrackerMasterEndpoint] - MapOutputTrackerMasterEndpoint stopped!
2021-12-08 15:33:56,512 [main] INFO [org.apache.spark.storage.memory.MemoryStore] - MemoryStore cleared
2021-12-08 15:33:56,512 [main] INFO [org.apache.spark.storage.BlockManager] - BlockManager stopped
2021-12-08 15:33:56,513 [main] INFO [org.apache.spark.storage.BlockManagerMaster] - BlockManagerMaster stopped
2021-12-08 15:33:56,514 [dispatcher-event-loop-4] INFO [org.apache.spark.scheduler.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint] - OutputCommitCoordinator stopped!
2021-12-08 15:33:56,517 [main] INFO [org.apache.spark.SparkContext] - Successfully stopped SparkContext
2021-12-08 15:33:56,519 [Thread-1] INFO [org.apache.spark.util.ShutdownHookManager] - Shutdown hook called
2021-12-08 15:33:56,519 [Thread-1] INFO [org.apache.spark.util.ShutdownHookManager] - Deleting directory C:\Users\ACER\AppData\Local\Temp\spark-1cf30fbf-4676-44a4-9f73-57e89ba9f9aa
2021-12-08 15:53:30,321 [main] INFO [org.apache.spark.SparkContext] - Running Spark version 2.3.0
2021-12-08 15:53:30,593 [main] INFO [org.apache.spark.SparkContext] - Submitted application: PaidPromotionAdjustParameter
2021-12-08 15:53:30,638 [main] INFO [org.apache.spark.SecurityManager] - Changing view acls to: ACER,root
2021-12-08 15:53:30,638 [main] INFO [org.apache.spark.SecurityManager] - Changing modify acls to: ACER,root
2021-12-08 15:53:30,639 [main] INFO [org.apache.spark.SecurityManager] - Changing view acls groups to: 
2021-12-08 15:53:30,639 [main] INFO [org.apache.spark.SecurityManager] - Changing modify acls groups to: 
2021-12-08 15:53:30,639 [main] INFO [org.apache.spark.SecurityManager] - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(ACER, root); groups with view permissions: Set(); users  with modify permissions: Set(ACER, root); groups with modify permissions: Set()
2021-12-08 15:53:31,194 [main] INFO [org.apache.spark.util.Utils] - Successfully started service 'sparkDriver' on port 62896.
2021-12-08 15:53:31,210 [main] INFO [org.apache.spark.SparkEnv] - Registering MapOutputTracker
2021-12-08 15:53:31,224 [main] INFO [org.apache.spark.SparkEnv] - Registering BlockManagerMaster
2021-12-08 15:53:31,226 [main] INFO [org.apache.spark.storage.BlockManagerMasterEndpoint] - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2021-12-08 15:53:31,226 [main] INFO [org.apache.spark.storage.BlockManagerMasterEndpoint] - BlockManagerMasterEndpoint up
2021-12-08 15:53:31,233 [main] INFO [org.apache.spark.storage.DiskBlockManager] - Created local directory at C:\Users\ACER\AppData\Local\Temp\blockmgr-1c0a2f58-ec7d-4292-a8d0-e70c8e72c6a9
2021-12-08 15:53:31,248 [main] INFO [org.apache.spark.storage.memory.MemoryStore] - MemoryStore started with capacity 1990.8 MB
2021-12-08 15:53:31,258 [main] INFO [org.apache.spark.SparkEnv] - Registering OutputCommitCoordinator
2021-12-08 15:53:31,309 [main] INFO [org.spark_project.jetty.util.log] - Logging initialized @1865ms
2021-12-08 15:53:31,366 [main] INFO [org.spark_project.jetty.server.Server] - jetty-9.3.z-SNAPSHOT
2021-12-08 15:53:31,377 [main] INFO [org.spark_project.jetty.server.Server] - Started @1932ms
2021-12-08 15:53:31,401 [main] INFO [org.spark_project.jetty.server.AbstractConnector] - Started ServerConnector@5b800468{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2021-12-08 15:53:31,401 [main] INFO [org.apache.spark.util.Utils] - Successfully started service 'SparkUI' on port 4040.
2021-12-08 15:53:31,420 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@1568159{/jobs,null,AVAILABLE,@Spark}
2021-12-08 15:53:31,421 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@63cd604c{/jobs/json,null,AVAILABLE,@Spark}
2021-12-08 15:53:31,422 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@3954d008{/jobs/job,null,AVAILABLE,@Spark}
2021-12-08 15:53:31,423 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@6d8792db{/jobs/job/json,null,AVAILABLE,@Spark}
2021-12-08 15:53:31,424 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@3a1d593e{/stages,null,AVAILABLE,@Spark}
2021-12-08 15:53:31,425 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@285d851a{/stages/json,null,AVAILABLE,@Spark}
2021-12-08 15:53:31,426 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@7876d598{/stages/stage,null,AVAILABLE,@Spark}
2021-12-08 15:53:31,427 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@4985cbcb{/stages/stage/json,null,AVAILABLE,@Spark}
2021-12-08 15:53:31,429 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@54361a9{/stages/pool,null,AVAILABLE,@Spark}
2021-12-08 15:53:31,430 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@293bb8a5{/stages/pool/json,null,AVAILABLE,@Spark}
2021-12-08 15:53:31,432 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@290b1b2e{/storage,null,AVAILABLE,@Spark}
2021-12-08 15:53:31,433 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@5db4c359{/storage/json,null,AVAILABLE,@Spark}
2021-12-08 15:53:31,434 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@6fefce9e{/storage/rdd,null,AVAILABLE,@Spark}
2021-12-08 15:53:31,435 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@8a589a2{/storage/rdd/json,null,AVAILABLE,@Spark}
2021-12-08 15:53:31,436 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@5cc69cfe{/environment,null,AVAILABLE,@Spark}
2021-12-08 15:53:31,437 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@11dee337{/environment/json,null,AVAILABLE,@Spark}
2021-12-08 15:53:31,438 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@74bdc168{/executors,null,AVAILABLE,@Spark}
2021-12-08 15:53:31,440 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@7bb3a9fe{/executors/json,null,AVAILABLE,@Spark}
2021-12-08 15:53:31,441 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@f19c9d2{/executors/threadDump,null,AVAILABLE,@Spark}
2021-12-08 15:53:31,442 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@a77614d{/executors/threadDump/json,null,AVAILABLE,@Spark}
2021-12-08 15:53:31,449 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@523424b5{/static,null,AVAILABLE,@Spark}
2021-12-08 15:53:31,450 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@12cd9150{/,null,AVAILABLE,@Spark}
2021-12-08 15:53:31,452 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@32fe9d0a{/api,null,AVAILABLE,@Spark}
2021-12-08 15:53:31,453 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@59fc684e{/jobs/job/kill,null,AVAILABLE,@Spark}
2021-12-08 15:53:31,454 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@355e34c7{/stages/stage/kill,null,AVAILABLE,@Spark}
2021-12-08 15:53:31,456 [main] INFO [org.apache.spark.ui.SparkUI] - Bound SparkUI to 0.0.0.0, and started at http://qb:4040
2021-12-08 15:53:31,533 [main] INFO [org.apache.spark.executor.Executor] - Starting executor ID driver on host localhost
2021-12-08 15:53:31,585 [main] INFO [org.apache.spark.util.Utils] - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 62937.
2021-12-08 15:53:31,586 [main] INFO [org.apache.spark.network.netty.NettyBlockTransferService] - Server created on qb:62937
2021-12-08 15:53:31,587 [main] INFO [org.apache.spark.storage.BlockManager] - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2021-12-08 15:53:31,588 [main] INFO [org.apache.spark.storage.BlockManagerMaster] - Registering BlockManager BlockManagerId(driver, qb, 62937, None)
2021-12-08 15:53:31,590 [dispatcher-event-loop-10] INFO [org.apache.spark.storage.BlockManagerMasterEndpoint] - Registering block manager qb:62937 with 1990.8 MB RAM, BlockManagerId(driver, qb, 62937, None)
2021-12-08 15:53:31,592 [main] INFO [org.apache.spark.storage.BlockManagerMaster] - Registered BlockManager BlockManagerId(driver, qb, 62937, None)
2021-12-08 15:53:31,592 [main] INFO [org.apache.spark.storage.BlockManager] - Initialized BlockManager: BlockManagerId(driver, qb, 62937, None)
2021-12-08 15:53:31,715 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@6fe46b62{/metrics/json,null,AVAILABLE,@Spark}
2021-12-08 15:53:32,176 [main] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_0 stored as values in memory (estimated size 312.7 KB, free 1990.5 MB)
2021-12-08 15:53:32,390 [main] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_0_piece0 stored as bytes in memory (estimated size 27.3 KB, free 1990.5 MB)
2021-12-08 15:53:32,391 [dispatcher-event-loop-0] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_0_piece0 in memory on qb:62937 (size: 27.3 KB, free: 1990.8 MB)
2021-12-08 15:53:32,395 [main] INFO [org.apache.spark.SparkContext] - Created broadcast 0 from textFile at PaidPromotionAdjustParameter.scala:236
2021-12-08 15:53:32,443 [main] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_1 stored as values in memory (estimated size 312.7 KB, free 1990.2 MB)
2021-12-08 15:53:32,457 [main] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_1_piece0 stored as bytes in memory (estimated size 27.3 KB, free 1990.1 MB)
2021-12-08 15:53:32,458 [dispatcher-event-loop-1] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_1_piece0 in memory on qb:62937 (size: 27.3 KB, free: 1990.7 MB)
2021-12-08 15:53:32,459 [main] INFO [org.apache.spark.SparkContext] - Created broadcast 1 from textFile at PaidPromotionAdjustParameter.scala:237
2021-12-08 15:53:32,781 [main] WARN [org.apache.hadoop.hdfs.shortcircuit.DomainSocketFactory] - The short-circuit local reads feature cannot be used because UNIX Domain sockets are not available on Windows.
2021-12-08 15:53:32,882 [main] INFO [org.apache.hadoop.mapred.FileInputFormat] - Total input paths to process : 1
2021-12-08 15:53:32,891 [main] INFO [org.apache.spark.SparkContext] - Starting job: count at PaidPromotionAdjustParameter.scala:245
2021-12-08 15:53:32,901 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 0 (count at PaidPromotionAdjustParameter.scala:245) with 2 output partitions
2021-12-08 15:53:32,901 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 0 (count at PaidPromotionAdjustParameter.scala:245)
2021-12-08 15:53:32,901 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List()
2021-12-08 15:53:32,902 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2021-12-08 15:53:32,908 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 0 (MapPartitionsRDD[4] at map at PaidPromotionAdjustParameter.scala:241), which has no missing parents
2021-12-08 15:53:32,941 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_2 stored as values in memory (estimated size 3.3 KB, free 1990.1 MB)
2021-12-08 15:53:32,946 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_2_piece0 stored as bytes in memory (estimated size 1994.0 B, free 1990.1 MB)
2021-12-08 15:53:32,947 [dispatcher-event-loop-2] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_2_piece0 in memory on qb:62937 (size: 1994.0 B, free: 1990.7 MB)
2021-12-08 15:53:32,947 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 2 from broadcast at DAGScheduler.scala:1039
2021-12-08 15:53:32,956 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from ResultStage 0 (MapPartitionsRDD[4] at map at PaidPromotionAdjustParameter.scala:241) (first 15 tasks are for partitions Vector(0, 1))
2021-12-08 15:53:32,957 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 0.0 with 2 tasks
2021-12-08 15:53:32,991 [dispatcher-event-loop-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 0.0 (TID 0, localhost, executor driver, partition 0, ANY, 7932 bytes)
2021-12-08 15:53:32,993 [dispatcher-event-loop-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 0.0 (TID 1, localhost, executor driver, partition 1, ANY, 7932 bytes)
2021-12-08 15:53:32,998 [Executor task launch worker for task 1] INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 0.0 (TID 1)
2021-12-08 15:53:32,998 [Executor task launch worker for task 0] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 0.0 (TID 0)
2021-12-08 15:53:33,039 [Executor task launch worker for task 0] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/handle_data/set-train-device-production-data/part-00000:0+3237750
2021-12-08 15:53:33,039 [Executor task launch worker for task 1] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/handle_data/set-train-device-production-data/part-00000:3237750+3237751
2021-12-08 15:53:33,677 [Executor task launch worker for task 1] INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 0.0 (TID 1). 754 bytes result sent to driver
2021-12-08 15:53:33,677 [Executor task launch worker for task 0] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 0.0 (TID 0). 754 bytes result sent to driver
2021-12-08 15:53:33,686 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 0.0 (TID 1) in 692 ms on localhost (executor driver) (1/2)
2021-12-08 15:53:33,687 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 0.0 (TID 0) in 706 ms on localhost (executor driver) (2/2)
2021-12-08 15:53:33,688 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 0.0, whose tasks have all completed, from pool 
2021-12-08 15:53:33,691 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 0 (count at PaidPromotionAdjustParameter.scala:245) finished in 0.768 s
2021-12-08 15:53:33,694 [main] INFO [org.apache.spark.scheduler.DAGScheduler] - Job 0 finished: count at PaidPromotionAdjustParameter.scala:245, took 0.804566 s
2021-12-08 15:53:33,696 [main] INFO [PaidPromotionAdjustParameter$] - 订购行为训练集个数：101055
2021-12-08 15:53:33,713 [main] INFO [org.apache.spark.SparkContext] - Starting job: zipWithIndex at PaidPromotionAdjustParameter.scala:250
2021-12-08 15:53:33,720 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 6 (distinct at PaidPromotionAdjustParameter.scala:249)
2021-12-08 15:53:33,721 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 1 (zipWithIndex at PaidPromotionAdjustParameter.scala:250) with 2 output partitions
2021-12-08 15:53:33,721 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 2 (zipWithIndex at PaidPromotionAdjustParameter.scala:250)
2021-12-08 15:53:33,721 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 1)
2021-12-08 15:53:33,722 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List(ShuffleMapStage 1)
2021-12-08 15:53:33,722 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ShuffleMapStage 1 (MapPartitionsRDD[6] at distinct at PaidPromotionAdjustParameter.scala:249), which has no missing parents
2021-12-08 15:53:33,730 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_3 stored as values in memory (estimated size 4.9 KB, free 1990.1 MB)
2021-12-08 15:53:33,735 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_3_piece0 stored as bytes in memory (estimated size 2.8 KB, free 1990.1 MB)
2021-12-08 15:53:33,735 [dispatcher-event-loop-8] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_3_piece0 in memory on qb:62937 (size: 2.8 KB, free: 1990.7 MB)
2021-12-08 15:53:33,735 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 3 from broadcast at DAGScheduler.scala:1039
2021-12-08 15:53:33,737 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from ShuffleMapStage 1 (MapPartitionsRDD[6] at distinct at PaidPromotionAdjustParameter.scala:249) (first 15 tasks are for partitions Vector(0, 1))
2021-12-08 15:53:33,737 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 1.0 with 2 tasks
2021-12-08 15:53:33,738 [dispatcher-event-loop-9] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 1.0 (TID 2, localhost, executor driver, partition 0, ANY, 7921 bytes)
2021-12-08 15:53:33,739 [dispatcher-event-loop-9] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 1.0 (TID 3, localhost, executor driver, partition 1, ANY, 7921 bytes)
2021-12-08 15:53:33,739 [Executor task launch worker for task 2] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 1.0 (TID 2)
2021-12-08 15:53:33,739 [Executor task launch worker for task 3] INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 1.0 (TID 3)
2021-12-08 15:53:33,743 [Executor task launch worker for task 3] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/handle_data/set-train-device-production-data/part-00000:3237750+3237751
2021-12-08 15:53:33,743 [Executor task launch worker for task 2] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/handle_data/set-train-device-production-data/part-00000:0+3237750
2021-12-08 15:53:33,963 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 10
2021-12-08 15:53:33,963 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 0
2021-12-08 15:53:33,963 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 24
2021-12-08 15:53:33,963 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 11
2021-12-08 15:53:33,976 [dispatcher-event-loop-2] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_2_piece0 on qb:62937 in memory (size: 1994.0 B, free: 1990.7 MB)
2021-12-08 15:53:33,978 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 8
2021-12-08 15:53:33,978 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 5
2021-12-08 15:53:33,978 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 21
2021-12-08 15:53:33,978 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 13
2021-12-08 15:53:33,978 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 20
2021-12-08 15:53:33,978 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 14
2021-12-08 15:53:33,978 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 7
2021-12-08 15:53:33,978 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 18
2021-12-08 15:53:33,978 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 4
2021-12-08 15:53:33,978 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 23
2021-12-08 15:53:33,978 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 15
2021-12-08 15:53:33,978 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1
2021-12-08 15:53:33,978 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 2
2021-12-08 15:53:33,979 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 3
2021-12-08 15:53:33,979 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 17
2021-12-08 15:53:33,979 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 22
2021-12-08 15:53:33,979 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 6
2021-12-08 15:53:33,979 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 16
2021-12-08 15:53:33,979 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 19
2021-12-08 15:53:33,979 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 12
2021-12-08 15:53:33,979 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 9
2021-12-08 15:53:34,121 [Executor task launch worker for task 3] INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 1.0 (TID 3). 1033 bytes result sent to driver
2021-12-08 15:53:34,136 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 1.0 (TID 3) in 398 ms on localhost (executor driver) (1/2)
2021-12-08 15:53:34,411 [Executor task launch worker for task 2] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 1.0 (TID 2). 1033 bytes result sent to driver
2021-12-08 15:53:34,414 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 1.0 (TID 2) in 676 ms on localhost (executor driver) (2/2)
2021-12-08 15:53:34,414 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 1.0, whose tasks have all completed, from pool 
2021-12-08 15:53:34,414 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ShuffleMapStage 1 (distinct at PaidPromotionAdjustParameter.scala:249) finished in 0.690 s
2021-12-08 15:53:34,415 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - looking for newly runnable stages
2021-12-08 15:53:34,415 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - running: Set()
2021-12-08 15:53:34,415 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - waiting: Set(ResultStage 2)
2021-12-08 15:53:34,416 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - failed: Set()
2021-12-08 15:53:34,418 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 2 (MapPartitionsRDD[8] at distinct at PaidPromotionAdjustParameter.scala:249), which has no missing parents
2021-12-08 15:53:34,422 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_4 stored as values in memory (estimated size 3.7 KB, free 1990.1 MB)
2021-12-08 15:53:34,426 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_4_piece0 stored as bytes in memory (estimated size 2.2 KB, free 1990.1 MB)
2021-12-08 15:53:34,427 [dispatcher-event-loop-4] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_4_piece0 in memory on qb:62937 (size: 2.2 KB, free: 1990.7 MB)
2021-12-08 15:53:34,427 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 4 from broadcast at DAGScheduler.scala:1039
2021-12-08 15:53:34,428 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from ResultStage 2 (MapPartitionsRDD[8] at distinct at PaidPromotionAdjustParameter.scala:249) (first 15 tasks are for partitions Vector(0, 1))
2021-12-08 15:53:34,428 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 2.0 with 2 tasks
2021-12-08 15:53:34,429 [dispatcher-event-loop-7] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 2.0 (TID 4, localhost, executor driver, partition 0, ANY, 7649 bytes)
2021-12-08 15:53:34,429 [dispatcher-event-loop-7] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 2.0 (TID 5, localhost, executor driver, partition 1, ANY, 7649 bytes)
2021-12-08 15:53:34,430 [Executor task launch worker for task 4] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 2.0 (TID 4)
2021-12-08 15:53:34,430 [Executor task launch worker for task 5] INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 2.0 (TID 5)
2021-12-08 15:53:34,442 [Executor task launch worker for task 5] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 2 non-empty blocks out of 2 blocks
2021-12-08 15:53:34,442 [Executor task launch worker for task 4] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 2 non-empty blocks out of 2 blocks
2021-12-08 15:53:34,443 [Executor task launch worker for task 5] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 4 ms
2021-12-08 15:53:34,443 [Executor task launch worker for task 4] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 4 ms
2021-12-08 15:53:34,479 [Executor task launch worker for task 5] INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 2.0 (TID 5). 1053 bytes result sent to driver
2021-12-08 15:53:34,479 [Executor task launch worker for task 4] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 2.0 (TID 4). 1053 bytes result sent to driver
2021-12-08 15:53:34,480 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 2.0 (TID 5) in 50 ms on localhost (executor driver) (1/2)
2021-12-08 15:53:34,480 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 2.0 (TID 4) in 52 ms on localhost (executor driver) (2/2)
2021-12-08 15:53:34,480 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 2.0, whose tasks have all completed, from pool 
2021-12-08 15:53:34,480 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 2 (zipWithIndex at PaidPromotionAdjustParameter.scala:250) finished in 0.060 s
2021-12-08 15:53:34,480 [main] INFO [org.apache.spark.scheduler.DAGScheduler] - Job 1 finished: zipWithIndex at PaidPromotionAdjustParameter.scala:250, took 0.767880 s
2021-12-08 15:53:34,503 [main] INFO [org.apache.spark.SparkContext] - Starting job: take at PaidPromotionAdjustParameter.scala:256
2021-12-08 15:53:34,504 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 10 (map at PaidPromotionAdjustParameter.scala:253)
2021-12-08 15:53:34,504 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 2 (take at PaidPromotionAdjustParameter.scala:256) with 1 output partitions
2021-12-08 15:53:34,504 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 5 (take at PaidPromotionAdjustParameter.scala:256)
2021-12-08 15:53:34,504 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 4)
2021-12-08 15:53:34,504 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List(ShuffleMapStage 4)
2021-12-08 15:53:34,505 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ShuffleMapStage 4 (MapPartitionsRDD[10] at map at PaidPromotionAdjustParameter.scala:253), which has no missing parents
2021-12-08 15:53:34,507 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_5 stored as values in memory (estimated size 4.0 KB, free 1990.1 MB)
2021-12-08 15:53:34,510 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_5_piece0 stored as bytes in memory (estimated size 2.3 KB, free 1990.1 MB)
2021-12-08 15:53:34,510 [dispatcher-event-loop-11] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_5_piece0 in memory on qb:62937 (size: 2.3 KB, free: 1990.7 MB)
2021-12-08 15:53:34,511 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 5 from broadcast at DAGScheduler.scala:1039
2021-12-08 15:53:34,511 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 3 missing tasks from ShuffleMapStage 4 (MapPartitionsRDD[10] at map at PaidPromotionAdjustParameter.scala:253) (first 15 tasks are for partitions Vector(0, 1, 2))
2021-12-08 15:53:34,511 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 4.0 with 3 tasks
2021-12-08 15:53:34,512 [dispatcher-event-loop-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 4.0 (TID 6, localhost, executor driver, partition 0, ANY, 7748 bytes)
2021-12-08 15:53:34,512 [dispatcher-event-loop-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 4.0 (TID 7, localhost, executor driver, partition 1, ANY, 7748 bytes)
2021-12-08 15:53:34,512 [dispatcher-event-loop-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 2.0 in stage 4.0 (TID 8, localhost, executor driver, partition 2, ANY, 7748 bytes)
2021-12-08 15:53:34,512 [Executor task launch worker for task 6] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 4.0 (TID 6)
2021-12-08 15:53:34,512 [Executor task launch worker for task 7] INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 4.0 (TID 7)
2021-12-08 15:53:34,513 [Executor task launch worker for task 8] INFO [org.apache.spark.executor.Executor] - Running task 2.0 in stage 4.0 (TID 8)
2021-12-08 15:53:34,515 [Executor task launch worker for task 6] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 2 non-empty blocks out of 2 blocks
2021-12-08 15:53:34,515 [Executor task launch worker for task 6] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 1 ms
2021-12-08 15:53:34,515 [Executor task launch worker for task 7] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 2 non-empty blocks out of 2 blocks
2021-12-08 15:53:34,515 [Executor task launch worker for task 7] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-08 15:53:34,515 [Executor task launch worker for task 8] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 2 non-empty blocks out of 2 blocks
2021-12-08 15:53:34,515 [Executor task launch worker for task 8] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-08 15:53:34,532 [Executor task launch worker for task 7] INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 4.0 (TID 7). 1205 bytes result sent to driver
2021-12-08 15:53:34,533 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 4.0 (TID 7) in 20 ms on localhost (executor driver) (1/3)
2021-12-08 15:53:34,533 [Executor task launch worker for task 6] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 4.0 (TID 6). 1162 bytes result sent to driver
2021-12-08 15:53:34,534 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 4.0 (TID 6) in 23 ms on localhost (executor driver) (2/3)
2021-12-08 15:53:34,534 [Executor task launch worker for task 8] INFO [org.apache.spark.executor.Executor] - Finished task 2.0 in stage 4.0 (TID 8). 1205 bytes result sent to driver
2021-12-08 15:53:34,535 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 2.0 in stage 4.0 (TID 8) in 23 ms on localhost (executor driver) (3/3)
2021-12-08 15:53:34,535 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 4.0, whose tasks have all completed, from pool 
2021-12-08 15:53:34,536 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ShuffleMapStage 4 (map at PaidPromotionAdjustParameter.scala:253) finished in 0.030 s
2021-12-08 15:53:34,536 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - looking for newly runnable stages
2021-12-08 15:53:34,536 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - running: Set()
2021-12-08 15:53:34,536 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - waiting: Set(ResultStage 5)
2021-12-08 15:53:34,536 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - failed: Set()
2021-12-08 15:53:34,536 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 5 (MapPartitionsRDD[12] at map at PaidPromotionAdjustParameter.scala:255), which has no missing parents
2021-12-08 15:53:34,538 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_6 stored as values in memory (estimated size 3.6 KB, free 1990.1 MB)
2021-12-08 15:53:34,540 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_6_piece0 stored as bytes in memory (estimated size 2.1 KB, free 1990.1 MB)
2021-12-08 15:53:34,541 [dispatcher-event-loop-6] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_6_piece0 in memory on qb:62937 (size: 2.1 KB, free: 1990.7 MB)
2021-12-08 15:53:34,541 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 6 from broadcast at DAGScheduler.scala:1039
2021-12-08 15:53:34,542 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 5 (MapPartitionsRDD[12] at map at PaidPromotionAdjustParameter.scala:255) (first 15 tasks are for partitions Vector(0))
2021-12-08 15:53:34,542 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 5.0 with 1 tasks
2021-12-08 15:53:34,542 [dispatcher-event-loop-8] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 5.0 (TID 9, localhost, executor driver, partition 0, PROCESS_LOCAL, 7649 bytes)
2021-12-08 15:53:34,543 [Executor task launch worker for task 9] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 5.0 (TID 9)
2021-12-08 15:53:34,544 [Executor task launch worker for task 9] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 0 non-empty blocks out of 3 blocks
2021-12-08 15:53:34,544 [Executor task launch worker for task 9] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-08 15:53:34,549 [Executor task launch worker for task 9] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 5.0 (TID 9). 1011 bytes result sent to driver
2021-12-08 15:53:34,549 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 5.0 (TID 9) in 7 ms on localhost (executor driver) (1/1)
2021-12-08 15:53:34,550 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 5.0, whose tasks have all completed, from pool 
2021-12-08 15:53:34,550 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 5 (take at PaidPromotionAdjustParameter.scala:256) finished in 0.013 s
2021-12-08 15:53:34,550 [main] INFO [org.apache.spark.scheduler.DAGScheduler] - Job 2 finished: take at PaidPromotionAdjustParameter.scala:256, took 0.046951 s
2021-12-08 15:53:34,557 [main] INFO [org.apache.spark.SparkContext] - Starting job: take at PaidPromotionAdjustParameter.scala:256
2021-12-08 15:53:34,557 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 3 (take at PaidPromotionAdjustParameter.scala:256) with 2 output partitions
2021-12-08 15:53:34,558 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 8 (take at PaidPromotionAdjustParameter.scala:256)
2021-12-08 15:53:34,558 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 7)
2021-12-08 15:53:34,558 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2021-12-08 15:53:34,558 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 8 (MapPartitionsRDD[12] at map at PaidPromotionAdjustParameter.scala:255), which has no missing parents
2021-12-08 15:53:34,559 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_7 stored as values in memory (estimated size 3.6 KB, free 1990.1 MB)
2021-12-08 15:53:34,562 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_7_piece0 stored as bytes in memory (estimated size 2.1 KB, free 1990.1 MB)
2021-12-08 15:53:34,562 [dispatcher-event-loop-11] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_7_piece0 in memory on qb:62937 (size: 2.1 KB, free: 1990.7 MB)
2021-12-08 15:53:34,562 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 7 from broadcast at DAGScheduler.scala:1039
2021-12-08 15:53:34,563 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from ResultStage 8 (MapPartitionsRDD[12] at map at PaidPromotionAdjustParameter.scala:255) (first 15 tasks are for partitions Vector(1, 2))
2021-12-08 15:53:34,563 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 8.0 with 2 tasks
2021-12-08 15:53:34,563 [dispatcher-event-loop-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 8.0 (TID 10, localhost, executor driver, partition 2, PROCESS_LOCAL, 7649 bytes)
2021-12-08 15:53:34,564 [dispatcher-event-loop-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 8.0 (TID 11, localhost, executor driver, partition 1, ANY, 7649 bytes)
2021-12-08 15:53:34,564 [Executor task launch worker for task 11] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 8.0 (TID 11)
2021-12-08 15:53:34,564 [Executor task launch worker for task 10] INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 8.0 (TID 10)
2021-12-08 15:53:34,565 [Executor task launch worker for task 11] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 3 non-empty blocks out of 3 blocks
2021-12-08 15:53:34,565 [Executor task launch worker for task 11] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-08 15:53:34,565 [Executor task launch worker for task 10] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 0 non-empty blocks out of 3 blocks
2021-12-08 15:53:34,566 [Executor task launch worker for task 10] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 1 ms
2021-12-08 15:53:34,571 [Executor task launch worker for task 10] INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 8.0 (TID 10). 1054 bytes result sent to driver
2021-12-08 15:53:34,572 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 8.0 (TID 10) in 9 ms on localhost (executor driver) (1/2)
2021-12-08 15:53:34,583 [Executor task launch worker for task 11] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 8.0 (TID 11). 1056 bytes result sent to driver
2021-12-08 15:53:34,583 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 8.0 (TID 11) in 19 ms on localhost (executor driver) (2/2)
2021-12-08 15:53:34,583 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 8.0, whose tasks have all completed, from pool 
2021-12-08 15:53:34,584 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 8 (take at PaidPromotionAdjustParameter.scala:256) finished in 0.026 s
2021-12-08 15:53:34,584 [main] INFO [org.apache.spark.scheduler.DAGScheduler] - Job 3 finished: take at PaidPromotionAdjustParameter.scala:256, took 0.027234 s
2021-12-08 15:53:34,584 [main] INFO [PaidPromotionAdjustParameter$] - 训练集产品包总数： 131
2021-12-08 15:53:34,600 [main] INFO [org.apache.hadoop.mapred.FileInputFormat] - Total input paths to process : 6
2021-12-08 15:53:34,602 [main] INFO [org.apache.spark.SparkContext] - Starting job: count at PaidPromotionAdjustParameter.scala:266
2021-12-08 15:53:34,603 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 4 (count at PaidPromotionAdjustParameter.scala:266) with 6 output partitions
2021-12-08 15:53:34,603 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 9 (count at PaidPromotionAdjustParameter.scala:266)
2021-12-08 15:53:34,603 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List()
2021-12-08 15:53:34,603 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2021-12-08 15:53:34,603 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 9 (MapPartitionsRDD[13] at map at PaidPromotionAdjustParameter.scala:262), which has no missing parents
2021-12-08 15:53:34,604 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_8 stored as values in memory (estimated size 3.3 KB, free 1990.1 MB)
2021-12-08 15:53:34,607 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_8_piece0 stored as bytes in memory (estimated size 1994.0 B, free 1990.1 MB)
2021-12-08 15:53:34,607 [dispatcher-event-loop-4] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_8_piece0 in memory on qb:62937 (size: 1994.0 B, free: 1990.7 MB)
2021-12-08 15:53:34,608 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 8 from broadcast at DAGScheduler.scala:1039
2021-12-08 15:53:34,608 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 6 missing tasks from ResultStage 9 (MapPartitionsRDD[13] at map at PaidPromotionAdjustParameter.scala:262) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5))
2021-12-08 15:53:34,608 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 9.0 with 6 tasks
2021-12-08 15:53:34,609 [dispatcher-event-loop-7] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 9.0 (TID 12, localhost, executor driver, partition 0, ANY, 7917 bytes)
2021-12-08 15:53:34,609 [dispatcher-event-loop-7] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 9.0 (TID 13, localhost, executor driver, partition 1, ANY, 7917 bytes)
2021-12-08 15:53:34,609 [dispatcher-event-loop-7] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 2.0 in stage 9.0 (TID 14, localhost, executor driver, partition 2, ANY, 7917 bytes)
2021-12-08 15:53:34,609 [dispatcher-event-loop-7] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 3.0 in stage 9.0 (TID 15, localhost, executor driver, partition 3, ANY, 7917 bytes)
2021-12-08 15:53:34,609 [dispatcher-event-loop-7] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 4.0 in stage 9.0 (TID 16, localhost, executor driver, partition 4, ANY, 7917 bytes)
2021-12-08 15:53:34,610 [dispatcher-event-loop-7] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 5.0 in stage 9.0 (TID 17, localhost, executor driver, partition 5, ANY, 7917 bytes)
2021-12-08 15:53:34,610 [Executor task launch worker for task 13] INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 9.0 (TID 13)
2021-12-08 15:53:34,610 [Executor task launch worker for task 14] INFO [org.apache.spark.executor.Executor] - Running task 2.0 in stage 9.0 (TID 14)
2021-12-08 15:53:34,610 [Executor task launch worker for task 12] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 9.0 (TID 12)
2021-12-08 15:53:34,610 [Executor task launch worker for task 15] INFO [org.apache.spark.executor.Executor] - Running task 3.0 in stage 9.0 (TID 15)
2021-12-08 15:53:34,611 [Executor task launch worker for task 16] INFO [org.apache.spark.executor.Executor] - Running task 4.0 in stage 9.0 (TID 16)
2021-12-08 15:53:34,611 [Executor task launch worker for task 17] INFO [org.apache.spark.executor.Executor] - Running task 5.0 in stage 9.0 (TID 17)
2021-12-08 15:53:34,612 [Executor task launch worker for task 14] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/handle_data/device_video_data/part-00002:0+7537224
2021-12-08 15:53:34,612 [Executor task launch worker for task 13] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/handle_data/device_video_data/part-00001:0+7544772
2021-12-08 15:53:34,612 [Executor task launch worker for task 12] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/handle_data/device_video_data/part-00000:0+3904159
2021-12-08 15:53:34,612 [Executor task launch worker for task 16] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/handle_data/device_video_data/part-00004:0+3818189
2021-12-08 15:53:34,614 [Executor task launch worker for task 17] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/handle_data/device_video_data/part-00005:0+7196304
2021-12-08 15:53:34,614 [Executor task launch worker for task 15] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/handle_data/device_video_data/part-00003:0+7644414
2021-12-08 15:53:34,767 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 109
2021-12-08 15:53:34,767 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 79
2021-12-08 15:53:34,767 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 49
2021-12-08 15:53:34,767 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 102
2021-12-08 15:53:34,768 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 69
2021-12-08 15:53:34,768 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 72
2021-12-08 15:53:34,768 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 43
2021-12-08 15:53:34,768 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 60
2021-12-08 15:53:34,768 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 30
2021-12-08 15:53:34,768 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 116
2021-12-08 15:53:34,768 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 122
2021-12-08 15:53:34,768 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 36
2021-12-08 15:53:34,768 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 147
2021-12-08 15:53:34,768 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 25
2021-12-08 15:53:34,768 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 137
2021-12-08 15:53:34,768 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 132
2021-12-08 15:53:34,768 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 135
2021-12-08 15:53:34,768 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 37
2021-12-08 15:53:34,769 [dispatcher-event-loop-3] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_6_piece0 on qb:62937 in memory (size: 2.1 KB, free: 1990.7 MB)
2021-12-08 15:53:34,770 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 27
2021-12-08 15:53:34,770 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 142
2021-12-08 15:53:34,770 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 117
2021-12-08 15:53:34,770 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 93
2021-12-08 15:53:34,770 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 121
2021-12-08 15:53:34,770 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 140
2021-12-08 15:53:34,770 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 75
2021-12-08 15:53:34,770 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 107
2021-12-08 15:53:34,770 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 51
2021-12-08 15:53:34,770 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 112
2021-12-08 15:53:34,770 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 50
2021-12-08 15:53:34,770 [dispatcher-event-loop-6] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_3_piece0 on qb:62937 in memory (size: 2.8 KB, free: 1990.7 MB)
2021-12-08 15:53:34,771 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 92
2021-12-08 15:53:34,771 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 59
2021-12-08 15:53:34,771 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 149
2021-12-08 15:53:34,771 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 126
2021-12-08 15:53:34,771 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 98
2021-12-08 15:53:34,771 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 31
2021-12-08 15:53:34,771 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 62
2021-12-08 15:53:34,771 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 100
2021-12-08 15:53:34,771 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 111
2021-12-08 15:53:34,771 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 40
2021-12-08 15:53:34,771 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 88
2021-12-08 15:53:34,771 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 32
2021-12-08 15:53:34,771 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 101
2021-12-08 15:53:34,771 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 124
2021-12-08 15:53:34,771 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 80
2021-12-08 15:53:34,771 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 76
2021-12-08 15:53:34,771 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 90
2021-12-08 15:53:34,771 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 70
2021-12-08 15:53:34,771 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 81
2021-12-08 15:53:34,771 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 99
2021-12-08 15:53:34,771 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 136
2021-12-08 15:53:34,771 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 106
2021-12-08 15:53:34,771 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 73
2021-12-08 15:53:34,771 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 103
2021-12-08 15:53:34,772 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 78
2021-12-08 15:53:34,772 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 55
2021-12-08 15:53:34,772 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 120
2021-12-08 15:53:34,772 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 46
2021-12-08 15:53:34,772 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 41
2021-12-08 15:53:34,772 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 97
2021-12-08 15:53:34,772 [dispatcher-event-loop-9] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_7_piece0 on qb:62937 in memory (size: 2.1 KB, free: 1990.7 MB)
2021-12-08 15:53:34,773 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 74
2021-12-08 15:53:34,773 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 86
2021-12-08 15:53:34,773 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 96
2021-12-08 15:53:34,773 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 83
2021-12-08 15:53:34,773 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 133
2021-12-08 15:53:34,773 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 115
2021-12-08 15:53:34,773 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 63
2021-12-08 15:53:34,773 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 38
2021-12-08 15:53:34,773 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 130
2021-12-08 15:53:34,773 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 110
2021-12-08 15:53:34,773 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 87
2021-12-08 15:53:34,773 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 33
2021-12-08 15:53:34,773 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 89
2021-12-08 15:53:34,773 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 104
2021-12-08 15:53:34,773 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 39
2021-12-08 15:53:34,773 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 42
2021-12-08 15:53:34,773 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 26
2021-12-08 15:53:34,773 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 29
2021-12-08 15:53:34,773 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 119
2021-12-08 15:53:34,773 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 85
2021-12-08 15:53:34,773 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 57
2021-12-08 15:53:34,773 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 125
2021-12-08 15:53:34,773 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 127
2021-12-08 15:53:34,773 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 146
2021-12-08 15:53:34,773 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 68
2021-12-08 15:53:34,774 [dispatcher-event-loop-1] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_4_piece0 on qb:62937 in memory (size: 2.2 KB, free: 1990.7 MB)
2021-12-08 15:53:34,774 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 44
2021-12-08 15:53:34,776 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned shuffle 1
2021-12-08 15:53:34,776 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 131
2021-12-08 15:53:34,776 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 105
2021-12-08 15:53:34,776 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 48
2021-12-08 15:53:34,776 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 114
2021-12-08 15:53:34,776 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 129
2021-12-08 15:53:34,776 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 65
2021-12-08 15:53:34,776 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 94
2021-12-08 15:53:34,776 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 45
2021-12-08 15:53:34,776 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 145
2021-12-08 15:53:34,776 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 148
2021-12-08 15:53:34,776 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 77
2021-12-08 15:53:34,776 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 35
2021-12-08 15:53:34,776 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 67
2021-12-08 15:53:34,777 [dispatcher-event-loop-5] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_5_piece0 on qb:62937 in memory (size: 2.3 KB, free: 1990.7 MB)
2021-12-08 15:53:34,778 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 71
2021-12-08 15:53:34,778 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 61
2021-12-08 15:53:34,778 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 128
2021-12-08 15:53:34,778 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 144
2021-12-08 15:53:34,778 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 53
2021-12-08 15:53:34,778 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 139
2021-12-08 15:53:34,778 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 141
2021-12-08 15:53:34,778 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 52
2021-12-08 15:53:34,778 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 56
2021-12-08 15:53:34,778 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 54
2021-12-08 15:53:34,778 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 113
2021-12-08 15:53:34,778 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 66
2021-12-08 15:53:34,778 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 28
2021-12-08 15:53:34,778 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 58
2021-12-08 15:53:34,778 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 138
2021-12-08 15:53:34,778 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 64
2021-12-08 15:53:34,778 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 123
2021-12-08 15:53:34,778 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 34
2021-12-08 15:53:34,778 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 84
2021-12-08 15:53:34,778 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 118
2021-12-08 15:53:34,778 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 143
2021-12-08 15:53:34,778 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 91
2021-12-08 15:53:34,778 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 95
2021-12-08 15:53:34,778 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 134
2021-12-08 15:53:34,778 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 108
2021-12-08 15:53:34,778 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 82
2021-12-08 15:53:34,778 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 47
2021-12-08 15:53:35,506 [Executor task launch worker for task 12] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 9.0 (TID 12). 754 bytes result sent to driver
2021-12-08 15:53:35,506 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 9.0 (TID 12) in 897 ms on localhost (executor driver) (1/6)
2021-12-08 15:53:37,312 [Executor task launch worker for task 16] INFO [org.apache.spark.executor.Executor] - Finished task 4.0 in stage 9.0 (TID 16). 711 bytes result sent to driver
2021-12-08 15:53:37,313 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 4.0 in stage 9.0 (TID 16) in 2704 ms on localhost (executor driver) (2/6)
2021-12-08 15:53:37,550 [Executor task launch worker for task 17] INFO [org.apache.spark.executor.Executor] - Finished task 5.0 in stage 9.0 (TID 17). 754 bytes result sent to driver
2021-12-08 15:53:37,550 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 5.0 in stage 9.0 (TID 17) in 2941 ms on localhost (executor driver) (3/6)
2021-12-08 15:53:37,712 [Executor task launch worker for task 13] INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 9.0 (TID 13). 754 bytes result sent to driver
2021-12-08 15:53:37,713 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 9.0 (TID 13) in 3104 ms on localhost (executor driver) (4/6)
2021-12-08 15:53:37,808 [Executor task launch worker for task 15] INFO [org.apache.spark.executor.Executor] - Finished task 3.0 in stage 9.0 (TID 15). 754 bytes result sent to driver
2021-12-08 15:53:37,808 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 3.0 in stage 9.0 (TID 15) in 3199 ms on localhost (executor driver) (5/6)
2021-12-08 15:53:38,071 [Executor task launch worker for task 14] INFO [org.apache.spark.executor.Executor] - Finished task 2.0 in stage 9.0 (TID 14). 754 bytes result sent to driver
2021-12-08 15:53:38,072 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 2.0 in stage 9.0 (TID 14) in 3463 ms on localhost (executor driver) (6/6)
2021-12-08 15:53:38,072 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 9.0, whose tasks have all completed, from pool 
2021-12-08 15:53:38,072 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 9 (count at PaidPromotionAdjustParameter.scala:266) finished in 3.468 s
2021-12-08 15:53:38,072 [main] INFO [org.apache.spark.scheduler.DAGScheduler] - Job 4 finished: count at PaidPromotionAdjustParameter.scala:266, took 3.469989 s
2021-12-08 15:53:38,072 [main] INFO [PaidPromotionAdjustParameter$] - 收视行为总数：869475
2021-12-08 15:53:38,081 [main] INFO [org.apache.spark.SparkContext] - Starting job: zipWithIndex at PaidPromotionAdjustParameter.scala:271
2021-12-08 15:53:38,081 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 15 (distinct at PaidPromotionAdjustParameter.scala:270)
2021-12-08 15:53:38,081 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 5 (zipWithIndex at PaidPromotionAdjustParameter.scala:271) with 11 output partitions
2021-12-08 15:53:38,081 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 11 (zipWithIndex at PaidPromotionAdjustParameter.scala:271)
2021-12-08 15:53:38,081 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 10)
2021-12-08 15:53:38,082 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List(ShuffleMapStage 10)
2021-12-08 15:53:38,082 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ShuffleMapStage 10 (MapPartitionsRDD[15] at distinct at PaidPromotionAdjustParameter.scala:270), which has no missing parents
2021-12-08 15:53:38,083 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_9 stored as values in memory (estimated size 4.9 KB, free 1990.1 MB)
2021-12-08 15:53:38,086 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_9_piece0 stored as bytes in memory (estimated size 2.8 KB, free 1990.1 MB)
2021-12-08 15:53:38,087 [dispatcher-event-loop-1] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_9_piece0 in memory on qb:62937 (size: 2.8 KB, free: 1990.7 MB)
2021-12-08 15:53:38,087 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 9 from broadcast at DAGScheduler.scala:1039
2021-12-08 15:53:38,088 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 6 missing tasks from ShuffleMapStage 10 (MapPartitionsRDD[15] at distinct at PaidPromotionAdjustParameter.scala:270) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5))
2021-12-08 15:53:38,088 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 10.0 with 6 tasks
2021-12-08 15:53:38,088 [dispatcher-event-loop-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 10.0 (TID 18, localhost, executor driver, partition 0, ANY, 7906 bytes)
2021-12-08 15:53:38,088 [dispatcher-event-loop-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 10.0 (TID 19, localhost, executor driver, partition 1, ANY, 7906 bytes)
2021-12-08 15:53:38,088 [dispatcher-event-loop-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 2.0 in stage 10.0 (TID 20, localhost, executor driver, partition 2, ANY, 7906 bytes)
2021-12-08 15:53:38,088 [dispatcher-event-loop-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 3.0 in stage 10.0 (TID 21, localhost, executor driver, partition 3, ANY, 7906 bytes)
2021-12-08 15:53:38,089 [dispatcher-event-loop-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 4.0 in stage 10.0 (TID 22, localhost, executor driver, partition 4, ANY, 7906 bytes)
2021-12-08 15:53:38,089 [dispatcher-event-loop-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 5.0 in stage 10.0 (TID 23, localhost, executor driver, partition 5, ANY, 7906 bytes)
2021-12-08 15:53:38,089 [Executor task launch worker for task 19] INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 10.0 (TID 19)
2021-12-08 15:53:38,089 [Executor task launch worker for task 22] INFO [org.apache.spark.executor.Executor] - Running task 4.0 in stage 10.0 (TID 22)
2021-12-08 15:53:38,089 [Executor task launch worker for task 18] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 10.0 (TID 18)
2021-12-08 15:53:38,089 [Executor task launch worker for task 21] INFO [org.apache.spark.executor.Executor] - Running task 3.0 in stage 10.0 (TID 21)
2021-12-08 15:53:38,089 [Executor task launch worker for task 23] INFO [org.apache.spark.executor.Executor] - Running task 5.0 in stage 10.0 (TID 23)
2021-12-08 15:53:38,089 [Executor task launch worker for task 20] INFO [org.apache.spark.executor.Executor] - Running task 2.0 in stage 10.0 (TID 20)
2021-12-08 15:53:38,091 [Executor task launch worker for task 20] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/handle_data/device_video_data/part-00002:0+7537224
2021-12-08 15:53:38,091 [Executor task launch worker for task 19] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/handle_data/device_video_data/part-00001:0+7544772
2021-12-08 15:53:38,091 [Executor task launch worker for task 21] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/handle_data/device_video_data/part-00003:0+7644414
2021-12-08 15:53:38,091 [Executor task launch worker for task 23] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/handle_data/device_video_data/part-00005:0+7196304
2021-12-08 15:53:38,091 [Executor task launch worker for task 18] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/handle_data/device_video_data/part-00000:0+3904159
2021-12-08 15:53:38,091 [Executor task launch worker for task 22] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/handle_data/device_video_data/part-00004:0+3818189
2021-12-08 15:53:38,733 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 167
2021-12-08 15:53:38,734 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 153
2021-12-08 15:53:38,734 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 173
2021-12-08 15:53:38,734 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 165
2021-12-08 15:53:38,734 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 164
2021-12-08 15:53:38,734 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 166
2021-12-08 15:53:38,734 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 152
2021-12-08 15:53:38,734 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 150
2021-12-08 15:53:38,734 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 171
2021-12-08 15:53:38,735 [dispatcher-event-loop-11] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_8_piece0 on qb:62937 in memory (size: 1994.0 B, free: 1990.7 MB)
2021-12-08 15:53:38,735 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 159
2021-12-08 15:53:38,735 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 156
2021-12-08 15:53:38,735 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 158
2021-12-08 15:53:38,735 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 172
2021-12-08 15:53:38,735 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 151
2021-12-08 15:53:38,735 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 160
2021-12-08 15:53:38,735 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 161
2021-12-08 15:53:38,735 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 169
2021-12-08 15:53:38,735 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 168
2021-12-08 15:53:38,735 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 163
2021-12-08 15:53:38,735 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 170
2021-12-08 15:53:38,735 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 157
2021-12-08 15:53:38,735 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 162
2021-12-08 15:53:38,735 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 174
2021-12-08 15:53:38,735 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 155
2021-12-08 15:53:38,735 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 154
2021-12-08 15:53:40,163 [Executor task launch worker for task 22] INFO [org.apache.spark.executor.Executor] - Finished task 4.0 in stage 10.0 (TID 22). 1042 bytes result sent to driver
2021-12-08 15:53:40,163 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 4.0 in stage 10.0 (TID 22) in 2074 ms on localhost (executor driver) (1/6)
2021-12-08 15:53:40,409 [Executor task launch worker for task 23] INFO [org.apache.spark.executor.Executor] - Finished task 5.0 in stage 10.0 (TID 23). 1042 bytes result sent to driver
2021-12-08 15:53:40,410 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 5.0 in stage 10.0 (TID 23) in 2321 ms on localhost (executor driver) (2/6)
2021-12-08 15:53:40,772 [Executor task launch worker for task 20] INFO [org.apache.spark.executor.Executor] - Finished task 2.0 in stage 10.0 (TID 20). 1042 bytes result sent to driver
2021-12-08 15:53:40,773 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 2.0 in stage 10.0 (TID 20) in 2685 ms on localhost (executor driver) (3/6)
2021-12-08 15:53:41,573 [Executor task launch worker for task 21] INFO [org.apache.spark.executor.Executor] - Finished task 3.0 in stage 10.0 (TID 21). 1042 bytes result sent to driver
2021-12-08 15:53:41,573 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 3.0 in stage 10.0 (TID 21) in 3485 ms on localhost (executor driver) (4/6)
2021-12-08 15:53:41,739 [Executor task launch worker for task 18] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 10.0 (TID 18). 1042 bytes result sent to driver
2021-12-08 15:53:41,740 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 10.0 (TID 18) in 3652 ms on localhost (executor driver) (5/6)
2021-12-08 15:53:41,986 [Executor task launch worker for task 19] INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 10.0 (TID 19). 1042 bytes result sent to driver
2021-12-08 15:53:41,987 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 10.0 (TID 19) in 3899 ms on localhost (executor driver) (6/6)
2021-12-08 15:53:41,987 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 10.0, whose tasks have all completed, from pool 
2021-12-08 15:53:41,988 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ShuffleMapStage 10 (distinct at PaidPromotionAdjustParameter.scala:270) finished in 3.905 s
2021-12-08 15:53:41,988 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - looking for newly runnable stages
2021-12-08 15:53:41,988 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - running: Set()
2021-12-08 15:53:41,988 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - waiting: Set(ResultStage 11)
2021-12-08 15:53:41,988 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - failed: Set()
2021-12-08 15:53:41,988 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 11 (MapPartitionsRDD[17] at distinct at PaidPromotionAdjustParameter.scala:270), which has no missing parents
2021-12-08 15:53:41,990 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_10 stored as values in memory (estimated size 3.7 KB, free 1990.1 MB)
2021-12-08 15:53:41,992 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_10_piece0 stored as bytes in memory (estimated size 2.2 KB, free 1990.1 MB)
2021-12-08 15:53:41,993 [dispatcher-event-loop-6] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_10_piece0 in memory on qb:62937 (size: 2.2 KB, free: 1990.7 MB)
2021-12-08 15:53:41,993 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 10 from broadcast at DAGScheduler.scala:1039
2021-12-08 15:53:41,993 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 11 missing tasks from ResultStage 11 (MapPartitionsRDD[17] at distinct at PaidPromotionAdjustParameter.scala:270) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10))
2021-12-08 15:53:41,993 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 11.0 with 11 tasks
2021-12-08 15:53:41,994 [dispatcher-event-loop-10] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 11.0 (TID 24, localhost, executor driver, partition 0, ANY, 7649 bytes)
2021-12-08 15:53:41,994 [dispatcher-event-loop-10] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 11.0 (TID 25, localhost, executor driver, partition 1, ANY, 7649 bytes)
2021-12-08 15:53:41,994 [dispatcher-event-loop-10] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 2.0 in stage 11.0 (TID 26, localhost, executor driver, partition 2, ANY, 7649 bytes)
2021-12-08 15:53:41,994 [dispatcher-event-loop-10] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 3.0 in stage 11.0 (TID 27, localhost, executor driver, partition 3, ANY, 7649 bytes)
2021-12-08 15:53:41,994 [dispatcher-event-loop-10] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 4.0 in stage 11.0 (TID 28, localhost, executor driver, partition 4, ANY, 7649 bytes)
2021-12-08 15:53:41,994 [dispatcher-event-loop-10] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 5.0 in stage 11.0 (TID 29, localhost, executor driver, partition 5, ANY, 7649 bytes)
2021-12-08 15:53:41,995 [dispatcher-event-loop-10] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 6.0 in stage 11.0 (TID 30, localhost, executor driver, partition 6, ANY, 7649 bytes)
2021-12-08 15:53:41,995 [dispatcher-event-loop-10] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 7.0 in stage 11.0 (TID 31, localhost, executor driver, partition 7, ANY, 7649 bytes)
2021-12-08 15:53:41,995 [dispatcher-event-loop-10] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 8.0 in stage 11.0 (TID 32, localhost, executor driver, partition 8, ANY, 7649 bytes)
2021-12-08 15:53:41,995 [dispatcher-event-loop-10] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 9.0 in stage 11.0 (TID 33, localhost, executor driver, partition 9, ANY, 7649 bytes)
2021-12-08 15:53:41,995 [dispatcher-event-loop-10] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 10.0 in stage 11.0 (TID 34, localhost, executor driver, partition 10, ANY, 7649 bytes)
2021-12-08 15:53:41,995 [Executor task launch worker for task 25] INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 11.0 (TID 25)
2021-12-08 15:53:41,995 [Executor task launch worker for task 27] INFO [org.apache.spark.executor.Executor] - Running task 3.0 in stage 11.0 (TID 27)
2021-12-08 15:53:41,995 [Executor task launch worker for task 24] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 11.0 (TID 24)
2021-12-08 15:53:41,995 [Executor task launch worker for task 29] INFO [org.apache.spark.executor.Executor] - Running task 5.0 in stage 11.0 (TID 29)
2021-12-08 15:53:41,995 [Executor task launch worker for task 28] INFO [org.apache.spark.executor.Executor] - Running task 4.0 in stage 11.0 (TID 28)
2021-12-08 15:53:41,995 [Executor task launch worker for task 26] INFO [org.apache.spark.executor.Executor] - Running task 2.0 in stage 11.0 (TID 26)
2021-12-08 15:53:41,996 [Executor task launch worker for task 30] INFO [org.apache.spark.executor.Executor] - Running task 6.0 in stage 11.0 (TID 30)
2021-12-08 15:53:41,996 [Executor task launch worker for task 32] INFO [org.apache.spark.executor.Executor] - Running task 8.0 in stage 11.0 (TID 32)
2021-12-08 15:53:41,996 [Executor task launch worker for task 31] INFO [org.apache.spark.executor.Executor] - Running task 7.0 in stage 11.0 (TID 31)
2021-12-08 15:53:41,997 [Executor task launch worker for task 33] INFO [org.apache.spark.executor.Executor] - Running task 9.0 in stage 11.0 (TID 33)
2021-12-08 15:53:41,997 [Executor task launch worker for task 34] INFO [org.apache.spark.executor.Executor] - Running task 10.0 in stage 11.0 (TID 34)
2021-12-08 15:53:41,999 [Executor task launch worker for task 29] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 6 non-empty blocks out of 6 blocks
2021-12-08 15:53:41,999 [Executor task launch worker for task 29] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-08 15:53:41,999 [Executor task launch worker for task 30] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 6 non-empty blocks out of 6 blocks
2021-12-08 15:53:41,999 [Executor task launch worker for task 30] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-08 15:53:41,999 [Executor task launch worker for task 24] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 6 non-empty blocks out of 6 blocks
2021-12-08 15:53:41,999 [Executor task launch worker for task 24] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-08 15:53:41,999 [Executor task launch worker for task 34] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 6 non-empty blocks out of 6 blocks
2021-12-08 15:53:41,999 [Executor task launch worker for task 34] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-08 15:53:41,999 [Executor task launch worker for task 26] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 6 non-empty blocks out of 6 blocks
2021-12-08 15:53:41,999 [Executor task launch worker for task 32] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 6 non-empty blocks out of 6 blocks
2021-12-08 15:53:41,999 [Executor task launch worker for task 27] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 6 non-empty blocks out of 6 blocks
2021-12-08 15:53:41,999 [Executor task launch worker for task 26] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-08 15:53:41,999 [Executor task launch worker for task 32] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-08 15:53:41,999 [Executor task launch worker for task 33] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 6 non-empty blocks out of 6 blocks
2021-12-08 15:53:41,999 [Executor task launch worker for task 27] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-08 15:53:41,999 [Executor task launch worker for task 33] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-08 15:53:41,999 [Executor task launch worker for task 31] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 6 non-empty blocks out of 6 blocks
2021-12-08 15:53:41,999 [Executor task launch worker for task 25] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 6 non-empty blocks out of 6 blocks
2021-12-08 15:53:41,999 [Executor task launch worker for task 31] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-08 15:53:41,999 [Executor task launch worker for task 25] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-08 15:53:41,999 [Executor task launch worker for task 28] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 6 non-empty blocks out of 6 blocks
2021-12-08 15:53:41,999 [Executor task launch worker for task 28] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-08 15:53:42,092 [Executor task launch worker for task 27] INFO [org.apache.spark.executor.Executor] - Finished task 3.0 in stage 11.0 (TID 27). 1054 bytes result sent to driver
2021-12-08 15:53:42,093 [Executor task launch worker for task 30] INFO [org.apache.spark.executor.Executor] - Finished task 6.0 in stage 11.0 (TID 30). 1054 bytes result sent to driver
2021-12-08 15:53:42,093 [Executor task launch worker for task 29] INFO [org.apache.spark.executor.Executor] - Finished task 5.0 in stage 11.0 (TID 29). 1054 bytes result sent to driver
2021-12-08 15:53:42,093 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 3.0 in stage 11.0 (TID 27) in 99 ms on localhost (executor driver) (1/11)
2021-12-08 15:53:42,093 [Executor task launch worker for task 34] INFO [org.apache.spark.executor.Executor] - Finished task 10.0 in stage 11.0 (TID 34). 1054 bytes result sent to driver
2021-12-08 15:53:42,093 [Executor task launch worker for task 33] INFO [org.apache.spark.executor.Executor] - Finished task 9.0 in stage 11.0 (TID 33). 1054 bytes result sent to driver
2021-12-08 15:53:42,093 [Executor task launch worker for task 26] INFO [org.apache.spark.executor.Executor] - Finished task 2.0 in stage 11.0 (TID 26). 1054 bytes result sent to driver
2021-12-08 15:53:42,094 [Executor task launch worker for task 24] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 11.0 (TID 24). 1054 bytes result sent to driver
2021-12-08 15:53:42,094 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 6.0 in stage 11.0 (TID 30) in 100 ms on localhost (executor driver) (2/11)
2021-12-08 15:53:42,094 [Executor task launch worker for task 32] INFO [org.apache.spark.executor.Executor] - Finished task 8.0 in stage 11.0 (TID 32). 1054 bytes result sent to driver
2021-12-08 15:53:42,094 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 5.0 in stage 11.0 (TID 29) in 100 ms on localhost (executor driver) (3/11)
2021-12-08 15:53:42,094 [Executor task launch worker for task 25] INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 11.0 (TID 25). 1054 bytes result sent to driver
2021-12-08 15:53:42,095 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 10.0 in stage 11.0 (TID 34) in 99 ms on localhost (executor driver) (4/11)
2021-12-08 15:53:42,095 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 9.0 in stage 11.0 (TID 33) in 100 ms on localhost (executor driver) (5/11)
2021-12-08 15:53:42,095 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 2.0 in stage 11.0 (TID 26) in 101 ms on localhost (executor driver) (6/11)
2021-12-08 15:53:42,095 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 11.0 (TID 24) in 101 ms on localhost (executor driver) (7/11)
2021-12-08 15:53:42,095 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 8.0 in stage 11.0 (TID 32) in 100 ms on localhost (executor driver) (8/11)
2021-12-08 15:53:42,095 [Executor task launch worker for task 31] INFO [org.apache.spark.executor.Executor] - Finished task 7.0 in stage 11.0 (TID 31). 1054 bytes result sent to driver
2021-12-08 15:53:42,095 [Executor task launch worker for task 28] INFO [org.apache.spark.executor.Executor] - Finished task 4.0 in stage 11.0 (TID 28). 1054 bytes result sent to driver
2021-12-08 15:53:42,095 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 11.0 (TID 25) in 101 ms on localhost (executor driver) (9/11)
2021-12-08 15:53:42,096 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 7.0 in stage 11.0 (TID 31) in 101 ms on localhost (executor driver) (10/11)
2021-12-08 15:53:42,096 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 4.0 in stage 11.0 (TID 28) in 102 ms on localhost (executor driver) (11/11)
2021-12-08 15:53:42,096 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 11.0, whose tasks have all completed, from pool 
2021-12-08 15:53:42,096 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 11 (zipWithIndex at PaidPromotionAdjustParameter.scala:271) finished in 0.107 s
2021-12-08 15:53:42,096 [main] INFO [org.apache.spark.scheduler.DAGScheduler] - Job 5 finished: zipWithIndex at PaidPromotionAdjustParameter.scala:271, took 4.015212 s
2021-12-08 15:53:42,115 [main] INFO [org.apache.spark.SparkContext] - Starting job: count at PaidPromotionAdjustParameter.scala:280
2021-12-08 15:53:42,119 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 23 (distinct at PaidPromotionAdjustParameter.scala:277)
2021-12-08 15:53:42,119 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 6 (count at PaidPromotionAdjustParameter.scala:280) with 1 output partitions
2021-12-08 15:53:42,119 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 13 (count at PaidPromotionAdjustParameter.scala:280)
2021-12-08 15:53:42,119 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 12)
2021-12-08 15:53:42,119 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List(ShuffleMapStage 12)
2021-12-08 15:53:42,119 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ShuffleMapStage 12 (MapPartitionsRDD[23] at distinct at PaidPromotionAdjustParameter.scala:277), which has no missing parents
2021-12-08 15:53:42,132 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 208
2021-12-08 15:53:42,132 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 206
2021-12-08 15:53:42,132 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 207
2021-12-08 15:53:42,132 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 204
2021-12-08 15:53:42,132 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 221
2021-12-08 15:53:42,132 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 223
2021-12-08 15:53:42,132 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 186
2021-12-08 15:53:42,133 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 201
2021-12-08 15:53:42,133 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 219
2021-12-08 15:53:42,133 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 218
2021-12-08 15:53:42,133 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 199
2021-12-08 15:53:42,133 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 212
2021-12-08 15:53:42,133 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 175
2021-12-08 15:53:42,133 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 187
2021-12-08 15:53:42,133 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 190
2021-12-08 15:53:42,133 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 178
2021-12-08 15:53:42,133 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 222
2021-12-08 15:53:42,133 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 213
2021-12-08 15:53:42,133 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 176
2021-12-08 15:53:42,133 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 192
2021-12-08 15:53:42,133 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 182
2021-12-08 15:53:42,133 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 202
2021-12-08 15:53:42,133 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 196
2021-12-08 15:53:42,133 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 181
2021-12-08 15:53:42,133 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 191
2021-12-08 15:53:42,133 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 194
2021-12-08 15:53:42,133 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 203
2021-12-08 15:53:42,133 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 224
2021-12-08 15:53:42,133 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 220
2021-12-08 15:53:42,133 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 185
2021-12-08 15:53:42,133 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 179
2021-12-08 15:53:42,133 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 195
2021-12-08 15:53:42,134 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 177
2021-12-08 15:53:42,134 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 184
2021-12-08 15:53:42,134 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 180
2021-12-08 15:53:42,134 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 217
2021-12-08 15:53:42,134 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 215
2021-12-08 15:53:42,134 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 193
2021-12-08 15:53:42,134 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 214
2021-12-08 15:53:42,134 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 216
2021-12-08 15:53:42,134 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 211
2021-12-08 15:53:42,135 [dispatcher-event-loop-8] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_10_piece0 on qb:62937 in memory (size: 2.2 KB, free: 1990.7 MB)
2021-12-08 15:53:42,135 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 200
2021-12-08 15:53:42,135 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 209
2021-12-08 15:53:42,135 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 188
2021-12-08 15:53:42,135 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 189
2021-12-08 15:53:42,135 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 197
2021-12-08 15:53:42,135 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 205
2021-12-08 15:53:42,135 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 210
2021-12-08 15:53:42,135 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 198
2021-12-08 15:53:42,135 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_11 stored as values in memory (estimated size 5.9 KB, free 1990.1 MB)
2021-12-08 15:53:42,136 [dispatcher-event-loop-1] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_9_piece0 on qb:62937 in memory (size: 2.8 KB, free: 1990.7 MB)
2021-12-08 15:53:42,137 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 183
2021-12-08 15:53:42,138 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_11_piece0 stored as bytes in memory (estimated size 3.3 KB, free 1990.1 MB)
2021-12-08 15:53:42,139 [dispatcher-event-loop-2] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_11_piece0 in memory on qb:62937 (size: 3.3 KB, free: 1990.7 MB)
2021-12-08 15:53:42,139 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 11 from broadcast at DAGScheduler.scala:1039
2021-12-08 15:53:42,139 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 8 missing tasks from ShuffleMapStage 12 (MapPartitionsRDD[23] at distinct at PaidPromotionAdjustParameter.scala:277) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7))
2021-12-08 15:53:42,140 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 12.0 with 8 tasks
2021-12-08 15:53:42,142 [dispatcher-event-loop-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 12.0 (TID 35, localhost, executor driver, partition 0, ANY, 8015 bytes)
2021-12-08 15:53:42,142 [dispatcher-event-loop-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 12.0 (TID 36, localhost, executor driver, partition 1, ANY, 8015 bytes)
2021-12-08 15:53:42,142 [dispatcher-event-loop-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 2.0 in stage 12.0 (TID 37, localhost, executor driver, partition 2, ANY, 8015 bytes)
2021-12-08 15:53:42,142 [dispatcher-event-loop-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 3.0 in stage 12.0 (TID 38, localhost, executor driver, partition 3, ANY, 8015 bytes)
2021-12-08 15:53:42,142 [dispatcher-event-loop-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 4.0 in stage 12.0 (TID 39, localhost, executor driver, partition 4, ANY, 8015 bytes)
2021-12-08 15:53:42,143 [dispatcher-event-loop-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 5.0 in stage 12.0 (TID 40, localhost, executor driver, partition 5, ANY, 8015 bytes)
2021-12-08 15:53:42,143 [dispatcher-event-loop-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 6.0 in stage 12.0 (TID 41, localhost, executor driver, partition 6, ANY, 8030 bytes)
2021-12-08 15:53:42,143 [dispatcher-event-loop-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 7.0 in stage 12.0 (TID 42, localhost, executor driver, partition 7, ANY, 8030 bytes)
2021-12-08 15:53:42,143 [Executor task launch worker for task 40] INFO [org.apache.spark.executor.Executor] - Running task 5.0 in stage 12.0 (TID 40)
2021-12-08 15:53:42,143 [Executor task launch worker for task 38] INFO [org.apache.spark.executor.Executor] - Running task 3.0 in stage 12.0 (TID 38)
2021-12-08 15:53:42,143 [Executor task launch worker for task 41] INFO [org.apache.spark.executor.Executor] - Running task 6.0 in stage 12.0 (TID 41)
2021-12-08 15:53:42,143 [Executor task launch worker for task 37] INFO [org.apache.spark.executor.Executor] - Running task 2.0 in stage 12.0 (TID 37)
2021-12-08 15:53:42,143 [Executor task launch worker for task 35] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 12.0 (TID 35)
2021-12-08 15:53:42,143 [Executor task launch worker for task 39] INFO [org.apache.spark.executor.Executor] - Running task 4.0 in stage 12.0 (TID 39)
2021-12-08 15:53:42,143 [Executor task launch worker for task 36] INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 12.0 (TID 36)
2021-12-08 15:53:42,143 [Executor task launch worker for task 42] INFO [org.apache.spark.executor.Executor] - Running task 7.0 in stage 12.0 (TID 42)
2021-12-08 15:53:42,146 [Executor task launch worker for task 42] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/handle_data/set-train-device-production-data/part-00000:3237750+3237751
2021-12-08 15:53:42,146 [Executor task launch worker for task 35] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/handle_data/device_video_data/part-00000:0+3904159
2021-12-08 15:53:42,146 [Executor task launch worker for task 39] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/handle_data/device_video_data/part-00004:0+3818189
2021-12-08 15:53:42,146 [Executor task launch worker for task 37] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/handle_data/device_video_data/part-00002:0+7537224
2021-12-08 15:53:42,146 [Executor task launch worker for task 40] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/handle_data/device_video_data/part-00005:0+7196304
2021-12-08 15:53:42,146 [Executor task launch worker for task 41] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/handle_data/set-train-device-production-data/part-00000:0+3237750
2021-12-08 15:53:42,146 [Executor task launch worker for task 38] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/handle_data/device_video_data/part-00003:0+7644414
2021-12-08 15:53:42,146 [Executor task launch worker for task 36] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/handle_data/device_video_data/part-00001:0+7544772
2021-12-08 15:53:44,206 [Executor task launch worker for task 41] INFO [org.apache.spark.executor.Executor] - Finished task 6.0 in stage 12.0 (TID 41). 1031 bytes result sent to driver
2021-12-08 15:53:44,206 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 6.0 in stage 12.0 (TID 41) in 2063 ms on localhost (executor driver) (1/8)
2021-12-08 15:53:44,323 [Executor task launch worker for task 42] INFO [org.apache.spark.executor.Executor] - Finished task 7.0 in stage 12.0 (TID 42). 1031 bytes result sent to driver
2021-12-08 15:53:44,323 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 7.0 in stage 12.0 (TID 42) in 2180 ms on localhost (executor driver) (2/8)
2021-12-08 15:53:44,812 [Executor task launch worker for task 40] INFO [org.apache.spark.executor.Executor] - Finished task 5.0 in stage 12.0 (TID 40). 1031 bytes result sent to driver
2021-12-08 15:53:44,812 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 5.0 in stage 12.0 (TID 40) in 2670 ms on localhost (executor driver) (3/8)
2021-12-08 15:53:45,556 [Executor task launch worker for task 39] INFO [org.apache.spark.executor.Executor] - Finished task 4.0 in stage 12.0 (TID 39). 1031 bytes result sent to driver
2021-12-08 15:53:45,556 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 4.0 in stage 12.0 (TID 39) in 3414 ms on localhost (executor driver) (4/8)
2021-12-08 15:53:45,601 [Executor task launch worker for task 35] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 12.0 (TID 35). 1031 bytes result sent to driver
2021-12-08 15:53:45,602 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 12.0 (TID 35) in 3462 ms on localhost (executor driver) (5/8)
2021-12-08 15:53:45,932 [Executor task launch worker for task 38] INFO [org.apache.spark.executor.Executor] - Finished task 3.0 in stage 12.0 (TID 38). 1031 bytes result sent to driver
2021-12-08 15:53:45,932 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 3.0 in stage 12.0 (TID 38) in 3790 ms on localhost (executor driver) (6/8)
2021-12-08 15:53:45,991 [Executor task launch worker for task 36] INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 12.0 (TID 36). 1031 bytes result sent to driver
2021-12-08 15:53:45,991 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 12.0 (TID 36) in 3849 ms on localhost (executor driver) (7/8)
2021-12-08 15:53:46,335 [Executor task launch worker for task 37] INFO [org.apache.spark.executor.Executor] - Finished task 2.0 in stage 12.0 (TID 37). 1031 bytes result sent to driver
2021-12-08 15:53:46,336 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 2.0 in stage 12.0 (TID 37) in 4194 ms on localhost (executor driver) (8/8)
2021-12-08 15:53:46,336 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 12.0, whose tasks have all completed, from pool 
2021-12-08 15:53:46,336 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ShuffleMapStage 12 (distinct at PaidPromotionAdjustParameter.scala:277) finished in 4.216 s
2021-12-08 15:53:46,336 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - looking for newly runnable stages
2021-12-08 15:53:46,336 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - running: Set()
2021-12-08 15:53:46,336 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - waiting: Set(ResultStage 13)
2021-12-08 15:53:46,336 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - failed: Set()
2021-12-08 15:53:46,337 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 13 (ZippedWithIndexRDD[26] at zipWithIndex at PaidPromotionAdjustParameter.scala:278), which has no missing parents
2021-12-08 15:53:46,337 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_12 stored as values in memory (estimated size 3.9 KB, free 1990.1 MB)
2021-12-08 15:53:46,339 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_12_piece0 stored as bytes in memory (estimated size 2.2 KB, free 1990.1 MB)
2021-12-08 15:53:46,340 [dispatcher-event-loop-5] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_12_piece0 in memory on qb:62937 (size: 2.2 KB, free: 1990.7 MB)
2021-12-08 15:53:46,340 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 12 from broadcast at DAGScheduler.scala:1039
2021-12-08 15:53:46,340 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 13 (ZippedWithIndexRDD[26] at zipWithIndex at PaidPromotionAdjustParameter.scala:278) (first 15 tasks are for partitions Vector(0))
2021-12-08 15:53:46,340 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 13.0 with 1 tasks
2021-12-08 15:53:46,341 [dispatcher-event-loop-6] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 13.0 (TID 43, localhost, executor driver, partition 0, ANY, 7759 bytes)
2021-12-08 15:53:46,341 [Executor task launch worker for task 43] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 13.0 (TID 43)
2021-12-08 15:53:46,342 [Executor task launch worker for task 43] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 8 non-empty blocks out of 8 blocks
2021-12-08 15:53:46,342 [Executor task launch worker for task 43] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-08 15:53:46,466 [Executor task launch worker for task 43] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 13.0 (TID 43). 1012 bytes result sent to driver
2021-12-08 15:53:46,467 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 13.0 (TID 43) in 127 ms on localhost (executor driver) (1/1)
2021-12-08 15:53:46,467 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 13.0, whose tasks have all completed, from pool 
2021-12-08 15:53:46,467 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 13 (count at PaidPromotionAdjustParameter.scala:280) finished in 0.130 s
2021-12-08 15:53:46,468 [main] INFO [org.apache.spark.scheduler.DAGScheduler] - Job 6 finished: count at PaidPromotionAdjustParameter.scala:280, took 4.351811 s
2021-12-08 15:53:46,468 [main] INFO [PaidPromotionAdjustParameter$] - 训练总用户数：104731
2021-12-08 15:53:46,507 [main] INFO [PaidPromotionAdjustParameter$] - Rdd转换时间 : 14s
2021-12-08 15:53:46,520 [main] INFO [org.apache.hadoop.conf.Configuration.deprecation] - mapred.output.dir is deprecated. Instead, use mapreduce.output.fileoutputformat.outputdir
2021-12-08 15:53:46,523 [main] INFO [org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter] - File Output Committer Algorithm version is 1
2021-12-08 15:53:46,562 [main] INFO [org.apache.spark.SparkContext] - Starting job: runJob at SparkHadoopWriter.scala:78
2021-12-08 15:53:46,563 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 13 (map at PaidPromotionAdjustParameter.scala:262)
2021-12-08 15:53:46,563 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 26 (zipWithIndex at PaidPromotionAdjustParameter.scala:278)
2021-12-08 15:53:46,563 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 39 (map at PaidPromotionAdjustParameter.scala:295)
2021-12-08 15:53:46,563 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 26 (zipWithIndex at PaidPromotionAdjustParameter.scala:278)
2021-12-08 15:53:46,563 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 4 (map at PaidPromotionAdjustParameter.scala:241)
2021-12-08 15:53:46,563 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 30 (map at PaidPromotionAdjustParameter.scala:286)
2021-12-08 15:53:46,564 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 9 (zipWithIndex at PaidPromotionAdjustParameter.scala:250)
2021-12-08 15:53:46,564 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 19 (map at PaidPromotionAdjustParameter.scala:272)
2021-12-08 15:53:46,564 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 7 (runJob at SparkHadoopWriter.scala:78) with 10 output partitions
2021-12-08 15:53:46,564 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 25 (runJob at SparkHadoopWriter.scala:78)
2021-12-08 15:53:46,564 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 20, ShuffleMapStage 17, ShuffleMapStage 24, ShuffleMapStage 22)
2021-12-08 15:53:46,564 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List(ShuffleMapStage 20, ShuffleMapStage 17, ShuffleMapStage 24, ShuffleMapStage 22)
2021-12-08 15:53:46,564 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ShuffleMapStage 15 (MapPartitionsRDD[13] at map at PaidPromotionAdjustParameter.scala:262), which has no missing parents
2021-12-08 15:53:46,566 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_13 stored as values in memory (estimated size 4.5 KB, free 1990.1 MB)
2021-12-08 15:53:46,569 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_13_piece0 stored as bytes in memory (estimated size 2.7 KB, free 1990.1 MB)
2021-12-08 15:53:46,569 [dispatcher-event-loop-1] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_13_piece0 in memory on qb:62937 (size: 2.7 KB, free: 1990.7 MB)
2021-12-08 15:53:46,569 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 13 from broadcast at DAGScheduler.scala:1039
2021-12-08 15:53:46,570 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 6 missing tasks from ShuffleMapStage 15 (MapPartitionsRDD[13] at map at PaidPromotionAdjustParameter.scala:262) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5))
2021-12-08 15:53:46,570 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 15.0 with 6 tasks
2021-12-08 15:53:46,570 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ShuffleMapStage 16 (ZippedWithIndexRDD[26] at zipWithIndex at PaidPromotionAdjustParameter.scala:278), which has no missing parents
2021-12-08 15:53:46,570 [dispatcher-event-loop-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 15.0 (TID 44, localhost, executor driver, partition 0, ANY, 7906 bytes)
2021-12-08 15:53:46,570 [dispatcher-event-loop-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 15.0 (TID 45, localhost, executor driver, partition 1, ANY, 7906 bytes)
2021-12-08 15:53:46,571 [dispatcher-event-loop-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 2.0 in stage 15.0 (TID 46, localhost, executor driver, partition 2, ANY, 7906 bytes)
2021-12-08 15:53:46,571 [dispatcher-event-loop-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 3.0 in stage 15.0 (TID 47, localhost, executor driver, partition 3, ANY, 7906 bytes)
2021-12-08 15:53:46,571 [dispatcher-event-loop-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 4.0 in stage 15.0 (TID 48, localhost, executor driver, partition 4, ANY, 7906 bytes)
2021-12-08 15:53:46,571 [dispatcher-event-loop-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 5.0 in stage 15.0 (TID 49, localhost, executor driver, partition 5, ANY, 7906 bytes)
2021-12-08 15:53:46,571 [Executor task launch worker for task 44] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 15.0 (TID 44)
2021-12-08 15:53:46,571 [Executor task launch worker for task 48] INFO [org.apache.spark.executor.Executor] - Running task 4.0 in stage 15.0 (TID 48)
2021-12-08 15:53:46,571 [Executor task launch worker for task 47] INFO [org.apache.spark.executor.Executor] - Running task 3.0 in stage 15.0 (TID 47)
2021-12-08 15:53:46,571 [Executor task launch worker for task 46] INFO [org.apache.spark.executor.Executor] - Running task 2.0 in stage 15.0 (TID 46)
2021-12-08 15:53:46,571 [Executor task launch worker for task 45] INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 15.0 (TID 45)
2021-12-08 15:53:46,571 [Executor task launch worker for task 49] INFO [org.apache.spark.executor.Executor] - Running task 5.0 in stage 15.0 (TID 49)
2021-12-08 15:53:46,571 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_14 stored as values in memory (estimated size 4.0 KB, free 1990.1 MB)
2021-12-08 15:53:46,573 [Executor task launch worker for task 44] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/handle_data/device_video_data/part-00000:0+3904159
2021-12-08 15:53:46,573 [Executor task launch worker for task 48] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/handle_data/device_video_data/part-00004:0+3818189
2021-12-08 15:53:46,573 [Executor task launch worker for task 46] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/handle_data/device_video_data/part-00002:0+7537224
2021-12-08 15:53:46,573 [Executor task launch worker for task 45] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/handle_data/device_video_data/part-00001:0+7544772
2021-12-08 15:53:46,573 [Executor task launch worker for task 47] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/handle_data/device_video_data/part-00003:0+7644414
2021-12-08 15:53:46,573 [Executor task launch worker for task 49] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/handle_data/device_video_data/part-00005:0+7196304
2021-12-08 15:53:46,574 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_14_piece0 stored as bytes in memory (estimated size 2.3 KB, free 1990.1 MB)
2021-12-08 15:53:46,575 [dispatcher-event-loop-8] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_14_piece0 in memory on qb:62937 (size: 2.3 KB, free: 1990.7 MB)
2021-12-08 15:53:46,575 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 14 from broadcast at DAGScheduler.scala:1039
2021-12-08 15:53:46,575 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ShuffleMapStage 16 (ZippedWithIndexRDD[26] at zipWithIndex at PaidPromotionAdjustParameter.scala:278) (first 15 tasks are for partitions Vector(0))
2021-12-08 15:53:46,575 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 16.0 with 1 tasks
2021-12-08 15:53:46,576 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ShuffleMapStage 18 (ZippedWithIndexRDD[26] at zipWithIndex at PaidPromotionAdjustParameter.scala:278), which has no missing parents
2021-12-08 15:53:46,576 [dispatcher-event-loop-7] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 16.0 (TID 50, localhost, executor driver, partition 0, ANY, 7748 bytes)
2021-12-08 15:53:46,576 [Executor task launch worker for task 50] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 16.0 (TID 50)
2021-12-08 15:53:46,577 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_15 stored as values in memory (estimated size 4.0 KB, free 1990.1 MB)
2021-12-08 15:53:46,578 [Executor task launch worker for task 50] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 8 non-empty blocks out of 8 blocks
2021-12-08 15:53:46,578 [Executor task launch worker for task 50] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 1 ms
2021-12-08 15:53:46,579 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_15_piece0 stored as bytes in memory (estimated size 2.3 KB, free 1990.1 MB)
2021-12-08 15:53:46,580 [dispatcher-event-loop-1] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_15_piece0 in memory on qb:62937 (size: 2.3 KB, free: 1990.7 MB)
2021-12-08 15:53:46,580 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 15 from broadcast at DAGScheduler.scala:1039
2021-12-08 15:53:46,580 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ShuffleMapStage 18 (ZippedWithIndexRDD[26] at zipWithIndex at PaidPromotionAdjustParameter.scala:278) (first 15 tasks are for partitions Vector(0))
2021-12-08 15:53:46,580 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 18.0 with 1 tasks
2021-12-08 15:53:46,581 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ShuffleMapStage 19 (MapPartitionsRDD[4] at map at PaidPromotionAdjustParameter.scala:241), which has no missing parents
2021-12-08 15:53:46,581 [dispatcher-event-loop-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 18.0 (TID 51, localhost, executor driver, partition 0, ANY, 7748 bytes)
2021-12-08 15:53:46,581 [Executor task launch worker for task 51] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 18.0 (TID 51)
2021-12-08 15:53:46,582 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_16 stored as values in memory (estimated size 4.5 KB, free 1990.1 MB)
2021-12-08 15:53:46,583 [Executor task launch worker for task 51] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 8 non-empty blocks out of 8 blocks
2021-12-08 15:53:46,583 [Executor task launch worker for task 51] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-08 15:53:46,584 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_16_piece0 stored as bytes in memory (estimated size 2.7 KB, free 1990.1 MB)
2021-12-08 15:53:46,584 [dispatcher-event-loop-10] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_16_piece0 in memory on qb:62937 (size: 2.7 KB, free: 1990.7 MB)
2021-12-08 15:53:46,585 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 16 from broadcast at DAGScheduler.scala:1039
2021-12-08 15:53:46,585 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from ShuffleMapStage 19 (MapPartitionsRDD[4] at map at PaidPromotionAdjustParameter.scala:241) (first 15 tasks are for partitions Vector(0, 1))
2021-12-08 15:53:46,585 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 19.0 with 2 tasks
2021-12-08 15:53:46,586 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ShuffleMapStage 22 (ZippedWithIndexRDD[9] at zipWithIndex at PaidPromotionAdjustParameter.scala:250), which has no missing parents
2021-12-08 15:53:46,586 [dispatcher-event-loop-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 19.0 (TID 52, localhost, executor driver, partition 0, ANY, 7921 bytes)
2021-12-08 15:53:46,586 [dispatcher-event-loop-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 19.0 (TID 53, localhost, executor driver, partition 1, ANY, 7921 bytes)
2021-12-08 15:53:46,586 [Executor task launch worker for task 53] INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 19.0 (TID 53)
2021-12-08 15:53:46,586 [Executor task launch worker for task 52] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 19.0 (TID 52)
2021-12-08 15:53:46,587 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_17 stored as values in memory (estimated size 4.0 KB, free 1990.1 MB)
2021-12-08 15:53:46,587 [Executor task launch worker for task 52] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/handle_data/set-train-device-production-data/part-00000:0+3237750
2021-12-08 15:53:46,587 [Executor task launch worker for task 53] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/handle_data/set-train-device-production-data/part-00000:3237750+3237751
2021-12-08 15:53:46,589 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_17_piece0 stored as bytes in memory (estimated size 2.3 KB, free 1990.1 MB)
2021-12-08 15:53:46,589 [dispatcher-event-loop-5] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_17_piece0 in memory on qb:62937 (size: 2.3 KB, free: 1990.7 MB)
2021-12-08 15:53:46,590 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 17 from broadcast at DAGScheduler.scala:1039
2021-12-08 15:53:46,591 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 3 missing tasks from ShuffleMapStage 22 (ZippedWithIndexRDD[9] at zipWithIndex at PaidPromotionAdjustParameter.scala:250) (first 15 tasks are for partitions Vector(0, 1, 2))
2021-12-08 15:53:46,591 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 22.0 with 3 tasks
2021-12-08 15:53:46,591 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ShuffleMapStage 24 (MapPartitionsRDD[19] at map at PaidPromotionAdjustParameter.scala:272), which has no missing parents
2021-12-08 15:53:46,591 [dispatcher-event-loop-6] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 22.0 (TID 54, localhost, executor driver, partition 0, ANY, 7748 bytes)
2021-12-08 15:53:46,592 [dispatcher-event-loop-6] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 22.0 (TID 55, localhost, executor driver, partition 1, ANY, 7748 bytes)
2021-12-08 15:53:46,592 [Executor task launch worker for task 54] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 22.0 (TID 54)
2021-12-08 15:53:46,592 [Executor task launch worker for task 55] INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 22.0 (TID 55)
2021-12-08 15:53:46,593 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_18 stored as values in memory (estimated size 4.1 KB, free 1990.1 MB)
2021-12-08 15:53:46,593 [Executor task launch worker for task 55] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 2 non-empty blocks out of 2 blocks
2021-12-08 15:53:46,594 [Executor task launch worker for task 54] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 2 non-empty blocks out of 2 blocks
2021-12-08 15:53:46,594 [Executor task launch worker for task 55] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 1 ms
2021-12-08 15:53:46,594 [Executor task launch worker for task 54] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 1 ms
2021-12-08 15:53:46,596 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_18_piece0 stored as bytes in memory (estimated size 2.4 KB, free 1990.1 MB)
2021-12-08 15:53:46,597 [dispatcher-event-loop-11] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_18_piece0 in memory on qb:62937 (size: 2.4 KB, free: 1990.7 MB)
2021-12-08 15:53:46,598 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 18 from broadcast at DAGScheduler.scala:1039
2021-12-08 15:53:46,598 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 12 missing tasks from ShuffleMapStage 24 (MapPartitionsRDD[19] at map at PaidPromotionAdjustParameter.scala:272) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11))
2021-12-08 15:53:46,598 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 24.0 with 12 tasks
2021-12-08 15:53:46,617 [Executor task launch worker for task 55] INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 22.0 (TID 55). 1205 bytes result sent to driver
2021-12-08 15:53:46,618 [dispatcher-event-loop-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 2.0 in stage 22.0 (TID 56, localhost, executor driver, partition 2, ANY, 7748 bytes)
2021-12-08 15:53:46,618 [Executor task launch worker for task 56] INFO [org.apache.spark.executor.Executor] - Running task 2.0 in stage 22.0 (TID 56)
2021-12-08 15:53:46,618 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 22.0 (TID 55) in 26 ms on localhost (executor driver) (1/3)
2021-12-08 15:53:46,619 [Executor task launch worker for task 54] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 22.0 (TID 54). 1162 bytes result sent to driver
2021-12-08 15:53:46,619 [dispatcher-event-loop-10] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 24.0 (TID 57, localhost, executor driver, partition 0, ANY, 7748 bytes)
2021-12-08 15:53:46,620 [Executor task launch worker for task 56] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 2 non-empty blocks out of 2 blocks
2021-12-08 15:53:46,620 [Executor task launch worker for task 56] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 1 ms
2021-12-08 15:53:46,620 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 22.0 (TID 54) in 29 ms on localhost (executor driver) (2/3)
2021-12-08 15:53:46,620 [Executor task launch worker for task 57] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 24.0 (TID 57)
2021-12-08 15:53:46,622 [Executor task launch worker for task 57] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 6 non-empty blocks out of 6 blocks
2021-12-08 15:53:46,622 [Executor task launch worker for task 57] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-08 15:53:46,640 [Executor task launch worker for task 56] INFO [org.apache.spark.executor.Executor] - Finished task 2.0 in stage 22.0 (TID 56). 1162 bytes result sent to driver
2021-12-08 15:53:46,640 [dispatcher-event-loop-9] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 24.0 (TID 58, localhost, executor driver, partition 1, ANY, 7748 bytes)
2021-12-08 15:53:46,641 [Executor task launch worker for task 58] INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 24.0 (TID 58)
2021-12-08 15:53:46,641 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 2.0 in stage 22.0 (TID 56) in 23 ms on localhost (executor driver) (3/3)
2021-12-08 15:53:46,641 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 22.0, whose tasks have all completed, from pool 
2021-12-08 15:53:46,641 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ShuffleMapStage 22 (zipWithIndex at PaidPromotionAdjustParameter.scala:250) finished in 0.055 s
2021-12-08 15:53:46,641 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - looking for newly runnable stages
2021-12-08 15:53:46,641 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - running: Set(ShuffleMapStage 15, ShuffleMapStage 19, ShuffleMapStage 16, ShuffleMapStage 24, ShuffleMapStage 18)
2021-12-08 15:53:46,641 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - waiting: Set(ShuffleMapStage 20, ShuffleMapStage 17, ResultStage 25)
2021-12-08 15:53:46,641 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - failed: Set()
2021-12-08 15:53:46,642 [Executor task launch worker for task 58] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 6 non-empty blocks out of 6 blocks
2021-12-08 15:53:46,642 [Executor task launch worker for task 58] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-08 15:53:46,675 [Executor task launch worker for task 57] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 24.0 (TID 57). 1171 bytes result sent to driver
2021-12-08 15:53:46,676 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 24.0 (TID 57) in 57 ms on localhost (executor driver) (1/12)
2021-12-08 15:53:46,677 [dispatcher-event-loop-5] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 2.0 in stage 24.0 (TID 59, localhost, executor driver, partition 2, ANY, 7748 bytes)
2021-12-08 15:53:46,677 [Executor task launch worker for task 59] INFO [org.apache.spark.executor.Executor] - Running task 2.0 in stage 24.0 (TID 59)
2021-12-08 15:53:46,678 [Executor task launch worker for task 59] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 6 non-empty blocks out of 6 blocks
2021-12-08 15:53:46,678 [Executor task launch worker for task 59] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-08 15:53:46,691 [Executor task launch worker for task 58] INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 24.0 (TID 58). 1257 bytes result sent to driver
2021-12-08 15:53:46,691 [dispatcher-event-loop-6] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 3.0 in stage 24.0 (TID 60, localhost, executor driver, partition 3, ANY, 7748 bytes)
2021-12-08 15:53:46,692 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 24.0 (TID 58) in 52 ms on localhost (executor driver) (2/12)
2021-12-08 15:53:46,692 [Executor task launch worker for task 60] INFO [org.apache.spark.executor.Executor] - Running task 3.0 in stage 24.0 (TID 60)
2021-12-08 15:53:46,693 [Executor task launch worker for task 60] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 6 non-empty blocks out of 6 blocks
2021-12-08 15:53:46,693 [Executor task launch worker for task 60] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-08 15:53:46,719 [Executor task launch worker for task 59] INFO [org.apache.spark.executor.Executor] - Finished task 2.0 in stage 24.0 (TID 59). 1171 bytes result sent to driver
2021-12-08 15:53:46,720 [dispatcher-event-loop-11] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 4.0 in stage 24.0 (TID 61, localhost, executor driver, partition 4, ANY, 7748 bytes)
2021-12-08 15:53:46,720 [Executor task launch worker for task 61] INFO [org.apache.spark.executor.Executor] - Running task 4.0 in stage 24.0 (TID 61)
2021-12-08 15:53:46,720 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 2.0 in stage 24.0 (TID 59) in 43 ms on localhost (executor driver) (3/12)
2021-12-08 15:53:46,721 [Executor task launch worker for task 61] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 6 non-empty blocks out of 6 blocks
2021-12-08 15:53:46,721 [Executor task launch worker for task 61] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-08 15:53:46,729 [Executor task launch worker for task 60] INFO [org.apache.spark.executor.Executor] - Finished task 3.0 in stage 24.0 (TID 60). 1171 bytes result sent to driver
2021-12-08 15:53:46,730 [dispatcher-event-loop-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 5.0 in stage 24.0 (TID 62, localhost, executor driver, partition 5, ANY, 7748 bytes)
2021-12-08 15:53:46,730 [Executor task launch worker for task 62] INFO [org.apache.spark.executor.Executor] - Running task 5.0 in stage 24.0 (TID 62)
2021-12-08 15:53:46,730 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 3.0 in stage 24.0 (TID 60) in 39 ms on localhost (executor driver) (4/12)
2021-12-08 15:53:46,731 [Executor task launch worker for task 62] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 6 non-empty blocks out of 6 blocks
2021-12-08 15:53:46,731 [Executor task launch worker for task 62] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-08 15:53:46,758 [Executor task launch worker for task 61] INFO [org.apache.spark.executor.Executor] - Finished task 4.0 in stage 24.0 (TID 61). 1214 bytes result sent to driver
2021-12-08 15:53:46,758 [dispatcher-event-loop-10] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 6.0 in stage 24.0 (TID 63, localhost, executor driver, partition 6, ANY, 7748 bytes)
2021-12-08 15:53:46,758 [Executor task launch worker for task 63] INFO [org.apache.spark.executor.Executor] - Running task 6.0 in stage 24.0 (TID 63)
2021-12-08 15:53:46,758 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 4.0 in stage 24.0 (TID 61) in 39 ms on localhost (executor driver) (5/12)
2021-12-08 15:53:46,759 [Executor task launch worker for task 63] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 6 non-empty blocks out of 6 blocks
2021-12-08 15:53:46,759 [Executor task launch worker for task 63] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-08 15:53:46,765 [Executor task launch worker for task 62] INFO [org.apache.spark.executor.Executor] - Finished task 5.0 in stage 24.0 (TID 62). 1214 bytes result sent to driver
2021-12-08 15:53:46,765 [dispatcher-event-loop-9] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 7.0 in stage 24.0 (TID 64, localhost, executor driver, partition 7, ANY, 7748 bytes)
2021-12-08 15:53:46,765 [Executor task launch worker for task 64] INFO [org.apache.spark.executor.Executor] - Running task 7.0 in stage 24.0 (TID 64)
2021-12-08 15:53:46,765 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 5.0 in stage 24.0 (TID 62) in 35 ms on localhost (executor driver) (6/12)
2021-12-08 15:53:46,766 [Executor task launch worker for task 64] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 6 non-empty blocks out of 6 blocks
2021-12-08 15:53:46,766 [Executor task launch worker for task 64] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-08 15:53:46,803 [Executor task launch worker for task 63] INFO [org.apache.spark.executor.Executor] - Finished task 6.0 in stage 24.0 (TID 63). 1171 bytes result sent to driver
2021-12-08 15:53:46,804 [dispatcher-event-loop-5] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 8.0 in stage 24.0 (TID 65, localhost, executor driver, partition 8, ANY, 7748 bytes)
2021-12-08 15:53:46,804 [Executor task launch worker for task 65] INFO [org.apache.spark.executor.Executor] - Running task 8.0 in stage 24.0 (TID 65)
2021-12-08 15:53:46,804 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 6.0 in stage 24.0 (TID 63) in 46 ms on localhost (executor driver) (7/12)
2021-12-08 15:53:46,805 [Executor task launch worker for task 65] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 6 non-empty blocks out of 6 blocks
2021-12-08 15:53:46,806 [Executor task launch worker for task 65] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 1 ms
2021-12-08 15:53:46,807 [Executor task launch worker for task 64] INFO [org.apache.spark.executor.Executor] - Finished task 7.0 in stage 24.0 (TID 64). 1214 bytes result sent to driver
2021-12-08 15:53:46,807 [dispatcher-event-loop-6] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 9.0 in stage 24.0 (TID 66, localhost, executor driver, partition 9, ANY, 7748 bytes)
2021-12-08 15:53:46,807 [Executor task launch worker for task 66] INFO [org.apache.spark.executor.Executor] - Running task 9.0 in stage 24.0 (TID 66)
2021-12-08 15:53:46,807 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 7.0 in stage 24.0 (TID 64) in 42 ms on localhost (executor driver) (8/12)
2021-12-08 15:53:46,808 [Executor task launch worker for task 66] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 6 non-empty blocks out of 6 blocks
2021-12-08 15:53:46,808 [Executor task launch worker for task 66] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-08 15:53:46,840 [dispatcher-event-loop-2] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_17_piece0 on qb:62937 in memory (size: 2.3 KB, free: 1990.7 MB)
2021-12-08 15:53:46,842 [dispatcher-event-loop-10] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_12_piece0 on qb:62937 in memory (size: 2.2 KB, free: 1990.7 MB)
2021-12-08 15:53:46,844 [dispatcher-event-loop-5] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_11_piece0 on qb:62937 in memory (size: 3.3 KB, free: 1990.7 MB)
2021-12-08 15:53:46,860 [Executor task launch worker for task 65] INFO [org.apache.spark.executor.Executor] - Finished task 8.0 in stage 24.0 (TID 65). 1257 bytes result sent to driver
2021-12-08 15:53:46,861 [dispatcher-event-loop-8] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 10.0 in stage 24.0 (TID 67, localhost, executor driver, partition 10, ANY, 7748 bytes)
2021-12-08 15:53:46,861 [Executor task launch worker for task 67] INFO [org.apache.spark.executor.Executor] - Running task 10.0 in stage 24.0 (TID 67)
2021-12-08 15:53:46,861 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 8.0 in stage 24.0 (TID 65) in 57 ms on localhost (executor driver) (9/12)
2021-12-08 15:53:46,861 [Executor task launch worker for task 66] INFO [org.apache.spark.executor.Executor] - Finished task 9.0 in stage 24.0 (TID 66). 1214 bytes result sent to driver
2021-12-08 15:53:46,863 [Executor task launch worker for task 67] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 6 non-empty blocks out of 6 blocks
2021-12-08 15:53:46,863 [Executor task launch worker for task 67] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-08 15:53:46,863 [dispatcher-event-loop-6] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 11.0 in stage 24.0 (TID 68, localhost, executor driver, partition 11, ANY, 7748 bytes)
2021-12-08 15:53:46,863 [Executor task launch worker for task 68] INFO [org.apache.spark.executor.Executor] - Running task 11.0 in stage 24.0 (TID 68)
2021-12-08 15:53:46,863 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 9.0 in stage 24.0 (TID 66) in 56 ms on localhost (executor driver) (10/12)
2021-12-08 15:53:46,864 [Executor task launch worker for task 68] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 6 non-empty blocks out of 6 blocks
2021-12-08 15:53:46,864 [Executor task launch worker for task 68] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-08 15:53:46,870 [Executor task launch worker for task 51] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 18.0 (TID 51). 1247 bytes result sent to driver
2021-12-08 15:53:46,871 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 18.0 (TID 51) in 290 ms on localhost (executor driver) (1/1)
2021-12-08 15:53:46,871 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 18.0, whose tasks have all completed, from pool 
2021-12-08 15:53:46,871 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ShuffleMapStage 18 (zipWithIndex at PaidPromotionAdjustParameter.scala:278) finished in 0.295 s
2021-12-08 15:53:46,871 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - looking for newly runnable stages
2021-12-08 15:53:46,871 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - running: Set(ShuffleMapStage 15, ShuffleMapStage 19, ShuffleMapStage 16, ShuffleMapStage 24)
2021-12-08 15:53:46,871 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - waiting: Set(ShuffleMapStage 20, ShuffleMapStage 17, ResultStage 25)
2021-12-08 15:53:46,871 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - failed: Set()
2021-12-08 15:53:46,893 [Executor task launch worker for task 67] INFO [org.apache.spark.executor.Executor] - Finished task 10.0 in stage 24.0 (TID 67). 1171 bytes result sent to driver
2021-12-08 15:53:46,894 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 10.0 in stage 24.0 (TID 67) in 33 ms on localhost (executor driver) (11/12)
2021-12-08 15:53:46,897 [Executor task launch worker for task 68] INFO [org.apache.spark.executor.Executor] - Finished task 11.0 in stage 24.0 (TID 68). 1214 bytes result sent to driver
2021-12-08 15:53:46,898 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 11.0 in stage 24.0 (TID 68) in 35 ms on localhost (executor driver) (12/12)
2021-12-08 15:53:46,898 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 24.0, whose tasks have all completed, from pool 
2021-12-08 15:53:46,898 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ShuffleMapStage 24 (map at PaidPromotionAdjustParameter.scala:272) finished in 0.305 s
2021-12-08 15:53:46,898 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - looking for newly runnable stages
2021-12-08 15:53:46,898 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - running: Set(ShuffleMapStage 15, ShuffleMapStage 19, ShuffleMapStage 16)
2021-12-08 15:53:46,898 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - waiting: Set(ShuffleMapStage 20, ShuffleMapStage 17, ResultStage 25)
2021-12-08 15:53:46,898 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - failed: Set()
2021-12-08 15:53:46,904 [Executor task launch worker for task 50] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 16.0 (TID 50). 1208 bytes result sent to driver
2021-12-08 15:53:46,905 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 16.0 (TID 50) in 329 ms on localhost (executor driver) (1/1)
2021-12-08 15:53:46,905 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 16.0, whose tasks have all completed, from pool 
2021-12-08 15:53:46,905 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ShuffleMapStage 16 (zipWithIndex at PaidPromotionAdjustParameter.scala:278) finished in 0.334 s
2021-12-08 15:53:46,905 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - looking for newly runnable stages
2021-12-08 15:53:46,905 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - running: Set(ShuffleMapStage 15, ShuffleMapStage 19)
2021-12-08 15:53:46,905 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - waiting: Set(ShuffleMapStage 20, ShuffleMapStage 17, ResultStage 25)
2021-12-08 15:53:46,905 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - failed: Set()
2021-12-08 15:53:48,248 [dispatcher-event-loop-4] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_14_piece0 on qb:62937 in memory (size: 2.3 KB, free: 1990.7 MB)
2021-12-08 15:53:48,249 [dispatcher-event-loop-7] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_15_piece0 on qb:62937 in memory (size: 2.3 KB, free: 1990.7 MB)
2021-12-08 15:53:48,250 [dispatcher-event-loop-1] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_18_piece0 on qb:62937 in memory (size: 2.4 KB, free: 1990.7 MB)
2021-12-08 15:53:48,330 [Executor task launch worker for task 48] INFO [org.apache.spark.executor.Executor] - Finished task 4.0 in stage 15.0 (TID 48). 864 bytes result sent to driver
2021-12-08 15:53:48,330 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 4.0 in stage 15.0 (TID 48) in 1759 ms on localhost (executor driver) (1/6)
2021-12-08 15:53:49,281 [Executor task launch worker for task 44] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 15.0 (TID 44). 864 bytes result sent to driver
2021-12-08 15:53:49,281 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 15.0 (TID 44) in 2711 ms on localhost (executor driver) (2/6)
2021-12-08 15:53:49,341 [Executor task launch worker for task 52] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 19.0 (TID 52). 903 bytes result sent to driver
2021-12-08 15:53:49,342 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 19.0 (TID 52) in 2756 ms on localhost (executor driver) (1/2)
2021-12-08 15:53:49,545 [Executor task launch worker for task 47] INFO [org.apache.spark.executor.Executor] - Finished task 3.0 in stage 15.0 (TID 47). 864 bytes result sent to driver
2021-12-08 15:53:49,545 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 3.0 in stage 15.0 (TID 47) in 2974 ms on localhost (executor driver) (3/6)
2021-12-08 15:53:49,878 [Executor task launch worker for task 49] INFO [org.apache.spark.executor.Executor] - Finished task 5.0 in stage 15.0 (TID 49). 864 bytes result sent to driver
2021-12-08 15:53:49,879 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 5.0 in stage 15.0 (TID 49) in 3308 ms on localhost (executor driver) (4/6)
2021-12-08 15:53:49,928 [Executor task launch worker for task 53] INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 19.0 (TID 53). 903 bytes result sent to driver
2021-12-08 15:53:49,929 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 19.0 (TID 53) in 3343 ms on localhost (executor driver) (2/2)
2021-12-08 15:53:49,929 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 19.0, whose tasks have all completed, from pool 
2021-12-08 15:53:49,929 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ShuffleMapStage 19 (map at PaidPromotionAdjustParameter.scala:241) finished in 3.348 s
2021-12-08 15:53:49,929 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - looking for newly runnable stages
2021-12-08 15:53:49,929 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - running: Set(ShuffleMapStage 15)
2021-12-08 15:53:49,929 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - waiting: Set(ShuffleMapStage 20, ShuffleMapStage 17, ResultStage 25)
2021-12-08 15:53:49,929 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - failed: Set()
2021-12-08 15:53:49,929 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ShuffleMapStage 20 (MapPartitionsRDD[30] at map at PaidPromotionAdjustParameter.scala:286), which has no missing parents
2021-12-08 15:53:49,931 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_19 stored as values in memory (estimated size 3.6 KB, free 1990.1 MB)
2021-12-08 15:53:49,933 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_19_piece0 stored as bytes in memory (estimated size 2.1 KB, free 1990.1 MB)
2021-12-08 15:53:49,934 [dispatcher-event-loop-8] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_19_piece0 in memory on qb:62937 (size: 2.1 KB, free: 1990.7 MB)
2021-12-08 15:53:49,934 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 19 from broadcast at DAGScheduler.scala:1039
2021-12-08 15:53:49,934 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from ShuffleMapStage 20 (MapPartitionsRDD[30] at map at PaidPromotionAdjustParameter.scala:286) (first 15 tasks are for partitions Vector(0, 1))
2021-12-08 15:53:49,934 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 20.0 with 2 tasks
2021-12-08 15:53:49,935 [dispatcher-event-loop-5] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 20.0 (TID 69, localhost, executor driver, partition 0, PROCESS_LOCAL, 7701 bytes)
2021-12-08 15:53:49,935 [dispatcher-event-loop-5] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 20.0 (TID 70, localhost, executor driver, partition 1, PROCESS_LOCAL, 7701 bytes)
2021-12-08 15:53:49,935 [Executor task launch worker for task 69] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 20.0 (TID 69)
2021-12-08 15:53:49,935 [Executor task launch worker for task 70] INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 20.0 (TID 70)
2021-12-08 15:53:49,938 [Executor task launch worker for task 69] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 2 non-empty blocks out of 2 blocks
2021-12-08 15:53:49,938 [Executor task launch worker for task 70] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 2 non-empty blocks out of 2 blocks
2021-12-08 15:53:49,938 [Executor task launch worker for task 70] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-08 15:53:49,938 [Executor task launch worker for task 69] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-08 15:53:49,940 [Executor task launch worker for task 69] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 1 blocks
2021-12-08 15:53:49,940 [Executor task launch worker for task 70] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 1 blocks
2021-12-08 15:53:49,941 [Executor task launch worker for task 69] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 1 ms
2021-12-08 15:53:49,941 [Executor task launch worker for task 70] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 1 ms
2021-12-08 15:53:49,946 [dispatcher-event-loop-2] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_16_piece0 on qb:62937 in memory (size: 2.7 KB, free: 1990.7 MB)
2021-12-08 15:53:50,219 [Executor task launch worker for task 69] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 20.0 (TID 69). 1248 bytes result sent to driver
2021-12-08 15:53:50,219 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 20.0 (TID 69) in 285 ms on localhost (executor driver) (1/2)
2021-12-08 15:53:50,220 [Executor task launch worker for task 70] INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 20.0 (TID 70). 1248 bytes result sent to driver
2021-12-08 15:53:50,220 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 20.0 (TID 70) in 285 ms on localhost (executor driver) (2/2)
2021-12-08 15:53:50,220 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 20.0, whose tasks have all completed, from pool 
2021-12-08 15:53:50,220 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ShuffleMapStage 20 (map at PaidPromotionAdjustParameter.scala:286) finished in 0.290 s
2021-12-08 15:53:50,220 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - looking for newly runnable stages
2021-12-08 15:53:50,220 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - running: Set(ShuffleMapStage 15)
2021-12-08 15:53:50,220 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - waiting: Set(ShuffleMapStage 17, ResultStage 25)
2021-12-08 15:53:50,220 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - failed: Set()
2021-12-08 15:53:50,556 [Executor task launch worker for task 46] INFO [org.apache.spark.executor.Executor] - Finished task 2.0 in stage 15.0 (TID 46). 864 bytes result sent to driver
2021-12-08 15:53:50,557 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 2.0 in stage 15.0 (TID 46) in 3987 ms on localhost (executor driver) (5/6)
2021-12-08 15:53:50,616 [Executor task launch worker for task 45] INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 15.0 (TID 45). 864 bytes result sent to driver
2021-12-08 15:53:50,616 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 15.0 (TID 45) in 4046 ms on localhost (executor driver) (6/6)
2021-12-08 15:53:50,616 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 15.0, whose tasks have all completed, from pool 
2021-12-08 15:53:50,616 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ShuffleMapStage 15 (map at PaidPromotionAdjustParameter.scala:262) finished in 4.051 s
2021-12-08 15:53:50,616 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - looking for newly runnable stages
2021-12-08 15:53:50,616 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - running: Set()
2021-12-08 15:53:50,616 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - waiting: Set(ShuffleMapStage 17, ResultStage 25)
2021-12-08 15:53:50,616 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - failed: Set()
2021-12-08 15:53:50,617 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ShuffleMapStage 17 (MapPartitionsRDD[39] at map at PaidPromotionAdjustParameter.scala:295), which has no missing parents
2021-12-08 15:53:50,617 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_20 stored as values in memory (estimated size 3.6 KB, free 1990.1 MB)
2021-12-08 15:53:50,619 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_20_piece0 stored as bytes in memory (estimated size 2.1 KB, free 1990.1 MB)
2021-12-08 15:53:50,619 [dispatcher-event-loop-4] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_20_piece0 in memory on qb:62937 (size: 2.1 KB, free: 1990.7 MB)
2021-12-08 15:53:50,619 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 20 from broadcast at DAGScheduler.scala:1039
2021-12-08 15:53:50,620 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 6 missing tasks from ShuffleMapStage 17 (MapPartitionsRDD[39] at map at PaidPromotionAdjustParameter.scala:295) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5))
2021-12-08 15:53:50,620 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 17.0 with 6 tasks
2021-12-08 15:53:50,620 [dispatcher-event-loop-8] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 17.0 (TID 71, localhost, executor driver, partition 0, PROCESS_LOCAL, 7701 bytes)
2021-12-08 15:53:50,620 [dispatcher-event-loop-8] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 17.0 (TID 72, localhost, executor driver, partition 1, PROCESS_LOCAL, 7701 bytes)
2021-12-08 15:53:50,620 [dispatcher-event-loop-8] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 2.0 in stage 17.0 (TID 73, localhost, executor driver, partition 2, PROCESS_LOCAL, 7701 bytes)
2021-12-08 15:53:50,620 [dispatcher-event-loop-8] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 3.0 in stage 17.0 (TID 74, localhost, executor driver, partition 3, PROCESS_LOCAL, 7701 bytes)
2021-12-08 15:53:50,620 [dispatcher-event-loop-8] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 4.0 in stage 17.0 (TID 75, localhost, executor driver, partition 4, PROCESS_LOCAL, 7701 bytes)
2021-12-08 15:53:50,620 [dispatcher-event-loop-8] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 5.0 in stage 17.0 (TID 76, localhost, executor driver, partition 5, PROCESS_LOCAL, 7701 bytes)
2021-12-08 15:53:50,621 [Executor task launch worker for task 73] INFO [org.apache.spark.executor.Executor] - Running task 2.0 in stage 17.0 (TID 73)
2021-12-08 15:53:50,621 [Executor task launch worker for task 72] INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 17.0 (TID 72)
2021-12-08 15:53:50,621 [Executor task launch worker for task 74] INFO [org.apache.spark.executor.Executor] - Running task 3.0 in stage 17.0 (TID 74)
2021-12-08 15:53:50,621 [Executor task launch worker for task 71] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 17.0 (TID 71)
2021-12-08 15:53:50,621 [Executor task launch worker for task 75] INFO [org.apache.spark.executor.Executor] - Running task 4.0 in stage 17.0 (TID 75)
2021-12-08 15:53:50,621 [Executor task launch worker for task 76] INFO [org.apache.spark.executor.Executor] - Running task 5.0 in stage 17.0 (TID 76)
2021-12-08 15:53:50,622 [Executor task launch worker for task 76] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 6 non-empty blocks out of 6 blocks
2021-12-08 15:53:50,622 [Executor task launch worker for task 74] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 6 non-empty blocks out of 6 blocks
2021-12-08 15:53:50,622 [Executor task launch worker for task 74] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-08 15:53:50,622 [Executor task launch worker for task 76] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-08 15:53:50,622 [Executor task launch worker for task 71] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 6 non-empty blocks out of 6 blocks
2021-12-08 15:53:50,622 [Executor task launch worker for task 72] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 6 non-empty blocks out of 6 blocks
2021-12-08 15:53:50,622 [Executor task launch worker for task 73] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 6 non-empty blocks out of 6 blocks
2021-12-08 15:53:50,622 [Executor task launch worker for task 75] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 6 non-empty blocks out of 6 blocks
2021-12-08 15:53:50,622 [Executor task launch worker for task 71] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-08 15:53:50,622 [Executor task launch worker for task 75] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-08 15:53:50,622 [Executor task launch worker for task 73] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-08 15:53:50,622 [Executor task launch worker for task 72] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-08 15:53:50,625 [Executor task launch worker for task 76] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 1 blocks
2021-12-08 15:53:50,625 [Executor task launch worker for task 74] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 1 blocks
2021-12-08 15:53:50,626 [Executor task launch worker for task 76] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 1 ms
2021-12-08 15:53:50,626 [Executor task launch worker for task 74] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 1 ms
2021-12-08 15:53:50,626 [Executor task launch worker for task 73] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 1 blocks
2021-12-08 15:53:50,626 [Executor task launch worker for task 73] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-08 15:53:50,626 [Executor task launch worker for task 71] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 1 blocks
2021-12-08 15:53:50,626 [Executor task launch worker for task 71] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-08 15:53:50,626 [Executor task launch worker for task 75] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 1 blocks
2021-12-08 15:53:50,626 [Executor task launch worker for task 75] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-08 15:53:50,626 [Executor task launch worker for task 72] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 1 blocks
2021-12-08 15:53:50,626 [Executor task launch worker for task 72] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-08 15:53:50,695 [dispatcher-event-loop-9] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_13_piece0 on qb:62937 in memory (size: 2.7 KB, free: 1990.7 MB)
2021-12-08 15:53:50,696 [dispatcher-event-loop-8] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_19_piece0 on qb:62937 in memory (size: 2.1 KB, free: 1990.7 MB)
2021-12-08 15:53:51,388 [Executor task launch worker for task 73] INFO [org.apache.spark.executor.Executor] - Finished task 2.0 in stage 17.0 (TID 73). 1257 bytes result sent to driver
2021-12-08 15:53:51,388 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 2.0 in stage 17.0 (TID 73) in 768 ms on localhost (executor driver) (1/6)
2021-12-08 15:53:51,405 [Executor task launch worker for task 74] INFO [org.apache.spark.executor.Executor] - Finished task 3.0 in stage 17.0 (TID 74). 1214 bytes result sent to driver
2021-12-08 15:53:51,405 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 3.0 in stage 17.0 (TID 74) in 785 ms on localhost (executor driver) (2/6)
2021-12-08 15:53:51,410 [Executor task launch worker for task 75] INFO [org.apache.spark.executor.Executor] - Finished task 4.0 in stage 17.0 (TID 75). 1214 bytes result sent to driver
2021-12-08 15:53:51,411 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 4.0 in stage 17.0 (TID 75) in 791 ms on localhost (executor driver) (3/6)
2021-12-08 15:53:51,415 [Executor task launch worker for task 76] INFO [org.apache.spark.executor.Executor] - Finished task 5.0 in stage 17.0 (TID 76). 1214 bytes result sent to driver
2021-12-08 15:53:51,415 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 5.0 in stage 17.0 (TID 76) in 795 ms on localhost (executor driver) (4/6)
2021-12-08 15:53:51,420 [Executor task launch worker for task 72] INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 17.0 (TID 72). 1257 bytes result sent to driver
2021-12-08 15:53:51,420 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 17.0 (TID 72) in 800 ms on localhost (executor driver) (5/6)
2021-12-08 15:53:51,424 [Executor task launch worker for task 71] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 17.0 (TID 71). 1214 bytes result sent to driver
2021-12-08 15:53:51,425 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 17.0 (TID 71) in 805 ms on localhost (executor driver) (6/6)
2021-12-08 15:53:51,425 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 17.0, whose tasks have all completed, from pool 
2021-12-08 15:53:51,425 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ShuffleMapStage 17 (map at PaidPromotionAdjustParameter.scala:295) finished in 0.808 s
2021-12-08 15:53:51,425 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - looking for newly runnable stages
2021-12-08 15:53:51,425 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - running: Set()
2021-12-08 15:53:51,425 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - waiting: Set(ResultStage 25)
2021-12-08 15:53:51,425 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - failed: Set()
2021-12-08 15:53:51,425 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 25 (MapPartitionsRDD[48] at saveAsTextFile at PaidPromotionAdjustParameter.scala:308), which has no missing parents
2021-12-08 15:53:51,437 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_21 stored as values in memory (estimated size 81.5 KB, free 1990.1 MB)
2021-12-08 15:53:51,439 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_21_piece0 stored as bytes in memory (estimated size 31.2 KB, free 1990.0 MB)
2021-12-08 15:53:51,439 [dispatcher-event-loop-3] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_21_piece0 in memory on qb:62937 (size: 31.2 KB, free: 1990.7 MB)
2021-12-08 15:53:51,440 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 21 from broadcast at DAGScheduler.scala:1039
2021-12-08 15:53:51,440 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 10 missing tasks from ResultStage 25 (MapPartitionsRDD[48] at saveAsTextFile at PaidPromotionAdjustParameter.scala:308) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
2021-12-08 15:53:51,440 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 25.0 with 10 tasks
2021-12-08 15:53:51,442 [dispatcher-event-loop-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 25.0 (TID 77, localhost, executor driver, partition 0, PROCESS_LOCAL, 8097 bytes)
2021-12-08 15:53:51,442 [dispatcher-event-loop-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 25.0 (TID 78, localhost, executor driver, partition 1, PROCESS_LOCAL, 8146 bytes)
2021-12-08 15:53:51,442 [dispatcher-event-loop-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 2.0 in stage 25.0 (TID 79, localhost, executor driver, partition 2, PROCESS_LOCAL, 8097 bytes)
2021-12-08 15:53:51,442 [dispatcher-event-loop-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 3.0 in stage 25.0 (TID 80, localhost, executor driver, partition 3, PROCESS_LOCAL, 8146 bytes)
2021-12-08 15:53:51,443 [dispatcher-event-loop-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 4.0 in stage 25.0 (TID 81, localhost, executor driver, partition 4, PROCESS_LOCAL, 8097 bytes)
2021-12-08 15:53:51,443 [dispatcher-event-loop-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 5.0 in stage 25.0 (TID 82, localhost, executor driver, partition 5, PROCESS_LOCAL, 8146 bytes)
2021-12-08 15:53:51,443 [dispatcher-event-loop-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 6.0 in stage 25.0 (TID 83, localhost, executor driver, partition 6, PROCESS_LOCAL, 8097 bytes)
2021-12-08 15:53:51,443 [dispatcher-event-loop-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 7.0 in stage 25.0 (TID 84, localhost, executor driver, partition 7, PROCESS_LOCAL, 8146 bytes)
2021-12-08 15:53:51,443 [dispatcher-event-loop-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 8.0 in stage 25.0 (TID 85, localhost, executor driver, partition 8, PROCESS_LOCAL, 8097 bytes)
2021-12-08 15:53:51,443 [dispatcher-event-loop-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 9.0 in stage 25.0 (TID 86, localhost, executor driver, partition 9, PROCESS_LOCAL, 8146 bytes)
2021-12-08 15:53:51,443 [Executor task launch worker for task 77] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 25.0 (TID 77)
2021-12-08 15:53:51,443 [Executor task launch worker for task 81] INFO [org.apache.spark.executor.Executor] - Running task 4.0 in stage 25.0 (TID 81)
2021-12-08 15:53:51,443 [Executor task launch worker for task 82] INFO [org.apache.spark.executor.Executor] - Running task 5.0 in stage 25.0 (TID 82)
2021-12-08 15:53:51,443 [Executor task launch worker for task 80] INFO [org.apache.spark.executor.Executor] - Running task 3.0 in stage 25.0 (TID 80)
2021-12-08 15:53:51,443 [Executor task launch worker for task 79] INFO [org.apache.spark.executor.Executor] - Running task 2.0 in stage 25.0 (TID 79)
2021-12-08 15:53:51,443 [Executor task launch worker for task 86] INFO [org.apache.spark.executor.Executor] - Running task 9.0 in stage 25.0 (TID 86)
2021-12-08 15:53:51,443 [Executor task launch worker for task 83] INFO [org.apache.spark.executor.Executor] - Running task 6.0 in stage 25.0 (TID 83)
2021-12-08 15:53:51,443 [Executor task launch worker for task 84] INFO [org.apache.spark.executor.Executor] - Running task 7.0 in stage 25.0 (TID 84)
2021-12-08 15:53:51,443 [Executor task launch worker for task 78] INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 25.0 (TID 78)
2021-12-08 15:53:51,446 [Executor task launch worker for task 85] INFO [org.apache.spark.executor.Executor] - Running task 8.0 in stage 25.0 (TID 85)
2021-12-08 15:53:51,467 [Executor task launch worker for task 81] INFO [org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter] - File Output Committer Algorithm version is 1
2021-12-08 15:53:51,467 [Executor task launch worker for task 82] INFO [org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter] - File Output Committer Algorithm version is 1
2021-12-08 15:53:51,467 [Executor task launch worker for task 78] INFO [org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter] - File Output Committer Algorithm version is 1
2021-12-08 15:53:51,467 [Executor task launch worker for task 79] INFO [org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter] - File Output Committer Algorithm version is 1
2021-12-08 15:53:51,467 [Executor task launch worker for task 86] INFO [org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter] - File Output Committer Algorithm version is 1
2021-12-08 15:53:51,468 [Executor task launch worker for task 80] INFO [org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter] - File Output Committer Algorithm version is 1
2021-12-08 15:53:51,467 [Executor task launch worker for task 85] INFO [org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter] - File Output Committer Algorithm version is 1
2021-12-08 15:53:51,468 [Executor task launch worker for task 77] INFO [org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter] - File Output Committer Algorithm version is 1
2021-12-08 15:53:51,467 [Executor task launch worker for task 83] INFO [org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter] - File Output Committer Algorithm version is 1
2021-12-08 15:53:51,469 [Executor task launch worker for task 84] INFO [org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter] - File Output Committer Algorithm version is 1
2021-12-08 15:53:51,502 [Executor task launch worker for task 77] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 2 non-empty blocks out of 2 blocks
2021-12-08 15:53:51,502 [Executor task launch worker for task 85] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 6 non-empty blocks out of 6 blocks
2021-12-08 15:53:51,502 [Executor task launch worker for task 84] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 6 non-empty blocks out of 6 blocks
2021-12-08 15:53:51,502 [Executor task launch worker for task 78] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 2 non-empty blocks out of 2 blocks
2021-12-08 15:53:51,502 [Executor task launch worker for task 81] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 6 non-empty blocks out of 6 blocks
2021-12-08 15:53:51,502 [Executor task launch worker for task 86] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 6 non-empty blocks out of 6 blocks
2021-12-08 15:53:51,502 [Executor task launch worker for task 81] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-08 15:53:51,502 [Executor task launch worker for task 79] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 6 non-empty blocks out of 6 blocks
2021-12-08 15:53:51,502 [Executor task launch worker for task 78] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-08 15:53:51,502 [Executor task launch worker for task 82] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 6 non-empty blocks out of 6 blocks
2021-12-08 15:53:51,502 [Executor task launch worker for task 84] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-08 15:53:51,502 [Executor task launch worker for task 85] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-08 15:53:51,502 [Executor task launch worker for task 77] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-08 15:53:51,502 [Executor task launch worker for task 83] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 6 non-empty blocks out of 6 blocks
2021-12-08 15:53:51,502 [Executor task launch worker for task 80] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 6 non-empty blocks out of 6 blocks
2021-12-08 15:53:51,502 [Executor task launch worker for task 82] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-08 15:53:51,503 [Executor task launch worker for task 80] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 1 ms
2021-12-08 15:53:51,502 [Executor task launch worker for task 79] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-08 15:53:51,502 [Executor task launch worker for task 86] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-08 15:53:51,502 [Executor task launch worker for task 83] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-08 15:53:51,505 [Executor task launch worker for task 78] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 3 blocks
2021-12-08 15:53:51,505 [Executor task launch worker for task 78] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-08 15:53:51,505 [Executor task launch worker for task 77] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 3 blocks
2021-12-08 15:53:51,505 [Executor task launch worker for task 77] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-08 15:53:51,507 [Executor task launch worker for task 81] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 12 blocks
2021-12-08 15:53:51,507 [Executor task launch worker for task 81] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-08 15:53:51,507 [Executor task launch worker for task 80] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 12 blocks
2021-12-08 15:53:51,507 [Executor task launch worker for task 80] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-08 15:53:51,507 [Executor task launch worker for task 82] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 12 blocks
2021-12-08 15:53:51,508 [Executor task launch worker for task 82] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 1 ms
2021-12-08 15:53:51,508 [Executor task launch worker for task 83] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 12 blocks
2021-12-08 15:53:51,508 [Executor task launch worker for task 85] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 12 blocks
2021-12-08 15:53:51,508 [Executor task launch worker for task 85] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-08 15:53:51,508 [Executor task launch worker for task 83] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-08 15:53:51,508 [Executor task launch worker for task 79] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 12 blocks
2021-12-08 15:53:51,508 [Executor task launch worker for task 79] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-08 15:53:51,509 [Executor task launch worker for task 86] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 12 blocks
2021-12-08 15:53:51,509 [Executor task launch worker for task 86] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-08 15:53:51,509 [Executor task launch worker for task 84] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 12 blocks
2021-12-08 15:53:51,509 [Executor task launch worker for task 84] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-08 15:53:51,577 [dispatcher-event-loop-0] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_20_piece0 on qb:62937 in memory (size: 2.1 KB, free: 1990.7 MB)
2021-12-08 15:53:51,626 [Executor task launch worker for task 78] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 2 non-empty blocks out of 2 blocks
2021-12-08 15:53:51,626 [Executor task launch worker for task 78] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-08 15:53:51,630 [Executor task launch worker for task 78] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 3 blocks
2021-12-08 15:53:51,630 [Executor task launch worker for task 78] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-08 15:53:51,769 [Executor task launch worker for task 86] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 6 non-empty blocks out of 6 blocks
2021-12-08 15:53:51,769 [Executor task launch worker for task 86] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-08 15:53:51,770 [Executor task launch worker for task 84] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 6 non-empty blocks out of 6 blocks
2021-12-08 15:53:51,770 [Executor task launch worker for task 84] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-08 15:53:51,777 [Executor task launch worker for task 86] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 12 blocks
2021-12-08 15:53:51,777 [Executor task launch worker for task 86] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-08 15:53:51,808 [Executor task launch worker for task 84] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 12 blocks
2021-12-08 15:53:51,808 [Executor task launch worker for task 84] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-08 15:53:51,828 [Executor task launch worker for task 80] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 6 non-empty blocks out of 6 blocks
2021-12-08 15:53:51,828 [Executor task launch worker for task 80] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-08 15:53:51,832 [Executor task launch worker for task 82] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 6 non-empty blocks out of 6 blocks
2021-12-08 15:53:51,832 [Executor task launch worker for task 82] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-08 15:53:51,834 [Executor task launch worker for task 80] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 12 blocks
2021-12-08 15:53:51,834 [Executor task launch worker for task 80] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-08 15:53:51,843 [Executor task launch worker for task 82] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 12 blocks
2021-12-08 15:53:51,843 [Executor task launch worker for task 82] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-08 15:53:52,565 [Executor task launch worker for task 77] INFO [org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter] - Saved output of task 'attempt_20211208155346_0048_m_000000_0' to hdfs://hdp1:8020/sk/chongqing/model/input/rating/_temporary/0/task_20211208155346_0048_m_000000
2021-12-08 15:53:52,566 [Executor task launch worker for task 77] INFO [org.apache.spark.mapred.SparkHadoopMapRedUtil] - attempt_20211208155346_0048_m_000000_0: Committed
2021-12-08 15:53:52,568 [Executor task launch worker for task 77] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 25.0 (TID 77). 1385 bytes result sent to driver
2021-12-08 15:53:52,571 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 25.0 (TID 77) in 1131 ms on localhost (executor driver) (1/10)
2021-12-08 15:53:52,693 [Executor task launch worker for task 83] INFO [org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter] - Saved output of task 'attempt_20211208155346_0048_m_000006_0' to hdfs://hdp1:8020/sk/chongqing/model/input/rating/_temporary/0/task_20211208155346_0048_m_000006
2021-12-08 15:53:52,693 [Executor task launch worker for task 83] INFO [org.apache.spark.mapred.SparkHadoopMapRedUtil] - attempt_20211208155346_0048_m_000006_0: Committed
2021-12-08 15:53:52,695 [Executor task launch worker for task 83] INFO [org.apache.spark.executor.Executor] - Finished task 6.0 in stage 25.0 (TID 83). 1342 bytes result sent to driver
2021-12-08 15:53:52,696 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 6.0 in stage 25.0 (TID 83) in 1253 ms on localhost (executor driver) (2/10)
2021-12-08 15:53:52,711 [Executor task launch worker for task 85] INFO [org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter] - Saved output of task 'attempt_20211208155346_0048_m_000008_0' to hdfs://hdp1:8020/sk/chongqing/model/input/rating/_temporary/0/task_20211208155346_0048_m_000008
2021-12-08 15:53:52,711 [Executor task launch worker for task 85] INFO [org.apache.spark.mapred.SparkHadoopMapRedUtil] - attempt_20211208155346_0048_m_000008_0: Committed
2021-12-08 15:53:52,712 [Executor task launch worker for task 85] INFO [org.apache.spark.executor.Executor] - Finished task 8.0 in stage 25.0 (TID 85). 1299 bytes result sent to driver
2021-12-08 15:53:52,713 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 8.0 in stage 25.0 (TID 85) in 1270 ms on localhost (executor driver) (3/10)
2021-12-08 15:53:52,726 [Executor task launch worker for task 81] INFO [org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter] - Saved output of task 'attempt_20211208155346_0048_m_000004_0' to hdfs://hdp1:8020/sk/chongqing/model/input/rating/_temporary/0/task_20211208155346_0048_m_000004
2021-12-08 15:53:52,726 [Executor task launch worker for task 81] INFO [org.apache.spark.mapred.SparkHadoopMapRedUtil] - attempt_20211208155346_0048_m_000004_0: Committed
2021-12-08 15:53:52,727 [Executor task launch worker for task 81] INFO [org.apache.spark.executor.Executor] - Finished task 4.0 in stage 25.0 (TID 81). 1342 bytes result sent to driver
2021-12-08 15:53:52,728 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 4.0 in stage 25.0 (TID 81) in 1285 ms on localhost (executor driver) (4/10)
2021-12-08 15:53:52,751 [Executor task launch worker for task 78] INFO [org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter] - Saved output of task 'attempt_20211208155346_0048_m_000001_0' to hdfs://hdp1:8020/sk/chongqing/model/input/rating/_temporary/0/task_20211208155346_0048_m_000001
2021-12-08 15:53:52,751 [Executor task launch worker for task 78] INFO [org.apache.spark.mapred.SparkHadoopMapRedUtil] - attempt_20211208155346_0048_m_000001_0: Committed
2021-12-08 15:53:52,752 [Executor task launch worker for task 78] INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 25.0 (TID 78). 1342 bytes result sent to driver
2021-12-08 15:53:52,752 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 25.0 (TID 78) in 1310 ms on localhost (executor driver) (5/10)
2021-12-08 15:53:52,768 [Executor task launch worker for task 84] INFO [org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter] - Saved output of task 'attempt_20211208155346_0048_m_000007_0' to hdfs://hdp1:8020/sk/chongqing/model/input/rating/_temporary/0/task_20211208155346_0048_m_000007
2021-12-08 15:53:52,768 [Executor task launch worker for task 84] INFO [org.apache.spark.mapred.SparkHadoopMapRedUtil] - attempt_20211208155346_0048_m_000007_0: Committed
2021-12-08 15:53:52,769 [Executor task launch worker for task 84] INFO [org.apache.spark.executor.Executor] - Finished task 7.0 in stage 25.0 (TID 84). 1342 bytes result sent to driver
2021-12-08 15:53:52,770 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 7.0 in stage 25.0 (TID 84) in 1327 ms on localhost (executor driver) (6/10)
2021-12-08 15:53:52,782 [Executor task launch worker for task 86] INFO [org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter] - Saved output of task 'attempt_20211208155346_0048_m_000009_0' to hdfs://hdp1:8020/sk/chongqing/model/input/rating/_temporary/0/task_20211208155346_0048_m_000009
2021-12-08 15:53:52,782 [Executor task launch worker for task 86] INFO [org.apache.spark.mapred.SparkHadoopMapRedUtil] - attempt_20211208155346_0048_m_000009_0: Committed
2021-12-08 15:53:52,784 [Executor task launch worker for task 86] INFO [org.apache.spark.executor.Executor] - Finished task 9.0 in stage 25.0 (TID 86). 1342 bytes result sent to driver
2021-12-08 15:53:52,784 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 9.0 in stage 25.0 (TID 86) in 1341 ms on localhost (executor driver) (7/10)
2021-12-08 15:53:52,859 [Executor task launch worker for task 79] INFO [org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter] - Saved output of task 'attempt_20211208155346_0048_m_000002_0' to hdfs://hdp1:8020/sk/chongqing/model/input/rating/_temporary/0/task_20211208155346_0048_m_000002
2021-12-08 15:53:52,859 [Executor task launch worker for task 79] INFO [org.apache.spark.mapred.SparkHadoopMapRedUtil] - attempt_20211208155346_0048_m_000002_0: Committed
2021-12-08 15:53:52,860 [Executor task launch worker for task 79] INFO [org.apache.spark.executor.Executor] - Finished task 2.0 in stage 25.0 (TID 79). 1385 bytes result sent to driver
2021-12-08 15:53:52,860 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 2.0 in stage 25.0 (TID 79) in 1418 ms on localhost (executor driver) (8/10)
2021-12-08 15:53:52,867 [Executor task launch worker for task 82] INFO [org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter] - Saved output of task 'attempt_20211208155346_0048_m_000005_0' to hdfs://hdp1:8020/sk/chongqing/model/input/rating/_temporary/0/task_20211208155346_0048_m_000005
2021-12-08 15:53:52,867 [Executor task launch worker for task 82] INFO [org.apache.spark.mapred.SparkHadoopMapRedUtil] - attempt_20211208155346_0048_m_000005_0: Committed
2021-12-08 15:53:52,867 [Executor task launch worker for task 80] INFO [org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter] - Saved output of task 'attempt_20211208155346_0048_m_000003_0' to hdfs://hdp1:8020/sk/chongqing/model/input/rating/_temporary/0/task_20211208155346_0048_m_000003
2021-12-08 15:53:52,867 [Executor task launch worker for task 80] INFO [org.apache.spark.mapred.SparkHadoopMapRedUtil] - attempt_20211208155346_0048_m_000003_0: Committed
2021-12-08 15:53:52,868 [Executor task launch worker for task 82] INFO [org.apache.spark.executor.Executor] - Finished task 5.0 in stage 25.0 (TID 82). 1342 bytes result sent to driver
2021-12-08 15:53:52,868 [Executor task launch worker for task 80] INFO [org.apache.spark.executor.Executor] - Finished task 3.0 in stage 25.0 (TID 80). 1342 bytes result sent to driver
2021-12-08 15:53:52,869 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 5.0 in stage 25.0 (TID 82) in 1426 ms on localhost (executor driver) (9/10)
2021-12-08 15:53:52,869 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 3.0 in stage 25.0 (TID 80) in 1427 ms on localhost (executor driver) (10/10)
2021-12-08 15:53:52,869 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 25.0, whose tasks have all completed, from pool 
2021-12-08 15:53:52,869 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 25 (runJob at SparkHadoopWriter.scala:78) finished in 1.443 s
2021-12-08 15:53:52,869 [main] INFO [org.apache.spark.scheduler.DAGScheduler] - Job 7 finished: runJob at SparkHadoopWriter.scala:78, took 6.308344 s
2021-12-08 15:53:53,080 [main] INFO [org.apache.spark.internal.io.SparkHadoopWriter] - Job job_20211208155346_0048 committed.
2021-12-08 15:53:53,085 [main] INFO [org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter] - File Output Committer Algorithm version is 1
2021-12-08 15:53:53,130 [main] INFO [org.apache.spark.SparkContext] - Starting job: runJob at SparkHadoopWriter.scala:78
2021-12-08 15:53:53,130 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 8 (runJob at SparkHadoopWriter.scala:78) with 1 output partitions
2021-12-08 15:53:53,130 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 27 (runJob at SparkHadoopWriter.scala:78)
2021-12-08 15:53:53,130 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 26)
2021-12-08 15:53:53,130 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2021-12-08 15:53:53,131 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 27 (MapPartitionsRDD[51] at saveAsTextFile at PaidPromotionAdjustParameter.scala:309), which has no missing parents
2021-12-08 15:53:53,139 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_22 stored as values in memory (estimated size 80.5 KB, free 1989.9 MB)
2021-12-08 15:53:53,141 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_22_piece0 stored as bytes in memory (estimated size 30.8 KB, free 1989.9 MB)
2021-12-08 15:53:53,141 [dispatcher-event-loop-2] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_22_piece0 in memory on qb:62937 (size: 30.8 KB, free: 1990.7 MB)
2021-12-08 15:53:53,141 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 22 from broadcast at DAGScheduler.scala:1039
2021-12-08 15:53:53,142 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 27 (MapPartitionsRDD[51] at saveAsTextFile at PaidPromotionAdjustParameter.scala:309) (first 15 tasks are for partitions Vector(0))
2021-12-08 15:53:53,142 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 27.0 with 1 tasks
2021-12-08 15:53:53,142 [dispatcher-event-loop-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 27.0 (TID 87, localhost, executor driver, partition 0, ANY, 8107 bytes)
2021-12-08 15:53:53,142 [Executor task launch worker for task 87] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 27.0 (TID 87)
2021-12-08 15:53:53,146 [Executor task launch worker for task 87] INFO [org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter] - File Output Committer Algorithm version is 1
2021-12-08 15:53:53,152 [Executor task launch worker for task 87] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 2 non-empty blocks out of 2 blocks
2021-12-08 15:53:53,152 [Executor task launch worker for task 87] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-08 15:53:53,156 [Executor task launch worker for task 87] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 2 non-empty blocks out of 2 blocks
2021-12-08 15:53:53,156 [Executor task launch worker for task 87] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-08 15:53:53,158 [Executor task launch worker for task 87] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 2 non-empty blocks out of 2 blocks
2021-12-08 15:53:53,158 [Executor task launch worker for task 87] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-08 15:53:53,217 [Executor task launch worker for task 87] INFO [org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter] - Saved output of task 'attempt_20211208155353_0051_m_000000_0' to hdfs://hdp1:8020/sk/chongqing/model/input/productionWithIndex/_temporary/0/task_20211208155353_0051_m_000000
2021-12-08 15:53:53,217 [Executor task launch worker for task 87] INFO [org.apache.spark.mapred.SparkHadoopMapRedUtil] - attempt_20211208155353_0051_m_000000_0: Committed
2021-12-08 15:53:53,219 [Executor task launch worker for task 87] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 27.0 (TID 87). 1213 bytes result sent to driver
2021-12-08 15:53:53,219 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 27.0 (TID 87) in 77 ms on localhost (executor driver) (1/1)
2021-12-08 15:53:53,219 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 27.0, whose tasks have all completed, from pool 
2021-12-08 15:53:53,219 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 27 (runJob at SparkHadoopWriter.scala:78) finished in 0.088 s
2021-12-08 15:53:53,219 [main] INFO [org.apache.spark.scheduler.DAGScheduler] - Job 8 finished: runJob at SparkHadoopWriter.scala:78, took 0.090217 s
2021-12-08 15:53:53,269 [main] INFO [org.apache.spark.internal.io.SparkHadoopWriter] - Job job_20211208155353_0051 committed.
2021-12-08 15:53:53,273 [main] INFO [org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter] - File Output Committer Algorithm version is 1
2021-12-08 15:53:53,294 [main] INFO [org.apache.spark.SparkContext] - Starting job: runJob at SparkHadoopWriter.scala:78
2021-12-08 15:53:53,295 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 9 (runJob at SparkHadoopWriter.scala:78) with 1 output partitions
2021-12-08 15:53:53,295 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 29 (runJob at SparkHadoopWriter.scala:78)
2021-12-08 15:53:53,295 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 28)
2021-12-08 15:53:53,295 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2021-12-08 15:53:53,295 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 29 (MapPartitionsRDD[54] at saveAsTextFile at PaidPromotionAdjustParameter.scala:310), which has no missing parents
2021-12-08 15:53:53,303 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_23 stored as values in memory (estimated size 80.5 KB, free 1989.8 MB)
2021-12-08 15:53:53,305 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_23_piece0 stored as bytes in memory (estimated size 30.8 KB, free 1989.8 MB)
2021-12-08 15:53:53,306 [dispatcher-event-loop-10] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_23_piece0 in memory on qb:62937 (size: 30.8 KB, free: 1990.7 MB)
2021-12-08 15:53:53,306 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 23 from broadcast at DAGScheduler.scala:1039
2021-12-08 15:53:53,308 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 29 (MapPartitionsRDD[54] at saveAsTextFile at PaidPromotionAdjustParameter.scala:310) (first 15 tasks are for partitions Vector(0))
2021-12-08 15:53:53,308 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 29.0 with 1 tasks
2021-12-08 15:53:53,308 [dispatcher-event-loop-8] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 29.0 (TID 88, localhost, executor driver, partition 0, ANY, 8035 bytes)
2021-12-08 15:53:53,309 [Executor task launch worker for task 88] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 29.0 (TID 88)
2021-12-08 15:53:53,313 [Executor task launch worker for task 88] INFO [org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter] - File Output Committer Algorithm version is 1
2021-12-08 15:53:53,318 [Executor task launch worker for task 88] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 8 non-empty blocks out of 8 blocks
2021-12-08 15:53:53,318 [Executor task launch worker for task 88] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-08 15:53:53,467 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 520
2021-12-08 15:53:53,467 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 514
2021-12-08 15:53:53,467 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 515
2021-12-08 15:53:53,467 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 507
2021-12-08 15:53:53,467 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 509
2021-12-08 15:53:53,467 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 524
2021-12-08 15:53:53,467 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 516
2021-12-08 15:53:53,467 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 522
2021-12-08 15:53:53,467 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 510
2021-12-08 15:53:53,467 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 517
2021-12-08 15:53:53,467 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 505
2021-12-08 15:53:53,468 [dispatcher-event-loop-6] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_21_piece0 on qb:62937 in memory (size: 31.2 KB, free: 1990.7 MB)
2021-12-08 15:53:53,468 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 504
2021-12-08 15:53:53,468 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 521
2021-12-08 15:53:53,468 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 506
2021-12-08 15:53:53,468 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 500
2021-12-08 15:53:53,468 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 511
2021-12-08 15:53:53,468 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 512
2021-12-08 15:53:53,468 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 502
2021-12-08 15:53:53,468 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 513
2021-12-08 15:53:53,468 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 501
2021-12-08 15:53:53,468 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 508
2021-12-08 15:53:53,468 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 503
2021-12-08 15:53:53,468 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 519
2021-12-08 15:53:53,469 [dispatcher-event-loop-3] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_22_piece0 on qb:62937 in memory (size: 30.8 KB, free: 1990.7 MB)
2021-12-08 15:53:53,469 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 523
2021-12-08 15:53:53,469 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 518
2021-12-08 15:53:53,867 [Executor task launch worker for task 88] INFO [org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter] - Saved output of task 'attempt_20211208155353_0054_m_000000_0' to hdfs://hdp1:8020/sk/chongqing/model/input/deviceWithIndex/_temporary/0/task_20211208155353_0054_m_000000
2021-12-08 15:53:53,867 [Executor task launch worker for task 88] INFO [org.apache.spark.mapred.SparkHadoopMapRedUtil] - attempt_20211208155353_0054_m_000000_0: Committed
2021-12-08 15:53:53,868 [Executor task launch worker for task 88] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 29.0 (TID 88). 1299 bytes result sent to driver
2021-12-08 15:53:53,869 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 29.0 (TID 88) in 561 ms on localhost (executor driver) (1/1)
2021-12-08 15:53:53,869 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 29.0, whose tasks have all completed, from pool 
2021-12-08 15:53:53,869 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 29 (runJob at SparkHadoopWriter.scala:78) finished in 0.574 s
2021-12-08 15:53:53,869 [main] INFO [org.apache.spark.scheduler.DAGScheduler] - Job 9 finished: runJob at SparkHadoopWriter.scala:78, took 0.575519 s
2021-12-08 15:53:53,919 [main] INFO [org.apache.spark.internal.io.SparkHadoopWriter] - Job job_20211208155353_0054 committed.
2021-12-08 15:53:53,923 [main] INFO [org.spark_project.jetty.server.AbstractConnector] - Stopped Spark@5b800468{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2021-12-08 15:53:53,925 [main] INFO [org.apache.spark.ui.SparkUI] - Stopped Spark web UI at http://qb:4040
2021-12-08 15:53:53,932 [dispatcher-event-loop-8] INFO [org.apache.spark.MapOutputTrackerMasterEndpoint] - MapOutputTrackerMasterEndpoint stopped!
2021-12-08 15:53:54,018 [main] INFO [org.apache.spark.storage.memory.MemoryStore] - MemoryStore cleared
2021-12-08 15:53:54,018 [main] INFO [org.apache.spark.storage.BlockManager] - BlockManager stopped
2021-12-08 15:53:54,019 [main] INFO [org.apache.spark.storage.BlockManagerMaster] - BlockManagerMaster stopped
2021-12-08 15:53:54,020 [dispatcher-event-loop-2] INFO [org.apache.spark.scheduler.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint] - OutputCommitCoordinator stopped!
2021-12-08 15:53:54,024 [main] INFO [org.apache.spark.SparkContext] - Successfully stopped SparkContext
2021-12-08 15:53:54,025 [Thread-1] INFO [org.apache.spark.util.ShutdownHookManager] - Shutdown hook called
2021-12-08 15:53:54,026 [Thread-1] INFO [org.apache.spark.util.ShutdownHookManager] - Deleting directory C:\Users\ACER\AppData\Local\Temp\spark-239842a0-f9ad-4b29-9435-9082b8836757
