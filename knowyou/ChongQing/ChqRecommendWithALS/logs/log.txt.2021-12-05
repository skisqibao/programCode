2021-12-05 01:26:14,065 [main] INFO [HelloTest$] - Hello
2021-12-05 01:26:14,067 [main] ERROR [HelloTest$] - BUG
2021-12-05 01:26:55,814 [main] INFO [HelloTest$] - Hello
2021-12-05 01:26:55,814 [main] ERROR [HelloTest$] - BUG
2021-12-05 01:31:22,792 [main] INFO [HelloTest$] - Hello
2021-12-05 01:31:22,792 [main] ERROR [HelloTest$] - BUG
2021-12-05 01:36:39,524 [main] INFO [HelloTest$] - Hello
2021-12-05 01:36:39,525 [main] ERROR [HelloTest$] - BUG
2021-12-05 15:58:04,380 [main] INFO [org.apache.spark.SparkContext] - Running Spark version 2.3.0
2021-12-05 15:58:04,697 [main] INFO [org.apache.spark.SparkContext] - Submitted application: PaidPromotion
2021-12-05 15:58:04,743 [main] INFO [org.apache.spark.SecurityManager] - Changing view acls to: ACER,root
2021-12-05 15:58:04,743 [main] INFO [org.apache.spark.SecurityManager] - Changing modify acls to: ACER,root
2021-12-05 15:58:04,744 [main] INFO [org.apache.spark.SecurityManager] - Changing view acls groups to: 
2021-12-05 15:58:04,744 [main] INFO [org.apache.spark.SecurityManager] - Changing modify acls groups to: 
2021-12-05 15:58:04,744 [main] INFO [org.apache.spark.SecurityManager] - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(ACER, root); groups with view permissions: Set(); users  with modify permissions: Set(ACER, root); groups with modify permissions: Set()
2021-12-05 15:58:05,307 [main] INFO [org.apache.spark.util.Utils] - Successfully started service 'sparkDriver' on port 57774.
2021-12-05 15:58:05,324 [main] INFO [org.apache.spark.SparkEnv] - Registering MapOutputTracker
2021-12-05 15:58:05,338 [main] INFO [org.apache.spark.SparkEnv] - Registering BlockManagerMaster
2021-12-05 15:58:05,340 [main] INFO [org.apache.spark.storage.BlockManagerMasterEndpoint] - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2021-12-05 15:58:05,341 [main] INFO [org.apache.spark.storage.BlockManagerMasterEndpoint] - BlockManagerMasterEndpoint up
2021-12-05 15:58:05,349 [main] INFO [org.apache.spark.storage.DiskBlockManager] - Created local directory at C:\Users\ACER\AppData\Local\Temp\blockmgr-efae4d28-6357-45dc-8ca2-5e91de25f3e5
2021-12-05 15:58:05,363 [main] INFO [org.apache.spark.storage.memory.MemoryStore] - MemoryStore started with capacity 1990.8 MB
2021-12-05 15:58:05,372 [main] INFO [org.apache.spark.SparkEnv] - Registering OutputCommitCoordinator
2021-12-05 15:58:05,424 [main] INFO [org.spark_project.jetty.util.log] - Logging initialized @1936ms
2021-12-05 15:58:05,471 [main] INFO [org.spark_project.jetty.server.Server] - jetty-9.3.z-SNAPSHOT
2021-12-05 15:58:05,482 [main] INFO [org.spark_project.jetty.server.Server] - Started @1994ms
2021-12-05 15:58:05,507 [main] INFO [org.spark_project.jetty.server.AbstractConnector] - Started ServerConnector@5b800468{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2021-12-05 15:58:05,507 [main] INFO [org.apache.spark.util.Utils] - Successfully started service 'SparkUI' on port 4040.
2021-12-05 15:58:05,526 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@1568159{/jobs,null,AVAILABLE,@Spark}
2021-12-05 15:58:05,527 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@63cd604c{/jobs/json,null,AVAILABLE,@Spark}
2021-12-05 15:58:05,527 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@3954d008{/jobs/job,null,AVAILABLE,@Spark}
2021-12-05 15:58:05,529 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@6d8792db{/jobs/job/json,null,AVAILABLE,@Spark}
2021-12-05 15:58:05,530 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@3a1d593e{/stages,null,AVAILABLE,@Spark}
2021-12-05 15:58:05,531 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@285d851a{/stages/json,null,AVAILABLE,@Spark}
2021-12-05 15:58:05,532 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@7876d598{/stages/stage,null,AVAILABLE,@Spark}
2021-12-05 15:58:05,534 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@4985cbcb{/stages/stage/json,null,AVAILABLE,@Spark}
2021-12-05 15:58:05,535 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@54361a9{/stages/pool,null,AVAILABLE,@Spark}
2021-12-05 15:58:05,536 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@293bb8a5{/stages/pool/json,null,AVAILABLE,@Spark}
2021-12-05 15:58:05,537 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@290b1b2e{/storage,null,AVAILABLE,@Spark}
2021-12-05 15:58:05,538 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@5db4c359{/storage/json,null,AVAILABLE,@Spark}
2021-12-05 15:58:05,540 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@6fefce9e{/storage/rdd,null,AVAILABLE,@Spark}
2021-12-05 15:58:05,542 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@8a589a2{/storage/rdd/json,null,AVAILABLE,@Spark}
2021-12-05 15:58:05,543 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@5cc69cfe{/environment,null,AVAILABLE,@Spark}
2021-12-05 15:58:05,545 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@11dee337{/environment/json,null,AVAILABLE,@Spark}
2021-12-05 15:58:05,546 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@74bdc168{/executors,null,AVAILABLE,@Spark}
2021-12-05 15:58:05,547 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@7bb3a9fe{/executors/json,null,AVAILABLE,@Spark}
2021-12-05 15:58:05,548 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@f19c9d2{/executors/threadDump,null,AVAILABLE,@Spark}
2021-12-05 15:58:05,549 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@a77614d{/executors/threadDump/json,null,AVAILABLE,@Spark}
2021-12-05 15:58:05,556 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@523424b5{/static,null,AVAILABLE,@Spark}
2021-12-05 15:58:05,557 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@12cd9150{/,null,AVAILABLE,@Spark}
2021-12-05 15:58:05,559 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@32fe9d0a{/api,null,AVAILABLE,@Spark}
2021-12-05 15:58:05,560 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@59fc684e{/jobs/job/kill,null,AVAILABLE,@Spark}
2021-12-05 15:58:05,561 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@355e34c7{/stages/stage/kill,null,AVAILABLE,@Spark}
2021-12-05 15:58:05,563 [main] INFO [org.apache.spark.ui.SparkUI] - Bound SparkUI to 0.0.0.0, and started at http://qb:4040
2021-12-05 15:58:05,649 [main] INFO [org.apache.spark.executor.Executor] - Starting executor ID driver on host localhost
2021-12-05 15:58:05,697 [main] INFO [org.apache.spark.util.Utils] - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 57815.
2021-12-05 15:58:05,698 [main] INFO [org.apache.spark.network.netty.NettyBlockTransferService] - Server created on qb:57815
2021-12-05 15:58:05,699 [main] INFO [org.apache.spark.storage.BlockManager] - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2021-12-05 15:58:05,700 [main] INFO [org.apache.spark.storage.BlockManagerMaster] - Registering BlockManager BlockManagerId(driver, qb, 57815, None)
2021-12-05 15:58:05,702 [dispatcher-event-loop-10] INFO [org.apache.spark.storage.BlockManagerMasterEndpoint] - Registering block manager qb:57815 with 1990.8 MB RAM, BlockManagerId(driver, qb, 57815, None)
2021-12-05 15:58:05,705 [main] INFO [org.apache.spark.storage.BlockManagerMaster] - Registered BlockManager BlockManagerId(driver, qb, 57815, None)
2021-12-05 15:58:05,705 [main] INFO [org.apache.spark.storage.BlockManager] - Initialized BlockManager: BlockManagerId(driver, qb, 57815, None)
2021-12-05 15:58:05,831 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@6fe46b62{/metrics/json,null,AVAILABLE,@Spark}
2021-12-05 15:58:06,268 [main] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_0 stored as values in memory (estimated size 312.7 KB, free 1990.5 MB)
2021-12-05 15:58:06,488 [main] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_0_piece0 stored as bytes in memory (estimated size 27.3 KB, free 1990.5 MB)
2021-12-05 15:58:06,490 [dispatcher-event-loop-0] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_0_piece0 in memory on qb:57815 (size: 27.3 KB, free: 1990.8 MB)
2021-12-05 15:58:06,494 [main] INFO [org.apache.spark.SparkContext] - Created broadcast 0 from textFile at PaidPromotionAdjustParameter.scala:98
2021-12-05 15:58:06,857 [main] WARN [org.apache.hadoop.hdfs.shortcircuit.DomainSocketFactory] - The short-circuit local reads feature cannot be used because UNIX Domain sockets are not available on Windows.
2021-12-05 15:58:06,946 [main] INFO [org.apache.hadoop.mapred.FileInputFormat] - Total input paths to process : 1
2021-12-05 15:58:06,985 [main] INFO [org.apache.spark.SparkContext] - Starting job: count at PaidPromotionAdjustParameter.scala:100
2021-12-05 15:58:06,995 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 0 (count at PaidPromotionAdjustParameter.scala:100) with 2 output partitions
2021-12-05 15:58:06,995 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 0 (count at PaidPromotionAdjustParameter.scala:100)
2021-12-05 15:58:06,995 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List()
2021-12-05 15:58:06,996 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2021-12-05 15:58:07,001 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 0 (/sk/chongqing/data/order_data.bcp MapPartitionsRDD[1] at textFile at PaidPromotionAdjustParameter.scala:98), which has no missing parents
2021-12-05 15:58:07,032 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_1 stored as values in memory (estimated size 3.1 KB, free 1990.5 MB)
2021-12-05 15:58:07,037 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_1_piece0 stored as bytes in memory (estimated size 1900.0 B, free 1990.5 MB)
2021-12-05 15:58:07,037 [dispatcher-event-loop-2] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_1_piece0 in memory on qb:57815 (size: 1900.0 B, free: 1990.8 MB)
2021-12-05 15:58:07,038 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 1 from broadcast at DAGScheduler.scala:1039
2021-12-05 15:58:07,047 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from ResultStage 0 (/sk/chongqing/data/order_data.bcp MapPartitionsRDD[1] at textFile at PaidPromotionAdjustParameter.scala:98) (first 15 tasks are for partitions Vector(0, 1))
2021-12-05 15:58:07,048 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 0.0 with 2 tasks
2021-12-05 15:58:07,080 [dispatcher-event-loop-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 0.0 (TID 0, localhost, executor driver, partition 0, ANY, 7896 bytes)
2021-12-05 15:58:07,082 [dispatcher-event-loop-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 0.0 (TID 1, localhost, executor driver, partition 1, ANY, 7896 bytes)
2021-12-05 15:58:07,087 [Executor task launch worker for task 0] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 0.0 (TID 0)
2021-12-05 15:58:07,087 [Executor task launch worker for task 1] INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 0.0 (TID 1)
2021-12-05 15:58:07,133 [Executor task launch worker for task 1] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/order_data.bcp:3442194+3442195
2021-12-05 15:58:07,133 [Executor task launch worker for task 0] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/order_data.bcp:0+3442194
2021-12-05 15:58:07,973 [Executor task launch worker for task 1] INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 0.0 (TID 1). 754 bytes result sent to driver
2021-12-05 15:58:07,983 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 0.0 (TID 1) in 900 ms on localhost (executor driver) (1/2)
2021-12-05 15:58:10,421 [Executor task launch worker for task 0] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 0.0 (TID 0). 754 bytes result sent to driver
2021-12-05 15:58:10,424 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 0.0 (TID 0) in 3353 ms on localhost (executor driver) (2/2)
2021-12-05 15:58:10,425 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 0.0, whose tasks have all completed, from pool 
2021-12-05 15:58:10,426 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 0 (count at PaidPromotionAdjustParameter.scala:100) finished in 3.411 s
2021-12-05 15:58:10,430 [main] INFO [org.apache.spark.scheduler.DAGScheduler] - Job 0 finished: count at PaidPromotionAdjustParameter.scala:100, took 3.445267 s
2021-12-05 15:58:10,431 [main] INFO [PaidPromotion$] - 订购总数107294
2021-12-05 15:58:10,435 [main] INFO [org.apache.spark.SparkContext] - Starting job: count at PaidPromotionAdjustParameter.scala:108
2021-12-05 15:58:10,436 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 1 (count at PaidPromotionAdjustParameter.scala:108) with 2 output partitions
2021-12-05 15:58:10,436 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 1 (count at PaidPromotionAdjustParameter.scala:108)
2021-12-05 15:58:10,436 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List()
2021-12-05 15:58:10,436 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2021-12-05 15:58:10,436 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 1 (MapPartitionsRDD[2] at map at PaidPromotionAdjustParameter.scala:104), which has no missing parents
2021-12-05 15:58:10,438 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_2 stored as values in memory (estimated size 3.3 KB, free 1990.5 MB)
2021-12-05 15:58:10,442 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_2_piece0 stored as bytes in memory (estimated size 1985.0 B, free 1990.5 MB)
2021-12-05 15:58:10,442 [dispatcher-event-loop-9] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_2_piece0 in memory on qb:57815 (size: 1985.0 B, free: 1990.8 MB)
2021-12-05 15:58:10,443 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 2 from broadcast at DAGScheduler.scala:1039
2021-12-05 15:58:10,444 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from ResultStage 1 (MapPartitionsRDD[2] at map at PaidPromotionAdjustParameter.scala:104) (first 15 tasks are for partitions Vector(0, 1))
2021-12-05 15:58:10,444 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 1.0 with 2 tasks
2021-12-05 15:58:10,444 [dispatcher-event-loop-5] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 1.0 (TID 2, localhost, executor driver, partition 0, ANY, 7896 bytes)
2021-12-05 15:58:10,445 [dispatcher-event-loop-5] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 1.0 (TID 3, localhost, executor driver, partition 1, ANY, 7896 bytes)
2021-12-05 15:58:10,445 [Executor task launch worker for task 3] INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 1.0 (TID 3)
2021-12-05 15:58:10,445 [Executor task launch worker for task 2] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 1.0 (TID 2)
2021-12-05 15:58:10,448 [Executor task launch worker for task 2] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/order_data.bcp:0+3442194
2021-12-05 15:58:10,448 [Executor task launch worker for task 3] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/order_data.bcp:3442194+3442195
2021-12-05 15:58:10,528 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 16
2021-12-05 15:58:10,528 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 22
2021-12-05 15:58:10,528 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 6
2021-12-05 15:58:10,528 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 12
2021-12-05 15:58:10,528 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 15
2021-12-05 15:58:10,528 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 24
2021-12-05 15:58:10,528 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 0
2021-12-05 15:58:10,528 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 11
2021-12-05 15:58:10,528 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 3
2021-12-05 15:58:10,528 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 20
2021-12-05 15:58:10,528 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 2
2021-12-05 15:58:10,528 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 7
2021-12-05 15:58:10,528 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 5
2021-12-05 15:58:10,528 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 14
2021-12-05 15:58:10,528 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 8
2021-12-05 15:58:10,528 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 9
2021-12-05 15:58:10,528 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 23
2021-12-05 15:58:10,529 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1
2021-12-05 15:58:10,529 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 4
2021-12-05 15:58:10,540 [dispatcher-event-loop-2] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_1_piece0 on qb:57815 in memory (size: 1900.0 B, free: 1990.8 MB)
2021-12-05 15:58:10,542 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 13
2021-12-05 15:58:10,542 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 19
2021-12-05 15:58:10,542 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 10
2021-12-05 15:58:10,542 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 18
2021-12-05 15:58:10,543 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 21
2021-12-05 15:58:10,543 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 17
2021-12-05 15:58:11,011 [Executor task launch worker for task 3] INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 1.0 (TID 3). 754 bytes result sent to driver
2021-12-05 15:58:11,014 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 1.0 (TID 3) in 569 ms on localhost (executor driver) (1/2)
2021-12-05 15:58:14,533 [Executor task launch worker for task 2] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 1.0 (TID 2). 754 bytes result sent to driver
2021-12-05 15:58:14,536 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 1.0 (TID 2) in 4092 ms on localhost (executor driver) (2/2)
2021-12-05 15:58:14,536 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 1.0, whose tasks have all completed, from pool 
2021-12-05 15:58:14,536 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 1 (count at PaidPromotionAdjustParameter.scala:108) finished in 4.099 s
2021-12-05 15:58:14,536 [main] INFO [org.apache.spark.scheduler.DAGScheduler] - Job 1 finished: count at PaidPromotionAdjustParameter.scala:108, took 4.101729 s
2021-12-05 15:58:14,537 [main] INFO [PaidPromotion$] - 订购总数：107294
2021-12-05 15:58:14,551 [main] INFO [org.apache.spark.SparkContext] - Starting job: count at PaidPromotionAdjustParameter.scala:121
2021-12-05 15:58:14,551 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 2 (count at PaidPromotionAdjustParameter.scala:121) with 2 output partitions
2021-12-05 15:58:14,551 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 2 (count at PaidPromotionAdjustParameter.scala:121)
2021-12-05 15:58:14,551 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List()
2021-12-05 15:58:14,551 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2021-12-05 15:58:14,552 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 2 (MapPartitionsRDD[3] at randomSplit at PaidPromotionAdjustParameter.scala:114), which has no missing parents
2021-12-05 15:58:14,553 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_3 stored as values in memory (estimated size 3.6 KB, free 1990.5 MB)
2021-12-05 15:58:14,559 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 35
2021-12-05 15:58:14,560 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 43
2021-12-05 15:58:14,560 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 32
2021-12-05 15:58:14,560 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 33
2021-12-05 15:58:14,560 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 37
2021-12-05 15:58:14,560 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_3_piece0 stored as bytes in memory (estimated size 2.1 KB, free 1990.5 MB)
2021-12-05 15:58:14,560 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 34
2021-12-05 15:58:14,561 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 31
2021-12-05 15:58:14,561 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 29
2021-12-05 15:58:14,561 [dispatcher-event-loop-1] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_3_piece0 in memory on qb:57815 (size: 2.1 KB, free: 1990.8 MB)
2021-12-05 15:58:14,561 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 3 from broadcast at DAGScheduler.scala:1039
2021-12-05 15:58:14,562 [dispatcher-event-loop-9] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_2_piece0 on qb:57815 in memory (size: 1985.0 B, free: 1990.8 MB)
2021-12-05 15:58:14,562 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 41
2021-12-05 15:58:14,562 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 28
2021-12-05 15:58:14,562 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from ResultStage 2 (MapPartitionsRDD[3] at randomSplit at PaidPromotionAdjustParameter.scala:114) (first 15 tasks are for partitions Vector(0, 1))
2021-12-05 15:58:14,563 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 49
2021-12-05 15:58:14,563 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 2.0 with 2 tasks
2021-12-05 15:58:14,563 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 47
2021-12-05 15:58:14,563 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 44
2021-12-05 15:58:14,563 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 25
2021-12-05 15:58:14,563 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 46
2021-12-05 15:58:14,564 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 48
2021-12-05 15:58:14,564 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 30
2021-12-05 15:58:14,564 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 45
2021-12-05 15:58:14,564 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 38
2021-12-05 15:58:14,564 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 26
2021-12-05 15:58:14,564 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 42
2021-12-05 15:58:14,564 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 36
2021-12-05 15:58:14,564 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 27
2021-12-05 15:58:14,564 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 40
2021-12-05 15:58:14,564 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 39
2021-12-05 15:58:14,564 [dispatcher-event-loop-5] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 2.0 (TID 4, localhost, executor driver, partition 0, ANY, 7896 bytes)
2021-12-05 15:58:14,565 [dispatcher-event-loop-5] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 2.0 (TID 5, localhost, executor driver, partition 1, ANY, 7896 bytes)
2021-12-05 15:58:14,565 [Executor task launch worker for task 5] INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 2.0 (TID 5)
2021-12-05 15:58:14,565 [Executor task launch worker for task 4] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 2.0 (TID 4)
2021-12-05 15:58:14,567 [Executor task launch worker for task 5] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/order_data.bcp:3442194+3442195
2021-12-05 15:58:14,568 [Executor task launch worker for task 4] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/order_data.bcp:0+3442194
2021-12-05 15:58:14,950 [Executor task launch worker for task 5] INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 2.0 (TID 5). 711 bytes result sent to driver
2021-12-05 15:58:14,950 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 2.0 (TID 5) in 386 ms on localhost (executor driver) (1/2)
2021-12-05 15:58:16,807 [Executor task launch worker for task 4] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 2.0 (TID 4). 711 bytes result sent to driver
2021-12-05 15:58:16,808 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 2.0 (TID 4) in 2244 ms on localhost (executor driver) (2/2)
2021-12-05 15:58:16,808 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 2.0, whose tasks have all completed, from pool 
2021-12-05 15:58:16,809 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 2 (count at PaidPromotionAdjustParameter.scala:121) finished in 2.257 s
2021-12-05 15:58:16,809 [main] INFO [org.apache.spark.scheduler.DAGScheduler] - Job 2 finished: count at PaidPromotionAdjustParameter.scala:121, took 2.257097 s
2021-12-05 15:58:16,809 [main] INFO [PaidPromotion$] - 初次切分训练集数量：37528
2021-12-05 15:58:16,811 [main] INFO [org.apache.spark.SparkContext] - Starting job: count at PaidPromotionAdjustParameter.scala:122
2021-12-05 15:58:16,813 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 3 (count at PaidPromotionAdjustParameter.scala:122) with 2 output partitions
2021-12-05 15:58:16,813 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 3 (count at PaidPromotionAdjustParameter.scala:122)
2021-12-05 15:58:16,813 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List()
2021-12-05 15:58:16,815 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2021-12-05 15:58:16,816 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 3 (MapPartitionsRDD[4] at randomSplit at PaidPromotionAdjustParameter.scala:114), which has no missing parents
2021-12-05 15:58:16,818 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_4 stored as values in memory (estimated size 3.6 KB, free 1990.5 MB)
2021-12-05 15:58:16,824 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_4_piece0 stored as bytes in memory (estimated size 2.1 KB, free 1990.5 MB)
2021-12-05 15:58:16,824 [dispatcher-event-loop-2] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_4_piece0 in memory on qb:57815 (size: 2.1 KB, free: 1990.8 MB)
2021-12-05 15:58:16,825 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 4 from broadcast at DAGScheduler.scala:1039
2021-12-05 15:58:16,825 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from ResultStage 3 (MapPartitionsRDD[4] at randomSplit at PaidPromotionAdjustParameter.scala:114) (first 15 tasks are for partitions Vector(0, 1))
2021-12-05 15:58:16,825 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 3.0 with 2 tasks
2021-12-05 15:58:16,826 [dispatcher-event-loop-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 3.0 (TID 6, localhost, executor driver, partition 0, ANY, 7896 bytes)
2021-12-05 15:58:16,826 [dispatcher-event-loop-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 3.0 (TID 7, localhost, executor driver, partition 1, ANY, 7896 bytes)
2021-12-05 15:58:16,827 [Executor task launch worker for task 7] INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 3.0 (TID 7)
2021-12-05 15:58:16,827 [Executor task launch worker for task 6] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 3.0 (TID 6)
2021-12-05 15:58:16,829 [Executor task launch worker for task 6] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/order_data.bcp:0+3442194
2021-12-05 15:58:16,829 [Executor task launch worker for task 7] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/order_data.bcp:3442194+3442195
2021-12-05 15:58:17,383 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 69
2021-12-05 15:58:17,383 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 67
2021-12-05 15:58:17,383 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 64
2021-12-05 15:58:17,384 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 74
2021-12-05 15:58:17,384 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 58
2021-12-05 15:58:17,384 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 54
2021-12-05 15:58:17,384 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 60
2021-12-05 15:58:17,384 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 70
2021-12-05 15:58:17,384 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 71
2021-12-05 15:58:17,385 [dispatcher-event-loop-9] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_3_piece0 on qb:57815 in memory (size: 2.1 KB, free: 1990.8 MB)
2021-12-05 15:58:17,386 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 59
2021-12-05 15:58:17,386 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 63
2021-12-05 15:58:17,386 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 61
2021-12-05 15:58:17,386 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 56
2021-12-05 15:58:17,387 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 68
2021-12-05 15:58:17,387 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 57
2021-12-05 15:58:17,387 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 65
2021-12-05 15:58:17,387 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 53
2021-12-05 15:58:17,387 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 51
2021-12-05 15:58:17,387 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 50
2021-12-05 15:58:17,387 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 73
2021-12-05 15:58:17,387 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 66
2021-12-05 15:58:17,387 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 62
2021-12-05 15:58:17,387 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 55
2021-12-05 15:58:17,387 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 52
2021-12-05 15:58:17,387 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 72
2021-12-05 15:58:17,877 [Executor task launch worker for task 6] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 3.0 (TID 6). 754 bytes result sent to driver
2021-12-05 15:58:17,877 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 3.0 (TID 6) in 1051 ms on localhost (executor driver) (1/2)
2021-12-05 15:58:18,041 [Executor task launch worker for task 7] INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 3.0 (TID 7). 754 bytes result sent to driver
2021-12-05 15:58:18,042 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 3.0 (TID 7) in 1216 ms on localhost (executor driver) (2/2)
2021-12-05 15:58:18,042 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 3.0, whose tasks have all completed, from pool 
2021-12-05 15:58:18,042 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 3 (count at PaidPromotionAdjustParameter.scala:122) finished in 1.225 s
2021-12-05 15:58:18,042 [main] INFO [org.apache.spark.scheduler.DAGScheduler] - Job 3 finished: count at PaidPromotionAdjustParameter.scala:122, took 1.229920 s
2021-12-05 15:58:18,042 [main] INFO [PaidPromotion$] - 初次切分验证集数量：69766
2021-12-05 15:58:18,107 [main] INFO [PaidPromotion$] - -----------------------------------
2021-12-05 15:58:18,108 [main] INFO [org.apache.spark.SparkContext] - Starting job: count at PaidPromotionAdjustParameter.scala:138
2021-12-05 15:58:18,114 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 6 (distinct at PaidPromotionAdjustParameter.scala:128)
2021-12-05 15:58:18,115 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 4 (count at PaidPromotionAdjustParameter.scala:138) with 2 output partitions
2021-12-05 15:58:18,115 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 5 (count at PaidPromotionAdjustParameter.scala:138)
2021-12-05 15:58:18,115 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 4)
2021-12-05 15:58:18,115 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List(ShuffleMapStage 4)
2021-12-05 15:58:18,116 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ShuffleMapStage 4 (MapPartitionsRDD[6] at distinct at PaidPromotionAdjustParameter.scala:128), which has no missing parents
2021-12-05 15:58:18,126 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_5 stored as values in memory (estimated size 5.2 KB, free 1990.5 MB)
2021-12-05 15:58:18,129 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_5_piece0 stored as bytes in memory (estimated size 2.9 KB, free 1990.5 MB)
2021-12-05 15:58:18,130 [dispatcher-event-loop-10] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_5_piece0 in memory on qb:57815 (size: 2.9 KB, free: 1990.8 MB)
2021-12-05 15:58:18,130 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 5 from broadcast at DAGScheduler.scala:1039
2021-12-05 15:58:18,132 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from ShuffleMapStage 4 (MapPartitionsRDD[6] at distinct at PaidPromotionAdjustParameter.scala:128) (first 15 tasks are for partitions Vector(0, 1))
2021-12-05 15:58:18,132 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 4.0 with 2 tasks
2021-12-05 15:58:18,133 [dispatcher-event-loop-7] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 4.0 (TID 8, localhost, executor driver, partition 0, ANY, 7885 bytes)
2021-12-05 15:58:18,133 [dispatcher-event-loop-7] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 4.0 (TID 9, localhost, executor driver, partition 1, ANY, 7885 bytes)
2021-12-05 15:58:18,134 [Executor task launch worker for task 8] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 4.0 (TID 8)
2021-12-05 15:58:18,134 [Executor task launch worker for task 9] INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 4.0 (TID 9)
2021-12-05 15:58:18,138 [Executor task launch worker for task 9] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/order_data.bcp:3442194+3442195
2021-12-05 15:58:18,138 [Executor task launch worker for task 8] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/order_data.bcp:0+3442194
2021-12-05 15:58:18,424 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 75
2021-12-05 15:58:18,424 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 87
2021-12-05 15:58:18,424 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 76
2021-12-05 15:58:18,424 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 90
2021-12-05 15:58:18,425 [dispatcher-event-loop-6] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_4_piece0 on qb:57815 in memory (size: 2.1 KB, free: 1990.8 MB)
2021-12-05 15:58:18,425 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 88
2021-12-05 15:58:18,425 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 96
2021-12-05 15:58:18,426 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 89
2021-12-05 15:58:18,426 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 94
2021-12-05 15:58:18,426 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 84
2021-12-05 15:58:18,426 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 99
2021-12-05 15:58:18,426 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 85
2021-12-05 15:58:18,426 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 92
2021-12-05 15:58:18,426 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 93
2021-12-05 15:58:18,426 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 81
2021-12-05 15:58:18,426 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 86
2021-12-05 15:58:18,426 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 77
2021-12-05 15:58:18,426 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 95
2021-12-05 15:58:18,426 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 97
2021-12-05 15:58:18,426 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 98
2021-12-05 15:58:18,426 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 91
2021-12-05 15:58:18,426 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 83
2021-12-05 15:58:18,426 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 82
2021-12-05 15:58:18,426 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 79
2021-12-05 15:58:18,426 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 80
2021-12-05 15:58:18,426 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 78
2021-12-05 15:58:18,820 [Executor task launch worker for task 9] INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 4.0 (TID 9). 1075 bytes result sent to driver
2021-12-05 15:58:18,834 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 4.0 (TID 9) in 701 ms on localhost (executor driver) (1/2)
2021-12-05 15:58:18,921 [Executor task launch worker for task 8] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 4.0 (TID 8). 1032 bytes result sent to driver
2021-12-05 15:58:18,922 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 4.0 (TID 8) in 790 ms on localhost (executor driver) (2/2)
2021-12-05 15:58:18,922 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 4.0, whose tasks have all completed, from pool 
2021-12-05 15:58:18,923 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ShuffleMapStage 4 (distinct at PaidPromotionAdjustParameter.scala:128) finished in 0.804 s
2021-12-05 15:58:18,923 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - looking for newly runnable stages
2021-12-05 15:58:18,924 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - running: Set()
2021-12-05 15:58:18,924 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - waiting: Set(ResultStage 5)
2021-12-05 15:58:18,924 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - failed: Set()
2021-12-05 15:58:18,927 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 5 (MapPartitionsRDD[8] at distinct at PaidPromotionAdjustParameter.scala:128), which has no missing parents
2021-12-05 15:58:18,931 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_6 stored as values in memory (estimated size 3.7 KB, free 1990.5 MB)
2021-12-05 15:58:18,934 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_6_piece0 stored as bytes in memory (estimated size 2.2 KB, free 1990.5 MB)
2021-12-05 15:58:18,935 [dispatcher-event-loop-9] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_6_piece0 in memory on qb:57815 (size: 2.2 KB, free: 1990.8 MB)
2021-12-05 15:58:18,936 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 6 from broadcast at DAGScheduler.scala:1039
2021-12-05 15:58:18,936 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from ResultStage 5 (MapPartitionsRDD[8] at distinct at PaidPromotionAdjustParameter.scala:128) (first 15 tasks are for partitions Vector(0, 1))
2021-12-05 15:58:18,936 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 5.0 with 2 tasks
2021-12-05 15:58:18,937 [dispatcher-event-loop-5] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 5.0 (TID 10, localhost, executor driver, partition 0, ANY, 7649 bytes)
2021-12-05 15:58:18,938 [dispatcher-event-loop-5] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 5.0 (TID 11, localhost, executor driver, partition 1, ANY, 7649 bytes)
2021-12-05 15:58:18,938 [Executor task launch worker for task 10] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 5.0 (TID 10)
2021-12-05 15:58:18,938 [Executor task launch worker for task 11] INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 5.0 (TID 11)
2021-12-05 15:58:18,947 [Executor task launch worker for task 11] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 2 non-empty blocks out of 2 blocks
2021-12-05 15:58:18,947 [Executor task launch worker for task 10] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 2 non-empty blocks out of 2 blocks
2021-12-05 15:58:18,949 [Executor task launch worker for task 11] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 4 ms
2021-12-05 15:58:18,949 [Executor task launch worker for task 10] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 4 ms
2021-12-05 15:58:19,051 [Executor task launch worker for task 11] INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 5.0 (TID 11). 1012 bytes result sent to driver
2021-12-05 15:58:19,051 [Executor task launch worker for task 10] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 5.0 (TID 10). 1012 bytes result sent to driver
2021-12-05 15:58:19,053 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 5.0 (TID 10) in 116 ms on localhost (executor driver) (1/2)
2021-12-05 15:58:19,053 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 5.0 (TID 11) in 115 ms on localhost (executor driver) (2/2)
2021-12-05 15:58:19,053 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 5.0, whose tasks have all completed, from pool 
2021-12-05 15:58:19,054 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 5 (count at PaidPromotionAdjustParameter.scala:138) finished in 0.126 s
2021-12-05 15:58:19,055 [main] INFO [org.apache.spark.scheduler.DAGScheduler] - Job 4 finished: count at PaidPromotionAdjustParameter.scala:138, took 0.946849 s
2021-12-05 15:58:19,055 [main] INFO [PaidPromotion$] - 训练集用户数 = 35802
2021-12-05 15:58:19,059 [main] INFO [org.apache.spark.SparkContext] - Starting job: count at PaidPromotionAdjustParameter.scala:139
2021-12-05 15:58:19,060 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 10 (distinct at PaidPromotionAdjustParameter.scala:129)
2021-12-05 15:58:19,060 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 5 (count at PaidPromotionAdjustParameter.scala:139) with 2 output partitions
2021-12-05 15:58:19,060 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 7 (count at PaidPromotionAdjustParameter.scala:139)
2021-12-05 15:58:19,060 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 6)
2021-12-05 15:58:19,060 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List(ShuffleMapStage 6)
2021-12-05 15:58:19,061 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ShuffleMapStage 6 (MapPartitionsRDD[10] at distinct at PaidPromotionAdjustParameter.scala:129), which has no missing parents
2021-12-05 15:58:19,062 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_7 stored as values in memory (estimated size 5.2 KB, free 1990.4 MB)
2021-12-05 15:58:19,065 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_7_piece0 stored as bytes in memory (estimated size 2.9 KB, free 1990.4 MB)
2021-12-05 15:58:19,066 [dispatcher-event-loop-2] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_7_piece0 in memory on qb:57815 (size: 2.9 KB, free: 1990.8 MB)
2021-12-05 15:58:19,067 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 7 from broadcast at DAGScheduler.scala:1039
2021-12-05 15:58:19,067 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from ShuffleMapStage 6 (MapPartitionsRDD[10] at distinct at PaidPromotionAdjustParameter.scala:129) (first 15 tasks are for partitions Vector(0, 1))
2021-12-05 15:58:19,068 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 6.0 with 2 tasks
2021-12-05 15:58:19,070 [dispatcher-event-loop-4] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 6.0 (TID 12, localhost, executor driver, partition 0, ANY, 7885 bytes)
2021-12-05 15:58:19,071 [dispatcher-event-loop-4] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 6.0 (TID 13, localhost, executor driver, partition 1, ANY, 7885 bytes)
2021-12-05 15:58:19,071 [Executor task launch worker for task 12] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 6.0 (TID 12)
2021-12-05 15:58:19,072 [Executor task launch worker for task 13] INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 6.0 (TID 13)
2021-12-05 15:58:19,074 [Executor task launch worker for task 12] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/order_data.bcp:0+3442194
2021-12-05 15:58:19,074 [Executor task launch worker for task 13] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/order_data.bcp:3442194+3442195
2021-12-05 15:58:19,393 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 114
2021-12-05 15:58:19,394 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 102
2021-12-05 15:58:19,394 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 116
2021-12-05 15:58:19,394 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 126
2021-12-05 15:58:19,394 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 131
2021-12-05 15:58:19,394 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 112
2021-12-05 15:58:19,394 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 133
2021-12-05 15:58:19,394 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 144
2021-12-05 15:58:19,394 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 117
2021-12-05 15:58:19,394 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 124
2021-12-05 15:58:19,394 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 139
2021-12-05 15:58:19,394 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 107
2021-12-05 15:58:19,394 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 119
2021-12-05 15:58:19,394 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 137
2021-12-05 15:58:19,394 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 113
2021-12-05 15:58:19,394 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 120
2021-12-05 15:58:19,394 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 125
2021-12-05 15:58:19,395 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 118
2021-12-05 15:58:19,395 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 128
2021-12-05 15:58:19,395 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 136
2021-12-05 15:58:19,395 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 127
2021-12-05 15:58:19,395 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 135
2021-12-05 15:58:19,395 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 138
2021-12-05 15:58:19,395 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 134
2021-12-05 15:58:19,395 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 143
2021-12-05 15:58:19,395 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 147
2021-12-05 15:58:19,395 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 101
2021-12-05 15:58:19,395 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 145
2021-12-05 15:58:19,396 [dispatcher-event-loop-9] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_5_piece0 on qb:57815 in memory (size: 2.9 KB, free: 1990.8 MB)
2021-12-05 15:58:19,396 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 108
2021-12-05 15:58:19,396 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 130
2021-12-05 15:58:19,396 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 100
2021-12-05 15:58:19,396 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 121
2021-12-05 15:58:19,396 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 149
2021-12-05 15:58:19,396 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 115
2021-12-05 15:58:19,396 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 123
2021-12-05 15:58:19,396 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 148
2021-12-05 15:58:19,396 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 105
2021-12-05 15:58:19,396 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 142
2021-12-05 15:58:19,396 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 111
2021-12-05 15:58:19,396 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 104
2021-12-05 15:58:19,396 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 129
2021-12-05 15:58:19,396 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 122
2021-12-05 15:58:19,397 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 140
2021-12-05 15:58:19,397 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 146
2021-12-05 15:58:19,397 [dispatcher-event-loop-11] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_6_piece0 on qb:57815 in memory (size: 2.2 KB, free: 1990.8 MB)
2021-12-05 15:58:19,397 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 106
2021-12-05 15:58:19,397 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 109
2021-12-05 15:58:19,397 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 110
2021-12-05 15:58:19,397 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 141
2021-12-05 15:58:19,397 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 132
2021-12-05 15:58:19,397 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 103
2021-12-05 15:58:19,539 [Executor task launch worker for task 12] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 6.0 (TID 12). 1032 bytes result sent to driver
2021-12-05 15:58:19,539 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 6.0 (TID 12) in 470 ms on localhost (executor driver) (1/2)
2021-12-05 15:58:19,817 [Executor task launch worker for task 13] INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 6.0 (TID 13). 1032 bytes result sent to driver
2021-12-05 15:58:19,817 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 6.0 (TID 13) in 746 ms on localhost (executor driver) (2/2)
2021-12-05 15:58:19,817 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 6.0, whose tasks have all completed, from pool 
2021-12-05 15:58:19,817 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ShuffleMapStage 6 (distinct at PaidPromotionAdjustParameter.scala:129) finished in 0.756 s
2021-12-05 15:58:19,817 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - looking for newly runnable stages
2021-12-05 15:58:19,817 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - running: Set()
2021-12-05 15:58:19,817 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - waiting: Set(ResultStage 7)
2021-12-05 15:58:19,817 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - failed: Set()
2021-12-05 15:58:19,818 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 7 (MapPartitionsRDD[12] at distinct at PaidPromotionAdjustParameter.scala:129), which has no missing parents
2021-12-05 15:58:19,819 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_8 stored as values in memory (estimated size 3.7 KB, free 1990.5 MB)
2021-12-05 15:58:19,822 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_8_piece0 stored as bytes in memory (estimated size 2.2 KB, free 1990.5 MB)
2021-12-05 15:58:19,822 [dispatcher-event-loop-2] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_8_piece0 in memory on qb:57815 (size: 2.2 KB, free: 1990.8 MB)
2021-12-05 15:58:19,823 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 8 from broadcast at DAGScheduler.scala:1039
2021-12-05 15:58:19,823 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from ResultStage 7 (MapPartitionsRDD[12] at distinct at PaidPromotionAdjustParameter.scala:129) (first 15 tasks are for partitions Vector(0, 1))
2021-12-05 15:58:19,823 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 7.0 with 2 tasks
2021-12-05 15:58:19,824 [dispatcher-event-loop-4] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 7.0 (TID 14, localhost, executor driver, partition 0, ANY, 7649 bytes)
2021-12-05 15:58:19,824 [dispatcher-event-loop-4] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 7.0 (TID 15, localhost, executor driver, partition 1, ANY, 7649 bytes)
2021-12-05 15:58:19,824 [Executor task launch worker for task 14] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 7.0 (TID 14)
2021-12-05 15:58:19,824 [Executor task launch worker for task 15] INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 7.0 (TID 15)
2021-12-05 15:58:19,825 [Executor task launch worker for task 14] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 2 non-empty blocks out of 2 blocks
2021-12-05 15:58:19,825 [Executor task launch worker for task 14] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-05 15:58:19,825 [Executor task launch worker for task 15] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 2 non-empty blocks out of 2 blocks
2021-12-05 15:58:19,825 [Executor task launch worker for task 15] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-05 15:58:19,889 [Executor task launch worker for task 14] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 7.0 (TID 14). 1055 bytes result sent to driver
2021-12-05 15:58:19,890 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 7.0 (TID 14) in 66 ms on localhost (executor driver) (1/2)
2021-12-05 15:58:19,890 [Executor task launch worker for task 15] INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 7.0 (TID 15). 1012 bytes result sent to driver
2021-12-05 15:58:19,890 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 7.0 (TID 15) in 66 ms on localhost (executor driver) (2/2)
2021-12-05 15:58:19,890 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 7.0, whose tasks have all completed, from pool 
2021-12-05 15:58:19,891 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 7 (count at PaidPromotionAdjustParameter.scala:139) finished in 0.072 s
2021-12-05 15:58:19,891 [main] INFO [org.apache.spark.scheduler.DAGScheduler] - Job 5 finished: count at PaidPromotionAdjustParameter.scala:139, took 0.831454 s
2021-12-05 15:58:19,891 [main] INFO [PaidPromotion$] - 验证集用户数 = 64302
2021-12-05 15:58:19,897 [main] INFO [org.apache.spark.SparkContext] - Starting job: count at PaidPromotionAdjustParameter.scala:140
2021-12-05 15:58:19,897 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 14 (intersection at PaidPromotionAdjustParameter.scala:130)
2021-12-05 15:58:19,897 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 13 (intersection at PaidPromotionAdjustParameter.scala:130)
2021-12-05 15:58:19,897 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 6 (count at PaidPromotionAdjustParameter.scala:140) with 2 output partitions
2021-12-05 15:58:19,897 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 12 (count at PaidPromotionAdjustParameter.scala:140)
2021-12-05 15:58:19,897 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 9, ShuffleMapStage 11)
2021-12-05 15:58:19,898 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List(ShuffleMapStage 9, ShuffleMapStage 11)
2021-12-05 15:58:19,898 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ShuffleMapStage 9 (MapPartitionsRDD[14] at intersection at PaidPromotionAdjustParameter.scala:130), which has no missing parents
2021-12-05 15:58:19,899 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_9 stored as values in memory (estimated size 4.0 KB, free 1990.5 MB)
2021-12-05 15:58:19,902 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_9_piece0 stored as bytes in memory (estimated size 2.3 KB, free 1990.4 MB)
2021-12-05 15:58:19,903 [dispatcher-event-loop-9] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_9_piece0 in memory on qb:57815 (size: 2.3 KB, free: 1990.8 MB)
2021-12-05 15:58:19,904 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 9 from broadcast at DAGScheduler.scala:1039
2021-12-05 15:58:19,905 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from ShuffleMapStage 9 (MapPartitionsRDD[14] at intersection at PaidPromotionAdjustParameter.scala:130) (first 15 tasks are for partitions Vector(0, 1))
2021-12-05 15:58:19,905 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 9.0 with 2 tasks
2021-12-05 15:58:19,905 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ShuffleMapStage 11 (MapPartitionsRDD[13] at intersection at PaidPromotionAdjustParameter.scala:130), which has no missing parents
2021-12-05 15:58:19,906 [dispatcher-event-loop-10] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 9.0 (TID 16, localhost, executor driver, partition 0, ANY, 7638 bytes)
2021-12-05 15:58:19,906 [dispatcher-event-loop-10] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 9.0 (TID 17, localhost, executor driver, partition 1, ANY, 7638 bytes)
2021-12-05 15:58:19,906 [Executor task launch worker for task 16] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 9.0 (TID 16)
2021-12-05 15:58:19,906 [Executor task launch worker for task 17] INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 9.0 (TID 17)
2021-12-05 15:58:19,907 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_10 stored as values in memory (estimated size 4.0 KB, free 1990.4 MB)
2021-12-05 15:58:19,909 [Executor task launch worker for task 17] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 2 non-empty blocks out of 2 blocks
2021-12-05 15:58:19,909 [Executor task launch worker for task 17] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-05 15:58:19,909 [Executor task launch worker for task 16] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 2 non-empty blocks out of 2 blocks
2021-12-05 15:58:19,909 [Executor task launch worker for task 16] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-05 15:58:19,910 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_10_piece0 stored as bytes in memory (estimated size 2.3 KB, free 1990.4 MB)
2021-12-05 15:58:19,910 [dispatcher-event-loop-0] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_10_piece0 in memory on qb:57815 (size: 2.3 KB, free: 1990.8 MB)
2021-12-05 15:58:19,911 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 10 from broadcast at DAGScheduler.scala:1039
2021-12-05 15:58:19,911 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from ShuffleMapStage 11 (MapPartitionsRDD[13] at intersection at PaidPromotionAdjustParameter.scala:130) (first 15 tasks are for partitions Vector(0, 1))
2021-12-05 15:58:19,911 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 11.0 with 2 tasks
2021-12-05 15:58:19,912 [dispatcher-event-loop-7] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 11.0 (TID 18, localhost, executor driver, partition 0, ANY, 7638 bytes)
2021-12-05 15:58:19,912 [dispatcher-event-loop-7] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 11.0 (TID 19, localhost, executor driver, partition 1, ANY, 7638 bytes)
2021-12-05 15:58:19,913 [Executor task launch worker for task 18] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 11.0 (TID 18)
2021-12-05 15:58:19,913 [Executor task launch worker for task 19] INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 11.0 (TID 19)
2021-12-05 15:58:19,915 [Executor task launch worker for task 18] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 2 non-empty blocks out of 2 blocks
2021-12-05 15:58:19,915 [Executor task launch worker for task 18] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-05 15:58:19,915 [Executor task launch worker for task 19] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 2 non-empty blocks out of 2 blocks
2021-12-05 15:58:19,915 [Executor task launch worker for task 19] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-05 15:58:19,975 [Executor task launch worker for task 18] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 11.0 (TID 18). 1204 bytes result sent to driver
2021-12-05 15:58:19,975 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 11.0 (TID 18) in 63 ms on localhost (executor driver) (1/2)
2021-12-05 15:58:19,982 [Executor task launch worker for task 19] INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 11.0 (TID 19). 1204 bytes result sent to driver
2021-12-05 15:58:19,983 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 11.0 (TID 19) in 71 ms on localhost (executor driver) (2/2)
2021-12-05 15:58:19,983 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 11.0, whose tasks have all completed, from pool 
2021-12-05 15:58:19,983 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ShuffleMapStage 11 (intersection at PaidPromotionAdjustParameter.scala:130) finished in 0.077 s
2021-12-05 15:58:19,983 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - looking for newly runnable stages
2021-12-05 15:58:19,983 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - running: Set(ShuffleMapStage 9)
2021-12-05 15:58:19,983 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - waiting: Set(ResultStage 12)
2021-12-05 15:58:19,983 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - failed: Set()
2021-12-05 15:58:19,999 [Executor task launch worker for task 16] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 9.0 (TID 16). 1204 bytes result sent to driver
2021-12-05 15:58:19,999 [Executor task launch worker for task 17] INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 9.0 (TID 17). 1204 bytes result sent to driver
2021-12-05 15:58:20,000 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 9.0 (TID 16) in 94 ms on localhost (executor driver) (1/2)
2021-12-05 15:58:20,000 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 9.0 (TID 17) in 94 ms on localhost (executor driver) (2/2)
2021-12-05 15:58:20,000 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 9.0, whose tasks have all completed, from pool 
2021-12-05 15:58:20,001 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ShuffleMapStage 9 (intersection at PaidPromotionAdjustParameter.scala:130) finished in 0.103 s
2021-12-05 15:58:20,001 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - looking for newly runnable stages
2021-12-05 15:58:20,001 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - running: Set()
2021-12-05 15:58:20,001 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - waiting: Set(ResultStage 12)
2021-12-05 15:58:20,001 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - failed: Set()
2021-12-05 15:58:20,001 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 12 (MapPartitionsRDD[18] at intersection at PaidPromotionAdjustParameter.scala:130), which has no missing parents
2021-12-05 15:58:20,005 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_11 stored as values in memory (estimated size 3.6 KB, free 1990.4 MB)
2021-12-05 15:58:20,008 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_11_piece0 stored as bytes in memory (estimated size 2.1 KB, free 1990.4 MB)
2021-12-05 15:58:20,008 [dispatcher-event-loop-9] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_11_piece0 in memory on qb:57815 (size: 2.1 KB, free: 1990.8 MB)
2021-12-05 15:58:20,009 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 11 from broadcast at DAGScheduler.scala:1039
2021-12-05 15:58:20,009 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from ResultStage 12 (MapPartitionsRDD[18] at intersection at PaidPromotionAdjustParameter.scala:130) (first 15 tasks are for partitions Vector(0, 1))
2021-12-05 15:58:20,009 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 12.0 with 2 tasks
2021-12-05 15:58:20,010 [dispatcher-event-loop-10] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 12.0 (TID 20, localhost, executor driver, partition 0, PROCESS_LOCAL, 7712 bytes)
2021-12-05 15:58:20,010 [dispatcher-event-loop-10] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 12.0 (TID 21, localhost, executor driver, partition 1, PROCESS_LOCAL, 7712 bytes)
2021-12-05 15:58:20,011 [Executor task launch worker for task 20] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 12.0 (TID 20)
2021-12-05 15:58:20,011 [Executor task launch worker for task 21] INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 12.0 (TID 21)
2021-12-05 15:58:20,015 [Executor task launch worker for task 20] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2021-12-05 15:58:20,015 [Executor task launch worker for task 21] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2021-12-05 15:58:20,015 [Executor task launch worker for task 20] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 1 ms
2021-12-05 15:58:20,015 [Executor task launch worker for task 21] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 1 ms
2021-12-05 15:58:20,020 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 189
2021-12-05 15:58:20,020 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 167
2021-12-05 15:58:20,020 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 150
2021-12-05 15:58:20,020 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 181
2021-12-05 15:58:20,020 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 178
2021-12-05 15:58:20,020 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 165
2021-12-05 15:58:20,020 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 195
2021-12-05 15:58:20,020 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 151
2021-12-05 15:58:20,021 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 190
2021-12-05 15:58:20,021 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 159
2021-12-05 15:58:20,021 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 169
2021-12-05 15:58:20,021 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 166
2021-12-05 15:58:20,021 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 162
2021-12-05 15:58:20,021 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 156
2021-12-05 15:58:20,021 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 188
2021-12-05 15:58:20,021 [Executor task launch worker for task 20] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2021-12-05 15:58:20,021 [Executor task launch worker for task 20] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-05 15:58:20,021 [Executor task launch worker for task 21] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2021-12-05 15:58:20,021 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 157
2021-12-05 15:58:20,021 [Executor task launch worker for task 21] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-05 15:58:20,021 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 176
2021-12-05 15:58:20,021 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 155
2021-12-05 15:58:20,021 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 179
2021-12-05 15:58:20,021 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 171
2021-12-05 15:58:20,021 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 153
2021-12-05 15:58:20,021 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 164
2021-12-05 15:58:20,021 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 187
2021-12-05 15:58:20,022 [dispatcher-event-loop-4] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_9_piece0 on qb:57815 in memory (size: 2.3 KB, free: 1990.8 MB)
2021-12-05 15:58:20,022 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 182
2021-12-05 15:58:20,022 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 177
2021-12-05 15:58:20,022 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 173
2021-12-05 15:58:20,022 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 152
2021-12-05 15:58:20,022 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 170
2021-12-05 15:58:20,022 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 160
2021-12-05 15:58:20,022 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 183
2021-12-05 15:58:20,022 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 168
2021-12-05 15:58:20,022 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 161
2021-12-05 15:58:20,023 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 172
2021-12-05 15:58:20,023 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 192
2021-12-05 15:58:20,023 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 193
2021-12-05 15:58:20,023 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 194
2021-12-05 15:58:20,023 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 186
2021-12-05 15:58:20,023 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 174
2021-12-05 15:58:20,024 [dispatcher-event-loop-6] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_8_piece0 on qb:57815 in memory (size: 2.2 KB, free: 1990.8 MB)
2021-12-05 15:58:20,024 [dispatcher-event-loop-9] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_7_piece0 on qb:57815 in memory (size: 2.9 KB, free: 1990.8 MB)
2021-12-05 15:58:20,025 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 158
2021-12-05 15:58:20,025 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 154
2021-12-05 15:58:20,025 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 199
2021-12-05 15:58:20,025 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 191
2021-12-05 15:58:20,025 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 196
2021-12-05 15:58:20,025 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 197
2021-12-05 15:58:20,025 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 198
2021-12-05 15:58:20,025 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 180
2021-12-05 15:58:20,025 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 185
2021-12-05 15:58:20,025 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 163
2021-12-05 15:58:20,025 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 175
2021-12-05 15:58:20,025 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 184
2021-12-05 15:58:20,026 [dispatcher-event-loop-11] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_10_piece0 on qb:57815 in memory (size: 2.3 KB, free: 1990.8 MB)
2021-12-05 15:58:20,198 [Executor task launch worker for task 21] INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 12.0 (TID 21). 1140 bytes result sent to driver
2021-12-05 15:58:20,198 [Executor task launch worker for task 20] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 12.0 (TID 20). 1140 bytes result sent to driver
2021-12-05 15:58:20,199 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 12.0 (TID 21) in 189 ms on localhost (executor driver) (1/2)
2021-12-05 15:58:20,199 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 12.0 (TID 20) in 190 ms on localhost (executor driver) (2/2)
2021-12-05 15:58:20,199 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 12.0, whose tasks have all completed, from pool 
2021-12-05 15:58:20,200 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 12 (count at PaidPromotionAdjustParameter.scala:140) finished in 0.198 s
2021-12-05 15:58:20,200 [main] INFO [org.apache.spark.scheduler.DAGScheduler] - Job 6 finished: count at PaidPromotionAdjustParameter.scala:140, took 0.303629 s
2021-12-05 15:58:20,200 [main] INFO [PaidPromotion$] - 共 同 用户数 = 4781
2021-12-05 15:58:20,204 [main] INFO [org.apache.spark.SparkContext] - Starting job: count at PaidPromotionAdjustParameter.scala:141
2021-12-05 15:58:20,204 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 20 (distinct at PaidPromotionAdjustParameter.scala:133)
2021-12-05 15:58:20,204 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 7 (count at PaidPromotionAdjustParameter.scala:141) with 2 output partitions
2021-12-05 15:58:20,205 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 14 (count at PaidPromotionAdjustParameter.scala:141)
2021-12-05 15:58:20,205 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 13)
2021-12-05 15:58:20,205 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List(ShuffleMapStage 13)
2021-12-05 15:58:20,205 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ShuffleMapStage 13 (MapPartitionsRDD[20] at distinct at PaidPromotionAdjustParameter.scala:133), which has no missing parents
2021-12-05 15:58:20,206 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_12 stored as values in memory (estimated size 5.2 KB, free 1990.5 MB)
2021-12-05 15:58:20,208 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_12_piece0 stored as bytes in memory (estimated size 2.9 KB, free 1990.5 MB)
2021-12-05 15:58:20,209 [dispatcher-event-loop-2] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_12_piece0 in memory on qb:57815 (size: 2.9 KB, free: 1990.8 MB)
2021-12-05 15:58:20,209 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 12 from broadcast at DAGScheduler.scala:1039
2021-12-05 15:58:20,209 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from ShuffleMapStage 13 (MapPartitionsRDD[20] at distinct at PaidPromotionAdjustParameter.scala:133) (first 15 tasks are for partitions Vector(0, 1))
2021-12-05 15:58:20,209 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 13.0 with 2 tasks
2021-12-05 15:58:20,210 [dispatcher-event-loop-6] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 13.0 (TID 22, localhost, executor driver, partition 0, ANY, 7885 bytes)
2021-12-05 15:58:20,210 [dispatcher-event-loop-6] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 13.0 (TID 23, localhost, executor driver, partition 1, ANY, 7885 bytes)
2021-12-05 15:58:20,210 [Executor task launch worker for task 23] INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 13.0 (TID 23)
2021-12-05 15:58:20,210 [Executor task launch worker for task 22] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 13.0 (TID 22)
2021-12-05 15:58:20,212 [Executor task launch worker for task 23] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/order_data.bcp:3442194+3442195
2021-12-05 15:58:20,212 [Executor task launch worker for task 22] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/order_data.bcp:0+3442194
2021-12-05 15:58:20,891 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 201
2021-12-05 15:58:20,891 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 237
2021-12-05 15:58:20,891 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 247
2021-12-05 15:58:20,891 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 225
2021-12-05 15:58:20,891 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 241
2021-12-05 15:58:20,891 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 263
2021-12-05 15:58:20,891 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 261
2021-12-05 15:58:20,891 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 205
2021-12-05 15:58:20,891 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 266
2021-12-05 15:58:20,891 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 212
2021-12-05 15:58:20,891 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 222
2021-12-05 15:58:20,891 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 236
2021-12-05 15:58:20,891 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 259
2021-12-05 15:58:20,891 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 258
2021-12-05 15:58:20,891 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 239
2021-12-05 15:58:20,891 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 208
2021-12-05 15:58:20,891 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 218
2021-12-05 15:58:20,891 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 271
2021-12-05 15:58:20,892 [dispatcher-event-loop-10] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_11_piece0 on qb:57815 in memory (size: 2.1 KB, free: 1990.8 MB)
2021-12-05 15:58:20,892 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 252
2021-12-05 15:58:20,892 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 246
2021-12-05 15:58:20,892 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 262
2021-12-05 15:58:20,892 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 217
2021-12-05 15:58:20,892 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 231
2021-12-05 15:58:20,892 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 204
2021-12-05 15:58:20,892 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 229
2021-12-05 15:58:20,892 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 215
2021-12-05 15:58:20,892 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 273
2021-12-05 15:58:20,892 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 230
2021-12-05 15:58:20,893 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 240
2021-12-05 15:58:20,893 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 269
2021-12-05 15:58:20,893 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 224
2021-12-05 15:58:20,893 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 206
2021-12-05 15:58:20,893 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 221
2021-12-05 15:58:20,893 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 267
2021-12-05 15:58:20,893 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 256
2021-12-05 15:58:20,893 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 232
2021-12-05 15:58:20,893 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 211
2021-12-05 15:58:20,893 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 270
2021-12-05 15:58:20,893 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 213
2021-12-05 15:58:20,893 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 228
2021-12-05 15:58:20,893 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 202
2021-12-05 15:58:20,893 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 238
2021-12-05 15:58:20,893 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 268
2021-12-05 15:58:20,893 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 203
2021-12-05 15:58:20,893 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 210
2021-12-05 15:58:20,893 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 214
2021-12-05 15:58:20,893 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 250
2021-12-05 15:58:20,893 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 251
2021-12-05 15:58:20,893 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 255
2021-12-05 15:58:20,893 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 253
2021-12-05 15:58:20,893 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 216
2021-12-05 15:58:20,893 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 243
2021-12-05 15:58:20,893 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 249
2021-12-05 15:58:20,893 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 223
2021-12-05 15:58:20,893 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 260
2021-12-05 15:58:20,893 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 272
2021-12-05 15:58:20,893 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 227
2021-12-05 15:58:20,893 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 245
2021-12-05 15:58:20,893 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 219
2021-12-05 15:58:20,893 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 200
2021-12-05 15:58:20,893 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 254
2021-12-05 15:58:20,893 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 220
2021-12-05 15:58:20,893 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 233
2021-12-05 15:58:20,893 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 244
2021-12-05 15:58:20,893 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 207
2021-12-05 15:58:20,893 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 235
2021-12-05 15:58:20,893 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 274
2021-12-05 15:58:20,893 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 248
2021-12-05 15:58:20,893 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 265
2021-12-05 15:58:20,893 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 226
2021-12-05 15:58:20,893 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 242
2021-12-05 15:58:20,893 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 209
2021-12-05 15:58:20,893 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 234
2021-12-05 15:58:20,893 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 264
2021-12-05 15:58:20,893 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 257
2021-12-05 15:58:20,909 [Executor task launch worker for task 23] INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 13.0 (TID 23). 1032 bytes result sent to driver
2021-12-05 15:58:20,909 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 13.0 (TID 23) in 699 ms on localhost (executor driver) (1/2)
2021-12-05 15:58:21,149 [Executor task launch worker for task 22] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 13.0 (TID 22). 1032 bytes result sent to driver
2021-12-05 15:58:21,149 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 13.0 (TID 22) in 939 ms on localhost (executor driver) (2/2)
2021-12-05 15:58:21,149 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 13.0, whose tasks have all completed, from pool 
2021-12-05 15:58:21,149 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ShuffleMapStage 13 (distinct at PaidPromotionAdjustParameter.scala:133) finished in 0.944 s
2021-12-05 15:58:21,150 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - looking for newly runnable stages
2021-12-05 15:58:21,150 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - running: Set()
2021-12-05 15:58:21,150 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - waiting: Set(ResultStage 14)
2021-12-05 15:58:21,150 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - failed: Set()
2021-12-05 15:58:21,150 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 14 (MapPartitionsRDD[22] at distinct at PaidPromotionAdjustParameter.scala:133), which has no missing parents
2021-12-05 15:58:21,151 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_13 stored as values in memory (estimated size 3.7 KB, free 1990.5 MB)
2021-12-05 15:58:21,154 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_13_piece0 stored as bytes in memory (estimated size 2.2 KB, free 1990.5 MB)
2021-12-05 15:58:21,156 [dispatcher-event-loop-7] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_13_piece0 in memory on qb:57815 (size: 2.2 KB, free: 1990.8 MB)
2021-12-05 15:58:21,156 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 13 from broadcast at DAGScheduler.scala:1039
2021-12-05 15:58:21,156 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from ResultStage 14 (MapPartitionsRDD[22] at distinct at PaidPromotionAdjustParameter.scala:133) (first 15 tasks are for partitions Vector(0, 1))
2021-12-05 15:58:21,156 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 14.0 with 2 tasks
2021-12-05 15:58:21,157 [dispatcher-event-loop-4] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 14.0 (TID 24, localhost, executor driver, partition 0, ANY, 7649 bytes)
2021-12-05 15:58:21,157 [dispatcher-event-loop-4] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 14.0 (TID 25, localhost, executor driver, partition 1, ANY, 7649 bytes)
2021-12-05 15:58:21,157 [Executor task launch worker for task 24] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 14.0 (TID 24)
2021-12-05 15:58:21,157 [Executor task launch worker for task 25] INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 14.0 (TID 25)
2021-12-05 15:58:21,158 [Executor task launch worker for task 24] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 2 non-empty blocks out of 2 blocks
2021-12-05 15:58:21,158 [Executor task launch worker for task 25] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 2 non-empty blocks out of 2 blocks
2021-12-05 15:58:21,158 [Executor task launch worker for task 24] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-05 15:58:21,158 [Executor task launch worker for task 25] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-05 15:58:21,173 [Executor task launch worker for task 24] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 14.0 (TID 24). 967 bytes result sent to driver
2021-12-05 15:58:21,173 [Executor task launch worker for task 25] INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 14.0 (TID 25). 967 bytes result sent to driver
2021-12-05 15:58:21,174 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 14.0 (TID 24) in 17 ms on localhost (executor driver) (1/2)
2021-12-05 15:58:21,174 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 14.0 (TID 25) in 17 ms on localhost (executor driver) (2/2)
2021-12-05 15:58:21,174 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 14.0, whose tasks have all completed, from pool 
2021-12-05 15:58:21,174 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 14 (count at PaidPromotionAdjustParameter.scala:141) finished in 0.024 s
2021-12-05 15:58:21,174 [main] INFO [org.apache.spark.scheduler.DAGScheduler] - Job 7 finished: count at PaidPromotionAdjustParameter.scala:141, took 0.970691 s
2021-12-05 15:58:21,175 [main] INFO [PaidPromotion$] - 训练集节目数 = 116
2021-12-05 15:58:21,177 [main] INFO [org.apache.spark.SparkContext] - Starting job: count at PaidPromotionAdjustParameter.scala:142
2021-12-05 15:58:21,178 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 24 (distinct at PaidPromotionAdjustParameter.scala:134)
2021-12-05 15:58:21,178 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 8 (count at PaidPromotionAdjustParameter.scala:142) with 2 output partitions
2021-12-05 15:58:21,178 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 16 (count at PaidPromotionAdjustParameter.scala:142)
2021-12-05 15:58:21,178 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 15)
2021-12-05 15:58:21,178 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List(ShuffleMapStage 15)
2021-12-05 15:58:21,178 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ShuffleMapStage 15 (MapPartitionsRDD[24] at distinct at PaidPromotionAdjustParameter.scala:134), which has no missing parents
2021-12-05 15:58:21,179 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_14 stored as values in memory (estimated size 5.2 KB, free 1990.4 MB)
2021-12-05 15:58:21,182 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_14_piece0 stored as bytes in memory (estimated size 2.9 KB, free 1990.4 MB)
2021-12-05 15:58:21,183 [dispatcher-event-loop-8] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_14_piece0 in memory on qb:57815 (size: 2.9 KB, free: 1990.8 MB)
2021-12-05 15:58:21,183 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 14 from broadcast at DAGScheduler.scala:1039
2021-12-05 15:58:21,183 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from ShuffleMapStage 15 (MapPartitionsRDD[24] at distinct at PaidPromotionAdjustParameter.scala:134) (first 15 tasks are for partitions Vector(0, 1))
2021-12-05 15:58:21,183 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 15.0 with 2 tasks
2021-12-05 15:58:21,184 [dispatcher-event-loop-5] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 15.0 (TID 26, localhost, executor driver, partition 0, ANY, 7885 bytes)
2021-12-05 15:58:21,184 [dispatcher-event-loop-5] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 15.0 (TID 27, localhost, executor driver, partition 1, ANY, 7885 bytes)
2021-12-05 15:58:21,185 [Executor task launch worker for task 26] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 15.0 (TID 26)
2021-12-05 15:58:21,185 [Executor task launch worker for task 27] INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 15.0 (TID 27)
2021-12-05 15:58:21,187 [Executor task launch worker for task 27] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/order_data.bcp:3442194+3442195
2021-12-05 15:58:21,187 [Executor task launch worker for task 26] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/order_data.bcp:0+3442194
2021-12-05 15:58:21,666 [Executor task launch worker for task 27] INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 15.0 (TID 27). 989 bytes result sent to driver
2021-12-05 15:58:21,666 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 15.0 (TID 27) in 482 ms on localhost (executor driver) (1/2)
2021-12-05 15:58:22,339 [Executor task launch worker for task 26] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 15.0 (TID 26). 989 bytes result sent to driver
2021-12-05 15:58:22,339 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 15.0 (TID 26) in 1155 ms on localhost (executor driver) (2/2)
2021-12-05 15:58:22,339 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 15.0, whose tasks have all completed, from pool 
2021-12-05 15:58:22,340 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ShuffleMapStage 15 (distinct at PaidPromotionAdjustParameter.scala:134) finished in 1.161 s
2021-12-05 15:58:22,340 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - looking for newly runnable stages
2021-12-05 15:58:22,340 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - running: Set()
2021-12-05 15:58:22,340 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - waiting: Set(ResultStage 16)
2021-12-05 15:58:22,340 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - failed: Set()
2021-12-05 15:58:22,340 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 16 (MapPartitionsRDD[26] at distinct at PaidPromotionAdjustParameter.scala:134), which has no missing parents
2021-12-05 15:58:22,341 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_15 stored as values in memory (estimated size 3.7 KB, free 1990.4 MB)
2021-12-05 15:58:22,343 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_15_piece0 stored as bytes in memory (estimated size 2.2 KB, free 1990.4 MB)
2021-12-05 15:58:22,343 [dispatcher-event-loop-7] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_15_piece0 in memory on qb:57815 (size: 2.2 KB, free: 1990.8 MB)
2021-12-05 15:58:22,343 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 15 from broadcast at DAGScheduler.scala:1039
2021-12-05 15:58:22,344 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from ResultStage 16 (MapPartitionsRDD[26] at distinct at PaidPromotionAdjustParameter.scala:134) (first 15 tasks are for partitions Vector(0, 1))
2021-12-05 15:58:22,344 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 16.0 with 2 tasks
2021-12-05 15:58:22,344 [dispatcher-event-loop-4] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 16.0 (TID 28, localhost, executor driver, partition 0, ANY, 7649 bytes)
2021-12-05 15:58:22,344 [dispatcher-event-loop-4] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 16.0 (TID 29, localhost, executor driver, partition 1, ANY, 7649 bytes)
2021-12-05 15:58:22,345 [Executor task launch worker for task 28] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 16.0 (TID 28)
2021-12-05 15:58:22,345 [Executor task launch worker for task 29] INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 16.0 (TID 29)
2021-12-05 15:58:22,346 [Executor task launch worker for task 29] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 2 non-empty blocks out of 2 blocks
2021-12-05 15:58:22,346 [Executor task launch worker for task 28] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 2 non-empty blocks out of 2 blocks
2021-12-05 15:58:22,346 [Executor task launch worker for task 29] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-05 15:58:22,346 [Executor task launch worker for task 28] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-05 15:58:22,360 [Executor task launch worker for task 29] INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 16.0 (TID 29). 1011 bytes result sent to driver
2021-12-05 15:58:22,360 [Executor task launch worker for task 28] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 16.0 (TID 28). 1010 bytes result sent to driver
2021-12-05 15:58:22,360 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 16.0 (TID 29) in 16 ms on localhost (executor driver) (1/2)
2021-12-05 15:58:22,360 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 16.0 (TID 28) in 16 ms on localhost (executor driver) (2/2)
2021-12-05 15:58:22,360 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 16.0, whose tasks have all completed, from pool 
2021-12-05 15:58:22,360 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 16 (count at PaidPromotionAdjustParameter.scala:142) finished in 0.020 s
2021-12-05 15:58:22,360 [main] INFO [org.apache.spark.scheduler.DAGScheduler] - Job 8 finished: count at PaidPromotionAdjustParameter.scala:142, took 1.182995 s
2021-12-05 15:58:22,361 [main] INFO [PaidPromotion$] - 验证集节目数 = 126
2021-12-05 15:58:22,363 [main] INFO [org.apache.spark.SparkContext] - Starting job: count at PaidPromotionAdjustParameter.scala:143
2021-12-05 15:58:22,364 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 28 (intersection at PaidPromotionAdjustParameter.scala:135)
2021-12-05 15:58:22,364 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 27 (intersection at PaidPromotionAdjustParameter.scala:135)
2021-12-05 15:58:22,364 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 9 (count at PaidPromotionAdjustParameter.scala:143) with 2 output partitions
2021-12-05 15:58:22,364 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 21 (count at PaidPromotionAdjustParameter.scala:143)
2021-12-05 15:58:22,364 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 20, ShuffleMapStage 18)
2021-12-05 15:58:22,364 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List(ShuffleMapStage 20, ShuffleMapStage 18)
2021-12-05 15:58:22,364 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ShuffleMapStage 18 (MapPartitionsRDD[28] at intersection at PaidPromotionAdjustParameter.scala:135), which has no missing parents
2021-12-05 15:58:22,365 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_16 stored as values in memory (estimated size 4.0 KB, free 1990.4 MB)
2021-12-05 15:58:22,367 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_16_piece0 stored as bytes in memory (estimated size 2.3 KB, free 1990.4 MB)
2021-12-05 15:58:22,367 [dispatcher-event-loop-8] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_16_piece0 in memory on qb:57815 (size: 2.3 KB, free: 1990.8 MB)
2021-12-05 15:58:22,367 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 16 from broadcast at DAGScheduler.scala:1039
2021-12-05 15:58:22,368 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from ShuffleMapStage 18 (MapPartitionsRDD[28] at intersection at PaidPromotionAdjustParameter.scala:135) (first 15 tasks are for partitions Vector(0, 1))
2021-12-05 15:58:22,368 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 18.0 with 2 tasks
2021-12-05 15:58:22,368 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ShuffleMapStage 20 (MapPartitionsRDD[27] at intersection at PaidPromotionAdjustParameter.scala:135), which has no missing parents
2021-12-05 15:58:22,368 [dispatcher-event-loop-5] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 18.0 (TID 30, localhost, executor driver, partition 0, ANY, 7638 bytes)
2021-12-05 15:58:22,368 [dispatcher-event-loop-5] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 18.0 (TID 31, localhost, executor driver, partition 1, ANY, 7638 bytes)
2021-12-05 15:58:22,368 [Executor task launch worker for task 31] INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 18.0 (TID 31)
2021-12-05 15:58:22,368 [Executor task launch worker for task 30] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 18.0 (TID 30)
2021-12-05 15:58:22,369 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_17 stored as values in memory (estimated size 4.0 KB, free 1990.4 MB)
2021-12-05 15:58:22,369 [Executor task launch worker for task 30] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 2 non-empty blocks out of 2 blocks
2021-12-05 15:58:22,369 [Executor task launch worker for task 31] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 2 non-empty blocks out of 2 blocks
2021-12-05 15:58:22,369 [Executor task launch worker for task 30] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-05 15:58:22,369 [Executor task launch worker for task 31] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-05 15:58:22,371 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_17_piece0 stored as bytes in memory (estimated size 2.3 KB, free 1990.4 MB)
2021-12-05 15:58:22,371 [dispatcher-event-loop-11] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_17_piece0 in memory on qb:57815 (size: 2.3 KB, free: 1990.8 MB)
2021-12-05 15:58:22,372 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 17 from broadcast at DAGScheduler.scala:1039
2021-12-05 15:58:22,372 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from ShuffleMapStage 20 (MapPartitionsRDD[27] at intersection at PaidPromotionAdjustParameter.scala:135) (first 15 tasks are for partitions Vector(0, 1))
2021-12-05 15:58:22,372 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 20.0 with 2 tasks
2021-12-05 15:58:22,373 [dispatcher-event-loop-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 20.0 (TID 32, localhost, executor driver, partition 0, ANY, 7638 bytes)
2021-12-05 15:58:22,373 [dispatcher-event-loop-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 20.0 (TID 33, localhost, executor driver, partition 1, ANY, 7638 bytes)
2021-12-05 15:58:22,373 [Executor task launch worker for task 32] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 20.0 (TID 32)
2021-12-05 15:58:22,373 [Executor task launch worker for task 33] INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 20.0 (TID 33)
2021-12-05 15:58:22,374 [Executor task launch worker for task 33] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 2 non-empty blocks out of 2 blocks
2021-12-05 15:58:22,374 [Executor task launch worker for task 32] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 2 non-empty blocks out of 2 blocks
2021-12-05 15:58:22,375 [Executor task launch worker for task 33] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 1 ms
2021-12-05 15:58:22,375 [Executor task launch worker for task 32] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 1 ms
2021-12-05 15:58:22,387 [Executor task launch worker for task 30] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 18.0 (TID 30). 1204 bytes result sent to driver
2021-12-05 15:58:22,387 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 18.0 (TID 30) in 19 ms on localhost (executor driver) (1/2)
2021-12-05 15:58:22,387 [Executor task launch worker for task 31] INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 18.0 (TID 31). 1204 bytes result sent to driver
2021-12-05 15:58:22,388 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 18.0 (TID 31) in 20 ms on localhost (executor driver) (2/2)
2021-12-05 15:58:22,388 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 18.0, whose tasks have all completed, from pool 
2021-12-05 15:58:22,388 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ShuffleMapStage 18 (intersection at PaidPromotionAdjustParameter.scala:135) finished in 0.023 s
2021-12-05 15:58:22,388 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - looking for newly runnable stages
2021-12-05 15:58:22,388 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - running: Set(ShuffleMapStage 20)
2021-12-05 15:58:22,388 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - waiting: Set(ResultStage 21)
2021-12-05 15:58:22,388 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - failed: Set()
2021-12-05 15:58:22,391 [Executor task launch worker for task 32] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 20.0 (TID 32). 1161 bytes result sent to driver
2021-12-05 15:58:22,391 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 20.0 (TID 32) in 18 ms on localhost (executor driver) (1/2)
2021-12-05 15:58:22,393 [Executor task launch worker for task 33] INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 20.0 (TID 33). 1118 bytes result sent to driver
2021-12-05 15:58:22,393 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 20.0 (TID 33) in 20 ms on localhost (executor driver) (2/2)
2021-12-05 15:58:22,393 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 20.0, whose tasks have all completed, from pool 
2021-12-05 15:58:22,393 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ShuffleMapStage 20 (intersection at PaidPromotionAdjustParameter.scala:135) finished in 0.024 s
2021-12-05 15:58:22,393 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - looking for newly runnable stages
2021-12-05 15:58:22,393 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - running: Set()
2021-12-05 15:58:22,393 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - waiting: Set(ResultStage 21)
2021-12-05 15:58:22,393 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - failed: Set()
2021-12-05 15:58:22,394 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 21 (MapPartitionsRDD[32] at intersection at PaidPromotionAdjustParameter.scala:135), which has no missing parents
2021-12-05 15:58:22,394 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_18 stored as values in memory (estimated size 3.6 KB, free 1990.4 MB)
2021-12-05 15:58:22,396 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_18_piece0 stored as bytes in memory (estimated size 2.1 KB, free 1990.4 MB)
2021-12-05 15:58:22,396 [dispatcher-event-loop-8] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_18_piece0 in memory on qb:57815 (size: 2.1 KB, free: 1990.8 MB)
2021-12-05 15:58:22,397 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 18 from broadcast at DAGScheduler.scala:1039
2021-12-05 15:58:22,397 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from ResultStage 21 (MapPartitionsRDD[32] at intersection at PaidPromotionAdjustParameter.scala:135) (first 15 tasks are for partitions Vector(0, 1))
2021-12-05 15:58:22,397 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 21.0 with 2 tasks
2021-12-05 15:58:22,397 [dispatcher-event-loop-5] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 21.0 (TID 34, localhost, executor driver, partition 0, PROCESS_LOCAL, 7712 bytes)
2021-12-05 15:58:22,397 [dispatcher-event-loop-5] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 21.0 (TID 35, localhost, executor driver, partition 1, PROCESS_LOCAL, 7712 bytes)
2021-12-05 15:58:22,397 [Executor task launch worker for task 34] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 21.0 (TID 34)
2021-12-05 15:58:22,397 [Executor task launch worker for task 35] INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 21.0 (TID 35)
2021-12-05 15:58:22,399 [Executor task launch worker for task 34] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2021-12-05 15:58:22,399 [Executor task launch worker for task 35] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2021-12-05 15:58:22,399 [Executor task launch worker for task 34] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-05 15:58:22,399 [Executor task launch worker for task 35] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-05 15:58:22,401 [Executor task launch worker for task 35] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2021-12-05 15:58:22,401 [Executor task launch worker for task 34] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2021-12-05 15:58:22,401 [Executor task launch worker for task 35] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-05 15:58:22,401 [Executor task launch worker for task 34] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-05 15:58:22,408 [Executor task launch worker for task 35] INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 21.0 (TID 35). 1010 bytes result sent to driver
2021-12-05 15:58:22,408 [Executor task launch worker for task 34] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 21.0 (TID 34). 1010 bytes result sent to driver
2021-12-05 15:58:22,408 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 21.0 (TID 35) in 11 ms on localhost (executor driver) (1/2)
2021-12-05 15:58:22,408 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 21.0 (TID 34) in 11 ms on localhost (executor driver) (2/2)
2021-12-05 15:58:22,408 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 21.0, whose tasks have all completed, from pool 
2021-12-05 15:58:22,409 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 21 (count at PaidPromotionAdjustParameter.scala:143) finished in 0.015 s
2021-12-05 15:58:22,409 [main] INFO [org.apache.spark.scheduler.DAGScheduler] - Job 9 finished: count at PaidPromotionAdjustParameter.scala:143, took 0.045530 s
2021-12-05 15:58:22,409 [main] INFO [PaidPromotion$] - 共 同 节目数 = 110
2021-12-05 15:58:22,416 [main] INFO [org.apache.spark.SparkContext] - Starting job: collect at PaidPromotionAdjustParameter.scala:146
2021-12-05 15:58:22,417 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 10 (collect at PaidPromotionAdjustParameter.scala:146) with 2 output partitions
2021-12-05 15:58:22,417 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 26 (collect at PaidPromotionAdjustParameter.scala:146)
2021-12-05 15:58:22,417 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 25, ShuffleMapStage 23)
2021-12-05 15:58:22,417 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2021-12-05 15:58:22,417 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 26 (MapPartitionsRDD[18] at intersection at PaidPromotionAdjustParameter.scala:130), which has no missing parents
2021-12-05 15:58:22,418 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_19 stored as values in memory (estimated size 3.8 KB, free 1990.4 MB)
2021-12-05 15:58:22,420 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_19_piece0 stored as bytes in memory (estimated size 2.2 KB, free 1990.4 MB)
2021-12-05 15:58:22,420 [dispatcher-event-loop-4] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_19_piece0 in memory on qb:57815 (size: 2.2 KB, free: 1990.8 MB)
2021-12-05 15:58:22,421 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 19 from broadcast at DAGScheduler.scala:1039
2021-12-05 15:58:22,422 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from ResultStage 26 (MapPartitionsRDD[18] at intersection at PaidPromotionAdjustParameter.scala:130) (first 15 tasks are for partitions Vector(0, 1))
2021-12-05 15:58:22,422 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 26.0 with 2 tasks
2021-12-05 15:58:22,422 [dispatcher-event-loop-7] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 26.0 (TID 36, localhost, executor driver, partition 0, PROCESS_LOCAL, 7712 bytes)
2021-12-05 15:58:22,423 [dispatcher-event-loop-7] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 26.0 (TID 37, localhost, executor driver, partition 1, PROCESS_LOCAL, 7712 bytes)
2021-12-05 15:58:22,423 [Executor task launch worker for task 36] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 26.0 (TID 36)
2021-12-05 15:58:22,423 [Executor task launch worker for task 37] INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 26.0 (TID 37)
2021-12-05 15:58:22,424 [Executor task launch worker for task 36] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2021-12-05 15:58:22,424 [Executor task launch worker for task 37] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2021-12-05 15:58:22,424 [Executor task launch worker for task 36] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-05 15:58:22,424 [Executor task launch worker for task 37] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-05 15:58:22,426 [Executor task launch worker for task 36] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2021-12-05 15:58:22,426 [Executor task launch worker for task 37] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2021-12-05 15:58:22,426 [Executor task launch worker for task 37] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-05 15:58:22,426 [Executor task launch worker for task 36] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-05 15:58:22,442 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 353
2021-12-05 15:58:22,442 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 447
2021-12-05 15:58:22,442 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 314
2021-12-05 15:58:22,442 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 344
2021-12-05 15:58:22,442 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 391
2021-12-05 15:58:22,443 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 368
2021-12-05 15:58:22,443 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 421
2021-12-05 15:58:22,443 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 335
2021-12-05 15:58:22,443 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 341
2021-12-05 15:58:22,443 [dispatcher-event-loop-8] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_14_piece0 on qb:57815 in memory (size: 2.9 KB, free: 1990.8 MB)
2021-12-05 15:58:22,444 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 422
2021-12-05 15:58:22,444 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 332
2021-12-05 15:58:22,444 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 374
2021-12-05 15:58:22,444 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 306
2021-12-05 15:58:22,444 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 318
2021-12-05 15:58:22,444 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 337
2021-12-05 15:58:22,444 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 393
2021-12-05 15:58:22,444 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 436
2021-12-05 15:58:22,444 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 350
2021-12-05 15:58:22,444 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 439
2021-12-05 15:58:22,444 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 349
2021-12-05 15:58:22,444 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 433
2021-12-05 15:58:22,444 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 281
2021-12-05 15:58:22,444 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 346
2021-12-05 15:58:22,444 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 343
2021-12-05 15:58:22,444 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 290
2021-12-05 15:58:22,444 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 294
2021-12-05 15:58:22,444 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 444
2021-12-05 15:58:22,444 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 312
2021-12-05 15:58:22,444 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 395
2021-12-05 15:58:22,444 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 399
2021-12-05 15:58:22,444 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 384
2021-12-05 15:58:22,444 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 304
2021-12-05 15:58:22,444 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 316
2021-12-05 15:58:22,444 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 362
2021-12-05 15:58:22,444 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 331
2021-12-05 15:58:22,444 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 292
2021-12-05 15:58:22,445 [dispatcher-event-loop-9] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_13_piece0 on qb:57815 in memory (size: 2.2 KB, free: 1990.8 MB)
2021-12-05 15:58:22,445 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 310
2021-12-05 15:58:22,445 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 431
2021-12-05 15:58:22,445 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 303
2021-12-05 15:58:22,446 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 324
2021-12-05 15:58:22,446 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 448
2021-12-05 15:58:22,446 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 378
2021-12-05 15:58:22,446 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 282
2021-12-05 15:58:22,446 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 298
2021-12-05 15:58:22,446 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 277
2021-12-05 15:58:22,446 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 354
2021-12-05 15:58:22,446 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 423
2021-12-05 15:58:22,446 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 326
2021-12-05 15:58:22,446 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 381
2021-12-05 15:58:22,446 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 418
2021-12-05 15:58:22,446 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 389
2021-12-05 15:58:22,446 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 340
2021-12-05 15:58:22,446 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 429
2021-12-05 15:58:22,446 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 301
2021-12-05 15:58:22,446 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 287
2021-12-05 15:58:22,446 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 430
2021-12-05 15:58:22,446 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 434
2021-12-05 15:58:22,446 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 323
2021-12-05 15:58:22,446 [dispatcher-event-loop-4] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_12_piece0 on qb:57815 in memory (size: 2.9 KB, free: 1990.8 MB)
2021-12-05 15:58:22,447 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 309
2021-12-05 15:58:22,447 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 435
2021-12-05 15:58:22,447 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 412
2021-12-05 15:58:22,447 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 386
2021-12-05 15:58:22,447 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 372
2021-12-05 15:58:22,447 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 370
2021-12-05 15:58:22,448 [dispatcher-event-loop-3] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_17_piece0 on qb:57815 in memory (size: 2.3 KB, free: 1990.8 MB)
2021-12-05 15:58:22,448 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 348
2021-12-05 15:58:22,448 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 364
2021-12-05 15:58:22,448 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 329
2021-12-05 15:58:22,448 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 401
2021-12-05 15:58:22,448 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 289
2021-12-05 15:58:22,448 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 322
2021-12-05 15:58:22,448 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 387
2021-12-05 15:58:22,448 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 388
2021-12-05 15:58:22,448 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 302
2021-12-05 15:58:22,448 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 295
2021-12-05 15:58:22,448 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 438
2021-12-05 15:58:22,448 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 449
2021-12-05 15:58:22,448 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 357
2021-12-05 15:58:22,448 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 390
2021-12-05 15:58:22,448 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 315
2021-12-05 15:58:22,448 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 334
2021-12-05 15:58:22,448 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 426
2021-12-05 15:58:22,448 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 400
2021-12-05 15:58:22,448 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 345
2021-12-05 15:58:22,448 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 398
2021-12-05 15:58:22,448 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 402
2021-12-05 15:58:22,448 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 317
2021-12-05 15:58:22,448 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 414
2021-12-05 15:58:22,448 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 377
2021-12-05 15:58:22,448 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 420
2021-12-05 15:58:22,448 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 342
2021-12-05 15:58:22,448 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 361
2021-12-05 15:58:22,448 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 375
2021-12-05 15:58:22,448 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 405
2021-12-05 15:58:22,448 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 371
2021-12-05 15:58:22,448 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 347
2021-12-05 15:58:22,449 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 305
2021-12-05 15:58:22,449 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 363
2021-12-05 15:58:22,449 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 352
2021-12-05 15:58:22,449 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 339
2021-12-05 15:58:22,449 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 321
2021-12-05 15:58:22,449 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 319
2021-12-05 15:58:22,449 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 404
2021-12-05 15:58:22,449 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 380
2021-12-05 15:58:22,449 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 275
2021-12-05 15:58:22,449 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 427
2021-12-05 15:58:22,449 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 432
2021-12-05 15:58:22,449 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 376
2021-12-05 15:58:22,449 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 373
2021-12-05 15:58:22,449 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 284
2021-12-05 15:58:22,449 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 320
2021-12-05 15:58:22,449 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 338
2021-12-05 15:58:22,449 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 443
2021-12-05 15:58:22,449 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 358
2021-12-05 15:58:22,449 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 385
2021-12-05 15:58:22,449 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 336
2021-12-05 15:58:22,449 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 446
2021-12-05 15:58:22,449 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 406
2021-12-05 15:58:22,449 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 383
2021-12-05 15:58:22,449 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 299
2021-12-05 15:58:22,449 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 356
2021-12-05 15:58:22,449 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 394
2021-12-05 15:58:22,449 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 416
2021-12-05 15:58:22,449 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 285
2021-12-05 15:58:22,450 [dispatcher-event-loop-8] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_18_piece0 on qb:57815 in memory (size: 2.1 KB, free: 1990.8 MB)
2021-12-05 15:58:22,450 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 311
2021-12-05 15:58:22,451 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 308
2021-12-05 15:58:22,451 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 425
2021-12-05 15:58:22,451 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 328
2021-12-05 15:58:22,451 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 441
2021-12-05 15:58:22,451 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 330
2021-12-05 15:58:22,451 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 445
2021-12-05 15:58:22,451 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 403
2021-12-05 15:58:22,451 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 286
2021-12-05 15:58:22,451 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 411
2021-12-05 15:58:22,451 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 325
2021-12-05 15:58:22,451 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 413
2021-12-05 15:58:22,451 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 300
2021-12-05 15:58:22,451 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 359
2021-12-05 15:58:22,451 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 288
2021-12-05 15:58:22,451 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 415
2021-12-05 15:58:22,451 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 417
2021-12-05 15:58:22,451 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 396
2021-12-05 15:58:22,452 [dispatcher-event-loop-9] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_15_piece0 on qb:57815 in memory (size: 2.2 KB, free: 1990.8 MB)
2021-12-05 15:58:22,452 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 276
2021-12-05 15:58:22,452 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 442
2021-12-05 15:58:22,452 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 293
2021-12-05 15:58:22,452 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 367
2021-12-05 15:58:22,452 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 437
2021-12-05 15:58:22,452 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 408
2021-12-05 15:58:22,452 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 369
2021-12-05 15:58:22,452 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 283
2021-12-05 15:58:22,452 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 382
2021-12-05 15:58:22,452 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 327
2021-12-05 15:58:22,452 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 333
2021-12-05 15:58:22,452 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 392
2021-12-05 15:58:22,452 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 296
2021-12-05 15:58:22,452 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 409
2021-12-05 15:58:22,452 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 351
2021-12-05 15:58:22,452 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 297
2021-12-05 15:58:22,452 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 410
2021-12-05 15:58:22,452 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 419
2021-12-05 15:58:22,452 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 366
2021-12-05 15:58:22,452 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 440
2021-12-05 15:58:22,452 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 355
2021-12-05 15:58:22,452 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 291
2021-12-05 15:58:22,452 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 407
2021-12-05 15:58:22,452 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 278
2021-12-05 15:58:22,452 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 307
2021-12-05 15:58:22,452 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 379
2021-12-05 15:58:22,453 [dispatcher-event-loop-4] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_16_piece0 on qb:57815 in memory (size: 2.3 KB, free: 1990.8 MB)
2021-12-05 15:58:22,454 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 424
2021-12-05 15:58:22,454 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 360
2021-12-05 15:58:22,454 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 428
2021-12-05 15:58:22,454 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 397
2021-12-05 15:58:22,454 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 280
2021-12-05 15:58:22,454 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 313
2021-12-05 15:58:22,454 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 279
2021-12-05 15:58:22,454 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 365
2021-12-05 15:58:22,503 [Executor task launch worker for task 36] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 26.0 (TID 36). 78505 bytes result sent to driver
2021-12-05 15:58:22,504 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 26.0 (TID 36) in 82 ms on localhost (executor driver) (1/2)
2021-12-05 15:58:22,515 [Executor task launch worker for task 37] INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 26.0 (TID 37). 82318 bytes result sent to driver
2021-12-05 15:58:22,516 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 26.0 (TID 37) in 94 ms on localhost (executor driver) (2/2)
2021-12-05 15:58:22,516 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 26.0, whose tasks have all completed, from pool 
2021-12-05 15:58:22,516 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 26 (collect at PaidPromotionAdjustParameter.scala:146) finished in 0.098 s
2021-12-05 15:58:22,517 [main] INFO [org.apache.spark.scheduler.DAGScheduler] - Job 10 finished: collect at PaidPromotionAdjustParameter.scala:146, took 0.099746 s
2021-12-05 15:58:22,521 [main] INFO [org.apache.spark.SparkContext] - Starting job: collect at PaidPromotionAdjustParameter.scala:147
2021-12-05 15:58:22,522 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 11 (collect at PaidPromotionAdjustParameter.scala:147) with 2 output partitions
2021-12-05 15:58:22,522 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 31 (collect at PaidPromotionAdjustParameter.scala:147)
2021-12-05 15:58:22,522 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 30, ShuffleMapStage 28)
2021-12-05 15:58:22,522 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2021-12-05 15:58:22,522 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 31 (MapPartitionsRDD[32] at intersection at PaidPromotionAdjustParameter.scala:135), which has no missing parents
2021-12-05 15:58:22,523 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_20 stored as values in memory (estimated size 3.8 KB, free 1990.5 MB)
2021-12-05 15:58:22,524 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_20_piece0 stored as bytes in memory (estimated size 2.2 KB, free 1990.5 MB)
2021-12-05 15:58:22,525 [dispatcher-event-loop-3] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_20_piece0 in memory on qb:57815 (size: 2.2 KB, free: 1990.8 MB)
2021-12-05 15:58:22,525 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 20 from broadcast at DAGScheduler.scala:1039
2021-12-05 15:58:22,525 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from ResultStage 31 (MapPartitionsRDD[32] at intersection at PaidPromotionAdjustParameter.scala:135) (first 15 tasks are for partitions Vector(0, 1))
2021-12-05 15:58:22,525 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 31.0 with 2 tasks
2021-12-05 15:58:22,526 [dispatcher-event-loop-6] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 31.0 (TID 38, localhost, executor driver, partition 0, PROCESS_LOCAL, 7712 bytes)
2021-12-05 15:58:22,526 [dispatcher-event-loop-6] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 31.0 (TID 39, localhost, executor driver, partition 1, PROCESS_LOCAL, 7712 bytes)
2021-12-05 15:58:22,526 [Executor task launch worker for task 39] INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 31.0 (TID 39)
2021-12-05 15:58:22,526 [Executor task launch worker for task 38] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 31.0 (TID 38)
2021-12-05 15:58:22,527 [Executor task launch worker for task 38] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2021-12-05 15:58:22,527 [Executor task launch worker for task 38] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-05 15:58:22,527 [Executor task launch worker for task 39] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2021-12-05 15:58:22,527 [Executor task launch worker for task 39] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-05 15:58:22,529 [Executor task launch worker for task 39] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2021-12-05 15:58:22,529 [Executor task launch worker for task 39] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-05 15:58:22,529 [Executor task launch worker for task 38] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2021-12-05 15:58:22,529 [Executor task launch worker for task 38] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-05 15:58:22,534 [Executor task launch worker for task 39] INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 31.0 (TID 39). 2732 bytes result sent to driver
2021-12-05 15:58:22,534 [Executor task launch worker for task 38] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 31.0 (TID 38). 2829 bytes result sent to driver
2021-12-05 15:58:22,534 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 31.0 (TID 39) in 8 ms on localhost (executor driver) (1/2)
2021-12-05 15:58:22,534 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 31.0 (TID 38) in 8 ms on localhost (executor driver) (2/2)
2021-12-05 15:58:22,534 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 31.0, whose tasks have all completed, from pool 
2021-12-05 15:58:22,535 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 31 (collect at PaidPromotionAdjustParameter.scala:147) finished in 0.013 s
2021-12-05 15:58:22,535 [main] INFO [org.apache.spark.scheduler.DAGScheduler] - Job 11 finished: collect at PaidPromotionAdjustParameter.scala:147, took 0.013387 s
2021-12-05 15:58:22,554 [main] INFO [org.apache.spark.SparkContext] - Starting job: count at PaidPromotionAdjustParameter.scala:156
2021-12-05 15:58:22,555 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 12 (count at PaidPromotionAdjustParameter.scala:156) with 4 output partitions
2021-12-05 15:58:22,556 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 32 (count at PaidPromotionAdjustParameter.scala:156)
2021-12-05 15:58:22,556 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List()
2021-12-05 15:58:22,556 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2021-12-05 15:58:22,556 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 32 (UnionRDD[35] at union at PaidPromotionAdjustParameter.scala:154), which has no missing parents
2021-12-05 15:58:22,566 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_21 stored as values in memory (estimated size 171.2 KB, free 1990.3 MB)
2021-12-05 15:58:22,568 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_21_piece0 stored as bytes in memory (estimated size 60.9 KB, free 1990.2 MB)
2021-12-05 15:58:22,569 [dispatcher-event-loop-9] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_21_piece0 in memory on qb:57815 (size: 60.9 KB, free: 1990.7 MB)
2021-12-05 15:58:22,569 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 21 from broadcast at DAGScheduler.scala:1039
2021-12-05 15:58:22,569 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 4 missing tasks from ResultStage 32 (UnionRDD[35] at union at PaidPromotionAdjustParameter.scala:154) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
2021-12-05 15:58:22,569 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 32.0 with 4 tasks
2021-12-05 15:58:22,571 [dispatcher-event-loop-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 32.0 (TID 40, localhost, executor driver, partition 0, ANY, 8005 bytes)
2021-12-05 15:58:22,571 [dispatcher-event-loop-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 32.0 (TID 41, localhost, executor driver, partition 1, ANY, 8005 bytes)
2021-12-05 15:58:22,571 [dispatcher-event-loop-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 2.0 in stage 32.0 (TID 42, localhost, executor driver, partition 2, ANY, 8005 bytes)
2021-12-05 15:58:22,571 [dispatcher-event-loop-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 3.0 in stage 32.0 (TID 43, localhost, executor driver, partition 3, ANY, 8005 bytes)
2021-12-05 15:58:22,572 [Executor task launch worker for task 42] INFO [org.apache.spark.executor.Executor] - Running task 2.0 in stage 32.0 (TID 42)
2021-12-05 15:58:22,572 [Executor task launch worker for task 43] INFO [org.apache.spark.executor.Executor] - Running task 3.0 in stage 32.0 (TID 43)
2021-12-05 15:58:22,572 [Executor task launch worker for task 41] INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 32.0 (TID 41)
2021-12-05 15:58:22,572 [Executor task launch worker for task 40] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 32.0 (TID 40)
2021-12-05 15:58:22,576 [Executor task launch worker for task 40] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/order_data.bcp:0+3442194
2021-12-05 15:58:22,576 [Executor task launch worker for task 42] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/order_data.bcp:0+3442194
2021-12-05 15:58:22,576 [Executor task launch worker for task 41] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/order_data.bcp:3442194+3442195
2021-12-05 15:58:22,576 [Executor task launch worker for task 43] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/order_data.bcp:3442194+3442195
2021-12-05 15:58:23,502 [Executor task launch worker for task 42] INFO [org.apache.spark.executor.Executor] - Finished task 2.0 in stage 32.0 (TID 42). 754 bytes result sent to driver
2021-12-05 15:58:23,502 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 2.0 in stage 32.0 (TID 42) in 931 ms on localhost (executor driver) (1/4)
2021-12-05 15:58:23,585 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 451
2021-12-05 15:58:23,585 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 465
2021-12-05 15:58:23,585 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 457
2021-12-05 15:58:23,585 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 471
2021-12-05 15:58:23,585 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 453
2021-12-05 15:58:23,585 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 492
2021-12-05 15:58:23,585 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 486
2021-12-05 15:58:23,585 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 452
2021-12-05 15:58:23,585 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 477
2021-12-05 15:58:23,585 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 469
2021-12-05 15:58:23,585 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 482
2021-12-05 15:58:23,585 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 481
2021-12-05 15:58:23,585 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 470
2021-12-05 15:58:23,585 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 499
2021-12-05 15:58:23,585 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 468
2021-12-05 15:58:23,585 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 459
2021-12-05 15:58:23,585 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 487
2021-12-05 15:58:23,585 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 495
2021-12-05 15:58:23,585 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 478
2021-12-05 15:58:23,585 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 456
2021-12-05 15:58:23,585 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 480
2021-12-05 15:58:23,585 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 479
2021-12-05 15:58:23,585 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 497
2021-12-05 15:58:23,585 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 473
2021-12-05 15:58:23,585 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 476
2021-12-05 15:58:23,585 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 464
2021-12-05 15:58:23,585 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 474
2021-12-05 15:58:23,585 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 494
2021-12-05 15:58:23,586 [dispatcher-event-loop-1] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_20_piece0 on qb:57815 in memory (size: 2.2 KB, free: 1990.7 MB)
2021-12-05 15:58:23,586 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 493
2021-12-05 15:58:23,586 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 450
2021-12-05 15:58:23,586 [dispatcher-event-loop-9] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_19_piece0 on qb:57815 in memory (size: 2.2 KB, free: 1990.7 MB)
2021-12-05 15:58:23,587 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 460
2021-12-05 15:58:23,587 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 462
2021-12-05 15:58:23,587 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 496
2021-12-05 15:58:23,587 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 483
2021-12-05 15:58:23,587 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 454
2021-12-05 15:58:23,587 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 475
2021-12-05 15:58:23,587 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 498
2021-12-05 15:58:23,587 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 490
2021-12-05 15:58:23,587 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 467
2021-12-05 15:58:23,587 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 485
2021-12-05 15:58:23,587 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 458
2021-12-05 15:58:23,587 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 488
2021-12-05 15:58:23,587 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 466
2021-12-05 15:58:23,587 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 455
2021-12-05 15:58:23,587 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 463
2021-12-05 15:58:23,587 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 489
2021-12-05 15:58:23,587 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 472
2021-12-05 15:58:23,587 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 484
2021-12-05 15:58:23,587 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 461
2021-12-05 15:58:23,587 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 491
2021-12-05 15:58:23,884 [Executor task launch worker for task 40] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 32.0 (TID 40). 797 bytes result sent to driver
2021-12-05 15:58:23,884 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 32.0 (TID 40) in 1315 ms on localhost (executor driver) (2/4)
2021-12-05 15:58:24,410 [Executor task launch worker for task 43] INFO [org.apache.spark.executor.Executor] - Finished task 3.0 in stage 32.0 (TID 43). 797 bytes result sent to driver
2021-12-05 15:58:24,411 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 3.0 in stage 32.0 (TID 43) in 1839 ms on localhost (executor driver) (3/4)
2021-12-05 15:58:24,441 [Executor task launch worker for task 41] INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 32.0 (TID 41). 797 bytes result sent to driver
2021-12-05 15:58:24,441 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 32.0 (TID 41) in 1870 ms on localhost (executor driver) (4/4)
2021-12-05 15:58:24,442 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 32.0, whose tasks have all completed, from pool 
2021-12-05 15:58:24,442 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 32 (count at PaidPromotionAdjustParameter.scala:156) finished in 1.885 s
2021-12-05 15:58:24,442 [main] INFO [org.apache.spark.scheduler.DAGScheduler] - Job 12 finished: count at PaidPromotionAdjustParameter.scala:156, took 1.888450 s
2021-12-05 15:58:24,442 [main] INFO [PaidPromotion$] - 最终训练集数量：101209
2021-12-05 15:58:24,444 [main] INFO [org.apache.spark.SparkContext] - Starting job: count at PaidPromotionAdjustParameter.scala:157
2021-12-05 15:58:24,444 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 13 (count at PaidPromotionAdjustParameter.scala:157) with 2 output partitions
2021-12-05 15:58:24,444 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 33 (count at PaidPromotionAdjustParameter.scala:157)
2021-12-05 15:58:24,444 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List()
2021-12-05 15:58:24,444 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2021-12-05 15:58:24,445 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 33 (MapPartitionsRDD[33] at filter at PaidPromotionAdjustParameter.scala:150), which has no missing parents
2021-12-05 15:58:24,449 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_22 stored as values in memory (estimated size 170.7 KB, free 1990.1 MB)
2021-12-05 15:58:24,451 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_22_piece0 stored as bytes in memory (estimated size 60.7 KB, free 1990.0 MB)
2021-12-05 15:58:24,452 [dispatcher-event-loop-2] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_22_piece0 in memory on qb:57815 (size: 60.7 KB, free: 1990.7 MB)
2021-12-05 15:58:24,452 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 22 from broadcast at DAGScheduler.scala:1039
2021-12-05 15:58:24,452 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from ResultStage 33 (MapPartitionsRDD[33] at filter at PaidPromotionAdjustParameter.scala:150) (first 15 tasks are for partitions Vector(0, 1))
2021-12-05 15:58:24,452 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 33.0 with 2 tasks
2021-12-05 15:58:24,453 [dispatcher-event-loop-7] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 33.0 (TID 44, localhost, executor driver, partition 0, ANY, 7896 bytes)
2021-12-05 15:58:24,453 [dispatcher-event-loop-7] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 33.0 (TID 45, localhost, executor driver, partition 1, ANY, 7896 bytes)
2021-12-05 15:58:24,453 [Executor task launch worker for task 45] INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 33.0 (TID 45)
2021-12-05 15:58:24,453 [Executor task launch worker for task 44] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 33.0 (TID 44)
2021-12-05 15:58:24,455 [Executor task launch worker for task 45] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/order_data.bcp:3442194+3442195
2021-12-05 15:58:24,455 [Executor task launch worker for task 44] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/order_data.bcp:0+3442194
2021-12-05 15:58:25,923 [Executor task launch worker for task 45] INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 33.0 (TID 45). 753 bytes result sent to driver
2021-12-05 15:58:25,923 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 33.0 (TID 45) in 1470 ms on localhost (executor driver) (1/2)
2021-12-05 15:58:27,224 [Executor task launch worker for task 44] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 33.0 (TID 44). 710 bytes result sent to driver
2021-12-05 15:58:27,224 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 33.0 (TID 44) in 2771 ms on localhost (executor driver) (2/2)
2021-12-05 15:58:27,224 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 33.0, whose tasks have all completed, from pool 
2021-12-05 15:58:27,224 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 33 (count at PaidPromotionAdjustParameter.scala:157) finished in 2.779 s
2021-12-05 15:58:27,225 [main] INFO [org.apache.spark.scheduler.DAGScheduler] - Job 13 finished: count at PaidPromotionAdjustParameter.scala:157, took 2.780967 s
2021-12-05 15:58:27,225 [main] INFO [PaidPromotion$] - 最终验证集数量：6085
2021-12-05 15:58:27,262 [main] INFO [PaidPromotion$] - -----------------------------------
2021-12-05 15:58:27,264 [main] INFO [org.apache.spark.SparkContext] - Starting job: count at PaidPromotionAdjustParameter.scala:169
2021-12-05 15:58:27,264 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 37 (distinct at PaidPromotionAdjustParameter.scala:160)
2021-12-05 15:58:27,264 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 14 (count at PaidPromotionAdjustParameter.scala:169) with 4 output partitions
2021-12-05 15:58:27,264 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 35 (count at PaidPromotionAdjustParameter.scala:169)
2021-12-05 15:58:27,264 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 34)
2021-12-05 15:58:27,264 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List(ShuffleMapStage 34)
2021-12-05 15:58:27,265 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ShuffleMapStage 34 (MapPartitionsRDD[37] at distinct at PaidPromotionAdjustParameter.scala:160), which has no missing parents
2021-12-05 15:58:27,266 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_23 stored as values in memory (estimated size 172.8 KB, free 1989.8 MB)
2021-12-05 15:58:27,271 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 520
2021-12-05 15:58:27,271 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 510
2021-12-05 15:58:27,271 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 534
2021-12-05 15:58:27,271 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 528
2021-12-05 15:58:27,271 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 502
2021-12-05 15:58:27,271 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 515
2021-12-05 15:58:27,271 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 545
2021-12-05 15:58:27,271 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 540
2021-12-05 15:58:27,271 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 517
2021-12-05 15:58:27,271 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 547
2021-12-05 15:58:27,271 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 504
2021-12-05 15:58:27,271 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 535
2021-12-05 15:58:27,271 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 537
2021-12-05 15:58:27,271 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 506
2021-12-05 15:58:27,271 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 533
2021-12-05 15:58:27,271 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 548
2021-12-05 15:58:27,271 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 513
2021-12-05 15:58:27,271 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 544
2021-12-05 15:58:27,271 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 532
2021-12-05 15:58:27,271 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 505
2021-12-05 15:58:27,272 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 521
2021-12-05 15:58:27,272 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 526
2021-12-05 15:58:27,272 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 507
2021-12-05 15:58:27,272 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 549
2021-12-05 15:58:27,272 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 541
2021-12-05 15:58:27,272 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 543
2021-12-05 15:58:27,272 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 501
2021-12-05 15:58:27,272 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 523
2021-12-05 15:58:27,272 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_23_piece0 stored as bytes in memory (estimated size 61.9 KB, free 1989.8 MB)
2021-12-05 15:58:27,272 [dispatcher-event-loop-9] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_23_piece0 in memory on qb:57815 (size: 61.9 KB, free: 1990.6 MB)
2021-12-05 15:58:27,272 [dispatcher-event-loop-9] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_22_piece0 on qb:57815 in memory (size: 60.7 KB, free: 1990.7 MB)
2021-12-05 15:58:27,272 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 23 from broadcast at DAGScheduler.scala:1039
2021-12-05 15:58:27,273 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 508
2021-12-05 15:58:27,273 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 518
2021-12-05 15:58:27,273 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 4 missing tasks from ShuffleMapStage 34 (MapPartitionsRDD[37] at distinct at PaidPromotionAdjustParameter.scala:160) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
2021-12-05 15:58:27,273 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 539
2021-12-05 15:58:27,273 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 538
2021-12-05 15:58:27,273 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 527
2021-12-05 15:58:27,273 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 525
2021-12-05 15:58:27,273 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 542
2021-12-05 15:58:27,273 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 34.0 with 4 tasks
2021-12-05 15:58:27,273 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 519
2021-12-05 15:58:27,273 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 531
2021-12-05 15:58:27,273 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 530
2021-12-05 15:58:27,273 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 500
2021-12-05 15:58:27,273 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 546
2021-12-05 15:58:27,273 [dispatcher-event-loop-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 34.0 (TID 46, localhost, executor driver, partition 0, ANY, 7994 bytes)
2021-12-05 15:58:27,274 [dispatcher-event-loop-7] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_21_piece0 on qb:57815 in memory (size: 60.9 KB, free: 1990.7 MB)
2021-12-05 15:58:27,274 [dispatcher-event-loop-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 34.0 (TID 47, localhost, executor driver, partition 1, ANY, 7994 bytes)
2021-12-05 15:58:27,274 [dispatcher-event-loop-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 2.0 in stage 34.0 (TID 48, localhost, executor driver, partition 2, ANY, 7994 bytes)
2021-12-05 15:58:27,274 [dispatcher-event-loop-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 3.0 in stage 34.0 (TID 49, localhost, executor driver, partition 3, ANY, 7994 bytes)
2021-12-05 15:58:27,274 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 512
2021-12-05 15:58:27,274 [Executor task launch worker for task 46] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 34.0 (TID 46)
2021-12-05 15:58:27,274 [Executor task launch worker for task 49] INFO [org.apache.spark.executor.Executor] - Running task 3.0 in stage 34.0 (TID 49)
2021-12-05 15:58:27,274 [Executor task launch worker for task 48] INFO [org.apache.spark.executor.Executor] - Running task 2.0 in stage 34.0 (TID 48)
2021-12-05 15:58:27,274 [Executor task launch worker for task 47] INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 34.0 (TID 47)
2021-12-05 15:58:27,274 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 516
2021-12-05 15:58:27,274 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 522
2021-12-05 15:58:27,274 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 529
2021-12-05 15:58:27,274 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 509
2021-12-05 15:58:27,274 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 503
2021-12-05 15:58:27,274 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 524
2021-12-05 15:58:27,274 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 511
2021-12-05 15:58:27,274 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 514
2021-12-05 15:58:27,274 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 536
2021-12-05 15:58:27,278 [Executor task launch worker for task 47] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/order_data.bcp:3442194+3442195
2021-12-05 15:58:27,278 [Executor task launch worker for task 49] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/order_data.bcp:3442194+3442195
2021-12-05 15:58:27,278 [Executor task launch worker for task 46] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/order_data.bcp:0+3442194
2021-12-05 15:58:27,278 [Executor task launch worker for task 48] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/order_data.bcp:0+3442194
2021-12-05 15:58:28,590 [Executor task launch worker for task 48] INFO [org.apache.spark.executor.Executor] - Finished task 2.0 in stage 34.0 (TID 48). 991 bytes result sent to driver
2021-12-05 15:58:28,590 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 2.0 in stage 34.0 (TID 48) in 1316 ms on localhost (executor driver) (1/4)
2021-12-05 15:58:28,802 [Executor task launch worker for task 46] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 34.0 (TID 46). 991 bytes result sent to driver
2021-12-05 15:58:28,803 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 34.0 (TID 46) in 1530 ms on localhost (executor driver) (2/4)
2021-12-05 15:58:28,911 [Executor task launch worker for task 47] INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 34.0 (TID 47). 1034 bytes result sent to driver
2021-12-05 15:58:28,912 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 34.0 (TID 47) in 1638 ms on localhost (executor driver) (3/4)
2021-12-05 15:58:29,149 [Executor task launch worker for task 49] INFO [org.apache.spark.executor.Executor] - Finished task 3.0 in stage 34.0 (TID 49). 1034 bytes result sent to driver
2021-12-05 15:58:29,150 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 3.0 in stage 34.0 (TID 49) in 1876 ms on localhost (executor driver) (4/4)
2021-12-05 15:58:29,150 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 34.0, whose tasks have all completed, from pool 
2021-12-05 15:58:29,150 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ShuffleMapStage 34 (distinct at PaidPromotionAdjustParameter.scala:160) finished in 1.885 s
2021-12-05 15:58:29,150 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - looking for newly runnable stages
2021-12-05 15:58:29,150 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - running: Set()
2021-12-05 15:58:29,150 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - waiting: Set(ResultStage 35)
2021-12-05 15:58:29,150 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - failed: Set()
2021-12-05 15:58:29,150 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 35 (MapPartitionsRDD[39] at distinct at PaidPromotionAdjustParameter.scala:160), which has no missing parents
2021-12-05 15:58:29,151 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_24 stored as values in memory (estimated size 3.7 KB, free 1990.2 MB)
2021-12-05 15:58:29,152 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_24_piece0 stored as bytes in memory (estimated size 2.2 KB, free 1990.2 MB)
2021-12-05 15:58:29,153 [dispatcher-event-loop-4] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_24_piece0 in memory on qb:57815 (size: 2.2 KB, free: 1990.7 MB)
2021-12-05 15:58:29,153 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 24 from broadcast at DAGScheduler.scala:1039
2021-12-05 15:58:29,153 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 4 missing tasks from ResultStage 35 (MapPartitionsRDD[39] at distinct at PaidPromotionAdjustParameter.scala:160) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
2021-12-05 15:58:29,153 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 35.0 with 4 tasks
2021-12-05 15:58:29,153 [dispatcher-event-loop-11] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 35.0 (TID 50, localhost, executor driver, partition 0, ANY, 7649 bytes)
2021-12-05 15:58:29,154 [dispatcher-event-loop-11] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 35.0 (TID 51, localhost, executor driver, partition 1, ANY, 7649 bytes)
2021-12-05 15:58:29,154 [dispatcher-event-loop-11] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 2.0 in stage 35.0 (TID 52, localhost, executor driver, partition 2, ANY, 7649 bytes)
2021-12-05 15:58:29,154 [dispatcher-event-loop-11] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 3.0 in stage 35.0 (TID 53, localhost, executor driver, partition 3, ANY, 7649 bytes)
2021-12-05 15:58:29,154 [Executor task launch worker for task 51] INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 35.0 (TID 51)
2021-12-05 15:58:29,154 [Executor task launch worker for task 53] INFO [org.apache.spark.executor.Executor] - Running task 3.0 in stage 35.0 (TID 53)
2021-12-05 15:58:29,154 [Executor task launch worker for task 52] INFO [org.apache.spark.executor.Executor] - Running task 2.0 in stage 35.0 (TID 52)
2021-12-05 15:58:29,154 [Executor task launch worker for task 50] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 35.0 (TID 50)
2021-12-05 15:58:29,155 [Executor task launch worker for task 51] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 4 non-empty blocks out of 4 blocks
2021-12-05 15:58:29,155 [Executor task launch worker for task 53] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 4 non-empty blocks out of 4 blocks
2021-12-05 15:58:29,155 [Executor task launch worker for task 51] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-05 15:58:29,155 [Executor task launch worker for task 53] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-05 15:58:29,155 [Executor task launch worker for task 50] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 4 non-empty blocks out of 4 blocks
2021-12-05 15:58:29,155 [Executor task launch worker for task 52] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 4 non-empty blocks out of 4 blocks
2021-12-05 15:58:29,155 [Executor task launch worker for task 50] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-05 15:58:29,155 [Executor task launch worker for task 52] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-05 15:58:29,202 [Executor task launch worker for task 52] INFO [org.apache.spark.executor.Executor] - Finished task 2.0 in stage 35.0 (TID 52). 1055 bytes result sent to driver
2021-12-05 15:58:29,202 [Executor task launch worker for task 51] INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 35.0 (TID 51). 1055 bytes result sent to driver
2021-12-05 15:58:29,202 [Executor task launch worker for task 50] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 35.0 (TID 50). 1055 bytes result sent to driver
2021-12-05 15:58:29,203 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 35.0 (TID 51) in 49 ms on localhost (executor driver) (1/4)
2021-12-05 15:58:29,203 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 2.0 in stage 35.0 (TID 52) in 49 ms on localhost (executor driver) (2/4)
2021-12-05 15:58:29,203 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 35.0 (TID 50) in 50 ms on localhost (executor driver) (3/4)
2021-12-05 15:58:29,206 [Executor task launch worker for task 53] INFO [org.apache.spark.executor.Executor] - Finished task 3.0 in stage 35.0 (TID 53). 1055 bytes result sent to driver
2021-12-05 15:58:29,206 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 3.0 in stage 35.0 (TID 53) in 52 ms on localhost (executor driver) (4/4)
2021-12-05 15:58:29,206 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 35.0, whose tasks have all completed, from pool 
2021-12-05 15:58:29,206 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 35 (count at PaidPromotionAdjustParameter.scala:169) finished in 0.056 s
2021-12-05 15:58:29,206 [main] INFO [org.apache.spark.scheduler.DAGScheduler] - Job 14 finished: count at PaidPromotionAdjustParameter.scala:169, took 1.942173 s
2021-12-05 15:58:29,207 [main] INFO [PaidPromotion$] - 最终训练集用户数 = 95323
2021-12-05 15:58:29,209 [main] INFO [org.apache.spark.SparkContext] - Starting job: count at PaidPromotionAdjustParameter.scala:170
2021-12-05 15:58:29,209 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 41 (distinct at PaidPromotionAdjustParameter.scala:161)
2021-12-05 15:58:29,209 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 15 (count at PaidPromotionAdjustParameter.scala:170) with 2 output partitions
2021-12-05 15:58:29,209 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 37 (count at PaidPromotionAdjustParameter.scala:170)
2021-12-05 15:58:29,209 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 36)
2021-12-05 15:58:29,209 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List(ShuffleMapStage 36)
2021-12-05 15:58:29,210 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ShuffleMapStage 36 (MapPartitionsRDD[41] at distinct at PaidPromotionAdjustParameter.scala:161), which has no missing parents
2021-12-05 15:58:29,212 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_25 stored as values in memory (estimated size 172.2 KB, free 1990.1 MB)
2021-12-05 15:58:29,214 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_25_piece0 stored as bytes in memory (estimated size 61.6 KB, free 1990.0 MB)
2021-12-05 15:58:29,215 [dispatcher-event-loop-0] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_25_piece0 in memory on qb:57815 (size: 61.6 KB, free: 1990.7 MB)
2021-12-05 15:58:29,215 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 25 from broadcast at DAGScheduler.scala:1039
2021-12-05 15:58:29,215 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from ShuffleMapStage 36 (MapPartitionsRDD[41] at distinct at PaidPromotionAdjustParameter.scala:161) (first 15 tasks are for partitions Vector(0, 1))
2021-12-05 15:58:29,215 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 36.0 with 2 tasks
2021-12-05 15:58:29,216 [dispatcher-event-loop-9] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 36.0 (TID 54, localhost, executor driver, partition 0, ANY, 7885 bytes)
2021-12-05 15:58:29,216 [dispatcher-event-loop-9] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 36.0 (TID 55, localhost, executor driver, partition 1, ANY, 7885 bytes)
2021-12-05 15:58:29,216 [Executor task launch worker for task 55] INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 36.0 (TID 55)
2021-12-05 15:58:29,216 [Executor task launch worker for task 54] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 36.0 (TID 54)
2021-12-05 15:58:29,218 [Executor task launch worker for task 54] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/order_data.bcp:0+3442194
2021-12-05 15:58:29,218 [Executor task launch worker for task 55] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/order_data.bcp:3442194+3442195
2021-12-05 15:58:30,523 [Executor task launch worker for task 55] INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 36.0 (TID 55). 989 bytes result sent to driver
2021-12-05 15:58:30,524 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 36.0 (TID 55) in 1308 ms on localhost (executor driver) (1/2)
2021-12-05 15:58:30,865 [Executor task launch worker for task 54] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 36.0 (TID 54). 989 bytes result sent to driver
2021-12-05 15:58:30,866 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 36.0 (TID 54) in 1650 ms on localhost (executor driver) (2/2)
2021-12-05 15:58:30,866 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 36.0, whose tasks have all completed, from pool 
2021-12-05 15:58:30,866 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ShuffleMapStage 36 (distinct at PaidPromotionAdjustParameter.scala:161) finished in 1.656 s
2021-12-05 15:58:30,866 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - looking for newly runnable stages
2021-12-05 15:58:30,866 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - running: Set()
2021-12-05 15:58:30,866 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - waiting: Set(ResultStage 37)
2021-12-05 15:58:30,866 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - failed: Set()
2021-12-05 15:58:30,866 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 37 (MapPartitionsRDD[43] at distinct at PaidPromotionAdjustParameter.scala:161), which has no missing parents
2021-12-05 15:58:30,867 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_26 stored as values in memory (estimated size 3.7 KB, free 1990.0 MB)
2021-12-05 15:58:30,869 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_26_piece0 stored as bytes in memory (estimated size 2.2 KB, free 1990.0 MB)
2021-12-05 15:58:30,869 [dispatcher-event-loop-1] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_26_piece0 in memory on qb:57815 (size: 2.2 KB, free: 1990.6 MB)
2021-12-05 15:58:30,869 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 26 from broadcast at DAGScheduler.scala:1039
2021-12-05 15:58:30,869 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from ResultStage 37 (MapPartitionsRDD[43] at distinct at PaidPromotionAdjustParameter.scala:161) (first 15 tasks are for partitions Vector(0, 1))
2021-12-05 15:58:30,869 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 37.0 with 2 tasks
2021-12-05 15:58:30,870 [dispatcher-event-loop-10] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 37.0 (TID 56, localhost, executor driver, partition 0, ANY, 7649 bytes)
2021-12-05 15:58:30,870 [dispatcher-event-loop-10] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 37.0 (TID 57, localhost, executor driver, partition 1, ANY, 7649 bytes)
2021-12-05 15:58:30,870 [Executor task launch worker for task 56] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 37.0 (TID 56)
2021-12-05 15:58:30,870 [Executor task launch worker for task 57] INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 37.0 (TID 57)
2021-12-05 15:58:30,871 [Executor task launch worker for task 57] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 2 non-empty blocks out of 2 blocks
2021-12-05 15:58:30,871 [Executor task launch worker for task 56] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 2 non-empty blocks out of 2 blocks
2021-12-05 15:58:30,871 [Executor task launch worker for task 57] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-05 15:58:30,871 [Executor task launch worker for task 56] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-05 15:58:30,889 [Executor task launch worker for task 57] INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 37.0 (TID 57). 1054 bytes result sent to driver
2021-12-05 15:58:30,889 [Executor task launch worker for task 56] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 37.0 (TID 56). 1054 bytes result sent to driver
2021-12-05 15:58:30,889 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 37.0 (TID 57) in 19 ms on localhost (executor driver) (1/2)
2021-12-05 15:58:30,889 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 37.0 (TID 56) in 19 ms on localhost (executor driver) (2/2)
2021-12-05 15:58:30,889 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 37.0, whose tasks have all completed, from pool 
2021-12-05 15:58:30,889 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 37 (count at PaidPromotionAdjustParameter.scala:170) finished in 0.022 s
2021-12-05 15:58:30,889 [main] INFO [org.apache.spark.scheduler.DAGScheduler] - Job 15 finished: count at PaidPromotionAdjustParameter.scala:170, took 1.680225 s
2021-12-05 15:58:30,889 [main] INFO [PaidPromotion$] - 最终验证集用户数 = 4776
2021-12-05 15:58:30,891 [main] INFO [org.apache.spark.SparkContext] - Starting job: count at PaidPromotionAdjustParameter.scala:171
2021-12-05 15:58:30,892 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 45 (intersection at PaidPromotionAdjustParameter.scala:162)
2021-12-05 15:58:30,892 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 44 (intersection at PaidPromotionAdjustParameter.scala:162)
2021-12-05 15:58:30,892 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 16 (count at PaidPromotionAdjustParameter.scala:171) with 4 output partitions
2021-12-05 15:58:30,892 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 42 (count at PaidPromotionAdjustParameter.scala:171)
2021-12-05 15:58:30,892 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 39, ShuffleMapStage 41)
2021-12-05 15:58:30,892 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List(ShuffleMapStage 39, ShuffleMapStage 41)
2021-12-05 15:58:30,892 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ShuffleMapStage 39 (MapPartitionsRDD[45] at intersection at PaidPromotionAdjustParameter.scala:162), which has no missing parents
2021-12-05 15:58:30,893 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_27 stored as values in memory (estimated size 4.0 KB, free 1990.0 MB)
2021-12-05 15:58:30,895 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_27_piece0 stored as bytes in memory (estimated size 2.3 KB, free 1990.0 MB)
2021-12-05 15:58:30,895 [dispatcher-event-loop-11] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_27_piece0 in memory on qb:57815 (size: 2.3 KB, free: 1990.6 MB)
2021-12-05 15:58:30,896 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 27 from broadcast at DAGScheduler.scala:1039
2021-12-05 15:58:30,896 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from ShuffleMapStage 39 (MapPartitionsRDD[45] at intersection at PaidPromotionAdjustParameter.scala:162) (first 15 tasks are for partitions Vector(0, 1))
2021-12-05 15:58:30,896 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 39.0 with 2 tasks
2021-12-05 15:58:30,896 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ShuffleMapStage 41 (MapPartitionsRDD[44] at intersection at PaidPromotionAdjustParameter.scala:162), which has no missing parents
2021-12-05 15:58:30,896 [dispatcher-event-loop-4] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 39.0 (TID 58, localhost, executor driver, partition 0, ANY, 7638 bytes)
2021-12-05 15:58:30,896 [dispatcher-event-loop-4] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 39.0 (TID 59, localhost, executor driver, partition 1, ANY, 7638 bytes)
2021-12-05 15:58:30,896 [Executor task launch worker for task 58] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 39.0 (TID 58)
2021-12-05 15:58:30,896 [Executor task launch worker for task 59] INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 39.0 (TID 59)
2021-12-05 15:58:30,897 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_28 stored as values in memory (estimated size 4.0 KB, free 1990.0 MB)
2021-12-05 15:58:30,897 [Executor task launch worker for task 59] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 2 non-empty blocks out of 2 blocks
2021-12-05 15:58:30,897 [Executor task launch worker for task 59] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-05 15:58:30,897 [Executor task launch worker for task 58] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 2 non-empty blocks out of 2 blocks
2021-12-05 15:58:30,897 [Executor task launch worker for task 58] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-05 15:58:30,899 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_28_piece0 stored as bytes in memory (estimated size 2.3 KB, free 1990.0 MB)
2021-12-05 15:58:30,899 [dispatcher-event-loop-8] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_28_piece0 in memory on qb:57815 (size: 2.3 KB, free: 1990.6 MB)
2021-12-05 15:58:30,899 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 28 from broadcast at DAGScheduler.scala:1039
2021-12-05 15:58:30,899 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 4 missing tasks from ShuffleMapStage 41 (MapPartitionsRDD[44] at intersection at PaidPromotionAdjustParameter.scala:162) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
2021-12-05 15:58:30,899 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 41.0 with 4 tasks
2021-12-05 15:58:30,900 [dispatcher-event-loop-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 41.0 (TID 60, localhost, executor driver, partition 0, ANY, 7638 bytes)
2021-12-05 15:58:30,900 [dispatcher-event-loop-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 41.0 (TID 61, localhost, executor driver, partition 1, ANY, 7638 bytes)
2021-12-05 15:58:30,900 [dispatcher-event-loop-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 2.0 in stage 41.0 (TID 62, localhost, executor driver, partition 2, ANY, 7638 bytes)
2021-12-05 15:58:30,900 [dispatcher-event-loop-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 3.0 in stage 41.0 (TID 63, localhost, executor driver, partition 3, ANY, 7638 bytes)
2021-12-05 15:58:30,900 [Executor task launch worker for task 60] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 41.0 (TID 60)
2021-12-05 15:58:30,900 [Executor task launch worker for task 61] INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 41.0 (TID 61)
2021-12-05 15:58:30,901 [Executor task launch worker for task 62] INFO [org.apache.spark.executor.Executor] - Running task 2.0 in stage 41.0 (TID 62)
2021-12-05 15:58:30,901 [Executor task launch worker for task 63] INFO [org.apache.spark.executor.Executor] - Running task 3.0 in stage 41.0 (TID 63)
2021-12-05 15:58:30,901 [Executor task launch worker for task 61] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 4 non-empty blocks out of 4 blocks
2021-12-05 15:58:30,901 [Executor task launch worker for task 61] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-05 15:58:30,901 [Executor task launch worker for task 60] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 4 non-empty blocks out of 4 blocks
2021-12-05 15:58:30,901 [Executor task launch worker for task 60] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-05 15:58:30,901 [Executor task launch worker for task 62] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 4 non-empty blocks out of 4 blocks
2021-12-05 15:58:30,901 [Executor task launch worker for task 63] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 4 non-empty blocks out of 4 blocks
2021-12-05 15:58:30,901 [Executor task launch worker for task 62] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-05 15:58:30,901 [Executor task launch worker for task 63] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-05 15:58:30,933 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 620
2021-12-05 15:58:30,936 [dispatcher-event-loop-0] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_25_piece0 on qb:57815 in memory (size: 61.6 KB, free: 1990.7 MB)
2021-12-05 15:58:30,943 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 561
2021-12-05 15:58:30,943 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 553
2021-12-05 15:58:30,943 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 629
2021-12-05 15:58:30,943 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 648
2021-12-05 15:58:30,943 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 635
2021-12-05 15:58:30,943 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 614
2021-12-05 15:58:30,943 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 579
2021-12-05 15:58:30,943 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 639
2021-12-05 15:58:30,943 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 640
2021-12-05 15:58:30,943 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 576
2021-12-05 15:58:30,943 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 633
2021-12-05 15:58:30,943 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 587
2021-12-05 15:58:30,943 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 571
2021-12-05 15:58:30,943 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 632
2021-12-05 15:58:30,943 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 631
2021-12-05 15:58:30,943 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 593
2021-12-05 15:58:30,943 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 601
2021-12-05 15:58:30,943 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 611
2021-12-05 15:58:30,943 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 564
2021-12-05 15:58:30,943 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 602
2021-12-05 15:58:30,943 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 644
2021-12-05 15:58:30,943 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 554
2021-12-05 15:58:30,943 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 642
2021-12-05 15:58:30,944 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 597
2021-12-05 15:58:30,944 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 624
2021-12-05 15:58:30,944 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 637
2021-12-05 15:58:30,945 [dispatcher-event-loop-2] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_24_piece0 on qb:57815 in memory (size: 2.2 KB, free: 1990.7 MB)
2021-12-05 15:58:30,945 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 606
2021-12-05 15:58:30,946 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 634
2021-12-05 15:58:30,946 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 586
2021-12-05 15:58:30,946 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 643
2021-12-05 15:58:30,946 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 628
2021-12-05 15:58:30,946 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 583
2021-12-05 15:58:30,946 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 615
2021-12-05 15:58:30,946 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 638
2021-12-05 15:58:30,946 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 600
2021-12-05 15:58:30,946 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 630
2021-12-05 15:58:30,946 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 559
2021-12-05 15:58:30,946 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 641
2021-12-05 15:58:30,946 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 595
2021-12-05 15:58:30,946 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 619
2021-12-05 15:58:30,946 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 591
2021-12-05 15:58:30,947 [dispatcher-event-loop-10] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_23_piece0 on qb:57815 in memory (size: 61.9 KB, free: 1990.8 MB)
2021-12-05 15:58:30,947 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 574
2021-12-05 15:58:30,947 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 569
2021-12-05 15:58:30,947 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 603
2021-12-05 15:58:30,947 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 596
2021-12-05 15:58:30,947 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 555
2021-12-05 15:58:30,947 [Executor task launch worker for task 58] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 39.0 (TID 58). 1249 bytes result sent to driver
2021-12-05 15:58:30,947 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 582
2021-12-05 15:58:30,947 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 621
2021-12-05 15:58:30,948 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 590
2021-12-05 15:58:30,948 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 649
2021-12-05 15:58:30,948 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 613
2021-12-05 15:58:30,948 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 565
2021-12-05 15:58:30,948 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 625
2021-12-05 15:58:30,948 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 557
2021-12-05 15:58:30,948 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 623
2021-12-05 15:58:30,948 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 617
2021-12-05 15:58:30,948 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 647
2021-12-05 15:58:30,948 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 570
2021-12-05 15:58:30,948 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 572
2021-12-05 15:58:30,948 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 39.0 (TID 58) in 52 ms on localhost (executor driver) (1/2)
2021-12-05 15:58:30,948 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 581
2021-12-05 15:58:30,948 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 588
2021-12-05 15:58:30,948 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 592
2021-12-05 15:58:30,948 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 610
2021-12-05 15:58:30,948 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 646
2021-12-05 15:58:30,948 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 577
2021-12-05 15:58:30,948 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 589
2021-12-05 15:58:30,948 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 612
2021-12-05 15:58:30,948 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 551
2021-12-05 15:58:30,949 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 636
2021-12-05 15:58:30,949 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 563
2021-12-05 15:58:30,950 [dispatcher-event-loop-9] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_26_piece0 on qb:57815 in memory (size: 2.2 KB, free: 1990.8 MB)
2021-12-05 15:58:30,950 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 562
2021-12-05 15:58:30,950 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 575
2021-12-05 15:58:30,950 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 594
2021-12-05 15:58:30,950 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 605
2021-12-05 15:58:30,950 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 608
2021-12-05 15:58:30,950 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 567
2021-12-05 15:58:30,950 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 607
2021-12-05 15:58:30,950 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 566
2021-12-05 15:58:30,950 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 599
2021-12-05 15:58:30,950 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 622
2021-12-05 15:58:30,950 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 618
2021-12-05 15:58:30,950 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 616
2021-12-05 15:58:30,950 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 550
2021-12-05 15:58:30,950 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 598
2021-12-05 15:58:30,950 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 578
2021-12-05 15:58:30,950 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 645
2021-12-05 15:58:30,950 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 558
2021-12-05 15:58:30,950 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 560
2021-12-05 15:58:30,950 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 556
2021-12-05 15:58:30,950 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 584
2021-12-05 15:58:30,950 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 626
2021-12-05 15:58:30,950 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 573
2021-12-05 15:58:30,950 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 552
2021-12-05 15:58:30,950 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 568
2021-12-05 15:58:30,950 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 604
2021-12-05 15:58:30,950 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 585
2021-12-05 15:58:30,950 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 609
2021-12-05 15:58:30,950 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 627
2021-12-05 15:58:30,950 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 580
2021-12-05 15:58:30,950 [Executor task launch worker for task 59] INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 39.0 (TID 59). 1249 bytes result sent to driver
2021-12-05 15:58:30,951 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 39.0 (TID 59) in 55 ms on localhost (executor driver) (2/2)
2021-12-05 15:58:30,951 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 39.0, whose tasks have all completed, from pool 
2021-12-05 15:58:30,951 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ShuffleMapStage 39 (intersection at PaidPromotionAdjustParameter.scala:162) finished in 0.059 s
2021-12-05 15:58:30,951 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - looking for newly runnable stages
2021-12-05 15:58:30,951 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - running: Set(ShuffleMapStage 41)
2021-12-05 15:58:30,951 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - waiting: Set(ResultStage 42)
2021-12-05 15:58:30,951 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - failed: Set()
2021-12-05 15:58:30,974 [Executor task launch worker for task 60] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 41.0 (TID 60). 1206 bytes result sent to driver
2021-12-05 15:58:30,975 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 41.0 (TID 60) in 75 ms on localhost (executor driver) (1/4)
2021-12-05 15:58:30,976 [Executor task launch worker for task 63] INFO [org.apache.spark.executor.Executor] - Finished task 3.0 in stage 41.0 (TID 63). 1206 bytes result sent to driver
2021-12-05 15:58:30,976 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 3.0 in stage 41.0 (TID 63) in 76 ms on localhost (executor driver) (2/4)
2021-12-05 15:58:30,978 [Executor task launch worker for task 62] INFO [org.apache.spark.executor.Executor] - Finished task 2.0 in stage 41.0 (TID 62). 1249 bytes result sent to driver
2021-12-05 15:58:30,979 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 2.0 in stage 41.0 (TID 62) in 79 ms on localhost (executor driver) (3/4)
2021-12-05 15:58:30,982 [Executor task launch worker for task 61] INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 41.0 (TID 61). 1206 bytes result sent to driver
2021-12-05 15:58:30,983 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 41.0 (TID 61) in 83 ms on localhost (executor driver) (4/4)
2021-12-05 15:58:30,983 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 41.0, whose tasks have all completed, from pool 
2021-12-05 15:58:30,983 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ShuffleMapStage 41 (intersection at PaidPromotionAdjustParameter.scala:162) finished in 0.086 s
2021-12-05 15:58:30,983 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - looking for newly runnable stages
2021-12-05 15:58:30,983 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - running: Set()
2021-12-05 15:58:30,983 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - waiting: Set(ResultStage 42)
2021-12-05 15:58:30,983 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - failed: Set()
2021-12-05 15:58:30,983 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 42 (MapPartitionsRDD[49] at intersection at PaidPromotionAdjustParameter.scala:162), which has no missing parents
2021-12-05 15:58:30,984 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_29 stored as values in memory (estimated size 3.6 KB, free 1990.5 MB)
2021-12-05 15:58:30,985 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_29_piece0 stored as bytes in memory (estimated size 2.1 KB, free 1990.5 MB)
2021-12-05 15:58:30,986 [dispatcher-event-loop-1] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_29_piece0 in memory on qb:57815 (size: 2.1 KB, free: 1990.8 MB)
2021-12-05 15:58:30,986 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 29 from broadcast at DAGScheduler.scala:1039
2021-12-05 15:58:30,986 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 4 missing tasks from ResultStage 42 (MapPartitionsRDD[49] at intersection at PaidPromotionAdjustParameter.scala:162) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
2021-12-05 15:58:30,986 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 42.0 with 4 tasks
2021-12-05 15:58:30,987 [dispatcher-event-loop-8] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 42.0 (TID 64, localhost, executor driver, partition 0, PROCESS_LOCAL, 7712 bytes)
2021-12-05 15:58:30,987 [dispatcher-event-loop-8] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 42.0 (TID 65, localhost, executor driver, partition 1, PROCESS_LOCAL, 7712 bytes)
2021-12-05 15:58:30,987 [dispatcher-event-loop-8] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 2.0 in stage 42.0 (TID 66, localhost, executor driver, partition 2, PROCESS_LOCAL, 7712 bytes)
2021-12-05 15:58:30,987 [dispatcher-event-loop-8] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 3.0 in stage 42.0 (TID 67, localhost, executor driver, partition 3, PROCESS_LOCAL, 7712 bytes)
2021-12-05 15:58:30,987 [Executor task launch worker for task 67] INFO [org.apache.spark.executor.Executor] - Running task 3.0 in stage 42.0 (TID 67)
2021-12-05 15:58:30,987 [Executor task launch worker for task 64] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 42.0 (TID 64)
2021-12-05 15:58:30,987 [Executor task launch worker for task 66] INFO [org.apache.spark.executor.Executor] - Running task 2.0 in stage 42.0 (TID 66)
2021-12-05 15:58:30,987 [Executor task launch worker for task 65] INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 42.0 (TID 65)
2021-12-05 15:58:30,988 [Executor task launch worker for task 67] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 4 blocks
2021-12-05 15:58:30,988 [Executor task launch worker for task 66] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 4 blocks
2021-12-05 15:58:30,988 [Executor task launch worker for task 65] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 4 blocks
2021-12-05 15:58:30,988 [Executor task launch worker for task 67] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-05 15:58:30,988 [Executor task launch worker for task 65] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-05 15:58:30,988 [Executor task launch worker for task 66] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-05 15:58:30,988 [Executor task launch worker for task 64] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 4 blocks
2021-12-05 15:58:30,988 [Executor task launch worker for task 64] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-05 15:58:30,990 [Executor task launch worker for task 65] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2021-12-05 15:58:30,990 [Executor task launch worker for task 64] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2021-12-05 15:58:30,990 [Executor task launch worker for task 65] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-05 15:58:30,990 [Executor task launch worker for task 64] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-05 15:58:30,990 [Executor task launch worker for task 66] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2021-12-05 15:58:30,990 [Executor task launch worker for task 67] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2021-12-05 15:58:30,990 [Executor task launch worker for task 66] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-05 15:58:30,990 [Executor task launch worker for task 67] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-05 15:58:31,038 [Executor task launch worker for task 64] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 42.0 (TID 64). 1054 bytes result sent to driver
2021-12-05 15:58:31,039 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 42.0 (TID 64) in 53 ms on localhost (executor driver) (1/4)
2021-12-05 15:58:31,039 [Executor task launch worker for task 66] INFO [org.apache.spark.executor.Executor] - Finished task 2.0 in stage 42.0 (TID 66). 1054 bytes result sent to driver
2021-12-05 15:58:31,039 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 2.0 in stage 42.0 (TID 66) in 52 ms on localhost (executor driver) (2/4)
2021-12-05 15:58:31,042 [Executor task launch worker for task 67] INFO [org.apache.spark.executor.Executor] - Finished task 3.0 in stage 42.0 (TID 67). 1054 bytes result sent to driver
2021-12-05 15:58:31,042 [Executor task launch worker for task 65] INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 42.0 (TID 65). 1054 bytes result sent to driver
2021-12-05 15:58:31,043 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 3.0 in stage 42.0 (TID 67) in 56 ms on localhost (executor driver) (3/4)
2021-12-05 15:58:31,043 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 42.0 (TID 65) in 56 ms on localhost (executor driver) (4/4)
2021-12-05 15:58:31,043 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 42.0, whose tasks have all completed, from pool 
2021-12-05 15:58:31,043 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 42 (count at PaidPromotionAdjustParameter.scala:171) finished in 0.059 s
2021-12-05 15:58:31,043 [main] INFO [org.apache.spark.scheduler.DAGScheduler] - Job 16 finished: count at PaidPromotionAdjustParameter.scala:171, took 0.151334 s
2021-12-05 15:58:31,044 [main] INFO [PaidPromotion$] - 最终共 同 用户数 = 4776
2021-12-05 15:58:31,046 [main] INFO [org.apache.spark.SparkContext] - Starting job: count at PaidPromotionAdjustParameter.scala:172
2021-12-05 15:58:31,046 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 51 (distinct at PaidPromotionAdjustParameter.scala:164)
2021-12-05 15:58:31,046 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 17 (count at PaidPromotionAdjustParameter.scala:172) with 4 output partitions
2021-12-05 15:58:31,046 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 44 (count at PaidPromotionAdjustParameter.scala:172)
2021-12-05 15:58:31,046 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 43)
2021-12-05 15:58:31,046 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List(ShuffleMapStage 43)
2021-12-05 15:58:31,047 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ShuffleMapStage 43 (MapPartitionsRDD[51] at distinct at PaidPromotionAdjustParameter.scala:164), which has no missing parents
2021-12-05 15:58:31,048 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_30 stored as values in memory (estimated size 172.8 KB, free 1990.3 MB)
2021-12-05 15:58:31,050 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_30_piece0 stored as bytes in memory (estimated size 61.9 KB, free 1990.2 MB)
2021-12-05 15:58:31,050 [dispatcher-event-loop-4] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_30_piece0 in memory on qb:57815 (size: 61.9 KB, free: 1990.7 MB)
2021-12-05 15:58:31,050 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 30 from broadcast at DAGScheduler.scala:1039
2021-12-05 15:58:31,051 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 4 missing tasks from ShuffleMapStage 43 (MapPartitionsRDD[51] at distinct at PaidPromotionAdjustParameter.scala:164) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
2021-12-05 15:58:31,051 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 43.0 with 4 tasks
2021-12-05 15:58:31,051 [dispatcher-event-loop-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 43.0 (TID 68, localhost, executor driver, partition 0, ANY, 7994 bytes)
2021-12-05 15:58:31,051 [dispatcher-event-loop-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 43.0 (TID 69, localhost, executor driver, partition 1, ANY, 7994 bytes)
2021-12-05 15:58:31,051 [dispatcher-event-loop-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 2.0 in stage 43.0 (TID 70, localhost, executor driver, partition 2, ANY, 7994 bytes)
2021-12-05 15:58:31,051 [dispatcher-event-loop-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 3.0 in stage 43.0 (TID 71, localhost, executor driver, partition 3, ANY, 7994 bytes)
2021-12-05 15:58:31,051 [Executor task launch worker for task 70] INFO [org.apache.spark.executor.Executor] - Running task 2.0 in stage 43.0 (TID 70)
2021-12-05 15:58:31,051 [Executor task launch worker for task 68] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 43.0 (TID 68)
2021-12-05 15:58:31,051 [Executor task launch worker for task 71] INFO [org.apache.spark.executor.Executor] - Running task 3.0 in stage 43.0 (TID 71)
2021-12-05 15:58:31,051 [Executor task launch worker for task 69] INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 43.0 (TID 69)
2021-12-05 15:58:31,054 [Executor task launch worker for task 71] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/order_data.bcp:3442194+3442195
2021-12-05 15:58:31,054 [Executor task launch worker for task 69] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/order_data.bcp:3442194+3442195
2021-12-05 15:58:31,054 [Executor task launch worker for task 68] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/order_data.bcp:0+3442194
2021-12-05 15:58:31,054 [Executor task launch worker for task 70] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/order_data.bcp:0+3442194
2021-12-05 15:58:31,986 [Executor task launch worker for task 70] INFO [org.apache.spark.executor.Executor] - Finished task 2.0 in stage 43.0 (TID 70). 991 bytes result sent to driver
2021-12-05 15:58:31,987 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 2.0 in stage 43.0 (TID 70) in 936 ms on localhost (executor driver) (1/4)
2021-12-05 15:58:32,073 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 665
2021-12-05 15:58:32,073 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 679
2021-12-05 15:58:32,073 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 660
2021-12-05 15:58:32,073 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 664
2021-12-05 15:58:32,073 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 672
2021-12-05 15:58:32,073 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 705
2021-12-05 15:58:32,073 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 683
2021-12-05 15:58:32,073 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 701
2021-12-05 15:58:32,073 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 715
2021-12-05 15:58:32,073 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 684
2021-12-05 15:58:32,073 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 713
2021-12-05 15:58:32,073 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 680
2021-12-05 15:58:32,073 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 681
2021-12-05 15:58:32,073 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 651
2021-12-05 15:58:32,073 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 702
2021-12-05 15:58:32,073 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 703
2021-12-05 15:58:32,073 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 709
2021-12-05 15:58:32,073 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 662
2021-12-05 15:58:32,073 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 670
2021-12-05 15:58:32,073 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 657
2021-12-05 15:58:32,074 [dispatcher-event-loop-0] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_27_piece0 on qb:57815 in memory (size: 2.3 KB, free: 1990.7 MB)
2021-12-05 15:58:32,074 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 692
2021-12-05 15:58:32,074 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 691
2021-12-05 15:58:32,075 [dispatcher-event-loop-4] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_29_piece0 on qb:57815 in memory (size: 2.1 KB, free: 1990.7 MB)
2021-12-05 15:58:32,075 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 720
2021-12-05 15:58:32,075 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 677
2021-12-05 15:58:32,075 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 682
2021-12-05 15:58:32,075 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 714
2021-12-05 15:58:32,075 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 716
2021-12-05 15:58:32,075 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 676
2021-12-05 15:58:32,075 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 685
2021-12-05 15:58:32,075 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 661
2021-12-05 15:58:32,075 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 694
2021-12-05 15:58:32,075 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 717
2021-12-05 15:58:32,075 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 722
2021-12-05 15:58:32,075 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 696
2021-12-05 15:58:32,075 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 712
2021-12-05 15:58:32,075 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 673
2021-12-05 15:58:32,075 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 663
2021-12-05 15:58:32,075 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 678
2021-12-05 15:58:32,075 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 667
2021-12-05 15:58:32,075 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 656
2021-12-05 15:58:32,075 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 652
2021-12-05 15:58:32,075 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 719
2021-12-05 15:58:32,075 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 706
2021-12-05 15:58:32,075 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 666
2021-12-05 15:58:32,075 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 653
2021-12-05 15:58:32,075 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 675
2021-12-05 15:58:32,075 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 718
2021-12-05 15:58:32,075 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 690
2021-12-05 15:58:32,075 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 671
2021-12-05 15:58:32,075 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 707
2021-12-05 15:58:32,075 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 655
2021-12-05 15:58:32,075 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 699
2021-12-05 15:58:32,075 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 674
2021-12-05 15:58:32,075 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 723
2021-12-05 15:58:32,075 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 700
2021-12-05 15:58:32,075 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 710
2021-12-05 15:58:32,075 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 688
2021-12-05 15:58:32,075 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 711
2021-12-05 15:58:32,075 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 695
2021-12-05 15:58:32,075 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 704
2021-12-05 15:58:32,075 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 698
2021-12-05 15:58:32,075 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 721
2021-12-05 15:58:32,075 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 669
2021-12-05 15:58:32,075 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 689
2021-12-05 15:58:32,075 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 658
2021-12-05 15:58:32,075 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 693
2021-12-05 15:58:32,075 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 697
2021-12-05 15:58:32,075 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 686
2021-12-05 15:58:32,075 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 708
2021-12-05 15:58:32,075 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 654
2021-12-05 15:58:32,075 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 659
2021-12-05 15:58:32,075 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 724
2021-12-05 15:58:32,075 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 668
2021-12-05 15:58:32,076 [dispatcher-event-loop-8] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_28_piece0 on qb:57815 in memory (size: 2.3 KB, free: 1990.7 MB)
2021-12-05 15:58:32,076 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 650
2021-12-05 15:58:32,076 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 687
2021-12-05 15:58:32,628 [Executor task launch worker for task 69] INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 43.0 (TID 69). 1034 bytes result sent to driver
2021-12-05 15:58:32,628 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 43.0 (TID 69) in 1577 ms on localhost (executor driver) (2/4)
2021-12-05 15:58:34,311 [Executor task launch worker for task 71] INFO [org.apache.spark.executor.Executor] - Finished task 3.0 in stage 43.0 (TID 71). 1034 bytes result sent to driver
2021-12-05 15:58:34,311 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 3.0 in stage 43.0 (TID 71) in 3260 ms on localhost (executor driver) (3/4)
2021-12-05 15:58:35,284 [Executor task launch worker for task 68] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 43.0 (TID 68). 1034 bytes result sent to driver
2021-12-05 15:58:35,284 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 43.0 (TID 68) in 4233 ms on localhost (executor driver) (4/4)
2021-12-05 15:58:35,284 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 43.0, whose tasks have all completed, from pool 
2021-12-05 15:58:35,284 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ShuffleMapStage 43 (distinct at PaidPromotionAdjustParameter.scala:164) finished in 4.237 s
2021-12-05 15:58:35,284 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - looking for newly runnable stages
2021-12-05 15:58:35,285 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - running: Set()
2021-12-05 15:58:35,285 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - waiting: Set(ResultStage 44)
2021-12-05 15:58:35,285 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - failed: Set()
2021-12-05 15:58:35,285 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 44 (MapPartitionsRDD[53] at distinct at PaidPromotionAdjustParameter.scala:164), which has no missing parents
2021-12-05 15:58:35,285 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_31 stored as values in memory (estimated size 3.7 KB, free 1990.2 MB)
2021-12-05 15:58:35,287 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_31_piece0 stored as bytes in memory (estimated size 2.2 KB, free 1990.2 MB)
2021-12-05 15:58:35,287 [dispatcher-event-loop-9] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_31_piece0 in memory on qb:57815 (size: 2.2 KB, free: 1990.7 MB)
2021-12-05 15:58:35,287 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 31 from broadcast at DAGScheduler.scala:1039
2021-12-05 15:58:35,287 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 4 missing tasks from ResultStage 44 (MapPartitionsRDD[53] at distinct at PaidPromotionAdjustParameter.scala:164) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
2021-12-05 15:58:35,287 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 44.0 with 4 tasks
2021-12-05 15:58:35,288 [dispatcher-event-loop-6] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 44.0 (TID 72, localhost, executor driver, partition 0, ANY, 7649 bytes)
2021-12-05 15:58:35,288 [dispatcher-event-loop-6] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 44.0 (TID 73, localhost, executor driver, partition 1, ANY, 7649 bytes)
2021-12-05 15:58:35,288 [dispatcher-event-loop-6] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 2.0 in stage 44.0 (TID 74, localhost, executor driver, partition 2, ANY, 7649 bytes)
2021-12-05 15:58:35,288 [dispatcher-event-loop-6] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 3.0 in stage 44.0 (TID 75, localhost, executor driver, partition 3, ANY, 7649 bytes)
2021-12-05 15:58:35,288 [Executor task launch worker for task 73] INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 44.0 (TID 73)
2021-12-05 15:58:35,288 [Executor task launch worker for task 72] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 44.0 (TID 72)
2021-12-05 15:58:35,288 [Executor task launch worker for task 75] INFO [org.apache.spark.executor.Executor] - Running task 3.0 in stage 44.0 (TID 75)
2021-12-05 15:58:35,288 [Executor task launch worker for task 74] INFO [org.apache.spark.executor.Executor] - Running task 2.0 in stage 44.0 (TID 74)
2021-12-05 15:58:35,289 [Executor task launch worker for task 73] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 4 non-empty blocks out of 4 blocks
2021-12-05 15:58:35,289 [Executor task launch worker for task 75] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 4 non-empty blocks out of 4 blocks
2021-12-05 15:58:35,289 [Executor task launch worker for task 72] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 4 non-empty blocks out of 4 blocks
2021-12-05 15:58:35,289 [Executor task launch worker for task 72] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-05 15:58:35,289 [Executor task launch worker for task 73] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-05 15:58:35,289 [Executor task launch worker for task 74] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 4 non-empty blocks out of 4 blocks
2021-12-05 15:58:35,289 [Executor task launch worker for task 74] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-05 15:58:35,289 [Executor task launch worker for task 75] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-05 15:58:35,308 [Executor task launch worker for task 74] INFO [org.apache.spark.executor.Executor] - Finished task 2.0 in stage 44.0 (TID 74). 1010 bytes result sent to driver
2021-12-05 15:58:35,308 [Executor task launch worker for task 75] INFO [org.apache.spark.executor.Executor] - Finished task 3.0 in stage 44.0 (TID 75). 1010 bytes result sent to driver
2021-12-05 15:58:35,308 [Executor task launch worker for task 72] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 44.0 (TID 72). 1010 bytes result sent to driver
2021-12-05 15:58:35,308 [Executor task launch worker for task 73] INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 44.0 (TID 73). 1010 bytes result sent to driver
2021-12-05 15:58:35,308 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 2.0 in stage 44.0 (TID 74) in 20 ms on localhost (executor driver) (1/4)
2021-12-05 15:58:35,309 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 3.0 in stage 44.0 (TID 75) in 21 ms on localhost (executor driver) (2/4)
2021-12-05 15:58:35,309 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 44.0 (TID 72) in 21 ms on localhost (executor driver) (3/4)
2021-12-05 15:58:35,309 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 44.0 (TID 73) in 21 ms on localhost (executor driver) (4/4)
2021-12-05 15:58:35,309 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 44.0, whose tasks have all completed, from pool 
2021-12-05 15:58:35,309 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 44 (count at PaidPromotionAdjustParameter.scala:172) finished in 0.024 s
2021-12-05 15:58:35,309 [main] INFO [org.apache.spark.scheduler.DAGScheduler] - Job 17 finished: count at PaidPromotionAdjustParameter.scala:172, took 4.263507 s
2021-12-05 15:58:35,309 [main] INFO [PaidPromotion$] - 最终训练集节目数 = 132
2021-12-05 15:58:35,311 [main] INFO [org.apache.spark.SparkContext] - Starting job: count at PaidPromotionAdjustParameter.scala:173
2021-12-05 15:58:35,312 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 55 (distinct at PaidPromotionAdjustParameter.scala:165)
2021-12-05 15:58:35,312 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 18 (count at PaidPromotionAdjustParameter.scala:173) with 2 output partitions
2021-12-05 15:58:35,312 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 46 (count at PaidPromotionAdjustParameter.scala:173)
2021-12-05 15:58:35,312 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 45)
2021-12-05 15:58:35,312 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List(ShuffleMapStage 45)
2021-12-05 15:58:35,312 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ShuffleMapStage 45 (MapPartitionsRDD[55] at distinct at PaidPromotionAdjustParameter.scala:165), which has no missing parents
2021-12-05 15:58:35,314 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_32 stored as values in memory (estimated size 172.2 KB, free 1990.1 MB)
2021-12-05 15:58:35,315 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_32_piece0 stored as bytes in memory (estimated size 61.6 KB, free 1990.0 MB)
2021-12-05 15:58:35,315 [dispatcher-event-loop-10] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_32_piece0 in memory on qb:57815 (size: 61.6 KB, free: 1990.7 MB)
2021-12-05 15:58:35,316 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 32 from broadcast at DAGScheduler.scala:1039
2021-12-05 15:58:35,316 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from ShuffleMapStage 45 (MapPartitionsRDD[55] at distinct at PaidPromotionAdjustParameter.scala:165) (first 15 tasks are for partitions Vector(0, 1))
2021-12-05 15:58:35,316 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 45.0 with 2 tasks
2021-12-05 15:58:35,316 [dispatcher-event-loop-5] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 45.0 (TID 76, localhost, executor driver, partition 0, ANY, 7885 bytes)
2021-12-05 15:58:35,316 [dispatcher-event-loop-5] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 45.0 (TID 77, localhost, executor driver, partition 1, ANY, 7885 bytes)
2021-12-05 15:58:35,316 [Executor task launch worker for task 76] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 45.0 (TID 76)
2021-12-05 15:58:35,317 [Executor task launch worker for task 77] INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 45.0 (TID 77)
2021-12-05 15:58:35,319 [Executor task launch worker for task 76] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/order_data.bcp:0+3442194
2021-12-05 15:58:35,319 [Executor task launch worker for task 77] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/order_data.bcp:3442194+3442195
2021-12-05 15:58:36,510 [Executor task launch worker for task 77] INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 45.0 (TID 77). 989 bytes result sent to driver
2021-12-05 15:58:36,510 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 45.0 (TID 77) in 1194 ms on localhost (executor driver) (1/2)
2021-12-05 15:58:37,508 [Executor task launch worker for task 76] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 45.0 (TID 76). 989 bytes result sent to driver
2021-12-05 15:58:37,508 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 45.0 (TID 76) in 2192 ms on localhost (executor driver) (2/2)
2021-12-05 15:58:37,508 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 45.0, whose tasks have all completed, from pool 
2021-12-05 15:58:37,508 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ShuffleMapStage 45 (distinct at PaidPromotionAdjustParameter.scala:165) finished in 2.196 s
2021-12-05 15:58:37,508 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - looking for newly runnable stages
2021-12-05 15:58:37,508 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - running: Set()
2021-12-05 15:58:37,508 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - waiting: Set(ResultStage 46)
2021-12-05 15:58:37,508 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - failed: Set()
2021-12-05 15:58:37,508 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 46 (MapPartitionsRDD[57] at distinct at PaidPromotionAdjustParameter.scala:165), which has no missing parents
2021-12-05 15:58:37,509 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_33 stored as values in memory (estimated size 3.7 KB, free 1990.0 MB)
2021-12-05 15:58:37,511 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_33_piece0 stored as bytes in memory (estimated size 2.2 KB, free 1990.0 MB)
2021-12-05 15:58:37,511 [dispatcher-event-loop-11] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_33_piece0 in memory on qb:57815 (size: 2.2 KB, free: 1990.6 MB)
2021-12-05 15:58:37,511 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 33 from broadcast at DAGScheduler.scala:1039
2021-12-05 15:58:37,511 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from ResultStage 46 (MapPartitionsRDD[57] at distinct at PaidPromotionAdjustParameter.scala:165) (first 15 tasks are for partitions Vector(0, 1))
2021-12-05 15:58:37,511 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 46.0 with 2 tasks
2021-12-05 15:58:37,512 [dispatcher-event-loop-4] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 46.0 (TID 78, localhost, executor driver, partition 0, ANY, 7649 bytes)
2021-12-05 15:58:37,512 [dispatcher-event-loop-4] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 46.0 (TID 79, localhost, executor driver, partition 1, ANY, 7649 bytes)
2021-12-05 15:58:37,512 [Executor task launch worker for task 78] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 46.0 (TID 78)
2021-12-05 15:58:37,512 [Executor task launch worker for task 79] INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 46.0 (TID 79)
2021-12-05 15:58:37,513 [Executor task launch worker for task 78] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 2 non-empty blocks out of 2 blocks
2021-12-05 15:58:37,513 [Executor task launch worker for task 78] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-05 15:58:37,513 [Executor task launch worker for task 79] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 2 non-empty blocks out of 2 blocks
2021-12-05 15:58:37,513 [Executor task launch worker for task 79] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-05 15:58:37,525 [Executor task launch worker for task 79] INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 46.0 (TID 79). 1053 bytes result sent to driver
2021-12-05 15:58:37,525 [Executor task launch worker for task 78] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 46.0 (TID 78). 1053 bytes result sent to driver
2021-12-05 15:58:37,525 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 46.0 (TID 79) in 13 ms on localhost (executor driver) (1/2)
2021-12-05 15:58:37,525 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 46.0 (TID 78) in 13 ms on localhost (executor driver) (2/2)
2021-12-05 15:58:37,525 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 46.0, whose tasks have all completed, from pool 
2021-12-05 15:58:37,526 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 46 (count at PaidPromotionAdjustParameter.scala:173) finished in 0.016 s
2021-12-05 15:58:37,526 [main] INFO [org.apache.spark.scheduler.DAGScheduler] - Job 18 finished: count at PaidPromotionAdjustParameter.scala:173, took 2.214373 s
2021-12-05 15:58:37,526 [main] INFO [PaidPromotion$] - 最终验证集节目数 = 80
2021-12-05 15:58:37,528 [main] INFO [org.apache.spark.SparkContext] - Starting job: count at PaidPromotionAdjustParameter.scala:174
2021-12-05 15:58:37,529 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 59 (intersection at PaidPromotionAdjustParameter.scala:166)
2021-12-05 15:58:37,529 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 58 (intersection at PaidPromotionAdjustParameter.scala:166)
2021-12-05 15:58:37,529 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 19 (count at PaidPromotionAdjustParameter.scala:174) with 4 output partitions
2021-12-05 15:58:37,529 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 51 (count at PaidPromotionAdjustParameter.scala:174)
2021-12-05 15:58:37,529 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 48, ShuffleMapStage 50)
2021-12-05 15:58:37,529 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List(ShuffleMapStage 48, ShuffleMapStage 50)
2021-12-05 15:58:37,529 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ShuffleMapStage 48 (MapPartitionsRDD[59] at intersection at PaidPromotionAdjustParameter.scala:166), which has no missing parents
2021-12-05 15:58:37,530 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_34 stored as values in memory (estimated size 4.0 KB, free 1990.0 MB)
2021-12-05 15:58:37,532 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_34_piece0 stored as bytes in memory (estimated size 2.3 KB, free 1990.0 MB)
2021-12-05 15:58:37,533 [dispatcher-event-loop-10] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_34_piece0 in memory on qb:57815 (size: 2.3 KB, free: 1990.6 MB)
2021-12-05 15:58:37,533 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 34 from broadcast at DAGScheduler.scala:1039
2021-12-05 15:58:37,533 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from ShuffleMapStage 48 (MapPartitionsRDD[59] at intersection at PaidPromotionAdjustParameter.scala:166) (first 15 tasks are for partitions Vector(0, 1))
2021-12-05 15:58:37,533 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 48.0 with 2 tasks
2021-12-05 15:58:37,533 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ShuffleMapStage 50 (MapPartitionsRDD[58] at intersection at PaidPromotionAdjustParameter.scala:166), which has no missing parents
2021-12-05 15:58:37,534 [dispatcher-event-loop-5] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 48.0 (TID 80, localhost, executor driver, partition 0, ANY, 7638 bytes)
2021-12-05 15:58:37,534 [dispatcher-event-loop-5] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 48.0 (TID 81, localhost, executor driver, partition 1, ANY, 7638 bytes)
2021-12-05 15:58:37,534 [Executor task launch worker for task 80] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 48.0 (TID 80)
2021-12-05 15:58:37,534 [Executor task launch worker for task 81] INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 48.0 (TID 81)
2021-12-05 15:58:37,534 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_35 stored as values in memory (estimated size 4.0 KB, free 1990.0 MB)
2021-12-05 15:58:37,535 [Executor task launch worker for task 80] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 2 non-empty blocks out of 2 blocks
2021-12-05 15:58:37,535 [Executor task launch worker for task 80] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-05 15:58:37,535 [Executor task launch worker for task 81] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 2 non-empty blocks out of 2 blocks
2021-12-05 15:58:37,535 [Executor task launch worker for task 81] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-05 15:58:37,536 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_35_piece0 stored as bytes in memory (estimated size 2.3 KB, free 1990.0 MB)
2021-12-05 15:58:37,536 [dispatcher-event-loop-0] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_35_piece0 in memory on qb:57815 (size: 2.3 KB, free: 1990.6 MB)
2021-12-05 15:58:37,536 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 35 from broadcast at DAGScheduler.scala:1039
2021-12-05 15:58:37,537 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 4 missing tasks from ShuffleMapStage 50 (MapPartitionsRDD[58] at intersection at PaidPromotionAdjustParameter.scala:166) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
2021-12-05 15:58:37,537 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 50.0 with 4 tasks
2021-12-05 15:58:37,537 [dispatcher-event-loop-7] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 50.0 (TID 82, localhost, executor driver, partition 0, ANY, 7638 bytes)
2021-12-05 15:58:37,537 [dispatcher-event-loop-7] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 50.0 (TID 83, localhost, executor driver, partition 1, ANY, 7638 bytes)
2021-12-05 15:58:37,537 [dispatcher-event-loop-7] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 2.0 in stage 50.0 (TID 84, localhost, executor driver, partition 2, ANY, 7638 bytes)
2021-12-05 15:58:37,537 [dispatcher-event-loop-7] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 3.0 in stage 50.0 (TID 85, localhost, executor driver, partition 3, ANY, 7638 bytes)
2021-12-05 15:58:37,537 [Executor task launch worker for task 82] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 50.0 (TID 82)
2021-12-05 15:58:37,537 [Executor task launch worker for task 85] INFO [org.apache.spark.executor.Executor] - Running task 3.0 in stage 50.0 (TID 85)
2021-12-05 15:58:37,537 [Executor task launch worker for task 84] INFO [org.apache.spark.executor.Executor] - Running task 2.0 in stage 50.0 (TID 84)
2021-12-05 15:58:37,537 [Executor task launch worker for task 83] INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 50.0 (TID 83)
2021-12-05 15:58:37,538 [Executor task launch worker for task 82] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 4 non-empty blocks out of 4 blocks
2021-12-05 15:58:37,538 [Executor task launch worker for task 82] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-05 15:58:37,538 [Executor task launch worker for task 84] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 4 non-empty blocks out of 4 blocks
2021-12-05 15:58:37,538 [Executor task launch worker for task 85] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 4 non-empty blocks out of 4 blocks
2021-12-05 15:58:37,538 [Executor task launch worker for task 83] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 4 non-empty blocks out of 4 blocks
2021-12-05 15:58:37,538 [Executor task launch worker for task 84] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-05 15:58:37,538 [Executor task launch worker for task 83] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-05 15:58:37,538 [Executor task launch worker for task 85] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-05 15:58:37,548 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 758
2021-12-05 15:58:37,548 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 735
2021-12-05 15:58:37,548 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 751
2021-12-05 15:58:37,548 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 795
2021-12-05 15:58:37,548 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 775
2021-12-05 15:58:37,548 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 730
2021-12-05 15:58:37,548 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 780
2021-12-05 15:58:37,548 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 824
2021-12-05 15:58:37,548 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 774
2021-12-05 15:58:37,548 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 731
2021-12-05 15:58:37,548 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 811
2021-12-05 15:58:37,548 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 779
2021-12-05 15:58:37,548 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 741
2021-12-05 15:58:37,548 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 728
2021-12-05 15:58:37,548 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 782
2021-12-05 15:58:37,548 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 778
2021-12-05 15:58:37,548 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 759
2021-12-05 15:58:37,548 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 797
2021-12-05 15:58:37,548 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 764
2021-12-05 15:58:37,548 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 804
2021-12-05 15:58:37,548 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 771
2021-12-05 15:58:37,548 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 799
2021-12-05 15:58:37,548 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 754
2021-12-05 15:58:37,548 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 815
2021-12-05 15:58:37,548 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 818
2021-12-05 15:58:37,548 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 776
2021-12-05 15:58:37,548 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 752
2021-12-05 15:58:37,548 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 750
2021-12-05 15:58:37,549 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 807
2021-12-05 15:58:37,549 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 755
2021-12-05 15:58:37,549 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 756
2021-12-05 15:58:37,549 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 821
2021-12-05 15:58:37,549 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 777
2021-12-05 15:58:37,549 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 739
2021-12-05 15:58:37,550 [dispatcher-event-loop-10] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_32_piece0 on qb:57815 in memory (size: 61.6 KB, free: 1990.7 MB)
2021-12-05 15:58:37,550 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 734
2021-12-05 15:58:37,550 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 788
2021-12-05 15:58:37,550 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 787
2021-12-05 15:58:37,550 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 767
2021-12-05 15:58:37,550 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 783
2021-12-05 15:58:37,550 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 727
2021-12-05 15:58:37,550 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 753
2021-12-05 15:58:37,550 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 808
2021-12-05 15:58:37,550 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 733
2021-12-05 15:58:37,550 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 800
2021-12-05 15:58:37,550 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 784
2021-12-05 15:58:37,550 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 742
2021-12-05 15:58:37,550 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 766
2021-12-05 15:58:37,550 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 820
2021-12-05 15:58:37,550 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 736
2021-12-05 15:58:37,550 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 798
2021-12-05 15:58:37,551 [dispatcher-event-loop-6] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_30_piece0 on qb:57815 in memory (size: 61.9 KB, free: 1990.8 MB)
2021-12-05 15:58:37,551 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 785
2021-12-05 15:58:37,552 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 790
2021-12-05 15:58:37,552 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 743
2021-12-05 15:58:37,552 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 791
2021-12-05 15:58:37,552 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 792
2021-12-05 15:58:37,552 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 793
2021-12-05 15:58:37,552 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 809
2021-12-05 15:58:37,552 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 810
2021-12-05 15:58:37,552 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 803
2021-12-05 15:58:37,552 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 781
2021-12-05 15:58:37,552 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 744
2021-12-05 15:58:37,552 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 763
2021-12-05 15:58:37,552 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 805
2021-12-05 15:58:37,552 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 747
2021-12-05 15:58:37,552 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 746
2021-12-05 15:58:37,552 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 748
2021-12-05 15:58:37,552 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 745
2021-12-05 15:58:37,552 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 789
2021-12-05 15:58:37,552 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 770
2021-12-05 15:58:37,552 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 772
2021-12-05 15:58:37,552 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 816
2021-12-05 15:58:37,552 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 738
2021-12-05 15:58:37,552 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 740
2021-12-05 15:58:37,552 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 769
2021-12-05 15:58:37,552 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 773
2021-12-05 15:58:37,552 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 806
2021-12-05 15:58:37,552 [dispatcher-event-loop-11] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_33_piece0 on qb:57815 in memory (size: 2.2 KB, free: 1990.8 MB)
2021-12-05 15:58:37,553 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 749
2021-12-05 15:58:37,553 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 757
2021-12-05 15:58:37,553 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 762
2021-12-05 15:58:37,553 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 786
2021-12-05 15:58:37,553 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 817
2021-12-05 15:58:37,553 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 794
2021-12-05 15:58:37,553 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 802
2021-12-05 15:58:37,553 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 768
2021-12-05 15:58:37,553 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 796
2021-12-05 15:58:37,553 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 761
2021-12-05 15:58:37,553 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 765
2021-12-05 15:58:37,553 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 760
2021-12-05 15:58:37,553 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 801
2021-12-05 15:58:37,553 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 726
2021-12-05 15:58:37,553 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 732
2021-12-05 15:58:37,553 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 813
2021-12-05 15:58:37,553 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 814
2021-12-05 15:58:37,553 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 819
2021-12-05 15:58:37,553 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 823
2021-12-05 15:58:37,553 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 812
2021-12-05 15:58:37,554 [dispatcher-event-loop-8] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_31_piece0 on qb:57815 in memory (size: 2.2 KB, free: 1990.8 MB)
2021-12-05 15:58:37,554 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 737
2021-12-05 15:58:37,554 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 725
2021-12-05 15:58:37,554 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 729
2021-12-05 15:58:37,554 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 822
2021-12-05 15:58:37,559 [Executor task launch worker for task 81] INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 48.0 (TID 81). 1206 bytes result sent to driver
2021-12-05 15:58:37,559 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 48.0 (TID 81) in 25 ms on localhost (executor driver) (1/2)
2021-12-05 15:58:37,560 [Executor task launch worker for task 80] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 48.0 (TID 80). 1206 bytes result sent to driver
2021-12-05 15:58:37,560 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 48.0 (TID 80) in 26 ms on localhost (executor driver) (2/2)
2021-12-05 15:58:37,560 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 48.0, whose tasks have all completed, from pool 
2021-12-05 15:58:37,561 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ShuffleMapStage 48 (intersection at PaidPromotionAdjustParameter.scala:166) finished in 0.031 s
2021-12-05 15:58:37,561 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - looking for newly runnable stages
2021-12-05 15:58:37,561 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - running: Set(ShuffleMapStage 50)
2021-12-05 15:58:37,561 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - waiting: Set(ResultStage 51)
2021-12-05 15:58:37,561 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - failed: Set()
2021-12-05 15:58:37,561 [Executor task launch worker for task 82] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 50.0 (TID 82). 1249 bytes result sent to driver
2021-12-05 15:58:37,561 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 50.0 (TID 82) in 24 ms on localhost (executor driver) (1/4)
2021-12-05 15:58:37,562 [Executor task launch worker for task 83] INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 50.0 (TID 83). 1249 bytes result sent to driver
2021-12-05 15:58:37,562 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 50.0 (TID 83) in 25 ms on localhost (executor driver) (2/4)
2021-12-05 15:58:37,563 [Executor task launch worker for task 85] INFO [org.apache.spark.executor.Executor] - Finished task 3.0 in stage 50.0 (TID 85). 1249 bytes result sent to driver
2021-12-05 15:58:37,564 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 3.0 in stage 50.0 (TID 85) in 27 ms on localhost (executor driver) (3/4)
2021-12-05 15:58:37,565 [Executor task launch worker for task 84] INFO [org.apache.spark.executor.Executor] - Finished task 2.0 in stage 50.0 (TID 84). 1249 bytes result sent to driver
2021-12-05 15:58:37,565 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 2.0 in stage 50.0 (TID 84) in 28 ms on localhost (executor driver) (4/4)
2021-12-05 15:58:37,565 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 50.0, whose tasks have all completed, from pool 
2021-12-05 15:58:37,565 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ShuffleMapStage 50 (intersection at PaidPromotionAdjustParameter.scala:166) finished in 0.031 s
2021-12-05 15:58:37,565 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - looking for newly runnable stages
2021-12-05 15:58:37,565 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - running: Set()
2021-12-05 15:58:37,565 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - waiting: Set(ResultStage 51)
2021-12-05 15:58:37,565 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - failed: Set()
2021-12-05 15:58:37,565 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 51 (MapPartitionsRDD[63] at intersection at PaidPromotionAdjustParameter.scala:166), which has no missing parents
2021-12-05 15:58:37,566 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_36 stored as values in memory (estimated size 3.6 KB, free 1990.5 MB)
2021-12-05 15:58:37,568 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_36_piece0 stored as bytes in memory (estimated size 2.1 KB, free 1990.5 MB)
2021-12-05 15:58:37,568 [dispatcher-event-loop-7] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_36_piece0 in memory on qb:57815 (size: 2.1 KB, free: 1990.8 MB)
2021-12-05 15:58:37,569 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 36 from broadcast at DAGScheduler.scala:1039
2021-12-05 15:58:37,569 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 4 missing tasks from ResultStage 51 (MapPartitionsRDD[63] at intersection at PaidPromotionAdjustParameter.scala:166) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
2021-12-05 15:58:37,569 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 51.0 with 4 tasks
2021-12-05 15:58:37,569 [dispatcher-event-loop-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 51.0 (TID 86, localhost, executor driver, partition 0, PROCESS_LOCAL, 7712 bytes)
2021-12-05 15:58:37,569 [dispatcher-event-loop-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 51.0 (TID 87, localhost, executor driver, partition 1, PROCESS_LOCAL, 7712 bytes)
2021-12-05 15:58:37,569 [dispatcher-event-loop-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 2.0 in stage 51.0 (TID 88, localhost, executor driver, partition 2, PROCESS_LOCAL, 7712 bytes)
2021-12-05 15:58:37,569 [dispatcher-event-loop-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 3.0 in stage 51.0 (TID 89, localhost, executor driver, partition 3, PROCESS_LOCAL, 7712 bytes)
2021-12-05 15:58:37,570 [Executor task launch worker for task 87] INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 51.0 (TID 87)
2021-12-05 15:58:37,570 [Executor task launch worker for task 89] INFO [org.apache.spark.executor.Executor] - Running task 3.0 in stage 51.0 (TID 89)
2021-12-05 15:58:37,570 [Executor task launch worker for task 86] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 51.0 (TID 86)
2021-12-05 15:58:37,570 [Executor task launch worker for task 88] INFO [org.apache.spark.executor.Executor] - Running task 2.0 in stage 51.0 (TID 88)
2021-12-05 15:58:37,570 [Executor task launch worker for task 87] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 4 blocks
2021-12-05 15:58:37,570 [Executor task launch worker for task 89] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 4 blocks
2021-12-05 15:58:37,571 [Executor task launch worker for task 87] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 1 ms
2021-12-05 15:58:37,571 [Executor task launch worker for task 89] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 1 ms
2021-12-05 15:58:37,571 [Executor task launch worker for task 88] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 4 blocks
2021-12-05 15:58:37,571 [Executor task launch worker for task 86] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 4 blocks
2021-12-05 15:58:37,571 [Executor task launch worker for task 88] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-05 15:58:37,571 [Executor task launch worker for task 86] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 1 ms
2021-12-05 15:58:37,573 [Executor task launch worker for task 88] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2021-12-05 15:58:37,573 [Executor task launch worker for task 87] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2021-12-05 15:58:37,573 [Executor task launch worker for task 88] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 1 ms
2021-12-05 15:58:37,573 [Executor task launch worker for task 86] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2021-12-05 15:58:37,573 [Executor task launch worker for task 89] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2021-12-05 15:58:37,573 [Executor task launch worker for task 86] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-05 15:58:37,573 [Executor task launch worker for task 87] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 1 ms
2021-12-05 15:58:37,573 [Executor task launch worker for task 89] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-05 15:58:37,581 [Executor task launch worker for task 88] INFO [org.apache.spark.executor.Executor] - Finished task 2.0 in stage 51.0 (TID 88). 1010 bytes result sent to driver
2021-12-05 15:58:37,581 [Executor task launch worker for task 86] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 51.0 (TID 86). 1010 bytes result sent to driver
2021-12-05 15:58:37,581 [Executor task launch worker for task 89] INFO [org.apache.spark.executor.Executor] - Finished task 3.0 in stage 51.0 (TID 89). 1010 bytes result sent to driver
2021-12-05 15:58:37,581 [Executor task launch worker for task 87] INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 51.0 (TID 87). 1010 bytes result sent to driver
2021-12-05 15:58:37,582 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 2.0 in stage 51.0 (TID 88) in 13 ms on localhost (executor driver) (1/4)
2021-12-05 15:58:37,582 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 51.0 (TID 86) in 13 ms on localhost (executor driver) (2/4)
2021-12-05 15:58:37,582 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 3.0 in stage 51.0 (TID 89) in 13 ms on localhost (executor driver) (3/4)
2021-12-05 15:58:37,582 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 51.0 (TID 87) in 13 ms on localhost (executor driver) (4/4)
2021-12-05 15:58:37,582 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 51.0, whose tasks have all completed, from pool 
2021-12-05 15:58:37,582 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 51 (count at PaidPromotionAdjustParameter.scala:174) finished in 0.016 s
2021-12-05 15:58:37,583 [main] INFO [org.apache.spark.scheduler.DAGScheduler] - Job 19 finished: count at PaidPromotionAdjustParameter.scala:174, took 0.053989 s
2021-12-05 15:58:37,583 [main] INFO [PaidPromotion$] - 最终共 同 节目数 = 80
2021-12-05 15:58:37,600 [main] INFO [org.apache.hadoop.conf.Configuration.deprecation] - mapred.output.dir is deprecated. Instead, use mapreduce.output.fileoutputformat.outputdir
2021-12-05 15:58:37,602 [main] INFO [org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter] - File Output Committer Algorithm version is 1
2021-12-05 15:58:37,699 [main] INFO [org.apache.spark.SparkContext] - Starting job: runJob at SparkHadoopWriter.scala:78
2021-12-05 15:58:37,700 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 20 (runJob at SparkHadoopWriter.scala:78) with 1 output partitions
2021-12-05 15:58:37,700 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 52 (runJob at SparkHadoopWriter.scala:78)
2021-12-05 15:58:37,700 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List()
2021-12-05 15:58:37,701 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2021-12-05 15:58:37,701 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 52 (MapPartitionsRDD[66] at saveAsTextFile at PaidPromotionAdjustParameter.scala:179), which has no missing parents
2021-12-05 15:58:37,710 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_37 stored as values in memory (estimated size 247.9 KB, free 1990.2 MB)
2021-12-05 15:58:37,712 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_37_piece0 stored as bytes in memory (estimated size 89.9 KB, free 1990.1 MB)
2021-12-05 15:58:37,712 [dispatcher-event-loop-5] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_37_piece0 in memory on qb:57815 (size: 89.9 KB, free: 1990.7 MB)
2021-12-05 15:58:37,713 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 37 from broadcast at DAGScheduler.scala:1039
2021-12-05 15:58:37,713 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 52 (MapPartitionsRDD[66] at saveAsTextFile at PaidPromotionAdjustParameter.scala:179) (first 15 tasks are for partitions Vector(0))
2021-12-05 15:58:37,713 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 52.0 with 1 tasks
2021-12-05 15:58:37,715 [dispatcher-event-loop-6] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 52.0 (TID 90, localhost, executor driver, partition 0, ANY, 8509 bytes)
2021-12-05 15:58:37,716 [Executor task launch worker for task 90] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 52.0 (TID 90)
2021-12-05 15:58:37,734 [Executor task launch worker for task 90] INFO [org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter] - File Output Committer Algorithm version is 1
2021-12-05 15:58:37,824 [Executor task launch worker for task 90] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/order_data.bcp:0+3442194
2021-12-05 15:58:39,265 [Executor task launch worker for task 90] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/order_data.bcp:3442194+3442195
2021-12-05 15:58:40,543 [Executor task launch worker for task 90] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/order_data.bcp:0+3442194
2021-12-05 15:58:40,799 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 856
2021-12-05 15:58:40,800 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 874
2021-12-05 15:58:40,800 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 844
2021-12-05 15:58:40,800 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 868
2021-12-05 15:58:40,800 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 842
2021-12-05 15:58:40,800 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 888
2021-12-05 15:58:40,800 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 887
2021-12-05 15:58:40,800 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 867
2021-12-05 15:58:40,800 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 869
2021-12-05 15:58:40,800 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 861
2021-12-05 15:58:40,800 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 870
2021-12-05 15:58:40,800 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 898
2021-12-05 15:58:40,800 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 830
2021-12-05 15:58:40,800 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 846
2021-12-05 15:58:40,800 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 877
2021-12-05 15:58:40,801 [dispatcher-event-loop-8] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_34_piece0 on qb:57815 in memory (size: 2.3 KB, free: 1990.7 MB)
2021-12-05 15:58:40,801 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 883
2021-12-05 15:58:40,801 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 893
2021-12-05 15:58:40,801 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 884
2021-12-05 15:58:40,801 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 827
2021-12-05 15:58:40,801 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 865
2021-12-05 15:58:40,801 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 890
2021-12-05 15:58:40,801 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 853
2021-12-05 15:58:40,801 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 891
2021-12-05 15:58:40,801 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 899
2021-12-05 15:58:40,801 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 871
2021-12-05 15:58:40,801 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 858
2021-12-05 15:58:40,801 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 832
2021-12-05 15:58:40,801 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 862
2021-12-05 15:58:40,801 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 843
2021-12-05 15:58:40,801 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 848
2021-12-05 15:58:40,801 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 834
2021-12-05 15:58:40,801 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 873
2021-12-05 15:58:40,801 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 835
2021-12-05 15:58:40,801 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 885
2021-12-05 15:58:40,801 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 852
2021-12-05 15:58:40,801 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 882
2021-12-05 15:58:40,801 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 837
2021-12-05 15:58:40,801 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 829
2021-12-05 15:58:40,801 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 886
2021-12-05 15:58:40,801 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 895
2021-12-05 15:58:40,802 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 839
2021-12-05 15:58:40,802 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 872
2021-12-05 15:58:40,802 [dispatcher-event-loop-9] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_36_piece0 on qb:57815 in memory (size: 2.1 KB, free: 1990.7 MB)
2021-12-05 15:58:40,802 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 889
2021-12-05 15:58:40,802 [dispatcher-event-loop-6] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_35_piece0 on qb:57815 in memory (size: 2.3 KB, free: 1990.7 MB)
2021-12-05 15:58:40,803 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 845
2021-12-05 15:58:40,803 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 879
2021-12-05 15:58:40,803 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 876
2021-12-05 15:58:40,803 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 863
2021-12-05 15:58:40,803 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 854
2021-12-05 15:58:40,803 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 840
2021-12-05 15:58:40,803 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 833
2021-12-05 15:58:40,803 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 850
2021-12-05 15:58:40,803 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 866
2021-12-05 15:58:40,803 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 860
2021-12-05 15:58:40,803 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 847
2021-12-05 15:58:40,803 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 897
2021-12-05 15:58:40,803 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 831
2021-12-05 15:58:40,803 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 855
2021-12-05 15:58:40,803 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 896
2021-12-05 15:58:40,803 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 841
2021-12-05 15:58:40,803 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 851
2021-12-05 15:58:40,803 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 825
2021-12-05 15:58:40,803 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 859
2021-12-05 15:58:40,803 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 864
2021-12-05 15:58:40,803 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 836
2021-12-05 15:58:40,803 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 881
2021-12-05 15:58:40,803 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 875
2021-12-05 15:58:40,803 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 878
2021-12-05 15:58:40,803 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 826
2021-12-05 15:58:40,803 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 894
2021-12-05 15:58:40,803 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 849
2021-12-05 15:58:40,803 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 892
2021-12-05 15:58:40,803 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 857
2021-12-05 15:58:40,803 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 880
2021-12-05 15:58:40,803 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 838
2021-12-05 15:58:40,803 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 828
2021-12-05 15:58:40,903 [Executor task launch worker for task 90] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/order_data.bcp:3442194+3442195
2021-12-05 15:58:41,503 [Executor task launch worker for task 90] INFO [org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter] - Saved output of task 'attempt_20211205155837_0066_m_000000_0' to hdfs://hdp1:8020/sk/chongqing/handle_data/set-train-device-production-data/_temporary/0/task_20211205155837_0066_m_000000
2021-12-05 15:58:41,504 [Executor task launch worker for task 90] INFO [org.apache.spark.mapred.SparkHadoopMapRedUtil] - attempt_20211205155837_0066_m_000000_0: Committed
2021-12-05 15:58:41,506 [Executor task launch worker for task 90] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 52.0 (TID 90). 998 bytes result sent to driver
2021-12-05 15:58:41,509 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 52.0 (TID 90) in 3796 ms on localhost (executor driver) (1/1)
2021-12-05 15:58:41,509 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 52.0, whose tasks have all completed, from pool 
2021-12-05 15:58:41,509 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 52 (runJob at SparkHadoopWriter.scala:78) finished in 3.808 s
2021-12-05 15:58:41,509 [main] INFO [org.apache.spark.scheduler.DAGScheduler] - Job 20 finished: runJob at SparkHadoopWriter.scala:78, took 3.809272 s
2021-12-05 15:58:41,578 [main] INFO [org.apache.spark.internal.io.SparkHadoopWriter] - Job job_20211205155837_0066 committed.
2021-12-05 15:58:41,583 [main] INFO [org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter] - File Output Committer Algorithm version is 1
2021-12-05 15:58:41,603 [main] INFO [org.apache.spark.SparkContext] - Starting job: runJob at SparkHadoopWriter.scala:78
2021-12-05 15:58:41,603 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 21 (runJob at SparkHadoopWriter.scala:78) with 1 output partitions
2021-12-05 15:58:41,603 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 53 (runJob at SparkHadoopWriter.scala:78)
2021-12-05 15:58:41,603 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List()
2021-12-05 15:58:41,603 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2021-12-05 15:58:41,603 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 53 (MapPartitionsRDD[69] at saveAsTextFile at PaidPromotionAdjustParameter.scala:182), which has no missing parents
2021-12-05 15:58:41,612 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_38 stored as values in memory (estimated size 247.3 KB, free 1989.9 MB)
2021-12-05 15:58:41,614 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_38_piece0 stored as bytes in memory (estimated size 89.4 KB, free 1989.8 MB)
2021-12-05 15:58:41,614 [dispatcher-event-loop-11] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_38_piece0 in memory on qb:57815 (size: 89.4 KB, free: 1990.6 MB)
2021-12-05 15:58:41,615 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 38 from broadcast at DAGScheduler.scala:1039
2021-12-05 15:58:41,615 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 53 (MapPartitionsRDD[69] at saveAsTextFile at PaidPromotionAdjustParameter.scala:182) (first 15 tasks are for partitions Vector(0))
2021-12-05 15:58:41,615 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 53.0 with 1 tasks
2021-12-05 15:58:41,615 [dispatcher-event-loop-4] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 53.0 (TID 91, localhost, executor driver, partition 0, ANY, 8337 bytes)
2021-12-05 15:58:41,615 [Executor task launch worker for task 91] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 53.0 (TID 91)
2021-12-05 15:58:41,621 [Executor task launch worker for task 91] INFO [org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter] - File Output Committer Algorithm version is 1
2021-12-05 15:58:41,953 [Executor task launch worker for task 91] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/order_data.bcp:0+3442194
2021-12-05 15:58:43,830 [Executor task launch worker for task 91] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/order_data.bcp:3442194+3442195
2021-12-05 15:58:46,902 [Executor task launch worker for task 91] INFO [org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter] - Saved output of task 'attempt_20211205155841_0069_m_000000_0' to hdfs://hdp1:8020/sk/chongqing/handle_data/set-validation-device-production-data/_temporary/0/task_20211205155841_0069_m_000000
2021-12-05 15:58:46,902 [Executor task launch worker for task 91] INFO [org.apache.spark.mapred.SparkHadoopMapRedUtil] - attempt_20211205155841_0069_m_000000_0: Committed
2021-12-05 15:58:46,903 [Executor task launch worker for task 91] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 53.0 (TID 91). 912 bytes result sent to driver
2021-12-05 15:58:46,905 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 53.0 (TID 91) in 5290 ms on localhost (executor driver) (1/1)
2021-12-05 15:58:46,905 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 53.0, whose tasks have all completed, from pool 
2021-12-05 15:58:46,905 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 53 (runJob at SparkHadoopWriter.scala:78) finished in 5.301 s
2021-12-05 15:58:46,905 [main] INFO [org.apache.spark.scheduler.DAGScheduler] - Job 21 finished: runJob at SparkHadoopWriter.scala:78, took 5.302324 s
2021-12-05 15:58:47,374 [main] INFO [org.apache.spark.internal.io.SparkHadoopWriter] - Job job_20211205155841_0069 committed.
2021-12-05 15:58:47,385 [main] INFO [PaidPromotion$] - 验证集用户实际观看列表-----------------------------------
2021-12-05 15:58:47,387 [main] INFO [org.apache.spark.SparkContext] - Starting job: count at PaidPromotionAdjustParameter.scala:192
2021-12-05 15:58:47,387 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 33 (filter at PaidPromotionAdjustParameter.scala:150)
2021-12-05 15:58:47,387 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 22 (count at PaidPromotionAdjustParameter.scala:192) with 2 output partitions
2021-12-05 15:58:47,387 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 55 (count at PaidPromotionAdjustParameter.scala:192)
2021-12-05 15:58:47,387 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 54)
2021-12-05 15:58:47,387 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List(ShuffleMapStage 54)
2021-12-05 15:58:47,387 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ShuffleMapStage 54 (MapPartitionsRDD[33] at filter at PaidPromotionAdjustParameter.scala:150), which has no missing parents
2021-12-05 15:58:47,389 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_39 stored as values in memory (estimated size 172.7 KB, free 1989.6 MB)
2021-12-05 15:58:47,390 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_39_piece0 stored as bytes in memory (estimated size 61.8 KB, free 1989.6 MB)
2021-12-05 15:58:47,391 [dispatcher-event-loop-3] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_39_piece0 in memory on qb:57815 (size: 61.8 KB, free: 1990.5 MB)
2021-12-05 15:58:47,391 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 39 from broadcast at DAGScheduler.scala:1039
2021-12-05 15:58:47,391 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from ShuffleMapStage 54 (MapPartitionsRDD[33] at filter at PaidPromotionAdjustParameter.scala:150) (first 15 tasks are for partitions Vector(0, 1))
2021-12-05 15:58:47,391 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 54.0 with 2 tasks
2021-12-05 15:58:47,392 [dispatcher-event-loop-9] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 54.0 (TID 92, localhost, executor driver, partition 0, ANY, 7885 bytes)
2021-12-05 15:58:47,392 [dispatcher-event-loop-9] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 54.0 (TID 93, localhost, executor driver, partition 1, ANY, 7885 bytes)
2021-12-05 15:58:47,392 [Executor task launch worker for task 93] INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 54.0 (TID 93)
2021-12-05 15:58:47,392 [Executor task launch worker for task 92] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 54.0 (TID 92)
2021-12-05 15:58:47,394 [Executor task launch worker for task 93] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/order_data.bcp:3442194+3442195
2021-12-05 15:58:47,394 [Executor task launch worker for task 92] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/order_data.bcp:0+3442194
2021-12-05 15:58:47,770 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 928
2021-12-05 15:58:47,771 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 924
2021-12-05 15:58:47,771 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 907
2021-12-05 15:58:47,771 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 915
2021-12-05 15:58:47,771 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 934
2021-12-05 15:58:47,771 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 935
2021-12-05 15:58:47,771 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 930
2021-12-05 15:58:47,771 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 943
2021-12-05 15:58:47,771 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 931
2021-12-05 15:58:47,771 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 942
2021-12-05 15:58:47,771 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 932
2021-12-05 15:58:47,771 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 908
2021-12-05 15:58:47,771 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 920
2021-12-05 15:58:47,771 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 909
2021-12-05 15:58:47,771 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 944
2021-12-05 15:58:47,771 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 926
2021-12-05 15:58:47,771 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 903
2021-12-05 15:58:47,771 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 922
2021-12-05 15:58:47,771 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 923
2021-12-05 15:58:47,771 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 946
2021-12-05 15:58:47,771 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 904
2021-12-05 15:58:47,771 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 911
2021-12-05 15:58:47,771 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 919
2021-12-05 15:58:47,771 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 936
2021-12-05 15:58:47,771 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 938
2021-12-05 15:58:47,771 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 916
2021-12-05 15:58:47,771 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 905
2021-12-05 15:58:47,771 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 913
2021-12-05 15:58:47,771 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 937
2021-12-05 15:58:47,772 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 940
2021-12-05 15:58:47,772 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 939
2021-12-05 15:58:47,772 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 906
2021-12-05 15:58:47,772 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 929
2021-12-05 15:58:47,772 [dispatcher-event-loop-0] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_38_piece0 on qb:57815 in memory (size: 89.4 KB, free: 1990.6 MB)
2021-12-05 15:58:47,772 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 927
2021-12-05 15:58:47,772 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 933
2021-12-05 15:58:47,772 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 941
2021-12-05 15:58:47,772 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 902
2021-12-05 15:58:47,772 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 917
2021-12-05 15:58:47,772 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 948
2021-12-05 15:58:47,772 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 949
2021-12-05 15:58:47,772 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 914
2021-12-05 15:58:47,772 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 900
2021-12-05 15:58:47,772 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 947
2021-12-05 15:58:47,772 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 912
2021-12-05 15:58:47,772 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 910
2021-12-05 15:58:47,772 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 918
2021-12-05 15:58:47,772 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 921
2021-12-05 15:58:47,773 [dispatcher-event-loop-2] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_37_piece0 on qb:57815 in memory (size: 89.9 KB, free: 1990.7 MB)
2021-12-05 15:58:47,773 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 925
2021-12-05 15:58:47,773 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 901
2021-12-05 15:58:47,773 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 945
2021-12-05 15:58:48,487 [Executor task launch worker for task 93] INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 54.0 (TID 93). 903 bytes result sent to driver
2021-12-05 15:58:48,487 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 54.0 (TID 93) in 1095 ms on localhost (executor driver) (1/2)
2021-12-05 15:58:49,196 [Executor task launch worker for task 92] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 54.0 (TID 92). 903 bytes result sent to driver
2021-12-05 15:58:49,197 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 54.0 (TID 92) in 1805 ms on localhost (executor driver) (2/2)
2021-12-05 15:58:49,197 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 54.0, whose tasks have all completed, from pool 
2021-12-05 15:58:49,197 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ShuffleMapStage 54 (filter at PaidPromotionAdjustParameter.scala:150) finished in 1.810 s
2021-12-05 15:58:49,197 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - looking for newly runnable stages
2021-12-05 15:58:49,197 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - running: Set()
2021-12-05 15:58:49,197 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - waiting: Set(ResultStage 55)
2021-12-05 15:58:49,197 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - failed: Set()
2021-12-05 15:58:49,197 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 55 (MapPartitionsRDD[71] at map at PaidPromotionAdjustParameter.scala:186), which has no missing parents
2021-12-05 15:58:49,200 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_40 stored as values in memory (estimated size 173.6 KB, free 1990.1 MB)
2021-12-05 15:58:49,202 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_40_piece0 stored as bytes in memory (estimated size 62.1 KB, free 1990.0 MB)
2021-12-05 15:58:49,202 [dispatcher-event-loop-3] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_40_piece0 in memory on qb:57815 (size: 62.1 KB, free: 1990.7 MB)
2021-12-05 15:58:49,203 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 40 from broadcast at DAGScheduler.scala:1039
2021-12-05 15:58:49,203 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from ResultStage 55 (MapPartitionsRDD[71] at map at PaidPromotionAdjustParameter.scala:186) (first 15 tasks are for partitions Vector(0, 1))
2021-12-05 15:58:49,203 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 55.0 with 2 tasks
2021-12-05 15:58:49,203 [dispatcher-event-loop-9] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 55.0 (TID 94, localhost, executor driver, partition 0, ANY, 7649 bytes)
2021-12-05 15:58:49,203 [dispatcher-event-loop-9] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 55.0 (TID 95, localhost, executor driver, partition 1, ANY, 7649 bytes)
2021-12-05 15:58:49,203 [Executor task launch worker for task 94] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 55.0 (TID 94)
2021-12-05 15:58:49,203 [Executor task launch worker for task 95] INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 55.0 (TID 95)
2021-12-05 15:58:49,205 [Executor task launch worker for task 95] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 2 non-empty blocks out of 2 blocks
2021-12-05 15:58:49,205 [Executor task launch worker for task 94] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 2 non-empty blocks out of 2 blocks
2021-12-05 15:58:49,205 [Executor task launch worker for task 95] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-05 15:58:49,205 [Executor task launch worker for task 94] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-05 15:58:49,244 [Executor task launch worker for task 95] INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 55.0 (TID 95). 1054 bytes result sent to driver
2021-12-05 15:58:49,244 [Executor task launch worker for task 94] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 55.0 (TID 94). 1054 bytes result sent to driver
2021-12-05 15:58:49,244 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 55.0 (TID 95) in 41 ms on localhost (executor driver) (1/2)
2021-12-05 15:58:49,244 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 55.0 (TID 94) in 41 ms on localhost (executor driver) (2/2)
2021-12-05 15:58:49,244 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 55.0, whose tasks have all completed, from pool 
2021-12-05 15:58:49,244 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 55 (count at PaidPromotionAdjustParameter.scala:192) finished in 0.046 s
2021-12-05 15:58:49,244 [main] INFO [org.apache.spark.scheduler.DAGScheduler] - Job 22 finished: count at PaidPromotionAdjustParameter.scala:192, took 1.857162 s
2021-12-05 15:58:49,245 [main] INFO [PaidPromotion$] - 验证集用户列表数量：4776
2021-12-05 15:58:49,255 [main] INFO [org.apache.spark.SparkContext] - Starting job: take at PaidPromotionAdjustParameter.scala:193
2021-12-05 15:58:49,256 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 23 (take at PaidPromotionAdjustParameter.scala:193) with 1 output partitions
2021-12-05 15:58:49,256 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 57 (take at PaidPromotionAdjustParameter.scala:193)
2021-12-05 15:58:49,256 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 56)
2021-12-05 15:58:49,256 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2021-12-05 15:58:49,256 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 57 (MapPartitionsRDD[71] at map at PaidPromotionAdjustParameter.scala:186), which has no missing parents
2021-12-05 15:58:49,257 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_41 stored as values in memory (estimated size 173.8 KB, free 1989.8 MB)
2021-12-05 15:58:49,259 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_41_piece0 stored as bytes in memory (estimated size 62.2 KB, free 1989.8 MB)
2021-12-05 15:58:49,259 [dispatcher-event-loop-0] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_41_piece0 in memory on qb:57815 (size: 62.2 KB, free: 1990.6 MB)
2021-12-05 15:58:49,259 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 41 from broadcast at DAGScheduler.scala:1039
2021-12-05 15:58:49,260 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 57 (MapPartitionsRDD[71] at map at PaidPromotionAdjustParameter.scala:186) (first 15 tasks are for partitions Vector(0))
2021-12-05 15:58:49,260 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 57.0 with 1 tasks
2021-12-05 15:58:49,260 [dispatcher-event-loop-4] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 57.0 (TID 96, localhost, executor driver, partition 0, ANY, 7649 bytes)
2021-12-05 15:58:49,260 [Executor task launch worker for task 96] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 57.0 (TID 96)
2021-12-05 15:58:49,262 [Executor task launch worker for task 96] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 2 non-empty blocks out of 2 blocks
2021-12-05 15:58:49,262 [Executor task launch worker for task 96] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-05 15:58:49,276 [Executor task launch worker for task 96] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 57.0 (TID 96). 2755 bytes result sent to driver
2021-12-05 15:58:49,276 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 57.0 (TID 96) in 16 ms on localhost (executor driver) (1/1)
2021-12-05 15:58:49,276 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 57.0, whose tasks have all completed, from pool 
2021-12-05 15:58:49,276 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 57 (take at PaidPromotionAdjustParameter.scala:193) finished in 0.020 s
2021-12-05 15:58:49,276 [main] INFO [org.apache.spark.scheduler.DAGScheduler] - Job 23 finished: take at PaidPromotionAdjustParameter.scala:193, took 0.020870 s
2021-12-05 15:58:49,285 [main] INFO [PaidPromotion$] - 训练集用户实际观看列表-----------------------------------
2021-12-05 15:58:49,286 [main] INFO [org.apache.spark.SparkContext] - Starting job: count at PaidPromotionAdjustParameter.scala:203
2021-12-05 15:58:49,287 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 35 (union at PaidPromotionAdjustParameter.scala:154)
2021-12-05 15:58:49,287 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 24 (count at PaidPromotionAdjustParameter.scala:203) with 4 output partitions
2021-12-05 15:58:49,287 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 59 (count at PaidPromotionAdjustParameter.scala:203)
2021-12-05 15:58:49,287 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 58)
2021-12-05 15:58:49,287 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List(ShuffleMapStage 58)
2021-12-05 15:58:49,287 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ShuffleMapStage 58 (UnionRDD[35] at union at PaidPromotionAdjustParameter.scala:154), which has no missing parents
2021-12-05 15:58:49,288 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_42 stored as values in memory (estimated size 173.3 KB, free 1989.6 MB)
2021-12-05 15:58:49,290 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_42_piece0 stored as bytes in memory (estimated size 62.0 KB, free 1989.5 MB)
2021-12-05 15:58:49,290 [dispatcher-event-loop-8] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_42_piece0 in memory on qb:57815 (size: 62.0 KB, free: 1990.5 MB)
2021-12-05 15:58:49,291 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 42 from broadcast at DAGScheduler.scala:1039
2021-12-05 15:58:49,291 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 4 missing tasks from ShuffleMapStage 58 (UnionRDD[35] at union at PaidPromotionAdjustParameter.scala:154) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
2021-12-05 15:58:49,291 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 58.0 with 4 tasks
2021-12-05 15:58:49,291 [dispatcher-event-loop-10] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 58.0 (TID 97, localhost, executor driver, partition 0, ANY, 7994 bytes)
2021-12-05 15:58:49,291 [dispatcher-event-loop-10] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 58.0 (TID 98, localhost, executor driver, partition 1, ANY, 7994 bytes)
2021-12-05 15:58:49,291 [dispatcher-event-loop-10] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 2.0 in stage 58.0 (TID 99, localhost, executor driver, partition 2, ANY, 7994 bytes)
2021-12-05 15:58:49,291 [dispatcher-event-loop-10] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 3.0 in stage 58.0 (TID 100, localhost, executor driver, partition 3, ANY, 7994 bytes)
2021-12-05 15:58:49,291 [Executor task launch worker for task 97] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 58.0 (TID 97)
2021-12-05 15:58:49,291 [Executor task launch worker for task 100] INFO [org.apache.spark.executor.Executor] - Running task 3.0 in stage 58.0 (TID 100)
2021-12-05 15:58:49,291 [Executor task launch worker for task 99] INFO [org.apache.spark.executor.Executor] - Running task 2.0 in stage 58.0 (TID 99)
2021-12-05 15:58:49,291 [Executor task launch worker for task 98] INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 58.0 (TID 98)
2021-12-05 15:58:49,293 [Executor task launch worker for task 97] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/order_data.bcp:0+3442194
2021-12-05 15:58:49,293 [Executor task launch worker for task 100] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/order_data.bcp:3442194+3442195
2021-12-05 15:58:49,293 [Executor task launch worker for task 98] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/order_data.bcp:3442194+3442195
2021-12-05 15:58:49,293 [Executor task launch worker for task 99] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/order_data.bcp:0+3442194
2021-12-05 15:58:50,028 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 969
2021-12-05 15:58:50,028 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 975
2021-12-05 15:58:50,028 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 959
2021-12-05 15:58:50,028 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 958
2021-12-05 15:58:50,028 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 972
2021-12-05 15:58:50,028 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 987
2021-12-05 15:58:50,028 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 993
2021-12-05 15:58:50,028 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1011
2021-12-05 15:58:50,029 [dispatcher-event-loop-0] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_39_piece0 on qb:57815 in memory (size: 61.8 KB, free: 1990.6 MB)
2021-12-05 15:58:50,029 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 962
2021-12-05 15:58:50,029 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1018
2021-12-05 15:58:50,029 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1023
2021-12-05 15:58:50,029 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 955
2021-12-05 15:58:50,029 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 983
2021-12-05 15:58:50,029 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 988
2021-12-05 15:58:50,029 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1008
2021-12-05 15:58:50,029 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1017
2021-12-05 15:58:50,029 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1020
2021-12-05 15:58:50,029 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 986
2021-12-05 15:58:50,029 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 989
2021-12-05 15:58:50,029 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 973
2021-12-05 15:58:50,029 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 960
2021-12-05 15:58:50,029 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1001
2021-12-05 15:58:50,029 [dispatcher-event-loop-2] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_41_piece0 on qb:57815 in memory (size: 62.2 KB, free: 1990.7 MB)
2021-12-05 15:58:50,030 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 979
2021-12-05 15:58:50,030 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 963
2021-12-05 15:58:50,030 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1009
2021-12-05 15:58:50,030 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1019
2021-12-05 15:58:50,030 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 996
2021-12-05 15:58:50,030 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 998
2021-12-05 15:58:50,030 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1002
2021-12-05 15:58:50,030 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1010
2021-12-05 15:58:50,030 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 953
2021-12-05 15:58:50,030 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 984
2021-12-05 15:58:50,030 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 977
2021-12-05 15:58:50,030 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 968
2021-12-05 15:58:50,030 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 966
2021-12-05 15:58:50,030 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1005
2021-12-05 15:58:50,030 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1015
2021-12-05 15:58:50,030 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1003
2021-12-05 15:58:50,030 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 980
2021-12-05 15:58:50,030 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 956
2021-12-05 15:58:50,030 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 999
2021-12-05 15:58:50,030 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1024
2021-12-05 15:58:50,030 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 974
2021-12-05 15:58:50,030 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 994
2021-12-05 15:58:50,030 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 995
2021-12-05 15:58:50,030 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 965
2021-12-05 15:58:50,030 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 950
2021-12-05 15:58:50,030 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1016
2021-12-05 15:58:50,030 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1012
2021-12-05 15:58:50,030 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 957
2021-12-05 15:58:50,030 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 954
2021-12-05 15:58:50,030 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 981
2021-12-05 15:58:50,030 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 978
2021-12-05 15:58:50,030 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1000
2021-12-05 15:58:50,030 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 951
2021-12-05 15:58:50,030 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 970
2021-12-05 15:58:50,030 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 964
2021-12-05 15:58:50,030 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 982
2021-12-05 15:58:50,030 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1013
2021-12-05 15:58:50,030 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 992
2021-12-05 15:58:50,030 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 967
2021-12-05 15:58:50,030 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1021
2021-12-05 15:58:50,030 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 961
2021-12-05 15:58:50,030 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 985
2021-12-05 15:58:50,030 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1004
2021-12-05 15:58:50,030 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1022
2021-12-05 15:58:50,031 [dispatcher-event-loop-3] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_40_piece0 on qb:57815 in memory (size: 62.1 KB, free: 1990.7 MB)
2021-12-05 15:58:50,031 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 976
2021-12-05 15:58:50,031 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1007
2021-12-05 15:58:50,031 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 990
2021-12-05 15:58:50,031 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1014
2021-12-05 15:58:50,031 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 991
2021-12-05 15:58:50,031 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1006
2021-12-05 15:58:50,031 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 997
2021-12-05 15:58:50,031 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 971
2021-12-05 15:58:50,031 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 952
2021-12-05 15:58:50,481 [Executor task launch worker for task 97] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 58.0 (TID 97). 905 bytes result sent to driver
2021-12-05 15:58:50,482 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 58.0 (TID 97) in 1191 ms on localhost (executor driver) (1/4)
2021-12-05 15:58:50,627 [Executor task launch worker for task 99] INFO [org.apache.spark.executor.Executor] - Finished task 2.0 in stage 58.0 (TID 99). 905 bytes result sent to driver
2021-12-05 15:58:50,628 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 2.0 in stage 58.0 (TID 99) in 1337 ms on localhost (executor driver) (2/4)
2021-12-05 15:58:50,687 [Executor task launch worker for task 98] INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 58.0 (TID 98). 905 bytes result sent to driver
2021-12-05 15:58:50,687 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 58.0 (TID 98) in 1396 ms on localhost (executor driver) (3/4)
2021-12-05 15:58:50,799 [Executor task launch worker for task 100] INFO [org.apache.spark.executor.Executor] - Finished task 3.0 in stage 58.0 (TID 100). 905 bytes result sent to driver
2021-12-05 15:58:50,800 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 3.0 in stage 58.0 (TID 100) in 1509 ms on localhost (executor driver) (4/4)
2021-12-05 15:58:50,800 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 58.0, whose tasks have all completed, from pool 
2021-12-05 15:58:50,800 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ShuffleMapStage 58 (union at PaidPromotionAdjustParameter.scala:154) finished in 1.513 s
2021-12-05 15:58:50,800 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - looking for newly runnable stages
2021-12-05 15:58:50,800 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - running: Set()
2021-12-05 15:58:50,800 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - waiting: Set(ResultStage 59)
2021-12-05 15:58:50,800 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - failed: Set()
2021-12-05 15:58:50,800 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 59 (MapPartitionsRDD[73] at map at PaidPromotionAdjustParameter.scala:197), which has no missing parents
2021-12-05 15:58:50,801 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_43 stored as values in memory (estimated size 174.1 KB, free 1990.1 MB)
2021-12-05 15:58:50,803 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_43_piece0 stored as bytes in memory (estimated size 62.5 KB, free 1990.0 MB)
2021-12-05 15:58:50,803 [dispatcher-event-loop-11] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_43_piece0 in memory on qb:57815 (size: 62.5 KB, free: 1990.7 MB)
2021-12-05 15:58:50,803 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 43 from broadcast at DAGScheduler.scala:1039
2021-12-05 15:58:50,804 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 4 missing tasks from ResultStage 59 (MapPartitionsRDD[73] at map at PaidPromotionAdjustParameter.scala:197) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
2021-12-05 15:58:50,804 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 59.0 with 4 tasks
2021-12-05 15:58:50,804 [dispatcher-event-loop-4] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 59.0 (TID 101, localhost, executor driver, partition 0, ANY, 7649 bytes)
2021-12-05 15:58:50,804 [dispatcher-event-loop-4] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 59.0 (TID 102, localhost, executor driver, partition 1, ANY, 7649 bytes)
2021-12-05 15:58:50,804 [dispatcher-event-loop-4] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 2.0 in stage 59.0 (TID 103, localhost, executor driver, partition 2, ANY, 7649 bytes)
2021-12-05 15:58:50,804 [dispatcher-event-loop-4] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 3.0 in stage 59.0 (TID 104, localhost, executor driver, partition 3, ANY, 7649 bytes)
2021-12-05 15:58:50,804 [Executor task launch worker for task 101] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 59.0 (TID 101)
2021-12-05 15:58:50,804 [Executor task launch worker for task 102] INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 59.0 (TID 102)
2021-12-05 15:58:50,804 [Executor task launch worker for task 103] INFO [org.apache.spark.executor.Executor] - Running task 2.0 in stage 59.0 (TID 103)
2021-12-05 15:58:50,804 [Executor task launch worker for task 104] INFO [org.apache.spark.executor.Executor] - Running task 3.0 in stage 59.0 (TID 104)
2021-12-05 15:58:50,806 [Executor task launch worker for task 101] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 4 non-empty blocks out of 4 blocks
2021-12-05 15:58:50,806 [Executor task launch worker for task 103] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 4 non-empty blocks out of 4 blocks
2021-12-05 15:58:50,806 [Executor task launch worker for task 103] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-05 15:58:50,806 [Executor task launch worker for task 104] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 4 non-empty blocks out of 4 blocks
2021-12-05 15:58:50,806 [Executor task launch worker for task 102] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 4 non-empty blocks out of 4 blocks
2021-12-05 15:58:50,807 [Executor task launch worker for task 102] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 1 ms
2021-12-05 15:58:50,806 [Executor task launch worker for task 101] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-05 15:58:50,807 [Executor task launch worker for task 104] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 1 ms
2021-12-05 15:58:50,896 [dispatcher-event-loop-1] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_42_piece0 on qb:57815 in memory (size: 62.0 KB, free: 1990.7 MB)
2021-12-05 15:58:50,941 [Executor task launch worker for task 103] INFO [org.apache.spark.executor.Executor] - Finished task 2.0 in stage 59.0 (TID 103). 1098 bytes result sent to driver
2021-12-05 15:58:50,942 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 2.0 in stage 59.0 (TID 103) in 138 ms on localhost (executor driver) (1/4)
2021-12-05 15:58:50,943 [Executor task launch worker for task 101] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 59.0 (TID 101). 1098 bytes result sent to driver
2021-12-05 15:58:50,943 [Executor task launch worker for task 104] INFO [org.apache.spark.executor.Executor] - Finished task 3.0 in stage 59.0 (TID 104). 1098 bytes result sent to driver
2021-12-05 15:58:50,943 [Executor task launch worker for task 102] INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 59.0 (TID 102). 1098 bytes result sent to driver
2021-12-05 15:58:50,943 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 59.0 (TID 101) in 139 ms on localhost (executor driver) (2/4)
2021-12-05 15:58:50,943 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 3.0 in stage 59.0 (TID 104) in 139 ms on localhost (executor driver) (3/4)
2021-12-05 15:58:50,943 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 59.0 (TID 102) in 139 ms on localhost (executor driver) (4/4)
2021-12-05 15:58:50,944 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 59.0, whose tasks have all completed, from pool 
2021-12-05 15:58:50,944 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 59 (count at PaidPromotionAdjustParameter.scala:203) finished in 0.144 s
2021-12-05 15:58:50,944 [main] INFO [org.apache.spark.scheduler.DAGScheduler] - Job 24 finished: count at PaidPromotionAdjustParameter.scala:203, took 1.658386 s
2021-12-05 15:58:50,944 [main] INFO [PaidPromotion$] - 训练集用户列表数量：95323
2021-12-05 15:58:50,952 [main] INFO [org.apache.spark.SparkContext] - Starting job: take at PaidPromotionAdjustParameter.scala:204
2021-12-05 15:58:50,952 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 25 (take at PaidPromotionAdjustParameter.scala:204) with 1 output partitions
2021-12-05 15:58:50,952 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 61 (take at PaidPromotionAdjustParameter.scala:204)
2021-12-05 15:58:50,952 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 60)
2021-12-05 15:58:50,952 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2021-12-05 15:58:50,952 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 61 (MapPartitionsRDD[73] at map at PaidPromotionAdjustParameter.scala:197), which has no missing parents
2021-12-05 15:58:50,954 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_44 stored as values in memory (estimated size 174.3 KB, free 1990.1 MB)
2021-12-05 15:58:50,956 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_44_piece0 stored as bytes in memory (estimated size 62.6 KB, free 1990.0 MB)
2021-12-05 15:58:50,956 [dispatcher-event-loop-4] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_44_piece0 in memory on qb:57815 (size: 62.6 KB, free: 1990.7 MB)
2021-12-05 15:58:50,956 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 44 from broadcast at DAGScheduler.scala:1039
2021-12-05 15:58:50,957 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 61 (MapPartitionsRDD[73] at map at PaidPromotionAdjustParameter.scala:197) (first 15 tasks are for partitions Vector(0))
2021-12-05 15:58:50,957 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 61.0 with 1 tasks
2021-12-05 15:58:50,957 [dispatcher-event-loop-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 61.0 (TID 105, localhost, executor driver, partition 0, ANY, 7649 bytes)
2021-12-05 15:58:50,957 [Executor task launch worker for task 105] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 61.0 (TID 105)
2021-12-05 15:58:50,959 [Executor task launch worker for task 105] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 4 non-empty blocks out of 4 blocks
2021-12-05 15:58:50,959 [Executor task launch worker for task 105] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-05 15:58:50,995 [Executor task launch worker for task 105] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 61.0 (TID 105). 2431 bytes result sent to driver
2021-12-05 15:58:50,995 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 61.0 (TID 105) in 38 ms on localhost (executor driver) (1/1)
2021-12-05 15:58:50,995 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 61.0, whose tasks have all completed, from pool 
2021-12-05 15:58:50,996 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 61 (take at PaidPromotionAdjustParameter.scala:204) finished in 0.044 s
2021-12-05 15:58:50,996 [main] INFO [org.apache.spark.scheduler.DAGScheduler] - Job 25 finished: take at PaidPromotionAdjustParameter.scala:204, took 0.043986 s
2021-12-05 15:58:50,999 [main] INFO [org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter] - File Output Committer Algorithm version is 1
2021-12-05 15:58:51,033 [main] INFO [org.apache.spark.SparkContext] - Starting job: runJob at SparkHadoopWriter.scala:78
2021-12-05 15:58:51,034 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 26 (runJob at SparkHadoopWriter.scala:78) with 1 output partitions
2021-12-05 15:58:51,034 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 63 (runJob at SparkHadoopWriter.scala:78)
2021-12-05 15:58:51,034 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 62)
2021-12-05 15:58:51,034 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2021-12-05 15:58:51,034 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 63 (MapPartitionsRDD[75] at saveAsTextFile at PaidPromotionAdjustParameter.scala:206), which has no missing parents
2021-12-05 15:58:51,042 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_45 stored as values in memory (estimated size 250.0 KB, free 1989.8 MB)
2021-12-05 15:58:51,044 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_45_piece0 stored as bytes in memory (estimated size 90.7 KB, free 1989.7 MB)
2021-12-05 15:58:51,044 [dispatcher-event-loop-3] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_45_piece0 in memory on qb:57815 (size: 90.7 KB, free: 1990.6 MB)
2021-12-05 15:58:51,045 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 45 from broadcast at DAGScheduler.scala:1039
2021-12-05 15:58:51,045 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 63 (MapPartitionsRDD[75] at saveAsTextFile at PaidPromotionAdjustParameter.scala:206) (first 15 tasks are for partitions Vector(0))
2021-12-05 15:58:51,045 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 63.0 with 1 tasks
2021-12-05 15:58:51,045 [dispatcher-event-loop-5] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 63.0 (TID 106, localhost, executor driver, partition 0, ANY, 7943 bytes)
2021-12-05 15:58:51,045 [Executor task launch worker for task 106] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 63.0 (TID 106)
2021-12-05 15:58:51,051 [Executor task launch worker for task 106] INFO [org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter] - File Output Committer Algorithm version is 1
2021-12-05 15:58:51,062 [Executor task launch worker for task 106] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 2 non-empty blocks out of 2 blocks
2021-12-05 15:58:51,062 [Executor task launch worker for task 106] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-05 15:58:51,078 [Executor task launch worker for task 106] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 2 non-empty blocks out of 2 blocks
2021-12-05 15:58:51,078 [Executor task launch worker for task 106] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-05 15:58:52,538 [Executor task launch worker for task 106] INFO [org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter] - Saved output of task 'attempt_20211205155850_0075_m_000000_0' to hdfs://hdp1:8020/sk/chongqing/list/validation/_temporary/0/task_20211205155850_0075_m_000000
2021-12-05 15:58:52,538 [Executor task launch worker for task 106] INFO [org.apache.spark.mapred.SparkHadoopMapRedUtil] - attempt_20211205155850_0075_m_000000_0: Committed
2021-12-05 15:58:52,539 [Executor task launch worker for task 106] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 63.0 (TID 106). 1256 bytes result sent to driver
2021-12-05 15:58:52,539 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 63.0 (TID 106) in 1494 ms on localhost (executor driver) (1/1)
2021-12-05 15:58:52,539 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 63.0, whose tasks have all completed, from pool 
2021-12-05 15:58:52,539 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 63 (runJob at SparkHadoopWriter.scala:78) finished in 1.505 s
2021-12-05 15:58:52,539 [main] INFO [org.apache.spark.scheduler.DAGScheduler] - Job 26 finished: runJob at SparkHadoopWriter.scala:78, took 1.505792 s
2021-12-05 15:58:52,666 [main] INFO [org.apache.spark.internal.io.SparkHadoopWriter] - Job job_20211205155850_0075 committed.
2021-12-05 15:58:52,668 [main] INFO [org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter] - File Output Committer Algorithm version is 1
2021-12-05 15:58:52,688 [main] INFO [org.apache.spark.SparkContext] - Starting job: runJob at SparkHadoopWriter.scala:78
2021-12-05 15:58:52,688 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 27 (runJob at SparkHadoopWriter.scala:78) with 1 output partitions
2021-12-05 15:58:52,688 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 65 (runJob at SparkHadoopWriter.scala:78)
2021-12-05 15:58:52,688 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 64)
2021-12-05 15:58:52,688 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2021-12-05 15:58:52,688 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 65 (MapPartitionsRDD[77] at saveAsTextFile at PaidPromotionAdjustParameter.scala:207), which has no missing parents
2021-12-05 15:58:52,696 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_46 stored as values in memory (estimated size 250.6 KB, free 1989.4 MB)
2021-12-05 15:58:52,698 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_46_piece0 stored as bytes in memory (estimated size 91.2 KB, free 1989.3 MB)
2021-12-05 15:58:52,698 [dispatcher-event-loop-0] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_46_piece0 in memory on qb:57815 (size: 91.2 KB, free: 1990.5 MB)
2021-12-05 15:58:52,698 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 46 from broadcast at DAGScheduler.scala:1039
2021-12-05 15:58:52,698 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 65 (MapPartitionsRDD[77] at saveAsTextFile at PaidPromotionAdjustParameter.scala:207) (first 15 tasks are for partitions Vector(0))
2021-12-05 15:58:52,698 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 65.0 with 1 tasks
2021-12-05 15:58:52,699 [dispatcher-event-loop-11] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 65.0 (TID 107, localhost, executor driver, partition 0, ANY, 7979 bytes)
2021-12-05 15:58:52,699 [Executor task launch worker for task 107] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 65.0 (TID 107)
2021-12-05 15:58:52,705 [Executor task launch worker for task 107] INFO [org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter] - File Output Committer Algorithm version is 1
2021-12-05 15:58:52,713 [Executor task launch worker for task 107] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 4 non-empty blocks out of 4 blocks
2021-12-05 15:58:52,713 [Executor task launch worker for task 107] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-05 15:58:52,758 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1044
2021-12-05 15:58:52,758 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1065
2021-12-05 15:58:52,758 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1104
2021-12-05 15:58:52,758 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1083
2021-12-05 15:58:52,758 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1085
2021-12-05 15:58:52,758 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1030
2021-12-05 15:58:52,758 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1058
2021-12-05 15:58:52,758 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1027
2021-12-05 15:58:52,758 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1033
2021-12-05 15:58:52,758 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1079
2021-12-05 15:58:52,758 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1090
2021-12-05 15:58:52,758 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1120
2021-12-05 15:58:52,758 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1077
2021-12-05 15:58:52,759 [dispatcher-event-loop-8] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_44_piece0 on qb:57815 in memory (size: 62.6 KB, free: 1990.5 MB)
2021-12-05 15:58:52,760 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1055
2021-12-05 15:58:52,760 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1049
2021-12-05 15:58:52,760 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1067
2021-12-05 15:58:52,760 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1105
2021-12-05 15:58:52,760 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1110
2021-12-05 15:58:52,760 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1041
2021-12-05 15:58:52,760 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1069
2021-12-05 15:58:52,760 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1040
2021-12-05 15:58:52,760 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1081
2021-12-05 15:58:52,760 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1063
2021-12-05 15:58:52,760 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1098
2021-12-05 15:58:52,760 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1099
2021-12-05 15:58:52,760 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1118
2021-12-05 15:58:52,760 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1091
2021-12-05 15:58:52,760 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1100
2021-12-05 15:58:52,760 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1056
2021-12-05 15:58:52,760 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1086
2021-12-05 15:58:52,760 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1028
2021-12-05 15:58:52,760 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1054
2021-12-05 15:58:52,760 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1089
2021-12-05 15:58:52,760 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1103
2021-12-05 15:58:52,760 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1107
2021-12-05 15:58:52,760 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1031
2021-12-05 15:58:52,760 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1037
2021-12-05 15:58:52,760 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1087
2021-12-05 15:58:52,760 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1115
2021-12-05 15:58:52,760 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1080
2021-12-05 15:58:52,760 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1116
2021-12-05 15:58:52,760 [dispatcher-event-loop-5] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_43_piece0 on qb:57815 in memory (size: 62.5 KB, free: 1990.6 MB)
2021-12-05 15:58:52,761 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1114
2021-12-05 15:58:52,761 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1064
2021-12-05 15:58:52,761 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1096
2021-12-05 15:58:52,761 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1046
2021-12-05 15:58:52,761 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1078
2021-12-05 15:58:52,761 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1123
2021-12-05 15:58:52,761 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1042
2021-12-05 15:58:52,761 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1106
2021-12-05 15:58:52,761 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1076
2021-12-05 15:58:52,761 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1108
2021-12-05 15:58:52,761 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1095
2021-12-05 15:58:52,761 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1113
2021-12-05 15:58:52,761 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1109
2021-12-05 15:58:52,761 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1029
2021-12-05 15:58:52,761 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1124
2021-12-05 15:58:52,761 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1062
2021-12-05 15:58:52,761 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1075
2021-12-05 15:58:52,761 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1038
2021-12-05 15:58:52,761 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1122
2021-12-05 15:58:52,761 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1026
2021-12-05 15:58:52,761 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1061
2021-12-05 15:58:52,761 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1035
2021-12-05 15:58:52,761 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1084
2021-12-05 15:58:52,761 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1053
2021-12-05 15:58:52,761 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1047
2021-12-05 15:58:52,761 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1052
2021-12-05 15:58:52,761 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1072
2021-12-05 15:58:52,762 [dispatcher-event-loop-7] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_45_piece0 on qb:57815 in memory (size: 90.7 KB, free: 1990.7 MB)
2021-12-05 15:58:52,762 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1092
2021-12-05 15:58:52,762 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1050
2021-12-05 15:58:52,762 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1025
2021-12-05 15:58:52,762 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1088
2021-12-05 15:58:52,762 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1121
2021-12-05 15:58:52,762 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1036
2021-12-05 15:58:52,762 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1057
2021-12-05 15:58:52,762 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1094
2021-12-05 15:58:52,762 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1060
2021-12-05 15:58:52,762 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1097
2021-12-05 15:58:52,762 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1071
2021-12-05 15:58:52,762 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1051
2021-12-05 15:58:52,762 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1048
2021-12-05 15:58:52,762 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1045
2021-12-05 15:58:52,762 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1073
2021-12-05 15:58:52,762 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1082
2021-12-05 15:58:52,762 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1039
2021-12-05 15:58:52,762 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1074
2021-12-05 15:58:52,762 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1059
2021-12-05 15:58:52,762 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1070
2021-12-05 15:58:52,762 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1102
2021-12-05 15:58:52,762 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1112
2021-12-05 15:58:52,762 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1111
2021-12-05 15:58:52,763 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1101
2021-12-05 15:58:52,763 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1034
2021-12-05 15:58:52,763 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1119
2021-12-05 15:58:52,763 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1032
2021-12-05 15:58:52,763 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1093
2021-12-05 15:58:52,763 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1066
2021-12-05 15:58:52,763 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1117
2021-12-05 15:58:52,763 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1043
2021-12-05 15:58:52,763 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1068
2021-12-05 15:58:52,776 [Executor task launch worker for task 107] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 4 non-empty blocks out of 4 blocks
2021-12-05 15:58:52,776 [Executor task launch worker for task 107] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-05 15:58:52,838 [Executor task launch worker for task 107] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 4 non-empty blocks out of 4 blocks
2021-12-05 15:58:52,838 [Executor task launch worker for task 107] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 1 ms
2021-12-05 15:58:52,895 [Executor task launch worker for task 107] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 4 non-empty blocks out of 4 blocks
2021-12-05 15:58:52,895 [Executor task launch worker for task 107] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-05 15:58:57,353 [Executor task launch worker for task 107] INFO [org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter] - Saved output of task 'attempt_20211205155852_0077_m_000000_0' to hdfs://hdp1:8020/sk/chongqing/list/train/_temporary/0/task_20211205155852_0077_m_000000
2021-12-05 15:58:57,353 [Executor task launch worker for task 107] INFO [org.apache.spark.mapred.SparkHadoopMapRedUtil] - attempt_20211205155852_0077_m_000000_0: Committed
2021-12-05 15:58:57,354 [Executor task launch worker for task 107] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 65.0 (TID 107). 1342 bytes result sent to driver
2021-12-05 15:58:57,355 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 65.0 (TID 107) in 4655 ms on localhost (executor driver) (1/1)
2021-12-05 15:58:57,355 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 65.0, whose tasks have all completed, from pool 
2021-12-05 15:58:57,355 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 65 (runJob at SparkHadoopWriter.scala:78) finished in 4.666 s
2021-12-05 15:58:57,356 [main] INFO [org.apache.spark.scheduler.DAGScheduler] - Job 27 finished: runJob at SparkHadoopWriter.scala:78, took 4.667875 s
2021-12-05 15:58:57,958 [main] INFO [org.apache.spark.internal.io.SparkHadoopWriter] - Job job_20211205155852_0077 committed.
2021-12-05 15:58:57,963 [main] INFO [org.spark_project.jetty.server.AbstractConnector] - Stopped Spark@5b800468{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2021-12-05 15:58:57,964 [main] INFO [org.apache.spark.ui.SparkUI] - Stopped Spark web UI at http://qb:4040
2021-12-05 15:58:57,971 [dispatcher-event-loop-4] INFO [org.apache.spark.MapOutputTrackerMasterEndpoint] - MapOutputTrackerMasterEndpoint stopped!
2021-12-05 15:58:58,059 [main] INFO [org.apache.spark.storage.memory.MemoryStore] - MemoryStore cleared
2021-12-05 15:58:58,060 [main] INFO [org.apache.spark.storage.BlockManager] - BlockManager stopped
2021-12-05 15:58:58,060 [main] INFO [org.apache.spark.storage.BlockManagerMaster] - BlockManagerMaster stopped
2021-12-05 15:58:58,062 [dispatcher-event-loop-1] INFO [org.apache.spark.scheduler.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint] - OutputCommitCoordinator stopped!
2021-12-05 15:58:58,065 [main] INFO [org.apache.spark.SparkContext] - Successfully stopped SparkContext
2021-12-05 15:58:58,067 [Thread-1] INFO [org.apache.spark.util.ShutdownHookManager] - Shutdown hook called
2021-12-05 15:58:58,068 [Thread-1] INFO [org.apache.spark.util.ShutdownHookManager] - Deleting directory C:\Users\ACER\AppData\Local\Temp\spark-79f13655-d72e-49a1-8961-11573d21f7e8
2021-12-05 16:00:39,546 [main] INFO [org.apache.spark.SparkContext] - Running Spark version 2.3.0
2021-12-05 16:00:39,834 [main] INFO [org.apache.spark.SparkContext] - Submitted application: PaidPromotion
2021-12-05 16:00:39,890 [main] INFO [org.apache.spark.SecurityManager] - Changing view acls to: ACER,root
2021-12-05 16:00:39,890 [main] INFO [org.apache.spark.SecurityManager] - Changing modify acls to: ACER,root
2021-12-05 16:00:39,890 [main] INFO [org.apache.spark.SecurityManager] - Changing view acls groups to: 
2021-12-05 16:00:39,891 [main] INFO [org.apache.spark.SecurityManager] - Changing modify acls groups to: 
2021-12-05 16:00:39,891 [main] INFO [org.apache.spark.SecurityManager] - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(ACER, root); groups with view permissions: Set(); users  with modify permissions: Set(ACER, root); groups with modify permissions: Set()
2021-12-05 16:00:40,512 [main] INFO [org.apache.spark.util.Utils] - Successfully started service 'sparkDriver' on port 53362.
2021-12-05 16:00:40,531 [main] INFO [org.apache.spark.SparkEnv] - Registering MapOutputTracker
2021-12-05 16:00:40,551 [main] INFO [org.apache.spark.SparkEnv] - Registering BlockManagerMaster
2021-12-05 16:00:40,554 [main] INFO [org.apache.spark.storage.BlockManagerMasterEndpoint] - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2021-12-05 16:00:40,554 [main] INFO [org.apache.spark.storage.BlockManagerMasterEndpoint] - BlockManagerMasterEndpoint up
2021-12-05 16:00:40,566 [main] INFO [org.apache.spark.storage.DiskBlockManager] - Created local directory at C:\Users\ACER\AppData\Local\Temp\blockmgr-02e928c1-d1e8-4971-906b-c3629124367a
2021-12-05 16:00:40,581 [main] INFO [org.apache.spark.storage.memory.MemoryStore] - MemoryStore started with capacity 1990.8 MB
2021-12-05 16:00:40,590 [main] INFO [org.apache.spark.SparkEnv] - Registering OutputCommitCoordinator
2021-12-05 16:00:40,648 [main] INFO [org.spark_project.jetty.util.log] - Logging initialized @2003ms
2021-12-05 16:00:40,701 [main] INFO [org.spark_project.jetty.server.Server] - jetty-9.3.z-SNAPSHOT
2021-12-05 16:00:40,713 [main] INFO [org.spark_project.jetty.server.Server] - Started @2069ms
2021-12-05 16:00:40,745 [main] INFO [org.spark_project.jetty.server.AbstractConnector] - Started ServerConnector@5b800468{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2021-12-05 16:00:40,745 [main] INFO [org.apache.spark.util.Utils] - Successfully started service 'SparkUI' on port 4040.
2021-12-05 16:00:40,769 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@1568159{/jobs,null,AVAILABLE,@Spark}
2021-12-05 16:00:40,770 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@63cd604c{/jobs/json,null,AVAILABLE,@Spark}
2021-12-05 16:00:40,771 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@3954d008{/jobs/job,null,AVAILABLE,@Spark}
2021-12-05 16:00:40,772 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@6d8792db{/jobs/job/json,null,AVAILABLE,@Spark}
2021-12-05 16:00:40,773 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@3a1d593e{/stages,null,AVAILABLE,@Spark}
2021-12-05 16:00:40,774 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@285d851a{/stages/json,null,AVAILABLE,@Spark}
2021-12-05 16:00:40,775 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@7876d598{/stages/stage,null,AVAILABLE,@Spark}
2021-12-05 16:00:40,778 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@4985cbcb{/stages/stage/json,null,AVAILABLE,@Spark}
2021-12-05 16:00:40,779 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@54361a9{/stages/pool,null,AVAILABLE,@Spark}
2021-12-05 16:00:40,780 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@293bb8a5{/stages/pool/json,null,AVAILABLE,@Spark}
2021-12-05 16:00:40,781 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@290b1b2e{/storage,null,AVAILABLE,@Spark}
2021-12-05 16:00:40,782 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@5db4c359{/storage/json,null,AVAILABLE,@Spark}
2021-12-05 16:00:40,784 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@6fefce9e{/storage/rdd,null,AVAILABLE,@Spark}
2021-12-05 16:00:40,785 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@8a589a2{/storage/rdd/json,null,AVAILABLE,@Spark}
2021-12-05 16:00:40,787 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@5cc69cfe{/environment,null,AVAILABLE,@Spark}
2021-12-05 16:00:40,788 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@11dee337{/environment/json,null,AVAILABLE,@Spark}
2021-12-05 16:00:40,790 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@74bdc168{/executors,null,AVAILABLE,@Spark}
2021-12-05 16:00:40,791 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@7bb3a9fe{/executors/json,null,AVAILABLE,@Spark}
2021-12-05 16:00:40,794 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@f19c9d2{/executors/threadDump,null,AVAILABLE,@Spark}
2021-12-05 16:00:40,796 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@a77614d{/executors/threadDump/json,null,AVAILABLE,@Spark}
2021-12-05 16:00:40,805 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@523424b5{/static,null,AVAILABLE,@Spark}
2021-12-05 16:00:40,807 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@12cd9150{/,null,AVAILABLE,@Spark}
2021-12-05 16:00:40,809 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@32fe9d0a{/api,null,AVAILABLE,@Spark}
2021-12-05 16:00:40,812 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@59fc684e{/jobs/job/kill,null,AVAILABLE,@Spark}
2021-12-05 16:00:40,815 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@355e34c7{/stages/stage/kill,null,AVAILABLE,@Spark}
2021-12-05 16:00:40,817 [main] INFO [org.apache.spark.ui.SparkUI] - Bound SparkUI to 0.0.0.0, and started at http://qb:4040
2021-12-05 16:00:40,907 [main] INFO [org.apache.spark.executor.Executor] - Starting executor ID driver on host localhost
2021-12-05 16:00:40,968 [main] INFO [org.apache.spark.util.Utils] - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 53406.
2021-12-05 16:00:40,969 [main] INFO [org.apache.spark.network.netty.NettyBlockTransferService] - Server created on qb:53406
2021-12-05 16:00:40,970 [main] INFO [org.apache.spark.storage.BlockManager] - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2021-12-05 16:00:40,971 [main] INFO [org.apache.spark.storage.BlockManagerMaster] - Registering BlockManager BlockManagerId(driver, qb, 53406, None)
2021-12-05 16:00:40,975 [dispatcher-event-loop-10] INFO [org.apache.spark.storage.BlockManagerMasterEndpoint] - Registering block manager qb:53406 with 1990.8 MB RAM, BlockManagerId(driver, qb, 53406, None)
2021-12-05 16:00:40,977 [main] INFO [org.apache.spark.storage.BlockManagerMaster] - Registered BlockManager BlockManagerId(driver, qb, 53406, None)
2021-12-05 16:00:40,978 [main] INFO [org.apache.spark.storage.BlockManager] - Initialized BlockManager: BlockManagerId(driver, qb, 53406, None)
2021-12-05 16:00:41,144 [main] INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@6fe46b62{/metrics/json,null,AVAILABLE,@Spark}
2021-12-05 16:00:41,696 [main] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_0 stored as values in memory (estimated size 312.7 KB, free 1990.5 MB)
2021-12-05 16:00:41,932 [main] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_0_piece0 stored as bytes in memory (estimated size 27.3 KB, free 1990.5 MB)
2021-12-05 16:00:41,933 [dispatcher-event-loop-0] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_0_piece0 in memory on qb:53406 (size: 27.3 KB, free: 1990.8 MB)
2021-12-05 16:00:41,936 [main] INFO [org.apache.spark.SparkContext] - Created broadcast 0 from textFile at PaidPromotionAdjustParameter.scala:98
2021-12-05 16:00:42,316 [main] WARN [org.apache.hadoop.hdfs.shortcircuit.DomainSocketFactory] - The short-circuit local reads feature cannot be used because UNIX Domain sockets are not available on Windows.
2021-12-05 16:00:42,564 [main] INFO [org.apache.hadoop.mapred.FileInputFormat] - Total input paths to process : 1
2021-12-05 16:00:42,713 [main] INFO [org.apache.spark.SparkContext] - Starting job: count at PaidPromotionAdjustParameter.scala:100
2021-12-05 16:00:42,725 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 0 (count at PaidPromotionAdjustParameter.scala:100) with 2 output partitions
2021-12-05 16:00:42,725 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 0 (count at PaidPromotionAdjustParameter.scala:100)
2021-12-05 16:00:42,725 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List()
2021-12-05 16:00:42,726 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2021-12-05 16:00:42,732 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 0 (/sk/chongqing/data/order_data.bcp MapPartitionsRDD[1] at textFile at PaidPromotionAdjustParameter.scala:98), which has no missing parents
2021-12-05 16:00:42,762 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_1 stored as values in memory (estimated size 3.1 KB, free 1990.5 MB)
2021-12-05 16:00:42,768 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_1_piece0 stored as bytes in memory (estimated size 1900.0 B, free 1990.5 MB)
2021-12-05 16:00:42,768 [dispatcher-event-loop-1] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_1_piece0 in memory on qb:53406 (size: 1900.0 B, free: 1990.8 MB)
2021-12-05 16:00:42,769 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 1 from broadcast at DAGScheduler.scala:1039
2021-12-05 16:00:42,779 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from ResultStage 0 (/sk/chongqing/data/order_data.bcp MapPartitionsRDD[1] at textFile at PaidPromotionAdjustParameter.scala:98) (first 15 tasks are for partitions Vector(0, 1))
2021-12-05 16:00:42,779 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 0.0 with 2 tasks
2021-12-05 16:00:42,817 [dispatcher-event-loop-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 0.0 (TID 0, localhost, executor driver, partition 0, ANY, 7896 bytes)
2021-12-05 16:00:42,818 [dispatcher-event-loop-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 0.0 (TID 1, localhost, executor driver, partition 1, ANY, 7896 bytes)
2021-12-05 16:00:42,823 [Executor task launch worker for task 0] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 0.0 (TID 0)
2021-12-05 16:00:42,823 [Executor task launch worker for task 1] INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 0.0 (TID 1)
2021-12-05 16:00:42,868 [Executor task launch worker for task 0] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/order_data.bcp:0+3442194
2021-12-05 16:00:42,868 [Executor task launch worker for task 1] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/order_data.bcp:3442194+3442195
2021-12-05 16:00:43,535 [Executor task launch worker for task 1] INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 0.0 (TID 1). 754 bytes result sent to driver
2021-12-05 16:00:43,544 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 0.0 (TID 1) in 725 ms on localhost (executor driver) (1/2)
2021-12-05 16:00:43,606 [Executor task launch worker for task 0] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 0.0 (TID 0). 754 bytes result sent to driver
2021-12-05 16:00:43,609 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 0.0 (TID 0) in 803 ms on localhost (executor driver) (2/2)
2021-12-05 16:00:43,610 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 0.0, whose tasks have all completed, from pool 
2021-12-05 16:00:43,611 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 0 (count at PaidPromotionAdjustParameter.scala:100) finished in 0.866 s
2021-12-05 16:00:43,615 [main] INFO [org.apache.spark.scheduler.DAGScheduler] - Job 0 finished: count at PaidPromotionAdjustParameter.scala:100, took 0.902199 s
2021-12-05 16:00:43,616 [main] INFO [PaidPromotion$] - 订购总数107294
2021-12-05 16:00:43,621 [main] INFO [org.apache.spark.SparkContext] - Starting job: count at PaidPromotionAdjustParameter.scala:108
2021-12-05 16:00:43,622 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 1 (count at PaidPromotionAdjustParameter.scala:108) with 2 output partitions
2021-12-05 16:00:43,622 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 1 (count at PaidPromotionAdjustParameter.scala:108)
2021-12-05 16:00:43,622 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List()
2021-12-05 16:00:43,622 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2021-12-05 16:00:43,622 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 1 (MapPartitionsRDD[2] at map at PaidPromotionAdjustParameter.scala:104), which has no missing parents
2021-12-05 16:00:43,623 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_2 stored as values in memory (estimated size 3.3 KB, free 1990.5 MB)
2021-12-05 16:00:43,628 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_2_piece0 stored as bytes in memory (estimated size 1985.0 B, free 1990.5 MB)
2021-12-05 16:00:43,628 [dispatcher-event-loop-7] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_2_piece0 in memory on qb:53406 (size: 1985.0 B, free: 1990.8 MB)
2021-12-05 16:00:43,629 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 2 from broadcast at DAGScheduler.scala:1039
2021-12-05 16:00:43,629 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from ResultStage 1 (MapPartitionsRDD[2] at map at PaidPromotionAdjustParameter.scala:104) (first 15 tasks are for partitions Vector(0, 1))
2021-12-05 16:00:43,629 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 1.0 with 2 tasks
2021-12-05 16:00:43,630 [dispatcher-event-loop-8] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 1.0 (TID 2, localhost, executor driver, partition 0, ANY, 7896 bytes)
2021-12-05 16:00:43,631 [dispatcher-event-loop-8] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 1.0 (TID 3, localhost, executor driver, partition 1, ANY, 7896 bytes)
2021-12-05 16:00:43,631 [Executor task launch worker for task 2] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 1.0 (TID 2)
2021-12-05 16:00:43,631 [Executor task launch worker for task 3] INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 1.0 (TID 3)
2021-12-05 16:00:43,634 [Executor task launch worker for task 3] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/order_data.bcp:3442194+3442195
2021-12-05 16:00:43,634 [Executor task launch worker for task 2] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/order_data.bcp:0+3442194
2021-12-05 16:00:43,735 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1
2021-12-05 16:00:43,735 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 13
2021-12-05 16:00:43,736 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 12
2021-12-05 16:00:43,736 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 23
2021-12-05 16:00:43,736 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 8
2021-12-05 16:00:43,736 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 15
2021-12-05 16:00:43,736 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 19
2021-12-05 16:00:43,736 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 21
2021-12-05 16:00:43,736 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 5
2021-12-05 16:00:43,736 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 17
2021-12-05 16:00:43,736 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 0
2021-12-05 16:00:43,736 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 10
2021-12-05 16:00:43,749 [dispatcher-event-loop-1] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_1_piece0 on qb:53406 in memory (size: 1900.0 B, free: 1990.8 MB)
2021-12-05 16:00:43,751 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 24
2021-12-05 16:00:43,751 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 11
2021-12-05 16:00:43,751 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 4
2021-12-05 16:00:43,751 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 3
2021-12-05 16:00:43,751 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 6
2021-12-05 16:00:43,752 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 16
2021-12-05 16:00:43,752 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 20
2021-12-05 16:00:43,752 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 7
2021-12-05 16:00:43,752 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 9
2021-12-05 16:00:43,752 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 22
2021-12-05 16:00:43,752 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 14
2021-12-05 16:00:43,752 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 18
2021-12-05 16:00:43,752 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 2
2021-12-05 16:00:44,115 [Executor task launch worker for task 2] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 1.0 (TID 2). 754 bytes result sent to driver
2021-12-05 16:00:44,122 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 1.0 (TID 2) in 491 ms on localhost (executor driver) (1/2)
2021-12-05 16:00:44,318 [Executor task launch worker for task 3] INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 1.0 (TID 3). 754 bytes result sent to driver
2021-12-05 16:00:44,321 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 1.0 (TID 3) in 691 ms on localhost (executor driver) (2/2)
2021-12-05 16:00:44,321 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 1.0, whose tasks have all completed, from pool 
2021-12-05 16:00:44,321 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 1 (count at PaidPromotionAdjustParameter.scala:108) finished in 0.698 s
2021-12-05 16:00:44,322 [main] INFO [org.apache.spark.scheduler.DAGScheduler] - Job 1 finished: count at PaidPromotionAdjustParameter.scala:108, took 0.700940 s
2021-12-05 16:00:44,322 [main] INFO [PaidPromotion$] - 订购总数：107294
2021-12-05 16:00:44,339 [main] INFO [org.apache.spark.SparkContext] - Starting job: count at PaidPromotionAdjustParameter.scala:121
2021-12-05 16:00:44,339 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 2 (count at PaidPromotionAdjustParameter.scala:121) with 2 output partitions
2021-12-05 16:00:44,339 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 2 (count at PaidPromotionAdjustParameter.scala:121)
2021-12-05 16:00:44,339 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List()
2021-12-05 16:00:44,340 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2021-12-05 16:00:44,340 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 2 (MapPartitionsRDD[3] at randomSplit at PaidPromotionAdjustParameter.scala:114), which has no missing parents
2021-12-05 16:00:44,341 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_3 stored as values in memory (estimated size 3.6 KB, free 1990.5 MB)
2021-12-05 16:00:44,346 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_3_piece0 stored as bytes in memory (estimated size 2.1 KB, free 1990.5 MB)
2021-12-05 16:00:44,347 [dispatcher-event-loop-3] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_3_piece0 in memory on qb:53406 (size: 2.1 KB, free: 1990.8 MB)
2021-12-05 16:00:44,347 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 3 from broadcast at DAGScheduler.scala:1039
2021-12-05 16:00:44,348 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from ResultStage 2 (MapPartitionsRDD[3] at randomSplit at PaidPromotionAdjustParameter.scala:114) (first 15 tasks are for partitions Vector(0, 1))
2021-12-05 16:00:44,348 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 2.0 with 2 tasks
2021-12-05 16:00:44,349 [dispatcher-event-loop-5] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 2.0 (TID 4, localhost, executor driver, partition 0, ANY, 7896 bytes)
2021-12-05 16:00:44,350 [dispatcher-event-loop-5] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 2.0 (TID 5, localhost, executor driver, partition 1, ANY, 7896 bytes)
2021-12-05 16:00:44,350 [Executor task launch worker for task 4] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 2.0 (TID 4)
2021-12-05 16:00:44,350 [Executor task launch worker for task 5] INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 2.0 (TID 5)
2021-12-05 16:00:44,355 [Executor task launch worker for task 5] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/order_data.bcp:3442194+3442195
2021-12-05 16:00:44,355 [Executor task launch worker for task 4] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/order_data.bcp:0+3442194
2021-12-05 16:00:44,789 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 42
2021-12-05 16:00:44,789 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 30
2021-12-05 16:00:44,789 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 37
2021-12-05 16:00:44,789 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 36
2021-12-05 16:00:44,789 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 32
2021-12-05 16:00:44,790 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 45
2021-12-05 16:00:44,790 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 48
2021-12-05 16:00:44,790 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 38
2021-12-05 16:00:44,790 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 33
2021-12-05 16:00:44,790 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 35
2021-12-05 16:00:44,790 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 39
2021-12-05 16:00:44,790 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 46
2021-12-05 16:00:44,791 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 26
2021-12-05 16:00:44,791 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 31
2021-12-05 16:00:44,791 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 27
2021-12-05 16:00:44,791 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 47
2021-12-05 16:00:44,791 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 43
2021-12-05 16:00:44,791 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 41
2021-12-05 16:00:44,791 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 34
2021-12-05 16:00:44,791 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 25
2021-12-05 16:00:44,791 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 28
2021-12-05 16:00:44,791 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 29
2021-12-05 16:00:44,791 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 44
2021-12-05 16:00:44,791 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 40
2021-12-05 16:00:44,792 [dispatcher-event-loop-10] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_2_piece0 on qb:53406 in memory (size: 1985.0 B, free: 1990.8 MB)
2021-12-05 16:00:44,793 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 49
2021-12-05 16:00:45,628 [Executor task launch worker for task 5] INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 2.0 (TID 5). 754 bytes result sent to driver
2021-12-05 16:00:45,628 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 2.0 (TID 5) in 1279 ms on localhost (executor driver) (1/2)
2021-12-05 16:00:46,456 [Executor task launch worker for task 4] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 2.0 (TID 4). 754 bytes result sent to driver
2021-12-05 16:00:46,457 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 2.0 (TID 4) in 2108 ms on localhost (executor driver) (2/2)
2021-12-05 16:00:46,457 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 2.0, whose tasks have all completed, from pool 
2021-12-05 16:00:46,457 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 2 (count at PaidPromotionAdjustParameter.scala:121) finished in 2.117 s
2021-12-05 16:00:46,458 [main] INFO [org.apache.spark.scheduler.DAGScheduler] - Job 2 finished: count at PaidPromotionAdjustParameter.scala:121, took 2.118767 s
2021-12-05 16:00:46,458 [main] INFO [PaidPromotion$] - 初次切分训练集数量：57374
2021-12-05 16:00:46,460 [main] INFO [org.apache.spark.SparkContext] - Starting job: count at PaidPromotionAdjustParameter.scala:122
2021-12-05 16:00:46,460 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 3 (count at PaidPromotionAdjustParameter.scala:122) with 2 output partitions
2021-12-05 16:00:46,460 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 3 (count at PaidPromotionAdjustParameter.scala:122)
2021-12-05 16:00:46,460 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List()
2021-12-05 16:00:46,460 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2021-12-05 16:00:46,461 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 3 (MapPartitionsRDD[4] at randomSplit at PaidPromotionAdjustParameter.scala:114), which has no missing parents
2021-12-05 16:00:46,462 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_4 stored as values in memory (estimated size 3.6 KB, free 1990.5 MB)
2021-12-05 16:00:46,466 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_4_piece0 stored as bytes in memory (estimated size 2.1 KB, free 1990.5 MB)
2021-12-05 16:00:46,466 [dispatcher-event-loop-1] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_4_piece0 in memory on qb:53406 (size: 2.1 KB, free: 1990.8 MB)
2021-12-05 16:00:46,467 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 4 from broadcast at DAGScheduler.scala:1039
2021-12-05 16:00:46,468 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from ResultStage 3 (MapPartitionsRDD[4] at randomSplit at PaidPromotionAdjustParameter.scala:114) (first 15 tasks are for partitions Vector(0, 1))
2021-12-05 16:00:46,468 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 3.0 with 2 tasks
2021-12-05 16:00:46,469 [dispatcher-event-loop-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 3.0 (TID 6, localhost, executor driver, partition 0, ANY, 7896 bytes)
2021-12-05 16:00:46,469 [dispatcher-event-loop-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 3.0 (TID 7, localhost, executor driver, partition 1, ANY, 7896 bytes)
2021-12-05 16:00:46,469 [Executor task launch worker for task 6] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 3.0 (TID 6)
2021-12-05 16:00:46,469 [Executor task launch worker for task 7] INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 3.0 (TID 7)
2021-12-05 16:00:46,471 [Executor task launch worker for task 6] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/order_data.bcp:0+3442194
2021-12-05 16:00:46,472 [Executor task launch worker for task 7] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/order_data.bcp:3442194+3442195
2021-12-05 16:00:46,782 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 53
2021-12-05 16:00:46,782 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 55
2021-12-05 16:00:46,783 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 50
2021-12-05 16:00:46,783 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 64
2021-12-05 16:00:46,783 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 62
2021-12-05 16:00:46,783 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 70
2021-12-05 16:00:46,783 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 65
2021-12-05 16:00:46,783 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 51
2021-12-05 16:00:46,783 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 63
2021-12-05 16:00:46,783 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 69
2021-12-05 16:00:46,783 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 54
2021-12-05 16:00:46,783 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 59
2021-12-05 16:00:46,783 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 61
2021-12-05 16:00:46,783 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 52
2021-12-05 16:00:46,783 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 73
2021-12-05 16:00:46,784 [dispatcher-event-loop-7] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_3_piece0 on qb:53406 in memory (size: 2.1 KB, free: 1990.8 MB)
2021-12-05 16:00:46,784 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 68
2021-12-05 16:00:46,784 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 71
2021-12-05 16:00:46,785 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 58
2021-12-05 16:00:46,785 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 57
2021-12-05 16:00:46,785 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 67
2021-12-05 16:00:46,785 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 66
2021-12-05 16:00:46,785 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 56
2021-12-05 16:00:46,785 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 72
2021-12-05 16:00:46,785 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 74
2021-12-05 16:00:46,785 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 60
2021-12-05 16:00:46,908 [Executor task launch worker for task 6] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 3.0 (TID 6). 754 bytes result sent to driver
2021-12-05 16:00:46,908 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 3.0 (TID 6) in 440 ms on localhost (executor driver) (1/2)
2021-12-05 16:00:47,904 [Executor task launch worker for task 7] INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 3.0 (TID 7). 754 bytes result sent to driver
2021-12-05 16:00:47,904 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 3.0 (TID 7) in 1435 ms on localhost (executor driver) (2/2)
2021-12-05 16:00:47,904 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 3.0, whose tasks have all completed, from pool 
2021-12-05 16:00:47,904 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 3 (count at PaidPromotionAdjustParameter.scala:122) finished in 1.443 s
2021-12-05 16:00:47,905 [main] INFO [org.apache.spark.scheduler.DAGScheduler] - Job 3 finished: count at PaidPromotionAdjustParameter.scala:122, took 1.444511 s
2021-12-05 16:00:47,905 [main] INFO [PaidPromotion$] - 初次切分验证集数量：49920
2021-12-05 16:00:47,965 [main] INFO [PaidPromotion$] - -----------------------------------
2021-12-05 16:00:47,967 [main] INFO [org.apache.spark.SparkContext] - Starting job: count at PaidPromotionAdjustParameter.scala:138
2021-12-05 16:00:47,974 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 6 (distinct at PaidPromotionAdjustParameter.scala:128)
2021-12-05 16:00:47,974 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 4 (count at PaidPromotionAdjustParameter.scala:138) with 2 output partitions
2021-12-05 16:00:47,975 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 5 (count at PaidPromotionAdjustParameter.scala:138)
2021-12-05 16:00:47,975 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 4)
2021-12-05 16:00:47,975 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List(ShuffleMapStage 4)
2021-12-05 16:00:47,976 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ShuffleMapStage 4 (MapPartitionsRDD[6] at distinct at PaidPromotionAdjustParameter.scala:128), which has no missing parents
2021-12-05 16:00:47,984 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_5 stored as values in memory (estimated size 5.2 KB, free 1990.5 MB)
2021-12-05 16:00:47,987 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_5_piece0 stored as bytes in memory (estimated size 2.9 KB, free 1990.5 MB)
2021-12-05 16:00:47,987 [dispatcher-event-loop-10] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_5_piece0 in memory on qb:53406 (size: 2.9 KB, free: 1990.8 MB)
2021-12-05 16:00:47,988 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 5 from broadcast at DAGScheduler.scala:1039
2021-12-05 16:00:47,989 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from ShuffleMapStage 4 (MapPartitionsRDD[6] at distinct at PaidPromotionAdjustParameter.scala:128) (first 15 tasks are for partitions Vector(0, 1))
2021-12-05 16:00:47,990 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 4.0 with 2 tasks
2021-12-05 16:00:47,991 [dispatcher-event-loop-11] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 4.0 (TID 8, localhost, executor driver, partition 0, ANY, 7885 bytes)
2021-12-05 16:00:47,991 [dispatcher-event-loop-11] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 4.0 (TID 9, localhost, executor driver, partition 1, ANY, 7885 bytes)
2021-12-05 16:00:47,991 [Executor task launch worker for task 8] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 4.0 (TID 8)
2021-12-05 16:00:47,991 [Executor task launch worker for task 9] INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 4.0 (TID 9)
2021-12-05 16:00:47,997 [Executor task launch worker for task 8] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/order_data.bcp:0+3442194
2021-12-05 16:00:47,997 [Executor task launch worker for task 9] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/order_data.bcp:3442194+3442195
2021-12-05 16:00:48,513 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 95
2021-12-05 16:00:48,514 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 83
2021-12-05 16:00:48,514 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 88
2021-12-05 16:00:48,514 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 87
2021-12-05 16:00:48,514 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 77
2021-12-05 16:00:48,514 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 76
2021-12-05 16:00:48,514 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 79
2021-12-05 16:00:48,514 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 81
2021-12-05 16:00:48,514 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 94
2021-12-05 16:00:48,514 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 92
2021-12-05 16:00:48,514 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 85
2021-12-05 16:00:48,514 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 82
2021-12-05 16:00:48,514 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 90
2021-12-05 16:00:48,515 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 78
2021-12-05 16:00:48,515 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 93
2021-12-05 16:00:48,517 [dispatcher-event-loop-4] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_4_piece0 on qb:53406 in memory (size: 2.1 KB, free: 1990.8 MB)
2021-12-05 16:00:48,518 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 89
2021-12-05 16:00:48,519 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 86
2021-12-05 16:00:48,519 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 91
2021-12-05 16:00:48,519 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 96
2021-12-05 16:00:48,519 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 80
2021-12-05 16:00:48,519 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 75
2021-12-05 16:00:48,519 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 84
2021-12-05 16:00:48,520 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 97
2021-12-05 16:00:48,521 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 99
2021-12-05 16:00:48,521 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 98
2021-12-05 16:00:48,651 [Executor task launch worker for task 8] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 4.0 (TID 8). 1032 bytes result sent to driver
2021-12-05 16:00:48,664 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 4.0 (TID 8) in 673 ms on localhost (executor driver) (1/2)
2021-12-05 16:00:49,516 [Executor task launch worker for task 9] INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 4.0 (TID 9). 1032 bytes result sent to driver
2021-12-05 16:00:49,518 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 4.0 (TID 9) in 1527 ms on localhost (executor driver) (2/2)
2021-12-05 16:00:49,518 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 4.0, whose tasks have all completed, from pool 
2021-12-05 16:00:49,519 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ShuffleMapStage 4 (distinct at PaidPromotionAdjustParameter.scala:128) finished in 1.541 s
2021-12-05 16:00:49,520 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - looking for newly runnable stages
2021-12-05 16:00:49,521 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - running: Set()
2021-12-05 16:00:49,522 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - waiting: Set(ResultStage 5)
2021-12-05 16:00:49,522 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - failed: Set()
2021-12-05 16:00:49,524 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 5 (MapPartitionsRDD[8] at distinct at PaidPromotionAdjustParameter.scala:128), which has no missing parents
2021-12-05 16:00:49,530 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_6 stored as values in memory (estimated size 3.7 KB, free 1990.5 MB)
2021-12-05 16:00:49,532 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_6_piece0 stored as bytes in memory (estimated size 2.2 KB, free 1990.5 MB)
2021-12-05 16:00:49,533 [dispatcher-event-loop-7] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_6_piece0 in memory on qb:53406 (size: 2.2 KB, free: 1990.8 MB)
2021-12-05 16:00:49,533 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 6 from broadcast at DAGScheduler.scala:1039
2021-12-05 16:00:49,533 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from ResultStage 5 (MapPartitionsRDD[8] at distinct at PaidPromotionAdjustParameter.scala:128) (first 15 tasks are for partitions Vector(0, 1))
2021-12-05 16:00:49,533 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 5.0 with 2 tasks
2021-12-05 16:00:49,535 [dispatcher-event-loop-9] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 5.0 (TID 10, localhost, executor driver, partition 0, ANY, 7649 bytes)
2021-12-05 16:00:49,535 [dispatcher-event-loop-9] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 5.0 (TID 11, localhost, executor driver, partition 1, ANY, 7649 bytes)
2021-12-05 16:00:49,535 [Executor task launch worker for task 10] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 5.0 (TID 10)
2021-12-05 16:00:49,535 [Executor task launch worker for task 11] INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 5.0 (TID 11)
2021-12-05 16:00:49,547 [Executor task launch worker for task 10] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 2 non-empty blocks out of 2 blocks
2021-12-05 16:00:49,547 [Executor task launch worker for task 11] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 2 non-empty blocks out of 2 blocks
2021-12-05 16:00:49,549 [Executor task launch worker for task 10] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 5 ms
2021-12-05 16:00:49,549 [Executor task launch worker for task 11] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 5 ms
2021-12-05 16:00:49,671 [Executor task launch worker for task 11] INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 5.0 (TID 11). 1055 bytes result sent to driver
2021-12-05 16:00:49,671 [Executor task launch worker for task 10] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 5.0 (TID 10). 1055 bytes result sent to driver
2021-12-05 16:00:49,672 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 5.0 (TID 10) in 138 ms on localhost (executor driver) (1/2)
2021-12-05 16:00:49,672 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 5.0 (TID 11) in 137 ms on localhost (executor driver) (2/2)
2021-12-05 16:00:49,672 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 5.0, whose tasks have all completed, from pool 
2021-12-05 16:00:49,673 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 5 (count at PaidPromotionAdjustParameter.scala:138) finished in 0.146 s
2021-12-05 16:00:49,673 [main] INFO [org.apache.spark.scheduler.DAGScheduler] - Job 4 finished: count at PaidPromotionAdjustParameter.scala:138, took 1.705915 s
2021-12-05 16:00:49,673 [main] INFO [PaidPromotion$] - 训练集用户数 = 53655
2021-12-05 16:00:49,676 [main] INFO [org.apache.spark.SparkContext] - Starting job: count at PaidPromotionAdjustParameter.scala:139
2021-12-05 16:00:49,676 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 10 (distinct at PaidPromotionAdjustParameter.scala:129)
2021-12-05 16:00:49,677 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 5 (count at PaidPromotionAdjustParameter.scala:139) with 2 output partitions
2021-12-05 16:00:49,677 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 7 (count at PaidPromotionAdjustParameter.scala:139)
2021-12-05 16:00:49,677 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 6)
2021-12-05 16:00:49,677 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List(ShuffleMapStage 6)
2021-12-05 16:00:49,677 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ShuffleMapStage 6 (MapPartitionsRDD[10] at distinct at PaidPromotionAdjustParameter.scala:129), which has no missing parents
2021-12-05 16:00:49,679 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_7 stored as values in memory (estimated size 5.2 KB, free 1990.4 MB)
2021-12-05 16:00:49,682 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_7_piece0 stored as bytes in memory (estimated size 2.9 KB, free 1990.4 MB)
2021-12-05 16:00:49,683 [dispatcher-event-loop-1] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_7_piece0 in memory on qb:53406 (size: 2.9 KB, free: 1990.8 MB)
2021-12-05 16:00:49,683 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 7 from broadcast at DAGScheduler.scala:1039
2021-12-05 16:00:49,684 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from ShuffleMapStage 6 (MapPartitionsRDD[10] at distinct at PaidPromotionAdjustParameter.scala:129) (first 15 tasks are for partitions Vector(0, 1))
2021-12-05 16:00:49,684 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 6.0 with 2 tasks
2021-12-05 16:00:49,685 [dispatcher-event-loop-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 6.0 (TID 12, localhost, executor driver, partition 0, ANY, 7885 bytes)
2021-12-05 16:00:49,685 [dispatcher-event-loop-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 6.0 (TID 13, localhost, executor driver, partition 1, ANY, 7885 bytes)
2021-12-05 16:00:49,685 [Executor task launch worker for task 13] INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 6.0 (TID 13)
2021-12-05 16:00:49,685 [Executor task launch worker for task 12] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 6.0 (TID 12)
2021-12-05 16:00:49,687 [Executor task launch worker for task 12] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/order_data.bcp:0+3442194
2021-12-05 16:00:49,687 [Executor task launch worker for task 13] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/order_data.bcp:3442194+3442195
2021-12-05 16:00:50,138 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 130
2021-12-05 16:00:50,138 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 135
2021-12-05 16:00:50,138 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 142
2021-12-05 16:00:50,138 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 144
2021-12-05 16:00:50,138 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 126
2021-12-05 16:00:50,138 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 128
2021-12-05 16:00:50,138 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 104
2021-12-05 16:00:50,138 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 146
2021-12-05 16:00:50,139 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 115
2021-12-05 16:00:50,139 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 107
2021-12-05 16:00:50,139 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 113
2021-12-05 16:00:50,139 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 129
2021-12-05 16:00:50,139 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 114
2021-12-05 16:00:50,139 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 112
2021-12-05 16:00:50,140 [dispatcher-event-loop-7] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_5_piece0 on qb:53406 in memory (size: 2.9 KB, free: 1990.8 MB)
2021-12-05 16:00:50,140 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 117
2021-12-05 16:00:50,140 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 124
2021-12-05 16:00:50,140 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 110
2021-12-05 16:00:50,140 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 148
2021-12-05 16:00:50,140 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 123
2021-12-05 16:00:50,141 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 106
2021-12-05 16:00:50,141 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 103
2021-12-05 16:00:50,141 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 109
2021-12-05 16:00:50,141 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 149
2021-12-05 16:00:50,141 [dispatcher-event-loop-10] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_6_piece0 on qb:53406 in memory (size: 2.2 KB, free: 1990.8 MB)
2021-12-05 16:00:50,142 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 120
2021-12-05 16:00:50,142 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 143
2021-12-05 16:00:50,142 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 132
2021-12-05 16:00:50,142 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 136
2021-12-05 16:00:50,142 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 108
2021-12-05 16:00:50,142 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 139
2021-12-05 16:00:50,142 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 138
2021-12-05 16:00:50,142 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 118
2021-12-05 16:00:50,142 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 134
2021-12-05 16:00:50,142 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 137
2021-12-05 16:00:50,142 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 100
2021-12-05 16:00:50,142 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 121
2021-12-05 16:00:50,142 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 133
2021-12-05 16:00:50,142 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 127
2021-12-05 16:00:50,142 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 105
2021-12-05 16:00:50,142 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 125
2021-12-05 16:00:50,142 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 140
2021-12-05 16:00:50,142 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 147
2021-12-05 16:00:50,142 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 145
2021-12-05 16:00:50,142 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 111
2021-12-05 16:00:50,142 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 141
2021-12-05 16:00:50,142 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 101
2021-12-05 16:00:50,142 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 131
2021-12-05 16:00:50,142 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 122
2021-12-05 16:00:50,142 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 102
2021-12-05 16:00:50,142 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 119
2021-12-05 16:00:50,142 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 116
2021-12-05 16:00:50,244 [Executor task launch worker for task 12] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 6.0 (TID 12). 1032 bytes result sent to driver
2021-12-05 16:00:50,244 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 6.0 (TID 12) in 560 ms on localhost (executor driver) (1/2)
2021-12-05 16:00:50,464 [Executor task launch worker for task 13] INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 6.0 (TID 13). 1032 bytes result sent to driver
2021-12-05 16:00:50,465 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 6.0 (TID 13) in 780 ms on localhost (executor driver) (2/2)
2021-12-05 16:00:50,465 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 6.0, whose tasks have all completed, from pool 
2021-12-05 16:00:50,465 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ShuffleMapStage 6 (distinct at PaidPromotionAdjustParameter.scala:129) finished in 0.787 s
2021-12-05 16:00:50,465 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - looking for newly runnable stages
2021-12-05 16:00:50,465 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - running: Set()
2021-12-05 16:00:50,465 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - waiting: Set(ResultStage 7)
2021-12-05 16:00:50,465 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - failed: Set()
2021-12-05 16:00:50,466 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 7 (MapPartitionsRDD[12] at distinct at PaidPromotionAdjustParameter.scala:129), which has no missing parents
2021-12-05 16:00:50,466 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_8 stored as values in memory (estimated size 3.7 KB, free 1990.5 MB)
2021-12-05 16:00:50,469 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_8_piece0 stored as bytes in memory (estimated size 2.2 KB, free 1990.5 MB)
2021-12-05 16:00:50,470 [dispatcher-event-loop-1] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_8_piece0 in memory on qb:53406 (size: 2.2 KB, free: 1990.8 MB)
2021-12-05 16:00:50,470 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 8 from broadcast at DAGScheduler.scala:1039
2021-12-05 16:00:50,471 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from ResultStage 7 (MapPartitionsRDD[12] at distinct at PaidPromotionAdjustParameter.scala:129) (first 15 tasks are for partitions Vector(0, 1))
2021-12-05 16:00:50,471 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 7.0 with 2 tasks
2021-12-05 16:00:50,471 [dispatcher-event-loop-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 7.0 (TID 14, localhost, executor driver, partition 0, ANY, 7649 bytes)
2021-12-05 16:00:50,472 [dispatcher-event-loop-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 7.0 (TID 15, localhost, executor driver, partition 1, ANY, 7649 bytes)
2021-12-05 16:00:50,472 [Executor task launch worker for task 15] INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 7.0 (TID 15)
2021-12-05 16:00:50,472 [Executor task launch worker for task 14] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 7.0 (TID 14)
2021-12-05 16:00:50,474 [Executor task launch worker for task 14] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 2 non-empty blocks out of 2 blocks
2021-12-05 16:00:50,474 [Executor task launch worker for task 14] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-05 16:00:50,474 [Executor task launch worker for task 15] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 2 non-empty blocks out of 2 blocks
2021-12-05 16:00:50,474 [Executor task launch worker for task 15] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-05 16:00:50,533 [Executor task launch worker for task 14] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 7.0 (TID 14). 1012 bytes result sent to driver
2021-12-05 16:00:50,533 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 7.0 (TID 14) in 62 ms on localhost (executor driver) (1/2)
2021-12-05 16:00:50,539 [Executor task launch worker for task 15] INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 7.0 (TID 15). 1055 bytes result sent to driver
2021-12-05 16:00:50,540 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 7.0 (TID 15) in 69 ms on localhost (executor driver) (2/2)
2021-12-05 16:00:50,540 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 7.0, whose tasks have all completed, from pool 
2021-12-05 16:00:50,540 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 7 (count at PaidPromotionAdjustParameter.scala:139) finished in 0.074 s
2021-12-05 16:00:50,540 [main] INFO [org.apache.spark.scheduler.DAGScheduler] - Job 5 finished: count at PaidPromotionAdjustParameter.scala:139, took 0.865191 s
2021-12-05 16:00:50,541 [main] INFO [PaidPromotion$] - 验证集用户数 = 46948
2021-12-05 16:00:50,545 [main] INFO [org.apache.spark.SparkContext] - Starting job: count at PaidPromotionAdjustParameter.scala:140
2021-12-05 16:00:50,545 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 14 (intersection at PaidPromotionAdjustParameter.scala:130)
2021-12-05 16:00:50,546 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 13 (intersection at PaidPromotionAdjustParameter.scala:130)
2021-12-05 16:00:50,546 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 6 (count at PaidPromotionAdjustParameter.scala:140) with 2 output partitions
2021-12-05 16:00:50,546 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 12 (count at PaidPromotionAdjustParameter.scala:140)
2021-12-05 16:00:50,546 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 9, ShuffleMapStage 11)
2021-12-05 16:00:50,546 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List(ShuffleMapStage 9, ShuffleMapStage 11)
2021-12-05 16:00:50,546 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ShuffleMapStage 9 (MapPartitionsRDD[14] at intersection at PaidPromotionAdjustParameter.scala:130), which has no missing parents
2021-12-05 16:00:50,547 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_9 stored as values in memory (estimated size 4.0 KB, free 1990.5 MB)
2021-12-05 16:00:50,550 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_9_piece0 stored as bytes in memory (estimated size 2.3 KB, free 1990.4 MB)
2021-12-05 16:00:50,551 [dispatcher-event-loop-7] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_9_piece0 in memory on qb:53406 (size: 2.3 KB, free: 1990.8 MB)
2021-12-05 16:00:50,552 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 9 from broadcast at DAGScheduler.scala:1039
2021-12-05 16:00:50,552 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from ShuffleMapStage 9 (MapPartitionsRDD[14] at intersection at PaidPromotionAdjustParameter.scala:130) (first 15 tasks are for partitions Vector(0, 1))
2021-12-05 16:00:50,552 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 9.0 with 2 tasks
2021-12-05 16:00:50,553 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ShuffleMapStage 11 (MapPartitionsRDD[13] at intersection at PaidPromotionAdjustParameter.scala:130), which has no missing parents
2021-12-05 16:00:50,553 [dispatcher-event-loop-8] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 9.0 (TID 16, localhost, executor driver, partition 0, ANY, 7638 bytes)
2021-12-05 16:00:50,553 [dispatcher-event-loop-8] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 9.0 (TID 17, localhost, executor driver, partition 1, ANY, 7638 bytes)
2021-12-05 16:00:50,553 [Executor task launch worker for task 17] INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 9.0 (TID 17)
2021-12-05 16:00:50,554 [Executor task launch worker for task 16] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 9.0 (TID 16)
2021-12-05 16:00:50,555 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_10 stored as values in memory (estimated size 4.0 KB, free 1990.4 MB)
2021-12-05 16:00:50,557 [Executor task launch worker for task 16] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 2 non-empty blocks out of 2 blocks
2021-12-05 16:00:50,557 [Executor task launch worker for task 17] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 2 non-empty blocks out of 2 blocks
2021-12-05 16:00:50,557 [Executor task launch worker for task 16] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-05 16:00:50,557 [Executor task launch worker for task 17] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-05 16:00:50,560 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_10_piece0 stored as bytes in memory (estimated size 2.3 KB, free 1990.4 MB)
2021-12-05 16:00:50,561 [dispatcher-event-loop-0] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_10_piece0 in memory on qb:53406 (size: 2.3 KB, free: 1990.8 MB)
2021-12-05 16:00:50,561 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 10 from broadcast at DAGScheduler.scala:1039
2021-12-05 16:00:50,562 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from ShuffleMapStage 11 (MapPartitionsRDD[13] at intersection at PaidPromotionAdjustParameter.scala:130) (first 15 tasks are for partitions Vector(0, 1))
2021-12-05 16:00:50,562 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 11.0 with 2 tasks
2021-12-05 16:00:50,563 [dispatcher-event-loop-11] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 11.0 (TID 18, localhost, executor driver, partition 0, ANY, 7638 bytes)
2021-12-05 16:00:50,563 [dispatcher-event-loop-11] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 11.0 (TID 19, localhost, executor driver, partition 1, ANY, 7638 bytes)
2021-12-05 16:00:50,563 [Executor task launch worker for task 18] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 11.0 (TID 18)
2021-12-05 16:00:50,563 [Executor task launch worker for task 19] INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 11.0 (TID 19)
2021-12-05 16:00:50,565 [Executor task launch worker for task 18] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 2 non-empty blocks out of 2 blocks
2021-12-05 16:00:50,565 [Executor task launch worker for task 18] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-05 16:00:50,565 [Executor task launch worker for task 19] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 2 non-empty blocks out of 2 blocks
2021-12-05 16:00:50,565 [Executor task launch worker for task 19] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-05 16:00:50,644 [Executor task launch worker for task 17] INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 9.0 (TID 17). 1204 bytes result sent to driver
2021-12-05 16:00:50,644 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 9.0 (TID 17) in 91 ms on localhost (executor driver) (1/2)
2021-12-05 16:00:50,646 [Executor task launch worker for task 19] INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 11.0 (TID 19). 1204 bytes result sent to driver
2021-12-05 16:00:50,647 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 11.0 (TID 19) in 84 ms on localhost (executor driver) (1/2)
2021-12-05 16:00:50,650 [Executor task launch worker for task 16] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 9.0 (TID 16). 1204 bytes result sent to driver
2021-12-05 16:00:50,651 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 9.0 (TID 16) in 98 ms on localhost (executor driver) (2/2)
2021-12-05 16:00:50,651 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 9.0, whose tasks have all completed, from pool 
2021-12-05 16:00:50,651 [Executor task launch worker for task 18] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 11.0 (TID 18). 1204 bytes result sent to driver
2021-12-05 16:00:50,652 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ShuffleMapStage 9 (intersection at PaidPromotionAdjustParameter.scala:130) finished in 0.104 s
2021-12-05 16:00:50,652 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - looking for newly runnable stages
2021-12-05 16:00:50,652 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - running: Set(ShuffleMapStage 11)
2021-12-05 16:00:50,652 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 11.0 (TID 18) in 90 ms on localhost (executor driver) (2/2)
2021-12-05 16:00:50,652 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - waiting: Set(ResultStage 12)
2021-12-05 16:00:50,652 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - failed: Set()
2021-12-05 16:00:50,652 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 11.0, whose tasks have all completed, from pool 
2021-12-05 16:00:50,653 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ShuffleMapStage 11 (intersection at PaidPromotionAdjustParameter.scala:130) finished in 0.099 s
2021-12-05 16:00:50,653 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - looking for newly runnable stages
2021-12-05 16:00:50,653 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - running: Set()
2021-12-05 16:00:50,653 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - waiting: Set(ResultStage 12)
2021-12-05 16:00:50,653 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - failed: Set()
2021-12-05 16:00:50,653 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 12 (MapPartitionsRDD[18] at intersection at PaidPromotionAdjustParameter.scala:130), which has no missing parents
2021-12-05 16:00:50,655 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_11 stored as values in memory (estimated size 3.6 KB, free 1990.4 MB)
2021-12-05 16:00:50,658 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_11_piece0 stored as bytes in memory (estimated size 2.1 KB, free 1990.4 MB)
2021-12-05 16:00:50,659 [dispatcher-event-loop-7] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_11_piece0 in memory on qb:53406 (size: 2.1 KB, free: 1990.8 MB)
2021-12-05 16:00:50,659 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 11 from broadcast at DAGScheduler.scala:1039
2021-12-05 16:00:50,659 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from ResultStage 12 (MapPartitionsRDD[18] at intersection at PaidPromotionAdjustParameter.scala:130) (first 15 tasks are for partitions Vector(0, 1))
2021-12-05 16:00:50,659 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 12.0 with 2 tasks
2021-12-05 16:00:50,660 [dispatcher-event-loop-8] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 12.0 (TID 20, localhost, executor driver, partition 0, PROCESS_LOCAL, 7712 bytes)
2021-12-05 16:00:50,660 [dispatcher-event-loop-8] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 12.0 (TID 21, localhost, executor driver, partition 1, PROCESS_LOCAL, 7712 bytes)
2021-12-05 16:00:50,661 [Executor task launch worker for task 20] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 12.0 (TID 20)
2021-12-05 16:00:50,661 [Executor task launch worker for task 21] INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 12.0 (TID 21)
2021-12-05 16:00:50,663 [Executor task launch worker for task 21] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2021-12-05 16:00:50,663 [Executor task launch worker for task 20] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2021-12-05 16:00:50,663 [Executor task launch worker for task 21] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-05 16:00:50,663 [Executor task launch worker for task 20] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-05 16:00:50,666 [Executor task launch worker for task 20] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2021-12-05 16:00:50,666 [Executor task launch worker for task 21] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2021-12-05 16:00:50,666 [Executor task launch worker for task 20] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 1 ms
2021-12-05 16:00:50,666 [Executor task launch worker for task 21] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 1 ms
2021-12-05 16:00:50,759 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 151
2021-12-05 16:00:50,759 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 184
2021-12-05 16:00:50,760 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 192
2021-12-05 16:00:50,760 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 194
2021-12-05 16:00:50,760 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 154
2021-12-05 16:00:50,760 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 189
2021-12-05 16:00:50,760 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 183
2021-12-05 16:00:50,760 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 180
2021-12-05 16:00:50,760 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 164
2021-12-05 16:00:50,760 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 152
2021-12-05 16:00:50,760 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 186
2021-12-05 16:00:50,760 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 160
2021-12-05 16:00:50,760 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 199
2021-12-05 16:00:50,760 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 179
2021-12-05 16:00:50,760 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 182
2021-12-05 16:00:50,761 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 185
2021-12-05 16:00:50,762 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 187
2021-12-05 16:00:50,762 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 167
2021-12-05 16:00:50,762 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 157
2021-12-05 16:00:50,762 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 196
2021-12-05 16:00:50,762 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 153
2021-12-05 16:00:50,762 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 174
2021-12-05 16:00:50,762 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 169
2021-12-05 16:00:50,762 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 175
2021-12-05 16:00:50,762 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 181
2021-12-05 16:00:50,762 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 158
2021-12-05 16:00:50,762 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 176
2021-12-05 16:00:50,762 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 168
2021-12-05 16:00:50,762 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 150
2021-12-05 16:00:50,762 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 195
2021-12-05 16:00:50,762 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 166
2021-12-05 16:00:50,762 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 190
2021-12-05 16:00:50,762 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 159
2021-12-05 16:00:50,762 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 161
2021-12-05 16:00:50,762 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 193
2021-12-05 16:00:50,762 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 163
2021-12-05 16:00:50,762 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 170
2021-12-05 16:00:50,763 [dispatcher-event-loop-1] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_8_piece0 on qb:53406 in memory (size: 2.2 KB, free: 1990.8 MB)
2021-12-05 16:00:50,765 [dispatcher-event-loop-4] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_10_piece0 on qb:53406 in memory (size: 2.3 KB, free: 1990.8 MB)
2021-12-05 16:00:50,766 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 173
2021-12-05 16:00:50,766 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 155
2021-12-05 16:00:50,766 [dispatcher-event-loop-7] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_9_piece0 on qb:53406 in memory (size: 2.3 KB, free: 1990.8 MB)
2021-12-05 16:00:50,767 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 156
2021-12-05 16:00:50,767 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 171
2021-12-05 16:00:50,767 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 162
2021-12-05 16:00:50,767 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 172
2021-12-05 16:00:50,767 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 197
2021-12-05 16:00:50,768 [dispatcher-event-loop-9] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_7_piece0 on qb:53406 in memory (size: 2.9 KB, free: 1990.8 MB)
2021-12-05 16:00:50,768 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 188
2021-12-05 16:00:50,768 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 198
2021-12-05 16:00:50,768 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 178
2021-12-05 16:00:50,768 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 165
2021-12-05 16:00:50,768 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 191
2021-12-05 16:00:50,768 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 177
2021-12-05 16:00:50,882 [Executor task launch worker for task 21] INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 12.0 (TID 21). 1054 bytes result sent to driver
2021-12-05 16:00:50,882 [Executor task launch worker for task 20] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 12.0 (TID 20). 1054 bytes result sent to driver
2021-12-05 16:00:50,882 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 12.0 (TID 21) in 222 ms on localhost (executor driver) (1/2)
2021-12-05 16:00:50,883 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 12.0 (TID 20) in 223 ms on localhost (executor driver) (2/2)
2021-12-05 16:00:50,883 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 12.0, whose tasks have all completed, from pool 
2021-12-05 16:00:50,883 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 12 (count at PaidPromotionAdjustParameter.scala:140) finished in 0.230 s
2021-12-05 16:00:50,883 [main] INFO [org.apache.spark.scheduler.DAGScheduler] - Job 6 finished: count at PaidPromotionAdjustParameter.scala:140, took 0.337838 s
2021-12-05 16:00:50,884 [main] INFO [PaidPromotion$] - 共 同 用户数 = 5280
2021-12-05 16:00:50,887 [main] INFO [org.apache.spark.SparkContext] - Starting job: count at PaidPromotionAdjustParameter.scala:141
2021-12-05 16:00:50,888 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 20 (distinct at PaidPromotionAdjustParameter.scala:133)
2021-12-05 16:00:50,888 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 7 (count at PaidPromotionAdjustParameter.scala:141) with 2 output partitions
2021-12-05 16:00:50,888 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 14 (count at PaidPromotionAdjustParameter.scala:141)
2021-12-05 16:00:50,888 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 13)
2021-12-05 16:00:50,888 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List(ShuffleMapStage 13)
2021-12-05 16:00:50,888 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ShuffleMapStage 13 (MapPartitionsRDD[20] at distinct at PaidPromotionAdjustParameter.scala:133), which has no missing parents
2021-12-05 16:00:50,890 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_12 stored as values in memory (estimated size 5.2 KB, free 1990.5 MB)
2021-12-05 16:00:50,894 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_12_piece0 stored as bytes in memory (estimated size 2.9 KB, free 1990.5 MB)
2021-12-05 16:00:50,895 [dispatcher-event-loop-1] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_12_piece0 in memory on qb:53406 (size: 2.9 KB, free: 1990.8 MB)
2021-12-05 16:00:50,895 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 12 from broadcast at DAGScheduler.scala:1039
2021-12-05 16:00:50,895 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from ShuffleMapStage 13 (MapPartitionsRDD[20] at distinct at PaidPromotionAdjustParameter.scala:133) (first 15 tasks are for partitions Vector(0, 1))
2021-12-05 16:00:50,895 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 13.0 with 2 tasks
2021-12-05 16:00:50,896 [dispatcher-event-loop-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 13.0 (TID 22, localhost, executor driver, partition 0, ANY, 7885 bytes)
2021-12-05 16:00:50,896 [dispatcher-event-loop-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 13.0 (TID 23, localhost, executor driver, partition 1, ANY, 7885 bytes)
2021-12-05 16:00:50,896 [Executor task launch worker for task 23] INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 13.0 (TID 23)
2021-12-05 16:00:50,896 [Executor task launch worker for task 22] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 13.0 (TID 22)
2021-12-05 16:00:50,897 [Executor task launch worker for task 22] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/order_data.bcp:0+3442194
2021-12-05 16:00:50,897 [Executor task launch worker for task 23] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/order_data.bcp:3442194+3442195
2021-12-05 16:00:51,418 [Executor task launch worker for task 22] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 13.0 (TID 22). 946 bytes result sent to driver
2021-12-05 16:00:51,419 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 13.0 (TID 22) in 523 ms on localhost (executor driver) (1/2)
2021-12-05 16:00:51,814 [Executor task launch worker for task 23] INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 13.0 (TID 23). 946 bytes result sent to driver
2021-12-05 16:00:51,815 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 13.0 (TID 23) in 919 ms on localhost (executor driver) (2/2)
2021-12-05 16:00:51,815 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 13.0, whose tasks have all completed, from pool 
2021-12-05 16:00:51,815 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ShuffleMapStage 13 (distinct at PaidPromotionAdjustParameter.scala:133) finished in 0.926 s
2021-12-05 16:00:51,815 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - looking for newly runnable stages
2021-12-05 16:00:51,815 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - running: Set()
2021-12-05 16:00:51,815 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - waiting: Set(ResultStage 14)
2021-12-05 16:00:51,815 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - failed: Set()
2021-12-05 16:00:51,815 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 14 (MapPartitionsRDD[22] at distinct at PaidPromotionAdjustParameter.scala:133), which has no missing parents
2021-12-05 16:00:51,816 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_13 stored as values in memory (estimated size 3.7 KB, free 1990.5 MB)
2021-12-05 16:00:51,818 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_13_piece0 stored as bytes in memory (estimated size 2.2 KB, free 1990.4 MB)
2021-12-05 16:00:51,819 [dispatcher-event-loop-7] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_13_piece0 in memory on qb:53406 (size: 2.2 KB, free: 1990.8 MB)
2021-12-05 16:00:51,819 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 13 from broadcast at DAGScheduler.scala:1039
2021-12-05 16:00:51,820 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from ResultStage 14 (MapPartitionsRDD[22] at distinct at PaidPromotionAdjustParameter.scala:133) (first 15 tasks are for partitions Vector(0, 1))
2021-12-05 16:00:51,820 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 14.0 with 2 tasks
2021-12-05 16:00:51,821 [dispatcher-event-loop-10] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 14.0 (TID 24, localhost, executor driver, partition 0, ANY, 7649 bytes)
2021-12-05 16:00:51,821 [dispatcher-event-loop-10] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 14.0 (TID 25, localhost, executor driver, partition 1, ANY, 7649 bytes)
2021-12-05 16:00:51,821 [Executor task launch worker for task 25] INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 14.0 (TID 25)
2021-12-05 16:00:51,821 [Executor task launch worker for task 24] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 14.0 (TID 24)
2021-12-05 16:00:51,823 [Executor task launch worker for task 24] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 2 non-empty blocks out of 2 blocks
2021-12-05 16:00:51,823 [Executor task launch worker for task 25] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 2 non-empty blocks out of 2 blocks
2021-12-05 16:00:51,823 [Executor task launch worker for task 24] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-05 16:00:51,823 [Executor task launch worker for task 25] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-05 16:00:51,838 [Executor task launch worker for task 24] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 14.0 (TID 24). 1053 bytes result sent to driver
2021-12-05 16:00:51,838 [Executor task launch worker for task 25] INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 14.0 (TID 25). 1010 bytes result sent to driver
2021-12-05 16:00:51,838 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 14.0 (TID 24) in 18 ms on localhost (executor driver) (1/2)
2021-12-05 16:00:51,838 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 14.0 (TID 25) in 17 ms on localhost (executor driver) (2/2)
2021-12-05 16:00:51,838 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 14.0, whose tasks have all completed, from pool 
2021-12-05 16:00:51,839 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 14 (count at PaidPromotionAdjustParameter.scala:141) finished in 0.023 s
2021-12-05 16:00:51,840 [main] INFO [org.apache.spark.scheduler.DAGScheduler] - Job 7 finished: count at PaidPromotionAdjustParameter.scala:141, took 0.952158 s
2021-12-05 16:00:51,841 [main] INFO [PaidPromotion$] - 训练集节目数 = 124
2021-12-05 16:00:51,844 [main] INFO [org.apache.spark.SparkContext] - Starting job: count at PaidPromotionAdjustParameter.scala:142
2021-12-05 16:00:51,844 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 24 (distinct at PaidPromotionAdjustParameter.scala:134)
2021-12-05 16:00:51,844 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 8 (count at PaidPromotionAdjustParameter.scala:142) with 2 output partitions
2021-12-05 16:00:51,844 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 16 (count at PaidPromotionAdjustParameter.scala:142)
2021-12-05 16:00:51,844 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 15)
2021-12-05 16:00:51,844 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List(ShuffleMapStage 15)
2021-12-05 16:00:51,845 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ShuffleMapStage 15 (MapPartitionsRDD[24] at distinct at PaidPromotionAdjustParameter.scala:134), which has no missing parents
2021-12-05 16:00:51,846 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_14 stored as values in memory (estimated size 5.2 KB, free 1990.4 MB)
2021-12-05 16:00:51,848 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_14_piece0 stored as bytes in memory (estimated size 2.9 KB, free 1990.4 MB)
2021-12-05 16:00:51,848 [dispatcher-event-loop-1] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_14_piece0 in memory on qb:53406 (size: 2.9 KB, free: 1990.8 MB)
2021-12-05 16:00:51,849 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 14 from broadcast at DAGScheduler.scala:1039
2021-12-05 16:00:51,849 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from ShuffleMapStage 15 (MapPartitionsRDD[24] at distinct at PaidPromotionAdjustParameter.scala:134) (first 15 tasks are for partitions Vector(0, 1))
2021-12-05 16:00:51,849 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 15.0 with 2 tasks
2021-12-05 16:00:51,849 [dispatcher-event-loop-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 15.0 (TID 26, localhost, executor driver, partition 0, ANY, 7885 bytes)
2021-12-05 16:00:51,850 [dispatcher-event-loop-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 15.0 (TID 27, localhost, executor driver, partition 1, ANY, 7885 bytes)
2021-12-05 16:00:51,850 [Executor task launch worker for task 27] INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 15.0 (TID 27)
2021-12-05 16:00:51,850 [Executor task launch worker for task 26] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 15.0 (TID 26)
2021-12-05 16:00:51,851 [Executor task launch worker for task 27] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/order_data.bcp:3442194+3442195
2021-12-05 16:00:51,851 [Executor task launch worker for task 26] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/order_data.bcp:0+3442194
2021-12-05 16:00:51,967 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 229
2021-12-05 16:00:51,967 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 216
2021-12-05 16:00:51,967 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 314
2021-12-05 16:00:51,967 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 213
2021-12-05 16:00:51,967 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 303
2021-12-05 16:00:51,967 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 222
2021-12-05 16:00:51,967 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 315
2021-12-05 16:00:51,967 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 260
2021-12-05 16:00:51,967 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 268
2021-12-05 16:00:51,967 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 244
2021-12-05 16:00:51,967 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 250
2021-12-05 16:00:51,967 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 237
2021-12-05 16:00:51,967 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 288
2021-12-05 16:00:51,967 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 270
2021-12-05 16:00:51,967 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 261
2021-12-05 16:00:51,967 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 234
2021-12-05 16:00:51,967 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 322
2021-12-05 16:00:51,967 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 204
2021-12-05 16:00:51,967 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 239
2021-12-05 16:00:51,967 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 220
2021-12-05 16:00:51,967 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 254
2021-12-05 16:00:51,967 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 208
2021-12-05 16:00:51,967 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 284
2021-12-05 16:00:51,967 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 252
2021-12-05 16:00:51,967 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 283
2021-12-05 16:00:51,967 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 311
2021-12-05 16:00:51,967 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 246
2021-12-05 16:00:51,967 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 320
2021-12-05 16:00:51,967 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 259
2021-12-05 16:00:51,967 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 262
2021-12-05 16:00:51,967 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 295
2021-12-05 16:00:51,967 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 256
2021-12-05 16:00:51,967 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 227
2021-12-05 16:00:51,967 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 296
2021-12-05 16:00:51,967 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 277
2021-12-05 16:00:51,967 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 286
2021-12-05 16:00:51,967 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 305
2021-12-05 16:00:51,967 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 217
2021-12-05 16:00:51,967 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 291
2021-12-05 16:00:51,967 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 297
2021-12-05 16:00:51,967 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 285
2021-12-05 16:00:51,968 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 223
2021-12-05 16:00:51,968 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 306
2021-12-05 16:00:51,968 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 312
2021-12-05 16:00:51,968 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 300
2021-12-05 16:00:51,968 [dispatcher-event-loop-7] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_12_piece0 on qb:53406 in memory (size: 2.9 KB, free: 1990.8 MB)
2021-12-05 16:00:51,969 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 231
2021-12-05 16:00:51,969 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 272
2021-12-05 16:00:51,969 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 211
2021-12-05 16:00:51,970 [dispatcher-event-loop-8] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_13_piece0 on qb:53406 in memory (size: 2.2 KB, free: 1990.8 MB)
2021-12-05 16:00:51,970 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 218
2021-12-05 16:00:51,970 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 207
2021-12-05 16:00:51,970 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 221
2021-12-05 16:00:51,970 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 245
2021-12-05 16:00:51,970 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 319
2021-12-05 16:00:51,970 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 200
2021-12-05 16:00:51,970 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 206
2021-12-05 16:00:51,971 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 302
2021-12-05 16:00:51,971 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 271
2021-12-05 16:00:51,971 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 215
2021-12-05 16:00:51,971 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 258
2021-12-05 16:00:51,971 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 278
2021-12-05 16:00:51,971 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 228
2021-12-05 16:00:51,971 [dispatcher-event-loop-1] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_11_piece0 on qb:53406 in memory (size: 2.1 KB, free: 1990.8 MB)
2021-12-05 16:00:51,972 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 273
2021-12-05 16:00:51,972 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 313
2021-12-05 16:00:51,972 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 324
2021-12-05 16:00:51,972 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 318
2021-12-05 16:00:51,972 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 212
2021-12-05 16:00:51,972 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 316
2021-12-05 16:00:51,972 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 263
2021-12-05 16:00:51,972 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 274
2021-12-05 16:00:51,972 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 255
2021-12-05 16:00:51,972 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 276
2021-12-05 16:00:51,972 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 275
2021-12-05 16:00:51,972 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 293
2021-12-05 16:00:51,972 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 321
2021-12-05 16:00:51,972 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 236
2021-12-05 16:00:51,972 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 282
2021-12-05 16:00:51,972 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 241
2021-12-05 16:00:51,972 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 308
2021-12-05 16:00:51,972 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 257
2021-12-05 16:00:51,972 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 202
2021-12-05 16:00:51,972 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 310
2021-12-05 16:00:51,972 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 251
2021-12-05 16:00:51,972 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 294
2021-12-05 16:00:51,972 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 247
2021-12-05 16:00:51,972 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 292
2021-12-05 16:00:51,972 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 304
2021-12-05 16:00:51,972 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 309
2021-12-05 16:00:51,972 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 205
2021-12-05 16:00:51,972 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 289
2021-12-05 16:00:51,972 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 301
2021-12-05 16:00:51,972 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 232
2021-12-05 16:00:51,972 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 248
2021-12-05 16:00:51,972 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 298
2021-12-05 16:00:51,972 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 209
2021-12-05 16:00:51,972 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 264
2021-12-05 16:00:51,972 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 242
2021-12-05 16:00:51,972 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 240
2021-12-05 16:00:51,972 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 323
2021-12-05 16:00:51,972 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 266
2021-12-05 16:00:51,972 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 267
2021-12-05 16:00:51,972 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 299
2021-12-05 16:00:51,972 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 307
2021-12-05 16:00:51,972 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 219
2021-12-05 16:00:51,972 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 233
2021-12-05 16:00:51,972 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 201
2021-12-05 16:00:51,972 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 226
2021-12-05 16:00:51,972 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 243
2021-12-05 16:00:51,972 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 287
2021-12-05 16:00:51,972 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 238
2021-12-05 16:00:51,972 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 265
2021-12-05 16:00:51,972 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 203
2021-12-05 16:00:51,972 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 290
2021-12-05 16:00:51,972 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 317
2021-12-05 16:00:51,972 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 279
2021-12-05 16:00:51,972 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 230
2021-12-05 16:00:51,972 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 210
2021-12-05 16:00:51,972 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 249
2021-12-05 16:00:51,972 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 269
2021-12-05 16:00:51,972 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 235
2021-12-05 16:00:51,972 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 225
2021-12-05 16:00:51,972 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 280
2021-12-05 16:00:51,972 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 214
2021-12-05 16:00:51,972 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 253
2021-12-05 16:00:51,972 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 224
2021-12-05 16:00:51,972 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 281
2021-12-05 16:00:52,249 [Executor task launch worker for task 27] INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 15.0 (TID 27). 1032 bytes result sent to driver
2021-12-05 16:00:52,250 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 15.0 (TID 27) in 401 ms on localhost (executor driver) (1/2)
2021-12-05 16:00:52,508 [Executor task launch worker for task 26] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 15.0 (TID 26). 989 bytes result sent to driver
2021-12-05 16:00:52,508 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 15.0 (TID 26) in 659 ms on localhost (executor driver) (2/2)
2021-12-05 16:00:52,508 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 15.0, whose tasks have all completed, from pool 
2021-12-05 16:00:52,508 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ShuffleMapStage 15 (distinct at PaidPromotionAdjustParameter.scala:134) finished in 0.663 s
2021-12-05 16:00:52,508 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - looking for newly runnable stages
2021-12-05 16:00:52,508 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - running: Set()
2021-12-05 16:00:52,508 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - waiting: Set(ResultStage 16)
2021-12-05 16:00:52,508 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - failed: Set()
2021-12-05 16:00:52,508 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 16 (MapPartitionsRDD[26] at distinct at PaidPromotionAdjustParameter.scala:134), which has no missing parents
2021-12-05 16:00:52,509 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_15 stored as values in memory (estimated size 3.7 KB, free 1990.5 MB)
2021-12-05 16:00:52,511 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_15_piece0 stored as bytes in memory (estimated size 2.2 KB, free 1990.5 MB)
2021-12-05 16:00:52,511 [dispatcher-event-loop-6] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_15_piece0 in memory on qb:53406 (size: 2.2 KB, free: 1990.8 MB)
2021-12-05 16:00:52,512 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 15 from broadcast at DAGScheduler.scala:1039
2021-12-05 16:00:52,512 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from ResultStage 16 (MapPartitionsRDD[26] at distinct at PaidPromotionAdjustParameter.scala:134) (first 15 tasks are for partitions Vector(0, 1))
2021-12-05 16:00:52,512 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 16.0 with 2 tasks
2021-12-05 16:00:52,513 [dispatcher-event-loop-7] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 16.0 (TID 28, localhost, executor driver, partition 0, ANY, 7649 bytes)
2021-12-05 16:00:52,513 [dispatcher-event-loop-7] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 16.0 (TID 29, localhost, executor driver, partition 1, ANY, 7649 bytes)
2021-12-05 16:00:52,513 [Executor task launch worker for task 29] INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 16.0 (TID 29)
2021-12-05 16:00:52,513 [Executor task launch worker for task 28] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 16.0 (TID 28)
2021-12-05 16:00:52,515 [Executor task launch worker for task 29] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 2 non-empty blocks out of 2 blocks
2021-12-05 16:00:52,515 [Executor task launch worker for task 28] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 2 non-empty blocks out of 2 blocks
2021-12-05 16:00:52,515 [Executor task launch worker for task 29] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 1 ms
2021-12-05 16:00:52,515 [Executor task launch worker for task 28] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 1 ms
2021-12-05 16:00:52,530 [Executor task launch worker for task 28] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 16.0 (TID 28). 1010 bytes result sent to driver
2021-12-05 16:00:52,530 [Executor task launch worker for task 29] INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 16.0 (TID 29). 1010 bytes result sent to driver
2021-12-05 16:00:52,531 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 16.0 (TID 28) in 18 ms on localhost (executor driver) (1/2)
2021-12-05 16:00:52,531 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 16.0 (TID 29) in 18 ms on localhost (executor driver) (2/2)
2021-12-05 16:00:52,531 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 16.0, whose tasks have all completed, from pool 
2021-12-05 16:00:52,531 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 16 (count at PaidPromotionAdjustParameter.scala:142) finished in 0.022 s
2021-12-05 16:00:52,531 [main] INFO [org.apache.spark.scheduler.DAGScheduler] - Job 8 finished: count at PaidPromotionAdjustParameter.scala:142, took 0.688014 s
2021-12-05 16:00:52,531 [main] INFO [PaidPromotion$] - 验证集节目数 = 118
2021-12-05 16:00:52,534 [main] INFO [org.apache.spark.SparkContext] - Starting job: count at PaidPromotionAdjustParameter.scala:143
2021-12-05 16:00:52,534 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 28 (intersection at PaidPromotionAdjustParameter.scala:135)
2021-12-05 16:00:52,534 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 27 (intersection at PaidPromotionAdjustParameter.scala:135)
2021-12-05 16:00:52,535 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 9 (count at PaidPromotionAdjustParameter.scala:143) with 2 output partitions
2021-12-05 16:00:52,535 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 21 (count at PaidPromotionAdjustParameter.scala:143)
2021-12-05 16:00:52,535 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 20, ShuffleMapStage 18)
2021-12-05 16:00:52,535 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List(ShuffleMapStage 20, ShuffleMapStage 18)
2021-12-05 16:00:52,535 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ShuffleMapStage 18 (MapPartitionsRDD[28] at intersection at PaidPromotionAdjustParameter.scala:135), which has no missing parents
2021-12-05 16:00:52,536 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_16 stored as values in memory (estimated size 4.0 KB, free 1990.5 MB)
2021-12-05 16:00:52,538 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_16_piece0 stored as bytes in memory (estimated size 2.3 KB, free 1990.4 MB)
2021-12-05 16:00:52,538 [dispatcher-event-loop-11] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_16_piece0 in memory on qb:53406 (size: 2.3 KB, free: 1990.8 MB)
2021-12-05 16:00:52,539 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 16 from broadcast at DAGScheduler.scala:1039
2021-12-05 16:00:52,539 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from ShuffleMapStage 18 (MapPartitionsRDD[28] at intersection at PaidPromotionAdjustParameter.scala:135) (first 15 tasks are for partitions Vector(0, 1))
2021-12-05 16:00:52,539 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 18.0 with 2 tasks
2021-12-05 16:00:52,540 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ShuffleMapStage 20 (MapPartitionsRDD[27] at intersection at PaidPromotionAdjustParameter.scala:135), which has no missing parents
2021-12-05 16:00:52,540 [dispatcher-event-loop-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 18.0 (TID 30, localhost, executor driver, partition 0, ANY, 7638 bytes)
2021-12-05 16:00:52,540 [dispatcher-event-loop-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 18.0 (TID 31, localhost, executor driver, partition 1, ANY, 7638 bytes)
2021-12-05 16:00:52,540 [Executor task launch worker for task 30] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 18.0 (TID 30)
2021-12-05 16:00:52,540 [Executor task launch worker for task 31] INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 18.0 (TID 31)
2021-12-05 16:00:52,541 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_17 stored as values in memory (estimated size 4.0 KB, free 1990.4 MB)
2021-12-05 16:00:52,541 [Executor task launch worker for task 31] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 2 non-empty blocks out of 2 blocks
2021-12-05 16:00:52,541 [Executor task launch worker for task 31] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-05 16:00:52,541 [Executor task launch worker for task 30] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 2 non-empty blocks out of 2 blocks
2021-12-05 16:00:52,541 [Executor task launch worker for task 30] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-05 16:00:52,542 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_17_piece0 stored as bytes in memory (estimated size 2.3 KB, free 1990.4 MB)
2021-12-05 16:00:52,543 [dispatcher-event-loop-3] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_17_piece0 in memory on qb:53406 (size: 2.3 KB, free: 1990.8 MB)
2021-12-05 16:00:52,543 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 17 from broadcast at DAGScheduler.scala:1039
2021-12-05 16:00:52,543 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from ShuffleMapStage 20 (MapPartitionsRDD[27] at intersection at PaidPromotionAdjustParameter.scala:135) (first 15 tasks are for partitions Vector(0, 1))
2021-12-05 16:00:52,543 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 20.0 with 2 tasks
2021-12-05 16:00:52,544 [dispatcher-event-loop-5] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 20.0 (TID 32, localhost, executor driver, partition 0, ANY, 7638 bytes)
2021-12-05 16:00:52,544 [dispatcher-event-loop-5] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 20.0 (TID 33, localhost, executor driver, partition 1, ANY, 7638 bytes)
2021-12-05 16:00:52,544 [Executor task launch worker for task 33] INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 20.0 (TID 33)
2021-12-05 16:00:52,544 [Executor task launch worker for task 32] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 20.0 (TID 32)
2021-12-05 16:00:52,545 [Executor task launch worker for task 32] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 2 non-empty blocks out of 2 blocks
2021-12-05 16:00:52,545 [Executor task launch worker for task 32] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-05 16:00:52,545 [Executor task launch worker for task 33] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 2 non-empty blocks out of 2 blocks
2021-12-05 16:00:52,545 [Executor task launch worker for task 33] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-05 16:00:52,562 [Executor task launch worker for task 30] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 18.0 (TID 30). 1161 bytes result sent to driver
2021-12-05 16:00:52,564 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 18.0 (TID 30) in 24 ms on localhost (executor driver) (1/2)
2021-12-05 16:00:52,566 [Executor task launch worker for task 31] INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 18.0 (TID 31). 1161 bytes result sent to driver
2021-12-05 16:00:52,567 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 18.0 (TID 31) in 27 ms on localhost (executor driver) (2/2)
2021-12-05 16:00:52,567 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 18.0, whose tasks have all completed, from pool 
2021-12-05 16:00:52,567 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ShuffleMapStage 18 (intersection at PaidPromotionAdjustParameter.scala:135) finished in 0.032 s
2021-12-05 16:00:52,567 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - looking for newly runnable stages
2021-12-05 16:00:52,567 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - running: Set(ShuffleMapStage 20)
2021-12-05 16:00:52,567 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - waiting: Set(ResultStage 21)
2021-12-05 16:00:52,567 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - failed: Set()
2021-12-05 16:00:52,568 [Executor task launch worker for task 32] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 20.0 (TID 32). 1161 bytes result sent to driver
2021-12-05 16:00:52,568 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 20.0 (TID 32) in 24 ms on localhost (executor driver) (1/2)
2021-12-05 16:00:52,568 [Executor task launch worker for task 33] INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 20.0 (TID 33). 1161 bytes result sent to driver
2021-12-05 16:00:52,569 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 20.0 (TID 33) in 25 ms on localhost (executor driver) (2/2)
2021-12-05 16:00:52,569 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 20.0, whose tasks have all completed, from pool 
2021-12-05 16:00:52,569 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ShuffleMapStage 20 (intersection at PaidPromotionAdjustParameter.scala:135) finished in 0.029 s
2021-12-05 16:00:52,569 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - looking for newly runnable stages
2021-12-05 16:00:52,569 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - running: Set()
2021-12-05 16:00:52,569 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - waiting: Set(ResultStage 21)
2021-12-05 16:00:52,569 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - failed: Set()
2021-12-05 16:00:52,569 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 21 (MapPartitionsRDD[32] at intersection at PaidPromotionAdjustParameter.scala:135), which has no missing parents
2021-12-05 16:00:52,570 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_18 stored as values in memory (estimated size 3.6 KB, free 1990.4 MB)
2021-12-05 16:00:52,572 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_18_piece0 stored as bytes in memory (estimated size 2.1 KB, free 1990.4 MB)
2021-12-05 16:00:52,573 [dispatcher-event-loop-11] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_18_piece0 in memory on qb:53406 (size: 2.1 KB, free: 1990.8 MB)
2021-12-05 16:00:52,573 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 18 from broadcast at DAGScheduler.scala:1039
2021-12-05 16:00:52,573 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from ResultStage 21 (MapPartitionsRDD[32] at intersection at PaidPromotionAdjustParameter.scala:135) (first 15 tasks are for partitions Vector(0, 1))
2021-12-05 16:00:52,573 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 21.0 with 2 tasks
2021-12-05 16:00:52,574 [dispatcher-event-loop-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 21.0 (TID 34, localhost, executor driver, partition 0, PROCESS_LOCAL, 7712 bytes)
2021-12-05 16:00:52,574 [dispatcher-event-loop-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 21.0 (TID 35, localhost, executor driver, partition 1, PROCESS_LOCAL, 7712 bytes)
2021-12-05 16:00:52,574 [Executor task launch worker for task 34] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 21.0 (TID 34)
2021-12-05 16:00:52,574 [Executor task launch worker for task 35] INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 21.0 (TID 35)
2021-12-05 16:00:52,575 [Executor task launch worker for task 35] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2021-12-05 16:00:52,575 [Executor task launch worker for task 34] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2021-12-05 16:00:52,575 [Executor task launch worker for task 35] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-05 16:00:52,575 [Executor task launch worker for task 34] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-05 16:00:52,577 [Executor task launch worker for task 35] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2021-12-05 16:00:52,577 [Executor task launch worker for task 34] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2021-12-05 16:00:52,577 [Executor task launch worker for task 35] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-05 16:00:52,577 [Executor task launch worker for task 34] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-05 16:00:52,583 [Executor task launch worker for task 34] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 21.0 (TID 34). 1053 bytes result sent to driver
2021-12-05 16:00:52,583 [Executor task launch worker for task 35] INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 21.0 (TID 35). 1053 bytes result sent to driver
2021-12-05 16:00:52,584 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 21.0 (TID 34) in 11 ms on localhost (executor driver) (1/2)
2021-12-05 16:00:52,584 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 21.0 (TID 35) in 10 ms on localhost (executor driver) (2/2)
2021-12-05 16:00:52,584 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 21.0, whose tasks have all completed, from pool 
2021-12-05 16:00:52,584 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 21 (count at PaidPromotionAdjustParameter.scala:143) finished in 0.015 s
2021-12-05 16:00:52,584 [main] INFO [org.apache.spark.scheduler.DAGScheduler] - Job 9 finished: count at PaidPromotionAdjustParameter.scala:143, took 0.050268 s
2021-12-05 16:00:52,585 [main] INFO [PaidPromotion$] - 共 同 节目数 = 110
2021-12-05 16:00:52,593 [main] INFO [org.apache.spark.SparkContext] - Starting job: collect at PaidPromotionAdjustParameter.scala:146
2021-12-05 16:00:52,593 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 10 (collect at PaidPromotionAdjustParameter.scala:146) with 2 output partitions
2021-12-05 16:00:52,593 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 26 (collect at PaidPromotionAdjustParameter.scala:146)
2021-12-05 16:00:52,593 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 25, ShuffleMapStage 23)
2021-12-05 16:00:52,593 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2021-12-05 16:00:52,593 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 26 (MapPartitionsRDD[18] at intersection at PaidPromotionAdjustParameter.scala:130), which has no missing parents
2021-12-05 16:00:52,595 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_19 stored as values in memory (estimated size 3.8 KB, free 1990.4 MB)
2021-12-05 16:00:52,598 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_19_piece0 stored as bytes in memory (estimated size 2.2 KB, free 1990.4 MB)
2021-12-05 16:00:52,598 [dispatcher-event-loop-6] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_19_piece0 in memory on qb:53406 (size: 2.2 KB, free: 1990.8 MB)
2021-12-05 16:00:52,598 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 19 from broadcast at DAGScheduler.scala:1039
2021-12-05 16:00:52,599 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from ResultStage 26 (MapPartitionsRDD[18] at intersection at PaidPromotionAdjustParameter.scala:130) (first 15 tasks are for partitions Vector(0, 1))
2021-12-05 16:00:52,599 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 26.0 with 2 tasks
2021-12-05 16:00:52,600 [dispatcher-event-loop-7] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 26.0 (TID 36, localhost, executor driver, partition 0, PROCESS_LOCAL, 7712 bytes)
2021-12-05 16:00:52,600 [dispatcher-event-loop-7] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 26.0 (TID 37, localhost, executor driver, partition 1, PROCESS_LOCAL, 7712 bytes)
2021-12-05 16:00:52,600 [Executor task launch worker for task 37] INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 26.0 (TID 37)
2021-12-05 16:00:52,600 [Executor task launch worker for task 36] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 26.0 (TID 36)
2021-12-05 16:00:52,601 [Executor task launch worker for task 36] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2021-12-05 16:00:52,601 [Executor task launch worker for task 36] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-05 16:00:52,601 [Executor task launch worker for task 37] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2021-12-05 16:00:52,601 [Executor task launch worker for task 37] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-05 16:00:52,603 [Executor task launch worker for task 36] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2021-12-05 16:00:52,603 [Executor task launch worker for task 37] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2021-12-05 16:00:52,603 [Executor task launch worker for task 36] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-05 16:00:52,603 [Executor task launch worker for task 37] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-05 16:00:52,679 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 333
2021-12-05 16:00:52,679 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 448
2021-12-05 16:00:52,679 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 348
2021-12-05 16:00:52,682 [dispatcher-event-loop-11] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_16_piece0 on qb:53406 in memory (size: 2.3 KB, free: 1990.8 MB)
2021-12-05 16:00:52,683 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 418
2021-12-05 16:00:52,683 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 363
2021-12-05 16:00:52,683 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 391
2021-12-05 16:00:52,683 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 332
2021-12-05 16:00:52,683 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 415
2021-12-05 16:00:52,683 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 434
2021-12-05 16:00:52,683 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 349
2021-12-05 16:00:52,683 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 358
2021-12-05 16:00:52,683 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 343
2021-12-05 16:00:52,683 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 431
2021-12-05 16:00:52,683 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 393
2021-12-05 16:00:52,683 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 328
2021-12-05 16:00:52,683 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 439
2021-12-05 16:00:52,683 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 375
2021-12-05 16:00:52,683 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 445
2021-12-05 16:00:52,683 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 378
2021-12-05 16:00:52,683 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 373
2021-12-05 16:00:52,683 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 337
2021-12-05 16:00:52,683 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 377
2021-12-05 16:00:52,683 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 441
2021-12-05 16:00:52,683 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 449
2021-12-05 16:00:52,683 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 357
2021-12-05 16:00:52,683 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 444
2021-12-05 16:00:52,683 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 354
2021-12-05 16:00:52,683 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 392
2021-12-05 16:00:52,683 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 403
2021-12-05 16:00:52,683 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 416
2021-12-05 16:00:52,683 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 397
2021-12-05 16:00:52,683 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 406
2021-12-05 16:00:52,683 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 417
2021-12-05 16:00:52,685 [dispatcher-event-loop-2] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_18_piece0 on qb:53406 in memory (size: 2.1 KB, free: 1990.8 MB)
2021-12-05 16:00:52,685 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 365
2021-12-05 16:00:52,685 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 428
2021-12-05 16:00:52,685 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 446
2021-12-05 16:00:52,685 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 429
2021-12-05 16:00:52,685 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 368
2021-12-05 16:00:52,685 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 427
2021-12-05 16:00:52,685 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 426
2021-12-05 16:00:52,685 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 395
2021-12-05 16:00:52,685 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 347
2021-12-05 16:00:52,686 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 404
2021-12-05 16:00:52,686 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 433
2021-12-05 16:00:52,686 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 384
2021-12-05 16:00:52,686 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 341
2021-12-05 16:00:52,687 [dispatcher-event-loop-6] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_17_piece0 on qb:53406 in memory (size: 2.3 KB, free: 1990.8 MB)
2021-12-05 16:00:52,688 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 414
2021-12-05 16:00:52,688 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 405
2021-12-05 16:00:52,688 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 374
2021-12-05 16:00:52,688 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 430
2021-12-05 16:00:52,688 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 369
2021-12-05 16:00:52,688 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 383
2021-12-05 16:00:52,688 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 408
2021-12-05 16:00:52,688 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 364
2021-12-05 16:00:52,688 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 410
2021-12-05 16:00:52,688 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 371
2021-12-05 16:00:52,688 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 346
2021-12-05 16:00:52,688 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 342
2021-12-05 16:00:52,688 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 400
2021-12-05 16:00:52,688 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 329
2021-12-05 16:00:52,688 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 438
2021-12-05 16:00:52,688 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 435
2021-12-05 16:00:52,688 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 334
2021-12-05 16:00:52,688 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 388
2021-12-05 16:00:52,688 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 359
2021-12-05 16:00:52,688 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 336
2021-12-05 16:00:52,688 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 338
2021-12-05 16:00:52,688 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 376
2021-12-05 16:00:52,688 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 442
2021-12-05 16:00:52,688 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 340
2021-12-05 16:00:52,688 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 372
2021-12-05 16:00:52,688 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 362
2021-12-05 16:00:52,688 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 432
2021-12-05 16:00:52,688 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 360
2021-12-05 16:00:52,688 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 382
2021-12-05 16:00:52,688 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 396
2021-12-05 16:00:52,688 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 344
2021-12-05 16:00:52,688 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 379
2021-12-05 16:00:52,689 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 367
2021-12-05 16:00:52,689 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 389
2021-12-05 16:00:52,689 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 330
2021-12-05 16:00:52,689 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 387
2021-12-05 16:00:52,689 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 370
2021-12-05 16:00:52,689 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 385
2021-12-05 16:00:52,689 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 411
2021-12-05 16:00:52,689 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 355
2021-12-05 16:00:52,689 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 386
2021-12-05 16:00:52,689 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 436
2021-12-05 16:00:52,689 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 420
2021-12-05 16:00:52,689 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 351
2021-12-05 16:00:52,689 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 381
2021-12-05 16:00:52,689 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 390
2021-12-05 16:00:52,689 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 409
2021-12-05 16:00:52,691 [dispatcher-event-loop-10] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_14_piece0 on qb:53406 in memory (size: 2.9 KB, free: 1990.8 MB)
2021-12-05 16:00:52,692 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 440
2021-12-05 16:00:52,692 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 401
2021-12-05 16:00:52,692 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 412
2021-12-05 16:00:52,692 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 423
2021-12-05 16:00:52,692 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 325
2021-12-05 16:00:52,692 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 407
2021-12-05 16:00:52,692 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 443
2021-12-05 16:00:52,692 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 394
2021-12-05 16:00:52,692 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 447
2021-12-05 16:00:52,692 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 419
2021-12-05 16:00:52,692 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 361
2021-12-05 16:00:52,692 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 366
2021-12-05 16:00:52,692 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 398
2021-12-05 16:00:52,692 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 399
2021-12-05 16:00:52,692 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 421
2021-12-05 16:00:52,692 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 422
2021-12-05 16:00:52,692 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 353
2021-12-05 16:00:52,692 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 437
2021-12-05 16:00:52,692 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 413
2021-12-05 16:00:52,692 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 402
2021-12-05 16:00:52,692 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 380
2021-12-05 16:00:52,692 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 352
2021-12-05 16:00:52,692 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 331
2021-12-05 16:00:52,693 [dispatcher-event-loop-11] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_15_piece0 on qb:53406 in memory (size: 2.2 KB, free: 1990.8 MB)
2021-12-05 16:00:52,693 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 350
2021-12-05 16:00:52,693 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 345
2021-12-05 16:00:52,693 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 425
2021-12-05 16:00:52,693 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 326
2021-12-05 16:00:52,693 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 335
2021-12-05 16:00:52,693 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 339
2021-12-05 16:00:52,693 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 356
2021-12-05 16:00:52,693 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 327
2021-12-05 16:00:52,694 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 424
2021-12-05 16:00:52,698 [Executor task launch worker for task 37] INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 26.0 (TID 37). 89250 bytes result sent to driver
2021-12-05 16:00:52,699 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 26.0 (TID 37) in 99 ms on localhost (executor driver) (1/2)
2021-12-05 16:00:52,701 [Executor task launch worker for task 36] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 26.0 (TID 36). 88123 bytes result sent to driver
2021-12-05 16:00:52,701 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 26.0 (TID 36) in 101 ms on localhost (executor driver) (2/2)
2021-12-05 16:00:52,701 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 26.0, whose tasks have all completed, from pool 
2021-12-05 16:00:52,701 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 26 (collect at PaidPromotionAdjustParameter.scala:146) finished in 0.107 s
2021-12-05 16:00:52,702 [main] INFO [org.apache.spark.scheduler.DAGScheduler] - Job 10 finished: collect at PaidPromotionAdjustParameter.scala:146, took 0.108723 s
2021-12-05 16:00:52,707 [main] INFO [org.apache.spark.SparkContext] - Starting job: collect at PaidPromotionAdjustParameter.scala:147
2021-12-05 16:00:52,708 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 11 (collect at PaidPromotionAdjustParameter.scala:147) with 2 output partitions
2021-12-05 16:00:52,708 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 31 (collect at PaidPromotionAdjustParameter.scala:147)
2021-12-05 16:00:52,708 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 30, ShuffleMapStage 28)
2021-12-05 16:00:52,708 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2021-12-05 16:00:52,708 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 31 (MapPartitionsRDD[32] at intersection at PaidPromotionAdjustParameter.scala:135), which has no missing parents
2021-12-05 16:00:52,709 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_20 stored as values in memory (estimated size 3.8 KB, free 1990.5 MB)
2021-12-05 16:00:52,711 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_20_piece0 stored as bytes in memory (estimated size 2.2 KB, free 1990.5 MB)
2021-12-05 16:00:52,712 [dispatcher-event-loop-2] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_20_piece0 in memory on qb:53406 (size: 2.2 KB, free: 1990.8 MB)
2021-12-05 16:00:52,712 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 20 from broadcast at DAGScheduler.scala:1039
2021-12-05 16:00:52,712 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from ResultStage 31 (MapPartitionsRDD[32] at intersection at PaidPromotionAdjustParameter.scala:135) (first 15 tasks are for partitions Vector(0, 1))
2021-12-05 16:00:52,712 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 31.0 with 2 tasks
2021-12-05 16:00:52,712 [dispatcher-event-loop-5] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 31.0 (TID 38, localhost, executor driver, partition 0, PROCESS_LOCAL, 7712 bytes)
2021-12-05 16:00:52,713 [dispatcher-event-loop-5] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 31.0 (TID 39, localhost, executor driver, partition 1, PROCESS_LOCAL, 7712 bytes)
2021-12-05 16:00:52,713 [Executor task launch worker for task 39] INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 31.0 (TID 39)
2021-12-05 16:00:52,713 [Executor task launch worker for task 38] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 31.0 (TID 38)
2021-12-05 16:00:52,714 [Executor task launch worker for task 38] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2021-12-05 16:00:52,714 [Executor task launch worker for task 39] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2021-12-05 16:00:52,714 [Executor task launch worker for task 38] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-05 16:00:52,714 [Executor task launch worker for task 39] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-05 16:00:52,716 [Executor task launch worker for task 39] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2021-12-05 16:00:52,716 [Executor task launch worker for task 38] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2021-12-05 16:00:52,716 [Executor task launch worker for task 39] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-05 16:00:52,716 [Executor task launch worker for task 38] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-05 16:00:52,725 [Executor task launch worker for task 39] INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 31.0 (TID 39). 2603 bytes result sent to driver
2021-12-05 16:00:52,725 [Executor task launch worker for task 38] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 31.0 (TID 38). 2884 bytes result sent to driver
2021-12-05 16:00:52,725 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 31.0 (TID 39) in 13 ms on localhost (executor driver) (1/2)
2021-12-05 16:00:52,725 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 31.0 (TID 38) in 13 ms on localhost (executor driver) (2/2)
2021-12-05 16:00:52,725 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 31.0, whose tasks have all completed, from pool 
2021-12-05 16:00:52,726 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 31 (collect at PaidPromotionAdjustParameter.scala:147) finished in 0.018 s
2021-12-05 16:00:52,726 [main] INFO [org.apache.spark.scheduler.DAGScheduler] - Job 11 finished: collect at PaidPromotionAdjustParameter.scala:147, took 0.019036 s
2021-12-05 16:00:52,743 [main] INFO [org.apache.spark.SparkContext] - Starting job: count at PaidPromotionAdjustParameter.scala:156
2021-12-05 16:00:52,744 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 12 (count at PaidPromotionAdjustParameter.scala:156) with 4 output partitions
2021-12-05 16:00:52,744 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 32 (count at PaidPromotionAdjustParameter.scala:156)
2021-12-05 16:00:52,744 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List()
2021-12-05 16:00:52,744 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2021-12-05 16:00:52,744 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 32 (UnionRDD[35] at union at PaidPromotionAdjustParameter.scala:154), which has no missing parents
2021-12-05 16:00:52,753 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_21 stored as values in memory (estimated size 188.3 KB, free 1990.3 MB)
2021-12-05 16:00:52,758 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_21_piece0 stored as bytes in memory (estimated size 66.3 KB, free 1990.2 MB)
2021-12-05 16:00:52,759 [dispatcher-event-loop-10] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_21_piece0 in memory on qb:53406 (size: 66.3 KB, free: 1990.7 MB)
2021-12-05 16:00:52,759 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 21 from broadcast at DAGScheduler.scala:1039
2021-12-05 16:00:52,761 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 4 missing tasks from ResultStage 32 (UnionRDD[35] at union at PaidPromotionAdjustParameter.scala:154) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
2021-12-05 16:00:52,761 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 32.0 with 4 tasks
2021-12-05 16:00:52,765 [dispatcher-event-loop-8] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 32.0 (TID 40, localhost, executor driver, partition 0, ANY, 8005 bytes)
2021-12-05 16:00:52,765 [dispatcher-event-loop-8] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 32.0 (TID 41, localhost, executor driver, partition 1, ANY, 8005 bytes)
2021-12-05 16:00:52,765 [dispatcher-event-loop-8] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 2.0 in stage 32.0 (TID 42, localhost, executor driver, partition 2, ANY, 8005 bytes)
2021-12-05 16:00:52,765 [dispatcher-event-loop-8] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 3.0 in stage 32.0 (TID 43, localhost, executor driver, partition 3, ANY, 8005 bytes)
2021-12-05 16:00:52,765 [Executor task launch worker for task 40] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 32.0 (TID 40)
2021-12-05 16:00:52,765 [Executor task launch worker for task 42] INFO [org.apache.spark.executor.Executor] - Running task 2.0 in stage 32.0 (TID 42)
2021-12-05 16:00:52,765 [Executor task launch worker for task 43] INFO [org.apache.spark.executor.Executor] - Running task 3.0 in stage 32.0 (TID 43)
2021-12-05 16:00:52,765 [Executor task launch worker for task 41] INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 32.0 (TID 41)
2021-12-05 16:00:52,769 [Executor task launch worker for task 43] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/order_data.bcp:3442194+3442195
2021-12-05 16:00:52,769 [Executor task launch worker for task 40] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/order_data.bcp:0+3442194
2021-12-05 16:00:52,769 [Executor task launch worker for task 42] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/order_data.bcp:0+3442194
2021-12-05 16:00:52,769 [Executor task launch worker for task 41] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/order_data.bcp:3442194+3442195
2021-12-05 16:00:53,828 [Executor task launch worker for task 40] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 32.0 (TID 40). 711 bytes result sent to driver
2021-12-05 16:00:53,828 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 32.0 (TID 40) in 1065 ms on localhost (executor driver) (1/4)
2021-12-05 16:00:54,026 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 471
2021-12-05 16:00:54,026 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 494
2021-12-05 16:00:54,026 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 456
2021-12-05 16:00:54,027 [dispatcher-event-loop-3] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_19_piece0 on qb:53406 in memory (size: 2.2 KB, free: 1990.7 MB)
2021-12-05 16:00:54,027 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 482
2021-12-05 16:00:54,027 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 475
2021-12-05 16:00:54,027 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 472
2021-12-05 16:00:54,027 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 457
2021-12-05 16:00:54,027 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 455
2021-12-05 16:00:54,027 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 498
2021-12-05 16:00:54,027 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 481
2021-12-05 16:00:54,027 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 460
2021-12-05 16:00:54,027 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 464
2021-12-05 16:00:54,027 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 465
2021-12-05 16:00:54,027 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 468
2021-12-05 16:00:54,027 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 474
2021-12-05 16:00:54,027 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 485
2021-12-05 16:00:54,027 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 473
2021-12-05 16:00:54,027 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 479
2021-12-05 16:00:54,027 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 476
2021-12-05 16:00:54,027 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 463
2021-12-05 16:00:54,027 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 490
2021-12-05 16:00:54,027 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 495
2021-12-05 16:00:54,027 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 469
2021-12-05 16:00:54,027 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 458
2021-12-05 16:00:54,027 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 496
2021-12-05 16:00:54,027 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 461
2021-12-05 16:00:54,027 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 497
2021-12-05 16:00:54,027 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 489
2021-12-05 16:00:54,027 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 492
2021-12-05 16:00:54,027 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 493
2021-12-05 16:00:54,027 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 459
2021-12-05 16:00:54,027 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 467
2021-12-05 16:00:54,027 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 478
2021-12-05 16:00:54,027 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 480
2021-12-05 16:00:54,027 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 484
2021-12-05 16:00:54,027 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 499
2021-12-05 16:00:54,027 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 454
2021-12-05 16:00:54,027 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 488
2021-12-05 16:00:54,027 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 466
2021-12-05 16:00:54,027 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 462
2021-12-05 16:00:54,027 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 450
2021-12-05 16:00:54,027 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 453
2021-12-05 16:00:54,027 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 470
2021-12-05 16:00:54,027 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 451
2021-12-05 16:00:54,027 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 487
2021-12-05 16:00:54,027 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 491
2021-12-05 16:00:54,027 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 483
2021-12-05 16:00:54,028 [dispatcher-event-loop-10] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_20_piece0 on qb:53406 in memory (size: 2.2 KB, free: 1990.7 MB)
2021-12-05 16:00:54,028 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 486
2021-12-05 16:00:54,028 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 452
2021-12-05 16:00:54,028 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 477
2021-12-05 16:00:54,105 [Executor task launch worker for task 42] INFO [org.apache.spark.executor.Executor] - Finished task 2.0 in stage 32.0 (TID 42). 754 bytes result sent to driver
2021-12-05 16:00:54,107 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 2.0 in stage 32.0 (TID 42) in 1342 ms on localhost (executor driver) (2/4)
2021-12-05 16:00:54,147 [Executor task launch worker for task 43] INFO [org.apache.spark.executor.Executor] - Finished task 3.0 in stage 32.0 (TID 43). 754 bytes result sent to driver
2021-12-05 16:00:54,148 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 3.0 in stage 32.0 (TID 43) in 1383 ms on localhost (executor driver) (3/4)
2021-12-05 16:00:54,297 [Executor task launch worker for task 41] INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 32.0 (TID 41). 754 bytes result sent to driver
2021-12-05 16:00:54,297 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 32.0 (TID 41) in 1532 ms on localhost (executor driver) (4/4)
2021-12-05 16:00:54,297 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 32.0, whose tasks have all completed, from pool 
2021-12-05 16:00:54,298 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 32 (count at PaidPromotionAdjustParameter.scala:156) finished in 1.553 s
2021-12-05 16:00:54,298 [main] INFO [org.apache.spark.scheduler.DAGScheduler] - Job 12 finished: count at PaidPromotionAdjustParameter.scala:156, took 1.555259 s
2021-12-05 16:00:54,298 [main] INFO [PaidPromotion$] - 最终训练集数量：100999
2021-12-05 16:00:54,300 [main] INFO [org.apache.spark.SparkContext] - Starting job: count at PaidPromotionAdjustParameter.scala:157
2021-12-05 16:00:54,300 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 13 (count at PaidPromotionAdjustParameter.scala:157) with 2 output partitions
2021-12-05 16:00:54,300 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 33 (count at PaidPromotionAdjustParameter.scala:157)
2021-12-05 16:00:54,300 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List()
2021-12-05 16:00:54,300 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2021-12-05 16:00:54,300 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 33 (MapPartitionsRDD[33] at filter at PaidPromotionAdjustParameter.scala:150), which has no missing parents
2021-12-05 16:00:54,302 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_22 stored as values in memory (estimated size 187.7 KB, free 1990.0 MB)
2021-12-05 16:00:54,304 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_22_piece0 stored as bytes in memory (estimated size 66.0 KB, free 1990.0 MB)
2021-12-05 16:00:54,304 [dispatcher-event-loop-1] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_22_piece0 in memory on qb:53406 (size: 66.0 KB, free: 1990.6 MB)
2021-12-05 16:00:54,304 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 22 from broadcast at DAGScheduler.scala:1039
2021-12-05 16:00:54,305 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from ResultStage 33 (MapPartitionsRDD[33] at filter at PaidPromotionAdjustParameter.scala:150) (first 15 tasks are for partitions Vector(0, 1))
2021-12-05 16:00:54,305 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 33.0 with 2 tasks
2021-12-05 16:00:54,306 [dispatcher-event-loop-4] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 33.0 (TID 44, localhost, executor driver, partition 0, ANY, 7896 bytes)
2021-12-05 16:00:54,306 [dispatcher-event-loop-4] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 33.0 (TID 45, localhost, executor driver, partition 1, ANY, 7896 bytes)
2021-12-05 16:00:54,306 [Executor task launch worker for task 45] INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 33.0 (TID 45)
2021-12-05 16:00:54,306 [Executor task launch worker for task 44] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 33.0 (TID 44)
2021-12-05 16:00:54,309 [Executor task launch worker for task 44] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/order_data.bcp:0+3442194
2021-12-05 16:00:54,309 [Executor task launch worker for task 45] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/order_data.bcp:3442194+3442195
2021-12-05 16:00:55,414 [Executor task launch worker for task 45] INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 33.0 (TID 45). 710 bytes result sent to driver
2021-12-05 16:00:55,414 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 33.0 (TID 45) in 1108 ms on localhost (executor driver) (1/2)
2021-12-05 16:00:55,493 [Executor task launch worker for task 44] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 33.0 (TID 44). 710 bytes result sent to driver
2021-12-05 16:00:55,493 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 33.0 (TID 44) in 1188 ms on localhost (executor driver) (2/2)
2021-12-05 16:00:55,493 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 33.0, whose tasks have all completed, from pool 
2021-12-05 16:00:55,493 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 33 (count at PaidPromotionAdjustParameter.scala:157) finished in 1.193 s
2021-12-05 16:00:55,493 [main] INFO [org.apache.spark.scheduler.DAGScheduler] - Job 13 finished: count at PaidPromotionAdjustParameter.scala:157, took 1.193778 s
2021-12-05 16:00:55,493 [main] INFO [PaidPromotion$] - 最终验证集数量：6295
2021-12-05 16:00:55,532 [main] INFO [PaidPromotion$] - -----------------------------------
2021-12-05 16:00:55,534 [main] INFO [org.apache.spark.SparkContext] - Starting job: count at PaidPromotionAdjustParameter.scala:169
2021-12-05 16:00:55,534 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 37 (distinct at PaidPromotionAdjustParameter.scala:160)
2021-12-05 16:00:55,534 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 14 (count at PaidPromotionAdjustParameter.scala:169) with 4 output partitions
2021-12-05 16:00:55,534 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 35 (count at PaidPromotionAdjustParameter.scala:169)
2021-12-05 16:00:55,534 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 34)
2021-12-05 16:00:55,534 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List(ShuffleMapStage 34)
2021-12-05 16:00:55,535 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ShuffleMapStage 34 (MapPartitionsRDD[37] at distinct at PaidPromotionAdjustParameter.scala:160), which has no missing parents
2021-12-05 16:00:55,536 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_23 stored as values in memory (estimated size 189.9 KB, free 1989.8 MB)
2021-12-05 16:00:55,538 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_23_piece0 stored as bytes in memory (estimated size 67.2 KB, free 1989.7 MB)
2021-12-05 16:00:55,539 [dispatcher-event-loop-9] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_23_piece0 in memory on qb:53406 (size: 67.2 KB, free: 1990.6 MB)
2021-12-05 16:00:55,539 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 23 from broadcast at DAGScheduler.scala:1039
2021-12-05 16:00:55,539 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 4 missing tasks from ShuffleMapStage 34 (MapPartitionsRDD[37] at distinct at PaidPromotionAdjustParameter.scala:160) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
2021-12-05 16:00:55,539 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 34.0 with 4 tasks
2021-12-05 16:00:55,540 [dispatcher-event-loop-7] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 34.0 (TID 46, localhost, executor driver, partition 0, ANY, 7994 bytes)
2021-12-05 16:00:55,541 [dispatcher-event-loop-7] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 34.0 (TID 47, localhost, executor driver, partition 1, ANY, 7994 bytes)
2021-12-05 16:00:55,541 [dispatcher-event-loop-7] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 2.0 in stage 34.0 (TID 48, localhost, executor driver, partition 2, ANY, 7994 bytes)
2021-12-05 16:00:55,541 [dispatcher-event-loop-7] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 3.0 in stage 34.0 (TID 49, localhost, executor driver, partition 3, ANY, 7994 bytes)
2021-12-05 16:00:55,541 [Executor task launch worker for task 46] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 34.0 (TID 46)
2021-12-05 16:00:55,541 [Executor task launch worker for task 48] INFO [org.apache.spark.executor.Executor] - Running task 2.0 in stage 34.0 (TID 48)
2021-12-05 16:00:55,541 [Executor task launch worker for task 49] INFO [org.apache.spark.executor.Executor] - Running task 3.0 in stage 34.0 (TID 49)
2021-12-05 16:00:55,541 [Executor task launch worker for task 47] INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 34.0 (TID 47)
2021-12-05 16:00:55,544 [Executor task launch worker for task 48] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/order_data.bcp:0+3442194
2021-12-05 16:00:55,544 [Executor task launch worker for task 46] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/order_data.bcp:0+3442194
2021-12-05 16:00:55,544 [Executor task launch worker for task 47] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/order_data.bcp:3442194+3442195
2021-12-05 16:00:55,544 [Executor task launch worker for task 49] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/order_data.bcp:3442194+3442195
2021-12-05 16:00:56,121 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 530
2021-12-05 16:00:56,122 [dispatcher-event-loop-6] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_21_piece0 on qb:53406 in memory (size: 66.3 KB, free: 1990.6 MB)
2021-12-05 16:00:56,122 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 532
2021-12-05 16:00:56,122 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 546
2021-12-05 16:00:56,122 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 538
2021-12-05 16:00:56,122 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 536
2021-12-05 16:00:56,122 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 515
2021-12-05 16:00:56,122 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 516
2021-12-05 16:00:56,122 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 513
2021-12-05 16:00:56,122 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 528
2021-12-05 16:00:56,122 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 527
2021-12-05 16:00:56,122 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 523
2021-12-05 16:00:56,123 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 508
2021-12-05 16:00:56,123 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 510
2021-12-05 16:00:56,123 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 540
2021-12-05 16:00:56,123 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 507
2021-12-05 16:00:56,123 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 526
2021-12-05 16:00:56,123 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 520
2021-12-05 16:00:56,123 [dispatcher-event-loop-3] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_22_piece0 on qb:53406 in memory (size: 66.0 KB, free: 1990.7 MB)
2021-12-05 16:00:56,123 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 539
2021-12-05 16:00:56,124 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 549
2021-12-05 16:00:56,124 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 547
2021-12-05 16:00:56,124 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 548
2021-12-05 16:00:56,124 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 541
2021-12-05 16:00:56,124 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 512
2021-12-05 16:00:56,124 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 505
2021-12-05 16:00:56,124 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 506
2021-12-05 16:00:56,124 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 537
2021-12-05 16:00:56,124 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 524
2021-12-05 16:00:56,124 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 544
2021-12-05 16:00:56,124 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 533
2021-12-05 16:00:56,124 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 529
2021-12-05 16:00:56,124 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 519
2021-12-05 16:00:56,124 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 511
2021-12-05 16:00:56,124 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 522
2021-12-05 16:00:56,124 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 531
2021-12-05 16:00:56,124 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 504
2021-12-05 16:00:56,124 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 500
2021-12-05 16:00:56,124 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 503
2021-12-05 16:00:56,124 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 521
2021-12-05 16:00:56,124 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 525
2021-12-05 16:00:56,124 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 535
2021-12-05 16:00:56,124 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 517
2021-12-05 16:00:56,124 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 514
2021-12-05 16:00:56,124 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 542
2021-12-05 16:00:56,124 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 534
2021-12-05 16:00:56,124 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 502
2021-12-05 16:00:56,124 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 543
2021-12-05 16:00:56,124 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 509
2021-12-05 16:00:56,124 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 518
2021-12-05 16:00:56,124 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 501
2021-12-05 16:00:56,124 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 545
2021-12-05 16:00:56,315 [Executor task launch worker for task 48] INFO [org.apache.spark.executor.Executor] - Finished task 2.0 in stage 34.0 (TID 48). 1077 bytes result sent to driver
2021-12-05 16:00:56,316 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 2.0 in stage 34.0 (TID 48) in 774 ms on localhost (executor driver) (1/4)
2021-12-05 16:00:56,628 [Executor task launch worker for task 47] INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 34.0 (TID 47). 1077 bytes result sent to driver
2021-12-05 16:00:56,629 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 34.0 (TID 47) in 1089 ms on localhost (executor driver) (2/4)
2021-12-05 16:00:57,348 [Executor task launch worker for task 46] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 34.0 (TID 46). 1077 bytes result sent to driver
2021-12-05 16:00:57,348 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 34.0 (TID 46) in 1808 ms on localhost (executor driver) (3/4)
2021-12-05 16:00:58,502 [Executor task launch worker for task 49] INFO [org.apache.spark.executor.Executor] - Finished task 3.0 in stage 34.0 (TID 49). 1077 bytes result sent to driver
2021-12-05 16:00:58,502 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 3.0 in stage 34.0 (TID 49) in 2961 ms on localhost (executor driver) (4/4)
2021-12-05 16:00:58,502 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 34.0, whose tasks have all completed, from pool 
2021-12-05 16:00:58,502 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ShuffleMapStage 34 (distinct at PaidPromotionAdjustParameter.scala:160) finished in 2.967 s
2021-12-05 16:00:58,502 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - looking for newly runnable stages
2021-12-05 16:00:58,502 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - running: Set()
2021-12-05 16:00:58,502 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - waiting: Set(ResultStage 35)
2021-12-05 16:00:58,502 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - failed: Set()
2021-12-05 16:00:58,503 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 35 (MapPartitionsRDD[39] at distinct at PaidPromotionAdjustParameter.scala:160), which has no missing parents
2021-12-05 16:00:58,503 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_24 stored as values in memory (estimated size 3.7 KB, free 1990.2 MB)
2021-12-05 16:00:58,505 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_24_piece0 stored as bytes in memory (estimated size 2.2 KB, free 1990.2 MB)
2021-12-05 16:00:58,505 [dispatcher-event-loop-11] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_24_piece0 in memory on qb:53406 (size: 2.2 KB, free: 1990.7 MB)
2021-12-05 16:00:58,506 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 24 from broadcast at DAGScheduler.scala:1039
2021-12-05 16:00:58,506 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 4 missing tasks from ResultStage 35 (MapPartitionsRDD[39] at distinct at PaidPromotionAdjustParameter.scala:160) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
2021-12-05 16:00:58,506 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 35.0 with 4 tasks
2021-12-05 16:00:58,506 [dispatcher-event-loop-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 35.0 (TID 50, localhost, executor driver, partition 0, ANY, 7649 bytes)
2021-12-05 16:00:58,506 [dispatcher-event-loop-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 35.0 (TID 51, localhost, executor driver, partition 1, ANY, 7649 bytes)
2021-12-05 16:00:58,506 [dispatcher-event-loop-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 2.0 in stage 35.0 (TID 52, localhost, executor driver, partition 2, ANY, 7649 bytes)
2021-12-05 16:00:58,506 [dispatcher-event-loop-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 3.0 in stage 35.0 (TID 53, localhost, executor driver, partition 3, ANY, 7649 bytes)
2021-12-05 16:00:58,507 [Executor task launch worker for task 51] INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 35.0 (TID 51)
2021-12-05 16:00:58,507 [Executor task launch worker for task 53] INFO [org.apache.spark.executor.Executor] - Running task 3.0 in stage 35.0 (TID 53)
2021-12-05 16:00:58,507 [Executor task launch worker for task 50] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 35.0 (TID 50)
2021-12-05 16:00:58,507 [Executor task launch worker for task 52] INFO [org.apache.spark.executor.Executor] - Running task 2.0 in stage 35.0 (TID 52)
2021-12-05 16:00:58,508 [Executor task launch worker for task 50] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 4 non-empty blocks out of 4 blocks
2021-12-05 16:00:58,508 [Executor task launch worker for task 51] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 4 non-empty blocks out of 4 blocks
2021-12-05 16:00:58,508 [Executor task launch worker for task 51] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-05 16:00:58,508 [Executor task launch worker for task 50] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-05 16:00:58,508 [Executor task launch worker for task 52] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 4 non-empty blocks out of 4 blocks
2021-12-05 16:00:58,508 [Executor task launch worker for task 52] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-05 16:00:58,508 [Executor task launch worker for task 53] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 4 non-empty blocks out of 4 blocks
2021-12-05 16:00:58,508 [Executor task launch worker for task 53] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-05 16:00:58,557 [Executor task launch worker for task 51] INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 35.0 (TID 51). 1012 bytes result sent to driver
2021-12-05 16:00:58,557 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 35.0 (TID 51) in 51 ms on localhost (executor driver) (1/4)
2021-12-05 16:00:58,558 [Executor task launch worker for task 53] INFO [org.apache.spark.executor.Executor] - Finished task 3.0 in stage 35.0 (TID 53). 1055 bytes result sent to driver
2021-12-05 16:00:58,559 [Executor task launch worker for task 50] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 35.0 (TID 50). 1012 bytes result sent to driver
2021-12-05 16:00:58,559 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 3.0 in stage 35.0 (TID 53) in 53 ms on localhost (executor driver) (2/4)
2021-12-05 16:00:58,559 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 35.0 (TID 50) in 53 ms on localhost (executor driver) (3/4)
2021-12-05 16:00:58,559 [Executor task launch worker for task 52] INFO [org.apache.spark.executor.Executor] - Finished task 2.0 in stage 35.0 (TID 52). 1055 bytes result sent to driver
2021-12-05 16:00:58,560 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 2.0 in stage 35.0 (TID 52) in 54 ms on localhost (executor driver) (4/4)
2021-12-05 16:00:58,560 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 35.0, whose tasks have all completed, from pool 
2021-12-05 16:00:58,560 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 35 (count at PaidPromotionAdjustParameter.scala:169) finished in 0.057 s
2021-12-05 16:00:58,560 [main] INFO [org.apache.spark.scheduler.DAGScheduler] - Job 14 finished: count at PaidPromotionAdjustParameter.scala:169, took 3.026655 s
2021-12-05 16:00:58,561 [main] INFO [PaidPromotion$] - 最终训练集用户数 = 95323
2021-12-05 16:00:58,565 [main] INFO [org.apache.spark.SparkContext] - Starting job: count at PaidPromotionAdjustParameter.scala:170
2021-12-05 16:00:58,565 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 41 (distinct at PaidPromotionAdjustParameter.scala:161)
2021-12-05 16:00:58,565 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 15 (count at PaidPromotionAdjustParameter.scala:170) with 2 output partitions
2021-12-05 16:00:58,565 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 37 (count at PaidPromotionAdjustParameter.scala:170)
2021-12-05 16:00:58,565 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 36)
2021-12-05 16:00:58,566 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List(ShuffleMapStage 36)
2021-12-05 16:00:58,566 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ShuffleMapStage 36 (MapPartitionsRDD[41] at distinct at PaidPromotionAdjustParameter.scala:161), which has no missing parents
2021-12-05 16:00:58,567 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_25 stored as values in memory (estimated size 189.3 KB, free 1990.0 MB)
2021-12-05 16:00:58,569 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_25_piece0 stored as bytes in memory (estimated size 66.9 KB, free 1990.0 MB)
2021-12-05 16:00:58,569 [dispatcher-event-loop-10] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_25_piece0 in memory on qb:53406 (size: 66.9 KB, free: 1990.6 MB)
2021-12-05 16:00:58,570 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 25 from broadcast at DAGScheduler.scala:1039
2021-12-05 16:00:58,570 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from ShuffleMapStage 36 (MapPartitionsRDD[41] at distinct at PaidPromotionAdjustParameter.scala:161) (first 15 tasks are for partitions Vector(0, 1))
2021-12-05 16:00:58,570 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 36.0 with 2 tasks
2021-12-05 16:00:58,570 [dispatcher-event-loop-8] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 36.0 (TID 54, localhost, executor driver, partition 0, ANY, 7885 bytes)
2021-12-05 16:00:58,570 [dispatcher-event-loop-8] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 36.0 (TID 55, localhost, executor driver, partition 1, ANY, 7885 bytes)
2021-12-05 16:00:58,570 [Executor task launch worker for task 55] INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 36.0 (TID 55)
2021-12-05 16:00:58,570 [Executor task launch worker for task 54] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 36.0 (TID 54)
2021-12-05 16:00:58,573 [Executor task launch worker for task 55] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/order_data.bcp:3442194+3442195
2021-12-05 16:00:58,573 [Executor task launch worker for task 54] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/order_data.bcp:0+3442194
2021-12-05 16:00:59,021 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 595
2021-12-05 16:00:59,021 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 565
2021-12-05 16:00:59,022 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 586
2021-12-05 16:00:59,022 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 598
2021-12-05 16:00:59,022 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 560
2021-12-05 16:00:59,022 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 559
2021-12-05 16:00:59,022 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 563
2021-12-05 16:00:59,022 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 587
2021-12-05 16:00:59,022 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 569
2021-12-05 16:00:59,022 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 574
2021-12-05 16:00:59,022 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 594
2021-12-05 16:00:59,022 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 550
2021-12-05 16:00:59,022 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 575
2021-12-05 16:00:59,022 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 592
2021-12-05 16:00:59,022 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 591
2021-12-05 16:00:59,022 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 582
2021-12-05 16:00:59,022 [dispatcher-event-loop-6] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_23_piece0 on qb:53406 in memory (size: 67.2 KB, free: 1990.7 MB)
2021-12-05 16:00:59,022 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 596
2021-12-05 16:00:59,022 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 579
2021-12-05 16:00:59,023 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 584
2021-12-05 16:00:59,023 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 597
2021-12-05 16:00:59,023 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 562
2021-12-05 16:00:59,023 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 564
2021-12-05 16:00:59,023 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 581
2021-12-05 16:00:59,023 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 599
2021-12-05 16:00:59,023 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 558
2021-12-05 16:00:59,023 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 566
2021-12-05 16:00:59,023 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 551
2021-12-05 16:00:59,023 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 590
2021-12-05 16:00:59,023 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 567
2021-12-05 16:00:59,023 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 571
2021-12-05 16:00:59,023 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 557
2021-12-05 16:00:59,023 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 555
2021-12-05 16:00:59,023 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 561
2021-12-05 16:00:59,023 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 589
2021-12-05 16:00:59,023 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 583
2021-12-05 16:00:59,023 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 585
2021-12-05 16:00:59,023 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 553
2021-12-05 16:00:59,023 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 588
2021-12-05 16:00:59,023 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 552
2021-12-05 16:00:59,023 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 593
2021-12-05 16:00:59,023 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 573
2021-12-05 16:00:59,023 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 580
2021-12-05 16:00:59,023 [dispatcher-event-loop-3] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_24_piece0 on qb:53406 in memory (size: 2.2 KB, free: 1990.7 MB)
2021-12-05 16:00:59,023 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 578
2021-12-05 16:00:59,023 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 568
2021-12-05 16:00:59,023 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 554
2021-12-05 16:00:59,023 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 576
2021-12-05 16:00:59,023 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 570
2021-12-05 16:00:59,023 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 572
2021-12-05 16:00:59,023 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 556
2021-12-05 16:00:59,024 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 577
2021-12-05 16:00:59,595 [Executor task launch worker for task 54] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 36.0 (TID 54). 1032 bytes result sent to driver
2021-12-05 16:00:59,596 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 36.0 (TID 54) in 1026 ms on localhost (executor driver) (1/2)
2021-12-05 16:00:59,953 [Executor task launch worker for task 55] INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 36.0 (TID 55). 1032 bytes result sent to driver
2021-12-05 16:00:59,953 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 36.0 (TID 55) in 1383 ms on localhost (executor driver) (2/2)
2021-12-05 16:00:59,953 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 36.0, whose tasks have all completed, from pool 
2021-12-05 16:00:59,954 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ShuffleMapStage 36 (distinct at PaidPromotionAdjustParameter.scala:161) finished in 1.388 s
2021-12-05 16:00:59,954 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - looking for newly runnable stages
2021-12-05 16:00:59,954 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - running: Set()
2021-12-05 16:00:59,954 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - waiting: Set(ResultStage 37)
2021-12-05 16:00:59,954 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - failed: Set()
2021-12-05 16:00:59,954 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 37 (MapPartitionsRDD[43] at distinct at PaidPromotionAdjustParameter.scala:161), which has no missing parents
2021-12-05 16:00:59,955 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_26 stored as values in memory (estimated size 3.7 KB, free 1990.2 MB)
2021-12-05 16:00:59,956 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_26_piece0 stored as bytes in memory (estimated size 2.2 KB, free 1990.2 MB)
2021-12-05 16:00:59,957 [dispatcher-event-loop-10] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_26_piece0 in memory on qb:53406 (size: 2.2 KB, free: 1990.7 MB)
2021-12-05 16:00:59,957 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 26 from broadcast at DAGScheduler.scala:1039
2021-12-05 16:00:59,957 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from ResultStage 37 (MapPartitionsRDD[43] at distinct at PaidPromotionAdjustParameter.scala:161) (first 15 tasks are for partitions Vector(0, 1))
2021-12-05 16:00:59,957 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 37.0 with 2 tasks
2021-12-05 16:00:59,958 [dispatcher-event-loop-8] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 37.0 (TID 56, localhost, executor driver, partition 0, ANY, 7649 bytes)
2021-12-05 16:00:59,958 [dispatcher-event-loop-8] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 37.0 (TID 57, localhost, executor driver, partition 1, ANY, 7649 bytes)
2021-12-05 16:00:59,958 [Executor task launch worker for task 56] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 37.0 (TID 56)
2021-12-05 16:00:59,958 [Executor task launch worker for task 57] INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 37.0 (TID 57)
2021-12-05 16:00:59,959 [Executor task launch worker for task 57] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 2 non-empty blocks out of 2 blocks
2021-12-05 16:00:59,959 [Executor task launch worker for task 56] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 2 non-empty blocks out of 2 blocks
2021-12-05 16:00:59,959 [Executor task launch worker for task 57] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-05 16:00:59,959 [Executor task launch worker for task 56] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-05 16:00:59,982 [Executor task launch worker for task 57] INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 37.0 (TID 57). 1054 bytes result sent to driver
2021-12-05 16:00:59,982 [Executor task launch worker for task 56] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 37.0 (TID 56). 1054 bytes result sent to driver
2021-12-05 16:00:59,982 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 37.0 (TID 57) in 24 ms on localhost (executor driver) (1/2)
2021-12-05 16:00:59,982 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 37.0 (TID 56) in 25 ms on localhost (executor driver) (2/2)
2021-12-05 16:00:59,982 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 37.0, whose tasks have all completed, from pool 
2021-12-05 16:00:59,982 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 37 (count at PaidPromotionAdjustParameter.scala:170) finished in 0.028 s
2021-12-05 16:00:59,983 [main] INFO [org.apache.spark.scheduler.DAGScheduler] - Job 15 finished: count at PaidPromotionAdjustParameter.scala:170, took 1.417699 s
2021-12-05 16:00:59,983 [main] INFO [PaidPromotion$] - 最终验证集用户数 = 5278
2021-12-05 16:00:59,985 [main] INFO [org.apache.spark.SparkContext] - Starting job: count at PaidPromotionAdjustParameter.scala:171
2021-12-05 16:00:59,985 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 44 (intersection at PaidPromotionAdjustParameter.scala:162)
2021-12-05 16:00:59,986 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 45 (intersection at PaidPromotionAdjustParameter.scala:162)
2021-12-05 16:00:59,986 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 16 (count at PaidPromotionAdjustParameter.scala:171) with 4 output partitions
2021-12-05 16:00:59,986 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 42 (count at PaidPromotionAdjustParameter.scala:171)
2021-12-05 16:00:59,986 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 39, ShuffleMapStage 41)
2021-12-05 16:00:59,986 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List(ShuffleMapStage 39, ShuffleMapStage 41)
2021-12-05 16:00:59,986 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ShuffleMapStage 39 (MapPartitionsRDD[44] at intersection at PaidPromotionAdjustParameter.scala:162), which has no missing parents
2021-12-05 16:00:59,987 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_27 stored as values in memory (estimated size 4.0 KB, free 1990.2 MB)
2021-12-05 16:00:59,988 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_27_piece0 stored as bytes in memory (estimated size 2.3 KB, free 1990.2 MB)
2021-12-05 16:00:59,989 [dispatcher-event-loop-6] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_27_piece0 in memory on qb:53406 (size: 2.3 KB, free: 1990.7 MB)
2021-12-05 16:00:59,989 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 27 from broadcast at DAGScheduler.scala:1039
2021-12-05 16:00:59,989 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 4 missing tasks from ShuffleMapStage 39 (MapPartitionsRDD[44] at intersection at PaidPromotionAdjustParameter.scala:162) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
2021-12-05 16:00:59,989 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 39.0 with 4 tasks
2021-12-05 16:00:59,989 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ShuffleMapStage 41 (MapPartitionsRDD[45] at intersection at PaidPromotionAdjustParameter.scala:162), which has no missing parents
2021-12-05 16:00:59,989 [dispatcher-event-loop-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 39.0 (TID 58, localhost, executor driver, partition 0, ANY, 7638 bytes)
2021-12-05 16:00:59,989 [dispatcher-event-loop-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 39.0 (TID 59, localhost, executor driver, partition 1, ANY, 7638 bytes)
2021-12-05 16:00:59,989 [dispatcher-event-loop-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 2.0 in stage 39.0 (TID 60, localhost, executor driver, partition 2, ANY, 7638 bytes)
2021-12-05 16:00:59,990 [dispatcher-event-loop-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 3.0 in stage 39.0 (TID 61, localhost, executor driver, partition 3, ANY, 7638 bytes)
2021-12-05 16:00:59,990 [Executor task launch worker for task 58] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 39.0 (TID 58)
2021-12-05 16:00:59,990 [Executor task launch worker for task 61] INFO [org.apache.spark.executor.Executor] - Running task 3.0 in stage 39.0 (TID 61)
2021-12-05 16:00:59,990 [Executor task launch worker for task 60] INFO [org.apache.spark.executor.Executor] - Running task 2.0 in stage 39.0 (TID 60)
2021-12-05 16:00:59,990 [Executor task launch worker for task 59] INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 39.0 (TID 59)
2021-12-05 16:00:59,990 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_28 stored as values in memory (estimated size 4.0 KB, free 1990.2 MB)
2021-12-05 16:00:59,991 [Executor task launch worker for task 58] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 4 non-empty blocks out of 4 blocks
2021-12-05 16:00:59,991 [Executor task launch worker for task 59] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 4 non-empty blocks out of 4 blocks
2021-12-05 16:00:59,991 [Executor task launch worker for task 58] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-05 16:00:59,991 [Executor task launch worker for task 60] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 4 non-empty blocks out of 4 blocks
2021-12-05 16:00:59,991 [Executor task launch worker for task 59] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-05 16:00:59,991 [Executor task launch worker for task 61] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 4 non-empty blocks out of 4 blocks
2021-12-05 16:00:59,991 [Executor task launch worker for task 60] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-05 16:00:59,991 [Executor task launch worker for task 61] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-05 16:00:59,992 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_28_piece0 stored as bytes in memory (estimated size 2.3 KB, free 1990.2 MB)
2021-12-05 16:00:59,993 [dispatcher-event-loop-10] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_28_piece0 in memory on qb:53406 (size: 2.3 KB, free: 1990.7 MB)
2021-12-05 16:00:59,993 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 28 from broadcast at DAGScheduler.scala:1039
2021-12-05 16:00:59,994 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from ShuffleMapStage 41 (MapPartitionsRDD[45] at intersection at PaidPromotionAdjustParameter.scala:162) (first 15 tasks are for partitions Vector(0, 1))
2021-12-05 16:00:59,994 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 41.0 with 2 tasks
2021-12-05 16:00:59,996 [dispatcher-event-loop-8] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 41.0 (TID 62, localhost, executor driver, partition 0, ANY, 7638 bytes)
2021-12-05 16:00:59,996 [dispatcher-event-loop-8] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 41.0 (TID 63, localhost, executor driver, partition 1, ANY, 7638 bytes)
2021-12-05 16:01:00,003 [Executor task launch worker for task 62] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 41.0 (TID 62)
2021-12-05 16:01:00,003 [Executor task launch worker for task 63] INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 41.0 (TID 63)
2021-12-05 16:01:00,004 [Executor task launch worker for task 63] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 2 non-empty blocks out of 2 blocks
2021-12-05 16:01:00,004 [Executor task launch worker for task 62] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 2 non-empty blocks out of 2 blocks
2021-12-05 16:01:00,004 [Executor task launch worker for task 63] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-05 16:01:00,004 [Executor task launch worker for task 62] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-05 16:01:00,045 [Executor task launch worker for task 62] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 41.0 (TID 62). 1163 bytes result sent to driver
2021-12-05 16:01:00,046 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 41.0 (TID 62) in 51 ms on localhost (executor driver) (1/2)
2021-12-05 16:01:00,049 [Executor task launch worker for task 63] INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 41.0 (TID 63). 1163 bytes result sent to driver
2021-12-05 16:01:00,049 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 41.0 (TID 63) in 53 ms on localhost (executor driver) (2/2)
2021-12-05 16:01:00,049 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 41.0, whose tasks have all completed, from pool 
2021-12-05 16:01:00,049 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ShuffleMapStage 41 (intersection at PaidPromotionAdjustParameter.scala:162) finished in 0.060 s
2021-12-05 16:01:00,049 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - looking for newly runnable stages
2021-12-05 16:01:00,049 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - running: Set(ShuffleMapStage 39)
2021-12-05 16:01:00,049 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - waiting: Set(ResultStage 42)
2021-12-05 16:01:00,049 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - failed: Set()
2021-12-05 16:01:00,065 [Executor task launch worker for task 58] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 39.0 (TID 58). 1163 bytes result sent to driver
2021-12-05 16:01:00,065 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 39.0 (TID 58) in 76 ms on localhost (executor driver) (1/4)
2021-12-05 16:01:00,066 [Executor task launch worker for task 61] INFO [org.apache.spark.executor.Executor] - Finished task 3.0 in stage 39.0 (TID 61). 1163 bytes result sent to driver
2021-12-05 16:01:00,066 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 3.0 in stage 39.0 (TID 61) in 77 ms on localhost (executor driver) (2/4)
2021-12-05 16:01:00,067 [Executor task launch worker for task 60] INFO [org.apache.spark.executor.Executor] - Finished task 2.0 in stage 39.0 (TID 60). 1163 bytes result sent to driver
2021-12-05 16:01:00,067 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 2.0 in stage 39.0 (TID 60) in 78 ms on localhost (executor driver) (3/4)
2021-12-05 16:01:00,071 [Executor task launch worker for task 59] INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 39.0 (TID 59). 1163 bytes result sent to driver
2021-12-05 16:01:00,072 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 39.0 (TID 59) in 83 ms on localhost (executor driver) (4/4)
2021-12-05 16:01:00,072 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 39.0, whose tasks have all completed, from pool 
2021-12-05 16:01:00,072 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ShuffleMapStage 39 (intersection at PaidPromotionAdjustParameter.scala:162) finished in 0.086 s
2021-12-05 16:01:00,072 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - looking for newly runnable stages
2021-12-05 16:01:00,072 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - running: Set()
2021-12-05 16:01:00,072 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - waiting: Set(ResultStage 42)
2021-12-05 16:01:00,072 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - failed: Set()
2021-12-05 16:01:00,072 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 42 (MapPartitionsRDD[49] at intersection at PaidPromotionAdjustParameter.scala:162), which has no missing parents
2021-12-05 16:01:00,073 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_29 stored as values in memory (estimated size 3.6 KB, free 1990.2 MB)
2021-12-05 16:01:00,076 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_29_piece0 stored as bytes in memory (estimated size 2.1 KB, free 1990.2 MB)
2021-12-05 16:01:00,077 [dispatcher-event-loop-9] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_29_piece0 in memory on qb:53406 (size: 2.1 KB, free: 1990.7 MB)
2021-12-05 16:01:00,077 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 29 from broadcast at DAGScheduler.scala:1039
2021-12-05 16:01:00,078 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 4 missing tasks from ResultStage 42 (MapPartitionsRDD[49] at intersection at PaidPromotionAdjustParameter.scala:162) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
2021-12-05 16:01:00,078 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 42.0 with 4 tasks
2021-12-05 16:01:00,079 [dispatcher-event-loop-7] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 42.0 (TID 64, localhost, executor driver, partition 0, PROCESS_LOCAL, 7712 bytes)
2021-12-05 16:01:00,079 [dispatcher-event-loop-7] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 42.0 (TID 65, localhost, executor driver, partition 1, PROCESS_LOCAL, 7712 bytes)
2021-12-05 16:01:00,079 [dispatcher-event-loop-7] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 2.0 in stage 42.0 (TID 66, localhost, executor driver, partition 2, PROCESS_LOCAL, 7712 bytes)
2021-12-05 16:01:00,079 [dispatcher-event-loop-7] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 3.0 in stage 42.0 (TID 67, localhost, executor driver, partition 3, PROCESS_LOCAL, 7712 bytes)
2021-12-05 16:01:00,079 [Executor task launch worker for task 65] INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 42.0 (TID 65)
2021-12-05 16:01:00,079 [Executor task launch worker for task 67] INFO [org.apache.spark.executor.Executor] - Running task 3.0 in stage 42.0 (TID 67)
2021-12-05 16:01:00,079 [Executor task launch worker for task 66] INFO [org.apache.spark.executor.Executor] - Running task 2.0 in stage 42.0 (TID 66)
2021-12-05 16:01:00,079 [Executor task launch worker for task 64] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 42.0 (TID 64)
2021-12-05 16:01:00,083 [Executor task launch worker for task 65] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 4 blocks
2021-12-05 16:01:00,083 [Executor task launch worker for task 67] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 4 blocks
2021-12-05 16:01:00,083 [Executor task launch worker for task 65] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-05 16:01:00,083 [Executor task launch worker for task 67] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-05 16:01:00,083 [Executor task launch worker for task 66] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 4 blocks
2021-12-05 16:01:00,083 [Executor task launch worker for task 64] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 4 blocks
2021-12-05 16:01:00,083 [Executor task launch worker for task 66] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-05 16:01:00,083 [Executor task launch worker for task 64] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-05 16:01:00,085 [Executor task launch worker for task 67] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2021-12-05 16:01:00,085 [Executor task launch worker for task 66] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2021-12-05 16:01:00,085 [Executor task launch worker for task 67] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-05 16:01:00,085 [Executor task launch worker for task 65] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2021-12-05 16:01:00,085 [Executor task launch worker for task 64] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2021-12-05 16:01:00,085 [Executor task launch worker for task 66] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-05 16:01:00,085 [Executor task launch worker for task 64] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-05 16:01:00,085 [Executor task launch worker for task 65] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-05 16:01:00,144 [Executor task launch worker for task 66] INFO [org.apache.spark.executor.Executor] - Finished task 2.0 in stage 42.0 (TID 66). 1054 bytes result sent to driver
2021-12-05 16:01:00,145 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 2.0 in stage 42.0 (TID 66) in 66 ms on localhost (executor driver) (1/4)
2021-12-05 16:01:00,146 [Executor task launch worker for task 64] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 42.0 (TID 64). 1054 bytes result sent to driver
2021-12-05 16:01:00,146 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 42.0 (TID 64) in 67 ms on localhost (executor driver) (2/4)
2021-12-05 16:01:00,148 [Executor task launch worker for task 65] INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 42.0 (TID 65). 1054 bytes result sent to driver
2021-12-05 16:01:00,148 [Executor task launch worker for task 67] INFO [org.apache.spark.executor.Executor] - Finished task 3.0 in stage 42.0 (TID 67). 1054 bytes result sent to driver
2021-12-05 16:01:00,148 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 42.0 (TID 65) in 69 ms on localhost (executor driver) (3/4)
2021-12-05 16:01:00,149 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 3.0 in stage 42.0 (TID 67) in 70 ms on localhost (executor driver) (4/4)
2021-12-05 16:01:00,149 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 42.0, whose tasks have all completed, from pool 
2021-12-05 16:01:00,149 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 42 (count at PaidPromotionAdjustParameter.scala:171) finished in 0.076 s
2021-12-05 16:01:00,149 [main] INFO [org.apache.spark.scheduler.DAGScheduler] - Job 16 finished: count at PaidPromotionAdjustParameter.scala:171, took 0.163512 s
2021-12-05 16:01:00,149 [main] INFO [PaidPromotion$] - 最终共 同 用户数 = 5278
2021-12-05 16:01:00,152 [main] INFO [org.apache.spark.SparkContext] - Starting job: count at PaidPromotionAdjustParameter.scala:172
2021-12-05 16:01:00,152 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 51 (distinct at PaidPromotionAdjustParameter.scala:164)
2021-12-05 16:01:00,152 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 17 (count at PaidPromotionAdjustParameter.scala:172) with 4 output partitions
2021-12-05 16:01:00,152 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 44 (count at PaidPromotionAdjustParameter.scala:172)
2021-12-05 16:01:00,152 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 43)
2021-12-05 16:01:00,152 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List(ShuffleMapStage 43)
2021-12-05 16:01:00,153 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ShuffleMapStage 43 (MapPartitionsRDD[51] at distinct at PaidPromotionAdjustParameter.scala:164), which has no missing parents
2021-12-05 16:01:00,154 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_30 stored as values in memory (estimated size 189.9 KB, free 1990.0 MB)
2021-12-05 16:01:00,157 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_30_piece0 stored as bytes in memory (estimated size 67.2 KB, free 1989.9 MB)
2021-12-05 16:01:00,157 [dispatcher-event-loop-3] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_30_piece0 in memory on qb:53406 (size: 67.2 KB, free: 1990.6 MB)
2021-12-05 16:01:00,157 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 30 from broadcast at DAGScheduler.scala:1039
2021-12-05 16:01:00,157 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 4 missing tasks from ShuffleMapStage 43 (MapPartitionsRDD[51] at distinct at PaidPromotionAdjustParameter.scala:164) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
2021-12-05 16:01:00,157 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 43.0 with 4 tasks
2021-12-05 16:01:00,158 [dispatcher-event-loop-5] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 43.0 (TID 68, localhost, executor driver, partition 0, ANY, 7994 bytes)
2021-12-05 16:01:00,158 [dispatcher-event-loop-5] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 43.0 (TID 69, localhost, executor driver, partition 1, ANY, 7994 bytes)
2021-12-05 16:01:00,158 [dispatcher-event-loop-5] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 2.0 in stage 43.0 (TID 70, localhost, executor driver, partition 2, ANY, 7994 bytes)
2021-12-05 16:01:00,158 [dispatcher-event-loop-5] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 3.0 in stage 43.0 (TID 71, localhost, executor driver, partition 3, ANY, 7994 bytes)
2021-12-05 16:01:00,159 [Executor task launch worker for task 70] INFO [org.apache.spark.executor.Executor] - Running task 2.0 in stage 43.0 (TID 70)
2021-12-05 16:01:00,159 [Executor task launch worker for task 71] INFO [org.apache.spark.executor.Executor] - Running task 3.0 in stage 43.0 (TID 71)
2021-12-05 16:01:00,159 [Executor task launch worker for task 69] INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 43.0 (TID 69)
2021-12-05 16:01:00,159 [Executor task launch worker for task 68] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 43.0 (TID 68)
2021-12-05 16:01:00,169 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 619
2021-12-05 16:01:00,169 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 636
2021-12-05 16:01:00,169 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 679
2021-12-05 16:01:00,169 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 717
2021-12-05 16:01:00,170 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 631
2021-12-05 16:01:00,170 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 664
2021-12-05 16:01:00,170 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 696
2021-12-05 16:01:00,170 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 715
2021-12-05 16:01:00,170 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 602
2021-12-05 16:01:00,170 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 669
2021-12-05 16:01:00,170 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 661
2021-12-05 16:01:00,170 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 655
2021-12-05 16:01:00,170 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 707
2021-12-05 16:01:00,170 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 694
2021-12-05 16:01:00,170 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 665
2021-12-05 16:01:00,170 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 615
2021-12-05 16:01:00,170 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 604
2021-12-05 16:01:00,170 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 712
2021-12-05 16:01:00,170 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 613
2021-12-05 16:01:00,170 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 695
2021-12-05 16:01:00,170 [Executor task launch worker for task 68] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/order_data.bcp:0+3442194
2021-12-05 16:01:00,170 [Executor task launch worker for task 70] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/order_data.bcp:0+3442194
2021-12-05 16:01:00,170 [Executor task launch worker for task 69] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/order_data.bcp:3442194+3442195
2021-12-05 16:01:00,171 [Executor task launch worker for task 71] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/order_data.bcp:3442194+3442195
2021-12-05 16:01:00,171 [dispatcher-event-loop-1] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_27_piece0 on qb:53406 in memory (size: 2.3 KB, free: 1990.6 MB)
2021-12-05 16:01:00,172 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 716
2021-12-05 16:01:00,172 [dispatcher-event-loop-6] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_26_piece0 on qb:53406 in memory (size: 2.2 KB, free: 1990.6 MB)
2021-12-05 16:01:00,172 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 616
2021-12-05 16:01:00,172 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 724
2021-12-05 16:01:00,172 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 610
2021-12-05 16:01:00,172 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 648
2021-12-05 16:01:00,172 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 688
2021-12-05 16:01:00,172 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 704
2021-12-05 16:01:00,172 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 634
2021-12-05 16:01:00,172 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 609
2021-12-05 16:01:00,172 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 633
2021-12-05 16:01:00,172 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 689
2021-12-05 16:01:00,173 [dispatcher-event-loop-7] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_28_piece0 on qb:53406 in memory (size: 2.3 KB, free: 1990.6 MB)
2021-12-05 16:01:00,173 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 681
2021-12-05 16:01:00,173 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 632
2021-12-05 16:01:00,173 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 703
2021-12-05 16:01:00,173 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 705
2021-12-05 16:01:00,173 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 675
2021-12-05 16:01:00,173 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 626
2021-12-05 16:01:00,173 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 692
2021-12-05 16:01:00,173 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 653
2021-12-05 16:01:00,173 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 647
2021-12-05 16:01:00,173 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 624
2021-12-05 16:01:00,173 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 601
2021-12-05 16:01:00,173 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 614
2021-12-05 16:01:00,173 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 677
2021-12-05 16:01:00,173 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 670
2021-12-05 16:01:00,173 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 662
2021-12-05 16:01:00,173 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 666
2021-12-05 16:01:00,173 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 607
2021-12-05 16:01:00,173 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 673
2021-12-05 16:01:00,173 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 652
2021-12-05 16:01:00,173 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 623
2021-12-05 16:01:00,173 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 690
2021-12-05 16:01:00,173 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 643
2021-12-05 16:01:00,173 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 644
2021-12-05 16:01:00,173 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 722
2021-12-05 16:01:00,173 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 667
2021-12-05 16:01:00,173 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 654
2021-12-05 16:01:00,173 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 710
2021-12-05 16:01:00,173 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 714
2021-12-05 16:01:00,173 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 605
2021-12-05 16:01:00,173 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 691
2021-12-05 16:01:00,173 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 686
2021-12-05 16:01:00,173 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 711
2021-12-05 16:01:00,173 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 651
2021-12-05 16:01:00,174 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 672
2021-12-05 16:01:00,174 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 642
2021-12-05 16:01:00,174 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 646
2021-12-05 16:01:00,174 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 617
2021-12-05 16:01:00,174 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 603
2021-12-05 16:01:00,174 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 663
2021-12-05 16:01:00,174 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 606
2021-12-05 16:01:00,174 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 668
2021-12-05 16:01:00,174 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 649
2021-12-05 16:01:00,174 [dispatcher-event-loop-10] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_29_piece0 on qb:53406 in memory (size: 2.1 KB, free: 1990.6 MB)
2021-12-05 16:01:00,174 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 683
2021-12-05 16:01:00,174 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 629
2021-12-05 16:01:00,174 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 706
2021-12-05 16:01:00,174 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 608
2021-12-05 16:01:00,174 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 612
2021-12-05 16:01:00,174 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 600
2021-12-05 16:01:00,174 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 656
2021-12-05 16:01:00,174 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 720
2021-12-05 16:01:00,174 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 627
2021-12-05 16:01:00,174 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 635
2021-12-05 16:01:00,174 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 687
2021-12-05 16:01:00,174 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 697
2021-12-05 16:01:00,174 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 680
2021-12-05 16:01:00,174 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 621
2021-12-05 16:01:00,175 [dispatcher-event-loop-1] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_25_piece0 on qb:53406 in memory (size: 66.9 KB, free: 1990.7 MB)
2021-12-05 16:01:00,175 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 685
2021-12-05 16:01:00,175 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 676
2021-12-05 16:01:00,175 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 721
2021-12-05 16:01:00,175 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 660
2021-12-05 16:01:00,175 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 708
2021-12-05 16:01:00,175 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 618
2021-12-05 16:01:00,175 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 611
2021-12-05 16:01:00,175 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 684
2021-12-05 16:01:00,175 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 625
2021-12-05 16:01:00,175 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 698
2021-12-05 16:01:00,175 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 658
2021-12-05 16:01:00,175 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 702
2021-12-05 16:01:00,175 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 630
2021-12-05 16:01:00,175 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 699
2021-12-05 16:01:00,175 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 657
2021-12-05 16:01:00,175 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 620
2021-12-05 16:01:00,175 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 640
2021-12-05 16:01:00,175 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 701
2021-12-05 16:01:00,175 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 713
2021-12-05 16:01:00,175 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 723
2021-12-05 16:01:00,175 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 700
2021-12-05 16:01:00,175 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 638
2021-12-05 16:01:00,175 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 650
2021-12-05 16:01:00,175 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 645
2021-12-05 16:01:00,175 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 682
2021-12-05 16:01:00,175 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 693
2021-12-05 16:01:00,175 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 718
2021-12-05 16:01:00,175 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 637
2021-12-05 16:01:00,175 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 709
2021-12-05 16:01:00,175 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 678
2021-12-05 16:01:00,175 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 659
2021-12-05 16:01:00,175 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 674
2021-12-05 16:01:00,175 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 622
2021-12-05 16:01:00,175 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 628
2021-12-05 16:01:00,175 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 639
2021-12-05 16:01:00,175 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 641
2021-12-05 16:01:00,175 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 719
2021-12-05 16:01:00,175 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 671
2021-12-05 16:01:01,430 [Executor task launch worker for task 68] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 43.0 (TID 68). 1034 bytes result sent to driver
2021-12-05 16:01:01,431 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 43.0 (TID 68) in 1273 ms on localhost (executor driver) (1/4)
2021-12-05 16:01:01,662 [Executor task launch worker for task 71] INFO [org.apache.spark.executor.Executor] - Finished task 3.0 in stage 43.0 (TID 71). 1034 bytes result sent to driver
2021-12-05 16:01:01,662 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 3.0 in stage 43.0 (TID 71) in 1504 ms on localhost (executor driver) (2/4)
2021-12-05 16:01:01,672 [Executor task launch worker for task 69] INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 43.0 (TID 69). 1034 bytes result sent to driver
2021-12-05 16:01:01,672 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 43.0 (TID 69) in 1514 ms on localhost (executor driver) (3/4)
2021-12-05 16:01:01,711 [Executor task launch worker for task 70] INFO [org.apache.spark.executor.Executor] - Finished task 2.0 in stage 43.0 (TID 70). 1034 bytes result sent to driver
2021-12-05 16:01:01,711 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 2.0 in stage 43.0 (TID 70) in 1553 ms on localhost (executor driver) (4/4)
2021-12-05 16:01:01,711 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 43.0, whose tasks have all completed, from pool 
2021-12-05 16:01:01,712 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ShuffleMapStage 43 (distinct at PaidPromotionAdjustParameter.scala:164) finished in 1.558 s
2021-12-05 16:01:01,712 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - looking for newly runnable stages
2021-12-05 16:01:01,712 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - running: Set()
2021-12-05 16:01:01,712 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - waiting: Set(ResultStage 44)
2021-12-05 16:01:01,712 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - failed: Set()
2021-12-05 16:01:01,712 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 44 (MapPartitionsRDD[53] at distinct at PaidPromotionAdjustParameter.scala:164), which has no missing parents
2021-12-05 16:01:01,714 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_31 stored as values in memory (estimated size 3.7 KB, free 1990.2 MB)
2021-12-05 16:01:01,716 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_31_piece0 stored as bytes in memory (estimated size 2.2 KB, free 1990.2 MB)
2021-12-05 16:01:01,717 [dispatcher-event-loop-3] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_31_piece0 in memory on qb:53406 (size: 2.2 KB, free: 1990.7 MB)
2021-12-05 16:01:01,718 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 31 from broadcast at DAGScheduler.scala:1039
2021-12-05 16:01:01,718 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 4 missing tasks from ResultStage 44 (MapPartitionsRDD[53] at distinct at PaidPromotionAdjustParameter.scala:164) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
2021-12-05 16:01:01,718 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 44.0 with 4 tasks
2021-12-05 16:01:01,719 [dispatcher-event-loop-7] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 44.0 (TID 72, localhost, executor driver, partition 0, ANY, 7649 bytes)
2021-12-05 16:01:01,719 [dispatcher-event-loop-7] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 44.0 (TID 73, localhost, executor driver, partition 1, ANY, 7649 bytes)
2021-12-05 16:01:01,719 [dispatcher-event-loop-7] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 2.0 in stage 44.0 (TID 74, localhost, executor driver, partition 2, ANY, 7649 bytes)
2021-12-05 16:01:01,720 [dispatcher-event-loop-7] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 3.0 in stage 44.0 (TID 75, localhost, executor driver, partition 3, ANY, 7649 bytes)
2021-12-05 16:01:01,720 [Executor task launch worker for task 72] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 44.0 (TID 72)
2021-12-05 16:01:01,720 [Executor task launch worker for task 74] INFO [org.apache.spark.executor.Executor] - Running task 2.0 in stage 44.0 (TID 74)
2021-12-05 16:01:01,720 [Executor task launch worker for task 75] INFO [org.apache.spark.executor.Executor] - Running task 3.0 in stage 44.0 (TID 75)
2021-12-05 16:01:01,720 [Executor task launch worker for task 73] INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 44.0 (TID 73)
2021-12-05 16:01:01,721 [Executor task launch worker for task 72] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 4 non-empty blocks out of 4 blocks
2021-12-05 16:01:01,721 [Executor task launch worker for task 74] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 4 non-empty blocks out of 4 blocks
2021-12-05 16:01:01,721 [Executor task launch worker for task 74] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-05 16:01:01,721 [Executor task launch worker for task 72] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-05 16:01:01,721 [Executor task launch worker for task 75] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 4 non-empty blocks out of 4 blocks
2021-12-05 16:01:01,721 [Executor task launch worker for task 73] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 4 non-empty blocks out of 4 blocks
2021-12-05 16:01:01,721 [Executor task launch worker for task 73] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-05 16:01:01,721 [Executor task launch worker for task 75] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-05 16:01:01,743 [Executor task launch worker for task 75] INFO [org.apache.spark.executor.Executor] - Finished task 3.0 in stage 44.0 (TID 75). 967 bytes result sent to driver
2021-12-05 16:01:01,743 [Executor task launch worker for task 74] INFO [org.apache.spark.executor.Executor] - Finished task 2.0 in stage 44.0 (TID 74). 967 bytes result sent to driver
2021-12-05 16:01:01,743 [Executor task launch worker for task 72] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 44.0 (TID 72). 967 bytes result sent to driver
2021-12-05 16:01:01,743 [Executor task launch worker for task 73] INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 44.0 (TID 73). 1010 bytes result sent to driver
2021-12-05 16:01:01,744 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 3.0 in stage 44.0 (TID 75) in 23 ms on localhost (executor driver) (1/4)
2021-12-05 16:01:01,744 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 2.0 in stage 44.0 (TID 74) in 25 ms on localhost (executor driver) (2/4)
2021-12-05 16:01:01,744 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 44.0 (TID 72) in 25 ms on localhost (executor driver) (3/4)
2021-12-05 16:01:01,744 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 44.0 (TID 73) in 25 ms on localhost (executor driver) (4/4)
2021-12-05 16:01:01,744 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 44.0, whose tasks have all completed, from pool 
2021-12-05 16:01:01,744 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 44 (count at PaidPromotionAdjustParameter.scala:172) finished in 0.031 s
2021-12-05 16:01:01,744 [main] INFO [org.apache.spark.scheduler.DAGScheduler] - Job 17 finished: count at PaidPromotionAdjustParameter.scala:172, took 1.592915 s
2021-12-05 16:01:01,745 [main] INFO [PaidPromotion$] - 最终训练集节目数 = 132
2021-12-05 16:01:01,747 [main] INFO [org.apache.spark.SparkContext] - Starting job: count at PaidPromotionAdjustParameter.scala:173
2021-12-05 16:01:01,748 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 55 (distinct at PaidPromotionAdjustParameter.scala:165)
2021-12-05 16:01:01,748 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 18 (count at PaidPromotionAdjustParameter.scala:173) with 2 output partitions
2021-12-05 16:01:01,748 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 46 (count at PaidPromotionAdjustParameter.scala:173)
2021-12-05 16:01:01,748 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 45)
2021-12-05 16:01:01,748 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List(ShuffleMapStage 45)
2021-12-05 16:01:01,748 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ShuffleMapStage 45 (MapPartitionsRDD[55] at distinct at PaidPromotionAdjustParameter.scala:165), which has no missing parents
2021-12-05 16:01:01,751 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_32 stored as values in memory (estimated size 189.3 KB, free 1990.0 MB)
2021-12-05 16:01:01,754 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_32_piece0 stored as bytes in memory (estimated size 66.9 KB, free 1990.0 MB)
2021-12-05 16:01:01,754 [dispatcher-event-loop-6] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_32_piece0 in memory on qb:53406 (size: 66.9 KB, free: 1990.6 MB)
2021-12-05 16:01:01,755 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 32 from broadcast at DAGScheduler.scala:1039
2021-12-05 16:01:01,755 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from ShuffleMapStage 45 (MapPartitionsRDD[55] at distinct at PaidPromotionAdjustParameter.scala:165) (first 15 tasks are for partitions Vector(0, 1))
2021-12-05 16:01:01,755 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 45.0 with 2 tasks
2021-12-05 16:01:01,756 [dispatcher-event-loop-5] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 45.0 (TID 76, localhost, executor driver, partition 0, ANY, 7885 bytes)
2021-12-05 16:01:01,756 [dispatcher-event-loop-5] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 45.0 (TID 77, localhost, executor driver, partition 1, ANY, 7885 bytes)
2021-12-05 16:01:01,756 [Executor task launch worker for task 76] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 45.0 (TID 76)
2021-12-05 16:01:01,756 [Executor task launch worker for task 77] INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 45.0 (TID 77)
2021-12-05 16:01:01,758 [Executor task launch worker for task 76] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/order_data.bcp:0+3442194
2021-12-05 16:01:01,759 [Executor task launch worker for task 77] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/order_data.bcp:3442194+3442195
2021-12-05 16:01:02,612 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 731
2021-12-05 16:01:02,612 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 757
2021-12-05 16:01:02,612 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 769
2021-12-05 16:01:02,612 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 756
2021-12-05 16:01:02,612 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 747
2021-12-05 16:01:02,612 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 770
2021-12-05 16:01:02,612 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 727
2021-12-05 16:01:02,612 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 730
2021-12-05 16:01:02,612 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 732
2021-12-05 16:01:02,612 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 754
2021-12-05 16:01:02,612 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 755
2021-12-05 16:01:02,612 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 729
2021-12-05 16:01:02,612 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 768
2021-12-05 16:01:02,612 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 772
2021-12-05 16:01:02,612 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 746
2021-12-05 16:01:02,612 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 749
2021-12-05 16:01:02,612 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 773
2021-12-05 16:01:02,612 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 728
2021-12-05 16:01:02,612 [dispatcher-event-loop-1] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_30_piece0 on qb:53406 in memory (size: 67.2 KB, free: 1990.7 MB)
2021-12-05 16:01:02,613 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 760
2021-12-05 16:01:02,613 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 736
2021-12-05 16:01:02,613 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 742
2021-12-05 16:01:02,613 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 758
2021-12-05 16:01:02,613 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 763
2021-12-05 16:01:02,613 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 738
2021-12-05 16:01:02,613 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 750
2021-12-05 16:01:02,613 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 734
2021-12-05 16:01:02,614 [dispatcher-event-loop-0] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_31_piece0 on qb:53406 in memory (size: 2.2 KB, free: 1990.7 MB)
2021-12-05 16:01:02,614 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 767
2021-12-05 16:01:02,614 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 762
2021-12-05 16:01:02,614 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 761
2021-12-05 16:01:02,614 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 764
2021-12-05 16:01:02,614 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 766
2021-12-05 16:01:02,614 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 733
2021-12-05 16:01:02,614 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 726
2021-12-05 16:01:02,614 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 774
2021-12-05 16:01:02,614 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 739
2021-12-05 16:01:02,614 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 765
2021-12-05 16:01:02,614 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 741
2021-12-05 16:01:02,614 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 745
2021-12-05 16:01:02,614 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 751
2021-12-05 16:01:02,614 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 753
2021-12-05 16:01:02,614 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 743
2021-12-05 16:01:02,614 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 771
2021-12-05 16:01:02,614 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 744
2021-12-05 16:01:02,614 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 725
2021-12-05 16:01:02,614 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 759
2021-12-05 16:01:02,614 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 735
2021-12-05 16:01:02,614 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 737
2021-12-05 16:01:02,614 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 748
2021-12-05 16:01:02,614 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 752
2021-12-05 16:01:02,614 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 740
2021-12-05 16:01:02,942 [Executor task launch worker for task 77] INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 45.0 (TID 77). 1032 bytes result sent to driver
2021-12-05 16:01:02,942 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 45.0 (TID 77) in 1186 ms on localhost (executor driver) (1/2)
2021-12-05 16:01:02,972 [Executor task launch worker for task 76] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 45.0 (TID 76). 1075 bytes result sent to driver
2021-12-05 16:01:02,972 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 45.0 (TID 76) in 1216 ms on localhost (executor driver) (2/2)
2021-12-05 16:01:02,972 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 45.0, whose tasks have all completed, from pool 
2021-12-05 16:01:02,973 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ShuffleMapStage 45 (distinct at PaidPromotionAdjustParameter.scala:165) finished in 1.224 s
2021-12-05 16:01:02,973 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - looking for newly runnable stages
2021-12-05 16:01:02,973 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - running: Set()
2021-12-05 16:01:02,973 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - waiting: Set(ResultStage 46)
2021-12-05 16:01:02,973 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - failed: Set()
2021-12-05 16:01:02,973 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 46 (MapPartitionsRDD[57] at distinct at PaidPromotionAdjustParameter.scala:165), which has no missing parents
2021-12-05 16:01:02,973 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_33 stored as values in memory (estimated size 3.7 KB, free 1990.2 MB)
2021-12-05 16:01:02,975 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_33_piece0 stored as bytes in memory (estimated size 2.2 KB, free 1990.2 MB)
2021-12-05 16:01:02,975 [dispatcher-event-loop-3] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_33_piece0 in memory on qb:53406 (size: 2.2 KB, free: 1990.7 MB)
2021-12-05 16:01:02,975 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 33 from broadcast at DAGScheduler.scala:1039
2021-12-05 16:01:02,975 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from ResultStage 46 (MapPartitionsRDD[57] at distinct at PaidPromotionAdjustParameter.scala:165) (first 15 tasks are for partitions Vector(0, 1))
2021-12-05 16:01:02,975 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 46.0 with 2 tasks
2021-12-05 16:01:02,976 [dispatcher-event-loop-7] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 46.0 (TID 78, localhost, executor driver, partition 0, ANY, 7649 bytes)
2021-12-05 16:01:02,976 [dispatcher-event-loop-7] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 46.0 (TID 79, localhost, executor driver, partition 1, ANY, 7649 bytes)
2021-12-05 16:01:02,976 [Executor task launch worker for task 78] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 46.0 (TID 78)
2021-12-05 16:01:02,976 [Executor task launch worker for task 79] INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 46.0 (TID 79)
2021-12-05 16:01:02,977 [Executor task launch worker for task 79] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 2 non-empty blocks out of 2 blocks
2021-12-05 16:01:02,977 [Executor task launch worker for task 78] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 2 non-empty blocks out of 2 blocks
2021-12-05 16:01:02,977 [Executor task launch worker for task 79] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-05 16:01:02,977 [Executor task launch worker for task 78] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-05 16:01:02,990 [Executor task launch worker for task 78] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 46.0 (TID 78). 1010 bytes result sent to driver
2021-12-05 16:01:02,990 [Executor task launch worker for task 79] INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 46.0 (TID 79). 1010 bytes result sent to driver
2021-12-05 16:01:02,990 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 46.0 (TID 78) in 14 ms on localhost (executor driver) (1/2)
2021-12-05 16:01:02,990 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 46.0 (TID 79) in 14 ms on localhost (executor driver) (2/2)
2021-12-05 16:01:02,990 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 46.0, whose tasks have all completed, from pool 
2021-12-05 16:01:02,991 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 46 (count at PaidPromotionAdjustParameter.scala:173) finished in 0.018 s
2021-12-05 16:01:02,991 [main] INFO [org.apache.spark.scheduler.DAGScheduler] - Job 18 finished: count at PaidPromotionAdjustParameter.scala:173, took 1.242994 s
2021-12-05 16:01:02,991 [main] INFO [PaidPromotion$] - 最终验证集节目数 = 78
2021-12-05 16:01:02,994 [main] INFO [org.apache.spark.SparkContext] - Starting job: count at PaidPromotionAdjustParameter.scala:174
2021-12-05 16:01:02,995 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 58 (intersection at PaidPromotionAdjustParameter.scala:166)
2021-12-05 16:01:02,995 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 59 (intersection at PaidPromotionAdjustParameter.scala:166)
2021-12-05 16:01:02,995 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 19 (count at PaidPromotionAdjustParameter.scala:174) with 4 output partitions
2021-12-05 16:01:02,995 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 51 (count at PaidPromotionAdjustParameter.scala:174)
2021-12-05 16:01:02,995 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 48, ShuffleMapStage 50)
2021-12-05 16:01:02,996 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List(ShuffleMapStage 48, ShuffleMapStage 50)
2021-12-05 16:01:02,996 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ShuffleMapStage 48 (MapPartitionsRDD[58] at intersection at PaidPromotionAdjustParameter.scala:166), which has no missing parents
2021-12-05 16:01:02,997 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_34 stored as values in memory (estimated size 4.0 KB, free 1990.2 MB)
2021-12-05 16:01:03,000 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_34_piece0 stored as bytes in memory (estimated size 2.3 KB, free 1990.2 MB)
2021-12-05 16:01:03,000 [dispatcher-event-loop-1] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_34_piece0 in memory on qb:53406 (size: 2.3 KB, free: 1990.7 MB)
2021-12-05 16:01:03,001 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 34 from broadcast at DAGScheduler.scala:1039
2021-12-05 16:01:03,003 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 4 missing tasks from ShuffleMapStage 48 (MapPartitionsRDD[58] at intersection at PaidPromotionAdjustParameter.scala:166) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
2021-12-05 16:01:03,003 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 48.0 with 4 tasks
2021-12-05 16:01:03,003 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ShuffleMapStage 50 (MapPartitionsRDD[59] at intersection at PaidPromotionAdjustParameter.scala:166), which has no missing parents
2021-12-05 16:01:03,004 [dispatcher-event-loop-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 48.0 (TID 80, localhost, executor driver, partition 0, ANY, 7638 bytes)
2021-12-05 16:01:03,004 [dispatcher-event-loop-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 48.0 (TID 81, localhost, executor driver, partition 1, ANY, 7638 bytes)
2021-12-05 16:01:03,004 [dispatcher-event-loop-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 2.0 in stage 48.0 (TID 82, localhost, executor driver, partition 2, ANY, 7638 bytes)
2021-12-05 16:01:03,004 [dispatcher-event-loop-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 3.0 in stage 48.0 (TID 83, localhost, executor driver, partition 3, ANY, 7638 bytes)
2021-12-05 16:01:03,004 [Executor task launch worker for task 82] INFO [org.apache.spark.executor.Executor] - Running task 2.0 in stage 48.0 (TID 82)
2021-12-05 16:01:03,004 [Executor task launch worker for task 83] INFO [org.apache.spark.executor.Executor] - Running task 3.0 in stage 48.0 (TID 83)
2021-12-05 16:01:03,004 [Executor task launch worker for task 80] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 48.0 (TID 80)
2021-12-05 16:01:03,004 [Executor task launch worker for task 81] INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 48.0 (TID 81)
2021-12-05 16:01:03,004 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_35 stored as values in memory (estimated size 4.0 KB, free 1990.2 MB)
2021-12-05 16:01:03,005 [Executor task launch worker for task 80] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 4 non-empty blocks out of 4 blocks
2021-12-05 16:01:03,005 [Executor task launch worker for task 83] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 4 non-empty blocks out of 4 blocks
2021-12-05 16:01:03,005 [Executor task launch worker for task 83] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-05 16:01:03,005 [Executor task launch worker for task 80] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-05 16:01:03,005 [Executor task launch worker for task 82] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 4 non-empty blocks out of 4 blocks
2021-12-05 16:01:03,005 [Executor task launch worker for task 82] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-05 16:01:03,005 [Executor task launch worker for task 81] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 4 non-empty blocks out of 4 blocks
2021-12-05 16:01:03,005 [Executor task launch worker for task 81] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-05 16:01:03,007 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_35_piece0 stored as bytes in memory (estimated size 2.3 KB, free 1990.2 MB)
2021-12-05 16:01:03,007 [dispatcher-event-loop-3] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_35_piece0 in memory on qb:53406 (size: 2.3 KB, free: 1990.7 MB)
2021-12-05 16:01:03,007 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 35 from broadcast at DAGScheduler.scala:1039
2021-12-05 16:01:03,008 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from ShuffleMapStage 50 (MapPartitionsRDD[59] at intersection at PaidPromotionAdjustParameter.scala:166) (first 15 tasks are for partitions Vector(0, 1))
2021-12-05 16:01:03,008 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 50.0 with 2 tasks
2021-12-05 16:01:03,008 [dispatcher-event-loop-7] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 50.0 (TID 84, localhost, executor driver, partition 0, ANY, 7638 bytes)
2021-12-05 16:01:03,009 [dispatcher-event-loop-7] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 50.0 (TID 85, localhost, executor driver, partition 1, ANY, 7638 bytes)
2021-12-05 16:01:03,009 [Executor task launch worker for task 85] INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 50.0 (TID 85)
2021-12-05 16:01:03,009 [Executor task launch worker for task 84] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 50.0 (TID 84)
2021-12-05 16:01:03,010 [Executor task launch worker for task 85] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 2 non-empty blocks out of 2 blocks
2021-12-05 16:01:03,010 [Executor task launch worker for task 84] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 2 non-empty blocks out of 2 blocks
2021-12-05 16:01:03,010 [Executor task launch worker for task 85] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-05 16:01:03,010 [Executor task launch worker for task 84] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-05 16:01:03,024 [Executor task launch worker for task 80] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 48.0 (TID 80). 1206 bytes result sent to driver
2021-12-05 16:01:03,025 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 48.0 (TID 80) in 22 ms on localhost (executor driver) (1/4)
2021-12-05 16:01:03,025 [Executor task launch worker for task 83] INFO [org.apache.spark.executor.Executor] - Finished task 3.0 in stage 48.0 (TID 83). 1163 bytes result sent to driver
2021-12-05 16:01:03,026 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 3.0 in stage 48.0 (TID 83) in 22 ms on localhost (executor driver) (2/4)
2021-12-05 16:01:03,026 [Executor task launch worker for task 82] INFO [org.apache.spark.executor.Executor] - Finished task 2.0 in stage 48.0 (TID 82). 1206 bytes result sent to driver
2021-12-05 16:01:03,027 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 2.0 in stage 48.0 (TID 82) in 23 ms on localhost (executor driver) (3/4)
2021-12-05 16:01:03,027 [Executor task launch worker for task 81] INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 48.0 (TID 81). 1206 bytes result sent to driver
2021-12-05 16:01:03,028 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 48.0 (TID 81) in 24 ms on localhost (executor driver) (4/4)
2021-12-05 16:01:03,028 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 48.0, whose tasks have all completed, from pool 
2021-12-05 16:01:03,028 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ShuffleMapStage 48 (intersection at PaidPromotionAdjustParameter.scala:166) finished in 0.032 s
2021-12-05 16:01:03,028 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - looking for newly runnable stages
2021-12-05 16:01:03,028 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - running: Set(ShuffleMapStage 50)
2021-12-05 16:01:03,028 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - waiting: Set(ResultStage 51)
2021-12-05 16:01:03,028 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - failed: Set()
2021-12-05 16:01:03,035 [Executor task launch worker for task 85] INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 50.0 (TID 85). 1163 bytes result sent to driver
2021-12-05 16:01:03,035 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 50.0 (TID 85) in 27 ms on localhost (executor driver) (1/2)
2021-12-05 16:01:03,037 [Executor task launch worker for task 84] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 50.0 (TID 84). 1163 bytes result sent to driver
2021-12-05 16:01:03,038 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 50.0 (TID 84) in 30 ms on localhost (executor driver) (2/2)
2021-12-05 16:01:03,038 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 50.0, whose tasks have all completed, from pool 
2021-12-05 16:01:03,040 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ShuffleMapStage 50 (intersection at PaidPromotionAdjustParameter.scala:166) finished in 0.035 s
2021-12-05 16:01:03,040 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - looking for newly runnable stages
2021-12-05 16:01:03,040 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - running: Set()
2021-12-05 16:01:03,040 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - waiting: Set(ResultStage 51)
2021-12-05 16:01:03,040 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - failed: Set()
2021-12-05 16:01:03,041 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 51 (MapPartitionsRDD[63] at intersection at PaidPromotionAdjustParameter.scala:166), which has no missing parents
2021-12-05 16:01:03,041 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_36 stored as values in memory (estimated size 3.6 KB, free 1990.2 MB)
2021-12-05 16:01:03,043 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_36_piece0 stored as bytes in memory (estimated size 2.1 KB, free 1990.2 MB)
2021-12-05 16:01:03,043 [dispatcher-event-loop-6] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_36_piece0 in memory on qb:53406 (size: 2.1 KB, free: 1990.7 MB)
2021-12-05 16:01:03,043 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 36 from broadcast at DAGScheduler.scala:1039
2021-12-05 16:01:03,044 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 4 missing tasks from ResultStage 51 (MapPartitionsRDD[63] at intersection at PaidPromotionAdjustParameter.scala:166) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
2021-12-05 16:01:03,044 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 51.0 with 4 tasks
2021-12-05 16:01:03,044 [dispatcher-event-loop-5] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 51.0 (TID 86, localhost, executor driver, partition 0, PROCESS_LOCAL, 7712 bytes)
2021-12-05 16:01:03,044 [dispatcher-event-loop-5] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 51.0 (TID 87, localhost, executor driver, partition 1, PROCESS_LOCAL, 7712 bytes)
2021-12-05 16:01:03,044 [dispatcher-event-loop-5] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 2.0 in stage 51.0 (TID 88, localhost, executor driver, partition 2, PROCESS_LOCAL, 7712 bytes)
2021-12-05 16:01:03,044 [dispatcher-event-loop-5] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 3.0 in stage 51.0 (TID 89, localhost, executor driver, partition 3, PROCESS_LOCAL, 7712 bytes)
2021-12-05 16:01:03,044 [Executor task launch worker for task 89] INFO [org.apache.spark.executor.Executor] - Running task 3.0 in stage 51.0 (TID 89)
2021-12-05 16:01:03,044 [Executor task launch worker for task 87] INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 51.0 (TID 87)
2021-12-05 16:01:03,044 [Executor task launch worker for task 86] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 51.0 (TID 86)
2021-12-05 16:01:03,044 [Executor task launch worker for task 88] INFO [org.apache.spark.executor.Executor] - Running task 2.0 in stage 51.0 (TID 88)
2021-12-05 16:01:03,045 [Executor task launch worker for task 86] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 4 blocks
2021-12-05 16:01:03,045 [Executor task launch worker for task 89] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 4 blocks
2021-12-05 16:01:03,046 [Executor task launch worker for task 86] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 1 ms
2021-12-05 16:01:03,046 [Executor task launch worker for task 87] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 4 blocks
2021-12-05 16:01:03,046 [Executor task launch worker for task 89] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 1 ms
2021-12-05 16:01:03,046 [Executor task launch worker for task 88] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 4 blocks
2021-12-05 16:01:03,046 [Executor task launch worker for task 87] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-05 16:01:03,046 [Executor task launch worker for task 88] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 1 ms
2021-12-05 16:01:03,048 [Executor task launch worker for task 87] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2021-12-05 16:01:03,048 [Executor task launch worker for task 89] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2021-12-05 16:01:03,048 [Executor task launch worker for task 88] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2021-12-05 16:01:03,048 [Executor task launch worker for task 89] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-05 16:01:03,048 [Executor task launch worker for task 87] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-05 16:01:03,048 [Executor task launch worker for task 86] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2021-12-05 16:01:03,048 [Executor task launch worker for task 88] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-05 16:01:03,048 [Executor task launch worker for task 86] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-05 16:01:03,058 [Executor task launch worker for task 86] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 51.0 (TID 86). 1053 bytes result sent to driver
2021-12-05 16:01:03,058 [Executor task launch worker for task 89] INFO [org.apache.spark.executor.Executor] - Finished task 3.0 in stage 51.0 (TID 89). 1053 bytes result sent to driver
2021-12-05 16:01:03,058 [Executor task launch worker for task 88] INFO [org.apache.spark.executor.Executor] - Finished task 2.0 in stage 51.0 (TID 88). 1010 bytes result sent to driver
2021-12-05 16:01:03,058 [Executor task launch worker for task 87] INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 51.0 (TID 87). 1053 bytes result sent to driver
2021-12-05 16:01:03,059 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 51.0 (TID 86) in 15 ms on localhost (executor driver) (1/4)
2021-12-05 16:01:03,059 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 3.0 in stage 51.0 (TID 89) in 15 ms on localhost (executor driver) (2/4)
2021-12-05 16:01:03,059 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 2.0 in stage 51.0 (TID 88) in 15 ms on localhost (executor driver) (3/4)
2021-12-05 16:01:03,059 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 51.0 (TID 87) in 15 ms on localhost (executor driver) (4/4)
2021-12-05 16:01:03,059 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 51.0, whose tasks have all completed, from pool 
2021-12-05 16:01:03,059 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 51 (count at PaidPromotionAdjustParameter.scala:174) finished in 0.018 s
2021-12-05 16:01:03,059 [main] INFO [org.apache.spark.scheduler.DAGScheduler] - Job 19 finished: count at PaidPromotionAdjustParameter.scala:174, took 0.064947 s
2021-12-05 16:01:03,060 [main] INFO [PaidPromotion$] - 最终共 同 节目数 = 78
2021-12-05 16:01:03,082 [main] INFO [org.apache.hadoop.conf.Configuration.deprecation] - mapred.output.dir is deprecated. Instead, use mapreduce.output.fileoutputformat.outputdir
2021-12-05 16:01:03,086 [main] INFO [org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter] - File Output Committer Algorithm version is 1
2021-12-05 16:01:03,239 [main] INFO [org.apache.spark.SparkContext] - Starting job: runJob at SparkHadoopWriter.scala:78
2021-12-05 16:01:03,240 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 20 (runJob at SparkHadoopWriter.scala:78) with 1 output partitions
2021-12-05 16:01:03,240 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 52 (runJob at SparkHadoopWriter.scala:78)
2021-12-05 16:01:03,240 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List()
2021-12-05 16:01:03,240 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2021-12-05 16:01:03,240 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 52 (MapPartitionsRDD[66] at saveAsTextFile at PaidPromotionAdjustParameter.scala:179), which has no missing parents
2021-12-05 16:01:03,254 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_37 stored as values in memory (estimated size 264.9 KB, free 1989.9 MB)
2021-12-05 16:01:03,256 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_37_piece0 stored as bytes in memory (estimated size 95.4 KB, free 1989.8 MB)
2021-12-05 16:01:03,257 [dispatcher-event-loop-4] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_37_piece0 in memory on qb:53406 (size: 95.4 KB, free: 1990.6 MB)
2021-12-05 16:01:03,257 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 37 from broadcast at DAGScheduler.scala:1039
2021-12-05 16:01:03,258 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 52 (MapPartitionsRDD[66] at saveAsTextFile at PaidPromotionAdjustParameter.scala:179) (first 15 tasks are for partitions Vector(0))
2021-12-05 16:01:03,258 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 52.0 with 1 tasks
2021-12-05 16:01:03,260 [dispatcher-event-loop-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 52.0 (TID 90, localhost, executor driver, partition 0, ANY, 8509 bytes)
2021-12-05 16:01:03,260 [Executor task launch worker for task 90] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 52.0 (TID 90)
2021-12-05 16:01:03,286 [Executor task launch worker for task 90] INFO [org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter] - File Output Committer Algorithm version is 1
2021-12-05 16:01:03,416 [Executor task launch worker for task 90] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/order_data.bcp:0+3442194
2021-12-05 16:01:04,889 [Executor task launch worker for task 90] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/order_data.bcp:3442194+3442195
2021-12-05 16:01:06,064 [Executor task launch worker for task 90] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/order_data.bcp:0+3442194
2021-12-05 16:01:07,765 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 812
2021-12-05 16:01:07,765 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 780
2021-12-05 16:01:07,765 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 886
2021-12-05 16:01:07,765 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 862
2021-12-05 16:01:07,765 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 882
2021-12-05 16:01:07,765 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 806
2021-12-05 16:01:07,765 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 841
2021-12-05 16:01:07,765 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 816
2021-12-05 16:01:07,765 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 821
2021-12-05 16:01:07,767 [dispatcher-event-loop-7] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_36_piece0 on qb:53406 in memory (size: 2.1 KB, free: 1990.6 MB)
2021-12-05 16:01:07,767 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 805
2021-12-05 16:01:07,767 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 837
2021-12-05 16:01:07,767 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 867
2021-12-05 16:01:07,767 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 889
2021-12-05 16:01:07,767 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 893
2021-12-05 16:01:07,767 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 814
2021-12-05 16:01:07,767 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 857
2021-12-05 16:01:07,767 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 874
2021-12-05 16:01:07,767 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 776
2021-12-05 16:01:07,767 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 878
2021-12-05 16:01:07,767 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 891
2021-12-05 16:01:07,767 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 842
2021-12-05 16:01:07,767 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 787
2021-12-05 16:01:07,767 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 828
2021-12-05 16:01:07,767 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 833
2021-12-05 16:01:07,767 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 855
2021-12-05 16:01:07,767 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 811
2021-12-05 16:01:07,767 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 803
2021-12-05 16:01:07,768 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 831
2021-12-05 16:01:07,768 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 788
2021-12-05 16:01:07,768 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 799
2021-12-05 16:01:07,768 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 856
2021-12-05 16:01:07,768 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 887
2021-12-05 16:01:07,768 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 897
2021-12-05 16:01:07,768 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 896
2021-12-05 16:01:07,768 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 795
2021-12-05 16:01:07,768 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 858
2021-12-05 16:01:07,768 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 859
2021-12-05 16:01:07,768 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 783
2021-12-05 16:01:07,768 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 838
2021-12-05 16:01:07,768 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 881
2021-12-05 16:01:07,768 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 793
2021-12-05 16:01:07,768 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 817
2021-12-05 16:01:07,768 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 847
2021-12-05 16:01:07,768 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 845
2021-12-05 16:01:07,768 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 804
2021-12-05 16:01:07,768 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 863
2021-12-05 16:01:07,768 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 829
2021-12-05 16:01:07,768 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 880
2021-12-05 16:01:07,768 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 827
2021-12-05 16:01:07,768 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 781
2021-12-05 16:01:07,768 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 890
2021-12-05 16:01:07,768 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 792
2021-12-05 16:01:07,768 [dispatcher-event-loop-8] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_33_piece0 on qb:53406 in memory (size: 2.2 KB, free: 1990.6 MB)
2021-12-05 16:01:07,769 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 830
2021-12-05 16:01:07,769 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 894
2021-12-05 16:01:07,769 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 870
2021-12-05 16:01:07,769 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 843
2021-12-05 16:01:07,769 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 810
2021-12-05 16:01:07,769 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 798
2021-12-05 16:01:07,769 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 851
2021-12-05 16:01:07,769 [dispatcher-event-loop-10] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_32_piece0 on qb:53406 in memory (size: 66.9 KB, free: 1990.7 MB)
2021-12-05 16:01:07,770 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 808
2021-12-05 16:01:07,770 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 819
2021-12-05 16:01:07,770 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 797
2021-12-05 16:01:07,770 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 790
2021-12-05 16:01:07,770 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 791
2021-12-05 16:01:07,770 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 898
2021-12-05 16:01:07,770 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 879
2021-12-05 16:01:07,770 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 873
2021-12-05 16:01:07,770 [dispatcher-event-loop-6] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_34_piece0 on qb:53406 in memory (size: 2.3 KB, free: 1990.7 MB)
2021-12-05 16:01:07,770 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 779
2021-12-05 16:01:07,770 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 826
2021-12-05 16:01:07,770 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 888
2021-12-05 16:01:07,770 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 794
2021-12-05 16:01:07,770 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 840
2021-12-05 16:01:07,770 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 818
2021-12-05 16:01:07,770 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 839
2021-12-05 16:01:07,770 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 883
2021-12-05 16:01:07,770 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 823
2021-12-05 16:01:07,770 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 777
2021-12-05 16:01:07,770 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 815
2021-12-05 16:01:07,771 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 800
2021-12-05 16:01:07,771 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 802
2021-12-05 16:01:07,771 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 885
2021-12-05 16:01:07,771 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 850
2021-12-05 16:01:07,771 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 784
2021-12-05 16:01:07,771 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 875
2021-12-05 16:01:07,771 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 824
2021-12-05 16:01:07,771 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 778
2021-12-05 16:01:07,771 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 789
2021-12-05 16:01:07,771 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 835
2021-12-05 16:01:07,771 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 820
2021-12-05 16:01:07,771 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 871
2021-12-05 16:01:07,771 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 864
2021-12-05 16:01:07,771 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 782
2021-12-05 16:01:07,771 [dispatcher-event-loop-7] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_35_piece0 on qb:53406 in memory (size: 2.3 KB, free: 1990.7 MB)
2021-12-05 16:01:07,771 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 892
2021-12-05 16:01:07,771 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 801
2021-12-05 16:01:07,771 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 832
2021-12-05 16:01:07,771 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 861
2021-12-05 16:01:07,771 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 876
2021-12-05 16:01:07,771 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 775
2021-12-05 16:01:07,771 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 813
2021-12-05 16:01:07,771 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 836
2021-12-05 16:01:07,771 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 848
2021-12-05 16:01:07,771 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 872
2021-12-05 16:01:07,771 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 846
2021-12-05 16:01:07,771 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 844
2021-12-05 16:01:07,771 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 854
2021-12-05 16:01:07,771 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 809
2021-12-05 16:01:07,771 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 786
2021-12-05 16:01:07,771 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 860
2021-12-05 16:01:07,771 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 877
2021-12-05 16:01:07,771 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 834
2021-12-05 16:01:07,771 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 899
2021-12-05 16:01:07,771 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 785
2021-12-05 16:01:07,771 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 822
2021-12-05 16:01:07,771 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 796
2021-12-05 16:01:07,771 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 853
2021-12-05 16:01:07,771 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 849
2021-12-05 16:01:07,771 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 895
2021-12-05 16:01:07,771 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 825
2021-12-05 16:01:07,771 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 868
2021-12-05 16:01:07,771 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 852
2021-12-05 16:01:07,771 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 865
2021-12-05 16:01:07,771 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 869
2021-12-05 16:01:07,771 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 807
2021-12-05 16:01:07,771 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 866
2021-12-05 16:01:07,771 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 884
2021-12-05 16:01:08,347 [Executor task launch worker for task 90] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/order_data.bcp:3442194+3442195
2021-12-05 16:01:27,580 [Executor task launch worker for task 90] INFO [org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter] - Saved output of task 'attempt_20211205160103_0066_m_000000_0' to hdfs://hdp1:8020/sk/chongqing/handle_data/set-train-device-production-data/_temporary/0/task_20211205160103_0066_m_000000
2021-12-05 16:01:27,581 [Executor task launch worker for task 90] INFO [org.apache.spark.mapred.SparkHadoopMapRedUtil] - attempt_20211205160103_0066_m_000000_0: Committed
2021-12-05 16:01:27,582 [Executor task launch worker for task 90] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 52.0 (TID 90). 998 bytes result sent to driver
2021-12-05 16:01:27,585 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 52.0 (TID 90) in 24327 ms on localhost (executor driver) (1/1)
2021-12-05 16:01:27,585 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 52.0, whose tasks have all completed, from pool 
2021-12-05 16:01:27,585 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 52 (runJob at SparkHadoopWriter.scala:78) finished in 24.345 s
2021-12-05 16:01:27,586 [main] INFO [org.apache.spark.scheduler.DAGScheduler] - Job 20 finished: runJob at SparkHadoopWriter.scala:78, took 24.346957 s
2021-12-05 16:01:28,477 [main] INFO [org.apache.spark.internal.io.SparkHadoopWriter] - Job job_20211205160103_0066 committed.
2021-12-05 16:01:28,482 [main] INFO [org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter] - File Output Committer Algorithm version is 1
2021-12-05 16:01:28,566 [main] INFO [org.apache.spark.SparkContext] - Starting job: runJob at SparkHadoopWriter.scala:78
2021-12-05 16:01:28,566 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 21 (runJob at SparkHadoopWriter.scala:78) with 1 output partitions
2021-12-05 16:01:28,566 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 53 (runJob at SparkHadoopWriter.scala:78)
2021-12-05 16:01:28,566 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List()
2021-12-05 16:01:28,566 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2021-12-05 16:01:28,566 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 53 (MapPartitionsRDD[69] at saveAsTextFile at PaidPromotionAdjustParameter.scala:182), which has no missing parents
2021-12-05 16:01:28,576 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_38 stored as values in memory (estimated size 264.4 KB, free 1989.9 MB)
2021-12-05 16:01:28,578 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_38_piece0 stored as bytes in memory (estimated size 95.0 KB, free 1989.8 MB)
2021-12-05 16:01:28,579 [dispatcher-event-loop-0] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_38_piece0 in memory on qb:53406 (size: 95.0 KB, free: 1990.6 MB)
2021-12-05 16:01:28,579 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 38 from broadcast at DAGScheduler.scala:1039
2021-12-05 16:01:28,579 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 53 (MapPartitionsRDD[69] at saveAsTextFile at PaidPromotionAdjustParameter.scala:182) (first 15 tasks are for partitions Vector(0))
2021-12-05 16:01:28,579 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 53.0 with 1 tasks
2021-12-05 16:01:28,580 [dispatcher-event-loop-4] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 53.0 (TID 91, localhost, executor driver, partition 0, ANY, 8337 bytes)
2021-12-05 16:01:28,580 [Executor task launch worker for task 91] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 53.0 (TID 91)
2021-12-05 16:01:28,585 [Executor task launch worker for task 91] INFO [org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter] - File Output Committer Algorithm version is 1
2021-12-05 16:01:28,713 [Executor task launch worker for task 91] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/order_data.bcp:0+3442194
2021-12-05 16:01:32,490 [Executor task launch worker for task 91] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/order_data.bcp:3442194+3442195
2021-12-05 16:01:36,154 [Executor task launch worker for task 91] INFO [org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter] - Saved output of task 'attempt_20211205160128_0069_m_000000_0' to hdfs://hdp1:8020/sk/chongqing/handle_data/set-validation-device-production-data/_temporary/0/task_20211205160128_0069_m_000000
2021-12-05 16:01:36,154 [Executor task launch worker for task 91] INFO [org.apache.spark.mapred.SparkHadoopMapRedUtil] - attempt_20211205160128_0069_m_000000_0: Committed
2021-12-05 16:01:36,155 [Executor task launch worker for task 91] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 53.0 (TID 91). 955 bytes result sent to driver
2021-12-05 16:01:36,156 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 53.0 (TID 91) in 7577 ms on localhost (executor driver) (1/1)
2021-12-05 16:01:36,156 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 53.0, whose tasks have all completed, from pool 
2021-12-05 16:01:36,156 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 53 (runJob at SparkHadoopWriter.scala:78) finished in 7.589 s
2021-12-05 16:01:36,156 [main] INFO [org.apache.spark.scheduler.DAGScheduler] - Job 21 finished: runJob at SparkHadoopWriter.scala:78, took 7.590854 s
2021-12-05 16:01:36,981 [main] INFO [org.apache.spark.internal.io.SparkHadoopWriter] - Job job_20211205160128_0069 committed.
2021-12-05 16:01:36,993 [main] INFO [PaidPromotion$] - 验证集用户实际观看列表-----------------------------------
2021-12-05 16:01:36,994 [main] INFO [org.apache.spark.SparkContext] - Starting job: count at PaidPromotionAdjustParameter.scala:192
2021-12-05 16:01:36,995 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 33 (filter at PaidPromotionAdjustParameter.scala:150)
2021-12-05 16:01:36,995 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 22 (count at PaidPromotionAdjustParameter.scala:192) with 2 output partitions
2021-12-05 16:01:36,995 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 55 (count at PaidPromotionAdjustParameter.scala:192)
2021-12-05 16:01:36,995 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 54)
2021-12-05 16:01:36,995 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List(ShuffleMapStage 54)
2021-12-05 16:01:36,995 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ShuffleMapStage 54 (MapPartitionsRDD[33] at filter at PaidPromotionAdjustParameter.scala:150), which has no missing parents
2021-12-05 16:01:36,997 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_39 stored as values in memory (estimated size 189.8 KB, free 1989.6 MB)
2021-12-05 16:01:37,002 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_39_piece0 stored as bytes in memory (estimated size 67.1 KB, free 1989.5 MB)
2021-12-05 16:01:37,002 [dispatcher-event-loop-9] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_39_piece0 in memory on qb:53406 (size: 67.1 KB, free: 1990.5 MB)
2021-12-05 16:01:37,002 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 39 from broadcast at DAGScheduler.scala:1039
2021-12-05 16:01:37,002 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from ShuffleMapStage 54 (MapPartitionsRDD[33] at filter at PaidPromotionAdjustParameter.scala:150) (first 15 tasks are for partitions Vector(0, 1))
2021-12-05 16:01:37,002 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 54.0 with 2 tasks
2021-12-05 16:01:37,003 [dispatcher-event-loop-8] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 54.0 (TID 92, localhost, executor driver, partition 0, ANY, 7885 bytes)
2021-12-05 16:01:37,003 [dispatcher-event-loop-8] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 54.0 (TID 93, localhost, executor driver, partition 1, ANY, 7885 bytes)
2021-12-05 16:01:37,003 [Executor task launch worker for task 93] INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 54.0 (TID 93)
2021-12-05 16:01:37,003 [Executor task launch worker for task 92] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 54.0 (TID 92)
2021-12-05 16:01:37,005 [Executor task launch worker for task 93] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/order_data.bcp:3442194+3442195
2021-12-05 16:01:37,005 [Executor task launch worker for task 92] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/order_data.bcp:0+3442194
2021-12-05 16:01:40,507 [Executor task launch worker for task 93] INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 54.0 (TID 93). 860 bytes result sent to driver
2021-12-05 16:01:40,508 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 54.0 (TID 93) in 3505 ms on localhost (executor driver) (1/2)
2021-12-05 16:01:40,540 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 916
2021-12-05 16:01:40,540 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 925
2021-12-05 16:01:40,540 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 914
2021-12-05 16:01:40,541 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 936
2021-12-05 16:01:40,541 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 913
2021-12-05 16:01:40,541 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 947
2021-12-05 16:01:40,541 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 909
2021-12-05 16:01:40,541 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 908
2021-12-05 16:01:40,541 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 938
2021-12-05 16:01:40,542 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 924
2021-12-05 16:01:40,542 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 903
2021-12-05 16:01:40,542 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 948
2021-12-05 16:01:40,542 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 911
2021-12-05 16:01:40,542 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 917
2021-12-05 16:01:40,542 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 946
2021-12-05 16:01:40,542 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 930
2021-12-05 16:01:40,542 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 904
2021-12-05 16:01:40,542 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 931
2021-12-05 16:01:40,542 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 910
2021-12-05 16:01:40,542 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 943
2021-12-05 16:01:40,542 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 934
2021-12-05 16:01:40,542 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 918
2021-12-05 16:01:40,542 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 928
2021-12-05 16:01:40,542 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 923
2021-12-05 16:01:40,542 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 912
2021-12-05 16:01:40,542 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 921
2021-12-05 16:01:40,542 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 940
2021-12-05 16:01:40,542 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 919
2021-12-05 16:01:40,542 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 915
2021-12-05 16:01:40,542 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 926
2021-12-05 16:01:40,542 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 927
2021-12-05 16:01:40,542 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 900
2021-12-05 16:01:40,542 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 920
2021-12-05 16:01:40,542 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 949
2021-12-05 16:01:40,542 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 906
2021-12-05 16:01:40,542 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 929
2021-12-05 16:01:40,542 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 939
2021-12-05 16:01:40,542 [dispatcher-event-loop-6] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_38_piece0 on qb:53406 in memory (size: 95.0 KB, free: 1990.6 MB)
2021-12-05 16:01:40,543 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 942
2021-12-05 16:01:40,543 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 944
2021-12-05 16:01:40,543 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 902
2021-12-05 16:01:40,543 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 941
2021-12-05 16:01:40,543 [dispatcher-event-loop-7] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_37_piece0 on qb:53406 in memory (size: 95.4 KB, free: 1990.7 MB)
2021-12-05 16:01:40,543 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 935
2021-12-05 16:01:40,543 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 907
2021-12-05 16:01:40,543 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 905
2021-12-05 16:01:40,543 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 937
2021-12-05 16:01:40,543 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 945
2021-12-05 16:01:40,543 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 901
2021-12-05 16:01:40,543 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 922
2021-12-05 16:01:40,543 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 932
2021-12-05 16:01:40,543 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 933
2021-12-05 16:01:41,250 [Executor task launch worker for task 92] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 54.0 (TID 92). 903 bytes result sent to driver
2021-12-05 16:01:41,250 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 54.0 (TID 92) in 4247 ms on localhost (executor driver) (2/2)
2021-12-05 16:01:41,250 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 54.0, whose tasks have all completed, from pool 
2021-12-05 16:01:41,250 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ShuffleMapStage 54 (filter at PaidPromotionAdjustParameter.scala:150) finished in 4.255 s
2021-12-05 16:01:41,250 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - looking for newly runnable stages
2021-12-05 16:01:41,250 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - running: Set()
2021-12-05 16:01:41,250 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - waiting: Set(ResultStage 55)
2021-12-05 16:01:41,250 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - failed: Set()
2021-12-05 16:01:41,250 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 55 (MapPartitionsRDD[71] at map at PaidPromotionAdjustParameter.scala:186), which has no missing parents
2021-12-05 16:01:41,254 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_40 stored as values in memory (estimated size 190.7 KB, free 1990.0 MB)
2021-12-05 16:01:41,256 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_40_piece0 stored as bytes in memory (estimated size 67.5 KB, free 1990.0 MB)
2021-12-05 16:01:41,256 [dispatcher-event-loop-8] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_40_piece0 in memory on qb:53406 (size: 67.5 KB, free: 1990.6 MB)
2021-12-05 16:01:41,256 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 40 from broadcast at DAGScheduler.scala:1039
2021-12-05 16:01:41,257 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from ResultStage 55 (MapPartitionsRDD[71] at map at PaidPromotionAdjustParameter.scala:186) (first 15 tasks are for partitions Vector(0, 1))
2021-12-05 16:01:41,257 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 55.0 with 2 tasks
2021-12-05 16:01:41,257 [dispatcher-event-loop-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 55.0 (TID 94, localhost, executor driver, partition 0, ANY, 7649 bytes)
2021-12-05 16:01:41,257 [dispatcher-event-loop-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 55.0 (TID 95, localhost, executor driver, partition 1, ANY, 7649 bytes)
2021-12-05 16:01:41,257 [Executor task launch worker for task 94] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 55.0 (TID 94)
2021-12-05 16:01:41,257 [Executor task launch worker for task 95] INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 55.0 (TID 95)
2021-12-05 16:01:41,259 [Executor task launch worker for task 95] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 2 non-empty blocks out of 2 blocks
2021-12-05 16:01:41,259 [Executor task launch worker for task 94] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 2 non-empty blocks out of 2 blocks
2021-12-05 16:01:41,259 [Executor task launch worker for task 94] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-05 16:01:41,259 [Executor task launch worker for task 95] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-05 16:01:41,297 [Executor task launch worker for task 95] INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 55.0 (TID 95). 1054 bytes result sent to driver
2021-12-05 16:01:41,298 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 55.0 (TID 95) in 41 ms on localhost (executor driver) (1/2)
2021-12-05 16:01:41,299 [Executor task launch worker for task 94] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 55.0 (TID 94). 1054 bytes result sent to driver
2021-12-05 16:01:41,299 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 55.0 (TID 94) in 42 ms on localhost (executor driver) (2/2)
2021-12-05 16:01:41,299 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 55.0, whose tasks have all completed, from pool 
2021-12-05 16:01:41,299 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 55 (count at PaidPromotionAdjustParameter.scala:192) finished in 0.048 s
2021-12-05 16:01:41,299 [main] INFO [org.apache.spark.scheduler.DAGScheduler] - Job 22 finished: count at PaidPromotionAdjustParameter.scala:192, took 4.304847 s
2021-12-05 16:01:41,299 [main] INFO [PaidPromotion$] - 验证集用户列表数量：5278
2021-12-05 16:01:41,311 [main] INFO [org.apache.spark.SparkContext] - Starting job: take at PaidPromotionAdjustParameter.scala:193
2021-12-05 16:01:41,312 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 23 (take at PaidPromotionAdjustParameter.scala:193) with 1 output partitions
2021-12-05 16:01:41,312 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 57 (take at PaidPromotionAdjustParameter.scala:193)
2021-12-05 16:01:41,312 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 56)
2021-12-05 16:01:41,312 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2021-12-05 16:01:41,312 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 57 (MapPartitionsRDD[71] at map at PaidPromotionAdjustParameter.scala:186), which has no missing parents
2021-12-05 16:01:41,314 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_41 stored as values in memory (estimated size 190.8 KB, free 1989.8 MB)
2021-12-05 16:01:41,317 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_41_piece0 stored as bytes in memory (estimated size 67.6 KB, free 1989.7 MB)
2021-12-05 16:01:41,318 [dispatcher-event-loop-6] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_41_piece0 in memory on qb:53406 (size: 67.6 KB, free: 1990.6 MB)
2021-12-05 16:01:41,318 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 41 from broadcast at DAGScheduler.scala:1039
2021-12-05 16:01:41,318 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 57 (MapPartitionsRDD[71] at map at PaidPromotionAdjustParameter.scala:186) (first 15 tasks are for partitions Vector(0))
2021-12-05 16:01:41,318 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 57.0 with 1 tasks
2021-12-05 16:01:41,319 [dispatcher-event-loop-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 57.0 (TID 96, localhost, executor driver, partition 0, ANY, 7649 bytes)
2021-12-05 16:01:41,319 [Executor task launch worker for task 96] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 57.0 (TID 96)
2021-12-05 16:01:41,323 [Executor task launch worker for task 96] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 2 non-empty blocks out of 2 blocks
2021-12-05 16:01:41,323 [Executor task launch worker for task 96] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 1 ms
2021-12-05 16:01:41,337 [Executor task launch worker for task 96] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 57.0 (TID 96). 2686 bytes result sent to driver
2021-12-05 16:01:41,337 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 57.0 (TID 96) in 18 ms on localhost (executor driver) (1/1)
2021-12-05 16:01:41,337 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 57.0, whose tasks have all completed, from pool 
2021-12-05 16:01:41,338 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 57 (take at PaidPromotionAdjustParameter.scala:193) finished in 0.025 s
2021-12-05 16:01:41,338 [main] INFO [org.apache.spark.scheduler.DAGScheduler] - Job 23 finished: take at PaidPromotionAdjustParameter.scala:193, took 0.026040 s
2021-12-05 16:01:41,346 [main] INFO [PaidPromotion$] - 训练集用户实际观看列表-----------------------------------
2021-12-05 16:01:41,347 [main] INFO [org.apache.spark.SparkContext] - Starting job: count at PaidPromotionAdjustParameter.scala:203
2021-12-05 16:01:41,348 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 35 (union at PaidPromotionAdjustParameter.scala:154)
2021-12-05 16:01:41,348 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 24 (count at PaidPromotionAdjustParameter.scala:203) with 4 output partitions
2021-12-05 16:01:41,348 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 59 (count at PaidPromotionAdjustParameter.scala:203)
2021-12-05 16:01:41,348 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 58)
2021-12-05 16:01:41,348 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List(ShuffleMapStage 58)
2021-12-05 16:01:41,348 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ShuffleMapStage 58 (UnionRDD[35] at union at PaidPromotionAdjustParameter.scala:154), which has no missing parents
2021-12-05 16:01:41,349 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_42 stored as values in memory (estimated size 190.3 KB, free 1989.5 MB)
2021-12-05 16:01:41,351 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_42_piece0 stored as bytes in memory (estimated size 67.4 KB, free 1989.5 MB)
2021-12-05 16:01:41,351 [dispatcher-event-loop-11] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_42_piece0 in memory on qb:53406 (size: 67.4 KB, free: 1990.5 MB)
2021-12-05 16:01:41,352 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 42 from broadcast at DAGScheduler.scala:1039
2021-12-05 16:01:41,352 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 4 missing tasks from ShuffleMapStage 58 (UnionRDD[35] at union at PaidPromotionAdjustParameter.scala:154) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
2021-12-05 16:01:41,352 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 58.0 with 4 tasks
2021-12-05 16:01:41,352 [dispatcher-event-loop-9] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 58.0 (TID 97, localhost, executor driver, partition 0, ANY, 7994 bytes)
2021-12-05 16:01:41,353 [dispatcher-event-loop-9] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 58.0 (TID 98, localhost, executor driver, partition 1, ANY, 7994 bytes)
2021-12-05 16:01:41,353 [dispatcher-event-loop-9] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 2.0 in stage 58.0 (TID 99, localhost, executor driver, partition 2, ANY, 7994 bytes)
2021-12-05 16:01:41,353 [dispatcher-event-loop-9] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 3.0 in stage 58.0 (TID 100, localhost, executor driver, partition 3, ANY, 7994 bytes)
2021-12-05 16:01:41,353 [Executor task launch worker for task 97] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 58.0 (TID 97)
2021-12-05 16:01:41,353 [Executor task launch worker for task 99] INFO [org.apache.spark.executor.Executor] - Running task 2.0 in stage 58.0 (TID 99)
2021-12-05 16:01:41,353 [Executor task launch worker for task 98] INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 58.0 (TID 98)
2021-12-05 16:01:41,353 [Executor task launch worker for task 100] INFO [org.apache.spark.executor.Executor] - Running task 3.0 in stage 58.0 (TID 100)
2021-12-05 16:01:41,356 [Executor task launch worker for task 99] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/order_data.bcp:0+3442194
2021-12-05 16:01:41,356 [Executor task launch worker for task 97] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/order_data.bcp:0+3442194
2021-12-05 16:01:41,356 [Executor task launch worker for task 100] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/order_data.bcp:3442194+3442195
2021-12-05 16:01:41,357 [Executor task launch worker for task 98] INFO [org.apache.spark.rdd.HadoopRDD] - Input split: hdfs://hdp1:8020/sk/chongqing/data/order_data.bcp:3442194+3442195
2021-12-05 16:01:42,466 [Executor task launch worker for task 97] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 58.0 (TID 97). 862 bytes result sent to driver
2021-12-05 16:01:42,466 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 58.0 (TID 97) in 1114 ms on localhost (executor driver) (1/4)
2021-12-05 16:01:42,585 [Executor task launch worker for task 98] INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 58.0 (TID 98). 905 bytes result sent to driver
2021-12-05 16:01:42,585 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 58.0 (TID 98) in 1232 ms on localhost (executor driver) (2/4)
2021-12-05 16:01:46,789 [Executor task launch worker for task 100] INFO [org.apache.spark.executor.Executor] - Finished task 3.0 in stage 58.0 (TID 100). 862 bytes result sent to driver
2021-12-05 16:01:46,789 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 3.0 in stage 58.0 (TID 100) in 5436 ms on localhost (executor driver) (3/4)
2021-12-05 16:01:48,130 [Executor task launch worker for task 99] INFO [org.apache.spark.executor.Executor] - Finished task 2.0 in stage 58.0 (TID 99). 862 bytes result sent to driver
2021-12-05 16:01:48,131 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 2.0 in stage 58.0 (TID 99) in 6778 ms on localhost (executor driver) (4/4)
2021-12-05 16:01:48,131 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 58.0, whose tasks have all completed, from pool 
2021-12-05 16:01:48,131 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ShuffleMapStage 58 (union at PaidPromotionAdjustParameter.scala:154) finished in 6.783 s
2021-12-05 16:01:48,131 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - looking for newly runnable stages
2021-12-05 16:01:48,131 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - running: Set()
2021-12-05 16:01:48,131 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - waiting: Set(ResultStage 59)
2021-12-05 16:01:48,131 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - failed: Set()
2021-12-05 16:01:48,131 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 59 (MapPartitionsRDD[73] at map at PaidPromotionAdjustParameter.scala:197), which has no missing parents
2021-12-05 16:01:48,133 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_43 stored as values in memory (estimated size 191.2 KB, free 1989.3 MB)
2021-12-05 16:01:48,134 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_43_piece0 stored as bytes in memory (estimated size 67.8 KB, free 1989.2 MB)
2021-12-05 16:01:48,134 [dispatcher-event-loop-11] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_43_piece0 in memory on qb:53406 (size: 67.8 KB, free: 1990.4 MB)
2021-12-05 16:01:48,134 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 43 from broadcast at DAGScheduler.scala:1039
2021-12-05 16:01:48,135 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 4 missing tasks from ResultStage 59 (MapPartitionsRDD[73] at map at PaidPromotionAdjustParameter.scala:197) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
2021-12-05 16:01:48,135 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 59.0 with 4 tasks
2021-12-05 16:01:48,135 [dispatcher-event-loop-9] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 59.0 (TID 101, localhost, executor driver, partition 0, ANY, 7649 bytes)
2021-12-05 16:01:48,135 [dispatcher-event-loop-9] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 59.0 (TID 102, localhost, executor driver, partition 1, ANY, 7649 bytes)
2021-12-05 16:01:48,135 [dispatcher-event-loop-9] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 2.0 in stage 59.0 (TID 103, localhost, executor driver, partition 2, ANY, 7649 bytes)
2021-12-05 16:01:48,135 [dispatcher-event-loop-9] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 3.0 in stage 59.0 (TID 104, localhost, executor driver, partition 3, ANY, 7649 bytes)
2021-12-05 16:01:48,135 [Executor task launch worker for task 104] INFO [org.apache.spark.executor.Executor] - Running task 3.0 in stage 59.0 (TID 104)
2021-12-05 16:01:48,135 [Executor task launch worker for task 102] INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 59.0 (TID 102)
2021-12-05 16:01:48,135 [Executor task launch worker for task 103] INFO [org.apache.spark.executor.Executor] - Running task 2.0 in stage 59.0 (TID 103)
2021-12-05 16:01:48,135 [Executor task launch worker for task 101] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 59.0 (TID 101)
2021-12-05 16:01:48,137 [Executor task launch worker for task 102] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 4 non-empty blocks out of 4 blocks
2021-12-05 16:01:48,137 [Executor task launch worker for task 104] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 4 non-empty blocks out of 4 blocks
2021-12-05 16:01:48,137 [Executor task launch worker for task 104] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-05 16:01:48,137 [Executor task launch worker for task 102] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-05 16:01:48,137 [Executor task launch worker for task 103] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 4 non-empty blocks out of 4 blocks
2021-12-05 16:01:48,138 [Executor task launch worker for task 103] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 1 ms
2021-12-05 16:01:48,138 [Executor task launch worker for task 101] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 4 non-empty blocks out of 4 blocks
2021-12-05 16:01:48,138 [Executor task launch worker for task 101] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-05 16:01:48,155 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 956
2021-12-05 16:01:48,155 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 993
2021-12-05 16:01:48,155 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1012
2021-12-05 16:01:48,155 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 975
2021-12-05 16:01:48,155 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 979
2021-12-05 16:01:48,155 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1015
2021-12-05 16:01:48,155 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 973
2021-12-05 16:01:48,155 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 986
2021-12-05 16:01:48,155 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1016
2021-12-05 16:01:48,155 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 960
2021-12-05 16:01:48,155 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 977
2021-12-05 16:01:48,155 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1019
2021-12-05 16:01:48,155 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1010
2021-12-05 16:01:48,155 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 966
2021-12-05 16:01:48,155 [dispatcher-event-loop-6] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_41_piece0 on qb:53406 in memory (size: 67.6 KB, free: 1990.5 MB)
2021-12-05 16:01:48,156 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 968
2021-12-05 16:01:48,156 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 982
2021-12-05 16:01:48,156 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1004
2021-12-05 16:01:48,156 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1018
2021-12-05 16:01:48,156 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 999
2021-12-05 16:01:48,156 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1008
2021-12-05 16:01:48,156 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1017
2021-12-05 16:01:48,156 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 976
2021-12-05 16:01:48,156 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1006
2021-12-05 16:01:48,156 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 996
2021-12-05 16:01:48,156 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1002
2021-12-05 16:01:48,156 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1020
2021-12-05 16:01:48,156 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 988
2021-12-05 16:01:48,156 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1003
2021-12-05 16:01:48,156 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1007
2021-12-05 16:01:48,156 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1001
2021-12-05 16:01:48,156 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 952
2021-12-05 16:01:48,156 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 970
2021-12-05 16:01:48,156 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1000
2021-12-05 16:01:48,156 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 967
2021-12-05 16:01:48,156 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 954
2021-12-05 16:01:48,156 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1023
2021-12-05 16:01:48,156 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 994
2021-12-05 16:01:48,156 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1009
2021-12-05 16:01:48,156 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1005
2021-12-05 16:01:48,156 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 961
2021-12-05 16:01:48,156 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 990
2021-12-05 16:01:48,156 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 965
2021-12-05 16:01:48,156 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1014
2021-12-05 16:01:48,156 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1024
2021-12-05 16:01:48,156 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 969
2021-12-05 16:01:48,156 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 951
2021-12-05 16:01:48,156 [dispatcher-event-loop-7] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_40_piece0 on qb:53406 in memory (size: 67.5 KB, free: 1990.6 MB)
2021-12-05 16:01:48,157 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 998
2021-12-05 16:01:48,157 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 950
2021-12-05 16:01:48,157 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 981
2021-12-05 16:01:48,157 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 971
2021-12-05 16:01:48,157 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1013
2021-12-05 16:01:48,157 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 983
2021-12-05 16:01:48,157 [dispatcher-event-loop-1] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_39_piece0 on qb:53406 in memory (size: 67.1 KB, free: 1990.6 MB)
2021-12-05 16:01:48,157 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 987
2021-12-05 16:01:48,157 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 992
2021-12-05 16:01:48,157 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 985
2021-12-05 16:01:48,157 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 955
2021-12-05 16:01:48,157 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 953
2021-12-05 16:01:48,157 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 984
2021-12-05 16:01:48,157 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 972
2021-12-05 16:01:48,157 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 989
2021-12-05 16:01:48,157 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 958
2021-12-05 16:01:48,157 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 978
2021-12-05 16:01:48,157 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 964
2021-12-05 16:01:48,157 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 957
2021-12-05 16:01:48,157 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1022
2021-12-05 16:01:48,157 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 959
2021-12-05 16:01:48,157 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1021
2021-12-05 16:01:48,157 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 991
2021-12-05 16:01:48,157 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 980
2021-12-05 16:01:48,157 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 974
2021-12-05 16:01:48,157 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 962
2021-12-05 16:01:48,157 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1011
2021-12-05 16:01:48,157 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 995
2021-12-05 16:01:48,157 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 997
2021-12-05 16:01:48,157 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 963
2021-12-05 16:01:48,158 [dispatcher-event-loop-10] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_42_piece0 on qb:53406 in memory (size: 67.4 KB, free: 1990.7 MB)
2021-12-05 16:01:48,264 [Executor task launch worker for task 101] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 59.0 (TID 101). 1141 bytes result sent to driver
2021-12-05 16:01:48,264 [Executor task launch worker for task 102] INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 59.0 (TID 102). 1098 bytes result sent to driver
2021-12-05 16:01:48,264 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 59.0 (TID 101) in 129 ms on localhost (executor driver) (1/4)
2021-12-05 16:01:48,264 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 59.0 (TID 102) in 129 ms on localhost (executor driver) (2/4)
2021-12-05 16:01:48,265 [Executor task launch worker for task 103] INFO [org.apache.spark.executor.Executor] - Finished task 2.0 in stage 59.0 (TID 103). 1098 bytes result sent to driver
2021-12-05 16:01:48,265 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 2.0 in stage 59.0 (TID 103) in 130 ms on localhost (executor driver) (3/4)
2021-12-05 16:01:48,265 [Executor task launch worker for task 104] INFO [org.apache.spark.executor.Executor] - Finished task 3.0 in stage 59.0 (TID 104). 1098 bytes result sent to driver
2021-12-05 16:01:48,266 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 3.0 in stage 59.0 (TID 104) in 131 ms on localhost (executor driver) (4/4)
2021-12-05 16:01:48,266 [task-result-getter-0] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 59.0, whose tasks have all completed, from pool 
2021-12-05 16:01:48,266 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 59 (count at PaidPromotionAdjustParameter.scala:203) finished in 0.135 s
2021-12-05 16:01:48,266 [main] INFO [org.apache.spark.scheduler.DAGScheduler] - Job 24 finished: count at PaidPromotionAdjustParameter.scala:203, took 6.919239 s
2021-12-05 16:01:48,266 [main] INFO [PaidPromotion$] - 训练集用户列表数量：95323
2021-12-05 16:01:48,274 [main] INFO [org.apache.spark.SparkContext] - Starting job: take at PaidPromotionAdjustParameter.scala:204
2021-12-05 16:01:48,275 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 25 (take at PaidPromotionAdjustParameter.scala:204) with 1 output partitions
2021-12-05 16:01:48,275 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 61 (take at PaidPromotionAdjustParameter.scala:204)
2021-12-05 16:01:48,275 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 60)
2021-12-05 16:01:48,275 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2021-12-05 16:01:48,275 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 61 (MapPartitionsRDD[73] at map at PaidPromotionAdjustParameter.scala:197), which has no missing parents
2021-12-05 16:01:48,276 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_44 stored as values in memory (estimated size 191.4 KB, free 1990.0 MB)
2021-12-05 16:01:48,278 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_44_piece0 stored as bytes in memory (estimated size 67.9 KB, free 1990.0 MB)
2021-12-05 16:01:48,278 [dispatcher-event-loop-3] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_44_piece0 in memory on qb:53406 (size: 67.9 KB, free: 1990.6 MB)
2021-12-05 16:01:48,278 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 44 from broadcast at DAGScheduler.scala:1039
2021-12-05 16:01:48,279 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 61 (MapPartitionsRDD[73] at map at PaidPromotionAdjustParameter.scala:197) (first 15 tasks are for partitions Vector(0))
2021-12-05 16:01:48,279 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 61.0 with 1 tasks
2021-12-05 16:01:48,279 [dispatcher-event-loop-7] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 61.0 (TID 105, localhost, executor driver, partition 0, ANY, 7649 bytes)
2021-12-05 16:01:48,279 [Executor task launch worker for task 105] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 61.0 (TID 105)
2021-12-05 16:01:48,281 [Executor task launch worker for task 105] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 4 non-empty blocks out of 4 blocks
2021-12-05 16:01:48,281 [Executor task launch worker for task 105] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-05 16:01:48,315 [Executor task launch worker for task 105] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 61.0 (TID 105). 2414 bytes result sent to driver
2021-12-05 16:01:48,316 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 61.0 (TID 105) in 37 ms on localhost (executor driver) (1/1)
2021-12-05 16:01:48,316 [task-result-getter-1] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 61.0, whose tasks have all completed, from pool 
2021-12-05 16:01:48,316 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 61 (take at PaidPromotionAdjustParameter.scala:204) finished in 0.041 s
2021-12-05 16:01:48,316 [main] INFO [org.apache.spark.scheduler.DAGScheduler] - Job 25 finished: take at PaidPromotionAdjustParameter.scala:204, took 0.041494 s
2021-12-05 16:01:48,319 [main] INFO [org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter] - File Output Committer Algorithm version is 1
2021-12-05 16:01:48,384 [main] INFO [org.apache.spark.SparkContext] - Starting job: runJob at SparkHadoopWriter.scala:78
2021-12-05 16:01:48,384 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 26 (runJob at SparkHadoopWriter.scala:78) with 1 output partitions
2021-12-05 16:01:48,384 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 63 (runJob at SparkHadoopWriter.scala:78)
2021-12-05 16:01:48,384 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 62)
2021-12-05 16:01:48,384 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2021-12-05 16:01:48,385 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 63 (MapPartitionsRDD[75] at saveAsTextFile at PaidPromotionAdjustParameter.scala:206), which has no missing parents
2021-12-05 16:01:48,393 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_45 stored as values in memory (estimated size 267.1 KB, free 1989.7 MB)
2021-12-05 16:01:48,395 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_45_piece0 stored as bytes in memory (estimated size 95.9 KB, free 1989.6 MB)
2021-12-05 16:01:48,396 [dispatcher-event-loop-1] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_45_piece0 in memory on qb:53406 (size: 95.9 KB, free: 1990.5 MB)
2021-12-05 16:01:48,396 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 45 from broadcast at DAGScheduler.scala:1039
2021-12-05 16:01:48,396 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 63 (MapPartitionsRDD[75] at saveAsTextFile at PaidPromotionAdjustParameter.scala:206) (first 15 tasks are for partitions Vector(0))
2021-12-05 16:01:48,396 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 63.0 with 1 tasks
2021-12-05 16:01:48,396 [dispatcher-event-loop-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 63.0 (TID 106, localhost, executor driver, partition 0, ANY, 7943 bytes)
2021-12-05 16:01:48,397 [Executor task launch worker for task 106] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 63.0 (TID 106)
2021-12-05 16:01:48,401 [Executor task launch worker for task 106] INFO [org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter] - File Output Committer Algorithm version is 1
2021-12-05 16:01:48,485 [Executor task launch worker for task 106] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 2 non-empty blocks out of 2 blocks
2021-12-05 16:01:48,485 [Executor task launch worker for task 106] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-05 16:01:48,500 [Executor task launch worker for task 106] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 2 non-empty blocks out of 2 blocks
2021-12-05 16:01:48,500 [Executor task launch worker for task 106] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-05 16:01:51,918 [Executor task launch worker for task 106] INFO [org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter] - Saved output of task 'attempt_20211205160148_0075_m_000000_0' to hdfs://hdp1:8020/sk/chongqing/list/validation/_temporary/0/task_20211205160148_0075_m_000000
2021-12-05 16:01:51,918 [Executor task launch worker for task 106] INFO [org.apache.spark.mapred.SparkHadoopMapRedUtil] - attempt_20211205160148_0075_m_000000_0: Committed
2021-12-05 16:01:51,919 [Executor task launch worker for task 106] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 63.0 (TID 106). 1256 bytes result sent to driver
2021-12-05 16:01:51,919 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 63.0 (TID 106) in 3523 ms on localhost (executor driver) (1/1)
2021-12-05 16:01:51,919 [task-result-getter-3] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 63.0, whose tasks have all completed, from pool 
2021-12-05 16:01:51,919 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 63 (runJob at SparkHadoopWriter.scala:78) finished in 3.534 s
2021-12-05 16:01:51,919 [main] INFO [org.apache.spark.scheduler.DAGScheduler] - Job 26 finished: runJob at SparkHadoopWriter.scala:78, took 3.535835 s
2021-12-05 16:01:52,905 [main] INFO [org.apache.spark.internal.io.SparkHadoopWriter] - Job job_20211205160148_0075 committed.
2021-12-05 16:01:52,911 [main] INFO [org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter] - File Output Committer Algorithm version is 1
2021-12-05 16:01:53,043 [main] INFO [org.apache.spark.SparkContext] - Starting job: runJob at SparkHadoopWriter.scala:78
2021-12-05 16:01:53,044 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 27 (runJob at SparkHadoopWriter.scala:78) with 1 output partitions
2021-12-05 16:01:53,044 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 65 (runJob at SparkHadoopWriter.scala:78)
2021-12-05 16:01:53,044 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 64)
2021-12-05 16:01:53,044 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2021-12-05 16:01:53,044 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 65 (MapPartitionsRDD[77] at saveAsTextFile at PaidPromotionAdjustParameter.scala:207), which has no missing parents
2021-12-05 16:01:53,054 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_46 stored as values in memory (estimated size 267.7 KB, free 1989.3 MB)
2021-12-05 16:01:53,056 [dag-scheduler-event-loop] INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_46_piece0 stored as bytes in memory (estimated size 96.3 KB, free 1989.3 MB)
2021-12-05 16:01:53,057 [dispatcher-event-loop-5] INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_46_piece0 in memory on qb:53406 (size: 96.3 KB, free: 1990.5 MB)
2021-12-05 16:01:53,057 [dag-scheduler-event-loop] INFO [org.apache.spark.SparkContext] - Created broadcast 46 from broadcast at DAGScheduler.scala:1039
2021-12-05 16:01:53,057 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 65 (MapPartitionsRDD[77] at saveAsTextFile at PaidPromotionAdjustParameter.scala:207) (first 15 tasks are for partitions Vector(0))
2021-12-05 16:01:53,057 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 65.0 with 1 tasks
2021-12-05 16:01:53,057 [dispatcher-event-loop-3] INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 65.0 (TID 107, localhost, executor driver, partition 0, ANY, 7979 bytes)
2021-12-05 16:01:53,058 [Executor task launch worker for task 107] INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 65.0 (TID 107)
2021-12-05 16:01:53,063 [Executor task launch worker for task 107] INFO [org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter] - File Output Committer Algorithm version is 1
2021-12-05 16:01:53,169 [Executor task launch worker for task 107] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 4 non-empty blocks out of 4 blocks
2021-12-05 16:01:53,169 [Executor task launch worker for task 107] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-05 16:01:53,216 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1117
2021-12-05 16:01:53,216 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1057
2021-12-05 16:01:53,217 [dispatcher-event-loop-1] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_43_piece0 on qb:53406 in memory (size: 67.8 KB, free: 1990.5 MB)
2021-12-05 16:01:53,217 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1090
2021-12-05 16:01:53,217 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1103
2021-12-05 16:01:53,217 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1111
2021-12-05 16:01:53,217 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1049
2021-12-05 16:01:53,217 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1076
2021-12-05 16:01:53,217 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1062
2021-12-05 16:01:53,217 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1043
2021-12-05 16:01:53,217 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1059
2021-12-05 16:01:53,217 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1071
2021-12-05 16:01:53,217 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1098
2021-12-05 16:01:53,217 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1120
2021-12-05 16:01:53,217 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1085
2021-12-05 16:01:53,217 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1037
2021-12-05 16:01:53,217 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1035
2021-12-05 16:01:53,218 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1066
2021-12-05 16:01:53,218 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1044
2021-12-05 16:01:53,218 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1114
2021-12-05 16:01:53,218 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1093
2021-12-05 16:01:53,218 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1122
2021-12-05 16:01:53,218 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1040
2021-12-05 16:01:53,218 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1056
2021-12-05 16:01:53,218 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1075
2021-12-05 16:01:53,218 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1058
2021-12-05 16:01:53,218 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1051
2021-12-05 16:01:53,218 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1046
2021-12-05 16:01:53,218 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1031
2021-12-05 16:01:53,218 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1032
2021-12-05 16:01:53,218 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1097
2021-12-05 16:01:53,218 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1106
2021-12-05 16:01:53,218 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1092
2021-12-05 16:01:53,218 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1064
2021-12-05 16:01:53,218 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1091
2021-12-05 16:01:53,218 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1047
2021-12-05 16:01:53,218 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1112
2021-12-05 16:01:53,218 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1074
2021-12-05 16:01:53,218 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1025
2021-12-05 16:01:53,218 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1102
2021-12-05 16:01:53,218 [dispatcher-event-loop-10] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_45_piece0 on qb:53406 in memory (size: 95.9 KB, free: 1990.6 MB)
2021-12-05 16:01:53,218 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1123
2021-12-05 16:01:53,219 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1078
2021-12-05 16:01:53,219 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1084
2021-12-05 16:01:53,219 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1099
2021-12-05 16:01:53,219 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1072
2021-12-05 16:01:53,219 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1027
2021-12-05 16:01:53,219 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1110
2021-12-05 16:01:53,219 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1054
2021-12-05 16:01:53,219 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1118
2021-12-05 16:01:53,219 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1029
2021-12-05 16:01:53,219 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1080
2021-12-05 16:01:53,219 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1100
2021-12-05 16:01:53,219 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1119
2021-12-05 16:01:53,219 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1086
2021-12-05 16:01:53,219 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1083
2021-12-05 16:01:53,219 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1045
2021-12-05 16:01:53,219 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1116
2021-12-05 16:01:53,219 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1042
2021-12-05 16:01:53,219 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1109
2021-12-05 16:01:53,219 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1053
2021-12-05 16:01:53,219 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1087
2021-12-05 16:01:53,219 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1089
2021-12-05 16:01:53,219 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1079
2021-12-05 16:01:53,219 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1115
2021-12-05 16:01:53,219 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1061
2021-12-05 16:01:53,219 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1036
2021-12-05 16:01:53,219 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1050
2021-12-05 16:01:53,219 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1026
2021-12-05 16:01:53,219 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1121
2021-12-05 16:01:53,219 [dispatcher-event-loop-6] INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_44_piece0 on qb:53406 in memory (size: 67.9 KB, free: 1990.7 MB)
2021-12-05 16:01:53,219 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1107
2021-12-05 16:01:53,219 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1039
2021-12-05 16:01:53,219 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1096
2021-12-05 16:01:53,219 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1108
2021-12-05 16:01:53,219 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1041
2021-12-05 16:01:53,220 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1069
2021-12-05 16:01:53,220 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1082
2021-12-05 16:01:53,220 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1088
2021-12-05 16:01:53,220 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1068
2021-12-05 16:01:53,220 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1048
2021-12-05 16:01:53,220 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1113
2021-12-05 16:01:53,220 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1067
2021-12-05 16:01:53,220 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1063
2021-12-05 16:01:53,220 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1070
2021-12-05 16:01:53,220 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1101
2021-12-05 16:01:53,220 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1105
2021-12-05 16:01:53,220 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1104
2021-12-05 16:01:53,220 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1028
2021-12-05 16:01:53,220 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1033
2021-12-05 16:01:53,220 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1065
2021-12-05 16:01:53,220 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1077
2021-12-05 16:01:53,220 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1094
2021-12-05 16:01:53,220 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1060
2021-12-05 16:01:53,220 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1052
2021-12-05 16:01:53,220 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1081
2021-12-05 16:01:53,220 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1095
2021-12-05 16:01:53,220 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1034
2021-12-05 16:01:53,220 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1073
2021-12-05 16:01:53,220 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1030
2021-12-05 16:01:53,220 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1055
2021-12-05 16:01:53,220 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1038
2021-12-05 16:01:53,220 [Spark Context Cleaner] INFO [org.apache.spark.ContextCleaner] - Cleaned accumulator 1124
2021-12-05 16:01:53,228 [Executor task launch worker for task 107] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 4 non-empty blocks out of 4 blocks
2021-12-05 16:01:53,228 [Executor task launch worker for task 107] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-05 16:01:53,279 [Executor task launch worker for task 107] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 4 non-empty blocks out of 4 blocks
2021-12-05 16:01:53,279 [Executor task launch worker for task 107] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-05 16:01:53,332 [Executor task launch worker for task 107] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 4 non-empty blocks out of 4 blocks
2021-12-05 16:01:53,332 [Executor task launch worker for task 107] INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2021-12-05 16:02:16,442 [Executor task launch worker for task 107] INFO [org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter] - Saved output of task 'attempt_20211205160152_0077_m_000000_0' to hdfs://hdp1:8020/sk/chongqing/list/train/_temporary/0/task_20211205160152_0077_m_000000
2021-12-05 16:02:16,442 [Executor task launch worker for task 107] INFO [org.apache.spark.mapred.SparkHadoopMapRedUtil] - attempt_20211205160152_0077_m_000000_0: Committed
2021-12-05 16:02:16,444 [Executor task launch worker for task 107] INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 65.0 (TID 107). 1342 bytes result sent to driver
2021-12-05 16:02:16,445 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 65.0 (TID 107) in 23388 ms on localhost (executor driver) (1/1)
2021-12-05 16:02:16,445 [task-result-getter-2] INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 65.0, whose tasks have all completed, from pool 
2021-12-05 16:02:16,445 [dag-scheduler-event-loop] INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 65 (runJob at SparkHadoopWriter.scala:78) finished in 23.400 s
2021-12-05 16:02:16,446 [main] INFO [org.apache.spark.scheduler.DAGScheduler] - Job 27 finished: runJob at SparkHadoopWriter.scala:78, took 23.402377 s
2021-12-05 16:02:17,134 [main] INFO [org.apache.spark.internal.io.SparkHadoopWriter] - Job job_20211205160152_0077 committed.
2021-12-05 16:02:17,153 [main] INFO [org.spark_project.jetty.server.AbstractConnector] - Stopped Spark@5b800468{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2021-12-05 16:02:17,154 [main] INFO [org.apache.spark.ui.SparkUI] - Stopped Spark web UI at http://qb:4040
2021-12-05 16:02:17,163 [dispatcher-event-loop-10] INFO [org.apache.spark.MapOutputTrackerMasterEndpoint] - MapOutputTrackerMasterEndpoint stopped!
2021-12-05 16:02:17,242 [main] INFO [org.apache.spark.storage.memory.MemoryStore] - MemoryStore cleared
2021-12-05 16:02:17,242 [main] INFO [org.apache.spark.storage.BlockManager] - BlockManager stopped
2021-12-05 16:02:17,242 [main] INFO [org.apache.spark.storage.BlockManagerMaster] - BlockManagerMaster stopped
2021-12-05 16:02:17,244 [dispatcher-event-loop-3] INFO [org.apache.spark.scheduler.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint] - OutputCommitCoordinator stopped!
2021-12-05 16:02:17,246 [main] INFO [org.apache.spark.SparkContext] - Successfully stopped SparkContext
2021-12-05 16:02:17,247 [Thread-1] INFO [org.apache.spark.util.ShutdownHookManager] - Shutdown hook called
2021-12-05 16:02:17,248 [Thread-1] INFO [org.apache.spark.util.ShutdownHookManager] - Deleting directory C:\Users\ACER\AppData\Local\Temp\spark-c617d208-86d2-4411-8154-0710ec8ad843
